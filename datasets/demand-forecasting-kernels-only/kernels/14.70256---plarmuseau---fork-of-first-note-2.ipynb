{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsample = pd.read_csv('../input/sample_submission.csv')\n\ntrain['date'] = pd.to_datetime(train['date'])\ntest['date'] = pd.to_datetime(test['date'])\n\ntrain['month'] = train['date'].dt.month\ntrain['day'] = train['date'].dt.dayofweek\ntrain['year'] = train['date'].dt.year\n\ntest['month'] = test['date'].dt.month\ntest['day'] = test['date'].dt.dayofweek\ntest['year'] = test['date'].dt.year\n\ntrain['block'] = 60-((train['year']-2013)*12+train['month'])\ntrain['week'] = 260-((train['year']-2013)*52+train['date'].dt.week)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"928a58457b451a5422e87b4a1cba97038595d2c1"},"cell_type":"code","source":"    # Grouping by Date/Time to calculate number of trips\n    day_df = pd.Series(train.groupby(['date'])['sales'].sum())\n    # setting Date/Time as index\n    day_df.index = pd.DatetimeIndex(day_df.index)\n    # Resampling to daily trips\n    day_df = day_df.resample('1D').apply(np.sum)\n\n    day_df.plot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"135907e375ae710e973e8acd4261960352c18a37"},"cell_type":"markdown","source":"# trend - autocorrelation\n\n* there is a upward trend\n* there is a 7day  week autocorrelation effect\n* Yearly effects\n** there is a summer peak  effect\n** there is a 'halloween season' \n"},{"metadata":{"trusted":true,"_uuid":"acca44f08357e7d56d2604acbf0111b71e4c9648"},"cell_type":"code","source":"#Checking trend and autocorrelation\ndef initial_plots(time_series, num_lag):\n\n    #Original timeseries plot\n    plt.figure(1)\n    plt.plot(time_series)\n    plt.title('Original data across time')\n    plt.figure(2)\n    plot_acf(time_series, lags = num_lag)\n    plt.title('Autocorrelation plot')\n    plot_pacf(time_series, lags = num_lag)\n    plt.title('Partial autocorrelation plot')\n    \n    plt.show()\n\n    \n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\nprint('p-value: {}'.format(adfuller(day_df)[1]))\n\n#plotting\ninitial_plots(day_df, 45)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15b07450e046d3c54b3ec05fe72fbc08200aeffc"},"cell_type":"markdown","source":"# differencing\n\ntrend disappears as expected\n7day week effect remains"},{"metadata":{"trusted":true,"_uuid":"ffd5066826f71f57e258bebfa058d74fefd3bd39"},"cell_type":"code","source":"#storing differenced series\ndiff_series = day_df.diff(periods=1).diff(periods=7)\n\n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\nprint('p-value: {}'.format(adfuller(diff_series.dropna())[1]))\ninitial_plots(diff_series.dropna(), 30)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d2b7a9d6817dd3ccc29f4dc85bd3c3574abebf7"},"cell_type":"markdown","source":"# week arima\n\n* week effect disappears\n* differencing there is a year effect left over\n"},{"metadata":{"trusted":true,"_uuid":"b992e31ba8a0646fc518cd79ddc66c2822d40fc4"},"cell_type":"code","source":"    # Grouping by Date/Time to calculate number of trips\n    week_df = pd.Series(train.groupby(['week'])['sales'].sum())\n    # setting Date/Time as index\n    week_df.plot()\n    initial_plots(week_df, 45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad9a053e506941f4cff9168a101d693276ccf636"},"cell_type":"code","source":"#storing differenced series\ndiff_series = week_df.diff(periods=1)\n\n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\nprint('p-value: {}'.format(adfuller(diff_series.dropna())[1]))\ninitial_plots(diff_series.dropna(), 55)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fdae15cbc0fcd2161d27302fabc0052bc79ed42"},"cell_type":"markdown","source":"# month\n* year cycle very visible\n* differencing 1 month makes everything right\n"},{"metadata":{"trusted":true,"_uuid":"e9b3907feffe9efbcd2dc945b0459dbd47fdf4dc"},"cell_type":"code","source":"    # Grouping by Date/Time to calculate number of trips\n    month_df = pd.Series(train.groupby(['block'])['sales'].sum())\n    # setting Date/Time as index\n    month_df.plot()\n    initial_plots(month_df, 45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3937c565f4ff1fc4514737da93d952ea87974719"},"cell_type":"code","source":"#storing differenced series\ndiff_series = month_df.diff(periods=1).diff(periods=12)\n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\nprint('p-value: {}'.format(adfuller(diff_series.dropna())[1]))\ninitial_plots(diff_series.dropna(), 30)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc18c894149c4fe2d4a82483831a4a6673961109"},"cell_type":"markdown","source":"# a forecast brute"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"cb0aac6d0ebb0c8c0b79514686c7fbd39cdbb547"},"cell_type":"code","source":"train_p=train.pivot_table(index=['store', 'item'], columns='date', values='sales')\ntrain_p.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b9e85dee36dbd03e8497f0faa9fc45f56940638","collapsed":true},"cell_type":"code","source":"def piv_clust(data,veld,kolom,waarde,komponent):\n    from sklearn.decomposition import TruncatedSVD,FastICA\n    df = data.pivot_table(index=veld, columns=kolom, values=waarde, fill_value=0, aggfunc=np.sum)            #pivot table > signal should follow\n    svd = TruncatedSVD(n_components=komponent, n_iter=7, random_state=42)                                    #decomp functions\n    ica = FastICA(n_components=komponent, max_iter=1000, tol=0.1)\n    df_norm =( (df - df.mean()) / (df.max() - df.min()) ).fillna(0)                                          #normalize\n    return pd.DataFrame( np.concatenate([svd.fit_transform(df_norm)*svd.singular_values_, ica.fit_transform(df_norm)],axis=1) , index=df.index,columns=['clus'+str(x) for x in range(komponent+komponent)]),svd.explained_variance_ratio_  #U*S\n\n\nitem_c,item_sing=piv_clust(train,'item',['store','block'],'sales',10)\nstore_c,store_sing=piv_clust(train,'store',['item','block'],'sales',10)\n#train_s,sing_s=piv_clust(train_df,'shop_id',['item_category_id','date_block_num'],'item_price',10)\n#train_si,sing_si=piv_clust(train_df[train_df['date_block_num']>10],'item_id',['date_y'],'item_cnt_day',10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a927a02d4ae93388edea3452da47c8b74c671b0b","collapsed":true},"cell_type":"code","source":"train_t=train_p.merge(item_c,left_index=True,right_index=True)\ntrain_t=train_t.merge(store_c,left_index=True,right_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"077557c594ede0c765095d1747d3821ad864f5c3"},"cell_type":"code","source":"train_t.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a6a89a06a89952e72ec57750db2a91e6bb99b3b"},"cell_type":"code","source":"# Create linear regression object\nregr = linear_model.LinearRegression()\n\nfor xi in range(26,27):\n    # Train the model\n    x = train_t.iloc[:,1:]\n    y = train_t.iloc[:,0]\n    regr.fit(x, y)\n    # Make predictions\n    pred = regr.predict(x)\n    # The coefficients\n    print('Intercept: \\n', regr.intercept_)\n    print('Coefficients: \\n', regr.coef_)\n    # The mean squared error\n    print(xi,'MSRE: %.4f'%np.sqrt(((y-pred)*(y-pred)).mean()))\n    \n    train_f=train_p.iloc[:,:-1].merge(item_c,left_index=True,right_index=True)\n    train_f=train_f.merge(store_c,left_index=True,right_index=True)\n    pred =regr.predict(train_f)\n    print(pred)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb58014a738d45589929733fe4ddf0a5969059b7","collapsed":true},"cell_type":"code","source":"\ntest['block'] = 60-((test['year']-2013)*12+test['month'])\ntest.groupby(['store', 'item']).max()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"col = [i for i in test.columns if i not in ['date','id']]\ny = 'sales'\nprint(train_p.shape)\nytrain=train_p.iloc[:,-1:]\ntrain_x, train_cv, y, y_cv = train_test_split(train_p.iloc[:,-1:].reset_index(),ytrain, test_size=0.2, random_state=2018)\n\ndef XGB_regressor(train_X, train_y, test_X, test_y, feature_names=None, seed_val=2017, num_rounds=300):\n    param = {}\n    param['objective'] = 'reg:linear'\n    param['eta'] = 0.2\n    param['max_depth'] = 12\n    param['silent'] = 0\n    param['eval_metric'] = 'mae'\n    param['min_child_weight'] = 1\n    param['subsample'] = 0.7\n    param['colsample_bytree'] = 0.7\n    param['seed'] = seed_val\n    num_rounds = num_rounds\n\n    plst = list(param.items())\n\n    xgtrain = xgb.DMatrix(train_X, label=train_y)\n\n    if test_y is not None:\n        xgtest = xgb.DMatrix(test_X, label=test_y)\n        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=10)\n    else:\n        xgtest = xgb.DMatrix(test_X)\n        model = xgb.train(plst, xgtrain, num_rounds)\n        \n    return model    \n    \n    \nmodel = XGB_regressor(train_X = train_x, train_y = y, test_X = train_cv, test_y = y_cv)\ny_test = model.predict(xgb.DMatrix(pd.DataFrame(train_f,columns=train_p.iloc[:,-1:].columns).reset_index()), ntree_limit = model.best_ntree_limit)\nprint(y_test)\n#sample['sales'] = y_test\n#sample.to_csv('simple_xgb_starter.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}