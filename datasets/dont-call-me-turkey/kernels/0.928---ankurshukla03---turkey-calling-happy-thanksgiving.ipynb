{"cells":[{"metadata":{"_uuid":"5e673c44ffb1c656d9d714cc7aec1e722ad50180"},"cell_type":"markdown","source":"Thanks to this [Kernel](https://www.kaggle.com/michaelapers/lstm-starter-notebook/notebook) for easy and understandable approach. Trying different model for the prediction. Feel free to fork the notebook but do upvote it."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76fb7a0ac240b41b66987a1288c3d4b4eabce3eb"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Bidirectional,CuDNNLSTM, LSTM, BatchNormalization, Dropout, Input, Conv1D, Activation,CuDNNGRU, Reshape, GlobalMaxPooling1D, GlobalAveragePooling1D, concatenate\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Flatten\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"Let's read the data using pandas"},{"metadata":{"trusted":true,"_uuid":"bc121a39aeba02aa56f66ec5d87ec24d366ceff6"},"cell_type":"code","source":"train = pd.read_json('../input/train.json')\ntest = pd.read_json('../input/test.json')\nsample_submission = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42afab8380dcce48a3326bfdfa5564e76c682eeb"},"cell_type":"markdown","source":"Let's check the details of the above loaded files"},{"metadata":{"trusted":true,"_uuid":"af450a66f4de5996249c67971e7f71911879964f"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76d8185ed1e7d20ead249f5e29da17cb2f5ae3bd"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4f5d93ffd05e2397f618797c8862ce076bea614"},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"838387c6e0d80d173b58a7b84e3dfd4a555c5846"},"cell_type":"markdown","source":"Let's check the amount of data we have"},{"metadata":{"trusted":true,"_uuid":"f0177f65fe118817c3546f1d481d5a7cf367797c"},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e21d2beff2e172105b755c4f99d34c8c2880ab6"},"cell_type":"markdown","source":"Let's find how many real turkey sound we have in our train dataset"},{"metadata":{"trusted":true,"_uuid":"b9e04fa51500b86eb62923d2ba0b8f2f8ffca351"},"cell_type":"code","source":"turkey = len(train[train['is_turkey']==1])\nnot_turkey = len(train[train['is_turkey']==0])\nprint(\"Number of turkey sound :\",turkey)\nprint(\"Number of not turkey sound :\",not_turkey)\nprint(\"percentage of turkey sound {0:.2f}\".format(turkey/train.shape[0]))\nprint(\"percentage of not turkey sound {0:.2f}\".format(not_turkey/train.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"132f9b46a58050277a3b663dd086f4be57094a64"},"cell_type":"markdown","source":"Let's check how does the turkey sound"},{"metadata":{"trusted":true,"_uuid":"d466d9cf36f3d86b7783f88e4f02ffa37a38f058"},"cell_type":"code","source":"from IPython.display import YouTubeVideo\nrow = 3\nYouTubeVideo(train['vid_id'][row],start=train['start_time_seconds_youtube_clip'][row],end=train['end_time_seconds_youtube_clip'][row])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f228a5eb5c64bf865f5a3c08a6e6eb769e66d739"},"cell_type":"markdown","source":" Let's look at VGGish audio embeddings. You can get more details [here](https://github.com/tensorflow/models/tree/master/research/audioset#input-audio-features)"},{"metadata":{"trusted":true,"_uuid":"6e19e6b7313989dbb831ee912478513dceed9100"},"cell_type":"code","source":"print(train['audio_embedding'].head())\n\n#see the possible list lengths of the first dimension\nprint(\"train's audio_embedding can have this many frames: \"+ str(train['audio_embedding'].apply(lambda x: len(x)).unique())) \nprint(\"test's audio_embedding can have this many frames: \"+ str(test['audio_embedding'].apply(lambda x: len(x)).unique())) \n\n#see the possible list lengths of the first element\nprint(\"each frame can have this many features: \"+str(train['audio_embedding'].apply(lambda x: len(x[0])).unique()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d43bb32530c612e12875f61640136fd125813aed"},"cell_type":"markdown","source":"Let's divide the dataset into training and validation. Padding is required as you can see the embeddings can have uneven number of frames so we need to pad it for making the length of the frames equal"},{"metadata":{"trusted":true,"_uuid":"7df29dd49d944ebef707d6a087d8644b4b958b9d"},"cell_type":"code","source":"train_train, train_val = train_test_split(train)\nxtrain = train_train['audio_embedding'].tolist()\nytrain = train_train['is_turkey'].values\n\nxval = train_val['audio_embedding'].tolist()\nyval = train_val['is_turkey'].values\n\nx_train = pad_sequences(xtrain, maxlen=10)\nx_val = pad_sequences(xval, maxlen=10)\n\ny_train = np.asarray(ytrain)\ny_val = np.asarray(yval)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb9380ff9585fe88a77c365258554ae2e8d1357b"},"cell_type":"markdown","source":"## Define Model\n Trying differnet model"},{"metadata":{"trusted":true,"_uuid":"1b438e975e51a33bc3934500c00b05c8c9e2dfa9"},"cell_type":"code","source":"def first_model():\n    inp = Input((10, 128))\n    x = Conv1D(512, 10, padding='same')(inp)\n    x = Conv1D(256, 5, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Bidirectional(LSTM(512, return_sequences=True, recurrent_dropout=0.1))(x)\n    x = BatchNormalization()(x)\n    x = Conv1D(256, 10, padding='same')(x)\n    x = Conv1D(128, 5, padding='same')(x)\n    x = Bidirectional(LSTM(512, return_sequences=True, recurrent_dropout=0.1))(x)\n    x = Flatten()(x)\n    x = Dense(128, activation='relu')(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dense(1, activation='sigmoid')(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n    print(model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60c79f3be68953b07e34d12c59872ee6956a8e99"},"cell_type":"code","source":"def model2():\n    inp = Input(shape=(10, 128))\n    x = Conv1D(128, 1, padding='same')(inp)\n    x = BatchNormalization()(x)\n    x = Bidirectional(CuDNNGRU(256, return_sequences=True))(x)\n    x = Bidirectional(CuDNNGRU(128, return_sequences=True))(x)\n    avg_pool = GlobalAveragePooling1D()(x)\n    max_pool = GlobalMaxPooling1D()(x)\n    concat = concatenate([avg_pool, max_pool])\n    concat = Dense(64, activation=\"relu\")(concat)\n    concat = Dropout(0.5)(concat)\n    output = Dense(1, activation=\"sigmoid\")(concat)\n    model = Model(inputs=inp, outputs=output)\n    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n    print(model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33e270e27d38069cb7bc788f32b6ea95e4e9bc00"},"cell_type":"code","source":"# https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043\nclass Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a6d7cb8e35b1801157ca137f54ff70c015d13fc"},"cell_type":"code","source":"def model3():\n    model = Sequential()\n    model.add(BatchNormalization(momentum=0.90,input_shape=(10, 128)))\n    model.add(Bidirectional(CuDNNLSTM(128, return_sequences = True)))\n    model.add(Bidirectional(CuDNNLSTM(1, return_sequences = True)))\n    model.add(Attention(10))\n    model.add(Dense(1,activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    print(model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"348f589102b595572de495fd26661cdba6d285b0"},"cell_type":"markdown","source":"## Train the Model\nTill now model2 is performing best with 0.95 accuracy"},{"metadata":{"trusted":true,"_uuid":"0ee379f638da9e49ea482f8e0d2389bc69018188"},"cell_type":"code","source":"batch_size = 100\nepochs = 200\nmodel = first_model()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd8628e6df4a8d1ec4dbbad3993d34a25f2fde7a"},"cell_type":"markdown","source":"## Callbacks"},{"metadata":{"trusted":true,"_uuid":"b710463dc287a2fd9dfb69d9dd589e3c409ffdb0"},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                            patience=4, \n                                            verbose=1, \n                                            factor=0.5,\n                                            min_lr=0.00001)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                              patience=8,\n                              verbose=1,\n                              mode='min',\n                              restore_best_weights=True)\n\ncallback = [learning_rate_reduction,early_stopping]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"401244685147a514295a02597821b4f0c4d759e0"},"cell_type":"code","source":"history = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,validation_data=(x_val, y_val), callbacks=callback, verbose=2)\n\nscore, acc = model.evaluate(x_val, y_val, batch_size=batch_size)\nprint('Test accuracy:', acc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a2b82ebf23d8e0322e2e26b38b0bba3b240010f"},"cell_type":"markdown","source":"## Plotting the loss curves\nWe can see the model is converging very fast enough in just 7 or 8 epochs"},{"metadata":{"trusted":true,"_uuid":"79b94e0518e80915a7c2ab50367535008b0248d1"},"cell_type":"code","source":"#plt.figure(figsize=(12,8))\n#plt.plot(range(1, epochs+1), history.history['loss'], label='Train Accuracy')\n#plt.plot(range(1, epochs+1), history.history['val_loss'], label='Validation Accuracy')\n#plt.legend()\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"661fe130345241aa76ad1de185190d00e0d24009"},"cell_type":"markdown","source":"## Predicting Result "},{"metadata":{"trusted":true,"_uuid":"f02155e8da1e8834f85b906a0def34cc3ef8070f"},"cell_type":"code","source":"test_data = test['audio_embedding'].tolist()\nsubmission = model.predict(pad_sequences(test_data))\nsubmission = pd.DataFrame({'vid_id':test['vid_id'].values,'is_turkey':[x for y in submission for x in y]})\nsubmission['is_turkey'] = submission.is_turkey.round(0).astype(int)\nprint(submission.head(20))\nsubmission.to_csv('submission6.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8d28d469a8d088b1da2d8ebd12e0a91e8e7cab8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}