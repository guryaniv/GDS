{"nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "version": "3.6.3", "name": "python", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}}}, "nbformat_minor": 1, "cells": [{"cell_type": "markdown", "source": ["Hello everyone! In this kernel is represented 1 dimensional convolutional neural network. The idea is simple, without tuning of model's hyperparameters. The submission file is provided."], "metadata": {"_cell_guid": "102ad684-34c1-4813-a0e3-71e74b7ce003", "_uuid": "f3c80af0b8b741961fb9971aa18ba5f30c42654a"}}, {"cell_type": "markdown", "source": ["Feature binarization and scaling created by our team"], "metadata": {"_cell_guid": "af3ff81c-15a1-40ef-bf86-e57284969503", "_uuid": "54b2acb02e5f5b4b5efd15e3eab50c4f70da9f98"}}, {"outputs": [], "execution_count": null, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "\n", "SEED = 42\n", "np.random.seed(SEED)\n", "\n", "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n", "\n", "#binarization of features\n", "class FeatureBinarizatorAndScaler:\n", "    \"\"\" This class needed for scales and factorize features\n", "    \"\"\"\n", "    NUMERICAL_FEATURES = list()\n", "    CATEGORICAL_FEATURES = list()\n", "    BIN_FEATURES = list()\n", "    binarizers = dict()\n", "    scalers = dict()\n", "\n", "    def __init__(self, numerical=list(), categorical=list(), binfeatures = list(), binarizers=dict(), scalers=dict()):\n", "        self.NUMERICAL_FEATURES = numerical\n", "        self.CATEGORICAL_FEATURES = categorical\n", "        self.BIN_FEATURES = binfeatures\n", "        self.binarizers = binarizers\n", "        self.scalers = scalers\n", "\n", "    def fit(self, train_set):\n", "        for feature in train_set.columns:\n", "\n", "            if feature.split('_')[-1] == 'cat':\n", "                self.CATEGORICAL_FEATURES.append(feature)\n", "            elif feature.split('_')[-1] != 'bin':\n", "                self.NUMERICAL_FEATURES.append(feature)\n", "            else:\n", "                self.BIN_FEATURES.append(feature)\n", "        for feature in self.NUMERICAL_FEATURES:\n", "            scaler = StandardScaler()\n", "            self.scalers[feature] = scaler.fit(np.float64(train_set[feature]).reshape((len(train_set[feature]), 1)))\n", "        for feature in self.CATEGORICAL_FEATURES:\n", "            binarizer = LabelBinarizer()\n", "            self.binarizers[feature] = binarizer.fit(train_set[feature])\n", "\n", "    def transform(self, data):\n", "        binarizedAndScaledFeatures = np.empty((0, 0))\n", "        for feature in self.NUMERICAL_FEATURES:\n", "            if feature == self.NUMERICAL_FEATURES[0]:\n", "                binarizedAndScaledFeatures = self.scalers[feature].transform(np.float64(data[feature]).reshape(\n", "                    (len(data[feature]), 1)))\n", "            else:\n", "                binarizedAndScaledFeatures = np.concatenate((\n", "                    binarizedAndScaledFeatures,\n", "                    self.scalers[feature].transform(np.float64(data[feature]).reshape((len(data[feature]),\n", "                                                                                       1)))), axis=1)\n", "        for feature in self.CATEGORICAL_FEATURES:\n", "\n", "            binarizedAndScaledFeatures = np.concatenate((binarizedAndScaledFeatures,\n", "                                                         self.binarizers[feature].transform(data[feature])), axis=1)\n", "\n", "        for feature in self.BIN_FEATURES:\n", "            binarizedAndScaledFeatures = np.concatenate((binarizedAndScaledFeatures, np.array(data[feature]).reshape((len(data[feature]),\n", "                                                                                       1))), axis=1)\n", "\n", "        print(binarizedAndScaledFeatures.shape )\n", "\n", "        return binarizedAndScaledFeatures"], "metadata": {"_kg_hide-input": false, "_kg_hide-output": false, "_cell_guid": "834f3ba4-cc8b-4d39-b1ec-0bbce6c611f4", "collapsed": true, "_uuid": "1ace9b30137cf105e07400e29cfaca02cb24badc"}}, {"cell_type": "markdown", "source": ["Convolutional Neural Network implementation"], "metadata": {"_cell_guid": "af20eeb1-0f0a-4e5a-8a1c-b4b3db00d5b8", "_uuid": "5633409604267f6b9568d0b178bf069c15c27bce"}}, {"outputs": [], "execution_count": null, "cell_type": "code", "source": ["\n", "from keras.models import Sequential\n", "from keras.layers import Dense, Flatten, Convolution1D, Dropout\n", "from keras.optimizers import SGD\n", "from keras.initializers import random_uniform\n", "\n", "import pandas as pd\n", "\n", "X_train = pd.read_csv('../input/train.csv')\n", "y_train = X_train['target']\n", "X_test = pd.read_csv('../input/test.csv')\n", "test_id = X_test['id']\n", "X_test = X_test.drop(['id'], axis=1)\n", "X_train = X_train.drop(['id', 'target'], axis = 1)\n", "y_train1 = abs(-1+y_train)\n", "y_train = pd.concat([y_train, y_train1], axis=1)\n", "binarizerandscaler = FeatureBinarizatorAndScaler()\n", "binarizerandscaler.fit(X_train)\n", "X_train = binarizerandscaler.transform(X_train)\n", "X_test = binarizerandscaler.transform(X_test)\n", "y_train = y_train.as_matrix()\n", "\n", "\n", "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n", "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n", "\n", "#hyperparameters\n", "input_dimension = 226\n", "learning_rate = 0.0025\n", "momentum = 0.85\n", "hidden_initializer = random_uniform(seed=SEED)\n", "dropout_rate = 0.2\n", "\n", "\n", "# create model\n", "model = Sequential()\n", "model.add(Convolution1D(nb_filter=32, filter_length=3, input_shape=X_train.shape[1:3], activation='relu'))\n", "model.add(Convolution1D(nb_filter=16, filter_length=1, activation='relu'))\n", "model.add(Flatten())\n", "model.add(Dropout(dropout_rate))\n", "model.add(Dense(128, input_dim=input_dimension, kernel_initializer=hidden_initializer, activation='relu'))\n", "model.add(Dropout(dropout_rate))\n", "model.add(Dense(64, kernel_initializer=hidden_initializer, activation='relu'))\n", "model.add(Dense(2, kernel_initializer=hidden_initializer, activation='softmax'))\n", "\n", "sgd = SGD(lr=learning_rate, momentum=momentum)\n", "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['acc'])\n", "model.fit(X_train, y_train, epochs=5, batch_size=128)\n", "predictions = model.predict_proba(X_test)\n", "\n", "ans = pd.DataFrame(predictions)\n", "ans = ans[0]"], "metadata": {"collapsed": true, "_cell_guid": "cab4f87c-521d-4779-b598-42971064c240", "_uuid": "74271b30c7e41968023d919803285c2fe9649472"}}, {"outputs": [], "execution_count": null, "cell_type": "code", "source": ["# Create submission file\n", "sub = pd.DataFrame()\n", "sub['id'] = test_id\n", "sub['target'] = ans\n", "sub.to_csv('submission.csv', float_format='%.6f', index=False)\n"], "metadata": {"collapsed": true, "_cell_guid": "cdb1e843-5dc0-41b1-9aa2-0886bb6ebfb2", "_uuid": "deb477943486f87cc6939b0895b409a3e381369b"}}]}