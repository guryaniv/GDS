{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5da5a1eeaedddf3c019379686a9510491ad89b7"},"cell_type":"code","source":"import os \nimport sys \nimport random\nimport warnings\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport cv2\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input \nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\n\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"295261f58c6a8d6b9384b0bf0ae366ed326ffd46"},"cell_type":"code","source":"im_width=128\nim_hieght=128\nim_chan=1\npath_train='../input/train/'\npath_test='../input/test/'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"ids=['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013','7845115d01']\nplt.figure(figsize=(20,10))\nfor j, img_name in enumerate(ids):\n    q=j+1\n    img=load_img('../input/train/images/'+img_name+ '.png')\n    img_mask=load_img('../input/train/masks/'+img_name+'.png')\n    \n    plt.subplot(1,2*(1+len(ids)),q*2-1)\n    plt.imshow(img)\n    plt.subplot(1,2*(1+len(ids)),q*2)\n    plt.imshow(img_mask)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"347c2e49ebcb1ebb8bddb1265d6167ca49f32420"},"cell_type":"code","source":"train_ids= next(os.walk(path_train+'images'))[2]\ntest_ids= next(os.walk(path_test+'images'))[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96dfdf674a70715f73c8482b536d293a64e46243"},"cell_type":"code","source":"#get and resize the train images and masks\nX_train=np.zeros((len(train_ids), im_hieght, im_width, im_chan), dtype= np.uint8)\nY_train=np.zeros((len(train_ids), im_hieght, im_width, im_chan), dtype=np.bool)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(train_ids), total= len(train_ids)):\n    path= path_train\n    img= load_img(path +'/images/'+ id_)\n    x= img_to_array(img)[:,:,1]\n    x=resize(x, (128,128,1), mode='constant', preserve_range=True)\n    X_train[n]=x\n    mask= img_to_array(load_img(path+'/masks/'+id_))[:,:,1]\n    Y_train[n]=resize(mask,(128,128,1), mode='constant', preserve_range=True)\n    \nprint('Done')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"701acc62593b0b47fddba9f16455b48f78c3d339"},"cell_type":"code","source":"# checking if the data looks alright\nix= random.randint(0,len(train_ids))\nplt.imshow(np.dstack((X_train[ix], X_train[ix], X_train[ix])))\nplt.show()\ntmp=np.squeeze(Y_train[ix].astype(np.float32))\nplt.imshow(np.dstack((tmp,tmp,tmp)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42d9573038341e23e47cc32bdc345e41547894df"},"cell_type":"markdown","source":"****Train Model****\n\nour task is just like the segmentation model for nuclie detection and it is evaluated on iou metric. this is,nt in keras so we have to code it ourselves\n"},{"metadata":{"trusted":true,"_uuid":"b0fb5df623a64fcfce32072cf01c60b722af54ac"},"cell_type":"code","source":"# Define IoU metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4170e0b4709f8fa2f2e64f94deca5512a4764c8f"},"cell_type":"markdown","source":"This is the fun part. Building the sequential Model. The U-Net is basically looking like an Auto-Encoder with shortcuts.We're also sprinkling in some earlystopping to prevent overfitting. If you're running this on kaggle, this is the point, you want to have GPU support."},{"metadata":{"trusted":true,"_uuid":"7a076fcb6627f3729adf44fd24503341ecf3dd17"},"cell_type":"code","source":"# building a U-Net model\ninputs = Input((im_hieght, im_width, im_chan))\ns = Lambda(lambda x: x / 255) (inputs)\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\nu6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\nmodel.summary()\n               ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0047e8ed2acc47aa7d74a803e9b92d7efb9238e"},"cell_type":"code","source":"earlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True)\nresults = model.fit(X_train, Y_train, validation_split=0.1, batch_size=8, epochs=30, \n                    callbacks=[earlystopper, checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1d494586c65fa34ac1fed0720a97d0ebe0abf0b"},"cell_type":"code","source":"X_test=np.zeros((len(test_ids), im_hieght, im_width, im_chan), dtype= np.uint8)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n    path = path_test\n    img = load_img(path + '/images/' + id_)\n    x = img_to_array(img)[:,:,1]\n    sizes_test.append([x.shape[0], x.shape[1]])\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_test[n] = x\n\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84597501cbb567d0fdcee7d027a8f105691b7dbe"},"cell_type":"code","source":"# Predict on train, val and test\nmodel = load_model('model-tgs-salt-1.h5', custom_objects={'mean_iou': mean_iou})\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\npreds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\npreds_test = model.predict(X_test, verbose=1)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b54de4142da87a801ba87ea3f74d795b09b695d9"},"cell_type":"code","source":"# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in tnrange(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9873efbc9eb31331f04edc2c2afb56ecd90af39"},"cell_type":"code","source":"preds_test_upsampled[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f64420dea3615721e70ecfdd0fedce3b14ee6ddb"},"cell_type":"code","source":"# Perform a sanity check on some random training samples\nix = random.randint(0, len(preds_train_t))\nplt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\nplt.show()\ntmp = np.squeeze(Y_train[ix]).astype(np.float32)\nplt.imshow(np.dstack((tmp,tmp,tmp)))\nplt.show()\ntmp = np.squeeze(preds_train_t[ix]).astype(np.float32)\nplt.imshow(np.dstack((tmp,tmp,tmp)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00f39ca51716cdbcadbc0a93d00c90d7771a344b"},"cell_type":"code","source":"def RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n        \n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n\npred_dict = {fn[:-4]:RLenc(np.round(preds_test_upsampled[i])) for i,fn in tqdm_notebook(enumerate(test_ids))}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ec114cd44fdcb5959ab38d4ebe696c70d65cacc"},"cell_type":"code","source":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"337b5ca70b5dc246077c568628d970b21f58fe93"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}