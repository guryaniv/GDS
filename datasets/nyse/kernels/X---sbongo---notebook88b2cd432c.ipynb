{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "98b6c573-812c-7834-82b4-0c397027c9ff"
      },
      "outputs": [],
      "source": [
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import preprocessing\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "#read from fundamentals.csv\n",
        "#fundData = pd.read_csv(\"../input/fundamentals.csv\")\n",
        "priceData = pd.read_csv(\"../input/prices.csv\")\n",
        "\n",
        "#rename column name to prepare for merging\n",
        "#fundData = fundData.rename(columns={'Period Ending': 'date'})\n",
        "#fundData = fundData.rename(columns={'Ticker Symbol': 'symbol'})\n",
        "\n",
        "#print(fundData.head())\n",
        "#print(\"________\")\n",
        "#print(priceData.head())\n",
        "\n",
        "#innerjoin the fund table to the price table, since we only data that is complete \n",
        "#mergedTable = pd.merge(fundData, priceData, how='inner', on=['date', 'symbol'])\n",
        "#fill up all the NA fields\n",
        "#mergedTable = mergedTable.fillna(0)\n",
        "#mergedTable.to_csv('merged.csv')\n",
        "le = preprocessing.LabelEncoder()\n",
        "#mergedTable = priceData[\"symbol\"==\"WLTW\"]\n",
        "mergedTable = priceData.loc[priceData['symbol'] == \"WLTW\"]\n",
        "\n",
        "#print(mergedTable)\n",
        "print(\"________\")\n",
        "\n",
        "#then split into predictors and target sets\n",
        "targetSet = mergedTable.iloc[:,-4:-3]\n",
        "predictorSet = mergedTable.iloc[:,0:1]\n",
        "\n",
        "listP = [\"epoch\"]\n",
        "#encode the ticker string to integer\n",
        "#predictorSet[\"symbol\"] = le.fit_transform(predictorSet[\"symbol\"])\n",
        "#encode date\n",
        "predictorSet[\"date\"] = pd.to_datetime(predictorSet['date'])\n",
        "predictorSet['epoch'] = (predictorSet['date'] - dt.datetime(1970,1,1)).dt.total_seconds()\n",
        "#then drop date column\n",
        "#predictorSet = predictorSet.drop(['date'], axis=1)\n",
        "\n",
        "#print(targetSet)\n",
        "#print(predictorSet)\n",
        "print(\"________\")\n",
        "\n",
        "trainTargetData = targetSet[:200]\n",
        "trainPredictorData = predictorSet[:200]\n",
        "\n",
        "testTargetData = targetSet[200:]\n",
        "testPredictorData = predictorSet[200:]\n",
        "print(trainTargetData.head())\n",
        "print(trainPredictorData.head())\n",
        "print(testTargetData.head())\n",
        "print(testPredictorData.head())\n",
        "\n",
        "#print(testPredictorData[listP])\n",
        "#print(\"Contains NA values:\"+str(trainData.isnull().any().any()))\n",
        "\n",
        "#finally..\n",
        "lm = LinearRegression()\n",
        "lm.fit(trainPredictorData,trainTargetData) \n",
        "predictions = lm.predict(testPredictorData[listP])\n",
        "#print(predictions)\n",
        "predictions2 = predictions.copy()\n",
        "\n",
        "test = testTargetData.copy()\n",
        "#match actual and predicted ones\n",
        "test['predicted'] = predictions2\n",
        "print(test)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(testPredictorData[\"epoch\"], predictions)\n",
        "#ax.plot([testPredictorData[\"epoch\"].min(),testPredictorData[\"epoch\"].max()],[testTargetData[\"close\"].min(),testTargetData[\"close\"].max()], 'r:')\n",
        "ax.plot(testPredictorData[\"epoch\"], testTargetData[\"close\"], 'r:')\n",
        "ax.set_xlabel('date')\n",
        "ax.set_ylabel('price')\n",
        "plt.show()\n",
        "\n",
        "print(lm.score(testPredictorData, testTargetData))\n",
        "    \n",
        "#scores = cross_val_score(lm, iris.data, iris.target, cv=5)\n",
        "\n",
        "#print(\"training set size:\"+trainData.shape)\n",
        "#print(\"training set size:\"+testData.shape)\n",
        "#print(trainData)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}