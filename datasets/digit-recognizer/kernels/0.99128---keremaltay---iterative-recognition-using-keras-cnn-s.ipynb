{"cells":[{"metadata":{"_uuid":"c449dd0d015a26c76e22991380d4520a70287982"},"cell_type":"markdown","source":"# Purpose\nI'm trying to get familiar with the Kaggle kernels and explore model building. \n# Approach\nI'll start with an simple CNN architecture and iterate to improve performance of the model. \n# 1. Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\n\nfrom keras import backend as K\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization \nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.generic_utils import get_custom_objects\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a97f0cea46e52a3b73d20556887de5f849fba91a"},"cell_type":"markdown","source":"# 2. Load and handle data\nThe first column of the training data represents the output for the data, in which the rest of the columns represent the input. Kaggle does their testing on the test set. So in order to have my own guage on how well I'm going I divide the training set into two and have a validation set. Here I'm assuming the data sets come from the same distribution. Since we have a relatively small data I choose a 20% split."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Load the data\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\nx_train = train.iloc[:,1:].values.astype('float64')\ny_train = train.iloc[:,0].values.astype('int32')\ntest = test.values.astype('float64')\n\nm = x_train.shape[0]\n\n# Normalize and reshape\nx_train = x_train / 255\nx_train = x_train.reshape((m, 28, 28, 1))\ntest = test / 255\ntest = test.reshape((-1, 28, 28, 1))\n\n#One-hot output representaion\ny_train = to_categorical(y_train, num_classes = 10)\n\n# Split data\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2)\n\nprint(\"Number of examples: \", m)\nprint(\"Training input shape: \", x_train.shape)\nprint(\"Training output shape: \", y_train.shape)\nprint(\"Validate input shape: \", x_val.shape)\nprint(\"Validate output shape: \", y_val.shape)\nprint(\"Test input shape: \", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e2885fed1b4c42102bf46025b6b20be5843149f"},"cell_type":"markdown","source":"## Here's how the data looks like (below the code to show them) "},{"metadata":{"trusted":true,"_uuid":"138161f462ce07f299d421b77d6cc6c1f71158fc"},"cell_type":"code","source":"# Plot consecutive images\ndef sample_images(x,offset=0, sample_num=10):\n    for i in range(sample_num):\n        plt.subplot(math.ceil(sample_num/5), 5, i+1)\n        plt.imshow(x[offset + i][:, :, 0])\n    plt.show()\n\n# Plot an image given it's index\ndef sample_image(x, index):\n    plt.imshow(x[index][:, :, 0])\n\n\n#sample_image(x_train, 1)\nsample_images(x_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1a1fab738b8d42a8010fb643f7bfd4ad1a23e1c"},"cell_type":"markdown","source":"# 3. Hyperparameters\nI'll use epochs of 10 at each iteration and maybe a 30 for a final performance. I'll use a power of two for batches, 64 should be OK. (Hoping computer architecture helps performance)"},{"metadata":{"trusted":true,"_uuid":"2732408951dffcaecfa1aaefdd8ad18782df1965"},"cell_type":"code","source":"epochs = 20\nbatch_size = 64\nlearning_rate = 0.001\nactivation = 'tanh'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f549655ed06b2e0c75004152008b564d15adbbdc"},"cell_type":"markdown","source":"## Some custom activation functions below"},{"metadata":{"trusted":true,"_uuid":"dbf4fea46acc20101b7d6db248110bb6b2fd1ffd"},"cell_type":"code","source":"# Custom activations\ndef swish(x, beta=1):\n    return (K.sigmoid(beta*x) * x)\n\ndef aria(x, alpha=1.25, beta=1):\n    return ((K.sigmoid(beta*x)**alpha) * x)\n\nget_custom_objects().update({'swish': swish, 'aria': aria})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2629f9de4a7b812293cee8bc51440d328e90ca76"},"cell_type":"markdown","source":"# 4. Data augmentation\nMore relevant data is always welcome. Do not augment validation set as validation data should come from the same distributuion as the test set!<br/><br/> "},{"metadata":{"trusted":true,"_uuid":"e38a5f3b1d13bc1efdf595295fcae17286c36974","scrolled":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        rotation_range=10,\n        zoom_range = 0.1,\n        width_shift_range=0.1,\n        height_shift_range=0.1\n    )\ndatagen.fit(x_train)\n\nbatches = datagen.flow(x_train,y_train, batch_size=batch_size)\nprint(\"Number of training batches: \", len(batches))\n\nfirst_batch = batches[0][0]\nsample_images(first_batch, sample_num=25)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0441162212522ea8b5d478cbb38bdf43d306e6ef"},"cell_type":"markdown","source":"You can see the smaples from the augmented training set above. "},{"metadata":{"_uuid":"fef65228cf47a956ffb8d4b9ae323ced5e2938ba"},"cell_type":"markdown","source":"# 5. Models, Step by Step"},{"metadata":{"_uuid":"2f9e098dde9bc70e769a3c7d769c127b13a24262"},"cell_type":"markdown","source":"The first model I'll use will be a simple CNN. "},{"metadata":{"trusted":true,"_uuid":"2c529aa8ecc9010e2b960afd45dc584dc375c8e5"},"cell_type":"code","source":"def model_1():\n    model = Sequential()\n    model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', \n                     activation=activation, input_shape=(28,28,1)))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Flatten())\n    model.add(Dense(10, activation = \"softmax\"))\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"794e6635c57b39408c401d5953a0f30d33f3dbef"},"cell_type":"markdown","source":"Model 1, after 10 epochs, achives (loss: 0.0414 - acc: 0.9880 - val_loss: 0.0843 - val_acc: 0.9762). <br/> \nFor this MNSIT example I'm not getting into avoidable bias and assuming the best we can do is 1. That gives as an underfitting of 0.012 and overfitting 0.0118. These are already good results in my opinion. But let's be greedy, this might be a tutorial competition but still a competition. Let's go for a bigger network. "},{"metadata":{"trusted":true,"_uuid":"c2bf07f8419c46be0403ab3686e3786da8d97783"},"cell_type":"code","source":"#LeNet-5 like network\ndef model_2():\n    model = Sequential()\n    \n    # Layer1\n    model.add(Conv2D(filters=6, kernel_size=(5,5), activation=activation,\n                     padding = 'same', input_shape = (28,28,1)))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    # Layer2\n    model.add(Conv2D(filters=16, kernel_size=(5,5), activation=activation, \n                    padding = 'valid'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    #Layer3\n    model.add(Flatten())\n    model.add(Dense(120, activation=activation))\n    #Layer4\n    model.add(Dense(84, activation=activation))\n    #Layer5\n    model.add(Dense(10, activation = \"softmax\"))\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"838ffe86a75999ccd110d0d51b0e1cf475008619"},"cell_type":"markdown","source":"With valid padding(stride = 2):    (loss: 0.0124 - acc: 0.9966 - val_loss: 0.0558 - val_acc: 0.9838) <br />\nWith valid padding(stride = 1):     (loss: 0.0124 - acc: 0.9964 - val_loss: 0.0510 - val_acc: 0.9849)  <br />\nWith same padding(stride = 2):   (loss: 0.0071 - acc: 0.9981 - val_loss: 0.0495 - val_acc: 0.9849)  <br />\nWith same padding(stride = 1):    (loss: 0.0080 - acc: 0.9976 - val_loss: 0.0462 - val_acc: 0.9873)  <br />\nSame-valid padding(stride = 1):   (loss: 0.0073 - acc: 0.9980 - val_loss: 0.0533 - val_acc: 0.9839)  <br />\nIf you ask me why I tried all these combinations while the last one is more like the actual LeNet5, Keras just makes it too easy to try with no need to worry about the shapes of weights.  <br /><br />\nNow handling overfitting is more worthwhile for this model. Let's regularize. "},{"metadata":{"trusted":true,"_uuid":"afad104f1dd00e76509e443aa3c95b23eb150805"},"cell_type":"code","source":"# LeNet5 variation\ndef model_3():\n    model = Sequential()\n    \n    # Layer1\n    model.add(Conv2D(filters=6, kernel_size=(5,5), activation=activation,\n                     padding = 'same', input_shape = (28,28,1)))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    # Layer2\n    model.add(Conv2D(filters=16, kernel_size=(5,5), activation=activation, \n                    padding = 'same'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    #Layer3\n    model.add(Flatten())\n    model.add(Dense(120, activation=activation))\n    model.add(Dropout(0.25))\n    #Layer4\n    model.add(Dense(84, activation=activation))\n    model.add(Dropout(0.25))\n    #Layer5\n    model.add(Dense(10, activation = \"softmax\"))\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a014959b7de19c3b6ef01df159c8b25e0a45b5d8"},"cell_type":"markdown","source":"It didn't quite converge in 10 epochs now I'm using 20 with a book in front.<br/>\nlayer3 dropout 0.5, layer4 dropout 0.25:<br/>\n(loss: 0.0287 - acc: 0.9907 - val_loss: 0.0518 - val_acc: 0.9854)  <br/>\nlayer3 dropout 0.25, layer4 dropout 0.25:<br/>\n(loss: 0.0133 - acc: 0.9958 - val_loss: 0.0507 - val_acc: 0.9881)  <br/>\n\n<br/> For me convolutional weights always seem more precious so I first apply dropout on dense layers. "},{"metadata":{"_uuid":"598348604c723d30bceb6c8154f84429b7cb7933"},"cell_type":"markdown","source":"## Evaluate model "},{"metadata":{"trusted":true,"_uuid":"3b600cbef048e773d1df5a63f7e2cb61c4eb26af"},"cell_type":"code","source":"optimizer = Adam(lr=learning_rate)\nmodel = model_3()\nmodel.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78ed3f4541973309204055a0dd5ce5b4021874e6","scrolled":true},"cell_type":"code","source":"fitted_model = model.fit_generator(generator=batches, validation_data = (x_val,y_val), \n                                   epochs = epochs, steps_per_epoch = m // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1208188dd8832a60ac5bae707073f58911c592bf"},"cell_type":"code","source":"# Evaluate model\n# Loss plot\nplt.plot(fitted_model.history['loss'])\nplt.plot(fitted_model.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9b4b31f0eed692831cb1dbd2c3d5ca2621642e0"},"cell_type":"markdown","source":"# 6. Finishing\nUpon learning with the augmented data and having finalized the model, we can make use of the whole training set (including validation set). "},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"cfe987fc6bef4eaadd13428a437469c77735a397"},"cell_type":"code","source":"fitted_model = model.fit(np.concatenate((x_train, x_val), axis=0), \n                         np.concatenate((y_train, y_val), axis=0), \n                         batch_size=batch_size, epochs=epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb49c05f14bed7790dc7ef2e59cc0a78b12dbcce"},"cell_type":"code","source":"ypred = model.predict(test)\nypred = np.argmax(ypred,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d1f08b360fc66dcaeaa8e04aea5d59c53a1344d"},"cell_type":"markdown","source":"# Final notes\nYou can always loop between improving model, fighting overfitting and evaluating. Model_3 isn't the \"end all and be all\". <br/>"},{"metadata":{"trusted":true,"_uuid":"501869955c5062717c65eb6cd65e2f8c81c0b7e0"},"cell_type":"code","source":"submissions = pd.DataFrame({\"ImageId\": list(range(1,len(ypred)+1)),\n                         \"Label\": ypred})\nsubmissions.to_csv(\"cnn_model.csv\", index=False, header=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}