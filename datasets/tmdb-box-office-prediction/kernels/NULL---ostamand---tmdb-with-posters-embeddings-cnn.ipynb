{"cells":[{"metadata":{"_uuid":"f6b98dd9cb7c12e88e883ce412c0197de10984ea"},"cell_type":"markdown","source":"# TMDB with Posters Embeddings (CNN)\nUsing PyTorch 1.0.1.post2"},{"metadata":{"_uuid":"9aeddb5fd0e64a0c8f5908410a6eb7abcf85a847"},"cell_type":"markdown","source":"This kernel is more for fun than anything else. I am stuck at 1.98 RMSE & I don't want to scrape the internet for more features. \n\nAt this moment, it is a work in progress (an experiment). But, please, do follow along and if you have any idea on how it could be improved please leave a comment.\n\nI want to see if we can train a CNN to extract poster embeddings which could later be used as addtitionnal features in a gradient boosted tree. I created a dataset with all the posters of the training & test set (well I guess I did actually scrape the internet for more features hehe...)\n\nMy first try was to split the log of the revenue in ten different classes & train a CNN classifier. However, my results were not very satisfying with a final accuracy of about 20%.\n\nTherefore, I decided to combine some important features (determined by feature importance of a decision tree) with the output of a resnet18 (the poster embeddings).\n\nBelow, is the implementation in PyTorch. For now, I only consider the posters & the budget to predict the revenue. I will add more. "},{"metadata":{"_uuid":"95ce4ffd110f8d06ac1b1211f7dbaa377d75b327"},"cell_type":"markdown","source":"## Setup"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler \nfrom collections import Counter\nimport ast\nimport os \n\n%matplotlib inline\n\nimport pdb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e92d7e688a03bd590b2de0befedd772f5705157f"},"cell_type":"code","source":"torch.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12dd0019f3acce8121be112a5bdf7dae46ee4be2"},"cell_type":"code","source":"torch.cuda.is_available()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"_uuid":"c60936206ac9e36ceeddd57012274492a5a68bde"},"cell_type":"code","source":"!ls -c ../input/tmdb-box-office-prediction-posters/tmdb_box_office_prediction_posters/tmdb_box_office_prediction_posters","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true,"_uuid":"159a635fe1c711d5ada8e52948ed4a70344fdd54"},"cell_type":"code","source":"folder_posters = '../input/tmdb-box-office-prediction-posters/tmdb_box_office_prediction_posters/tmdb_box_office_prediction_posters'","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"_uuid":"3f6a48ff8e5c3d9a57dbdddc58c14816e0ef0061"},"cell_type":"code","source":"!ls -c ../input/tmdb-box-office-prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e7975ef1b79fe861cc99327ed540e0dc2d5390b"},"cell_type":"code","source":"folder_csv = '../input/tmdb-box-office-prediction'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Data"},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true,"_uuid":"9041378bc4ae088c9002352f89afd8036e2a929a"},"cell_type":"code","source":"# coming from an other kernel \n# will add the reference later\ndef clean(df):\n    \n    # Runtime na\n    df.loc[df.id == 1335, 'runtime'] = 119\n    df.loc[df.id == 1336, 'runtime'] = 130\n    df.loc[df.id == 2302, 'runtime'] = 100\n    df.loc[df.id == 2303, 'runtime'] = 81\n    \n    # Runtime 0\n    df.loc[df.id == 391, 'runtime'] = 86\n    df.loc[df.id == 592, 'runtime'] = 90\n    df.loc[df.id == 925, 'runtime'] = 86\n    df.loc[df.id == 978, 'runtime'] = 93\n    df.loc[df.id == 1256, 'runtime'] = 92\n    df.loc[df.id == 1542, 'runtime'] = 93\n    df.loc[df.id == 1875, 'runtime'] = 86\n    df.loc[df.id == 2151, 'runtime'] = 108\n    df.loc[df.id == 2499, 'runtime'] = 86\n    df.loc[df.id == 2646, 'runtime'] = 98\n    df.loc[df.id == 2786, 'runtime'] = 111\n    df.loc[df.id == 2866, 'runtime'] = 96\n    \n    df.loc[df.id == 3829, 'release_date'] = '6/1/00'\n    df.loc[df['id'] == 16,'revenue'] = 192864          # Skinning\n    df.loc[df['id'] == 90,'budget'] = 30000000         # Sommersby          \n    df.loc[df['id'] == 118,'budget'] = 60000000        # Wild Hogs\n    df.loc[df['id'] == 149,'budget'] = 18000000        # Beethoven\n    df.loc[df['id'] == 313,'revenue'] = 12000000       # The Cookout \n    df.loc[df['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\n    df.loc[df['id'] == 464,'budget'] = 20000000        # Parenthood\n    df.loc[df['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\n    df.loc[df['id'] == 513,'budget'] = 930000          # From Prada to Nada\n    df.loc[df['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\n    df.loc[df['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\n    df.loc[df['id'] == 850,'budget'] = 90000000        # Modern Times\n    df.loc[df['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\n    df.loc[df['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \n    df.loc[df['id'] == 1359,'budget'] = 10000000       # Stir Crazy \n    df.loc[df['id'] == 1542,'budget'] = 1              # All at Once\n    df.loc[df['id'] == 1542,'budget'] = 15800000       # Crocodile Dundee II\n    df.loc[df['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\n    df.loc[df['id'] == 1714,'budget'] = 46000000       # The Recruit\n    df.loc[df['id'] == 1721,'budget'] = 17500000       # Cocoon\n    df.loc[df['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\n    df.loc[df['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\n    df.loc[df['id'] == 2491,'revenue'] = 6800000       # Never Talk to Strangers\n    df.loc[df['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\n    df.loc[df['id'] == 2612,'budget'] = 15000000       # Field of Dreams\n    df.loc[df['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\n    df.loc[df['id'] == 2801,'budget'] = 10000000       # Fracture\n    df.loc[df['id'] == 3889,'budget'] = 15000000       # Colossal\n    df.loc[df['id'] == 6733,'budget'] = 5000000        # The Big Sick\n    df.loc[df['id'] == 3197,'budget'] = 8000000        # High-Rise\n    df.loc[df['id'] == 6683,'budget'] = 50000000       # The Pink Panther 2\n    df.loc[df['id'] == 5704,'budget'] = 4300000        # French Connection II\n    df.loc[df['id'] == 6109,'budget'] = 281756         # Dogtooth\n    df.loc[df['id'] == 7242,'budget'] = 10000000       # Addams Family Values\n    df.loc[df['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\n    df.loc[df['id'] == 5591,'budget'] = 4000000        # The Orphanage\n    df.loc[df['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\n\n    if 'revenue' in df.columns.values:\n        power_six = df.id[df.budget > 1000][df.revenue < 100]\n\n        for k in power_six :\n            df.loc[df['id'] == k,'revenue'] =  df.loc[df['id'] == k,'revenue'] * 1000000\n            \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4af648f8b31b8c96d79b477fc41b2cc6d26b13a","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_features_data(df):\n    # work on a copy \n    df = df.copy()\n    \n    # transform json\n    jsons = [\n        'crew', \n        'cast', \n        'Keywords',  \n        'genres', \n        'belongs_to_collection', \n        'production_companies', \n        'production_countries', \n        'spoken_languages'\n    ]\n    for j in jsons: \n        df[j] = df[j].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x))\n        \n    # release date year \n    release_date = pd.to_datetime(df.release_date, format='%m/%d/%y')\n    df['release_date_year'] = release_date.dt.year.apply(lambda x: x-100 if x>2018 else x)\n    df['release_date_month'] = release_date.dt.month\n    df['release_date_day'] = release_date.dt.day\n    df['release_date_quarter'] = release_date.dt.quarter\n    df['release_date_weekday'] = release_date.dt.weekday\n    df['release_date_weekofyear'] = release_date.dt.weekofyear\n    \n    # genres \n    df.genres = df.genres.apply(lambda x: [item['name'] for item in x])\n    df['num_genres'] = df.genres.apply(lambda x: len(x))\n    df.num_genres = df.num_genres.astype('float64')\n    \n    # one hot genre \n    genres = ['Drama', 'Comedy', 'Thriller', 'Action', 'Romance', 'Crime', \n              'Adventure', 'Horror', 'Science Fiction', 'Family', \n              'Fantasy', 'Mystery', 'Animation', 'History', 'Music', 'War', \n              'Documentary', 'Western', 'Foreign']\n    \n    genres_one_hot = np.zeros((len(df.genres),len(genres)))\n    for i in range(len(df)):\n        for j, genre in enumerate(genres):\n            row = df.iloc[i]\n            if genre in row['genres']:\n                genres_one_hot[i,j] = 1 \n                \n    # cast\n    cast = df.cast.apply( lambda x: ','.join([c['name'] for c in x] ))\n    df['size_of_cast'] = cast.apply(lambda x: len(x.split(',')))\n    \n    # crew\n    df['size_of_crew'] =  df['crew'].apply(lambda x: len(x))\n    \n    df['total_crew'] = df['size_of_crew'] + df['size_of_cast']\n                \n    # budget\n    df['log_budget'] = np.log1p(df.budget)\n    df['budget_by_runtime'] = df['budget']/df['runtime']\n    df['budget_by_popularity'] = df['budget']/df['popularity']\n    df['release_year_by_popularity'] = df['release_date_year']/df['popularity']\n    df['popularity_by_release_year'] = df['popularity']/df['release_date_year']\n\n    # scaled data \n    cols_to_scale = [\n        'release_date_year',\n        'release_date_month',\n        'release_date_day',\n        'release_date_quarter',\n        'release_date_weekday',\n        'release_date_weekofyear',\n        'popularity',\n        'budget', \n        'budget_by_runtime',\n        'budget_by_popularity',\n        'runtime', \n        'num_genres',\n        'log_budget', \n        'release_year_by_popularity', \n        'popularity_by_release_year',\n        'size_of_cast',\n        'size_of_crew'\n    ]\n    # make sure it is float before \n    for col in cols_to_scale:\n         df[col].astype('float64')\n            \n    scaler = StandardScaler()\n    data = scaler.fit_transform(df[cols_to_scale])\n    \n    # add other columns not to be scaled \n    data = np.concatenate([data,genres_one_hot], axis=1)\n    \n    return data, scaler ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ad29ec80a28da7900922dd6cc86b9c0c1edc45e"},"cell_type":"code","source":"df = pd.read_csv(f\"{os.path.join(folder_csv, 'train.csv')}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23f889da7fb4617295a1c5190e7c6ca4724482b1"},"cell_type":"code","source":"df = clean(df)\ntest, scaler = get_features_data(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5b6f28a70cd061bfde9acb670376cce928225da"},"cell_type":"code","source":"torch.from_numpy(test[0]).float().cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5045097cb118999f0fc7033bd74d8340f1e43951","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f154dd185f3ca752de9de97eef72c5739513abc4","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"sample_img_path  = os.path.join(os.path.join(folder_posters, 'train'), f\"{df.iloc[10].id}.jpeg\")\nplt.figure(figsize=(5,5))\nplt.imshow(Image.open(sample_img_path))\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"075c5ad3a9d4496e9694e84715bc5331cd325b64"},"cell_type":"code","source":"class MovieDataset(Dataset):\n    def __init__(self, csv_file, img_folder, transform=None, idx=None):\n        self.csv_file = csv_file\n        self.img_folder = img_folder \n        self.transform = transform\n        self.df = clean(pd.read_csv(csv_file))\n        # missing poster, will drop data for now \n        self.df.drop(self.df[self.df.id == 2303].index, inplace=True)\n        \n        # create features from dataframe \n        self.data, self.scaler = get_features_data(self.df)\n        self.fs = self.data.shape[1]\n        \n        if idx is not None:\n            self.df = self.df.iloc[idx]\n            \n        self.cols = self.df.columns.values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx): \n        features = torch.from_numpy(self.data[idx,:]).float()\n        img_path = os.path.join(self.img_folder, f\"{self.df.iloc[idx].id}.jpeg\")\n        target = None\n        if 'revenue' in self.cols:\n            target = np.log1p(self.df.iloc[idx].revenue)\n        image = Image.open(img_path)   \n        if self.transform:\n            image = self.transform(image)\n        return {'images': image, 'features': features, 'targets': target}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f39dcf0ecffa9edbeceba21f523d6786802793af"},"cell_type":"code","source":"def get_dataset(idx=None):\n    data_transform = transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, .456, 0.406], # imagenet normalization\n                             std=[0.229, 0.224, 0.225])\n    ])\n    dataset = MovieDataset(csv_file=f\"{os.path.join(folder_csv, 'train.csv')}\", \n                           img_folder=f\"{os.path.join(folder_posters, 'train')}\", \n                           transform=data_transform, \n                           idx=idx)\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6209d854f9539f215d06fd95ebadddaed9128acd","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"idx = [i for i in range(len(df)-1)]\nidx = np.random.permutation(idx)\ntrain_idx = idx[:round(0.9*(len(idx)))]\nvalid_idx = idx[round(0.9*(len(idx))):]\nlen(valid_idx) / (len(valid_idx) + len(train_idx))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b459ed0f7df31c80597314dbde810b677656af4","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train_dataset = get_dataset(idx=train_idx)\nvalid_dataset = get_dataset(idx=valid_idx)\nlen(valid_dataset) / (len(train_dataset) + len(valid_dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e45746df400b0437240362dcca1e207f4aa621f0"},"cell_type":"code","source":"train_dataset.fs","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0cd83c4e7a93820dc551d5d594d771e01e926b4"},"cell_type":"markdown","source":"Print some images and associated revenue from the MovieDataset."},{"metadata":{"trusted":true,"_uuid":"b0e81e0b98009ee880aee30729bc9e8c0f702e78"},"cell_type":"code","source":"dataloader = DataLoader(get_dataset(), batch_size=4, shuffle=True, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0fb14ea9d7895e40e8132fecd81927c31d445c5"},"cell_type":"code","source":"for _, sample_batch in enumerate(dataloader):\n    image = sample_batch['images']\n    revenue = sample_batch['targets']\n    batch_size = image.shape[0]\n    fig = plt.figure(figsize=(20,20))\n    for i in range(batch_size):\n        ax = plt.subplot(1, batch_size, i + 1)\n        plt.tight_layout()\n        data = image[i].cpu().numpy().transpose((1, 2, 0))\n        plt.imshow(np.interp(data, (data.min(), data.max()), (0, 1)))\n        ax.axis('off')\n        ax.set_title(f\"Sample {i+1}, Revenue: {revenue[i]:.2f}\")\n    plt.show()\n    break","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f68cd3bcbce9ecb9266313afec56485245e7d719"},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true,"_uuid":"cb622cec03a30722b587b81286a8a2f00797baab"},"cell_type":"code","source":"class WithPosterEmbeddings(nn.Module):\n    \n    def __init__(self, features_size, dp=0.5):\n        super().__init__()\n        self.dp = dp\n        self.img_emb_size = 10 # change image embedding size \n        self.features_size = features_size\n        \n        self.resnet18 = models.resnet18(pretrained=True)\n        # freeze all layers\n        for param in self.resnet18.parameters():\n            param.requires_grad = False\n            \n        #bs, drp, linear, relu   \n        self.resnet18.fc = nn.Sequential(\n            nn.BatchNorm1d(512),\n            nn.Dropout(self.dp),\n            nn.Linear(512, 1000, bias=True),\n            nn.ReLU(),\n            nn.BatchNorm1d(1000),\n            nn.Dropout(self.dp),\n            nn.Linear(1000, self.img_emb_size, bias=True),\n            nn.ReLU(),\n            nn.Dropout(self.dp) # dropout on the poster embeddings\n        )\n        \n        self.l1 = nn.Sequential(\n            nn.BatchNorm1d(self.img_emb_size + self.features_size), \n            nn.Linear(self.img_emb_size + self.features_size,512), \n            nn.ReLU()\n        )\n        \n        self.l2 = nn.Sequential(\n            nn.BatchNorm1d(512),\n            nn.Dropout(self.dp),\n            nn.Linear(512,256),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(self.dp),\n            nn.Linear(256,1) \n        )\n        \n    \"\"\" imgs: posters\n        x: features\n    \"\"\"\n    def forward(self, imgs, features, skip_cnn=False):\n        x = self.resnet18(imgs)\n        if skip_cnn: \n            x = torch.zeros(imgs.size(0),self.img_emb_size).float().cuda()\n        x = torch.cat([x, features], dim=1)\n        x = self.l2(self.l1(x))\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b08fb6eb4d752aac4183f501131fff60d10467e0"},"cell_type":"markdown","source":"## Train"},{"metadata":{"trusted":true,"_uuid":"8a6e6020e400e6734f5fb2006f0ee95c11861e11"},"cell_type":"code","source":"fs = 36 # feature size\n\nepochs =  50\nwd = 0.001\nlr = 1e-3\ndropout=0.5\nbs = 8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06754f7708f45b29455fe18dcd963c5a30fa266e","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"def calculate_rmse(model, dataloader, monitor=False, skip_cnn=False):\n    criterion = nn.MSELoss()\n    model.eval()\n    losses = []\n    for sample_batch in tqdm(dataloader, disable=(not monitor)):\n        images = sample_batch['images'].cuda()\n        features = sample_batch['features'].cuda()\n        targets = sample_batch['targets'].float().cuda()\n        \n        preds = model(images, features, skip_cnn=skip_cnn)\n        loss = criterion(preds,targets)\n        \n        losses.append( loss.item() * len(sample_batch))\n        \n    # set the model to train mode\n    model.train()\n    return np.sqrt(np.mean(losses))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"_uuid":"87067e187543d0b99d10c543637d3a6dc449dcfb"},"cell_type":"markdown","source":"```\nmodel = WithPosterEmbeddings(features_size = fs).cuda()\ndataloader_train = DataLoader(get_dataset(idx=train_idx), batch_size=bs, shuffle=True, num_workers=4)\ndataloader_iter = iter(dataloader_train)\nsample_batch = next(dataloader_iter)\nimages = sample_batch['images'].cuda()\nfeatures = sample_batch['features'].cuda()\ntargets = sample_batch['targets'].float().cuda()\n```"},{"metadata":{"trusted":true,"_uuid":"e5af066ea0ad1b5da8ae8454fbfffb3377540aaf"},"cell_type":"code","source":"# model & dataloader\nmodel = WithPosterEmbeddings(features_size = fs, dp=dropout).cuda()\ndataloader_train = DataLoader(get_dataset(idx=train_idx), batch_size=bs, shuffle=True, num_workers=4)\ndataloader_valid = DataLoader(get_dataset(idx=valid_idx), batch_size=bs, shuffle=True, num_workers=4)\n\ncriterion = nn.MSELoss()\nopt = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\nlr_sch = lr_scheduler.ReduceLROnPlateau(opt,'min', factor=0.1, patience=10, verbose=True) # learning rate scheduler \n\ni = 0\nrunning_losses = []\ntrain_losses = []\nvalid_losses = []\nfor epoch_i in range(epochs):\n    print(f\"Epoch {epoch_i+1}/{epochs}\")\n    running_loss = 0\n    for sample_batch in tqdm(dataloader_train):\n        images = sample_batch['images'].cuda()\n        features = sample_batch['features'].cuda()\n        targets = sample_batch['targets'].float().cuda()\n        \n        preds = model(images, features)\n        loss = criterion(preds,targets.unsqueeze(1))\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n        running_losses.append((i, loss.item() ))\n        i+=1\n        \n    print('Calculating validation loss..')\n    valid_losses.append((i, calculate_rmse(model, dataloader_valid)))\n    lr_sch.step(valid_losses[-1][1])\n    \n    print('Calculating train loss..')\n    train_losses.append((i, calculate_rmse(model, dataloader_train)))\n        \n    print(f\"Loss: {train_losses[-1][1]:.3f} (train) {valid_losses[-1][1]:.3f} (valid)\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e31f15f86d0f2d4a3ebefe55dfce9cfc83198e83"},"cell_type":"markdown","source":"* Loss: 2.939 (train) 4.986 (valid)"},{"metadata":{"_uuid":"9a64fb69aca6a1a081b4adb238851e6462b22387"},"cell_type":"markdown","source":"Plot losses"},{"metadata":{"trusted":true,"_uuid":"aa1ed8b26803342fcd2bf46af22cde3f37165a5a","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_rmse(train_losses, valid_losses):\n    plt.figure(figsize=(10,10))\n    plt.xlabel('Iteration #')\n    plt.ylabel('RMSE loss')\n    \n    it, loss = zip(*train_losses)\n    plt.plot(it, loss, marker='o')\n    \n    it, loss = zip(*valid_losses)\n    plt.plot(it, loss, marker='o')\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a265192464f6961ba2c8c04a2ac6c4469da7286c"},"cell_type":"code","source":"plot_rmse(train_losses, valid_losses)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2147ce14e260709d515d8a0a288cd8d1c046b7f9"},"cell_type":"markdown","source":"To verify if the poster embeddings did learn some features, I will calculate the RMSE with & without the embeddings on the validation set. "},{"metadata":{"trusted":true,"_uuid":"e881bac78a9fe7984241c00937abdf200c395d5b"},"cell_type":"code","source":"no_poster = calculate_rmse(model, dataloader_valid, skip_cnn=True)\nwith_poster = calculate_rmse(model, dataloader_valid, skip_cnn=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd2f2a8b59c69243cba6124be74296663914a431"},"cell_type":"code","source":"print(f\"Loss: {with_poster:.3f} (poster) {no_poster:.3f} (no poster)\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36907e1bdbf2e7edbc824a773495d0cbd7dc82df"},"cell_type":"markdown","source":"So, for now, the embeddings are making things actually worst (yeah! :P)\n\nThings I want to try:\n- Data augmentation on the posters\n- Adding more features. For now I only have the budget. Add more, maybe it will help the cnn part to learn embeddings.\n- After a first training phase, freeze the features layers & train only the cnn part. "},{"metadata":{"trusted":true,"_uuid":"bdb55c6fb3997df15da583adf82b7aed8495a629"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}