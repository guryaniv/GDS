{"nbformat_minor": 1, "cells": [{"outputs": [], "execution_count": null, "source": ["import pandas as pd\n", "import numpy as np\n", "from sklearn.metrics import log_loss\n", "import re,string\n", "import nltk\n", "from nltk.corpus import stopwords\n", "from nltk.stem import SnowballStemmer\n", "import string\n", "from sklearn.cross_validation import train_test_split\n", "import xgboost as xgb\n", "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n", "from sklearn.decomposition import TruncatedSVD\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv(\"../input/test.csv\")\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code", "metadata": {"_cell_guid": "fe97bcf1-f56e-43d8-b0e6-ebbe01e4084f", "_uuid": "641615bd571a34f7b79bf22121a9788b9d00ad17"}}, {"outputs": [], "execution_count": null, "source": ["train.shape,test.shape"], "cell_type": "code", "metadata": {}}, {"outputs": [], "execution_count": null, "source": ["train.drop(['id','qid1','qid2'],inplace=True,axis=1)\n", "target = train['is_duplicate']\n", "train.drop('is_duplicate',axis=1,inplace=True)"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["def similar(row):\n", "    try:\n", "        q1 = set(re.sub(\"[^\\w]\", \" \",  row['question1'].lower()).split())\n", "        q2 = set(re.sub(\"[^\\w]\", \" \",  row['question2'].lower()).split())\n", "        return len(q1 & q2)\n", "    except:\n", "        return 0"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["def unsimilar(row):\n", "    try:\n", "        q1 = set(re.sub(\"[^\\w]\", \" \",  row['question1'].lower()).split())\n", "        q2 = set(re.sub(\"[^\\w]\", \" \",  row['question2'].lower()).split())\n", "        o = q1&q2\n", "        o1 = q1 - o\n", "        o2 = q2 - o\n", "        return len(o1) + len(o2)\n", "    except:\n", "        return 0"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["def diffLen(row):\n", "    try:\n", "        return abs(len(row['question1']) - len(row['question2']))\n", "    except:\n", "        return 0"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["def puncCounts(row):\n", "    try:\n", "        q1 = len([w for w in row['question1'] if w in string.punctuation])/len(row['question1'])\n", "        q2 = len([w for w in row['question2'] if w in string.punctuation])/len(row['question2'])\n", "        return abs(q1-q2)\n", "    except:\n", "        return 0\n"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["def digitDiff(row):\n", "    try:\n", "        d1 = len([char.isdigit() for char in row['question1']])/len(row['question1'])\n", "        d2 = len([char.isdigit() for char in row['question2']])/len(row['question2'])\n", "        return abs(d1-d2)\n", "    except:\n", "        return 0\n", "\n", "\n", "def digit1(row):\n", "    try:\n", "        d1 = len([char.isdigit() for char in row['question1']]) > 0\n", "        return 1 if d1 > 0 else 0\n", "    except:\n", "        return 0\n", "def digit2(row):\n", "    try:\n", "        d2 = len([char.isdigit() for char in row['question2']]) > 0\n", "        return 1 if d2 > 0 else 0\n", "    except:\n", "        return 0"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["ss = set(stopwords.words('english'))\n", "def stopWords(row):\n", "    try:\n", "        q1 = set(re.sub(\"[^\\w]\", \" \",  row['question1'].lower()).split())\n", "        q2 = set(re.sub(\"[^\\w]\", \" \",  row['question2'].lower()).split())\n", "        l1 = len([i for i in q1 if i in ss])\n", "        l2 = len([i for i in q2 if i in ss])\n", "        return abs(l1-l2)\n", "    except:\n", "        return 0\n"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["train_cp = pd.DataFrame()\n", "test_cp = pd.DataFrame()"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["train_cp['stopwordsDiff'] = train.apply(stopWords,axis=1,raw=True)\n", "test_cp['stopwordsDiff'] = test.apply(stopWords,axis=1,raw=True)"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["train_cp['digitDiff'] = train.apply(digitDiff,axis=1,raw=True)\n", "train_cp['digit1'] = train.apply(digit1,axis=1,raw=True)\n", "train_cp['digit2'] = train.apply(digit2,axis=1,raw=True)\n", "\n", "test_cp['digitDiff'] = test.apply(digitDiff,axis=1,raw=True)\n", "test_cp['digit1'] = test.apply(digit1,axis=1,raw=True)\n", "test_cp['digit2'] = test.apply(digit2,axis=1,raw=True)"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["train_cp['puncCounts'] = train.apply(puncCounts,axis=1,raw=True)\n", "\n", "test_cp['puncCounts'] = test.apply(puncCounts,axis=1,raw=True)"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["train_cp['diffLen'] = train.apply(diffLen,axis=1,raw=True)\n", "\n", "test_cp['diffLen'] = test.apply(diffLen,axis=1,raw=True)"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["train_cp['similar'] = train.apply(similar,axis=1,raw=True)\n", "train_cp['unsimilar'] = train.apply(unsimilar,axis=1,raw=True)\n", "\n", "test_cp['similar'] = test.apply(similar,axis=1,raw=True)\n", "test_cp['unsimilar'] = test.apply(unsimilar,axis=1,raw=True)"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["tfIdf = TfidfVectorizer(ngram_range=(1,3),stop_words='english')\n", "train_idf = tfIdf.fit_transform(train['question1'].astype(str)+train['question2'].astype(str))\n", "test_idf = tfIdf.transform(test['question1'].astype(str)+test['question2'].astype(str))\n", "n_comp = 20\n", "svd = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n", "train_svd = pd.DataFrame(svd.fit_transform(train_idf))\n", "test_svd = pd.DataFrame(svd.transform(test_idf))\n", "\n", "#add this train_svd and test_svd to train and test respectively\n", "train_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n", "test_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n", "train_cp = pd.concat([train_cp, train_svd], axis=1)\n", "test_cp = pd.concat([test_cp,test_svd],axis=1)\n", "train_cp.shape,test_cp.shape"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["x_train, x_valid, y_train, y_valid = train_test_split(train_cp, target, test_size=0.2, random_state=4242)\n", "dtrain = xgb.DMatrix(x_train,y_train)\n", "dtest = xgb.DMatrix(x_valid)\n", "xgb_params = {\n", "    'eta': 0.05,\n", "    'max_depth': 5,\n", "    'subsample': 1.0,\n", "    'colsample_bytree': 0.7,\n", "    'silent': 1,\n", "    'objective':'binary:logistic',\n", "    'eval_metric':'logloss'\n", "}\n", "xgbc = xgb.train(xgb_params, dtrain, num_boost_round=1000, verbose_eval=20)\n", "xpreds = xgbc.predict(dtest)\n", "log_loss(y_valid,xpreds)"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["dtrain = xgb.DMatrix(train_cp,target)\n", "dtest = xgb.DMatrix(test_cp)\n", "xgbc = xgb.train(xgb_params, dtrain, num_boost_round=1000, verbose_eval=20)\n", "xpreds = xgbc.predict(dtest)"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["sub = pd.DataFrame()\n", "sub['test_id'] = test['test_id']\n", "sub['is_duplicate'] = xpreds\n", "sub.to_csv('simple_xgb.csv', index=False)"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": [], "cell_type": "code", "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"pygments_lexer": "ipython3", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "name": "python", "file_extension": ".py", "version": "3.6.4"}}}