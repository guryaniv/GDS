{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "00f56c71-4d96-8e01-3f92-ea36513ba84c"
      },
      "outputs": [],
      "source": [
        "#Libraries\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "import re\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cross_validation import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4e5f8616-cd40-9620-bb49-9ef9c95de77d"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('../input/train.csv', dtype={'Age': np.float64}, )\n",
        "\n",
        "df_test = pd.read_csv('../input/test.csv', dtype={'Age': np.float64}, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "20e177e0-3b6b-81a0-e5d9-8e6360fbeb6e"
      },
      "outputs": [],
      "source": [
        "df_train.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f47dccf2-dccd-1f2e-4189-f98f1abff85b"
      },
      "outputs": [],
      "source": [
        "df_test.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fc4363d3-57b0-99e8-5e80-a4fcb9c39ce9"
      },
      "source": [
        "819 rows in train data and 418 in test.\n",
        "There missing values in Age, Cabin and and Embarked columns in train and in Age and Cabin in test.\n",
        "Let's deal with each column step by step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6a18de53-92ca-8a7e-2039-ee8fdf33706f"
      },
      "outputs": [],
      "source": [
        "#Pclass. It seems that Pclass is useful and requires no changes.\n",
        "df_train.pivot_table('PassengerId', 'Pclass', 'Survived', 'count').plot(kind='bar', stacked=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "097c741f-57e0-e156-282a-718a55646f57"
      },
      "source": [
        "Names. It is a usual practice to extract Titles from Names to group passangers.\n",
        "Let's see unique values of Titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "172c079e-31eb-fbc7-3bfc-d187744a0fcc"
      },
      "outputs": [],
      "source": [
        "df_train['Title'] = df_train['Name'].apply(lambda x: (re.search(' ([a-zA-Z]+)\\.', x)).group(1))\n",
        "df_test['Title'] = df_test['Name'].apply(lambda x: (re.search(' ([a-zA-Z]+)\\.', x)).group(1))\n",
        "\n",
        "df_train['Title'].value_counts(), df_test['Title'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "94fa4658-1fb3-3e62-389c-411f3cc17a32"
      },
      "source": [
        "There are many titles. I tried to leave titles as they are, but it was a bad feature.\n",
        "There are several ways to group titles, I chose this one. At first create dictionary with mapping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "72e41ab9-620f-eac7-9c07-e7adf070026c"
      },
      "outputs": [],
      "source": [
        "#Dict\n",
        "title_mapping = {\n",
        "                    'Capt':       'Officer',\n",
        "                    'Col':        'Officer',\n",
        "                    'Major':      'Officer',\n",
        "                    'Jonkheer':   'Royalty',\n",
        "                    'Don':        'Royalty',\n",
        "                    'Sir' :       'Royalty',\n",
        "                    'Dr':         'Officer',\n",
        "                    'Rev':        'Officer',\n",
        "                    'Countess':   'Royalty',\n",
        "                    'Dona':       'Royalty',\n",
        "                    'Mme':        'Mrs',\n",
        "                    'Mlle':       'Miss',\n",
        "                    'Ms':         'Mrs',\n",
        "                    'Mr' :        'Mr',\n",
        "                    'Mrs' :       'Mrs',\n",
        "                    'Miss' :      'Miss',\n",
        "                    'Master' :    'Master',\n",
        "                    'Lady' :      'Royalty'\n",
        "                    } \n",
        "#Use dictionary to change values\n",
        "for k,v in title_mapping.items():\n",
        "    df_train.loc[df_train['Title'] == k, 'Title'] = v\n",
        "    df_test.loc[df_test['Title'] == k, 'Title'] = v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d5981996-6c99-cf53-d4e9-aa60f35ec567"
      },
      "outputs": [],
      "source": [
        "#Age. Missing values for Age should be filled. I think that simple mean/median isn't good enough.\n",
        "#After several tries I stopped at median by Title, Sex and Pclass.\n",
        "#df_train.groupby(['Title']).mean()\n",
        "#df_train.groupby(['Sex', 'Pclass', 'Title']).mean()\n",
        "print(df_train.groupby(['Title', 'Sex', 'Pclass'])['Age'].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "acd5b169-ff71-f171-a05a-dcb9fcfc44c9"
      },
      "outputs": [],
      "source": [
        "#Age. Fill NA with median by sex, pclass, title\n",
        "df_train['Age'] = df_train.groupby(['Sex','Pclass','Title'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
        "df_test['Age'] = df_test.groupby(['Sex','Pclass','Title'])['Age'].apply(lambda x: x.fillna(x.median()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "279ff205-bf90-cf25-8ed5-4c77e69008ce"
      },
      "source": [
        "Sex. At first I thought to divide passangers by males, females and childs, but it increased overfitting.\n",
        "Also I tried to replace values to 1 and 0 (instead of creating dummies), it also worked worse. So doing nothing here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6245b239-0538-69e1-28aa-8f3ae50c0a10"
      },
      "outputs": [],
      "source": [
        "df_train.groupby(['Pclass', 'Sex'])['Survived'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f2b8537c-d841-5466-3db0-044a16b59ed1"
      },
      "outputs": [],
      "source": [
        "#SibSp and Parch. These two variables allow to create a new variable for the size of the Family.\n",
        "#At first I created a single feature showing whether the person had family. It wasn't good enough.\n",
        "df_train['Family'] =  df_train['Parch'] + df_train['SibSp']\n",
        "df_test['Family'] =  df_test['Parch'] + df_test['SibSp']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "755a70ec-4520-ee3e-fd48-2f328634ebd0"
      },
      "outputs": [],
      "source": [
        "#Then I tried several variants and stopped on four groups: 0 relatives, 1-2, 3 and 5 or more.\n",
        "# From the table we can see that such grouping makes sense\n",
        "df_train.groupby(['Family']).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bdb5df7f-f963-816f-85ae-f6b83fec9ca8"
      },
      "outputs": [],
      "source": [
        "#A function for Family transformation\n",
        "def FamilySize(x):\n",
        "    if x == 1 or x == 2:\n",
        "        return 'little'\n",
        "    elif x == 3:\n",
        "        return 'medium'\n",
        "    elif x >= 5:\n",
        "        return 'big'\n",
        "    else:\n",
        "        return 'none'\n",
        "#Applying it\n",
        "df_train['Family'] = df_train['Family'].apply(lambda x : FamilySize(x))\n",
        "df_test['Family'] = df_test['Family'].apply(lambda x : FamilySize(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "55f83f6d-62e3-f910-cac6-a8fded1d0b56"
      },
      "outputs": [],
      "source": [
        "#Just to see the survival rate.\n",
        "#df_train.loc[df_train['Family'] == 'big']\n",
        "df_train.groupby(['Pclass', 'Family'])['Survived'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c6becfc7-31b1-e8a8-c726-5a3486927303"
      },
      "outputs": [],
      "source": [
        "#Ticket. We need to extract values from it. Function for extracting prefixes. Tickets have length of 1-3.\n",
        "\n",
        "''' \n",
        "At first I also wanted to use Ticket numbers, but it was useless or prone to overfitting\n",
        "def Ticket_Number(x):\n",
        "    l=x.split()\n",
        "    if len(x.split()) == 3:\n",
        "        return x.split()[2]\n",
        "    elif len(x.split()) == 2:\n",
        "        return x.split()[1]\n",
        "    else:\n",
        "        return x.split()[0]\n",
        "df_train['TicketNumber'] = df_train['Ticket'].apply(lambda x: Ticket_Number(x))        \n",
        "df_test['TicketNumber'] = df_test['Ticket'].apply(lambda x: Ticket_Number(x))        \n",
        "''' \n",
        "\n",
        "def Ticket_Prefix(x):\n",
        "    l=x.split()\n",
        "    if len(x.split()) == 3:\n",
        "        return x.split()[0] + x.split()[1]\n",
        "    elif len(x.split()) == 2:\n",
        "        return x.split()[0]\n",
        "    else:\n",
        "        return 'None'\n",
        "df_train['TicketPrefix'] = df_train['Ticket'].apply(lambda x: Ticket_Prefix(x))\n",
        "df_test['TicketPrefix'] = df_test['Ticket'].apply(lambda x: Ticket_Prefix(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "88a792ae-85ac-c8d5-7556-e9759fe053f8"
      },
      "outputs": [],
      "source": [
        "#Fare. There is only one missing value, and in test. Fill it with median for it Pclass.\n",
        "ax = plt.subplot()\n",
        "ax.set_ylabel('Average fare')\n",
        "df_train.groupby('Pclass').mean()['Fare'].plot(kind='bar',figsize=(7,3), ax = ax)\n",
        "df_test['Fare'] = df_test.groupby(['Pclass'])['Fare'].apply(lambda x: x.fillna(x.median()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2af4559a-80af-7746-8dfd-a58f77802673"
      },
      "outputs": [],
      "source": [
        "#Cabin. I thought about ignoring this, but it turned out to be good.\n",
        "#At first fill NA with 'Unknown',\n",
        "df_train.Cabin.fillna('Unknown',inplace=True)\n",
        "df_test.Cabin.fillna('Unknown',inplace=True)\n",
        "#Extract first letter\n",
        "df_train['Cabin'] = df_train['Cabin'].map(lambda x : x[0])\n",
        "df_test['Cabin'] = df_test['Cabin'].map(lambda x : x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f989bf5e-b105-c44b-ec75-9ab760fb8e4c"
      },
      "outputs": [],
      "source": [
        "#Now let's see. Most of the cabins aren't filled.\n",
        "f, ax = plt.subplots(figsize=(7, 3))\n",
        "sns.countplot(y=\"Cabin\", data=df_train, color=\"c\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1e8e67c6-970d-a48a-1078-0001c7776e11"
      },
      "outputs": [],
      "source": [
        "#Other cabins vary.\n",
        "sns.countplot(y=\"Cabin\", data=df_train[df_train.Cabin != 'U'], color=\"c\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c41e4ff9-2ebd-c35f-93fd-2ae95f0c0671"
      },
      "outputs": [],
      "source": [
        "#Most of passangers with unknown Cabins died\n",
        "sns.factorplot(\"Survived\", col=\"Cabin\",\n",
        "               col_wrap=4, data=df_train[df_train.Cabin == 'U'],\n",
        "               kind=\"count\", size=2.5, aspect=.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bd311a19-9fd5-344c-b2c2-017958692c39"
      },
      "outputs": [],
      "source": [
        "#For passengers with known Cabins survival rate varies.\n",
        "sns.factorplot(\"Survived\", col=\"Cabin\",\n",
        "               col_wrap=4, data=df_train[df_train.Cabin != 'U'],\n",
        "               kind=\"count\", size=2.5, aspect=.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "84cebb51-2d28-a98e-c513-2572cff7d5e0"
      },
      "outputs": [],
      "source": [
        "df_train.groupby(['Cabin']).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "feb44e39-a5d9-93b9-c804-a926dbd0d963"
      },
      "outputs": [],
      "source": [
        "#Embarked. Fill with most common value.\n",
        "MedEmbarked = df_train.groupby('Embarked').count()['PassengerId']\n",
        "df_train.Embarked.fillna(MedEmbarked,inplace=True)\n",
        "df_test.Embarked.fillna(MedEmbarked,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0660c8e6-0977-e511-862e-9bd2851237a3"
      },
      "outputs": [],
      "source": [
        "#This is how the data looks like now.\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2b0ee26a-9c4a-6df2-95a6-5a72a61fdcf9"
      },
      "outputs": [],
      "source": [
        "#For algorithms it is better to have dummies.\n",
        "dummies = pd.get_dummies(df_train['Pclass'], prefix='Pclass')\n",
        "df_train = df_train.join(dummies)\n",
        "dummies = pd.get_dummies(df_test['Pclass'], prefix='Pclass')\n",
        "df_test = df_test.join(dummies)\n",
        "dummies = pd.get_dummies(df_train['Title'])\n",
        "df_train = df_train.join(dummies)\n",
        "dummies = pd.get_dummies(df_test['Title'])\n",
        "df_test = df_test.join(dummies)\n",
        "dummies = pd.get_dummies(df_train['Sex'])\n",
        "df_train = df_train.join(dummies)\n",
        "dummies = pd.get_dummies(df_test['Sex'])\n",
        "df_test = df_test.join(dummies)\n",
        "dummies = pd.get_dummies(df_train['Cabin'], prefix='Cabin')\n",
        "df_train = df_train.join(dummies)\n",
        "dummies = pd.get_dummies(df_test['Cabin'], prefix='Cabin')\n",
        "df_test = df_test.join(dummies)\n",
        "dummies = pd.get_dummies(df_train['Embarked'], prefix='Embarked')\n",
        "df_train = df_train.join(dummies)\n",
        "dummies = pd.get_dummies(df_test['Embarked'], prefix='Embarked')\n",
        "df_test = df_test.join(dummies)\n",
        "dummies = pd.get_dummies(df_train['Family'], prefix='Family')\n",
        "df_train = df_train.join(dummies)\n",
        "dummies = pd.get_dummies(df_test['Family'], prefix='Family')\n",
        "df_test = df_test.join(dummies)\n",
        "dummies = pd.get_dummies(df_train['TicketPrefix'], prefix='TicketPrefix')\n",
        "df_train = df_train.join(dummies)\n",
        "dummies = pd.get_dummies(df_test['TicketPrefix'], prefix='TicketPrefix')\n",
        "df_test = df_test.join(dummies)\n",
        "\n",
        "#Drop unnecessary columns\n",
        "to_drop = ['Pclass','Ticket', 'Name', 'SibSp', 'Sex', 'Parch', 'Cabin', 'Embarked', 'Title', 'Family', 'TicketPrefix']\n",
        "for i in to_drop:\n",
        "    df_train = df_train.drop([i], axis=1)\n",
        "    df_test = df_test.drop([i], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9ce9cbfe-5657-6910-7335-5807a24d27b0"
      },
      "outputs": [],
      "source": [
        "#This is how the data looks like now.\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "585cd5fd-1556-5545-3bf9-34758a817706"
      },
      "outputs": [],
      "source": [
        "#These variables will be used for learning\n",
        "X_train = df_train.drop('Survived',axis=1)\n",
        "Y_train = df_train['Survived']\n",
        "X_test  = df_test.drop('PassengerId',axis=1).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0483418e-39d1-2bc7-ab93-21d195376cb9"
      },
      "outputs": [],
      "source": [
        "#Now to select features. This code ranks features by their importance fior Random Forest\n",
        "clf = RandomForestClassifier(n_estimators=200)\n",
        "clf = clf.fit(X_train, Y_train)\n",
        "indices = np.argsort(clf.feature_importances_)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print('Feature ranking:')\n",
        "\n",
        "for f in range(X_train.shape[1]):\n",
        "    print('%d. feature %d %s (%f)' % (f + 1, indices[f], X_train.columns[indices[f]],\n",
        "                                      clf.feature_importances_[indices[f]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "548659f8-a21e-c382-56ee-531e284b49bc"
      },
      "outputs": [],
      "source": [
        "#This is automatical feature selection\n",
        "model = SelectFromModel(clf, prefit=True)\n",
        "train_new = model.transform(X_train)\n",
        "train_new.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "75d78e49-893c-23e9-0458-6bae4aa94282"
      },
      "source": [
        "There are 15 features. New X for train and test will use these features.\n",
        "Somehow PassengerID is important. Sex, Titles and Pclass are obviously important.\n",
        "Family size and absense of information about Cabin are also significant.\n",
        "Sometimes the number of features differs due to randomness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "12a00abf-bcfb-078f-fe99-dd425cf9838b"
      },
      "outputs": [],
      "source": [
        "best_features=X_train.columns[indices[0:15]]\n",
        "X = df_train[best_features]\n",
        "Xt = df_test[best_features]\n",
        "best_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "96847857-43b9-a225-6340-1e9ee4a002ad"
      },
      "source": [
        "At some point I tried to normalize features, but it only made model worse.\n",
        "def scale_all_features():\n",
        "    \n",
        "    global combined\n",
        "    \n",
        "    features1 = list(X_train.columns)\n",
        "    features2 = list(X_test.columns)\n",
        "    features1.remove('PassengerId')\n",
        "    #features2.remove('PassengerId')\n",
        "    df_train[features1] = df_train[features1].apply(lambda x: x/x.max(), axis=0)\n",
        "    df_test[features2] = df_test[features2].apply(lambda x: x/x.max(), axis=0)\n",
        "    \n",
        "scale_all_features()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b207cd03-470c-6254-8fe9-c0c27269967d"
      },
      "outputs": [],
      "source": [
        "#Splitting data for tuning parameters for Random Forest.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y_train, test_size=0.33, random_state=44)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ebb21128-4d34-8d7d-4697-30e11c053270"
      },
      "outputs": [],
      "source": [
        "#I saw this part of code there: https://www.kaggle.com/creepykoala/titanic/study-of-tree-and-forest-algorithms\n",
        "#This is a great way to see how parameters influence the result of Random Forest\n",
        "plt.figure(figsize=(9,7))\n",
        "\n",
        "#N Estimators\n",
        "plt.subplot(3,3,1)\n",
        "feature_param = range(1,21)\n",
        "scores=[]\n",
        "for feature in feature_param:\n",
        "    clf = RandomForestClassifier(n_estimators=feature)\n",
        "    clf.fit(X_train,y_train)\n",
        "    scores.append(clf.score(X_test,y_test))\n",
        "plt.plot(scores, '.-')\n",
        "plt.axis('tight')\n",
        "plt.title('N Estimators')\n",
        "plt.grid();\n",
        "\n",
        "#Criterion\n",
        "plt.subplot(3,3,2)\n",
        "feature_param = ['gini','entropy']\n",
        "scores=[]\n",
        "for feature in feature_param:\n",
        "    clf = RandomForestClassifier(criterion=feature)\n",
        "    clf.fit(X_train,y_train)\n",
        "    scores.append(clf.score(X_test,y_test))\n",
        "plt.plot(scores, '.-')\n",
        "plt.title('Criterion')\n",
        "plt.xticks(range(len(feature_param)), feature_param)\n",
        "plt.grid();\n",
        "\n",
        "#Max Features\n",
        "plt.subplot(3,3,3)\n",
        "feature_param = ['auto','sqrt','log2',None]\n",
        "scores=[]\n",
        "for feature in feature_param:\n",
        "    clf = RandomForestClassifier(max_features=feature)\n",
        "    clf.fit(X_train,y_train)\n",
        "    scores.append(clf.score(X_test,y_test))\n",
        "plt.plot(scores, '.-')\n",
        "plt.axis('tight')\n",
        "plt.title('Max Features')\n",
        "plt.xticks(range(len(feature_param)), feature_param)\n",
        "plt.grid();\n",
        "\n",
        "#Max Depth\n",
        "plt.subplot(3,3,4)\n",
        "feature_param = range(1,21)\n",
        "scores=[]\n",
        "for feature in feature_param:\n",
        "    clf = RandomForestClassifier(max_depth=feature)\n",
        "    clf.fit(X_train,y_train)\n",
        "    scores.append(clf.score(X_test,y_test))\n",
        "plt.plot(feature_param, scores, '.-')\n",
        "plt.axis('tight')\n",
        "plt.title('Max Depth')\n",
        "plt.grid();\n",
        "\n",
        "#Min Samples Split\n",
        "plt.subplot(3,3,5)\n",
        "feature_param = range(2,21)\n",
        "scores=[]\n",
        "for feature in feature_param:\n",
        "    clf = RandomForestClassifier(min_samples_split =feature)\n",
        "    clf.fit(X_train,y_train)\n",
        "    scores.append(clf.score(X_test,y_test))\n",
        "plt.plot(feature_param, scores, '.-')\n",
        "plt.axis('tight')\n",
        "plt.title('Min Samples Split')\n",
        "plt.grid();\n",
        "\n",
        "#Min Weight Fraction Leaf\n",
        "plt.subplot(3,3,6)\n",
        "feature_param = np.linspace(0,0.5,10)\n",
        "scores=[]\n",
        "for feature in feature_param:\n",
        "    clf = RandomForestClassifier(min_weight_fraction_leaf =feature)\n",
        "    clf.fit(X_train,y_train)\n",
        "    scores.append(clf.score(X_test,y_test))\n",
        "plt.plot(feature_param, scores, '.-')\n",
        "plt.axis('tight')\n",
        "plt.title('Min Weight Fraction Leaf')\n",
        "plt.grid();\n",
        "\n",
        "#Max Leaf Nodes\n",
        "plt.subplot(3,3,7)\n",
        "feature_param = range(2,21)\n",
        "scores=[]\n",
        "for feature in feature_param:\n",
        "    clf = RandomForestClassifier(max_leaf_nodes=feature)\n",
        "    clf.fit(X_train,y_train)\n",
        "    scores.append(clf.score(X_test,y_test))\n",
        "plt.plot(feature_param, scores, '.-')\n",
        "plt.axis('tight')\n",
        "plt.title('Max Leaf Nodes')\n",
        "plt.grid();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1ff0aa1-ee6a-a808-d844-08a79e2fdfea"
      },
      "source": [
        "Now based on these graphs I tune the model.\n",
        "Normally you input all parameters and their potential values and run GridSearchCV.\n",
        "My PC isn't good enough so I divide parameters in two groups and repeatedly run two GridSearchCV until I'm satisfied with the result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7db1f527-f7fc-8e3c-26ce-9a7b7159ab31"
      },
      "outputs": [],
      "source": [
        "forest = RandomForestClassifier(max_depth = 5,                                \n",
        "                                min_samples_split =10,\n",
        "                                min_weight_fraction_leaf = 0.0,\n",
        "                                max_leaf_nodes = 16)\n",
        "\n",
        "parameter_grid = {'n_estimators' : [5, 8, 15],\n",
        "                  'criterion' : ['gini', 'entropy'],\n",
        "                  'max_features' : ['auto', 'sqrt', 'log2', None]\n",
        "                 }\n",
        "\n",
        "grid_search = GridSearchCV(forest, param_grid=parameter_grid, cv=StratifiedKFold(Y_train, n_folds=5))\n",
        "grid_search.fit(X, Y_train)\n",
        "print('Best score: {}'.format(grid_search.best_score_))\n",
        "print('Best parameters: {}'.format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e8f8fa8c-b79f-772a-fdc7-d2acf148e6fa"
      },
      "outputs": [],
      "source": [
        "forest = RandomForestClassifier(n_estimators = 8,\n",
        "                                criterion = 'gini',\n",
        "                                max_features = 'log2')\n",
        "parameter_grid = {\n",
        "                  'max_depth' : [None, 5, 10, 20],\n",
        "                  'min_samples_split' : [5, 7],\n",
        "                  'min_weight_fraction_leaf' : [0.0, 0.1, 0.2],\n",
        "                  'max_leaf_nodes' : [4, 10, 16],\n",
        "                 }\n",
        "\n",
        "grid_search = GridSearchCV(forest, param_grid=parameter_grid, cv=StratifiedKFold(Y_train, n_folds=5))\n",
        "grid_search.fit(X, Y_train)\n",
        "print('Best score: {}'.format(grid_search.best_score_))\n",
        "print('Best parameters: {}'.format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "66810133-f14f-d9b7-c874-e5f2828dd865"
      },
      "outputs": [],
      "source": [
        "#These are good parameters\n",
        "clf = RandomForestClassifier(n_estimators = 15,\n",
        "                                criterion = 'gini',\n",
        "                                max_features = 'sqrt',\n",
        "                                max_depth = None,                                \n",
        "                                min_samples_split =7,\n",
        "                                min_weight_fraction_leaf = 0.0,\n",
        "                                max_leaf_nodes = 18)\n",
        "\n",
        "clf.fit(X, Y_train)\n",
        "Y_pred_RF = clf.predict(Xt)\n",
        "clf.score(X, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4cf12a5c-a7fb-5578-d0f9-98dad313c722"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\n",
        "        'PassengerId': df_test['PassengerId'],\n",
        "        'Survived': Y_pred_RF\n",
        "    })\n",
        "submission.to_csv('titanic.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ecb158d0-ffce-e1e2-626f-53e928629d60"
      },
      "source": [
        "I didn't aim for a perfect model for my first attempt, I just wanted to use my skills. And due to randomness I wasn't able to reproduce my best result (0.799).\n",
        "\n",
        "I would really appreciate comments about my implementation."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}