{"nbformat_minor": 1, "cells": [{"cell_type": "code", "source": ["%matplotlib inline\n", "import os\n", "import matplotlib\n", "import matplotlib.pyplot as plt\n", "import pandas as pd\n", "import cv2\n", "import numpy as np\n", "from glob import glob\n", "import seaborn as sns"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "f39f0c6a929d0db7d1aa48c2722cce5c37aa3b5d", "collapsed": true, "_cell_guid": "a1767b4c-9ea3-4342-8ee5-56660856183b"}}, {"cell_type": "code", "source": ["BASE_DATA_FOLDER = \"../input\"\n", "TRAin_DATA_FOLDER = os.path.join(BASE_DATA_FOLDER, \"train\")"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "622180f74f171af387a6f40fadd8f23b6806885a", "collapsed": true, "_cell_guid": "c7a5628f-95de-419f-b850-eafe47b1e35d"}}, {"cell_type": "markdown", "source": ["### Read images\n", "Read in the images and convert it from RGB to BGR (because OpenCV uses BGR)"], "metadata": {"_uuid": "d069eff7a882e41838282d7e10f5d97e835d4447", "_cell_guid": "c10f40f2-f71e-4085-a744-42a142677558"}}, {"cell_type": "code", "source": ["images_per_class = {}\n", "for class_folder_name in os.listdir(TRAin_DATA_FOLDER):\n", "    class_folder_path = os.path.join(TRAin_DATA_FOLDER, class_folder_name)\n", "    class_label = class_folder_name\n", "    images_per_class[class_label] = []\n", "    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n", "        image_rgb = cv2.imread(image_path, cv2.IMREAD_COLOR)\n", "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n", "        images_per_class[class_label].append(image_bgr)"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "1d421d3a24167567cbc26d5f668acac290dc7b0f", "collapsed": true, "_cell_guid": "1019fbd1-3adb-402c-864a-3030694a12d8"}}, {"cell_type": "markdown", "source": ["### Number of images per class"], "metadata": {"_uuid": "62c42371237dfd9f56d01a725bf69d4627642d1a", "_cell_guid": "5b048546-3d90-4361-93de-f2a6172ff0df"}}, {"cell_type": "code", "source": ["for key,value in images_per_class.items():\n", "    print(\"{0} -> {1}\".format(key, len(value)))"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "d3f0406443e03dab008abcd2aa315f14108e5814", "collapsed": true, "_cell_guid": "b3a465ca-6600-46e2-a923-631eb4ec1b23"}}, {"cell_type": "markdown", "source": ["### Plot images\n", "Plot images so we can see what the input looks like"], "metadata": {"_uuid": "a4f0376c290e3efa6344f1a49e30ce580d45f17f", "_cell_guid": "59db49a3-8d9f-4a86-b2f3-12ea2db779f4"}}, {"cell_type": "code", "source": ["def plot_for_class(label):\n", "    nb_rows = 3\n", "    nb_cols = 3\n", "    fig, axs = plt.subplots(nb_rows, nb_cols, figsize=(6, 6))\n", "\n", "    n = 0\n", "    for i in range(0, nb_rows):\n", "        for j in range(0, nb_cols):\n", "            axs[i, j].xaxis.set_ticklabels([])\n", "            axs[i, j].yaxis.set_ticklabels([])\n", "            axs[i, j].imshow(images_per_class[label][n])\n", "            n += 1        "], "execution_count": null, "outputs": [], "metadata": {"_uuid": "d908e6a36213ed4807f36ff771031e5c45e1e506", "collapsed": true, "_cell_guid": "98e34b57-34de-4c04-8442-1b6e46a7e92d"}}, {"cell_type": "code", "source": ["plot_for_class(\"Small-flowered Cranesbill\")"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "c186f23d145dbb2987b6c41d21372db87dbbed95", "collapsed": true, "_cell_guid": "d4c11145-1017-47ca-9465-dff77a90937e"}}, {"cell_type": "code", "source": ["plot_for_class(\"Maize\")"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "c33768fb8bb0e80726846f7ccef279a031d778eb", "scrolled": false, "collapsed": true, "_cell_guid": "521a656a-377e-4555-a3ac-3b9e8849b47a"}}, {"cell_type": "markdown", "source": ["### Preprocessing for the images:"], "metadata": {"_uuid": "a4d9f5707e90e3a71dbb1ae65f424fc820210ce3", "_cell_guid": "a8c70b81-a900-4c71-8fc5-c907600b5d7f"}}, {"cell_type": "code", "source": ["def create_mask_for_plant(image):\n", "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n", "\n", "    sensitivity = 35\n", "    lower_hsv = np.array([60 - sensitivity, 100, 50])\n", "    upper_hsv = np.array([60 + sensitivity, 255, 255])\n", "\n", "    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n", "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n", "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n", "    \n", "    return mask\n", "\n", "def segment_plant(image):\n", "    mask = create_mask_for_plant(image)\n", "    output = cv2.bitwise_and(image, image, mask = mask)\n", "    return output\n", "\n", "def sharpen_image(image):\n", "    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n", "    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n", "    return image_sharp"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "5456e49c609494238a22e386fc11d8cab0bb62b0", "collapsed": true, "_cell_guid": "909ee9c0-2055-47de-9e76-c04a4bf9e7d9"}}, {"cell_type": "code", "source": ["# Test image to see the changes\n", "image = images_per_class[\"Small-flowered Cranesbill\"][97]\n", "\n", "image_mask = create_mask_for_plant(image)\n", "image_segmented = segment_plant(image)\n", "image_sharpen = sharpen_image(image)\n", "\n", "fig, axs = plt.subplots(1, 4, figsize=(20, 20))\n", "axs[0].imshow(image)\n", "axs[1].imshow(image_mask)\n", "axs[2].imshow(image_segmented)\n", "axs[3].imshow(image_sharpen)"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "b27217b1e5bbeacaca1dad627117d0a7a5953826", "scrolled": true, "collapsed": true, "_cell_guid": "4064997e-2a20-49a6-9110-1863e2af5f4d"}}, {"cell_type": "markdown", "source": ["After this step we can see that the image on the right is more recognizable than the original image on the left."], "metadata": {"_uuid": "8d27e084e8f79bad6e191ce7562f5af71b0e7048", "_cell_guid": "b1542194-f8a5-43b3-8a0a-5a3e5db6019d"}}, {"cell_type": "markdown", "source": ["----------------------------------------------"], "metadata": {"_uuid": "f6c3b077b7bd2c436c05d2ba2d0f1a62e8a2a914", "collapsed": true, "_cell_guid": "31468800-4545-4761-91f5-9fdb643cda46"}}, {"cell_type": "markdown", "source": ["From the mask image what we created (because we need that for the segmentation), we can extract some features. For example we can see how the area of the plant changes based on their classes."], "metadata": {"_uuid": "6ab28223af13a48c40b654ea571e0c2353f5a7ca", "_cell_guid": "968fee1b-2ba5-46c3-b76b-46f583130803"}}, {"cell_type": "markdown", "source": ["Of course from the contours we can extract much more information than the area of the\n", "contour and the number of components, but this is the one I would like to show you."], "metadata": {"_uuid": "ff56308f92af0a6f7456dc6682bd5882368533c1", "_cell_guid": "91814168-c271-4ce1-a965-aea6022c31d3"}}, {"cell_type": "code", "source": ["def find_contours(mask_image):\n", "    return cv2.findContours(mask_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n", "\n", "def calculate_largest_contour_area(contours):\n", "    if len(contours) == 0:\n", "        return 0\n", "    c = max(contours, key=cv2.contourArea)\n", "    return cv2.contourArea(c)\n", "\n", "def calculate_contours_area(contours, min_contour_area = 250):\n", "    area = 0\n", "    for c in contours:\n", "        c_area = cv2.contourArea(c)\n", "        if c_area >= min_contour_area:\n", "            area += c_area\n", "    return area"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "93325744901ac18c2a2c08f564e3ce66bf229b13", "collapsed": true, "_cell_guid": "2239a4ba-16d1-47be-a246-3b4eba20ab45"}}, {"cell_type": "code", "source": ["areas = []\n", "larges_contour_areas = []\n", "labels = []\n", "nb_of_contours = []\n", "\n", "for class_label in images_per_class.keys():\n", "    for image in images_per_class[class_label]:\n", "        mask = create_mask_for_plant(image)\n", "        contours = find_contours(mask)\n", "        \n", "        area = calculate_contours_area(contours)\n", "        largest_area = calculate_largest_contour_area(contours)\n", "        \n", "        areas.append(area)\n", "        nb_of_contours.append(len(contours))\n", "        larges_contour_areas.append(largest_area)\n", "        labels.append(class_label)"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "bddb5240dc2df60540caf939d8805c61196012cf", "collapsed": true, "_cell_guid": "ab51d5d9-b3b6-4cbe-a2df-26bf6f227b0f"}}, {"cell_type": "code", "source": ["features_df = pd.DataFrame()\n", "features_df[\"label\"] = labels\n", "features_df[\"area\"] = areas\n", "features_df[\"largest_area\"] = larges_contour_areas\n", "features_df[\"number_of_components\"] = nb_of_contours"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "83d1c887fcb36d77920c09ebfab7104c9c09854f", "collapsed": true, "_cell_guid": "90b25714-73d2-48a1-a743-f4ac720f3bdf"}}, {"cell_type": "code", "source": ["features_df.groupby(\"label\").describe()"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "46b46f8570a0a6fd46953fd05fa8941b6e6ef640", "scrolled": true, "collapsed": true, "_cell_guid": "9a5e8177-a11d-4ead-80ac-dd6580d90e80"}}], "nbformat": 4, "metadata": {"language_info": {"nbconvert_exporter": "python", "version": "3.6.3", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "pygments_lexer": "ipython3"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}}