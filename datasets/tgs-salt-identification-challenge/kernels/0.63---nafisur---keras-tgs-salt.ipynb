{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"## Loading Library"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix,f1_score\nfrom skimage.transform import resize\nimport tqdm\nfrom tqdm import tqdm_notebook,tnrange\nfrom keras.layers import Input,BatchNormalization,Dense,Dropout,Flatten,MaxPooling2D,GlobalAveragePooling2D,Conv2D,UpSampling2D,Conv2DTranspose,MaxPool2D\nfrom keras.models import Model,load_model,Sequential\nfrom keras.losses import binary_crossentropy,categorical_crossentropy\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\nfrom keras.utils import to_categorical\nfrom keras.applications.densenet import DenseNet121,preprocess_input as densenet_preprocessing\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2,preprocess_input as inception_preprocessing\nfrom keras.applications.resnet50 import ResNet50,preprocess_input as resnet_preprocessing\nfrom keras.applications.xception import Xception,preprocess_input as xception_preprocessing\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2,preprocess_input as inceptionresnet_prepross\nfrom keras.preprocessing.image import ImageDataGenerator,array_to_img,load_img,img_to_array\nfrom keras.layers.merge import concatenate\nfrom keras.layers.core import Lambda\nfrom keras import backend as K\nimport tensorflow as tf\nimport os\nimport sys\nimport seaborn as sn\nfrom PIL import Image\npd.set_option('display.max_colwidth',100)\n%matplotlib inline\nimport gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"40ee6bb7746cf7a7d83cd7d2a62931e2a9d3684f"},"cell_type":"markdown","source":"## Loading Dataset"},{"metadata":{"_uuid":"31905bdb9ebe809505790cfed0f243d717013da3"},"cell_type":"markdown","source":"** Creating two Dataframe which contains path of the images in train and test folder**"},{"metadata":{"trusted":true,"_uuid":"a82df07526c58ecb8eda64fd0706d19b2e50010d"},"cell_type":"code","source":"Train_Image_folder='../input/train/images/'\nTrain_Mask_folder='../input/train/masks/'\nTest_Image_folder='../input/test/images/'\nTrain_Image_name=os.listdir(path=Train_Image_folder)\nTest_Image_name=os.listdir(path=Test_Image_folder)\nTrain_Image_path=[]\nTrain_Mask_path=[]\nTrain_id=[]\nfor i in Train_Image_name:\n    path1=Train_Image_folder+i\n    path2=Train_Mask_folder+i\n    id1=i.split(sep='.')[0]\n    Train_Image_path.append(path1)\n    Train_Mask_path.append(path2)\n    Train_id.append(id1)\n  \n\nTest_Image_path=[]\nTest_id=[]\nfor i in Test_Image_name:\n    path=Test_Image_folder+i\n    id2=i.split(sep='.')[0]\n    Test_Image_path.append(path)\n    Test_id.append(id2)\n    \ndf_Train_path=pd.DataFrame({'id':Train_id,'Train_Image_path':Train_Image_path,'Train_Mask_path':Train_Mask_path})\ndf_Test_path=pd.DataFrame({'id':Test_id,'Test_Image_path':Test_Image_path})\n\ndf_depths=pd.read_csv('../input/depths.csv')\ndf_sub=pd.read_csv('../input/sample_submission.csv')\ndf_Train_path=df_Train_path.merge(df_depths,on='id',how='left')\ndf_Test_path=df_Test_path.merge(df_depths,on='id',how='left')\ndf_Test_path=df_sub.merge(df_Test_path,on='id',how='left')\nprint(df_Train_path.shape,df_Test_path.shape)\ndf_Train_path.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8529e571958c0785817c6028e750c43c283555ae"},"cell_type":"code","source":"df_Test_path.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6d8658915b01d3b27115b66f55b649789b497be"},"cell_type":"markdown","source":"** Loading the Train_Image, Train_Mask and Test_Image in pixel formate**"},{"metadata":{"trusted":true,"_uuid":"9fd791a081cf831a42194ffb7463ed04d195a93b"},"cell_type":"code","source":"def read_image(path,img_height,img_width,img_chan):\n    pixel=np.zeros((len(path), img_height, img_width, img_chan),dtype=np.float32)\n    for n, p in tqdm_notebook(enumerate(path), total=len(path)):\n        img = load_img(p)\n        x = img_to_array(img)[:,:,1]\n        x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n        x=x/255\n        pixel[n]=x\n    return pixel\n\nimg_height=128\nimg_width=128\nimg_chan=1\nTrain_Image_pixel=read_image(df_Train_path.Train_Image_path,img_height,img_width,img_chan)\nTrain_Mask_pixel=read_image(df_Train_path.Train_Mask_path,img_height,img_width,img_chan)\n\nprint('Train Image shape: ',Train_Image_pixel.shape)\nprint('Train Mask shape: ',Train_Mask_pixel.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61c419b7a9519e43022e23e48449c41c328caf9d"},"cell_type":"code","source":"# Get and resize test images\ndef read_image2(path,img_height,img_width,img_chan):\n    pixel=np.zeros((len(path), img_height, img_width, img_chan),dtype=np.float32)\n    sizes_test = []\n    for n, p in tqdm_notebook(enumerate(path), total=len(path)):\n        img = load_img(p)\n        x = img_to_array(img)[:,:,1]\n        sizes_test.append([x.shape[0], x.shape[1]])\n        x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n        x=x/255\n        pixel[n]=x\n    return pixel,sizes_test\n\nTest_Image_pixel,sizes_test=read_image2(df_Test_path.Test_Image_path,img_height,img_width,img_chan)\nprint('Test Image shape: ',Test_Image_pixel.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"deb281cea23ba6e246d8029e34510075911dae74"},"cell_type":"code","source":"array_to_img(Train_Image_pixel[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b0d531ea6b8c598a43e172ea25bbafe0d19fcc7"},"cell_type":"code","source":"array_to_img(Train_Mask_pixel[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"710eb7b6f40ae9c1bea03a86f11e9178b2db48e9"},"cell_type":"code","source":"array_to_img(Test_Image_pixel[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a44390688455f719089b61f9bf09ff04033a835a"},"cell_type":"markdown","source":"### Define IoU metric"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1a138c48e5368ce14c241e97826f2b7dea439c47"},"cell_type":"code","source":"# Define IoU metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7142d2000b8102a4f623d40c6ca4718120dc2738"},"cell_type":"code","source":"# Another method\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6816ee7187f760edb0ccf2d198ccc4df6054708d"},"cell_type":"markdown","source":"## Spliting training set"},{"metadata":{"trusted":true,"_uuid":"0448e82784244c948f1fcd34386386463b487441"},"cell_type":"code","source":"X=Train_Image_pixel\nY=Train_Mask_pixel\ntest=Test_Image_pixel\nX_train,X_val,y_train,y_val=train_test_split(X,Y,test_size=0.20,random_state=42)\nprint(X_train.shape,y_train.shape)\nprint(X_val.shape,y_val.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3164b799b3ad2bc07eaa463e8325ad14df40b8c1"},"cell_type":"markdown","source":"## 1. Building U-Net Model"},{"metadata":{"trusted":true,"_uuid":"8ac83436a1eb5efc1aa93387b20a6d96837db7fc","collapsed":true},"cell_type":"code","source":"# Build U-Net model\ninputs = Input((img_height, img_width, img_chan))\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\nu6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=[mean_iou])\n#model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aee8086fada3713b98063b91f950f973c8363d6f","collapsed":true},"cell_type":"code","source":"earlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True)\nresults = model.fit(X, Y,validation_split=0.1, batch_size=8, epochs=30,callbacks=[earlystopper, checkpointer])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02f9384877e240e9d72861a8f578c8e205625d32","collapsed":true},"cell_type":"code","source":"# Predict on train, val and test\nmodel = load_model('model-tgs-salt-1.h5', custom_objects={'mean_iou': mean_iou})\n#pred_train = model.predict(X_train, verbose=1)\n#pred_val = model.predict(X_val, verbose=1)\npreds_test = model.predict(test, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f18da2710da56f0231e3fcc8fb85a3fb81d08f2a","collapsed":true},"cell_type":"code","source":"# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in tnrange(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f97e9d121ddfc45a90cd2f968a79ea9a6fea228","collapsed":true},"cell_type":"code","source":"def RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"13dfd4398fce28ba31b04ea00526039c0fbc1e73"},"cell_type":"code","source":"pred_dict = {fn[:-4]:RLenc(np.round(preds_test_upsampled[i])) for i,fn in tqdm_notebook(enumerate(df_Test_path.Test_Image_path))}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"348cf2416e3c4ff04e424d2a2e84f7acc64f3be0","collapsed":true},"cell_type":"code","source":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nrle=sub[0].values\ndf_sub.rle_mask=rle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96079445f09791007716c022f0e18930f66600cc","collapsed":true},"cell_type":"code","source":"df_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e587c2f445702ec92ef9051be5d49ecfc14cc381"},"cell_type":"code","source":"df_sub.to_csv('sub1.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8e09b290d1832247cc70fefc94ea63265e7364d7"},"cell_type":"markdown","source":"## 2. Model2"},{"metadata":{"trusted":true,"_uuid":"0fc89da9a4f3ee59a9919ad93ba2b722ea6e2fef","collapsed":true},"cell_type":"code","source":"input_layer = Input((img_height, img_width, 1))\nc1 = Conv2D(filters=8, kernel_size=(3,3), activation='relu', padding='same')(input_layer)\nl = MaxPool2D(strides=(2,2))(c1)\nc2 = Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same')(l)\nl = MaxPool2D(strides=(2,2))(c2)\nc3 = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(l)\nl = MaxPool2D(strides=(2,2))(c3)\nc4 = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='same')(l)\nl = concatenate([UpSampling2D(size=(2,2))(c4), c3], axis=-1)\nl = Conv2D(filters=32, kernel_size=(2,2), activation='relu', padding='same')(l)\nl = concatenate([UpSampling2D(size=(2,2))(l), c2], axis=-1)\nl = Conv2D(filters=24, kernel_size=(2,2), activation='relu', padding='same')(l)\nl = concatenate([UpSampling2D(size=(2,2))(l), c1], axis=-1)\nl = Conv2D(filters=16, kernel_size=(2,2), activation='relu', padding='same')(l)\nl = Conv2D(filters=64, kernel_size=(1,1), activation='relu')(l)\nl = Dropout(0.5)(l)\noutput_layer = Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid')(l)\n                                                         \nmodel2 = Model(input_layer, output_layer)\nmodel2.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=[dice_coef])\n#model2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13048cdc55897d8686b13ce7120a74682806c9e8","scrolled":true,"collapsed":true},"cell_type":"code","source":"earlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint('model-tgs-salt-2.h5', verbose=1, save_best_only=True)\nresults = model2.fit(X, Y,validation_split=0.1, batch_size=8, epochs=30,callbacks=[earlystopper, checkpointer])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0764b65d92b65003370b9161d0afd250e90be3b","collapsed":true},"cell_type":"code","source":"model2 = load_model('model-tgs-salt-2.h5', custom_objects={'dice_coef': dice_coef})\npreds_test2 = model2.predict(test, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0393f6be860f545f94eb1f3d6fcb4da809d8f03","collapsed":true},"cell_type":"code","source":"# Create list of upsampled test masks\npreds_test_upsampled2 = []\nfor i in tnrange(len(preds_test2)):\n    preds_test_upsampled2.append(resize(np.squeeze(preds_test2[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac55b934c231de93eec5d355e5437377750b925b","collapsed":true},"cell_type":"code","source":"pred_dict2 = {fn[:-4]:RLenc(np.round(preds_test_upsampled2[i])) for i,fn in tqdm_notebook(enumerate(df_Test_path.Test_Image_path))}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49168adde31078158b502ffb1367cdde994e7ee4","collapsed":true},"cell_type":"code","source":"sub2 = pd.DataFrame.from_dict(pred_dict2,orient='index')\nrle2=sub2[0].values\ndf_sub.rle_mask=rle2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d07fbd27f0e735fedd08f62a7efb317877a6e9a","collapsed":true},"cell_type":"code","source":"df_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e0ace6e73f220a5f490a5802daddbf34ca31dff1"},"cell_type":"code","source":"df_sub.to_csv('sub2.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}