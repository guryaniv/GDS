{"cells":[{"metadata":{"_cell_guid":"e2de243a-455a-4130-b8c0-b93e933f3920","_uuid":"acd2cf30609aa7f191649b974fc908f22244e727"},"cell_type":"markdown","source":"# Quick Start: Google Landmark Recognition Challenge\n\n\n![Google Landmark Recognition Challenge](https://kaggle2.blob.core.windows.net/competitions/kaggle/7456/logos/header.png?t=2018-01-30-21-42-08)\n\nThis Kernel aims to be a quick and easy way for anyone to start the [Google Landmark Recognition Challenge](https://www.kaggle.com/c/landmark-recognition-challenge). In just 2 steps, you will be able to load the datasets, and get an explanatory visualization of it.\n\n> ** If you like this Kernel of find it useful, please upvote it or/and leave a comment.**\n\n> ** Any feedback, advise, comment would be highly appreciated in order to improve this Kernel.**"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true},"cell_type":"markdown","source":"---\n## Step 1: Load the Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false,"collapsed":true},"cell_type":"code","source":"# Load useful python libraries\nimport numpy as np\nimport pandas as pd \n\n# Set training and testing files\ntraining_file = '../input/train.csv'\ntesting_file = '../input/test.csv'\n\n# Load datasets\ntrain_data = pd.read_csv(training_file)\ntest_data = pd.read_csv(testing_file)\n\nprint(\"Data successfully loaded!\")","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"a199cca8-3109-44ee-be79-233174d6ed04","_uuid":"ad95d5fd7c79e59ca02d98fc879e948ede05c4ff","collapsed":true},"cell_type":"markdown","source":"---\n\n## Step 2: Dataset Summary & Exploration"},{"metadata":{"_cell_guid":"f02efc16-7509-4637-a605-61306a870e53","_uuid":"7e6d24ae468529741e6ec366b9e9107d61af96e6"},"cell_type":"markdown","source":"### Basic Summary of the Datasets"},{"metadata":{"_cell_guid":"b25b6cbd-4668-4b73-ba35-943bdbf6cb27","_uuid":"f8a8df38f1b20d8d4c82a877996ac4e250a89e02","trusted":false,"collapsed":true},"cell_type":"code","source":"# Number of training examples\nn_train = train_data.shape[0]\n\n# Number of testing examples\nn_test = test_data.shape[0]\n\n# Proportion of training and testing data\ntrain_per = n_train / (n_train + n_test) * 100\ntest_per = n_test / (n_train + n_test) * 100\n\n# Shape of the training and testing datasets\ntrain_shape = train_data.shape\ntest_shape = test_data.shape\n\n# Unique landmarks in the dataset\nn_classes = len(train_data['landmark_id'].unique())\n\nprint(\"Number of training examples =\", n_train)\nprint(\"Number of testing examples =\", n_test)\nprint(\"Proportion training/testing data = {0:.2f}% / {1:.2f}%\".format(train_per, test_per))\nprint(\"Training data shape =\", train_shape)\nprint(\"Testing data shape =\", test_shape)\nprint(\"Number of classes =\", n_classes)","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"a199cca8-3109-44ee-be79-233174d6ed04","_uuid":"ad95d5fd7c79e59ca02d98fc879e948ede05c4ff","collapsed":true},"cell_type":"markdown","source":"#### Training dataset (first rows)"},{"metadata":{"trusted":false,"_uuid":"fb3592968241e0543c72653bf396290bdc9f6452"},"cell_type":"code","source":"train_data.head()","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"a199cca8-3109-44ee-be79-233174d6ed04","_uuid":"ad95d5fd7c79e59ca02d98fc879e948ede05c4ff","collapsed":true},"cell_type":"markdown","source":"#### Testing dataset (first rows)"},{"metadata":{"trusted":false,"_uuid":"10c14ae9ba4839a4e82a17d1e21fa08fe000a831"},"cell_type":"code","source":"test_data.head()","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"f68cdb07-58bf-4e6c-a13c-44b81742dc31","_uuid":"152617fae3317d54b8fbc2f0ff090097717b6af1"},"cell_type":"markdown","source":"### Exploratory visualization of the dataset"},{"metadata":{"_uuid":"b64fbce4f3151647243a1a01684521331be54462","collapsed":true,"trusted":false},"cell_type":"code","source":"import sys, os, requests\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\ndef download_image(key, url):\n    # Define output directory and filename\n    out_dir = os.getcwd() + '/../output/'\n    filename = os.path.join(out_dir, '{}.jpg'.format(key))\n    \n    # Image already downloaded?\n    if not os.path.exists(filename):\n        # Download image data\n        try:\n            r = requests.get(url, stream=True)\n            with open(filename, 'wb') as f:  \n                f.write(r.content)\n        except:\n            print('Could not download image {0} from {1}'.format(key, url))\n            return\n    \n    # Open image\n    try:\n        image = plt.imread(filename)\n    except:\n        print('Failed to open image {}'.format(key))\n        return\n    \n    return image","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"9372dad3-44fc-4270-9a14-590eaaf357e2","_uuid":"eeab7ddb50c35f65db8a0085e5d6b0c3ec3cd86d","collapsed":true,"trusted":false},"cell_type":"code","source":"def explore_dataset(data, sample_id):\n    \"\"\"\n    Visualize the Google Landmark Recognition Dataset\n    \"\"\"\n    \n    # Check sample ID\n    data_len = data.shape[0]\n    if not (0 <= sample_id < data_len):\n        print(\"{} samples in dataset. {} is out of range.\".format(data_len, sample_id))\n        return None\n    \n    # Count the number of images by landmark ID\n    landmark_counts = pd.DataFrame(data['landmark_id'].value_counts())\n    landmark_counts.reset_index(inplace=True)\n    landmark_counts.columns = ['landmark_id', 'counts']\n    \n    print(\"First 20 most represented landmarks ID:\\n\")\n    print(landmark_counts.head(20))\n    \n    # Plot counts of landmarks ID in descending order\n    plt.figure(figsize=(12,12))\n    sns.set(font_scale=1.3)\n    sns.barplot(x='landmark_id', y='counts', data=landmark_counts.head(20))\n    plt.title('Most represented landmark ID')\n    plt.xlabel('Landmark ID')\n    plt.ylabel('# Samples')\n    plt.tight_layout()\n    plt.show()\n    \n    # Visualize dataset distribution\n    plt.figure(figsize=(12,12))\n    sns.distplot(data['landmark_id'])\n    plt.title(\"Dataset distribution\")\n    plt.show()\n    \n    # Visualize one sample from dataset\n    sample_data = data.iloc[sample_id]\n    sample_id = sample_data['id']\n    sample_url = sample_data['url']\n    sample_label = sample_data['landmark_id']\n    \n    sample_image = download_image(sample_id, sample_url)\n    \n    if sample_image is not None:\n        print('\\nExample of Image {}:'.format(sample_id))\n        print('> Min Value: {}, Max Value: {}'.format(sample_image.min(), sample_image.max()))\n        print('> Shape: {}'.format(sample_image.shape))\n        print('> URL: {}'.format(sample_url))\n        print('> Landmark ID: {}'.format(sample_label))\n\n        plt.figure()\n        plt.axis('off')\n        plt.imshow(sample_image)","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"30763e16-c986-4522-b77d-081a4abf45d5","_uuid":"4ca186249add5b3f00342697320cd2a93717a97e","trusted":false},"cell_type":"code","source":"# Visualize training dataset\nprint('--TRAIN DATASET\\n')\nexplore_dataset(train_data, 0)","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"8eeb6c97-dca7-4f9a-acc0-d4f547b37bf4","_uuid":"db7df1589d69a84f22cc9342aac0940e6cb11bae","collapsed":true,"trusted":false},"cell_type":"code","source":"from sklearn.utils import shuffle\n\ndef display_image_examples(data, labels, n_images_per_label = 5):\n    data_shuffled = shuffle(data)\n    \n    fig = plt.figure(figsize=(n_images_per_label, len(labels)))\n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images_per_label * len(labels))\n    \n    for i in range(len(labels)):\n        \n        # Choose the first 'n_images_per_label' indexes for each label\n        df = data[data['landmark_id'] == labels[i]]\n        df = df[:n_images_per_label]\n        \n        # Display corresponding images in data\n        count = 0\n        for index, row in df.iterrows():\n            # Download image from url\n            image = download_image(row['id'], row['url'])\n            # Plot it\n            count += 1\n            plt.subplot(len(labels), n_images_per_label, count+(i*n_images_per_label))\n            plt.imshow(image)\n            plt.axis('off')","execution_count":11,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6cb472edd972aa9b0a37f7e4da8b37a6e815883d"},"cell_type":"code","source":"import random\nfrom time import time\n\n# Generate 5 random landmarks ID\nrandom.seed(time())\nlandmarks = []\nfor i in range(5):\n    landmarks.append(random.randint(1, 14950))\n\n# Display some images from the training dataset for the previous generated landmarks ID\ndisplay_image_examples(train_data, landmarks, n_images_per_label = 3)","execution_count":15,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"d4ac107c446f1b627fc71c7470c16a667f0b105c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}