{"nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"pygments_lexer": "ipython3", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.0", "name": "python"}}, "nbformat_minor": 1, "cells": [{"source": ["import numpy as np\n", "import pandas as pd\n", "import datetime as dt\n", "from sklearn.metrics import mean_absolute_error\n", "import statsmodels.api as sm\n", "import statsmodels.formula.api as smf\n", "from statsmodels.regression.quantile_regression import QuantReg"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["from statsmodels.sandbox.tools import cross_val"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["train2017 = pd.read_csv('../input/train_2017.csv')\n", "train2016 = pd.read_csv('../input/train_2016_v2.csv')\n", "prop = pd.read_csv('../input/properties_2016.csv', low_memory = False)\n", "prop17 = pd.read_csv('../input/properties_2017.csv', low_memory = False)"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["zip_count = prop['regionidzip'].value_counts().to_dict()\n", "city_count = prop['regionidcity'].value_counts().to_dict()\n", "medyear = prop.groupby('regionidneighborhood')['yearbuilt'].aggregate('median').to_dict()\n", "meanarea = prop.groupby('regionidneighborhood')['calculatedfinishedsquarefeet'].aggregate('mean').to_dict()\n", "medlat = prop.groupby('regionidneighborhood')['latitude'].aggregate('median').to_dict()\n", "medlong = prop.groupby('regionidneighborhood')['longitude'].aggregate('median').to_dict()\n", "\n", "zip_count17 = prop17['regionidzip'].value_counts().to_dict()\n", "city_count17 = prop17['regionidcity'].value_counts().to_dict()\n", "medyear17 = prop17.groupby('regionidneighborhood')['yearbuilt'].aggregate('median').to_dict()\n", "meanarea17 = prop17.groupby('regionidneighborhood')['calculatedfinishedsquarefeet'].aggregate('mean').to_dict()\n", "medlat17 = prop17.groupby('regionidneighborhood')['latitude'].aggregate('median').to_dict()\n", "medlong17 = prop17.groupby('regionidneighborhood')['longitude'].aggregate('median').to_dict()"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["train2016 = train2016.merge(prop, how='left', on=['parcelid'])\n", "train2017 = train2017.merge(prop17, how='left', on=['parcelid'])"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["def calculate_features(df):\n", "    df['N-zip_count'] = df['regionidzip'].map(zip_count)\n", "    df['N-city_count'] = df['regionidcity'].map(city_count)\n", "    df['N-GarPoolAC'] = ((df['garagecarcnt']>0) & \\\n", "                         (df['pooltypeid10']>0) & \\\n", "                         (df['airconditioningtypeid']!=5))*1 \n", "    df['mean_area'] = df['regionidneighborhood'].map(meanarea)\n", "    df['med_year'] = df['regionidneighborhood'].map(medyear)\n", "    df['med_lat'] = df['regionidneighborhood'].map(medlat)\n", "    df['med_long'] = df['regionidneighborhood'].map(medlong)"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["def calculate_features17(df):\n", "    df['N-zip_count'] = df['regionidzip'].map(zip_count17)\n", "    df['N-city_count'] = df['regionidcity'].map(city_count17)\n", "    df['N-GarPoolAC'] = ((df['garagecarcnt']>0) & \\\n", "                         (df['pooltypeid10']>0) & \\\n", "                         (df['airconditioningtypeid']!=5))*1 \n", "    df['mean_area'] = df['regionidneighborhood'].map(meanarea17)\n", "    df['med_year'] = df['regionidneighborhood'].map(medyear17)\n", "    df['med_lat'] = df['regionidneighborhood'].map(medlat17)\n", "    df['med_long'] = df['regionidneighborhood'].map(medlong17)"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["calculate_features(train2016)\n", "calculate_features17(train2017)"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["train = pd.concat([train2016, train2017], axis = 0)"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["train['month'] = pd.to_datetime(train['transactiondate']).dt.month\n", "train['year'] = pd.to_datetime(train['transactiondate']).dt.year\n", "train['yearmonth'] = 100*train.year+train.month\n", "select_2016 = train['year']==2016\n", "basedate = pd.to_datetime('2015-11-17').toordinal()\n", "ordinal = pd.to_datetime(train.transactiondate).apply(lambda x: x.toordinal()-basedate)\n", "train['cos_t'] = ( ordinal*(2*np.pi/365.25) ).apply(np.cos)\n", "train['sin_t'] = ( ordinal*(2*np.pi/365.25) ).apply(np.sin)"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["train.columns"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["def impute_nas(train_df, test_df, feat):\n", "    meds = train_df.median()\n", "    for f in feat:\n", "        imputed = meds[f]\n", "        train_df[f] = train_df[f].replace(np.nan, meds[f])\n", "        test_df[f] = test_df[f].replace(np.nan, meds[f])"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["# dropped:\n", "\n", "#   calculatedbathnbr\n", "#   lotsizesquarefeet\n", "#   unitcnt\n", "#   finishedsquarefeet50\n", "#   numberofstories\n", "#   fireplacecnt\n", "#   fullbathcnt\n", "#   threequarterbathnbr\n", "#   finishedsquarefeet13\n", "#   poolsizesum\n", "#   yardbuildingsqft26\n", "\n", "#   N-city_count\n", "#   med_year\n", "#   med_lat\n", "#   med_long\n", "#   N-GarPoolAC"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["static_features = ['taxamount','structuretaxvaluedollarcnt',\n", "            'landtaxvaluedollarcnt', 'taxvaluedollarcnt', 'yearbuilt', \n", "             'finishedsquarefeet12', 'bedroomcnt', \n", "             'bathroomcnt', 'finishedsquarefeet15',\n", "             'finishedfloor1squarefeet', 'finishedsquarefeet6', 'garagetotalsqft',\n", "             'yardbuildingsqft17', 'garagecarcnt', \n", "             'N-zip_count', 'mean_area' ]\n", "features = static_features + ['cos_t', 'sin_t']"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["data = train[select_2016]\n", "n = np.sum(select_2016)\n", "k = 5\n", "\n", "X = data[features]\n", "y = data.logerror\n", "kf = cross_val.KFold(n, k=k)\n", "avgmae = 0\n", "for train_index, test_index in kf:\n", "    X_train_, X_test_, y_train, y_test = cross_val.split(train_index, test_index, X, y)\n", "    X_train = pd.DataFrame(X_train_.copy(), columns=features)\n", "    X_test = pd.DataFrame(X_test_.copy(), columns=features)\n", "    impute_nas(X_train, X_test, features)\n", "    reg = QuantReg(y_train, sm.add_constant(X_train)).fit(q=.5)\n", "    ypred = reg.predict(sm.add_constant(X_test,has_constant='add'))\n", "    mae = mean_absolute_error(y_test, ypred)\n", "    print( \"Fold MAE: \", mae )\n", "    avgmae += mae\n", "avgmae /= k\n", "print(\"\\nFeatures:\\n\", features, \"\\n\\nAverage MAE: \", avgmae)"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["# Test model on 2017 data\n", "\n", "data = train[select_2016]\n", "n = np.sum(select_2016)\n", "test = train[~select_2016]\n", "\n", "X = data[features].copy()\n", "y = data.logerror\n", "X_test = test[features].copy()\n", "y_test = test.logerror\n", "\n", "impute_nas(X, X_test, features)\n", "\n", "reg = QuantReg(y, sm.add_constant(X)).fit(q=.5)\n", "ypred = reg.predict(sm.add_constant(X_test,has_constant='add'))\n", "\n", "print( \"Baseline MAE: \", mean_absolute_error(y_test, 0*ypred) )\n", "print( \"Model MAE:    \", mean_absolute_error(y_test, ypred) )"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["sample_submission = pd.read_csv('../input/sample_submission.csv', low_memory = False)\n", "\n", "test_df = pd.merge( sample_submission[['ParcelId']], \n", "                    prop.rename(columns = {'parcelid': 'ParcelId'}), \n", "                    how = 'left', on = 'ParcelId' )"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["calculate_features(test_df)\n", "impute_nas(train[select_2016].copy(), test_df, static_features)"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["y_preds = []\n", "for tdate in ['2016-10-15', '2016-11-15', '2016-12-15']:\n", "    test_df['transactiondate'] = tdate\n", "    ordinal = pd.to_datetime(test_df.transactiondate).apply(lambda x: x.toordinal()-basedate)\n", "    test_df['cos_t'] = ( ordinal*(2*np.pi/365.25) ).apply(np.cos)\n", "    test_df['sin_t'] = ( ordinal*(2*np.pi/365.25) ).apply(np.sin)\n", "    X_test = sm.add_constant(test_df[features],has_constant='add')\n", "    pred = reg.predict(X_test)\n", "    y_pred=[]\n", "    for i,predict in enumerate(pred):\n", "       y_pred.append(str(round(predict,5)))\n", "    y_preds.append(np.array(y_pred))"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["output = pd.DataFrame({'ParcelId': sample_submission['ParcelId'].astype(np.int32),\n", "       '201610': y_preds[0], '201611': y_preds[1], '201612': y_preds[2],\n", "       '201710': y_preds[0], '201711': y_preds[1], '201712': y_preds[2]})\n", "\n", "cols = output.columns.tolist()\n", "cols"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["cols = cols[-1:] + cols[:-1]\n", "output = output[cols]\n", "output.head()"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["output.to_csv('lad2016.csv', index=False)"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["features"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}]}