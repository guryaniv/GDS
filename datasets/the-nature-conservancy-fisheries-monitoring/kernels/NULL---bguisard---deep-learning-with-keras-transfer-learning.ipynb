{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9dde40d5-25c1-9e72-557b-b2aa1fc552e6"
      },
      "source": [
        "# Transfer learning with Keras\n",
        "\n",
        "Transfer learning is a very powerful and quick way to have a working prototype Neural Net. It leverages from NNs that were trained in huge datasets and allows us to only fine tune the top layers of our model to address a new problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ce165979-1c40-5d2f-49ce-b013011239f5"
      },
      "source": [
        "**NOTE:**\n",
        "This model relies on transfer learning and will not work on your kaggle environment.  You can, however, download the .ipynb file and run it locally. It is recommended to run it on a GPU as the inception v3 is a very deep NN. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d53db2fb-a68a-47f5-a9ce-fdb52ebb2701"
      },
      "outputs": [],
      "source": [
        "# Initialization step 1\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os, cv2, random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "%matplotlib inline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2c52539a-2b16-854d-3c59-f8f6305abeae"
      },
      "outputs": [],
      "source": [
        "# Initialization step 2: Here we will define which model from Keras library we will use.\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, GlobalAveragePooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# First attempt will be with the inception v3 model\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b36ba431-cf89-0b0c-e1b3-95eb05016d79"
      },
      "source": [
        "# Data loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8298dce1-0f6e-74b3-8a53-adee5445b883"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "Forking Jeff Delaney's great method to load and preprocess the inputs. Check his notebook at:\n",
        "\n",
        "https://www.kaggle.com/jeffd23/the-nature-conservancy-fisheries-monitoring/deep-learning-in-the-deep-blue-lb-1-279\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "TRAIN_DIR = '../input/train/'\n",
        "TEST_DIR = '../input/test_stg1/'\n",
        "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
        "\n",
        "# Image dimentions for resizing:\n",
        "ROWS = 299  # Default input of inception v3 \n",
        "COLS = 299 # Default input of inception v3 \n",
        "CHANNELS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d93447da-9788-c660-6503-eb9b76a41da6"
      },
      "outputs": [],
      "source": [
        "def get_images(fish):\n",
        "    \"\"\"Load files from train folder\"\"\"\n",
        "    fish_dir = TRAIN_DIR+'{}'.format(fish)\n",
        "    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n",
        "    return images\n",
        "\n",
        "def read_image(src):\n",
        "    \"\"\"Read and resize individual images\"\"\"\n",
        "    im = cv2.imread(src, cv2.IMREAD_COLOR)\n",
        "    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n",
        "    return im\n",
        "\n",
        "\n",
        "files = []\n",
        "y_all = []\n",
        "\n",
        "for fish in FISH_CLASSES:\n",
        "    fish_files = get_images(fish)\n",
        "    files.extend(fish_files)\n",
        "    \n",
        "    y_fish = np.tile(fish, len(fish_files))\n",
        "    y_all.extend(y_fish)\n",
        "    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n",
        "    \n",
        "y_all = np.array(y_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "04abf989-9635-0c74-0138-4bb91a354201"
      },
      "outputs": [],
      "source": [
        "X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
        "\n",
        "for i, im in enumerate(files): \n",
        "    X_all[i] = read_image(TRAIN_DIR+im)\n",
        "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n",
        "\n",
        "print(X_all.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "661e96d7-870a-5a13-ea35-c5c2ac59348d"
      },
      "outputs": [],
      "source": [
        "# One Hot Encoding Labels to use with keras\n",
        "y_all = LabelEncoder().fit_transform(y_all)\n",
        "y_all = np_utils.to_categorical(y_all)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, \n",
        "                                                    test_size=0.2, random_state=23, \n",
        "                                                    stratify=y_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ad0f32a6-6da7-84c4-7119-e5a883b06c32"
      },
      "source": [
        "# Putting the inception model together\n",
        "\n",
        "We will leverage from Keras imagenet weights and use transfer learning just to fine tune the final layer. The method below was \"forked\" from the Keras application examples page: https://keras.io/applications/\n",
        "\n",
        "Please refer to the paper below for details on Inception v3:\n",
        "http://arxiv.org/abs/1512.00567"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5834a6a6-3a1a-b217-392e-6e10eeb48378"
      },
      "outputs": [],
      "source": [
        "# Remember that as a part of the preprocessing we have already scaled down the images to fit\n",
        "# the inception model input requirements.\n",
        "\n",
        "# create the base pre-trained model from Keras library\n",
        "base_model = InceptionV3(weights=None, include_top=False) #change weights to 'imagenet' on your local build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "af72633f-022e-6562-65a7-139584023145"
      },
      "outputs": [],
      "source": [
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "# and a logistic layer for the FISH_CLASSES = 8 we are trying to predict\n",
        "predictions = Dense(len(FISH_CLASSES), activation='sigmoid')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(input=base_model.input, output=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dce959ce-9aaf-da71-4667-630821feb2d9"
      },
      "outputs": [],
      "source": [
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9da36229-fe50-dfda-959a-e12a0a9a3c38"
      },
      "outputs": [],
      "source": [
        "# train the model on the new data for a few epochs. \n",
        "# Uncommednt the code and change the batch_size and nb_epoch below:\n",
        "\n",
        "\"\"\"\n",
        "model.fit(X_train, y_train, batch_size=64, nb_epoch=1,\n",
        "              validation_split=0.2, verbose=1, shuffle=True)\n",
        "\"\"\"\n",
        "\n",
        "# This will only train the recently created top layers\n",
        "# while keeping the pretrained model weights constant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "387aca56-b2c2-3a72-2a7b-96eedc6d8bce"
      },
      "outputs": [],
      "source": [
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first N layers and unfreeze the rest:\n",
        "\n",
        "N=172\n",
        "\n",
        "for layer in model.layers[:N]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[N:]:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a0d74010-1abf-bee6-13b2-a9c24615571a"
      },
      "outputs": [],
      "source": [
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "305331f0-cd47-d6b8-6584-6011452886d6"
      },
      "outputs": [],
      "source": [
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "\n",
        "\"\"\"\n",
        "model.fit(X_train, y_train, batch_size=64, nb_epoch=5,\n",
        "              validation_split=0.2, verbose=1, shuffle=True)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ae1be2bf-7637-fba9-5fe1-3e4d297ab00e"
      },
      "source": [
        "## Applying the model to your validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9850f326-241d-8a2a-c213-4b6ecad7d1c8"
      },
      "outputs": [],
      "source": [
        "#loss_and_metrics = model.evaluate(X_valid, y_valid, batch_size=64)\n",
        "#print (\"Validation Logloss: \", loss_and_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "08773ca8-5336-51b4-9e8a-63af61df3339"
      },
      "source": [
        "## DO NOT CONTINUE IF YOU DON'T LIKE YOUR LOSS ABOVE.\n",
        "\n",
        "Using your test set to fine tune your model will significantly increase the chance of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "34c7cb20-93bc-75f5-554b-3e9abe8082cd"
      },
      "source": [
        "After you are happy with the results obtained on the validation set above you should run it on the test set and submit your predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "866985bf-d894-d0a4-882f-08882b62c078"
      },
      "source": [
        "# ... and now to the Test Set\n",
        "\n",
        "Once again forking it from Jeff Delaney's NB. See link on the beggining of data loading and preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b4c4bf2b-a77b-6efe-1ea2-ae2000f8ac07"
      },
      "outputs": [],
      "source": [
        "test_files = [im for im in os.listdir(TEST_DIR)]\n",
        "test = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
        "\n",
        "for i, im in enumerate(test_files): \n",
        "    test[i] = read_image(TEST_DIR+im)\n",
        "    \n",
        "#test_preds = model.predict(test, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d5e558cd-78da-78a3-c41b-90b181a68209"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\n",
        "submission.insert(0, 'image', test_files)\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c15ace06-8b1f-7736-ddc5-e5b09503abfc"
      },
      "outputs": [],
      "source": [
        "OUT_DIR =  '../output/'\n",
        "file_name = 'output.csv'\n",
        "file_path_name = os.path.join(OUT_DIR, file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "94d32e04-ffb6-1db5-9756-e66b54ef1508"
      },
      "outputs": [],
      "source": [
        "# Uncommment to create a submission file:\n",
        "#submission.to_csv(file_path_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9ec5e8aa-84c7-ec85-283b-6948baeb2265"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}