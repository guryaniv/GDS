{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fc300fc4-0cd2-0156-5c8d-909443703a6b"
      },
      "source": [
        "I have found that the proportion of new asserts in the test set is higher than in the train set. One of my model has improved from 0.0141 to 0.147. I could share it after the deadline. In the meantime you could find the approach in this notebook. I believe even the local score is lower than the original one by Hamed https://www.kaggle.com/pinocchio/two-sigma-financial-modeling/tensorflow-lr/run/903884 this script should give a slightly higher score in the LB. Hope you could use this information to get out of the public-script score. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "addedb41-e29a-eb28-1115-63fb37dff2e2"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "07769336-c494-4fdb-691a-179d32b53ce8"
      },
      "outputs": [],
      "source": [
        "import kagglegym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing as pp\n",
        "\n",
        "env = kagglegym.make()\n",
        "o = env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b2d9b6e1-e524-cedf-bfab-7fbddb4a711a"
      },
      "outputs": [],
      "source": [
        "col = ['technical_20']\n",
        "train = o.train[col + ['id', 'timestamp', 'y']].copy(deep=True)\n",
        "\n",
        "im = pp.Imputer(strategy='median')\n",
        "train[col] = im.fit_transform(train[col])\n",
        "sX = pp.StandardScaler()\n",
        "train[col] = sX.fit_transform(train[col])\n",
        "train['b'] = 1\n",
        "\n",
        "y_min = train.y.min()\n",
        "y_max = train.y.max()\n",
        "\n",
        "df_id = train[['id', 'timestamp']].groupby('id').agg([np.min])\n",
        "df_id.reset_index(level=0, inplace=True)\n",
        "train = pd.merge(train, df_id, on='id', how='inner')\n",
        "train = train.rename(columns={train.columns[len(train.columns)-1]: 'min_ts'})\n",
        "train = train.loc[(train.min_ts > 1) & (train.y<y_max) & (train.y>y_min)].copy(deep=True)\n",
        "\n",
        "\n",
        "features = ['b']+col\n",
        "n = len(features)\n",
        "\n",
        "learning_rate = 0.01\n",
        "training_epochs = 1000\n",
        "cost_history = np.empty(shape=[1],dtype=float)\n",
        "\n",
        "X = tf.placeholder(tf.float32,[None,n])\n",
        "Y = tf.placeholder(tf.float32,[None,1])\n",
        "W = tf.Variable(tf.zeros([n,1]))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "y_ = tf.matmul(X, W)\n",
        "\n",
        "cost = tf.add(tf.reduce_mean(tf.square(y_ - Y)), tf.reduce_mean(tf.square(W)))\n",
        "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    sess.run(training_step,feed_dict={X: train[features], Y: train[['y']].values})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "77a14f3a-9dee-26a9-99c8-1567cef15530"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    o.features[col] = im.transform(o.features[col])\n",
        "    o.features[col] = sX.transform(o.features[col])\n",
        "    o.features['b'] = 1\n",
        "    \n",
        "    o.target.y = sess.run(y_, feed_dict={X:o.features[features]})\n",
        "    o.target.y = np.clip(o.target.y, y_min, y_max)\n",
        "    \n",
        "    o, reward, done, info = env.step(o.target)\n",
        "    if done:\n",
        "        print(info)\n",
        "        break\n",
        "    if o.features.timestamp[0] % 100 == 0:\n",
        "        print(reward)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}