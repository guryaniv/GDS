{"cells":[{"metadata":{"_uuid":"bd830b62e4dc75943ab9d7f8681b224f08baa39d"},"cell_type":"markdown","source":"This notebook uses the automatic features generated to make a prediction. The way the final score is put together using lgb doesn't change from the original found here https://www.kaggle.com/ogrellier/good-fun-with-ligthgbm/code . \n\nFeel free to explore the newly created variables or ask any questions !"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\ntrain = pd.read_csv(\"../input/automation-of-feature-creation/train.csv\")\ntest = pd.read_csv(\"../input/automation-of-feature-creation/test.csv\")\n# Any results you write to the current directory are saved as output.\ntmp = pd.read_csv(\"../input/home-credit-default-risk/application_test.csv\")\ntmp_train = pd.read_csv(\"../input/home-credit-default-risk/application_train.csv\")","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b486e804327992b5003a2823a6aa9c1cdeafc32d"},"cell_type":"code","source":"train['SK_ID_CURR'] = tmp_train['SK_ID_CURR']\ntest['SK_ID_CURR'] = tmp['SK_ID_CURR']","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a7f7a8a431e82ace1f7ae5d47dfbb02ff4a9552b"},"cell_type":"code","source":"probss = test['ProbTARGET1']\ndel test['ProbTARGET1']\ndel train['ProbTARGET1']\ny = train['TARGET']\ndel train['TARGET']","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0635116d6db51d75414408b553495e3172727126"},"cell_type":"code","source":"def mean_(x):\n    if '{' in x:\n        return x\n    if x=='Missing':\n        return -1\n    if '+inf' in x:\n        return float(x.replace(']','').replace('[','').split(';')[0])\n    if '-inf' in x:\n        return float(x.replace(']','').replace('[','').split(';')[1])\n    l = x.replace(']','').replace('[','').split(';')\n    return (float(l[0])+float(l[1]))/2\n\ndictionnary = {}\nfor i in train.columns:\n    if train[i].dtype!='object':\n        continue\n    try :\n        for j in train[i].unique():\n            dictionnary[j] = mean_(j)\n    except :\n        continue\nfor i in train.columns:\n    if train[i].dtype!='object':\n        continue\n    train[i] = train[i].map(dictionnary)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"53f6293b9f50868478b214b8aac9f97248d430d6"},"cell_type":"code","source":"for i in test.columns:\n    if test[i].dtype!='object':\n        continue\n    try :\n        for j in test[i].unique():\n            dictionnary[j] = mean(j)\n    except :\n        continue\nfor i in test.columns:\n    if test[i].dtype!='object':\n        continue\n    test[i] = test[i].map(dictionnary)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"779fd18326d6f8d1f89a5a3070eb3ba38ba66c4a","scrolled":true},"cell_type":"code","source":"to_dummy =[]\nfor i in test.columns:\n    if test[i].dtype==object:\n        try :\n            test[i]=test[i].astype(float)\n        except :\n            continue\n        if len(test[i].unique())<5:\n            to_dummy.append(i)\n        else :\n            del test[i]\n            #print(i)\ntest = pd.get_dummies(test,columns=to_dummy)\n\nto_dummy =[]\nfor i in train.columns:\n    if train[i].dtype==object:\n        try :\n            train[i]=train[i].astype(float)\n        except :\n            continue\n        if len(train[i].unique())<5:\n            to_dummy.append(i)\n        else :\n            del train[i]\n            #print(i)\ntrain = pd.get_dummies(train,columns=to_dummy)\n","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"29c183f225119119e20f838ba7e30f040646aa2d"},"cell_type":"code","source":"train.fillna(0,inplace=True)\ntest.fillna(0,inplace=True)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60c5e5269515276b0ed52766e8c6b8d2e7cbbbbf","collapsed":true},"cell_type":"code","source":"col_dict = {}\nfor i in train.columns:\n    if '>' in i:\n        col_dict[i] = i.replace('>','').replace('<','')\ntrain.rename(columns=col_dict,inplace = True)\ntest.rename(columns=col_dict, inplace =True)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"93929e6207a78e28db912d29c6beb9afe8c253b2"},"cell_type":"code","source":"for i in train.columns:\n    if train[i].dtype==object:\n        del train[i]\nfor i in test.columns:\n    if test[i].dtype==object:\n        del test[i]\n        \nfor i in train.columns:\n    if i not in test.columns:\n        del train[i]\n        \nfor j in test.columns:\n    if j not in train.columns:\n        del test[j]","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\n\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\nfrom sklearn.model_selection import KFold\nfrom lightgbm import LGBMClassifier\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\n\ndef train_model(data_, test_, y_, folds_):\n\n    oof_preds = np.zeros(data_.shape[0])\n    sub_preds = np.zeros(test_.shape[0])\n    \n    feature_importance_df = pd.DataFrame()\n    \n    feats = [f for f in data_.columns if f not in ['SK_ID_CURR']]\n    \n    for n_fold, (trn_idx, val_idx) in enumerate(folds_.split(data_)):\n        trn_x, trn_y = data_[feats].iloc[trn_idx], y_.iloc[trn_idx]\n        val_x, val_y = data_[feats].iloc[val_idx], y_.iloc[val_idx]\n        \n        clf = LGBMClassifier(\n            n_estimators=6000,\n            learning_rate=0.02,\n            num_leaves=40,\n            colsample_bytree=.8,\n            subsample=.8,\n            max_depth=12,\n            reg_alpha=.1,\n            reg_lambda=.1,\n            min_split_gain=.008,\n            min_child_weight=2,\n            min_child_samples=35,\n            silent=-1,\n            verbose=-1,\n        )\n        \n        clf.fit(trn_x, trn_y, \n                eval_set= [(trn_x, trn_y), (val_x, val_y)], \n                eval_metric='auc', verbose=500, early_stopping_rounds=300  #30\n               )\n        \n        oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n        sub_preds += clf.predict_proba(test_[feats], num_iteration=clf.best_iteration_)[:, 1] / folds_.n_splits\n        \n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = feats\n        fold_importance_df[\"importance\"] = clf.feature_importances_\n        fold_importance_df[\"fold\"] = n_fold + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        \n        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n        del clf, trn_x, trn_y, val_x, val_y\n        gc.collect()\n        \n    print('Full AUC score %.6f' % roc_auc_score(y, oof_preds)) \n    \n    test_['TARGET'] = sub_preds\n\n    return oof_preds, test_[['SK_ID_CURR', 'TARGET']], feature_importance_df\n    \n\ndef display_importances(feature_importance_df_):\n    # Plot feature importances\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n        by=\"importance\", ascending=False)[:50].index\n    \n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    \n    plt.figure(figsize=(8,10))\n    sns.barplot(x=\"importance\", y=\"feature\", \n                data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (avg over folds)')\n    #plt.tight_layout()\n    plt.savefig('lgbm_importances.png')\n\n\ndef display_roc_curve(y_, oof_preds_, folds_idx_):\n    # Plot ROC curves\n    plt.figure(figsize=(6,6))\n    scores = [] \n    for n_fold, (_, val_idx) in enumerate(folds_idx_):  \n        # Plot the roc curve\n        fpr, tpr, thresholds = roc_curve(y_.iloc[val_idx], oof_preds_[val_idx])\n        score = roc_auc_score(y_.iloc[val_idx], oof_preds_[val_idx])\n        scores.append(score)\n        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.4f)' % (n_fold + 1, score))\n    \n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Luck', alpha=.8)\n    fpr, tpr, thresholds = roc_curve(y_, oof_preds_)\n    score = roc_auc_score(y_, oof_preds_)\n    plt.plot(fpr, tpr, color='b',\n             label='Avg ROC (AUC = %0.4f $\\pm$ %0.4f)' % (score, np.std(scores)),\n             lw=2, alpha=.8)\n    \n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('LightGBM ROC Curve')\n    plt.legend(loc=\"lower right\")\n    #tight_layoutplt.tight_layout()\n    \n    plt.savefig('roc_curve.png')\n\n\ndef display_precision_recall(y_, oof_preds_, folds_idx_):\n    # Plot ROC curves\n    plt.figure(figsize=(6,6))\n    \n    scores = [] \n    for n_fold, (_, val_idx) in enumerate(folds_idx_):  \n        # Plot the roc curve\n        fpr, tpr, thresholds = roc_curve(y_.iloc[val_idx], oof_preds_[val_idx])\n        score = average_precision_score(y_.iloc[val_idx], oof_preds_[val_idx])\n        scores.append(score)\n        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='AP fold %d (AUC = %0.4f)' % (n_fold + 1, score))\n    \n    precision, recall, thresholds = precision_recall_curve(y_, oof_preds_)\n    score = average_precision_score(y_, oof_preds_)\n    plt.plot(precision, recall, color='b',\n             label='Avg ROC (AUC = %0.4f $\\pm$ %0.4f)' % (score, np.std(scores)),\n             lw=2, alpha=.8)\n    \n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('LightGBM Recall / Precision')\n    plt.legend(loc=\"best\")\n    #plt.tight_layout()\n    \n    plt.savefig('recall_precision_curve.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9493c2943c938fe048b5fbc7286b996e91e3429"},"cell_type":"code","source":"if __name__ == '__main__':\n    gc.enable()\n    # Build model inputs\n    #data, test, y = build_model_input()\n    # Create Folds\n    folds = KFold(n_splits=5, shuffle=True, random_state=123)\n    # Train model and get oof and test predictions\n    oof_preds, test_preds, importances = train_model(train, test, y, folds)\n    # Save test predictions\n    test_preds.to_csv('first_automated_submission.csv', index=False)\n    # Display a few graphs\n    folds_idx = [(trn_idx, val_idx) for trn_idx, val_idx in folds.split(train)]\n    display_importances(feature_importance_df_=importances)\n    display_roc_curve(y_=y, oof_preds_=oof_preds, folds_idx_=folds_idx)\n    display_precision_recall(y_=y, oof_preds_=oof_preds, folds_idx_=folds_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"54f0829c647f0ff813ffabd5087a1a9731cd541b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dac603d091a00d67a4ec2339402e19b901adb42b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}