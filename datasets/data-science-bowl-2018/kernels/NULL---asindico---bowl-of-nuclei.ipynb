{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"file_extension": ".py", "name": "python", "nbconvert_exporter": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3"}}, "cells": [{"metadata": {"_cell_guid": "a5ceca49-680d-4032-a770-9defe2130804", "_uuid": "c78c893920ad453af293aedfa83e34c56dbb4e19"}, "source": ["This dataset contains a large number of segmented nuclei images. The images were acquired under a variety of conditions and vary in the cell type, magnification, and imaging modality (brightfield vs. fluorescence). The dataset is designed to challenge an algorithm's ability to generalize across these variations.\n", "\n", "Each image is represented by an associated ImageId. Files belonging to an image are contained in a folder with this ImageId. Within this folder are two subfolders:\n", "\n", "images contains the image file.\n", "masks contains the segmented masks of each nucleus. This folder is only included in the training set. Each mask contains one nucleus. Masks are not allowed to overlap (no pixel belongs to two masks)."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "29646d45-5c66-4962-b3cc-f440bba45309", "_uuid": "58903f26e600e7101960fbbf51ce1652af5d1f2b"}, "source": ["import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from glob import glob\n", "import os\n", "from skimage.io import imread\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "%matplotlib inline\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# I used code from https://www.kaggle.com/kmader/nuclei-overview-to-submission to load the data\n", "train_labels = pd.read_csv('../input/stage1_train_labels.csv')\n", "train_labels['EncodedPixels'] = train_labels['EncodedPixels'].map(lambda ep: [int(x) for x in ep.split(' ')])\n", "all_images = glob(os.path.join('../input/', 'stage1_*', '*', '*', '*'))\n", "img_df = pd.DataFrame({'path': all_images})\n", "img_id = lambda in_path: in_path.split('/')[-3]\n", "img_type = lambda in_path: in_path.split('/')[-2]\n", "img_group = lambda in_path: in_path.split('/')[-4].split('_')[1]\n", "img_stage = lambda in_path: in_path.split('/')[-4].split('_')[0]\n", "img_df['ImageId'] = img_df['path'].map(img_id)\n", "img_df['ImageType'] = img_df['path'].map(img_type)\n", "img_df['TrainingSplit'] = img_df['path'].map(img_group)\n", "img_df['Stage'] = img_df['path'].map(img_stage)\n", "train_df = img_df.query('TrainingSplit==\"train\"')\n", "train_rows = []\n", "group_cols = ['Stage', 'ImageId']\n", "for n_group, n_rows in train_df.groupby(group_cols):\n", "    c_row = {col_name: col_value for col_name, col_value in zip(group_cols, n_group)}\n", "    c_row['masks'] = n_rows.query('ImageType == \"masks\"')['path'].values.tolist()\n", "    c_row['images'] = n_rows.query('ImageType == \"images\"')['path'].values.tolist()\n", "    train_rows += [c_row]\n", "train_img_df = pd.DataFrame(train_rows)    \n", "IMG_CHANNELS = 3\n", "def read_and_stack(in_img_list):\n", "    return np.sum(np.stack([imread(c_img) for c_img in in_img_list], 0), 0)/255.0\n", "train_img_df['images'] = train_img_df['images'].map(read_and_stack).map(lambda x: x[:,:,:IMG_CHANNELS])\n", "train_img_df['masks'] = train_img_df['masks'].map(read_and_stack).map(lambda x: x.astype(int))"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "e82d6f3c-7f59-4959-8a5d-6e11e81a4aab", "collapsed": true, "_uuid": "3981a8cd2858addb2363d95a77fc85a83eacb399"}, "source": ["test_df = img_df.query('TrainingSplit==\"test\"')\n", "test_rows = []\n", "group_cols = ['Stage', 'ImageId']\n", "for n_group, n_rows in test_df.groupby(group_cols):\n", "    c_row = {col_name: col_value for col_name, col_value in zip(group_cols, n_group)}\n", "    c_row['images'] = n_rows.query('ImageType == \"images\"')['path'].values.tolist()\n", "    test_rows += [c_row]\n", "test_img_df = pd.DataFrame(test_rows)    \n", "\n", "test_img_df['images'] = test_img_df['images'].map(read_and_stack).map(lambda x: x[:,:,:IMG_CHANNELS])"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "68dcf2a5-3ccd-4893-b4b6-e886e493ae07", "_uuid": "d3b72b0d78fd7cfbbf006d85406ae6e694954f87"}, "source": ["Let' check out these nuclei"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "945d534d-eed4-4553-8812-a4018c499f9c", "_uuid": "b98f9876c8b819ab691cbd3ce4b24c017d4b97d5"}, "source": ["f,axa = plt.subplots(1,2,figsize = (12,5))\n", "axa[0].imshow(train_img_df['images'][2])\n", "axa[1].imshow(train_img_df['images'][5])\n"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "17035b23-5ca0-498d-8d3e-edcbe6c256c4", "_uuid": "8bd438c970d0c4c4d814d7e87c423162eaea945e"}, "source": ["We are dealing with images with different size som RGB some in Grey Scale. I"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "447fb724-bbdf-40f8-b1e7-976a56e814f4", "_uuid": "c1b0a6bc0724c8324feba91da2f85577d114b6ee"}, "source": ["train_img_df['images'].map(lambda x: x.shape).value_counts()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "438b3da5-5942-4a9e-8bac-1c76a9375c6b", "_uuid": "0963bd443c80a5bc5650d7c457e3861d1b9782e7"}, "source": ["I will split the dataset 70% for training and 30% for Test/Validation."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "0cde627f-e636-4029-a3ed-66b41cbd14ff", "collapsed": true, "_uuid": "e04e6eb2049e8310127a14422fca9249348d0c41"}, "source": ["import math\n", "df = train_img_df.sample(frac=1, random_state= 42)\n", "Train = df[0:math.floor(len(df)*0.7)]\n", "Validation = df[len(Train):]\n", "Test = test_img_df"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "e8d1f51a-b034-4c78-8e62-b0bf12be9dec", "_uuid": "4b7da1add8d7d5361a98eef8c48047ad7c6bb5ee"}, "source": ["Then I define a function to resize all imges and turn them to 1 channel."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "edff8bcd-5eb6-4ddc-a043-2a1ae5a6253b", "collapsed": true, "_uuid": "336d8845a66a7744be485dffc4c6add6c9391e6c"}, "source": ["from skimage.io import imread, imshow, imread_collection, concatenate_images\n", "from skimage.transform import resize\n", "from skimage.morphology import label\n", "\n", "WIDTH = 128\n", "HEIGHT = 128\n", "\n", "def process(data,notest=True):\n", "    X = []\n", "    Y = []\n", "    print(\"Resizing all...\")\n", "    for i in range(len(data.images)):\n", "        img = resize(data.images.iloc[i], (HEIGHT, WIDTH,IMG_CHANNELS), mode='constant', preserve_range=True)\n", "        X.append(img)\n", "        if(notest):\n", "            img = resize(data.masks.iloc[i], (HEIGHT, WIDTH,1), mode='constant', preserve_range=True)\n", "            Y.append(img)\n", "    print(\"Done\")    \n", "    return X, Y\n", "\n", "    print(\"Turning all to 1 Channel\")\n", "    images= []\n", "    for i in range(len(data.images)):\n", "        img = np.zeros([WIDTH,HEIGHT])\n", "        for r in range(len(X[i])):\n", "            for c in range(len(X[i][r])):\n", "                img[r][c] = X[i][r][c].mean()\n", "        img = np.asarray(img).reshape(WIDTH,HEIGHT,1)\n", "        images.append(img)  \n", "    X = images\n", "    if(notest):\n", "        for i in range(len(data.images)):\n", "            Y[i] = np.asarray(Y[i]).reshape(WIDTH,HEIGHT,1)\n", "    print('Done')\n", "    return X, Y\n", "        "], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "f78f3505-7248-4845-bd4d-22a57f28f6bc", "_uuid": "234f7b71384a7cbe2564ca5693274d2cc3b0b13a"}, "source": ["print(\"Processing Train\")\n", "X_train,Y_train = process(Train)\n", "print(\"Processing Test\")\n", "X_val,Y_val = process(Validation)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "00ff5cc3-198c-43cf-8cac-716a5bd6df5a", "_uuid": "3a64b441737853e3e4e4e15e1ccf49f3b32b11e1"}, "source": ["X_test,Y_test = process(Test,notest= False)\n"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "78be11c6-855c-4ea2-9faf-54a209a23eea", "_uuid": "8464d61fb6371cd7d9dd4a808058a0a7d0dc5fcb"}, "source": ["np.asarray(X_test[0]).shape"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "16188e4a-7240-4483-bf00-38acbf329f1e", "_uuid": "cb91b05328b2fbcf61ddd3b2187a7a392c7f38e6"}, "source": ["n_img = 6\n", "fig, axa = plt.subplots(2, 3, figsize = (15, 6))\n", "axa[0][0].imshow(X_train[0].reshape(WIDTH,HEIGHT,3))\n", "axa[0][1].imshow(X_train[1].reshape(WIDTH,HEIGHT,3))\n", "axa[0][2].imshow(X_train[2].reshape(WIDTH,HEIGHT,3))\n", "axa[1][0].imshow(Y_train[0].reshape(WIDTH,HEIGHT))\n", "axa[1][1].imshow(Y_train[1].reshape(WIDTH,HEIGHT))\n", "axa[1][2].imshow(Y_train[2].reshape(WIDTH,HEIGHT))\n", "\n", "plt.show()\n", "\n"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "a59952cf-8a61-4795-a3b2-e4656e31d8f1", "collapsed": true, "_uuid": "3c694cd2afea4c1b04a98594ba22ac6400dded60"}, "source": ["This is the first time I design a U-net, the Idea is well depicted in the following picture (which is taken from the original U Net paper). The idea is the network is composed of two paths: a contracting path (left side of the figure) and an expansive path (on the right side of the figure). The former consists of the repeated application of convolutions, each followed by a rectified linear unit (ReLU) and a max pooling operation for downsampling.  Every step in the expansive path consists of an upsampling of the curren feature map followed by a convolution, a concatenation with the correspondingly \n", "feature map from the contracting path, and convolutions again with RELU activation.\n", "\n", "![](http://tuatini.me/content/images/2017/09/u-net-architecture-1.png)\n", "\n", "\n", "here follows some other kernels bout U-nets\n", "https://www.kaggle.com/drn01z3/end-to-end-baseline-with-u-net-keras\n", "https://www.kaggle.com/toregil/a-lung-u-net-in-keras\n"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "0e8946b1-fab5-48f1-8e9c-46471247032a", "collapsed": true, "_uuid": "92bb988eb4fbb38953fe389c2592de6c3c1c462a"}, "source": ["def dice_coef(y_true, y_pred):\n", "    y_true_f = K.flatten(y_true)\n", "    y_pred_f = K.flatten(y_pred)\n", "    intersection = K.sum(y_true_f * y_pred_f)\n", "    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "5e0816ba-4e27-4748-ac89-34df8a3e2a8b", "_uuid": "7ca558934f66c6a01a61eeb610ed0fd58d8a9fc1"}, "source": ["from keras.models import Model\n", "from keras.layers import *\n", "from keras.layers import UpSampling2D\n", "from keras.callbacks import * \n", "from keras.optimizers import Adam\n", "from keras.regularizers import l2\n", "from keras.preprocessing.image import ImageDataGenerator\n", "import keras.backend as K\n", "from keras.callbacks import LearningRateScheduler, ModelCheckpoint"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "fdaa453d-c95e-428b-a2de-f7b2bcbe0cdb", "collapsed": true, "_uuid": "ab75cfa3ddcaec85f770e13cab213aa9da0d9cf1"}, "source": ["input_layer = Input(shape=np.asarray(X_train).shape[1:])\n", "c1 = Conv2D(filters=8,\n", "            input_shape=[WIDTH,HEIGHT,IMG_CHANNELS],\n", "            kernel_size=(3,3), activation='relu', padding='same')(input_layer)\n", "l = MaxPool2D(strides=(2,2))(c1)\n", "\n", "c2 = Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same')(l)\n", "l = MaxPool2D(strides=(2,2))(c2)\n", "\n", "c3 = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(l)\n", "l = MaxPool2D(strides=(2,2))(c3)\n", "\n", "c4 = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='same')(l)\n", "\n", "#we concatenate the c3 output with the upsample of c4 and apply a further convolution\n", "l = concatenate([UpSampling2D(size=(2,2))(c4), c3], axis=-1)\n", "l = Conv2D(filters=32, kernel_size=(2,2), activation='relu', padding='same')(l)\n", "\n", "#the same up to the first layer\n", "l = concatenate([UpSampling2D(size=(2,2))(l), c2], axis=-1)\n", "l = Conv2D(filters=24, kernel_size=(2,2), activation='relu', padding='same')(l)\n", "\n", "l = concatenate([UpSampling2D(size=(2,2))(l), c1], axis=-1)\n", "l = Conv2D(filters=16, kernel_size=(2,2), activation='relu', padding='same')(l)\n", "\n", "l = Conv2D(filters=64, kernel_size=(1,1), activation='relu')(l)\n", "\n", "l = Dropout(0.5)(l)\n", "output_layer = Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid')(l)\n", "                                                         \n", "model = Model(input_layer, output_layer)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "70a9811d-338f-466a-aacc-491d7f436245", "_uuid": "8fb14ffa9835d4c5ba49e5cd67ab516425a15fde"}, "source": ["model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n", "model.summary()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "1c969948-5acd-414d-af03-d59768095483", "_uuid": "ed41a564ab45987809cc4a8e696856f9a1af6396"}, "source": ["earlystopper = EarlyStopping(patience=5, verbose=1)\n", "checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n", "results = model.fit(np.asarray(X_train), np.asarray(Y_train), validation_split=0.1, batch_size=16, epochs=10, \n", "                    callbacks=[earlystopper, checkpointer])"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "90093af4-95bf-4c2d-bce1-36eee1c4db71", "_uuid": "b914f55c143a2136feb4dd4f539fda8bc981baf2"}, "source": ["## Validation"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "10e77429-7c4c-478b-9ed8-1edf1199614e", "_uuid": "2db763150c6f8f4c655780e75449d062dcab0fdb"}, "source": ["Let's see how the trained U-Net performes against the Validation dataset"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "e27e4e0f-1971-4a50-b32d-f7a1ddd546d3", "collapsed": true, "_uuid": "d6f3344472a5bc5ab2ae69152bb2a7f1e2d14ef6"}, "source": ["preds = model.predict(np.asarray(X_val))"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "d97e93bd-0969-4978-9fc2-ac2e15f04f82", "_uuid": "bf213aef8a747789380c928fea312d10fd49d319"}, "source": ["n_img = 6\n", "fig, axa = plt.subplots(2, 3, figsize = (15, 6))\n", "axa[0][0].imshow(X_val[0].reshape(WIDTH,HEIGHT,3))\n", "axa[0][1].imshow(X_val[1].reshape(WIDTH,HEIGHT,3))\n", "axa[0][2].imshow(X_val[2].reshape(WIDTH,HEIGHT,3))\n", "axa[1][0].imshow(preds[0].reshape(WIDTH,HEIGHT))\n", "axa[1][1].imshow(preds[1].reshape(WIDTH,HEIGHT))\n", "axa[1][2].imshow(preds[2].reshape(WIDTH,HEIGHT))"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["from skimage.filters import threshold_otsu\n", "fpreds =[]\n", "for p in preds:\n", "    #thresh = threshold_otsu(p)\n", "    thresh = 0.5\n", "    binary = p > thresh\n", "    fpreds.append(binary)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["def iou(A,B):\n", "    intersect = (A*B)\n", "    union = (A+B)>0\n", "    return intersect.sum()/union.sum()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["ious = []\n", "for i in range(len(Y_val)):\n", "    ious.append(iou(Y_val[i],fpreds[i]))"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["pd.Series(ious).mean()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "9e74cada-17a6-49b9-b2a0-fbcc7039008b", "_uuid": "d75c55c835432adbdf3af173c55222f03ef0a867"}, "source": ["## Test"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "a3a44ffd-354c-45c8-9b38-cbf3b80c24da", "collapsed": true, "_uuid": "d54e1a1280a6b5580c56d36d9dda17a9a351d683"}, "source": ["tpreds = model.predict(np.asarray(X_test))"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true}, "source": ["fpreds = []\n", "for p in tpreds:\n", "    #thresh = threshold_otsu(p)\n", "    thresh = 0.5\n", "    binary = p > thresh\n", "    fpreds.append(binary)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true}, "source": ["fpreds = tpreds"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "970c85c3-1a3d-4654-b338-979b28d880cf", "collapsed": true, "_uuid": "bd86271a60ae324373bcf5b35fcb6f402c30fdd9"}, "source": ["fig, axa = plt.subplots(2, 3, figsize = (15, 6))\n", "axa[0][0].imshow(X_test[0].reshape(WIDTH,HEIGHT,3))\n", "axa[0][1].imshow(X_test[10].reshape(WIDTH,HEIGHT,3))\n", "axa[0][2].imshow(X_test[2].reshape(WIDTH,HEIGHT,3))\n", "axa[1][0].imshow(tpreds[0].reshape(WIDTH,HEIGHT))\n", "axa[1][1].imshow(tpreds[10].reshape(WIDTH,HEIGHT))\n", "axa[1][2].imshow(tpreds[2].reshape(WIDTH,HEIGHT))"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "97f74d02-3841-4f7a-b32c-c07caa4235d6", "collapsed": true, "_uuid": "276d72bf3bbc50151d325cb1698f4f070ab05f59"}, "source": ["test_sizes = Test.images.map(lambda x: x.shape)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "9e950d0c-1ef1-4818-8382-86f885b71a74", "collapsed": true, "_uuid": "eae5a47527d679e802658f08cf05fa6f3247d0e4"}, "source": ["preds_test_upsampled = []\n", "for i in range(len(tpreds)):\n", "    preds_test_upsampled.append(resize(np.squeeze(tpreds[i]), \n", "                                       (test_sizes[i][0], test_sizes[i][1]), \n", "                                       mode='constant', preserve_range=True))"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "02e1ffb4-7d7f-490c-9d92-8eaf37daa09d", "collapsed": true, "scrolled": true, "_uuid": "8e3b33b01e830a9d2903b871d2d3aa2990315986"}, "source": ["fig, axa = plt.subplots(1, 3, figsize = (15, 6))\n", "axa[0].imshow(preds_test_upsampled[0].reshape(test_sizes[0][0], test_sizes[0][1]))\n", "axa[1].imshow(preds_test_upsampled[1].reshape(test_sizes[1][0], test_sizes[1][1]))\n", "axa[2].imshow(preds_test_upsampled[2].reshape(test_sizes[2][0], test_sizes[2][1]))"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "5483c231-ddfc-40d5-bc67-e71f52860d6d", "_uuid": "4ab002351213eb6a4f61c860d5ef79baf55bdba6"}, "source": ["Thanks to https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "585cff23-4ccb-45ad-bd95-794b3b759020", "collapsed": true, "_uuid": "f13eec719c223b2b8f29cc6f0f191e68b40abb5c"}, "source": ["# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n", "def rle_encoding(x):\n", "    dots = np.where(x.T.flatten() == 1)[0]\n", "    run_lengths = []\n", "    prev = -2\n", "    for b in dots:\n", "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n", "        run_lengths[-1] += 1\n", "        prev = b\n", "    return run_lengths\n", "\n", "def prob_to_rles(x, cutoff=0.5):\n", "    lab_img = label(x > cutoff)\n", "    for i in range(1, lab_img.max() + 1):\n", "        yield rle_encoding(lab_img == i)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "a50e8d0d-3fc7-4a1f-9f35-908c721be300", "collapsed": true, "_uuid": "f72369d0c72436da32830f16a97530912a5ff911"}, "source": ["new_test_ids = []\n", "rles = []\n", "for n, id_ in enumerate(Test.ImageId):\n", "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n", "    rles.extend(rle)\n", "    new_test_ids.extend([id_] * len(rle))"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "146275c1-f139-47ce-af06-5d7ecc0f5479", "collapsed": true, "_uuid": "c4136e776f67f9fcab48fbae7473f71e4699e56e"}, "source": ["sub = pd.DataFrame()\n", "sub['ImageId'] = new_test_ids\n", "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n", "sub.to_csv('sub-dsbowl2018-1.csv', index=False)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "b392a576-ebd2-4121-85d8-8997ee593dac", "collapsed": true, "_uuid": "5019e69ce54056eb67b4fb92075c64bf9f9765c3"}, "source": [], "execution_count": null, "cell_type": "code", "outputs": []}], "nbformat": 4, "nbformat_minor": 1}