{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import os\nimport shutil\nfrom random import shuffle\n\n# make sure there's no dataset folder from previous executions\nif os.path.exists('./dataset'):\n    shutil.rmtree('./dataset')\n\n# create folder structure\nif not os.path.exists('./dataset'):\n    os.makedirs('./dataset')\n\nif not os.path.exists('./dataset/train'):\n    os.makedirs('./dataset/train')\nif not os.path.exists('./dataset/train/dog'):\n    os.makedirs('./dataset/train/dog')\nif not os.path.exists('./dataset/train/cat'):\n    os.makedirs('./dataset/train/cat')\n\nif not os.path.exists('./dataset/validation'):\n    os.makedirs('./dataset/validation')\nif not os.path.exists('./dataset/validation/dog'):\n    os.makedirs('./dataset/validation/dog')\nif not os.path.exists('./dataset/validation/cat'):\n    os.makedirs('./dataset/validation/cat')\n\nif not os.path.exists('./dataset/test'):\n    os.makedirs('./dataset/test')\nif not os.path.exists('./dataset/test/unlabeled'):\n    os.makedirs('./dataset/test/unlabeled')\n\n# select indices as for training and validation in random\nclass_size = 12500\ncat_indices = list(range(class_size))\ndog_indices = list(range(class_size))\n\nvalidation_to_train_ratio = 1. / 5.\n\nshuffle(cat_indices)\nshuffle(dog_indices)\n\ncat_train_indices = cat_indices[int(validation_to_train_ratio * class_size) : ]\ndog_train_indices = dog_indices[int(validation_to_train_ratio * class_size) : ]\ncat_validation_indices = cat_indices[0 : int(validation_to_train_ratio * class_size)]\ndog_validation_indices = dog_indices[0 : int(validation_to_train_ratio * class_size)]\n\nfor index in cat_train_indices:\n    src = '../input/train/cat.%d.jpg' % index\n    dst = './dataset/train/cat/cat.%s.jpg' % str(index).zfill(5)\n    shutil.copyfile(src, dst)\n\nfor index in dog_train_indices:\n    src = '../input/train/dog.%d.jpg' % index\n    dst = './dataset/train/dog/dog.%s.jpg' % str(index).zfill(5)\n    shutil.copyfile(src, dst)\n\nfor index in cat_validation_indices:\n    src = '../input/train/cat.%d.jpg' % index\n    dst = './dataset/validation/cat/cat.%s.jpg' % str(index).zfill(5)\n    shutil.copyfile(src, dst)\n\nfor index in dog_validation_indices:\n    src = '../input/train/dog.%d.jpg' % index\n    dst = './dataset/validation/dog/dog.%s.jpg' % str(index).zfill(5)\n    shutil.copyfile(src, dst)\n\nfor index in range(12500):\n    src = '../input/test/%d.jpg' % (index + 1)\n    dst = './dataset/test/unlabeled/%s.jpg' % str(index).zfill(5)\n    shutil.copyfile(src, dst)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\ntest_datagen = ImageDataGenerator(rescale = 1./255)\n\ntrain_generator = train_datagen.flow_from_directory('./dataset/train',\n                                                    target_size=(150, 150),\n                                                    batch_size=100,\n                                                    shuffle = True,\n                                                    class_mode='binary')\nvalidation_generator = test_datagen.flow_from_directory('./dataset/validation',\n                                                       target_size=(150, 150),\n                                                       batch_size=100,\n                                                       shuffle = False,\n                                                       class_mode='binary')\ntest_generator = test_datagen.flow_from_directory('./dataset/test',\n                                                  target_size=(150, 150),\n                                                  batch_size=100,\n                                                  shuffle = False,\n                                                  class_mode='binary')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"670e732e2fa5b8254c4b523bc3498fe0cb3c4196","collapsed":true},"cell_type":"code","source":"from keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.applications import VGG16\nfrom keras import regularizers\nimport keras.backend as K\n\nconv_base = VGG16(weights = 'imagenet',\n             include_top = False,\n             input_shape = (150, 150, 3))\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l1_l2(0.02)))\nmodel.add(layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l1_l2(0.01)))\n\nconv_base.trainable = True\nset_trainable = False\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\ndef pure_loss(y_true, y_pred):\n    return K.binary_crossentropy(y_true, y_pred)\n\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.Adadelta(), metrics=['acc', pure_loss])\n\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch = 50,\n                              epochs = 100,\n                              validation_data = validation_generator,\n                              validation_steps = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7799828c28c78d0b097e27a4b1f96bcd9420de28","collapsed":true},"cell_type":"code","source":"prediction = model.predict_generator(test_generator)\nprint(prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fdefa1cdcafb5d687eed974322e31d62f253a978"},"cell_type":"code","source":"import csv\n\ncsvData = [['id', 'label']]\nfor i, j in enumerate(prediction):\n    csvData.append([i + 1, j[0]])\ncsvFile = open('./submission.csv', 'w')\nwith csvFile:\n   writer = csv.writer(csvFile)\n   writer.writerows(csvData)\n\n# delete the dataset folder\nif os.path.exists('./dataset'):\n    shutil.rmtree('./dataset')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b778df0539aead5f033f9fc3dabb980bba13df9","collapsed":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\npure_loss = history.history['pure_loss']\nval_pure_loss = history.history['val_pure_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.figure(figsize = (12, 8))\nplt.plot(epochs, acc, 'ro', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure(figsize = (12, 8))\nplt.plot(epochs, loss, 'ro', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.figure(figsize = (12, 8))\nplt.plot(epochs, pure_loss, 'ro', label='Training pure loss')\nplt.plot(epochs, val_pure_loss, 'b', label='Validation pure loss')\nplt.title('Training and validation pure loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}