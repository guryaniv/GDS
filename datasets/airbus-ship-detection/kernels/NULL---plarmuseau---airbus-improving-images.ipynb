{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom skimage.data import imread\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cf2c43bfcd31772ddf1fb9bc31d775df00eed48","collapsed":true},"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c637577ab3a8ac8ffd67fe8bfcf8a43defc214d"},"cell_type":"markdown","source":"## Look at a sample of the training images."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"train = pd.read_csv('../input/train_ship_segmentations.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c280f6308cc97d6f30484391a9e785c00ee653f"},"cell_type":"markdown","source":"## Look at 25 images with ships..."},{"metadata":{"trusted":true,"_uuid":"8b48df1a40648b4c212768e130848560de994c7e","scrolled":true,"collapsed":true},"cell_type":"code","source":"sample = train[~train.EncodedPixels.isna()].sample(25)\n\nfig, ax = plt.subplots(5, 5, sharex='col', sharey='row')\nfig.set_size_inches(20, 20)\n\nfor i, imgid in enumerate(sample.ImageId):\n    col = i % 5\n    row = i // 5\n    \n    path = Path('../input/train') / '{}'.format(imgid)\n    img = imread(path)\n    \n    ax[row, col].imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb9bf42a94785f94cf7d43d0a05e2d12fb44107a","collapsed":true},"cell_type":"code","source":"#fig, ax = plt.subplots(5, 5, sharex='col', sharey='row')\n#fig.set_size_inches(20, 20)\nfrom PIL import Image, ImageEnhance\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom skimage.morphology import disk\nfrom skimage.filters import threshold_otsu, rank\nfrom skimage.util import img_as_ubyte\n\nfor i, imgid in enumerate(sample.ImageId):\n    col = i % 5\n    row = i // 5\n    \n    path = Path('../input/train') / '{}'.format(imgid)\n    img = imread(path)\n    img =img[:,:,1]\n    radius = 15\n    selem = disk(radius)\n\n    local_otsu = rank.otsu(img, selem)\n    threshold_global_otsu = threshold_otsu(img)\n    global_otsu = img >= threshold_global_otsu\n\n    fig, axes = plt.subplots(2, 2, figsize=(8, 5), sharex=True, sharey=True)\n    ax = axes.ravel()\n    plt.tight_layout()\n\n    fig.colorbar(ax[0].imshow(img, cmap=plt.cm.gray),\n                 ax=ax[0], orientation='horizontal')\n    ax[0].set_title('Original')\n    ax[0].axis('off')\n\n    fig.colorbar(ax[1].imshow(local_otsu, cmap=plt.cm.gray),\n                 ax=ax[1], orientation='horizontal')\n    ax[1].set_title('Local Otsu (radius=%d)' % radius)\n    ax[1].axis('off')\n\n    ax[2].imshow(img >= local_otsu, cmap=plt.cm.gray)\n    ax[2].set_title('Original >= Local Otsu' % threshold_global_otsu)\n    ax[2].axis('off')\n\n    ax[3].imshow(global_otsu, cmap=plt.cm.gray)\n    ax[3].set_title('Global Otsu (threshold = %d)' % threshold_global_otsu)\n    ax[3].axis('off')\n\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4a360b04380e5b9822ab614ae4eae3483ab9e8c"},"cell_type":"markdown","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.color import rgb2gray\nfrom skimage import data\nfrom skimage.filters import gaussian\nfrom skimage.segmentation import active_contour\n\nfor i, imgid in enumerate(sample.ImageId):\n    col = i % 5\n    row = i // 5\n    \n    path = Path('../input/train') / '{}'.format(imgid)\n    img = imread(path)\n    img =img[:,:,1]\n\n    image = img #img_as_float(data.camera())\n\n    s = np.linspace(0, 2*np.pi, 400)\n    x = 300 + 300*np.cos(s)\n    y = 300 + 300*np.sin(s)\n    init = np.array([x, y]).T\n\n    snake = active_contour(gaussian(img, 3),\n                           init, alpha=0.015, beta=10, gamma=0.001)\n\n    fig, ax = plt.subplots(figsize=(7, 7))\n    ax.imshow(img, cmap=plt.cm.gray)\n    ax.plot(init[:, 0], init[:, 1], '--r', lw=3)\n    ax.plot(snake[:, 0], snake[:, 1], '-b', lw=3)\n    ax.set_xticks([]), ax.set_yticks([])\n    ax.axis([0, img.shape[1], img.shape[0], 0])"},{"metadata":{"trusted":true,"_uuid":"c76126fa4808a5d4e3ade5dd8c2f5dba64e456de","collapsed":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import ndimage as ndi\n\nfrom skimage import feature\n\nfor i, imgid in enumerate(sample.ImageId):\n    col = i % 5\n    row = i // 5\n    \n    path = Path('../input/train') / '{}'.format(imgid)\n    img = imread(path)\n    im =img[:,:,1]\n    #im = ndi.gaussian_filter(img, 4)\n\n\n    # Compute the Canny filter for two values of sigma\n    edges1 = feature.canny(im, sigma=0.5)\n    edges2 = feature.canny(im, sigma=2)\n\n    # display results\n    fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\n                                        sharex=True, sharey=True)\n    \n    ax1.imshow(im, cmap=plt.cm.gray)\n    ax1.axis('off')\n    ax1.set_title('noisy image', fontsize=20)\n\n    ax2.imshow(edges1, cmap=plt.cm.gray)\n    ax2.axis('off')\n    ax2.set_title('Canny filter, $\\sigma=1$', fontsize=20)\n\n    ax3.imshow(edges2, cmap=plt.cm.gray)\n    ax3.axis('off')\n    ax3.set_title('Canny filter, $\\sigma=3$', fontsize=20)\n\n    fig.tight_layout()\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9f8b9cb837ce0d461cecd1e0703feee1cd59786","collapsed":true},"cell_type":"code","source":"from __future__ import print_function\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom skimage.data import astronaut\nfrom skimage.color import rgb2gray\nfrom skimage.filters import sobel\nfrom skimage.segmentation import felzenszwalb, slic, quickshift, watershed\nfrom skimage.segmentation import mark_boundaries\nfrom skimage.util import img_as_float\n\nfor i, imgid in enumerate(sample.ImageId):\n    col = i % 5\n    row = i // 5\n    \n    path = Path('../input/train') / '{}'.format(imgid)\n    print(path)\n    img = imread(path)\n    \n\n    segments_fz = felzenszwalb(img, scale=100, sigma=0.5, min_size=50)\n    segments_slic = slic(img, n_segments=250, compactness=10, sigma=1)\n    segments_quick = quickshift(img, kernel_size=3, max_dist=6, ratio=0.5)\n    gradient = sobel(rgb2gray(img))\n    segments_watershed = watershed(gradient, markers=250, compactness=0.001)\n\n    print(\"Felzenszwalb number of segments: {}\".format(len(np.unique(segments_fz))))\n    print('SLIC number of segments: {}'.format(len(np.unique(segments_slic))))\n    print('Quickshift number of segments: {}'.format(len(np.unique(segments_quick))))\n\n    fig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n\n    ax[0, 0].imshow(mark_boundaries(img, segments_fz))\n    ax[0, 0].set_title(\"Felzenszwalbs's method\")\n    ax[0, 1].imshow(mark_boundaries(img, segments_slic))\n    ax[0, 1].set_title('SLIC')\n    ax[1, 0].imshow(mark_boundaries(img, segments_quick))\n    ax[1, 0].set_title('Quickshift')\n    ax[1, 1].imshow(mark_boundaries(img, segments_watershed))\n    ax[1, 1].set_title('Compact watershed')\n\n    for a in ax.ravel():\n        a.set_axis_off()\n\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8d33ee05c97ecb8e55ecaf7d380cd4dafa8c5a0","collapsed":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom skimage import data\nfrom skimage.feature import match_template\nimg = imread('../input/train/15b4a80a3.jpg')\nboat1 = img[ 40:140, 370:520,:]\nimg = imread('../input/train/fad674252.jpg')\nboat3 = img[ 270:310, 640:740,:]\n\n\nimg = imread('../input/train/c62733fc9.jpg')\nboat2 = img[ 220:250, 375:475,:]\n\n\nfig = plt.figure(figsize=(8, 3))\nax1 = plt.subplot(1, 3, 1)\nax2 = plt.subplot(1, 3, 2)\nax3 = plt.subplot(1, 3, 3)\n\nax1.imshow(boat1)\nax2.imshow(boat2)\nax3.imshow(boat3)\n\nplt.show()\n    \nfor i, imgid in enumerate(sample.ImageId):\n    col = i % 5\n    row = i // 5\n    \n    path = Path('../input/train') / '{}'.format(imgid)\n    print(path)\n    img = imread(path)\n    fig = plt.figure(figsize=(8, 3))\n    ax1 = plt.subplot(1, 3, 1)\n    ax2 = plt.subplot(1, 3, 2)\n    ax3 = plt.subplot(1, 3, 3)\n\n    ax1.imshow(boat1)\n    ax1.set_axis_off()\n    ax1.set_title('template')\n    \n    result = match_template(img, boat1)\n    result2 = match_template(img, boat2)\n    result3 = match_template(img, boat3)\n    \n    ij = np.unravel_index(np.argmax(result), result.shape)\n    print(ij)\n    x, y,z = ij\n    \n    ij2 = np.unravel_index(np.argmax(result2), result2.shape)\n    print(ij2)\n    x2, y2,z = ij2\n    \n    ij3 = np.unravel_index(np.argmax(result3), result3.shape)\n    print(ij3)\n    x3, y3,z = ij3\n    \n    ax2.imshow(img, cmap=plt.cm.gray)\n    ax2.set_axis_off()\n    ax2.set_title('image')\n    # highlight matched region\n    hcoin, wcoin, z = boat1.shape\n    rect = plt.Rectangle((y,x), wcoin, hcoin, edgecolor='r', facecolor='none')\n    ax2.add_patch(rect)\n    \n    rect2 = plt.Rectangle((y2,x2), wcoin, hcoin, edgecolor='b', facecolor='none')\n    ax2.add_patch(rect2)\n\n    rect3 = plt.Rectangle((y3,x3), wcoin, hcoin, edgecolor='g', facecolor='none')\n    ax2.add_patch(rect3)\n    result=img[ x:x+wcoin, y:y+hcoin,:]\n    ax3.imshow(result)\n    ax3.set_axis_off()\n    #ax3.set_title('`match_template`\\nresult')\n    # highlight matched region\n    #ax3.autoscale(False)\n    #ax3.plot(x, y, 'o', markeredgecolor='r', markerfacecolor='none', markersize=10)\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c954e0657e18f7be6c5bff7b0b279d58af9a4c66"},"cell_type":"markdown","source":"## ...and 25 without ships."},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"44f8f6c310995282bc74d77afbda008abb67a7e8","collapsed":true},"cell_type":"code","source":"sample = train[train.EncodedPixels.isna()].sample(25)\n\nfig, ax = plt.subplots(5, 5, sharex='col', sharey='row')\nfig.set_size_inches(20, 20)\n\nfor i, imgid in enumerate(sample.ImageId):\n    col = i % 5\n    row = i // 5\n    \n    path = Path('../input/train') / '{}'.format(imgid)\n    img = imread(path)\n    \n    ax[row, col].imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"899ef6e2a72db9749b7200290c537465a7814da8"},"cell_type":"markdown","source":"## Look at class balance"},{"metadata":{"trusted":true,"_uuid":"0280055240c9ca385532beff63424f1f917d46a6","collapsed":true},"cell_type":"code","source":"train.groupby(train.EncodedPixels.isna()).size().plot(kind='bar', figsize=(12, 8));","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5b2b4f441d7d73baa3a2573f280b59a0b3f478e"},"cell_type":"markdown","source":"## Look at colour distributions between imags with ships and those without.\n\nLets look at 250 of each, sampled at random."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1681edef1d625e62fd45ebb28f151cd2aff669cb"},"cell_type":"code","source":"def get_img(imgid):\n    '''Return image array, given ID.'''\n    path = Path('../input/train/') / '{}'.format(imgid)\n    return imread(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"642e23bc325641393361420a4f3c3ae290a42121","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, sharex='col', sharey='row')\nfig.set_size_inches(20, 6)\n\nmask = train.EncodedPixels.isna()\nfor i, (msk, label) in enumerate(zip([mask, ~mask], ['No Ships', 'Ships'])):\n    _ids = train[msk].ImageId.sample(250)\n    imgs = np.array([get_img(_id) for _id in _ids])\n    \n    red = imgs[:, :, :, 0]\n    green = imgs[:, :, :, 1]\n    blue = imgs[:, :, :, 2]\n    \n    ax[i].plot(np.bincount(red.ravel()), color='orangered', label='red', lw=2)\n    ax[i].plot(np.bincount(green.ravel()), color='yellowgreen', label='green', lw=2)\n    ax[i].plot(np.bincount(blue.ravel()), color='skyblue', label='blue', lw=2)\n    ax[i].legend()\n    ax[i].title.set_text(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d2e4c851dd1b61e23dc5e5f8efa23cc4a60eb7b3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}