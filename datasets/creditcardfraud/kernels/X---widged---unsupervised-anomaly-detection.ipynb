{"cells":[{"metadata":{"_uuid":"d77e17704754fcc12aed372eca3be84ef98ba442"},"cell_type":"markdown","source":"* I believe that a system for anomaly detection should not be a supervised ML algorithm as it will learn (maybe) only anomalies it has seen. The true magic lies in being able to identify an anomaly never seen before...\n* The following is a kernel on a **Multi Gaussian Anomaly Detection UNSUPERVISED algorithm** using the credit card fraud detection dataset from Kaggle\n* As the data is very skewed - there are only 0.17% fraudulent transactions in the 280k samples -  accuracy is not a good metric: any \"model\" predicting ALL are normal transactions will have a 99.83% accuracy. So we need use Recall, Precision and their prodigy - the F1 score.\n* This multivariate gaussian anomaly detection does not take into account the time sequences, (while still having the time as a separate feature).\nThe time series nature of the anomaly detection should be dealt with RNN or LSMT or etc. - maybe another notebook.\n\n* Many thanks to the following kernels - learned a lot from them:\n* https://www.kaggle.com/tildekarthik/a-multivariate-gaussian-anomaly-detection\n* https://www.kaggle.com/clemensmzr/simple-multivariate-gaussian-anomaly-detection\n"},{"metadata":{"_cell_guid":"39fa021b-426e-45a2-90a5-c5c3f1dea498","_uuid":"16f9d7ff523d369820a361f01f1ab9d2f0dd70f7","trusted":true},"cell_type":"code","source":"# IMPORT MODULES\n\nimport numpy as np\nfrom numpy import ma\nimport pandas as pd\nimport math\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\n%matplotlib inline\nfrom matplotlib import ticker, cm\nfrom matplotlib.pyplot import figure\nimport seaborn as sns\n\nfrom scipy.stats import multivariate_normal\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report, precision_recall_fscore_support\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nprint(\"Modules imported...YAY !\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a83bbbcc-3cfe-4f3d-8b1f-d60a8241eba4","_uuid":"4aea5c7bfee88ad381c4c2b350195b2818338112","trusted":true},"cell_type":"code","source":"# LOAD DATA\n\ndfRaw = pd.read_csv('../input/creditcard.csv')\nprint(dfRaw.shape)\nprint(dfRaw.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d090dcd0ae534aec20381144696af2ac0f7707d5","collapsed":true},"cell_type":"code","source":"data = dfRaw.copy()\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\nprint(type(data))\nprint(\"data \", data.shape)\nprint(\"normal_data \", normal_data.shape)\nprint(\"fraud_data \", fraud_data.shape)\nprint(\"Percent fraud \", round(100*492/284807, 4),\"%\")\nprint(\"_\"*100)\nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"4a139ae5bac053937ede662b72b0208ef4c9da9b","collapsed":true},"cell_type":"code","source":"# Features' Prob DISTRIBUTION\n\nplt.figure()\nmatplotlib.style.use('ggplot')\npca_columns = list(data)[:-1]\nnormal_data[pca_columns].hist(stacked=False, bins=100, figsize=(12,30), layout=(16,2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6aa7fb8697a80ede29dafc92e3759c223d519656","collapsed":true},"cell_type":"code","source":"# PLOT AMOUNT - Norm vs Fraud\n\nnormal_data[\"Amount\"].loc[normal_data[\"Amount\"] < 500].hist(bins=100);\nplt.figure()\nfraud_data[\"Amount\"].loc[fraud_data[\"Amount\"] < 500].hist(bins=100);\nplt.figure()\nprint(\"Mean\", normal_data[\"Amount\"].mean(), fraud_data[\"Amount\"].mean())\nprint(\"Median\", normal_data[\"Amount\"].median(), fraud_data[\"Amount\"].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18872b84ab10c918f78256100b06e91da53b7789","collapsed":true},"cell_type":"code","source":"# PLOT TIME - Norm vs Fraud\n\nnormal_data[\"Time\"].hist(bins=100);\nplt.figure()\nfraud_data[\"Time\"].hist(bins=100);\nplt.figure()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"4b4e8235bdfc6023f16f7ebfc250dce1766dd892","collapsed":true},"cell_type":"code","source":"# data.plot.scatter(\"Time\",\"Amount\", c=\"Class\")\ndata.plot.scatter(\"V1\",\"V2\", c=\"Class\")\ndata.plot.scatter(\"V2\",\"V3\", c=\"Class\")\ndata.plot.scatter(\"V1\",\"V3\", c=\"Class\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"d22ed15fdd566ac52645519d4104d1f398875b65","collapsed":true},"cell_type":"code","source":"#  SCALER\n\ndata = dfRaw.copy()\n\nprint(data.shape)\nscl = StandardScaler()\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] \nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\nXscaled = scl.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((Xscaled, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = XcopyALL.columns)\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\nprint(data.shape)\n#print(data.head)\nprint(\"_\"*100)\nprint(\"data \", data.shape)\nprint(\"normal_data \", normal_data.shape)\nprint(\"fraud_data \", fraud_data.shape)\nprint(\"Percent fraud \", round(100*492/284807, 4),\"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b1895ad0980567dd07038efd64c69d02ff009b7","collapsed":true},"cell_type":"code","source":"# Features' Prob DISTRIBUTION AFTER Scaler\n\nplt.figure()\nmatplotlib.style.use('ggplot')\npca_columns = list(data)[:]\ndata[pca_columns].hist(stacked=False, bins=100, figsize=(12,30), layout=(16,2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa3171a509fef5a01025cec92bbb858fcad83ef2","collapsed":true},"cell_type":"code","source":"print(\"data['Time'].mean()  \", data['Time'].mean())\nprint(\"data['Amount'].mean()  \", data['Amount'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4f5e7beb7d54a7e588588fae46f5baaa862192f","collapsed":true},"cell_type":"code","source":"# CREATE the TRAIN, VALIDATION and TEST sets\n# Fraud data is ONLY in the CV and TEST - not in TRAIN\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\nprint(\"normal_data \", normal_data.shape)\nprint(\"fraud_data \", fraud_data.shape)\n\npca_columns = list(data)[:-1] \nnormal_pca_data = normal_data[pca_columns]\nfraud_pca_data = fraud_data[pca_columns]\n\nnum_test = 75000\nshuffled_data = normal_pca_data.sample(frac=1)[:-num_test].values\nX_train = shuffled_data\n\nX_valid = np.concatenate([shuffled_data[-2*num_test:-num_test], fraud_pca_data[:246]])\ny_valid = np.concatenate([np.zeros(num_test), np.ones(246)])\n\nX_test = np.concatenate([shuffled_data[-num_test:], fraud_pca_data[246:]])\ny_test = np.concatenate([np.zeros(num_test), np.ones(246)])\n\n\nprint(\"normal_pca_data \", normal_pca_data.shape)\nprint(\"fraud_pca_data\", fraud_pca_data.shape)\nprint(\"Fraud data divided between valid and test with NONE in the training\")\nprint(\"X_train \", X_train.shape)\nprint(\"X_valid \", X_valid.shape)\nprint(\"y_valid \", y_valid.shape)\nprint(\"X_test \", X_test.shape)\nprint(\"y_test \", y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b18032b819c61d729cc70947ed2da5919e473f7","collapsed":true},"cell_type":"code","source":"# Get Epsilon as the max prob \n\np = multivariate_normal(mean=np.mean(X_train,axis=0), cov=np.cov(X_train.T))\n\nx = p.pdf(fraud_pca_data)\nprint(\"max prob of x on fraud_pca_data\", max(x))\nx = p.pdf(X_valid)\nprint(\"max prob of x on X_valid\", max(x))\n\nepsilons = [1e-11,1e-12,1e-13,1e-14,1e-15,1e-16,1e-17,1e-18,1e-19,1e-20]\neps = epsilons[-1]\n\npred = (x <= eps)\nf = f1_score(y_valid, pred,average='binary')\nprint(\"F1 score on y_valid\", round(f,4), \" with epsilon \", eps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a08ddc6bdc8c5ed376721d7bd7fd09724db8120a","collapsed":true},"cell_type":"code","source":"# CONFUSION MATRIX and F1 SCORE\n\nx = p.pdf(X_valid)\nprint(\"max prob of x on X_valid\", max(x))\n\neps = 5e-15\n\nprint(\"epsilon \", eps)\nprint(\"_\"*50)\npred = (x<eps)\nCM = confusion_matrix(y_valid,pred)\ntn, fp, fn, tp = confusion_matrix(y_valid,pred).ravel()\n\nprint(CM)\nprint(\"_\"*50)\nprint(\"TP \", tp)\nprint(\"FP \", fp)\nprint(\"TN \", tn)\nprint(\"FN \", fn)\nprint(\"_\"*50)\n\n# F1 Score\n#print(\"F1 score\", round(f1_score(y_valid,pred, average='binary'), 4))\nprecision,recall,fbeta_score, support  = precision_recall_fscore_support(y_valid,pred, average='binary')\nprint(\"precision \", round((precision), 4))\nprint(\"recall \", round((recall), 4))\nprint(\"F1 score \", round((fbeta_score), 4))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f79eb2a320e0bc5c968aabd7736a58c259f75c32","collapsed":true},"cell_type":"code","source":"# Find the best EPSILON in terms of Recall, Precision and F1 Score\n\nvalidation = []\nfor thresh in np.linspace(eps*1e-150, eps*1e2, 100):\n    pred = (x<= thresh)\n    prec, recall, F1, support = precision_recall_fscore_support(y_valid, pred, average='binary')\n    validation.append([thresh, recall, prec, F1])\n    \nx = np.array(validation)[:, 0]\ny1 = np.array(validation)[:, 1]\ny2 = np.array(validation)[:, 2]\ny3 = np.array(validation)[:, 3]\n\n# 3 CHARTS - Recall, Precision and F1 score\n\nplt.plot(x, y1)\nplt.title(\"Recall\")\nplt.xscale('log')\nplt.show()\nplt.plot(x, y2)\nplt.title(\"Precision\")\nplt.xscale('log')\nplt.show()\nplt.plot(x, y3)\nplt.title(\"F1 score\")\nplt.xscale('log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"343ba22f35195173917b6e83964e69345ece6cc5","collapsed":true},"cell_type":"code","source":"# Recall, Precision and F1 Score on same chart\ndf=pd.DataFrame({'x': x, 'y1': y1, 'y2': y2, 'y3': y3 })\n \n# multiple line plot\nplt.xscale('log')\nplt.plot( 'x', 'y1', data=df, marker='', color='green', linewidth=2,  label=\"Recall\")\nplt.plot( 'x', 'y2', data=df, marker='', color='blue', linewidth=2, label=\"Precision\")\nplt.plot( 'x', 'y3', data=df, marker='o', color='red', markerfacecolor='orange',linewidth=3, markersize=6, label=\"F1 Score\")\nplt.legend()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e78237e36845df760bcb36b0932d45f5c46d80d"},"cell_type":"code","source":"#  SCALER & PCA ... instead of creating a pipeline...\n\ndata = dfRaw.copy()\n\n# Scaler\nprint(data.shape)\nscl = StandardScaler()\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] \nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\nXscaled = scl.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((Xscaled, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = XcopyALL.columns)\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\nprint(data.shape)\nprint(\"data \", data.shape)\nprint(\"normal_data \", normal_data.shape)\nprint(\"fraud_data \", fraud_data.shape)\nprint(\"Percent fraud \", round(100*492/284807, 4),\"%\")\nprint(\"_\"*100)\n\n# PCA\nprint(\"AFTER PCA\")\n\npca = PCA(n_components = 2) \n\nall_cols = list(data)[:] \npca_columns = list(data)[:-1] \nXcopy = data[pca_columns]\nXcopyALL = data[all_cols]\ndataPostPCA = pca.fit_transform(Xcopy)\nOnlyClass = data['Class'].values.reshape(-1,1)\ndata = np.concatenate((dataPostPCA, OnlyClass), axis=1)\ndata = pd.DataFrame(data, columns = [0,1,'Class'])\n\nnormal_data = data.loc[data[\"Class\"] == 0]\nfraud_data = data.loc[data[\"Class\"] == 1]\n\nprint(data.shape)\nprint(\"data \", data.shape)\nprint(\"normal_data \", normal_data.shape)\nprint(\"fraud_data \", fraud_data.shape)\nprint(\"Percent fraud \", round(100*492/284807, 4),\"%\")\n#print(\"_\"*100)\n#print(data.head)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a8df4d0c2055330b78d591c54f76ece442ebc2a"},"cell_type":"code","source":"# Get the Multi Variate Gaussian Prob Distribution Function for the 2 dimensions post PCA\n\nnormal_data=normal_data.copy()\nfraud_data= fraud_data.copy()\nnormal_data = normal_data.drop('Class', axis=1)\nfraud_data = fraud_data.drop('Class', axis=1)\nprint(normal_data.columns)\nprint(fraud_data.columns)\n\np = multivariate_normal(mean=np.mean(normal_data,axis=0), cov=np.cov(normal_data.T))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8cc6686d6d3a50b8a81af8cbfda1fb602899af43"},"cell_type":"code","source":"# View the FRAUD on a 2 dims (Post PCA) Guassian distribution of the normal data\n# Reducing from 30 dims to 2 - helps with the visualization but surely doesn't help with separating the Fraud from the Normal\n\nx, y = np.mgrid[-5.0:12.0:.01, -5.0:5.0:.01] \npos = np.empty(x.shape + (2,))\npos[:, :, 0] = x; pos[:, :, 1] = y\nrv = multivariate_normal(mean=np.mean(normal_data,axis=0), cov=np.cov(normal_data.T)) # mean and covariance matrix for 2 dims dataset\n\nfig, ax = plt.subplots()\ncs = ax.contourf(x, y, rv.pdf(pos))\ncbar = fig.colorbar(cs)\nplt.scatter(fraud_data[0],fraud_data[1], edgecolor=\"r\") # Location on chart of the anomaly points\nfig = matplotlib.pyplot.gcf()\nfig.set_size_inches(18.5, 10.5)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76f290bb74811ced591dea9620a99844e2fcccfb"},"cell_type":"code","source":"# View some NORMAL on a 2 dims (Post PCA) Guassian distribution of the normal data\n# Reducing from 30 dims to 2 - helps with the visualization but surely doesn't help with separating the Fraud from the Normal\n\nSampleNormal = normal_data[-500:]\n\nx, y = np.mgrid[-5.0:12.0:.01, -5.0:5.0:.01] \npos = np.empty(x.shape + (2,))\npos[:, :, 0] = x; pos[:, :, 1] = y\nrv = multivariate_normal(mean=np.mean(normal_data,axis=0), cov=np.cov(normal_data.T)) # mean and covariance matrix for 2 dims dataset\n\nfig, ax = plt.subplots()\ncs = ax.contourf(x, y, rv.pdf(pos))\ncbar = fig.colorbar(cs)\nplt.scatter(SampleNormal[0],SampleNormal[1], edgecolor=\"b\") # Location on chart of the anomaly points\nfig = matplotlib.pyplot.gcf()\nfig.set_size_inches(18.5, 10.5)\n#plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}