{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "067e51b5-a9f5-643a-3f97-0843f1f3a956"
      },
      "source": [
        "# Outline of this code:\n",
        "1. undersample non fraud dataset and make a balanced dataset as 1:1 to train the model\n",
        "2. use precision, recall, f1 and kappa to choose the best parameter c for regularization\n",
        "3. try different ratio of data to get more accurate and stable results\n",
        "4. using SMOTE to generate synthetic data points, accuracy is 0.944 and recall is 0.914 by logistic regression\n",
        "5. try to use random forest and orignal 1:1 ratio data set\n",
        "6. try to combine random forest and data after SMOTE\n",
        "7. eventually achieve recall rate is 1 and accuracy is 0.999871035061 and AUC is 0.99987081469"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "721872cd-e466-a65b-476b-d5ae9c23612c"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model, datasets\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, f1_score, cohen_kappa_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7366469a-c022-baaa-d883-462d5ff16bad"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"../input/creditcard.csv\")\n",
        "data.head()\n",
        "print(\"Non fraud rate:\")\n",
        "len(data.loc[data.loc[:, 'Class'] == 0, :]) / len(data.loc[:, 'Class'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "af12e0c6-cee3-6783-df8a-0cf078955c46"
      },
      "source": [
        "We found that the data is really biased toward non fraud data points. Therefore, in order to get robust result we have to resample the data. Firstly, we try to under sample the non-fraud data points to get 1:1 ratio dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c191bb90-7f3f-0238-e086-b917bd092d28"
      },
      "outputs": [],
      "source": [
        "# under sample non fraud\n",
        "len_fraud = len(data.loc[data.loc[:, 'Class'] == 1, :])\n",
        "print(\"number of fraud: \", len_fraud)\n",
        "# sample from non fraud to have 50/50 propotion\n",
        "sub_non_fraud = data.loc[data.loc[:, 'Class'] == 0, :].sample(len_fraud)\n",
        "sub_non_fraud.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ef441766-f099-0b6a-a081-50b995a61854"
      },
      "outputs": [],
      "source": [
        "# combine resample fraud and non fraud data\n",
        "data_resample = pd.concat([sub_non_fraud, data.loc[data.loc[:, 'Class'] == 1, :]])\n",
        "print(\"Non fraud rate:\")\n",
        "len(data_resample.loc[data_resample.loc[:, 'Class'] == 0, :]) / len(data_resample.loc[:, 'Class'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b68ff010-2b1d-1632-98ca-9a56280b0ddc"
      },
      "source": [
        "After under sample the non-fraud data points, we try logistic regression first as out benchmark. In this practice, we care not only the accuracy rate but also the recall rate. We introduce F1 and Cohen\u2019s kappa to compare different regularization power c.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ba07f19b-4b59-730f-47ea-3bb569188ea0"
      },
      "outputs": [],
      "source": [
        "# use k fold to find the highest recall rate parameter\n",
        "X = data_resample.iloc[:, 1:29]\n",
        "Y = data_resample.loc[:, \"Class\"]\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "kf.get_n_splits(X)\n",
        "# test on different regularation power\n",
        "cs = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "for c in cs:\n",
        "    accuracy = []\n",
        "    recall = []\n",
        "    f1 = []\n",
        "    kappa = []\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
        "        y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "        logreg = LogisticRegression(penalty='l1', solver='liblinear', C=c, max_iter=100)\n",
        "        logreg.fit(X_train, y_train)\n",
        "        y_test_pred = logreg.predict(X_test)\n",
        "        recall.append(recall_score(y_test, y_test_pred))\n",
        "        accuracy.append(accuracy_score(y_test, y_test_pred))\n",
        "        f1.append(f1_score(y_test, y_test_pred))\n",
        "        kappa.append(cohen_kappa_score(y_test, y_test_pred))\n",
        "    print(\"For c=\", c, \"\\t recall rate is\", np.mean(recall), \" and accuracy is\", np.mean(accuracy), \" f1 =\", np.mean(f1), \" kappa =\", np.mean(kappa))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8c77154b-3031-8bff-91c8-8d43f433ba3a"
      },
      "source": [
        "### After comparing Kappa and f1 score, we choose to use c = 1 as the best parameter for regularization.  \n",
        "Then we use c=1 and resample dataset to train logistic regression and predict on the original whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ed59ea47-9c55-3b09-e61b-c70b904d2a26"
      },
      "outputs": [],
      "source": [
        "# use all data after resample to train the model\n",
        "X = data_resample.iloc[:, 1:29]\n",
        "Y = data_resample.loc[:, \"Class\"]\n",
        "logreg = LogisticRegression(penalty='l1', solver='liblinear', C=1, max_iter=100)\n",
        "logreg.fit(X, Y)\n",
        "# apply to original dataset\n",
        "ori_data = pd.read_csv(\"../input/creditcard.csv\")\n",
        "X_test = ori_data.iloc[:, 1:29]\n",
        "Y_test = ori_data.loc[:, 'Class']\n",
        "Y_test_predict = logreg.predict(X_test)\n",
        "print(\"accuracy rate is \", accuracy_score(Y_test, Y_test_predict))\n",
        "print(\"recall rate is \", recall_score(Y_test, Y_test_predict))\n",
        "# AUC score\n",
        "roc_auc_score(Y_test, Y_test_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7ad35d1d-6ecd-b8a3-8f4a-0b2eef839fc2"
      },
      "source": [
        "## Different ratio of data  \n",
        "There is other method to tackle imbalance dataset. First I would like to try different ratio of fraud and non-fraud data such as 1:1.5, 1:2 and so on. Let's see what can it bring to us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4b4dc6c8-fe7c-187b-eaa6-1d18255d36c4"
      },
      "outputs": [],
      "source": [
        "# function to try to use different ratio and output the result\n",
        "def result_by_ratio(size_non_fraud):\n",
        "    # generate different ratio of data\n",
        "    sub_non_fraud = data.loc[data.loc[:, 'Class'] == 0, :].sample(int(len_fraud*size_non_fraud))\n",
        "    data_resample = pd.concat([sub_non_fraud, data.loc[data.loc[:, 'Class'] == 1, :]])\n",
        "    print(\"-----------------------------------------------\")\n",
        "    print(\"Non fraud rate:\", len(data_resample.loc[data_resample.loc[:, 'Class'] == 0, :]) / len(data_resample.loc[:, 'Class']))\n",
        "    # use k fold to find the highest recall rate parameter\n",
        "    X = data_resample.iloc[:, 1:29]\n",
        "    Y = data_resample.loc[:, \"Class\"]\n",
        "    kf = KFold(n_splits=5, shuffle=True)\n",
        "    kf.get_n_splits(X)\n",
        "    # test on different regularation power\n",
        "    cs = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "    for c in cs:\n",
        "        accuracy = []\n",
        "        recall = []\n",
        "        f1 = []\n",
        "        kappa = []\n",
        "        for train_index, test_index in kf.split(X):\n",
        "            X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
        "            y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "            logreg = LogisticRegression(penalty='l1', solver='liblinear', C=c, max_iter=100)\n",
        "            logreg.fit(X_train, y_train)\n",
        "            y_test_pred = logreg.predict(X_test)\n",
        "            recall.append(recall_score(y_test, y_test_pred))\n",
        "            accuracy.append(accuracy_score(y_test, y_test_pred))\n",
        "            f1.append(f1_score(y_test, y_test_pred))\n",
        "            kappa.append(cohen_kappa_score(y_test, y_test_pred))\n",
        "    chosed_c = cs[kappa.index(max(kappa))]\n",
        "    # use all data after resample to train the model\n",
        "    X = data_resample.iloc[:, 1:29]\n",
        "    Y = data_resample.loc[:, \"Class\"]\n",
        "    logreg = LogisticRegression(penalty='l1', solver='liblinear', C=chosed_c, max_iter=100)\n",
        "    logreg.fit(X, Y)\n",
        "    # apply to original dataset\n",
        "    ori_data = pd.read_csv(\"../input/creditcard.csv\")\n",
        "    X_test = ori_data.iloc[:, 1:29]\n",
        "    Y_test = ori_data.loc[:, 'Class']\n",
        "    Y_test_predict = logreg.predict(X_test)\n",
        "    print(\"when ratio is 1:\", size_non_fraud, \"accuracy is \", \\\n",
        "              accuracy_score(Y_test, Y_test_predict), \"and recall is\",recall_score(Y_test, Y_test_predict), \\\n",
        "          \" and ROC score is\", roc_auc_score(Y_test, Y_test_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "80924f96-09b3-fe19-e2fc-060e22b65521"
      },
      "outputs": [],
      "source": [
        "ratio_list = [1, 1.5, 2, 2.5, 3, 3.5, 4]\n",
        "for ratio in ratio_list:\n",
        "    result_by_ratio(ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "77263bca-987e-1d84-9ce9-6b2de9d3ab29"
      },
      "source": [
        "from the above result, we saw some dramatic drop in accuracy when we use some sample size and seems there is no good ratio of data that can help us to cure the imbalanced data. \n",
        "#### now I would like to generate Synthetic Samples by SMOTE  \n",
        "The SMOTE is a synthetic minority over-sampling technique to over sample the data. You may refer to [Imbalace learning](https://github.com/scikit-learn-contrib/imbalanced-learn) to have more info and different method. Here I use the basic one. For proformance purpose, I reduce the nonfraud data point to quarter to reduce the time to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b41f2696-1a7b-cac1-54bc-ea9a65fe7453"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sub_non_fraud = data.loc[data.loc[:, 'Class'] == 0, :].sample(int(len(data.loc[:, 'Class']) / 2))\n",
        "data_resample = pd.concat([sub_non_fraud, data.loc[data.loc[:, 'Class'] == 1, :]])\n",
        "X = data_resample.iloc[:, 1:29]\n",
        "y = data_resample.loc[:, \"Class\"]\n",
        "sm = SMOTE(kind='regular')\n",
        "X_resampled, y_resampled = sm.fit_sample(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e2a291f8-1fb4-fe31-6bb3-71e729bcac0d"
      },
      "outputs": [],
      "source": [
        "# size of X and y after SMOTE\n",
        "print(\"Size of X\", X_resampled.shape)\n",
        "print(\"Size of y\", y_resampled.shape)\n",
        "print(\"Size of fraud\", y_resampled[y_resampled == 1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "848ffc6c-fb75-6120-1613-3f1bd22c97d5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_resampled = pd.DataFrame(X_resampled)\n",
        "y_resampled = pd.DataFrame(y_resampled)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = 0.3, random_state = 42)\n",
        "c = [0.01, 0.1, 1, 10]\n",
        "logreg = LogisticRegressionCV(penalty='l2', solver='sag', Cs=c, refit=True, cv=10, max_iter=100)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_test_predict = logreg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "514a5c92-8cf4-cf67-b4a5-33f0bee9fd4a"
      },
      "outputs": [],
      "source": [
        "print(\"accuracy is \", accuracy_score(y_test, y_test_predict), \"and recall is\",recall_score(y_test, y_test_predict))\n",
        "print(\"AUC score is \", roc_auc_score(y_test, y_test_predict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6f971ded-1432-9005-a6d5-2d620582722d"
      },
      "source": [
        "### The result seems similar to previous one and doesn't improve a lot. Let's try different learning algorithm for example Random Forest. We use resample dataset by SMOTE combined with random forest. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7d36c764-7cbb-18d0-0b8e-f5e7ca8c516a"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train, y_train)\n",
        "y_test_predict = rf.predict(X_test)\n",
        "print(\"accuracy is \", accuracy_score(y_test, y_test_predict), \"and recall is\",recall_score(y_test, y_test_predict))\n",
        "print(\"AUC score is \", roc_auc_score(y_test, y_test_predict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e663c977-4987-f76f-2878-f154d46b46d8"
      },
      "source": [
        "## Here we get recall rate is almost 1 and really high AUC score. \n",
        "The result seems incredibly good. Does the result come from SMOTE or Random Forest. Let's use only the original data to train the random forest again without SMOTE resample dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b08b6455-0b3b-d1e2-db2c-e60b47e0a2dc"
      },
      "outputs": [],
      "source": [
        "# under sample non fraud\n",
        "len_fraud = len(data.loc[data.loc[:, 'Class'] == 1, :])\n",
        "# sample from non fraud to have 50/50 propotion\n",
        "sub_non_fraud = data.loc[data.loc[:, 'Class'] == 0, :].sample(len_fraud)\n",
        "data_resample = pd.concat([sub_non_fraud, data.loc[data.loc[:, 'Class'] == 1, :]])\n",
        "X = data_resample.iloc[:, 1:29]\n",
        "y = data_resample.loc[:, \"Class\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
        "rf2 = RandomForestClassifier(n_estimators=100)\n",
        "rf2.fit(X_train, y_train)\n",
        "\n",
        "ori_data = pd.read_csv(\"../input/creditcard.csv\")\n",
        "X_test = ori_data.iloc[:, 1:29]\n",
        "y_test = ori_data.loc[:, 'Class']\n",
        "y_test_predict = rf2.predict(X_test)\n",
        "print(\"accuracy rate is \", accuracy_score(y_test, y_test_predict))\n",
        "print(\"recall rate is \", recall_score(y_test, y_test_predict))\n",
        "print(\"AUC score is \", roc_auc_score(y_test, y_test_predict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1fc575e3-7d8c-1b8f-d491-5dd6bf81d64b"
      },
      "source": [
        "#### we conclude that combining SMOTE and Random forest, we can get a really good result. If we use only random forest, the result seems decent. "
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}