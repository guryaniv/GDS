{"cells":[{"metadata":{"trusted":true,"_uuid":"351c05785b228868181b3291bff9b58edfddaa83"},"cell_type":"code","source":"## Import necessary packages.\nimport numpy as np ## linear algebra\nimport pandas as pd ## data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))\nfrom sklearn import tree\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#######################\n# Data handling steps #\n#######################\n\n## Import Data from Website ##\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\n\n## Get Training data ##\n(market_train_df, news_train_df) = env.get_training_data()\nmarket_train_df.head()\n\n## Get Testing data.. probably not? ##\n# days = env.get_prediction_days()\n# (market_obs_df, news_obs_df, predictions_template_df) = next(days)\n\n## list of variables ##\nlist(market_train_df)\nlist(news_train_df)\n\n## Classification tree reference \n## https://scikit-learn.org/stable/modules/tree.html\n## https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/    \n\n## Check how the 'assetCode' is distributed ##\nmarket_assetCode = market_train_df['assetCode']\nnews_assetCode = news_train_df['assetCodes']\n\n## Make a crosstab for 'assetName' ##\nmarket_train_tab = pd.crosstab(index=market_assetCode, columns=\"count\") \nnews_train_tab = pd.crosstab(index=news_assetCode, columns=\"count\")\n\n## Our Research Target will be a asset whose assetCode is 'AAPL.O' ## \nassetCodelist = ['AMZN.O','EBAY.O','WMT.N','KR.N','COST.O','TGT.N','HD.N','CVS.N','BBY.N','LOW.N']\nMarket_IDlist = []\nfor i in range(len(assetCodelist)):\n    Market_IDlist = Market_IDlist + list(np.where(market_assetCode == assetCodelist[i])[0])\n\n## Create Market_TargetData... it is subset of market_train_df which contains only information about 'AAPL.O'\nMarket_TargetData = market_train_df.iloc[Market_IDlist]\n\n## Create Mk_data... it is subset of Market_TargetData which contains 'time' and 'returnsOpenNextMktres10' only.\nMk_data = Market_TargetData[['assetCode','time','returnsOpenNextMktres10']]\n\n## Create time Index.... we will pick only one data point from datameasures\nnt = Mk_data.shape[0]\nindexT = []\nfor i in range(nt):\n  num = str(Mk_data['time'].values[i])[:10] + Mk_data['assetCode'].values[i]\n  indexT = indexT + [num]\n\n## This can be used as Key value of time\nMk_data['index'] = indexT\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"## Extract Newsdata from training.. this takes quite long time!!\nn = len(news_assetCode)\nNs_data = pd.DataFrame()\nfor j in range(len(assetCodelist)):\n    News_ID = []\n    for i in range(n):\n        if assetCodelist[j] in news_assetCode[i]:\n            News_ID = News_ID + [i]\n\n    ## Create Ns_data... it is subset of news_train_df which contains only information about 'AAPL.O'\n    # nt_df[nt_df['sourceId']=='d7ad319ee02edea0'] can be used.. but this time assetsCode is string\n    Ns_data_temp = news_train_df.iloc[News_ID]\n\n    ## Create time Index.... we will pick only one data point from datameasures\n    nt = Ns_data_temp.shape[0]\n    indexT = []\n    for i in range(nt):\n      num = str(Ns_data_temp['time'].values[i])[:10] + assetCodelist[j]\n      indexT = indexT + [num]    \n    Ns_data_temp['indexT'] = indexT\n    Ns_data = pd.concat([Ns_data, Ns_data_temp], ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"955cb7828967b13fb445cb011a628bb6fdf6a8db"},"cell_type":"code","source":"## Set a rownumber for Ns_data before we reduce it.\nnt = Ns_data.shape[0]\nNs_data['rownumber'] = range(nt)\n\n## Reduce Ns_data...1. summarize time points to be distinct, and take latest point for each.\ntmp = np.unique(Ns_data['indexT'].values)\nnt = len(tmp)\n\n## Extract the latest row data which correspond to all disticnt time points. \nrowid = []\nfor i in range(nt):\n  a = Ns_data[Ns_data['indexT'] == tmp[i]]    \n  k = a.shape[0]\n  # Extract the last row number\n  rowid = rowid + [a['rownumber'].values[k-1]]\n    \n## Take subset of NS_data\nNs_data2 = Ns_data.iloc[rowid]\n\n## Left Join NewsData into Market Data... it creates Joined_Data\nJoined_Data = pd.merge(Mk_data, Ns_data2, left_on='index', right_on='indexT', how='left')\nJoined_Data[['index','returnsOpenNextMktres10']]\n\n## Now, Define new binary variable Y, which will be our response variable \ntmp = Joined_Data['returnsOpenNextMktres10']\nN = len(tmp)\nY = np.zeros(N)\nfor obs in range(N):\n  if tmp[obs] >= 0:\n    # Y becomes 1 if the return is positive\n    Y[obs] = 1\n  else:  \n    # Y becomes -1 if the return is  negative\n    Y[obs] = -1\nY = list(Y)    \n\n## Include Y into my dataframe\nJoined_Data['Y'] = list(Y)    \n\n## Now, we can check the dimension of the Joined_Data is (24980, 42)\nJoined_Data.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abeb4b1e31bf53ea74f1789f41d2ea5846d83f80"},"cell_type":"code","source":"Joined_Data['sentimentProportion'] = Joined_Data['sentimentWordCount'] / Joined_Data['wordCount']\n\n# change following column into category: 'takeSequence'\ntmp = Joined_Data['takeSequence']\nN = len(tmp)\nY = np.zeros(N)\nfor obs in range(N):\n  if tmp[obs] == 1:\n    Y[obs] = 1\n  else:  \n    Y[obs] = 0\nY = list(Y)\nJoined_Data['takeSequency'] = list(Y)\n\n# change following columns into category: 'marketCommentary'\ntmp = Joined_Data['marketCommentary']\nN = len(tmp)\nY = np.zeros(N)\nfor obs in range(N):\n  if tmp[obs] == 'FALSE':\n    Y[obs] = 0\n  else:  \n    Y[obs] = 1\nY = list(Y)\nJoined_Data['marketCommentary'] = list(Y)\n\n# change following columns into category: 'sentimentClass'\ntmp = Joined_Data['sentimentClass']\nN = len(tmp)\nY1 = np.zeros(N)\nY2 = np.zeros(N)\nfor obs in range(N):\n  if tmp[obs] == 1:\n    Y1[obs] = 1\n    Y2[obs] = 0\n  elif tmp[obs] == 0:\n    Y1[obs] = 0\n    Y2[obs] = 0\n  else:  \n    Y1[obs] = 0\n    Y2[obs] = 1\nY1 = list(Y1)\nY2 = list(Y2)\nJoined_Data['sentimentClassPositive'] = list(Y1)\nJoined_Data['sentimentClassNegative'] = list(Y2)\n\nJoined_Data2 = Joined_Data.drop(['sentimentClass','provider','returnsOpenNextMktres10', 'indexT', 'time_x','rownumber','assetCode', 'time_y','sourceTimestamp','firstCreated','sourceId', 'headline', 'subjects', 'audiences', 'bodySize', 'headlineTag', 'sentenceCount', 'wordCount', 'assetCodes', 'assetName', 'firstMentionSentence', 'sentimentNeutral', 'sentimentWordCount', 'noveltyCount12H', 'volumeCounts12H'], axis = 1)\n\n# divide into two groups based on 'index'\ntrain_data = pd.DataFrame()\ntest_data = pd.DataFrame()\nN = len(Joined_Data2)\nfor obs in range(N):\n    if Joined_Data2['index'][obs][0:7] < '2016-06':\n        train_data = pd.concat([train_data, Joined_Data2[obs:obs+1]], ignore_index=True)\n    else:\n        test_data = pd.concat([test_data, Joined_Data2[obs:obs+1]], ignore_index=True)\ntrain_data = train_data.drop(['index'], axis = 1)\ntest_data = test_data.drop(['index'], axis = 1)\n\ntrain_data.shape\ntest_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"218ea5642e4bd791d811c367734bac50c3a66512"},"cell_type":"code","source":"# individual part\n\n# fill NAs with zero + 'noNews' column\nN = len(train_data)\nM = len(test_data)\nC = train_data.columns\nD = test_data.columns\n\nY1 = np.zeros(N)\nfor obs in range(N):\n    if train_data['takeSequence'].isna()[obs]:\n        Y1[obs] = 1       \n    else:\n        Y1[obs] = 0\nfor i in C:\n    train_data[i] = train_data[i].fillna(0)\nY1 = list(Y1)\ntrain_data['noNews'] = list(Y1)\n\nY1 = np.zeros(M)\nfor obs in range(M):\n    if test_data['takeSequence'].isna()[obs]:\n        Y1[obs] = 1\n    else:\n        Y1[obs] = 0\nfor i in D:\n    test_data[i] = test_data[i].fillna(0) \nY1 = list(Y1)\ntest_data['noNews'] = list(Y1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aed1d2ae1c4ba37556d820b5176e8f823b0aa712"},"cell_type":"code","source":"# fit svm w/ 'noNews' column\n\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nX_train = train_data.loc[:, train_data.columns != 'Y'].values\nX_test = test_data.loc[:, test_data.columns != 'Y'].values\nX_train = np.array(X_train)\nX_test = np.array(X_test)\n\nY_train = train_data['Y']\nY_test = test_data['Y']\nY_train = np.array(Y_train)\nY_test = np.array(Y_test)\n\n# Create SVM classification object \nmodel = svm.SVC(kernel='rbf', gamma = 'auto') \n\n# there is various option associated with it, like changing kernel, gamma and C value.\nmodel.fit(X_train, Y_train)\nY_predict = model.predict(X_test)\nprint(accuracy_score(Y_test, Y_predict))\nconfusion_matrix(Y_test, Y_predict)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3879267b20a0973c7e8af9dffab4babf323d7a9"},"cell_type":"code","source":"# fit svm w/o 'noNews' column\n\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nX_train = train_data.loc[:, train_data.columns != 'Y']\nX_test = test_data.loc[:, test_data.columns != 'Y']\nX_train = X_train.loc[:, X_train.columns != 'noNews'].values\nX_test = X_test.loc[:, X_test.columns != 'noNews'].values\nX_train = np.array(X_train)\nX_test = np.array(X_test)\n\nY_train = train_data['Y']\nY_test = test_data['Y']\nY_train = np.array(Y_train)\nY_test = np.array(Y_test)\n\n# Create SVM classification object \nmodel = svm.SVC(kernel='rbf', gamma = 'auto') \n\n# there is various option associated with it, like changing kernel, gamma and C value.\nmodel.fit(X_train, Y_train)\nY_predict = model.predict(X_test)\nprint(accuracy_score(Y_test, Y_predict))\nconfusion_matrix(Y_test, Y_predict)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# fit svm w/o NA rows\n\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nN = len(train_data)\nM = len(test_data)\n\ntemplist = list(np.where(train_data['noNews'] == 0)[0])\ntrain_data2 = train_data.iloc[templist]\ntemplist = list(np.where(test_data['noNews'] == 0)[0])\ntest_data2 = test_data.iloc[templist]\n\nX_train = train_data2.loc[:, train_data2.columns != 'Y']\nX_test = test_data2.loc[:, test_data2.columns != 'Y']\nX_train = X_train.loc[:, X_train.columns != 'noNews'].values\nX_test = X_test.loc[:, X_test.columns != 'noNews'].values\nX_train = np.array(X_train)\nX_test = np.array(X_test)\n\nY_train = train_data2['Y']\nY_test = test_data2['Y']\nY_train = np.array(Y_train)\nY_test = np.array(Y_test)\n\n# Create SVM classification object \nmodel = svm.SVC(kernel='rbf', gamma = 'auto') \n\n# there is various option associated with it, like changing kernel, gamma and C value.\nmodel.fit(X_train, Y_train)\nY_predict = model.predict(X_test)\nprint(accuracy_score(Y_test, Y_predict))\nconfusion_matrix(Y_test, Y_predict)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}