{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c01175f4-5ab4-1071-c9f1-419bbd4887f9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3765b8ce-b464-5194-4a66-9a529597fa6f"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a6221de4-ca3d-1973-b682-286a0abfdd1a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import model_selection, preprocessing\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn import metrics\n",
        "\n",
        "train_df = pd.read_csv(\"../input/train.csv\")\n",
        "test_df = pd.read_csv(\"../input/test.csv\")\n",
        "print(\"train:\", train_df.shape)\n",
        "print(\"test:\" ,test_df.shape)\n",
        "\n",
        "                                    #correlation matrix#\n",
        "def corr_plot2(dataframe2, top_n2, target2, fig_x2, fig_y2):\n",
        "    corrmat2 = dataframe2.corr()\n",
        "    top_n2 = top_n2 + 1 \n",
        "    cols2 = corrmat2.nlargest(top_n2, target2)[target2].index\n",
        "    cm2 = np.corrcoef(train_df[cols2].values.T)\n",
        "    f2, ax2 = plt.subplots(figsize=(fig_x2,fig_y2))\n",
        "    sns.set(font_scale=1.25)\n",
        "    cmap2 = plt.cm.viridis\n",
        "    hm2 = sns.heatmap(cm2, cbar=False, annot=True, square=True,cmap = cmap2, fmt='.2f', annot_kws={'size': 10},\t yticklabels=cols2.values, xticklabels=cols2.values)\n",
        "    plt.show()\n",
        "    return cols2,cm2\n",
        "def corr_plot(dataframe, top_n, target, fig_x, fig_y):\n",
        "    corrmat = dataframe.corr()\n",
        "    top_n = top_n + 1 \n",
        "    cols = corrmat.nlargest(top_n, target)[target].index\n",
        "    cm = np.corrcoef(train_df[cols].values.T)\n",
        "    return cols,cm\n",
        "corr_20,cm = corr_plot(train_df, 30, 'price_doc', 10,10) \n",
        "corr_22 = corr_plot2(train_df, 30, 'price_doc', 10,10)  \n",
        "\n",
        "\n",
        "\n",
        "                           #Determine numerical columns and strings colums#\n",
        "dtypes = train_df.iloc[:,2:-1].dtypes\n",
        "string_cols = dtypes[dtypes == object].index\n",
        "num_cols = dtypes[dtypes != object].index\n",
        "\n",
        "\n",
        "                              #description of non_mumerical colones  #\n",
        "def categorical_summary(data, col):\n",
        "    filled_values = sum(data[col].notnull())\n",
        "    missing = sum(data[col].isnull())\n",
        "    cardinality = len(data[col].unique())\n",
        "    print(col.upper())\n",
        "    print('-------------------------------')\n",
        "    print('filled count: %s' %filled_values)\n",
        "    print('missing count: %s' %missing)\n",
        "    print('cardinality: %s' %cardinality)\n",
        "    print(data[col].value_counts())\n",
        "for col in string_cols:\n",
        "    categorical_summary(train_df, col)\n",
        "    \n",
        "    \n",
        "                                  #\"yes\" and \"no\" transformation #\n",
        "yes_no_list = ['culture_objects_top_25', 'thermal_power_plant_raion', 'incineration_raion', 'oil_chemistry_raion',\n",
        "          'radiation_raion', 'railroad_terminal_raion', 'big_market_raion', 'nuclear_reactor_raion',\n",
        "          'detention_facility_raion', 'water_1line', 'big_road1_1line', 'railroad_1line']\n",
        "for col in yes_no_list:\n",
        "    train_df.ix[train_df[col]=='yes', col]=1\n",
        "    train_df.ix[train_df[col]=='no', col]=0\n",
        "    test_df.ix[test_df[col]=='yes', col]=1\n",
        "    test_df.ix[test_df[col]=='no', col]=0\n",
        "    \n",
        "\n",
        "                                   #ecology column transformation#\n",
        "train_df.ix[train_df[\"ecology\"]=='poor', \"ecology\"]=0\n",
        "train_df.ix[train_df[\"ecology\"]=='good', \"ecology\"]=2\n",
        "train_df.ix[train_df[\"ecology\"]=='excellent', \"ecology\"]=3\n",
        "train_df.ix[train_df[\"ecology\"]=='satisfactory', \"ecology\"]=1\n",
        "test_df.ix[test_df[\"ecology\"]=='poor', \"ecology\"]=0\n",
        "test_df.ix[test_df[\"ecology\"]=='good', \"ecology\"]=2\n",
        "test_df.ix[test_df[\"ecology\"]=='excellent', \"ecology\"]=3\n",
        "test_df.ix[test_df[\"ecology\"]=='satisfactory', \"ecology\"]=1\n",
        "\n",
        "\n",
        "                     #determine the ecology's mean without missing data#\n",
        "i = 0;\n",
        "s = 0;\n",
        "for lig in train_df[\"ecology\"]:\n",
        "    if lig != \"no data\" :\n",
        "        i=i+1\n",
        "        s=s+lig\n",
        "mean = s/i   \n",
        "print (mean)\n",
        "i = 0;\n",
        "s = 0;\n",
        "for lig in test_df[\"ecology\"]:\n",
        "    if lig != \"no data\" :\n",
        "        i=i+1\n",
        "        s=s+lig\n",
        "mean = s/i   \n",
        "print (mean)\n",
        "\n",
        "\n",
        "                  #replace the missing data with the mean of ecology#\n",
        "train_df.ix[train_df[\"ecology\"]=='no data', \"ecology\"]=1\n",
        "test_df.ix[test_df[\"ecology\"]=='no data', \"ecology\"]=1\n",
        "\n",
        "\n",
        "                        #transformation of product_type#\n",
        "train_df.ix[train_df[\"product_type\"]=='Investment', \"product_type\"]=1\n",
        "train_df.ix[train_df[\"product_type\"]=='OwnerOccupier', \"product_type\"]=0\n",
        "test_df.ix[test_df[\"product_type\"]=='Investment', \"product_type\"]=1\n",
        "test_df.ix[test_df[\"product_type\"]=='OwnerOccupier', \"product_type\"]=0\n",
        "print (test_df.head)\n",
        "\n",
        "\n",
        "                          #test , train  's transformation# \n",
        "class DataFrameImputer(TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
        "        if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
        "        index=X.columns)\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        return X.fillna(self.fill)\n",
        "train_df = DataFrameImputer().fit_transform(train_df)\n",
        "test_df = DataFrameImputer().fit_transform(test_df)\n",
        "\n",
        "\n",
        "\n",
        "                                  #linear regression#\n",
        "y = train_df.price_doc\n",
        "train_X = train_df.drop([\"price_doc\",\"id\",\"timestamp\",\"sub_area\"],axis=1)\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(train_X, y)\n",
        "print(linreg.intercept_)\n",
        "print(linreg.coef_)\n",
        "test_X = test_df.drop([\"id\",\"timestamp\",\"sub_area\"],axis=1)\n",
        "y_pred = linreg.predict(test_X)\n",
        "print (y_pred)\n",
        "print (y_pred.shape)\n",
        "\n",
        "\n",
        "                                       #submission#\n",
        "submission_df = pd.DataFrame({'id':test_df.id, 'price_doc':y_pred}).set_index('id').to_csv('submission.csv')\n",
        "cwd = os.getcwd()\n",
        "#print (cwd)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}