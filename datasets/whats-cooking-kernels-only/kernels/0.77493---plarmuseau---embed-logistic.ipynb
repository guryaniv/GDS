{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import os\nimport gensim\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import PassiveAggressiveClassifier,Perceptron,SGDClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(os.listdir(\"../input\"))\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ceb8a1a50d95557c6c7ac9eae7c6c11596fa88a9","collapsed":true},"cell_type":"code","source":"data = pd.read_json('../input/train.json')\ntest = pd.read_json('../input/test.json')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"print('Training data shape: {}'.format(data.shape))\nprint('Test data shape: {}'.format(test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"eee7191cb9648164fb904c09596565deaaf6792c"},"cell_type":"code","source":"# Target variable \ntarget = data.cuisine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"99d10a97a371070b90dcd4f0b3dd58d725786ff2"},"cell_type":"code","source":"data['ingredient_count'] = data.ingredients.apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"390ef99096c0f6b6fde621b0249d69ecc3cae584"},"cell_type":"code","source":"def flatten_lists(lst):\n    \"\"\"Remove nested lists.\"\"\"\n    return [item for sublist in lst for item in sublist]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e1b1fedaaacba0d6f864e8a6d16ae96fa7b542a","collapsed":true},"cell_type":"code","source":"f = plt.figure(figsize=(14,8))\ngs = gridspec.GridSpec(2, 2)\n\nax1 = plt.subplot(gs[0, :])\ndata.ingredient_count.value_counts().hist(ax=ax1)\nax1.set_title('Recipe richness', fontsize=12)\n\nax2 = plt.subplot(gs[1, 0])\npd.Series(flatten_lists(list(data['ingredients']))).value_counts()[:20].plot(kind='barh', ax=ax2)\nax2.set_title('Most popular ingredients', fontsize=12)\n\nax3 = plt.subplot(gs[1, 1])\ndata.groupby('cuisine').mean()['ingredient_count'].sort_values(ascending=False).plot(kind='barh', ax=ax3)\nax3.set_title('Average number of ingredients in cuisines', fontsize=12)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9262693cc3bf753ee0cf9c8b6dbd73afa42b390d"},"cell_type":"code","source":"# Feed a word2vec with the ingredients\nw2v = gensim.models.Word2Vec(list(data.append(test).ingredients), size=1000, window=10, min_count=1, iter=20)  #cont min should be 1 since you want all unique words to embed, size should be as large as pissblie","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1578eed21f98b6e12861689fc5f2c8e1cf9ddbca"},"cell_type":"markdown","source":"Let's try some examples"},{"metadata":{"trusted":true,"_uuid":"523c6c1dc9a999817f40738ea6d54d932f5f47e5","collapsed":true},"cell_type":"code","source":"len(w2v.wv['onions'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0d5f99fe063a75294a8ebdb88e142f373582ded","collapsed":true},"cell_type":"code","source":"w2v.most_similar(['green onions'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42a13d48ab5efe4b829086e3ca6631bcdbd9f514","collapsed":true},"cell_type":"code","source":"w2v.most_similar(['kosher salt'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8a928ea00a08dbd276e653dd2578b6b03c3ff91b"},"cell_type":"code","source":"def document_vector(doc):\n    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n    doc = [word for word in doc if word in w2v.wv.vocab]\n    return np.mean(w2v[doc], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b8d1e09c13271f9f2386f82170e88da153383cc9"},"cell_type":"code","source":"data['doc_vector'] = data.ingredients.apply(document_vector)\ntest['doc_vector'] = test.ingredients.apply(document_vector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f2c0c277bd45fde4f35261fe0262bcd3fba17747"},"cell_type":"code","source":"lb = LabelEncoder()\ny = lb.fit_transform(target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68d8f66b5a7e04efed2940374e08dc056342c101","collapsed":true},"cell_type":"code","source":"print (\"TF-IDF on text data ... \")\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\ntfidf = CountVectorizer(ngram_range=(1,1)) #binary=True)\nprint(tfidf)\ndata['ingredients']= data['ingredients'].map(\", \".join)\ntest['ingredients']= test['ingredients'].map(\", \".join)\ntfidf.fit_transform(data['ingredients'].append(test['ingredients'])).astype(np.float32)\n\nX =  tfidf.transform(data['ingredients']).astype(np.float32)\nX_test = tfidf.transform(test['ingredients']).astype(np.float32)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b285a219ecf0bf0e1fbeae56aa372acca123865","collapsed":true},"cell_type":"code","source":"\nXv = list(data['doc_vector'])\nX_testv = list(test['doc_vector'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c385028a30b7d5666c4452ac76251b5ee8cfa51","collapsed":true},"cell_type":"code","source":"from sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import PassiveAggressiveClassifier,Perceptron,SGDClassifier\n\ntemp=np.concatenate( (X.todense(), Xv ), axis=1 )\nU1=pd.DataFrame( temp , index=data.index )\nprint(X.shape,U1.shape )\nclassifier = SGDClassifier(max_iter=20,n_jobs=4,fit_intercept=True)  #0.77\n\nmodel = OneVsRestClassifier(classifier)\nmodel.fit(U1,y)\nprint( (model.predict(U1)==y).mean() ) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82226a2d44a1bbd44745b1503134317e8e7e231b","collapsed":true},"cell_type":"code","source":"print( (model.predict(U1)==y).mean() ) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00a87854795f76a141e09658e5288123db189776","collapsed":true},"cell_type":"code","source":"temp=np.concatenate( (X_test.todense(), X_testv ), axis=1 )\nU2=pd.DataFrame( temp , index=test.index )\n\n# Predictions \nprint (\"Predict on test data ... \")\ny_test = model.predict(U2)\ny_pred = lb.inverse_transform(y_test)\n\n# Submission\nprint (\"Generate Submission File ... \")\ntest_id = test.id\nsub = pd.DataFrame({'id': test_id, 'cuisine': y_pred}, columns=['id', 'cuisine'])\nsub.to_csv('svm_output.csv', index=False)\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cdaeb53c50db435ad4230f30e8d799357eb83e88"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}