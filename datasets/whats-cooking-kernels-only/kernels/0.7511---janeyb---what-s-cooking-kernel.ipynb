{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #plotting\nimport seaborn as sns #plotting\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Loading the data\n\ntrain_df = pd.read_json('../input/train.json')\ntest_df = pd.read_json('../input/test.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ffc9ba1702567b9ca7aa259fa5026aabced0a22","scrolled":true},"cell_type":"code","source":"# Exploration\n\nprint ('Exploring the training data')\nprint (train_df.head(5))\nprint (train_df.shape)\nprint (train_df.columns)\nprint (train_df.info())\n\nprint ('-----------------------------------------------------------------------------------------------')\nprint ('Exploring the test data')\nprint (test_df.head(5))\nprint (test_df.shape)\nprint (test_df.info())\n\nprint ('-----------------------------------------------------------------------------------------------')\nprint ('How many cuisine types are there? How common are they in the data set?')\n\nunique_cuisine_types = train_df['cuisine'].nunique()\nprint ('There are %d unique cuisine types'  %  (unique_cuisine_types))\n\nfreq_cuisines = train_df['cuisine'].value_counts()\nplt.figure(figsize=(20,6))\nsns.barplot(x= freq_cuisines.index, y= freq_cuisines.values, color = 'b')\nplt.xlabel('type of cuisine')\nplt.ylabel('# of recipes')\nplt.title('# of recipes per type of cuisine in training data')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3bdd7280e3f38d8e4560f2fdde7d75408ac2456"},"cell_type":"markdown","source":"From briefly looking at the training and test data we can see that:\n1. The 'ingredients' column has a list of ingredients delimited by ','. We will have to deal with this when we tokenize the data. \n2. We can also spot  non-important words such as 'of' (in 'cream of tartar' which could be removed as they will not likely be linked to any particular cuisine\n3. There is a trade-off in tokenizing whole phrases, or individual words. Let's try individual words first..\n\nThere are also 20 cuisine types, with italian being the most popular, and brazilian being the least popular. \n\nNow let's look at how many ingredients we might be working with..."},{"metadata":{"trusted":true,"_uuid":"50439aa069351b4687988a2f7305267ac94f6959"},"cell_type":"code","source":"# Exploration continued...\n\n# 1. Counting the number of ingredients in each recipe list\nnumber_of_ingredients = []\nfor i in range(len(train_df['ingredients'])):\n    number_of_ingredients.append(len(train_df['ingredients'][i]))\n\ntrain_df['number_of_ingredients'] = number_of_ingredients\n\nprint ('The average number of ingredients is %d' % np.average(number_of_ingredients))\nprint ('The max number of ingredients is %d' % np.max(number_of_ingredients))\nprint ('The min number of ingredients is %d' % np.min(number_of_ingredients))\n\n# What do the ranges of # of ingredients look like for the different cuisines?\n\n# Getting the min and max values of the boxplots to order it by size of range\nlowIQ = train_df.groupby(['cuisine']).quantile(0.25)['number_of_ingredients']\nhighIQ = train_df.groupby(['cuisine']).quantile(0.75)['number_of_ingredients']\nIQR = highIQ - lowIQ\nminvalue = train_df.groupby(['cuisine']).min()['number_of_ingredients']\nmaxvalue = highIQ + (IQR * 1.5)\noverall_range = maxvalue - minvalue\nordered_cuisines = (overall_range.sort_values(ascending = False).index)\n\nplt.figure(figsize=(20,6))\nsns.boxplot(x=\"cuisine\", y=\"number_of_ingredients\",data= train_df, width = 0.7, color = 'b', order = ordered_cuisines)\nplt.xlabel('type of cuisine')\nplt.ylabel('# of ingredients')\nplt.title('spread of # of ingredients by type of cuisine, ordered by range in # of ingredients')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a35019a13fae1a03e9fa49168c681c349cbe8234"},"cell_type":"markdown","source":"The average number of ingredients is 10 but there is a huge range in all cuisine types, ranging from 65 to 1.\n\nAs you would expect... the British range excluding outliers has a maximum value which is relatively low whilst Vietnamese and Indian cuisines appear to use many more ingredients. \n\n.... Now let's turn the data into something we can work with for predictions and create our test and training data sets"},{"metadata":{"trusted":true,"_uuid":"9fbf45a7f51b435c32f72af22f11e3411a824314"},"cell_type":"code","source":"# Turn the ingredients into a single string so we can process them as individual words, as important words may be more easily recognised as common between \n# recipes.\ntrain_df['seperated_ingredients'] = train_df['ingredients'].apply(','.join)\ntest_df['seperated_ingredients'] = test_df['ingredients'].apply(','.join)\n\n# We also need to turn the cuisines into numbers for our neural networks later...\ntrain_df['cuisine'] = pd.Categorical(train_df['cuisine'])\n\n#To capture the category codes in a column for one-hot-encoding later (using keras.utils.to_categorical)\ntrain_df['cuisine_code'] = train_df.cuisine.cat.codes\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7cbfc39896c6ba6daddea4b21dd3704321ede5e"},"cell_type":"code","source":"#Splitting the training data\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train_df['seperated_ingredients'], train_df['cuisine_code'], test_size = 0.30, random_state = 102)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4186d49dbf8a05a0e64c40bf0f9d8c9cdd85bf0","trusted":true},"cell_type":"markdown","source":"To predict the cuisine types for the test data, I will use both CountVectorizer.\n\nCountVectorizer simply counts the number of text tokens and puts them in a matrix. \n\nThere will also be several conditions within the vectorization steps: \n1) Lemmatizing the words so that similar words can be recognised e.g. olives and olive\n2) Removing stopwords such as 'the' and 'and' which will likely not be linked to any cuisine type and will contribute to noise\n3) Tokenizing on words only with a token pattern, ignoring any numbers which again will likely just be noise. \n4) Ensuring all words are lowercase as capslock can interfere with matching. \n\n"},{"metadata":{"trusted":true,"_uuid":"338cee23708101fa5d2558c743954d62c15d8957"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom nltk import word_tokenize          \nfrom nltk.stem import WordNetLemmatizer \nclass LemmaTokenizer(object):\n       def __init__(self):\n            self.wnl = WordNetLemmatizer()\n       def __call__(self, doc):\n            return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\npattern = r\"[A-Za-z]\"\nfrom keras.utils import np_utils   \n\nvec = CountVectorizer(tokenizer=LemmaTokenizer(), stop_words = 'english', lowercase = True, token_pattern = pattern, ngram_range = (1,1))\ntraining_predictors = vec.fit_transform(train_df['seperated_ingredients'])\nn_cols = training_predictors.shape[1]\n# print (training_predictors) - need to find out what word id 9 is as it appears a lot in the first row..\ntraining_targets = np_utils.to_categorical(train_df['cuisine_code']) #y_train needs to be a list of numbers corresponding to cuisines\n#print (training_targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e20216943c61cf773457a93156092ff63af4869"},"cell_type":"code","source":"#Using neural networks\n\n#Imports\nimport keras\nfrom keras.layers import Dense , Dropout#\nfrom keras.models import Sequential #\nfrom keras.callbacks import EarlyStopping\nearly_stopping_monitor = EarlyStopping(patience = 3)\n\n# Set up the model: model\ndef get_model(dropout = 0.4):\n    model = Sequential()\n    # Add the first layer\n    model.add(Dense(1000, activation = 'relu', input_shape=(n_cols,)))\n    model.add(Dropout(dropout))\n    # Add a second layer\n    model.add(Dense(1000, activation = 'relu'))\n    model.add(Dropout(dropout))\n    # Add a third layer\n    model.add(Dense(1000, activation = 'softmax'))\n    model.add(Dropout(dropout))\n    # Add the output layer\n    model.add(Dense(20))\n    # Compile the model\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n    model.summary()\n    return model\n\nmodel_nn = get_model()\n# Fit the model\nmodel_nn.fit(training_predictors, training_targets,batch_size=300, epochs=10, validation_split = 0.3, callbacks = [early_stopping_monitor])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cf3e98bc091fc8443aae2ed2a54e688f5945e4c"},"cell_type":"code","source":"# Best score so far is: 0.74030 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30162113031a11b8537a61af10edfa8d2e93e886","scrolled":true},"cell_type":"code","source":"# Writing the test submission file \nsubmission = pl.predict(test_df['seperated_ingredients'])\n\nsubmission_file = pd.DataFrame(data = submission, columns = ['cuisine'], index = test_df['id'])\n\nsubmission_file.reset_index(level=0, inplace=True)\n\nprint (submission_file.head(5))\nsubmission_file.to_csv('submission4.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}