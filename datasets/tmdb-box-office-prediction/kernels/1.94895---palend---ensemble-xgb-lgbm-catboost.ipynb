{"cells":[{"metadata":{"_uuid":"578320fad012a00fc8231b6e0a7210f1b1975aa6"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"57432882dee312f49a8635e5ca10dd424af3ebcb"},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns \nimport ast\nfrom tqdm import tqdm\nfrom datetime import datetime\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85e47d6d91209014e7a3e897e4290793054bf2fb"},"cell_type":"code","source":"def prepare(df):\n    global json_cols\n    global train_dict\n    \n    df['rating'] = df['rating'].fillna(1.5)\n    df['totalVotes'] = df['totalVotes'].fillna(6)\n    df['weightedRating'] = ( df['rating']*df['totalVotes'] + 6.367 * 1000 ) / ( df['totalVotes'] + 1000 )\n\n    df[['release_month','release_day','release_year']]=df['release_date'].str.split('/',expand=True).replace(np.nan, 0).astype(int)\n    df['release_year'] = df['release_year']\n    df.loc[ (df['release_year'] <= 18) & (df['release_year'] < 100), \"release_year\"] += 2000\n    df.loc[ (df['release_year'] > 18)  & (df['release_year'] < 100), \"release_year\"] += 1900\n    \n    releaseDate = pd.to_datetime(df['release_date']) \n    df['release_dayofweek'] = releaseDate.dt.dayofweek \n    df['release_quarter'] = releaseDate.dt.quarter     \n\n    df['_budget_runtime_ratio'] = df['budget']/df['runtime'] \n    df['_budget_popularity_ratio'] = df['budget']/df['popularity']\n    df['_budget_year_ratio'] = df['budget']/(df['release_year']*df['release_year'])\n    df['_releaseYear_popularity_ratio'] = df['release_year']/df['popularity']\n    df['_releaseYear_popularity_ratio2'] = df['popularity']/df['release_year']\n\n    df['_popularity_totalVotes_ratio'] = df['totalVotes']/df['popularity']\n    df['_rating_popularity_ratio'] = df['rating']/df['popularity']\n    df['_rating_totalVotes_ratio'] = df['totalVotes']/df['rating']\n    df['_totalVotes_releaseYear_ratio'] = df['totalVotes']/df['release_year']\n    df['_budget_rating_ratio'] = df['budget']/df['rating']\n    df['_runtime_rating_ratio'] = df['runtime']/df['rating']\n    df['_budget_totalVotes_ratio'] = df['budget']/df['totalVotes']\n    \n    df['has_homepage'] = 0\n    df.loc[pd.isnull(df['homepage']) ,\"has_homepage\"] = 1\n    \n    df['isbelongs_to_collectionNA'] = 0\n    df.loc[pd.isnull(df['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 1\n    \n    df['isTaglineNA'] = 0\n    df.loc[df['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n\n    df['isOriginalLanguageEng'] = 0 \n    df.loc[ df['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\n    \n    df['isTitleDifferent'] = 1\n    df.loc[ df['original_title'] == df['title'] ,\"isTitleDifferent\"] = 0 \n\n    df['isMovieReleased'] = 1\n    df.loc[ df['status'] != \"Released\" ,\"isMovieReleased\"] = 0 \n\n    # get collection id\n    df['collection_id'] = df['belongs_to_collection'].apply(lambda x : np.nan if len(x)==0 else x[0]['id'])\n    \n    df['original_title_letter_count'] = df['original_title'].str.len() \n    df['original_title_word_count'] = df['original_title'].str.split().str.len() \n\n\n    df['title_word_count'] = df['title'].str.split().str.len()\n    df['overview_word_count'] = df['overview'].str.split().str.len()\n    df['tagline_word_count'] = df['tagline'].str.split().str.len()\n    \n    df['production_countries_count'] = df['production_countries'].apply(lambda x : len(x))\n    df['production_companies_count'] = df['production_companies'].apply(lambda x : len(x))\n    df['cast_count'] = df['cast'].apply(lambda x : len(x))\n    df['crew_count'] = df['cast'].apply(lambda x : len(x))\n\n    df['meanruntimeByYear'] = df.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\n    df['meanPopularityByYear'] = df.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\n    df['meanBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('mean')\n    df['meantotalVotesByYear'] = df.groupby(\"release_year\")[\"totalVotes\"].aggregate('mean')\n    df['meanTotalVotesByRating'] = df.groupby(\"rating\")[\"totalVotes\"].aggregate('mean')\n\n    for col in ['genres', 'production_countries', 'spoken_languages', 'production_companies'] :\n        df[col] = df[col].map(lambda x: sorted(list(set([n if n in train_dict[col] else col+'_etc' for n in [d['name'] for d in x]])))).map(lambda x: ','.join(map(str, x)))\n        temp = df[col].str.get_dummies(sep=',')\n        df = pd.concat([df, temp], axis=1, sort=False)\n    df.drop(['genres_etc'], axis = 1, inplace = True)\n    \n    df = df.drop(['id', 'revenue','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline', 'collection_id'\n    ],axis=1)\n    \n    df.fillna(value=0.0, inplace = True) \n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2c4e93105fac0ca2c48d0b1d4ac7cac1dce74dbd"},"cell_type":"code","source":"train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\ntrain['revenue'] = np.log1p(train['revenue'])\ny = train['revenue'].values\n\ntest = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')\ntest['revenue'] = np.nan\n\n# features from https://www.kaggle.com/kamalchhirang/eda-simple-feature-engineering-external-data\ntrain = pd.merge(train, pd.read_csv('../input/tmdb-box-office-movies-rating-total-votes/trainRatingTotalVotes.csv'), how='left', on=['imdb_id'])\ntest = pd.merge(test, pd.read_csv('../input/tmdb-box-office-movies-rating-total-votes/testRatingTotalVotes.csv'), how='left', on=['imdb_id'])\n\njson_cols = ['genres', 'production_companies', 'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\ndef get_dictionary(s):\n    try:\n        d = eval(s)\n    except:\n        d = {}\n    return d\n\nfor col in tqdm(json_cols + ['belongs_to_collection']) :\n    train[col] = train[col].apply(lambda x : get_dictionary(x))\n    test[col] = test[col].apply(lambda x : get_dictionary(x))\n\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21df291d86126c44981d46f9088fcfcbe2ed6306"},"cell_type":"code","source":"# parse json data and build category dictionary\ndef get_json_dict(df) :\n    global json_cols\n    result = dict()\n    for e_col in json_cols :\n        d = dict()\n        rows = df[e_col].values\n        for row in rows :\n            if row is None : continue\n            for i in row :\n                if i['name'] not in d :\n                    d[i['name']] = 0\n                d[i['name']] += 1\n        result[e_col] = d\n    return result\n\ntrain_dict = get_json_dict(train)\ntest_dict = get_json_dict(test)\n\n# remove cateogry with bias and low frequency\nfor col in json_cols :\n    \n    remove = []\n    train_id = set(list(train_dict[col].keys()))\n    test_id = set(list(test_dict[col].keys()))   \n    \n    remove += list(train_id - test_id) + list(test_id - train_id)\n    for i in train_id.union(test_id) - set(remove) :\n        if train_dict[col][i] < 10 or i == '' :\n            remove += [i]\n            \n    for i in remove :\n        if i in train_dict[col] :\n            del train_dict[col][i]\n        if i in test_dict[col] :\n            del test_dict[col][i]\n            \n    print(col, 'size :', len(train_id.union(test_id)), '->', len(train_dict[col]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"632541eeb1c317a45f78885ba8134e7c0e30a3af"},"cell_type":"code","source":"# prepare data\nall_data = prepare(pd.concat([train, test]).reset_index(drop = True))\ntrain = all_data.loc[:train.shape[0] - 1,:]\ntest = all_data.loc[train.shape[0]:,:]                           \nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eac34f1553d63edc351d72e923e41b10735f28e3"},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\nrandom_seed = 2019\nk = 5\nfold = list(KFold(k, shuffle = True, random_state = random_seed).split(train))\nnp.random.seed(random_seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04077f5e04a2f3f925afcda1b8190704ec697cbe"},"cell_type":"code","source":"import xgboost as xgb\n\ndef xgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n    \n    params = {'objective': 'reg:linear', \n              'eta': 0.01, \n              'max_depth': 6, \n              'subsample': 0.7, \n              'colsample_bytree': 0.8,  \n              'eval_metric': 'rmse', \n              'seed': random_seed, \n              'silent': True,\n    }\n    \n    record = dict()\n    model = xgb.train(params\n                      , xgb.DMatrix(trn_x, trn_y)\n                      , 10000\n                      , [(xgb.DMatrix(trn_x, trn_y), 'train'), (xgb.DMatrix(val_x, val_y), 'valid')]\n                      , verbose_eval=verbose\n                      , early_stopping_rounds=200\n                      , callbacks = [xgb.callback.record_evaluation(record)])\n    best_idx = np.argmin(np.array(record['valid']['rmse']))\n\n    val_pred = model.predict(xgb.DMatrix(val_x), ntree_limit=model.best_ntree_limit)\n    test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n\n    return {'val':val_pred, 'test':test_pred, 'error':record['valid']['rmse'][best_idx], 'importance':[i for k, i in model.get_score().items()]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5f64549667b1db29b0e19f49d65962b0353f2c5"},"cell_type":"code","source":"import lightgbm as lgb\n\ndef lgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n\n    params = {'objective':'regression',\n         'num_leaves' : 40,\n         'min_data_in_leaf' : 20,\n         'max_depth' : 4,\n         'learning_rate': 0.01,\n         \"feature_fraction\": 0.8,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.8,\n         \"bagging_seed\": random_seed,\n         \"metric\": 'rmse',\n         \"random_state\" : random_seed,\n         \"verbosity\": -1}\n\n    record = dict()\n    model = lgb.train(params\n                      , lgb.Dataset(trn_x, trn_y)\n                      , num_boost_round = 10000\n                      , valid_sets = [lgb.Dataset(val_x, val_y)]\n                      , verbose_eval = verbose\n                      , early_stopping_rounds = 200\n                      , callbacks = [lgb.record_evaluation(record)]\n                     )\n    best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n\n    val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n    test_pred = model.predict(test, num_iteration = model.best_iteration)\n    \n    return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fb7888d85656a52f081327db5d734db83d71fde"},"cell_type":"code","source":"from catboost import CatBoostRegressor\n\ndef cat_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n    \n    model = CatBoostRegressor(iterations=10000,\n                                 learning_rate=0.01,\n                                 depth=5,\n                                 eval_metric='RMSE',\n                                 colsample_bylevel=0.7,\n                                 random_seed = random_seed,\n                                 bagging_temperature = 0.2,\n                                 metric_period = None,\n                                 early_stopping_rounds=200\n                                )\n    model.fit(trn_x, trn_y,\n                 eval_set=(val_x, val_y),\n                 use_best_model=True,\n                 verbose=False)\n    \n    val_pred = model.predict(val_x)\n    test_pred = model.predict(test)\n    \n    return {'val':val_pred, 'test':test_pred, 'error':model.get_best_score()['validation_0']['RMSE'], 'importance':model.get_feature_importance()}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a974284e8e9a7491353eb8a2b5ba72bb7034ae59","scrolled":false},"cell_type":"code","source":"# run training & prediction\nresult_dict = dict()\nval_pred = np.zeros(train.shape[0])\ntest_pred = np.zeros(test.shape[0])\nfinal_err = 0\nverbose = False\n\nfor i, (trn, val) in enumerate(fold) :\n    print(i+1, \"fold.    RMSE\")\n    \n    trn_x = train.loc[trn, :]\n    trn_y = y[trn]\n    val_x = train.loc[val, :]\n    val_y = y[val]\n    \n    fold_val_pred = []\n    fold_test_pred = []\n    fold_err = []\n    \n    #\"\"\" xgboost\n    start = datetime.now()\n    result = xgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n    fold_val_pred.append(result['val'])\n    fold_test_pred.append(result['test'])\n    fold_err.append(result['error'])\n    print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n    #\"\"\"\n    \n    #\"\"\" lightgbm\n    start = datetime.now()\n    result = lgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n    fold_val_pred.append(result['val'])\n    fold_test_pred.append(result['test'])\n    fold_err.append(result['error'])\n    print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n    #\"\"\"\n    \n    #\"\"\" catboost model\n    start = datetime.now()\n    result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n    fold_val_pred.append(result['val'])\n    fold_test_pred.append(result['test'])\n    fold_err.append(result['error'])\n    print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n    #\"\"\"\n    \n    # mix result of multiple models\n    val_pred[val] += np.mean(np.array(fold_val_pred), axis = 0)\n    test_pred += np.mean(np.array(fold_test_pred), axis = 0) / k\n    final_err += (sum(fold_err) / len(fold_err)) / k\n    \n    print(\"---------------------------\")\n    print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) / len(fold_err)))\n    print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n    \n    print('')\n    \nprint(\"fianl avg   err.\", final_err)\nprint(\"fianl blend err.\", np.sqrt(np.mean((val_pred - y)**2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f73e2a46bcb6bd361eac1b8a088974a58db72a67"},"cell_type":"code","source":"submission = pd.read_csv('../input/tmdb-box-office-prediction/sample_submission.csv')\nsubmission['revenue'] = np.expm1(test_pred)\nsubmission.to_csv(\"submission.csv\", index=False)\nplt.show()\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}