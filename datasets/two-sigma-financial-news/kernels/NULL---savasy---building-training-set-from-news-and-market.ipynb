{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nimport numpy as np\nenv = twosigmanews.make_env()\n(market_train_df, news_train_df) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48cd757945a148a271e423e3a9e4b95336d7faf0"},"cell_type":"code","source":"# Select small portion of data for the matter of time complexity, ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db21a09651b50ccd53a818827af414fbb77a3776"},"cell_type":"code","source":"start='2016-09-09'\nM=market_train_df.loc[market_train_df['time']>start]\nN=news_train_df.loc[news_train_df['time']>start]\nM=M.reset_index(drop=True)\nN=N.reset_index(drop=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2f9cdcfed4e6f4277a1012cbf3f9dd12e296f9f"},"cell_type":"code","source":"# I need to parse time to get only YYYY-MM-DD\n# where the term zman means date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0602d38ef1c1838c412b3b19edab3817f2d0bad2"},"cell_type":"code","source":"M['zaman']=M.apply(lambda row: str(row[\"time\"]).split()[0],axis=1)\nN['zaman']=N.apply(lambda row: str(row[\"time\"]).split()[0],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d830c6e191b5b6f9bd5bede503541721f53fa86b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50f61b2d265fa68f292c3a1645556ff6ff7fe089"},"cell_type":"markdown","source":"# Creating dummy variables from news annotations and contents\n## First Training Vectorizer to build dummy variables from textual information"},{"metadata":{"trusted":true,"_uuid":"6dca8418f87dfcdb3b0155fe20684bdd70133131"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\nsize=0\n#headlineTag vectorizer Training\nheadlineT= [s.replace(\" \",\"_\").strip() for s in N[\"headlineTag\"]]\nheadlineTVectorizer = CountVectorizer(token_pattern=r'[a-zA-Z0-9\\-\\.:_]+')\nheadlineTVectorizer.fit(headlineT)\nq=len(headlineTVectorizer.vocabulary_)\nsize=size+q\nprint(\"headline Tag\",q)\n\n# provider vectorizer Training\nprovider=list(N[\"provider\"])\nproviderVectorizer=CountVectorizer(token_pattern=r'[a-zA-Z0-9\\-\\.:_]+')\nproviderVectorizer.fit(provider)\nq=len(providerVectorizer.vocabulary_)\nsize=size+q\nprint(\"Provider\",q)\n\n\n#headline vectorizer\nheadlines= N[\"headline\"]\nheadlineVectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=10000, stop_words='english', ngram_range=(1,3), token_pattern=r'[a-zA-Z0-9\\-\\.:]+')\nheadlineVectorizer.fit(headlines)\nq=len(headlineVectorizer.vocabulary_)\nsize=size+q\nprint(\"Headline\",q)\n\n#subjects vectorizer\nimport re\nss=N['subjects']\nsubjects=[re.sub (\"[{}'',]\" ,\"\",s) for s in ss]\nsset=list(set((\" \".join(subjects)).split()))\nsubjectVectorizer = CountVectorizer(token_pattern=r'[a-zA-Z0-9\\-\\.:_]+')\nsubjectVectorizer.fit(sset)\nq=len(subjectVectorizer.vocabulary_)\nsize=size+q\nprint(\"Subjects\",q)\n\nau=N['audiences']\naus=[re.sub (\"[{}'',]\" ,\"\",a) for a in au]\nsaus=list(set((\" \".join(aus)).split()))\nauVectorizer = CountVectorizer(token_pattern=r'[a-zA-Z0-9\\-\\.:_]+')\nauVectorizer.fit(saus)\nq=len(auVectorizer.vocabulary_)\nsize=size+q\nprint(\"Audience\",q)\n\nprint(\"* The total for news is\", size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46edc333109e2c2c58fd2d9205320c579e5635c5"},"cell_type":"markdown","source":"## Create a single vector from a given company and its related news for a specific day"},{"metadata":{"trusted":true,"_uuid":"5189295e45f8bb52334bd2a2b36b0327c059386a"},"cell_type":"code","source":"def buildVec(newsQA, marketQA):\n    #headline Trasformations\n    headlines=\" \".join(list(newsQA[\"headline\"]))\n    headlinesVec=headlineVectorizer.transform([headlines]).todense()\n    # provider\n    prov=\" \".join(list(newsQA[\"provider\"]))\n    provVec=providerVectorizer.transform([prov]).todense()\n    #comment\n    comment=newsQA[\"marketCommentary\"]\n    c=\" \".join(list([str(s) for s in comment]))\n    commentVec= [[c.split().count(\"True\") , c.split().count(\"False\")]]\n    #headlineTag\n    headlineT=\" \".join([s.replace(\" \",\"_\") for s in newsQA[\"headlineTag\"]])\n    headlineTVec=headlineTVectorizer.transform([headlineT]).todense()\n    #audience transformation\n    aud=[re.sub (\"[{}'',]\" ,\"\",s) for s in newsQA[\"audiences\"]]\n    auVec=auVectorizer.transform([\" \".join(aud)]).todense()\n    #subject transformation\n    subjects=[re.sub (\"[{}'',]\" ,\"\",s) for s in newsQA[\"subjects\"]]\n    subjectVec= subjectVectorizer.transform( [\" \".join(subjects)]).todense()\n    #numeric values\n    numvar=[\"urgency\", \"takeSequence\", \"bodySize\", \"companyCount\",\"sentenceCount\",\"wordCount\",\"firstMentionSentence\",\"sentimentClass\",\"sentimentNegative\",\"sentimentNeutral\",\"sentimentPositive\",\"sentimentWordCount\",\"noveltyCount12H\",\"noveltyCount24H\",\"noveltyCount3D\",\"noveltyCount5D\",\"noveltyCount7D\",\"volumeCounts12H\",\"volumeCounts24H\",\"volumeCounts3D\",\"volumeCounts5D\",\"volumeCounts7D\"]\n    numvarMean=newsQA[numvar].mean()\n    numvarMean=np.array(numvarMean)\n    # Concatenation NEws variables\n    newsVec=np.concatenate((headlinesVec, provVec, commentVec,headlineTVec,auVec, subjectVec, [numvarMean]),1)\n    #market vec\n    marketVec=np.array(list(marketQA[4:16]))\n    # all vec\n    allvec= np.concatenate((newsVec,[marketVec]),1)\n    return allvec\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"865003bd54d6dd5ec3cee94c5433b2e06202ade7"},"cell_type":"markdown","source":"# Finally a Function for Building  Training Set"},{"metadata":{"trusted":true,"_uuid":"d238d585fd28c8a08f149cd7d7528721b08c8591"},"cell_type":"code","source":"# train data collection\ndef buildTrainData(market_train_df, news_train_df, limit):\n    X=[]\n    i=0\n    count=0\n    hmnanrow=0\n    for row in market_train_df.itertuples():\n        if not (True in np.isnan(np.array(row[-10:15]))):\n            companyName= row.assetName\n            zaman=row.zaman\n            newsQA=news_train_df[  (news_train_df['assetName']==companyName) & (news_train_df['zaman']==zaman)]\n            newsCount=newsQA.shape[0]\n            count=count+1\n            if (count % 1000 ==0):\n             print(count)\n            if (count% (limit+1)==0):\n             print(count, len(X), hmnanrow)\n             break\n            #if newsCount>0:\n            if True:\n             marketQA=row\n             vecc=buildVec(newsQA, marketQA)\n             vecc2=np.array(vecc)[0]\n             X.append(vecc2)\n    return np.array(X)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f21cb3c7d883488458ad1b862d308dac70a15f5"},"cell_type":"markdown","source":"# NOW we are ready to call the functions\n# I build only first 5K cases for the simplicity, we can extend this range to improve the model performance"},{"metadata":{"trusted":true,"_uuid":"be184cf41e1b99a3911ec1d73a0c9d34ecf05316"},"cell_type":"code","source":"X_train= buildTrainData(M, N,5000)\nX_train[np.isnan(X_train)]=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7698978144b872447cf51e5f2cb60ed09081962f"},"cell_type":"code","source":"# lets traing and measue success as abinary classifications","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8a3640d891d97feb1cf8dd6897c19b896219b99"},"cell_type":"code","source":"lastC=X_train.shape[1]-1\nlastC\nX=X_train[:,:lastC]\ny=X_train[:,lastC]\n\n# Standardize the entire matrix\nfrom sklearn.preprocessing import StandardScaler\nstdsc = StandardScaler()\nX_std = stdsc.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6616c6d06afaf3a234dd36dac728cb10a8af5174"},"cell_type":"code","source":"X_std.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"beaa7c00e56bc2056428f356300cd01620994c28"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d35b8702352f20cf5e1999f456ed2426b24df8d"},"cell_type":"code","source":"# I convert the problem for binary classification, So not he problem is if the target varible is bigger than ZERO or NOT","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21179d065c003bc3b71c35377408cbe3fc9fb41d"},"cell_type":"code","source":"ycat= y>0\nsum(ycat) /ycat.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54ec826ce383cd39a2c62a6e73a4c862443bc1e5"},"cell_type":"code","source":"# I apply Log Reg to model, it must be bigger than 0.5147 (which is  class ratio above)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29f13abe307a6a079695977de0d1cf7adb7b6e84"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n\nclf=LogisticRegression()\nscores = cross_val_score(clf,X_std, ycat, cv=5)\nprint(scores.mean())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26b24ce56176ce08881496cd8c64b209b6658174"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9114e9fa2b7a1daca760a375009ff34f0285809"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}