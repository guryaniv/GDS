{"cells": [{"source": "**Objective**", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "f5a163b5658ef4fed6d12f7da4788ee7047f4e65", "_execution_state": "idle", "collapsed": false, "_cell_guid": "55d7d507-4a1c-4ce6-9fb0-9bb57a3b78ba"}, "execution_count": null}, {"source": "\nIn this notebook, we are going to predict the presence of invasive species from the pictures taken in a Brazilian national forest.", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "92251aeabce3f1a5da1b2346736b34b6f6b79fa9", "_execution_state": "idle", "collapsed": false, "_cell_guid": "c32fff1f-224c-4e57-a863-93712d17ab1a"}, "execution_count": null}, {"source": "Check the input files we have", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "04cfb2144271e043d290eae47157ae29172eb6db", "_execution_state": "idle", "collapsed": false, "_cell_guid": "05b71c99-b38a-4c50-b6ac-f2492ba2a683"}, "execution_count": null}, {"source": "import numpy as np \nimport pandas as pd \n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "477a9b28e600d7db109873a614c2fc80fa571213", "_execution_state": "idle", "_cell_guid": "f3f07f2e-e744-417d-aa2e-01bd50735e43"}, "execution_count": 1}, {"source": "Let's see the top 5 rows from train_label file", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "0d321112e1d2e4e351983d48cd14bf3113535cf5", "_execution_state": "idle", "collapsed": false, "_cell_guid": "6f2e39ea-ade4-4ae5-bb08-7530123518d6"}, "execution_count": null}, {"source": "train_labels_df = pd.read_csv(\"../input/train_labels.csv\")\ntrain_labels_df.head()", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "53ba0a063a29ba1d1ba6d0509128f5ce2d71862f", "_execution_state": "idle", "collapsed": false, "_cell_guid": "0e020bc5-6ee5-4f49-bfdf-04206b89080c"}, "execution_count": 2}, {"source": "train_labels_df.tail()", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "4e29cb8126f38b5b9c6115c5abb3bc4739473b2c", "_execution_state": "idle", "collapsed": false, "_cell_guid": "19340fdf-1d58-426e-beec-2683f2ece0c9"}, "execution_count": 3}, {"source": "train_labels_df.describe() #describing train_labels_df", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "fbc380c14b16ad6acdf5e8ad67f385955887f26d", "_execution_state": "idle", "collapsed": false, "_cell_guid": "6bb9f50f-1a02-4666-bae5-a1adc2fc5bc1"}, "execution_count": 4}, {"source": "train_labels_df.invasive.value_counts() #finding how many invasive and not invasive samples in train data", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "e4124c4ac830bdb791fa8effe2c680de851ea8b7", "_execution_state": "idle", "collapsed": false, "_cell_guid": "2e45350a-9958-40fe-a0bb-662149aaf635"}, "execution_count": 5}, {"source": "Find how many images in both train and test folders", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "b677d47e810d4ee0010dd2d57881325b6a7e0275", "_execution_state": "idle", "collapsed": false, "_cell_guid": "935ec0c9-48ce-4f39-97cb-c0502ff1afe1"}, "execution_count": null}, {"source": "#Getting image names from both train and test folders\ntrain_images_names = check_output([\"ls\", \"../input/train/\"]).decode(\"utf8\")\ntrain_images_names = train_images_names.split(\"\\n\")\ntest_images_names = check_output([\"ls\", \"../input/test/\"]).decode(\"utf8\")\ntest_images_names = test_images_names.split(\"\\n\")\nprint(\"Total train images\",len(train_images_names))\nprint(\"Total test images\",len(test_images_names))", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "d9184f428a9e506d5e0cd0fc859b48aa384c03e5", "_execution_state": "idle", "collapsed": false, "_cell_guid": "ed73c4d3-de6e-415e-b614-12dfddd34fa9"}, "execution_count": 6}, {"source": "Creating test dataframe for submission using test images names", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "372ee27612110a0b474430b1c2d2771fe83bc4ca", "_execution_state": "idle", "collapsed": false, "_cell_guid": "c58eccad-d61d-403f-b722-a0ed8e616dce"}, "execution_count": null}, {"source": "test_df = pd.DataFrame()\ntest_df[\"name\"] = [test_image.split(\".\")[0] for test_image in test_images_names]\ntest_df.head()", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "ab7255bfaca005e08188eb7e4c1b92edd3a56159", "_execution_state": "idle", "collapsed": false, "_cell_guid": "d3576861-b744-43b3-9db0-69c38cb54ab0"}, "execution_count": 7}, {"source": "Lets see some sample images for both invasive and non-invasive now.", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "a910965bbd2602e8ad0866f2b0df1353a48cc221", "_execution_state": "idle", "collapsed": false, "_cell_guid": "1c3a9d83-9fc2-4675-abe2-d8943875fcbc"}, "execution_count": null}, {"source": " **3.jpg** is invasive and **4.jpg** is non-invasive species. ", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "33c02c1d7cd77b5937060eea778120e0ad40ba03", "_execution_state": "idle", "collapsed": false, "_cell_guid": "c21aa5ca-8eb9-45af-9ee9-a33617a49715"}, "execution_count": null}, {"source": "% pylab inline\nimport os\nimport random\n\nimport pandas as pd\nfrom scipy.misc import imread\nprint(\"See train images with invasive and without invasive species\")\nprint(\"3.jpg - With Invasive species\")\nimg = imread(\"../input/train/3.jpg\")\nimshow(img)", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "ee6a0166877a29099a7ff5dcc1de01e52939334f", "_execution_state": "idle", "collapsed": false, "_cell_guid": "297765b2-cbe2-45e4-9d60-c8382f8e9ea3"}, "execution_count": 8}, {"source": "print(\"4.jpg - Non-Invasive species\")\nimg1 = imread(\"../input/train/4.jpg\")\nimshow(img1)", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "e219d306a235ef0d82a9213b08fe4b196b74ea46", "_execution_state": "idle", "collapsed": false, "_cell_guid": "3e9c84ef-08d8-4b5b-8fc5-4004ebe1708d"}, "execution_count": 9}, {"source": "#importing all the necessary modules\n% pylab inline\nimport os\nimport random\n\nimport pandas as pd\nfrom scipy.misc import imread\n\nroot_dir = os.path.abspath('.')\ndata_dir = '../input/'", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "8fc0ea213bcfbc29cbcd5374baa785844d53b0fb", "_execution_state": "idle", "collapsed": false, "_cell_guid": "85c17b7f-284f-4f67-abcc-310a614899f4"}, "execution_count": 10}, {"source": "Script to randomly select an image and printed it", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "dd6bc4e73d9400c3a70982eda21478d6f3350031", "_execution_state": "idle", "collapsed": false, "_cell_guid": "161ff655-6ac9-487a-8cd5-7c968b02ad87"}, "execution_count": null}, {"source": "i = random.choice(train_labels_df.index)\n\nimg_name = str(train_labels_df.name[i])+\".jpg\"\nimg = imread(os.path.join(data_dir, 'train', img_name))\n\nimshow(img)\nprint(\"Image\",img_name)\nprint(\"Invasive\", train_labels_df.invasive[i])", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "b80d0b263b06500b6761552d86960293191d94af", "_execution_state": "idle", "collapsed": false, "_cell_guid": "e79b6d29-5049-4055-af26-05f608d37a59"}, "execution_count": 11}, {"source": "All images are different in size. This may reduce the model accuracy. So we need to resize all the images to same size.", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "b8d8b45118e123d9e076b8722ef272d5a7d0e085", "_execution_state": "idle", "collapsed": false, "_cell_guid": "9fa153ac-0ce5-416b-9dbf-a745761fe98a"}, "execution_count": null}, {"source": "Load all the images and resize them into a single numpy array.", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "f4f4ceabbcbcdfc361a7f821e467148091c746c1", "_execution_state": "idle", "collapsed": false, "_cell_guid": "eadbc4f1-da91-48fe-9bbd-c5722e1e49b5"}, "execution_count": null}, {"source": "#Resizing train images\nfrom scipy.misc import imresize\n\ntemp = []\n\n\nfor img_name in train_labels_df.name:\n    img_path = os.path.join(data_dir, 'train', str(img_name)+\".jpg\")\n    img = imread(img_path)\n    img = imresize(img, (32, 32))\n\n    img = img.astype('float32')\n    temp.append(img)\ntrain_x = np.stack(temp)", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "5c9dec864433ef3ba0a865f6496d61cdb64e25cb", "_execution_state": "idle", "collapsed": false, "_cell_guid": "7cd040fa-7446-4d26-af52-c99f3b3b0643"}, "execution_count": 12}, {"source": "print(test_df.tail()) #Last row is null\ntest_df = test_df[:-1] #So removing last row from the test dataframe\nprint(test_df.tail())", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "d8fac962c3435bda3da7efb1a52d4126732ec4ea", "_execution_state": "idle", "collapsed": false, "_cell_guid": "6dece268-fd2e-407f-a1b8-637ad2896000"}, "execution_count": 13}, {"source": "#Resizing test images\ntemp = []\ni=0\nfor img_name in test_df.name:\n    img_path = os.path.join(data_dir, 'test', str(img_name)+\".jpg\")\n    try:\n        img = imread(img_path)\n        img = imresize(img, (32, 32))\n\n        img = img.astype('float32')\n        temp.append(img)\n        i=i+1\n    except:\n        continue\ntest_x = np.stack(temp)", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "07742c63d6ad2f993aecc0fbda433a4b5cb93c43", "_execution_state": "idle", "collapsed": false, "_cell_guid": "70370050-e66e-47d1-932b-2949dbbaf046"}, "execution_count": 14}, {"source": "We can do one more thing that could help us build a better model; i.e. we can normalize our images. Normalizing the images will make our train faster.", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "6e3540623f3254b1c9be9a3633c5797fbb55babb", "_execution_state": "idle", "collapsed": false, "_cell_guid": "2a0496b9-9ffe-4b45-8b68-1346e4431427"}, "execution_count": null}, {"source": "train_x = train_x / 255\ntest_x = test_x / 255", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "d219a9d44660d07bc67f8a85bd8d97b147458a87", "_execution_state": "idle", "collapsed": false, "_cell_guid": "7b28ddc9-0b8f-4ae7-a58f-bd08a5d3f28d"}, "execution_count": 15}, {"source": "Let's see the distribution of invasive images in our data", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "f221603db109847a86221bcf9e90f28bfae6a6cd", "_execution_state": "idle", "collapsed": false, "_cell_guid": "87a74862-b602-461f-9b46-370e63a93607"}, "execution_count": null}, {"source": "train_labels_df.invasive.value_counts(normalize=True)", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "89566657077ecacfc8268e04ee12bcc1e2db29a3", "_execution_state": "idle", "collapsed": false, "_cell_guid": "4680f68b-ec0e-460f-9971-e2e20cba06f8"}, "execution_count": 16}, {"source": "First we should specify all the parameters we will be using in our network", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "0284384acae3779f03f18bd362796c2e78f5a25e", "_execution_state": "idle", "collapsed": false, "_cell_guid": "59276297-0dd2-435d-8e9a-9a33e5ea0db5"}, "execution_count": null}, {"source": "import keras\nfrom sklearn.preprocessing import LabelEncoder\n\nlb = LabelEncoder()\ntrain_y = lb.fit_transform(train_labels_df.invasive)\ntrain_y = keras.utils.np_utils.to_categorical(train_y)\n\ninput_num_units = (32, 32, 3)\nhidden_num_units = 500\noutput_num_units = 2\n\nepochs = 5\nbatch_size = 128", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "951fd2ec99a1ee1819ccdd0aff3efd4901ca8e61", "_execution_state": "idle", "collapsed": false, "_cell_guid": "363e6e61-ed60-4793-90a8-edbf9ea55ba3"}, "execution_count": 17}, {"source": "#Import the necessary keras modules\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, InputLayer\n\n#Define our network\nmodel = Sequential([\n  InputLayer(input_shape=input_num_units),\n  Flatten(),\n  Dense(units=hidden_num_units, activation='relu'),\n  Dense(units=output_num_units, activation='softmax'),\n])", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "8bbddc1e54592000e502f9dd74cb918c9d50d293", "_execution_state": "idle", "collapsed": false, "_cell_guid": "998c3e10-f12d-4c25-b880-d16e476e5788"}, "execution_count": 18}, {"source": "To see how our model looks like; lets print it", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "df2b446cf1439c180ba8c79535c22aedb959e860", "_execution_state": "idle", "collapsed": false, "_cell_guid": "79788823-a816-4b03-9a6c-bea02c5a2032"}, "execution_count": null}, {"source": "model.summary()", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "01985f3ddd80985a312f8cf787a490529b22c671", "_execution_state": "idle", "collapsed": false, "_cell_guid": "f5c3fbaf-377b-41b5-ba11-ba382aefad93"}, "execution_count": 19}, {"source": "#Compile and train our network\nmodel.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1)", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "50112b9531a1e117a983fb123aeb7ae6c2347361", "_execution_state": "idle", "collapsed": false, "_cell_guid": "07ba8ce8-0043-471e-b01a-9304b6253525"}, "execution_count": 20}, {"source": "Let\u2019s tweak the code a little bit to cross validate it.", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "6d05d88af339d6e9e613fa486a9ce02245641566", "_execution_state": "idle", "collapsed": false, "_cell_guid": "a733097f-b672-4cf8-8410-8a9388f8a5a4"}, "execution_count": null}, {"source": "model.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1, validation_split=0.2)", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "28fa445944db59da9ffe2d2f88a9d06758aa7efc", "_execution_state": "idle", "collapsed": false, "_cell_guid": "403265f6-edb5-4133-908f-7f7c9d12281a"}, "execution_count": 21}, {"source": "Let's submit the result", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "8881e201641a35b9148b5f1547e4f6fd5bb21e4c", "_execution_state": "idle", "collapsed": false, "_cell_guid": "b7ff1e84-b378-455e-acaa-d18b92607329"}, "execution_count": null}, {"source": "pred = model.predict_classes(test_x)\npred = lb.inverse_transform(pred)\ntest_df['invasive'] = pred", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "99fcfd17559eca199449d93f18c59c5a017605ff", "_execution_state": "idle", "collapsed": false, "_cell_guid": "9af56e91-58ee-48b4-a657-0fdf79acc0e9"}, "execution_count": 22}, {"source": "test_df['invasive'].value_counts()", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "97f21865268da0d5f3f1cb2ae5e8ac54e8d1538d", "_execution_state": "idle", "collapsed": false, "_cell_guid": "dc5b1a1b-366b-4e34-9479-7df91c7aea6a"}, "execution_count": 23}, {"source": "test_df.to_csv('submission.csv', index=False)", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "0fb14548e863909c4efecc95c888192e9fa99191", "_execution_state": "idle", "collapsed": false, "_cell_guid": "cd0a337e-a0b3-4246-8c7d-2fcc67a9f53a"}, "execution_count": 24}, {"source": "Let's test our model using random image", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "4ea27c62561667135cf3a72bd2fc9846df073e1a", "_execution_state": "idle", "collapsed": false, "_cell_guid": "dbab62bb-52d2-4ba9-9dd2-0a7212127ed3"}, "execution_count": 23}, {"source": "i = random.choice(train_labels_df.index)\nimg_name = train_labels_df.name[i]\n\nimg = imread(os.path.join(data_dir, 'train', str(img_name)+\".jpg\")).astype('float32')\nimshow(imresize(img, (128, 128)))\npred = model.predict_classes(train_x)\nprint('Original:', train_labels_df.invasive[i], 'Predicted:', lb.inverse_transform(pred[i]))", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "4fba2717467c70299a9e769113ddea38d35996de", "_execution_state": "idle", "collapsed": false, "_cell_guid": "a10940f2-c75f-45fb-ae70-79ca3ef8be35"}, "execution_count": 26}, {"source": "For creating this notebook, i referred an article Solution for Age Detection Practice Problem from Analytics Vidya.", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "f86d328a496b516a17cfb228920f754fa9527bd7", "_execution_state": "idle", "collapsed": false, "_cell_guid": "185e4b11-670d-40c6-84f8-7e3ef7caa444"}, "execution_count": null}, {"source": "If you really feel this is helpful for you. Please upvote it and encourage me to write more. Thanks.", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "77d10afc20c22c68ebbb2bdbf8a3781cff076f73", "_execution_state": "idle", "collapsed": false, "_cell_guid": "23a67159-7863-43e5-9197-f2e04da65e74"}, "execution_count": 27}, {"source": "", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "763fc2f361f5026cc04c3c9dcf8d30ceb0fb6e64", "_execution_state": "idle", "collapsed": false, "_cell_guid": "88c723ea-c4ff-4a50-9b61-bc019e2fe109"}, "execution_count": null}], "nbformat_minor": 0, "metadata": {"language_info": {"nbconvert_exporter": "python", "version": "3.6.1", "mimetype": "text/x-python", "file_extension": ".py", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat": 4}