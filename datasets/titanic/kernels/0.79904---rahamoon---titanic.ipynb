{"cells":[
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "import pandas as pd\ntitanic_training_data = pd.read_csv(\"../input/train.csv\")\ntitanic_training_data.head(5)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "titanic_training_data.describe()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "titanic_training_data[\"Age\"] = titanic_training_data[\"Age\"].fillna(titanic_training_data[\"Age\"].median())\ntitanic_training_data.loc[titanic_training_data[\"Sex\"]==\"male\",\"Sex\"] = 0\ntitanic_training_data.loc[titanic_training_data[\"Sex\"]==\"female\",\"Sex\"] = 1\ntitanic_training_data[\"Embarked\"] = titanic_training_data[\"Embarked\"].fillna(\"S\")\ntitanic_training_data.loc[titanic_training_data[\"Embarked\"]== \"S\",\"Embarked\"] = 0\ntitanic_training_data.loc[titanic_training_data[\"Embarked\"]== \"C\",\"Embarked\"] = 1\ntitanic_training_data.loc[titanic_training_data[\"Embarked\"]== \"Q\",\"Embarked\"] = 2\ntitanic_training_data.head(10)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn.linear_model import LinearRegression\nfrom sklearn.cross_validation import KFold\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n\nalg = LinearRegression()\nkf = KFold(titanic_training_data.shape[0], n_folds=3, random_state=1)\npredictions = []\nfor train, test in kf:\n    train_predictors = (titanic_training_data[predictors].iloc[train,:])\n    train_target = titanic_training_data[\"Survived\"].iloc[train]\n    alg.fit(train_predictors, train_target)\n    test_predictions = alg.predict(titanic_training_data[predictors].iloc[test,:])\n    predictions.append(test_predictions)\n\n\npredictions = np.concatenate(predictions, axis=0)\npredictions[predictions > .5] = 1\npredictions[predictions <=.5] = 0\n\naccuracy_score(titanic_training_data[\"Survived\"],predictions)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "import re\n\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\ntitles = titanic_training_data[\"Name\"].apply(get_title)\nprint(pd.value_counts(titles))\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\nfor k,v in title_mapping.items():\n    titles[titles == k] = v\n\nprint(pd.value_counts(titles))\n\ntitanic_training_data[\"Title\"] = titles"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "\ntitanic_training_data[\"FamilySize\"] = titanic_training_data[\"SibSp\"] + titanic_training_data[\"Parch\"]\n\ntitanic_training_data[\"NameLength\"] = titanic_training_data[\"Name\"].apply(lambda x: len(x))\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "import operator\n\nfamily_id_mapping = {}\n\ndef get_family_id(row):\n    last_name = row[\"Name\"].split(\",\")[0]\n    family_id = \"{0}{1}\".format(last_name, row[\"FamilySize\"])\n    if family_id not in family_id_mapping:\n        if len(family_id_mapping) == 0:\n            current_id = 1\n        else:\n            current_id = (max(family_id_mapping.items(), key=operator.itemgetter(1))[1] + 1)\n        family_id_mapping[family_id] = current_id\n    return family_id_mapping[family_id]\n\nfamily_ids = titanic_training_data.apply(get_family_id, axis=1)\n\nfamily_ids[titanic_training_data[\"FamilySize\"] < 3] = -1\n\n# Print the count of each unique id.\nprint(pd.value_counts(family_ids))\n\ntitanic_training_data[\"FamilyId\"] = family_ids"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "import matplotlib.pyplot as plt\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cross_validation import cross_val_score\n\n%matplotlib inline\n\n\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n\n# Perform feature selection\nselector = SelectKBest(f_classif, k=5)\nselector.fit(titanic_training_data[predictors], titanic_training_data[\"Survived\"])\n\nprint(selector)\nscores = -np.log10(selector.pvalues_)\n\nplt.bar(range(len(predictors)), scores)\nplt.xticks(range(len(predictors)), predictors, rotation='vertical')\nplt.show()\n\npredictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n\nalg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\nscores = cross_val_score(alg, titanic_training_data[predictors], titanic_training_data[\"Survived\"], cv=3)\nprint(scores.mean())"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# The algorithms we want to ensemble.\n# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.\nalgorithms = [\n    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]],\n    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n]\n\n# Initialize the cross validation folds\nkf = KFold(titanic_training_data.shape[0], n_folds=3, random_state=1)\n\npredictions = []\nfor train, test in kf:\n    train_target = titanic_training_data[\"Survived\"].iloc[train]\n    full_test_predictions = []\n    # Make predictions for each algorithm on each fold\n    for alg, predictors in algorithms:\n        # Fit the algorithm on the training data.\n        alg.fit(titanic_training_data[predictors].iloc[train,:], train_target)\n        # Select and predict on the test fold.  \n        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n        test_predictions = alg.predict_proba(titanic_training_data[predictors].iloc[test,:].astype(float))[:,1]\n        full_test_predictions.append(test_predictions)\n    # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n    test_predictions[test_predictions <= .5] = 0\n    test_predictions[test_predictions > .5] = 1\n    predictions.append(test_predictions)\n\n# Put all the predictions together into one array.\npredictions = np.concatenate(predictions, axis=0)\n\n# Compute accuracy by comparing to the training data.\naccuracy = sum(predictions[predictions == titanic_training_data[\"Survived\"]]) / len(predictions)\nprint(accuracy)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "titanic_test_data = pd.read_csv(\"../input/test.csv\")\ntitanic_test_data.head(5)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "titanic_test_data.describe()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "titanic_test_data[\"Age\"] = titanic_test_data[\"Age\"].fillna(titanic_training_data[\"Age\"].median())\ntitanic_test_data.loc[titanic_test_data[\"Sex\"]==\"male\",\"Sex\"] = 0\ntitanic_test_data.loc[titanic_test_data[\"Sex\"]==\"female\",\"Sex\"] = 1\ntitanic_test_data[\"Embarked\"] = titanic_test_data[\"Embarked\"].fillna(\"S\")\ntitanic_test_data.loc[titanic_test_data[\"Embarked\"]==\"S\",\"Embarked\"] = 0\ntitanic_test_data.loc[titanic_test_data[\"Embarked\"]==\"C\",\"Embarked\"] = 1\ntitanic_test_data.loc[titanic_test_data[\"Embarked\"]==\"Q\",\"Embarked\"] = 2\ntitanic_test_data[\"Fare\"] = titanic_test_data[\"Fare\"].fillna(titanic_training_data[\"Fare\"].median())\ntitanic_test_data.describe()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "titanic_test_data.head(5)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "\ntitles = titanic_test_data[\"Name\"].apply(get_title)\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\nfor k,v in title_mapping.items():\n    titles[titles == k] = v\ntitanic_test_data[\"Title\"] = titles\nprint(pd.value_counts(titanic_test_data[\"Title\"]))\ntitanic_test_data[\"FamilySize\"] = titanic_test_data[\"SibSp\"] + titanic_test_data[\"Parch\"]\ntitanic_test_data[\"NameLength\"]=titanic_test_data[\"Name\"].apply(lambda x:len(x))\n\nfamily_ids = titanic_test_data.apply(get_family_id, axis=1)\nfamily_ids[titanic_test_data[\"FamilySize\"] < 3] = -1\ntitanic_test_data[\"FamilyId\"] = family_ids\n\ntitanic_test_data.head(5)\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n\nalgorithms = [\n    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n]\n\nfull_predictions = []\nfor alg, predictors in algorithms:\n    # Fit the algorithm using the full training data.\n    alg.fit(titanic_training_data[predictors], titanic_training_data[\"Survived\"])\n    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n    predictions = alg.predict_proba(titanic_test_data[predictors].astype(float))[:,1]\n    full_predictions.append(predictions)\n\n# The gradient boosting classifier generates better predictions, so we weight it higher.\npredictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\npredictions[predictions <= .5] = 0\npredictions[predictions > .5] = 1\npredictions = predictions.astype(int)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "submission = pd.DataFrame({\n        \"PassengerId\": titanic_test_data[\"PassengerId\"],\n        \"Survived\": predictions\n    })\n\nsubmission.to_csv(\"titanic_medrah_solution.csv\", index=False)"
 }
],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}, "nbformat": 4, "nbformat_minor": 0}