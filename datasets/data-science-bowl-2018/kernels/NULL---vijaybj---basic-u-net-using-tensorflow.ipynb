{"nbformat_minor": 1, "nbformat": 4, "cells": [{"source": ["#Intro\n", "First of all thanks to Kjetil \u00c5mdal-S\u00e6vik for providing excellent code for data preparation.\n", "Being a novice python programmer, my code may not be that much efficient but it may serve as a starting point for using TensorFlow."], "cell_type": "markdown", "metadata": {"collapsed": true, "_uuid": "abc85ca22cd2b023575e3f8d35634e81eaa6b0f4", "_cell_guid": "97ab7f65-6023-4a97-b40b-f404716c8c96"}}, {"outputs": [], "execution_count": null, "source": ["import os\n", "import sys\n", "import numpy as np\n", "import tensorflow as tf\n", "import random\n", "import math\n", "import warnings\n", "import pandas as pd\n", "import cv2\n", "import matplotlib.pyplot as plt\n", "\n", "from tqdm import tqdm\n", "from itertools import chain\n", "from skimage.io import imread, imshow, imread_collection, concatenate_images\n", "from skimage.transform import resize\n", "from skimage.morphology import label\n", "\n", "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n", "seed = 42\n", "random.seed = seed\n", "np.random.seed = seed"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "5c38504af3a84bee68c66d3cde74443c58df422f", "_cell_guid": "c332549b-8d23-4bb5-8497-e7a8eb8b21d2"}}, {"outputs": [], "execution_count": null, "source": ["# Set some parameters\n", "IMG_WIDTH = 128\n", "IMG_HEIGHT = 128\n", "IMG_CHANNELS = 3\n", "TRAIN_PATH = '../input/stage1_train/'\n", "TEST_PATH = '../input/stage1_test/'\n", "\n", "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n", "seed = 42\n", "random.seed = seed\n", "np.random.seed = seed"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "5d84a2852337e5699520058221d974ac47e7204a", "_cell_guid": "5babc1df-c8e8-4037-9537-ee7409d338ef"}}, {"outputs": [], "execution_count": null, "source": ["# Get train and test IDs\n", "train_ids = next(os.walk(TRAIN_PATH))[1]\n", "test_ids = next(os.walk(TEST_PATH))[1]"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "3fb9d6530fbbd0e22e41fc4fd9fd9fc0bff027ac", "_cell_guid": "ffa0caf0-2d1b-40f2-865b-8e6db88526b6"}}, {"outputs": [], "execution_count": null, "source": ["# Get and resize train images and masks\n", "images = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n", "labels = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n", "print('Getting and resizing train images and masks ... ')\n", "sys.stdout.flush()\n", "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n", "    path = TRAIN_PATH + id_\n", "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n", "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n", "    images[n] = img\n", "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n", "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n", "        mask_ = imread(path + '/masks/' + mask_file)\n", "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n", "                                      preserve_range=True), axis=-1)\n", "        mask = np.maximum(mask, mask_)\n", "    labels[n] = mask\n", "\n", "X_train = images\n", "Y_train = labels\n", "Y_train = Y_train.astype(np.float32)\n", "\n", "# Get and resize test images\n", "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n", "sizes_test = []\n", "print('Getting and resizing test images ... ')\n", "sys.stdout.flush()\n", "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n", "    path = TEST_PATH + id_\n", "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n", "    sizes_test.append([img.shape[0], img.shape[1]])\n", "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n", "    X_test[n] = img\n", "\n", "print('Done!')"], "cell_type": "code", "metadata": {"_uuid": "9e389ba8bdb5b6fc03b231b6a6c84a8bde634053", "_cell_guid": "ca0cc34b-c26f-41ee-88d7-975aebdb634e"}}, {"outputs": [], "execution_count": null, "source": ["def shuffle():\n", "    global images, labels\n", "    p = np.random.permutation(len(X_train))\n", "    images = X_train[p]\n", "    labels = Y_train[p]"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "2a83eab66bf55194f300953bea5534b6a043130f", "_cell_guid": "3f5e5a47-6133-4870-976a-a8e4fa7bf46c"}}, {"outputs": [], "execution_count": null, "source": ["def next_batch(batch_s, iters):\n", "    if(iters == 0):\n", "        shuffle()\n", "    count = batch_s * iters\n", "    return images[count:(count + batch_s)], labels[count:(count + batch_s)]"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "5a3b79a7d9ee881c68e7f6147964fcd30f726b4a", "_cell_guid": "3ca3becb-5613-431b-8a88-07d32ec751dc"}}, {"outputs": [], "execution_count": null, "source": ["def deconv2d(input_tensor, filter_size, output_size, out_channels, in_channels, name, strides = [1, 2, 2, 1]):\n", "    dyn_input_shape = tf.shape(input_tensor)\n", "    batch_size = dyn_input_shape[0]\n", "    out_shape = tf.stack([batch_size, output_size, output_size, out_channels])\n", "    filter_shape = [filter_size, filter_size, out_channels, in_channels]\n", "    w = tf.get_variable(name=name, shape=filter_shape)\n", "    h1 = tf.nn.conv2d_transpose(input_tensor, w, out_shape, strides, padding='VALID')\n", "    return h1"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "3d9f26384e23e070783ec0f4e2b4ba25d800a440", "_cell_guid": "10fd62e2-3b6a-4975-acb0-6d5759dce26f"}}, {"outputs": [], "execution_count": null, "source": ["X = tf.placeholder(tf.float32, [None, 128, 128, 3])\n", "Y_ = tf.placeholder(tf.float32, [None, 128, 128, 1])\n", "lr = tf.placeholder(tf.float32)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "061fd3457e6fc5e69212887327d31163832e1153", "_cell_guid": "22033858-fbe7-454e-9119-1f2a763070da"}}, {"outputs": [], "execution_count": null, "source": ["Y0 = tf.layers.conv2d(X, filters=16, kernel_size=1, strides=1, padding=\"VALID\", activation=tf.nn.relu)\n", "Y1 = tf.layers.conv2d(Y0, filters=32, kernel_size=2, strides=2, padding=\"VALID\", activation=tf.nn.relu)\n", "Y2 = tf.layers.conv2d(Y1, filters=64, kernel_size=2, strides=2, padding=\"VALID\", activation=tf.nn.relu)\n", "\n", "Y3_ = deconv2d(Y2, 1, 32, 32, 64, \"Y3_deconv\", strides=[1, 1, 1, 1])\n", "Y3_ = tf.nn.relu(Y3_)\n", "\n", "Y2_ = deconv2d(Y3_, 2, 64, 16, 32, \"Y2_deconv\")\n", "Y2_ = tf.nn.relu(Y2_)\n", "\n", "Y1_ = deconv2d(Y2_, 2, 128, 8, 16, \"Y1_deconv\")\n", "Y1_ = tf.nn.relu(Y1_)\n", "\n", "Y0_ = deconv2d(Y1_, 1, 128, 1, 8, \"Y0_deconv\", strides=[1, 1, 1, 1])\n", "\n", "logits = Y0_\n", "loss = tf.reduce_mean(tf.square(Y_ - logits))"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "0c5bffd335bcdfca6fe9b094eb1e64851c867477", "_cell_guid": "dedcf23a-9563-4d21-8383-b9ca8c39fc7a"}}, {"outputs": [], "execution_count": null, "source": ["optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n", "# init\n", "init = tf.global_variables_initializer()\n", "sess = tf.Session()\n", "sess.run(init)\n", "\n", "iter_count = 0\n", "\n", "for i in range(15000):\n", "    # training on batches of 5 images with 5 mask images\n", "    if(iter_count > 114):\n", "        iter_count = 0    \n", "\n", "    batch_X, batch_Y = next_batch(5, iter_count)\n", "\n", "    iter_count += 1\n", "\n", "    feed_dict = {X: batch_X, Y_: batch_Y, lr: 0.0005}\n", "    loss_value = sess.run([loss], feed_dict=feed_dict)\n", "\n", "    if(i % 500 == 0):\n", "        print(\"training loss:\", str(loss_value))\n", "\n", "print(\"Done!\")"], "cell_type": "code", "metadata": {"_uuid": "803a9718ece3860da0f9fa4f3eeeead84f177e5e", "_cell_guid": "2d02dbe7-ff9b-4921-92d5-d5a8b412b429"}}, {"source": ["Test on the data that is not seen by the network during training:"], "cell_type": "markdown", "metadata": {"_uuid": "e0ca515bd74d94605c0e4d47b2b5ccd84c7ac1ad", "_cell_guid": "e5b6c8c1-a848-45d0-bf94-4a5d403da697"}}, {"outputs": [], "execution_count": null, "source": ["ix = 20 #random.randint(0, 64) #len(X_test) - 1 = 64\n", "test_image = X_test[ix].astype(float)\n", "imshow(test_image)\n", "plt.show()"], "cell_type": "code", "metadata": {"_uuid": "ceb487c8c94b58011469b70821e30b24e9ffc611", "_cell_guid": "73046a2f-f74a-47e9-bd61-917427d59426"}}, {"outputs": [], "execution_count": null, "source": ["#print(ix)\n", "test_image = np.reshape(test_image, [-1, 128 , 128, 3])\n", "test_data = {X:test_image}\n", "\n", "test_mask = sess.run([logits],feed_dict=test_data)\n", "test_mask = np.reshape(test_mask, [128 , 128, 1])\n", "imshow(test_mask.squeeze(), cmap=\"gray_r\")\n", "plt.show()"], "cell_type": "code", "metadata": {"_uuid": "5977edd0b667233e6c474e11ae61709999526d90", "_cell_guid": "efdd905a-4955-4526-bb04-480cade00c01"}}, {"outputs": [], "execution_count": null, "source": [], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "3113f21420b0215142b2914bffa725926eec0878", "_cell_guid": "7139604f-9724-4621-a610-3ba851d20dbc"}}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"file_extension": ".py", "pygments_lexer": "ipython3", "name": "python", "version": "3.6.4", "nbconvert_exporter": "python", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}}}}