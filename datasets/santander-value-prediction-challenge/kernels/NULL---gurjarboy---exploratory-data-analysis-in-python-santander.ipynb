{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn import preprocessing, model_selection, metrics\nimport lightgbm as lgb\n\ncolor = sns.color_palette()\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"Let us look at the files given for the competition."},{"metadata":{"trusted":true,"_uuid":"5d45dbc1855c3c6a8a83a83a59a7a97227e4e7ff"},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input/\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ce1f3596c3c7a7517ba443fb4b86babe7ec62ac"},"cell_type":"code","source":"# Read the data - train and test data set\ntrain_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\nprint(\"Train rows and columns : \", train_df.shape)\nprint(\"Test rows and columns : \", test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b22c651f30e12a95c0e3cd98bec64755089c8022"},"cell_type":"code","source":"train_df.info\ntest_df.info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa20ca177ccf6d13408bb31f1808b531fe1e9909"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6921b15439c4f731a6eddb2b9156536a61c6c2d2"},"cell_type":"code","source":"\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"faefac2dafc51398843f9b817a479deb20fd9b30"},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df['target'].values))\nplt.xlabel('index', fontsize=9)\nplt.ylabel('Target', fontsize=9)\nplt.title(\"Target Distribution\", fontsize=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"0709d5725ef5d0c8faab4ae4126e39b123148d9d"},"cell_type":"code","source":"# Plot the histogram to view the distribution of the dependent variable\nplt.figure(figsize=(25,10))\nsns.distplot(train_df['target'].values,bins=50)\nplt.xlabel(\"Target\",fontsize=13)\nplt.title(\"Target distribution (Histogram)\",fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae1a426547ea4bdba7a7416218008c1dc98c02d3"},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.distplot(np.log1p(train_df[\"target\"].values),bins=50,kde=False)\nplt.xlabel(\"log of Target Variable\",fontsize=13)\nplt.title(\"The distribution of the log of the target variable\", fontsize=15)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e0714a9d0bea77e99de515cdc3dae939e46d6a3"},"cell_type":"code","source":"# To find the list of the variable which have the missing values and the frequency of the missing values\nmissing_data = train_df.isnull().sum(axis=0).reset_index()\nmissing_data.columns = ['variable_name', 'missing_frequency']\nmissing_data[\"missing_percent\"]=100*(missing_data['missing_frequency']/train_df.shape[0])\nmissing_data = missing_data[missing_data['missing_frequency']>0]\nmissing_data = missing_data.sort_values(by='missing_frequency')\nmissing_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f91ad42cc423d6d2b52682ad0173d2bfc3e11ed3"},"cell_type":"code","source":"dtype_df = train_df.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df.groupby(\"Column Type\").aggregate('count').reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a80057c133fefc8109b6b3c9f510b225799c423d"},"cell_type":"code","source":"train_df[\"0deb4b6a8\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ab0418147e9a5f8820c6ea2a40de6fbfcfb5770"},"cell_type":"code","source":"# To find the variable which have unique value ( I mean constant values)  # 256 variables\nunique_df = train_df.nunique().reset_index()\nunique_df.columns = [\"col_name\", \"unique_count\"]\nconstant_df = unique_df[unique_df[\"unique_count\"]==1]\nconstant_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19fd4096555a4fb8368281d1280b5dee78754f5c"},"cell_type":"code","source":"# List down all the constant variables\nstr(constant_df.col_name.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4eb8cf5510a594d9e294aa3dab65d7543c5a79ab"},"cell_type":"code","source":"# Correlation with the target variable\nfrom scipy.stats import spearmanr\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nlabels = []\nvalues = []\nfor col in train_df.columns:\n    if col not in [\"ID\", \"target\"]:\n        labels.append(col)\n        values.append(spearmanr(train_df[col].values, train_df[\"target\"].values)[0])\ncorr_df = pd.DataFrame({'col_labels':labels, 'corr_values':values})\ncorr_df = corr_df.sort_values(by='corr_values')\n \ncorr_df = corr_df[(corr_df['corr_values']>0.1) | (corr_df['corr_values']<-0.1)]\nind = np.arange(corr_df.shape[0])\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,30))\nrects = ax.barh(ind, np.array(corr_df.corr_values.values), color='b')\nax.set_yticks(ind)\nax.set_yticklabels(corr_df.col_labels.values, rotation='horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation coefficient of the variables\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ea4a093434e3325d8480f7ea0b119a9b30aee7c"},"cell_type":"code","source":"# Correlation Heat map\n\ncols_to_use = corr_df[(corr_df['corr_values']>0.11) | (corr_df['corr_values']<-0.11)].col_labels.tolist()\n\ntemp_df = train_df[cols_to_use]\ncorrmat = temp_df.corr(method='spearman')\nf, ax = plt.subplots(figsize=(20, 20))\n\n# Draw the heatmap using seaborn\nsns.heatmap(corrmat, vmax=1., square=True, cmap=\"YlGnBu\", annot=True)\nplt.title(\"Important variables correlation map\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48263691c8e7b9d586fc093c853ad400505b1bd3"},"cell_type":"code","source":"# Get the X and y variables for building model\ntrain_X = train_df.drop(constant_df.col_name.tolist() + [\"ID\", \"target\"], axis=1)\ntest_X = test_df.drop(constant_df.col_name.tolist() + [\"ID\"], axis=1)\ntrain_y = np.log1p(train_df[\"target\"].values)\ntrain_X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26612f290f925ddf64d216198a660b67926117ea"},"cell_type":"code","source":"train_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9e8ad5654b0d7be0aec3977b353b51c3c36a04c"},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d6991935abc18558c1ea21b58dab0ddc31a9b5c"},"cell_type":"code","source":"from sklearn import ensemble\nmodel = ensemble.ExtraTreesRegressor(n_estimators=200, max_depth=20, max_features=0.5, n_jobs=-1, random_state=0)\nmodel.fit(train_X, train_y)\n\n## plot the importances ##\nfeat_names = train_X.columns.values\nimportances = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\nindices = np.argsort(importances)[::-1][:20]\n\nplt.figure(figsize=(12,12))\nplt.title(\"Feature importances\")\nplt.bar(range(len(indices)), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\nplt.xlim([-1, len(indices)])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b53ccf1441d938d85cc2a4aee28abc750acdc8a1"},"cell_type":"code","source":"# Feature Importance  and light gbm\ndef run_lgb(train_X, train_y, val_X, val_y, test_X):\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\",\n        \"num_leaves\" : 30,\n        \"learning_rate\" : 0.01,\n        \"bagging_fraction\" : 0.7,\n        \"feature_fraction\" : 0.7,\n        \"bagging_frequency\" : 5,\n        \"bagging_seed\" : 2018,\n        \"verbosity\" : -1\n    }\n    \n    lgtrain = lgb.Dataset(train_X, label=train_y)\n    lgval = lgb.Dataset(val_X, label=val_y)\n    evals_result = {}\n    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=200, evals_result=evals_result)\n    \n    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n    return pred_test_y, model, evals_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb7ab22762349c6f20025dbe1e7d46dc56d5890f"},"cell_type":"code","source":"# K fold cross validation and average the prediction \nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\npred_test_full = 0\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_X.loc[dev_index,:], train_X.loc[val_index,:]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    pred_test, model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y, test_X)\n    pred_test_full += pred_test\npred_test_full /= 5.\npred_test_full = np.expm1(pred_test_full)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20fca30aa6f0fd3dd5dfe8cbc95585e03e5b0630"},"cell_type":"code","source":"# Making a submission file #\nsub_df = pd.DataFrame({\"ID\":test_df[\"ID\"].values})\nsub_df[\"target\"] = pred_test_full\nsub_df.to_csv(\"BaselineLGB.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfc31c289978c9bbb0a362a923a8806d0b2e5f6a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4da75ff794b672e2fc1a529470ff5b27b028a806"},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2e108b5caf9ee624d3e267a8c324a6463785f60c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}