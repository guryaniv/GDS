Can you help end gender bias in pronoun resolution? Pronoun resolution is part
of coreference resolution, the task of pairing an expression to its referring
entity. This is an important task for natural language understanding, and the
resolution of ambiguous pronouns is a longstanding challenge. Unfortunately,
recent studies have suggested gender bias among state-of-the-art coreference
resolvers. Google AI Language aims to improve gender-fairness in modeling by
releasing the Gendered Ambiguous Pronouns (GAP) dataset, containing gender-
balanced pronouns (50% of its examples containing feminine pronouns, and 50%
containing masculine pronouns). In this two-stage competition, Kagglers are
challenged to build pronoun resolution systems that perform equally well
regardless of pronoun gender. Stage two's final evaluation will use a new
dataset following the same format. To encourage gender-fair modeling, the
ratio of masculine to feminine examples in the official test data will not be
known ahead of time. \---------- Please cite the original paper if you use GAP
in your work: @inproceedings{webster2018gap, title = {Mind the GAP: A Balanced
Corpus of Gendered Ambiguous Pronouns}, author = {Webster, Kellie and
Recasens, Marta and Axelrod, Vera and Baldridge, Jason}, booktitle =
{Transactions of the ACL}, year = {2018}, pages = {to appear}, }

