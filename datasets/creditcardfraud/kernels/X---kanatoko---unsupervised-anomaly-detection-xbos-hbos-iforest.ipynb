{"cells":[{"metadata":{"_cell_guid":"ffebd89a-8e12-4418-8d78-908dcb15589b","_uuid":"3e5daee8be3b9d08920adfb32ae22b8ca8ad41e2"},"cell_type":"markdown","source":"# Fully Unsupervised Anomaly Detection\n## [XBOS](https://github.com/Kanatoko/XBOS-anomaly-detection) vs [HBOS](https://www.dfki.de/KI2012/PosterDemoTrack/ki2012pd13.pdf) vs [Isolation Forest](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf)"},{"metadata":{"_cell_guid":"66c4d446-610a-460e-9962-25514a79cb63","_uuid":"3d9afee104fff66012c8ac19d0c92c623792d63d"},"cell_type":"markdown","source":"### 1. Loading XBOS class.\nXBOS is a cluster-based anomaly detection algorithm. Source code is available at [GitHub](https://github.com/Kanatoko/XBOS-anomaly-detection)"},{"metadata":{"_cell_guid":"eb5a029c-ac02-44a5-89ac-0abc305017d5","collapsed":true,"_uuid":"5524bb9650da384c284c6fdb38a5fc0a96812b49","trusted":false},"cell_type":"code","source":"# Author: Kanatoko(https://twitter.com/kinyuka)\n# License: BSD 3 clause\n\nfrom sklearn.cluster import KMeans\nimport numpy as np\nfrom pandas import DataFrame\nfrom math import pow\nimport math\n\nclass XBOS:\n    \n    def __init__(self,n_clusters=15,effectiveness=500,max_iter=2):\n        self.n_clusters=n_clusters\n        self.effectiveness=effectiveness\n        self.max_iter=max_iter\n        self.kmeans = {}\n        self.cluster_score = {}\n        \n    def fit(self, data):\n        length = len(data)\n        for column in data.columns:\n            kmeans = KMeans(n_clusters=self.n_clusters,max_iter=self.max_iter)\n            self.kmeans[column]=kmeans\n            kmeans.fit(data[column].values.reshape(-1,1))\n            assign = DataFrame(kmeans.predict(data[column].values.reshape(-1,1)),columns=['cluster'])\n            cluster_score=assign.groupby('cluster').apply(len).apply(lambda x:x/length)\n            ratio=cluster_score.copy()\n        \n            sorted_centers = sorted(kmeans.cluster_centers_)\n            max_distance = ( sorted_centers[-1] - sorted_centers[0] )[ 0 ]\n        \n            for i in range(self.n_clusters):\n                for k in range(self.n_clusters):\n                    if i != k:\n                        dist = abs(kmeans.cluster_centers_[i] - kmeans.cluster_centers_[k])/max_distance\n                        effect = ratio[k]*(1/pow(self.effectiveness,dist))\n                        cluster_score[i] = cluster_score[i]+effect\n                        \n            self.cluster_score[column] = cluster_score\n                    \n    def predict(self, data):\n        length = len(data)\n        score_array = np.zeros(length)\n        for column in data.columns:\n            kmeans = self.kmeans[ column ]\n            cluster_score = self.cluster_score[ column ]\n            \n            assign = kmeans.predict( data[ column ].values.reshape(-1,1) )\n            #print(assign)\n            \n            for i in range(length):\n                score_array[i] = score_array[i] + math.log10( cluster_score[assign[i]] )\n            \n        return score_array\n    \n    def fit_predict(self,data):\n        self.fit(data)\n        return self.predict(data)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4b01ae31-41ab-4bef-a5f4-50c48ec510aa","_uuid":"7f79e40a4018129548da8397a2c9d83a404fe578"},"cell_type":"markdown","source":"### 2. Loading HBOS class.\nHBOS is a histogram-based anomaly detection algorithm. Below is a python implementation by me.[GitHub]https://github.com/Kanatoko/HBOS-python). Original Java implementation is available at [GitHub](https://github.com/Markus-Go/rapidminer-anomalydetection)  "},{"metadata":{"_cell_guid":"33969560-6867-4780-a626-b17926fd81a5","collapsed":true,"_uuid":"f7313ec76165e2714f51b0e5c6aca4e3bcf717da","trusted":false},"cell_type":"code","source":"import math\nimport numpy as np\nfrom pandas import DataFrame\nimport datetime\nfrom itertools import repeat\n\nclass HBOS:\n        \n    def __init__(self, log_scale=True, ranked=False, bin_info_array=[], mode_array=[], nominal_array=[]):\n        self.log_scale = log_scale\n        self.ranked = ranked\n        self.bin_info_array = bin_info_array\n        self.mode_array = mode_array\n        self.nominal_array = nominal_array\n        # self.histogram_list = []\n        \n    def fit(self, data):\n        attr_size = len(data.columns)\n        total_data_size = len(data)\n        \n        # init params if needed\n        if len(self.bin_info_array) == 0:\n            self.bin_info_array = list(repeat(-1, attr_size))\n        \n        if len(self.mode_array) == 0:\n            self.mode_array = list(repeat('dynamic binwidth', attr_size))\n            \n        if len(self.nominal_array) == 0:\n            self.nominal_array = list(repeat(False, attr_size))\n        \n        if self.ranked:\n            self.log_scale = False\n            \n        normal = 1.0\n        \n        # calculate standard _bin size if needed\n        for i in range(len(self.bin_info_array)):\n            if self.bin_info_array[ i ] == -1:\n                self.bin_info_array[ i ] = round(math.sqrt(len(data)))\n                \n        # initialize histogram\n        self.histogram_list = []\n        for i in range(attr_size):\n            self.histogram_list.append([])\n            \n        # save maximum value for every attribute(needed to normalize _bin width)\n        maximum_value_of_rows = data.apply(max).values\n        \n        # sort data\n        sorted_data = data.apply(sorted)\n        \n        # create histograms\n        for attrIndex in range(len(sorted_data.columns)):\n            attr = sorted_data.columns[ attrIndex ]\n            last = 0\n            bin_start = sorted_data[ attr ][ 0 ]\n            if self.mode_array[ attrIndex ] == 'dynamic binwidth':\n                if self.nominal_array[ attrIndex ] == True:\n                    while last < len(sorted_data) - 1:\n                        last = self.create_dynamic_histogram(self.histogram_list, sorted_data, last, 1, attrIndex, True)\n                else:\n                    length = len(sorted_data)\n                    binwidth = self.bin_info_array[ attrIndex ]\n                    while last < len(sorted_data) - 1:\n                        values_per_bin = math.floor(len(sorted_data) / self.bin_info_array[ attrIndex ])\n                        last = self.create_dynamic_histogram(self.histogram_list, sorted_data, last, values_per_bin, attrIndex, False)\n                        if binwidth > 1:\n                            length = length - self.histogram_list[ attrIndex ][ -1 ].quantity\n                            binwidth = binwidth - 1\n            else:\n                count_bins = 0\n                binwidth = (sorted_data[ attr ][ len(sorted_data) - 1 ] - sorted_data[ attr ][ 0 ]) / self.bin_info_array[ attrIndex ]\n                if (self.nominal_array[ attrIndex ] == True) | (binwidth == 0):\n                    binwidth = 1\n                while last < len(sorted_data):\n                    is_last_bin = count_bins == self.bin_info_array[ attrIndex ] - 1\n                    last = self.create_static_histogram(self.histogram_list, sorted_data, last, binwidth, attrIndex, bin_start, is_last_bin)\n                    bin_start = bin_start + binwidth\n                    count_bins = count_bins + 1\n    \n        # calculate score using normalized _bin width\n        # _bin width is normalized to the number of datapoints\n        # save maximum score for every attr(needed to normalize score)\n        max_score = []\n        \n        # loop for all histograms\n        for i in range(len(self.histogram_list)):\n            max_score.append(0)\n            histogram = self.histogram_list[ i ]\n            \n            # loop for all bins\n            for k in range(len(histogram)):\n                _bin = histogram[ k ]\n                _bin.total_data_size = total_data_size\n                _bin.calc_score(maximum_value_of_rows[ i ])\n                if max_score[ i ] < _bin.score:\n                    max_score[ i ] = _bin.score\n                    \n        for i in range(len(self.histogram_list)):\n            histogram = self.histogram_list[ i ]\n            for k in range(len(histogram)):\n                _bin = histogram[ k ]\n                _bin.normalize_score(normal, max_score[ i ], self.log_scale)\n                \n        # if ranked\n        \n    def predict(self, data):\n        score_array = []\n        for i in range(len(data)):\n            each_data = data.values[ i ]\n            value = 1\n            if self.log_scale | self.ranked:\n                value = 0\n            for attr in range(len(data.columns)):\n                score = self.get_score(self.histogram_list[ attr ], each_data[ attr ])\n                if self.log_scale:\n                    value = value + score\n                elif self.ranked:\n                    value = value + score\n                else:\n                    value = value * score\n            score_array.append(value)\n        return score_array\n    \n    def fit_predict(self, data):\n        self.fit(data)\n        return self.predict(data)\n                \n    def get_score(self, histogram, value):\n        for i in range(len(histogram) - 1):\n            _bin = histogram[ i ]\n            if (_bin.range_from <= value) & (value < _bin.range_to):\n                return _bin.score\n            \n        _bin = histogram[ -1 ]\n        if (_bin.range_from <= value) & (value <= _bin.range_to):\n            return _bin.score\n        return 0\n          \n    @staticmethod  \n    def check_amount(sortedData, first_occurrence, values_per_bin, attr):\n        # check if there are more than values_per_bin values of a given value\n        if first_occurrence + values_per_bin < len(sortedData):\n            if sortedData[ attr ][ first_occurrence ] == sortedData[ attr ][ first_occurrence + values_per_bin ]:\n                return True\n            else:\n                return False\n        else:\n            return False\n            \n    @staticmethod\n    def create_dynamic_histogram(histogram_list, sortedData, first_index, values_per_bin, attrIndex, isNominal):\n        last_index = 0\n        attr = sortedData.columns[ attrIndex ]\n        \n        # create new _bin\n        _bin = HistogramBin(sortedData[ attr ][ first_index ], 0, 0)\n            \n        # check if an end of the data is near\n        if first_index + values_per_bin < len(sortedData):\n            last_index = first_index + values_per_bin\n        else:\n            last_index = len(sortedData)\n    \n        # the first value always goes to the _bin\n        _bin.add_quantitiy(1)\n        \n        # for every other value\n        # check if it is the same as the last value\n        # if so\n        #   put it into the _bin\n        # if not\n        #   check if there are more than values_per_bin of that value\n        #   if so\n        #     open new _bin\n        #   if not\n        #     continue putting the value into the _bin\n        \n        cursor = first_index\n        for i in range(first_index + 1, last_index):\n            if sortedData[ attr ][ i ] == sortedData[ attr ][ cursor ]:\n                _bin.add_quantitiy(1)\n                cursor = cursor + 1\n            else:\n                if HBOS.check_amount(sortedData, i, values_per_bin, attr):\n                    break\n                else:\n                    _bin.add_quantitiy(1)\n                    cursor = cursor + 1\n                    \n        # continue to put values in the _bin until a new values arrive\n        for i in range(cursor + 1, len(sortedData)):\n            if sortedData[ attr ][ i ] == sortedData[ attr ][ cursor ]:\n                _bin.quantity = _bin.quantity + 1\n                cursor = cursor + 1\n            else:\n                break\n                \n        # adjust range of the bins\n        if cursor + 1 < len(sortedData):\n            _bin.range_to = sortedData[ attr ][ cursor + 1 ]\n        else:  # last data\n            if isNominal:\n                _bin.range_to = sortedData[ attr ][ len(sortedData) - 1 ] + 1\n            else:\n                _bin.range_to = sortedData[ attr ][ len(sortedData) - 1 ]\n                \n        # save _bin\n        if _bin.range_to - _bin.range_from > 0:\n            histogram_list[ attrIndex ].append(_bin)\n        elif len(histogram_list[ attrIndex ]) == 0:\n            _bin.range_to = _bin.range_to + 1\n            histogram_list[ attrIndex ].append(_bin)\n        else:\n            # if the _bin would have length of zero\n            # we merge it with previous _bin\n            # this can happen at the end of the histogram\n            lastBin = histogram_list[ attrIndex ][ -1 ]\n            lastBin.add_quantitiy(_bin.quantity)\n            lastBin.range_to = _bin.range_to\n        \n        return cursor + 1\n\n    @staticmethod\n    def create_static_histogram(histogram_list, sorted_data, first_index, binwidth, attrIndex, bin_start, last_bin):\n        attr = sorted_data.columns[ attrIndex ]\n        _bin = HistogramBin(bin_start, bin_start + binwidth, 0)\n        if last_bin == True:\n            _bin = HistogramBin(bin_start, sorted_data[ attr ][ len(sorted_data) - 1 ], 0)\n        \n        last = first_index - 1\n        cursor = first_index\n        \n        while True:\n            if cursor >= len(sorted_data):\n                break\n            if sorted_data[ attr ][ cursor ] > _bin.range_to:\n                break\n            _bin.quantity = _bin.quantity + 1\n            last = cursor\n            cursor = cursor + 1\n            \n        histogram_list[ attrIndex ].append(_bin)\n        return last + 1                 \n       \n\nclass HistogramBin:\n\n    def __init__(self, range_from, range_to, quantity):\n        self.range_from = range_from\n        self.range_to = range_to\n        self.quantity = quantity\n        self.score = 0\n        self.total_data_size = 0\n        \n    def get_height(self):\n        width = self.range_to - self.range_from\n        height = self.quantity / width\n        return height\n    \n    def add_quantitiy(self, anz):\n        self.quantity = self.quantity + anz\n        \n    def calc_score(self, max_score):\n        if max_score == 0:\n            max_score = 1\n        \n        if self.quantity > 0:\n            self.score = self.quantity / ((self.range_to - self.range_from) * self.total_data_size / abs(max_score))\n        \n    def normalize_score(self, normal, max_score, log_scale):\n        self.score = self.score * normal / max_score\n        if(self.score == 0):\n            return\n        self.score = 1 / self.score\n        if log_scale:\n            self.score = math.log10(self.score)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c8e8e60c-cd30-4b64-860c-6990367a531a","_uuid":"d98e32ff8bd548e1224cd6fa05a53ae9947af607"},"cell_type":"markdown","source":"### 3. Prepare to use Isolation Forest"},{"metadata":{"_cell_guid":"06ad457b-67ef-46fd-b2e6-c489f806e904","collapsed":true,"_uuid":"9eba6a7b48ce6d96b5d789a6c431fb88b8ff36d2","trusted":false},"cell_type":"code","source":"from sklearn.ensemble import IsolationForest","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"28533740-f527-48aa-8e43-5033458415e4","_uuid":"e488f13469a72753df6e2e47cea6a49162fc5777"},"cell_type":"markdown","source":"### 4. Loading data"},{"metadata":{"_cell_guid":"9b6d7088-3c29-40f4-83ce-1352d66f439c","collapsed":true,"_uuid":"4d53ab5e81d8756dfe612d7b52c8c05ea044e0f2","trusted":false},"cell_type":"code","source":"import pandas as pd\ndataset = pd.read_csv( \"../input/creditcard.csv\")\norig = dataset.copy()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79e25c92-c17a-4ab5-a995-349cc1780392","_uuid":"a3cb29aa412be0879e0dde6d1ee568916449ffd9"},"cell_type":"markdown","source":"### 5. Preview dataset"},{"metadata":{"_cell_guid":"bfb169c4-d4df-487a-8d11-a62f12829a81","collapsed":true,"_uuid":"f66702de60c270b9d20501a1494490f38686aefd","trusted":false},"cell_type":"code","source":"dataset[:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d669684c-5557-4d06-a535-24e5f08efaca","_uuid":"b1bb4276f5ad4995b0844c0fe476540b4c5e262d"},"cell_type":"markdown","source":"### 6. Remove labels for unsupervised learning"},{"metadata":{"_cell_guid":"8e297561-2f09-4d63-94b6-380ba3618820","collapsed":true,"_uuid":"5a5dfc5123d65ea996f22466b062bdf24a7aee92","trusted":false},"cell_type":"code","source":"del dataset['Time']\ndel dataset['Amount']\ndel dataset['Class']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"049f7ef0-0c10-406c-bb7b-4762ecc5ae80","_uuid":"d5c47a3dc5c7c5ee33e5f9154f23a329970f21d6"},"cell_type":"markdown","source":"### 7. View dataset"},{"metadata":{"_cell_guid":"b6a72393-c1ea-4ebd-a370-7665e21e0f8b","collapsed":true,"_uuid":"c3757f69318028aae1915bcf7916fa5b120ec2cf","trusted":false},"cell_type":"code","source":"dataset[:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ff54b382-f5d7-4a23-bf3b-9fed5b56ca04","_uuid":"6c657ac3d7b6c88dfcad2d36c190ea379a9da88e"},"cell_type":"markdown","source":"Now the dataset contains only V1,V2....V28 columns. ( No labels )"},{"metadata":{"_cell_guid":"611fc68b-92d9-4141-81e7-7212b18258c7","_uuid":"e06178a66a54d1e438fe9ac9d59771c59eac9477"},"cell_type":"markdown","source":"### 8. Execute HBOS"},{"metadata":{"_cell_guid":"c845ea7e-e634-4751-bdb1-4b585171953a","collapsed":true,"_uuid":"bd7638664164612db830cb9267415e4b6a03af77","trusted":false},"cell_type":"code","source":"hbos = HBOS()\nhbos_result = hbos.fit_predict(dataset)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fc8e7696-b980-40a4-b7d2-287731089cbe","_uuid":"eb36fc6729563e4d9683e6a7d3519ad02cb318c8"},"cell_type":"markdown","source":"#### 8.1 View HBOS result\nIn HBOS, The higher the score, the more it is abnormal."},{"metadata":{"_cell_guid":"693cb7a4-bbcb-4091-99e8-34cc3f8a9211","collapsed":true,"_uuid":"cf6b9c2dae47d27b5b9f6f3b99ab9bfbf4cada9b","trusted":false},"cell_type":"code","source":"hbos_result[:12]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1232d0bd-7077-45e4-8901-41d34c3ce71e","_uuid":"e5a0562c900954e0600cfb434a6d989c3a9f38aa"},"cell_type":"markdown","source":"#### 8.2 Merge HBOS result with labeld data( orig ) for evaluation"},{"metadata":{"_cell_guid":"79612b9a-d260-43fc-a55c-1402a94e71bd","collapsed":true,"_uuid":"a4be54a5a8db44fdcbb4f793a2cb4b2a251246c8","trusted":false},"cell_type":"code","source":"hbos_orig = orig.copy()\nhbos_orig['hbos'] = hbos_result","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f23a1f76-f0ce-4e9f-9d07-462a81d71306","_uuid":"4844b10711bf965dcea9daf61737937c720d644e"},"cell_type":"markdown","source":"#### 8.3 View merged data"},{"metadata":{"_cell_guid":"dea46f92-9c3b-44f2-a3ad-ba85ec9b73d6","collapsed":true,"_uuid":"2239c5c217fdf419b5672079ea1321aecb68d39a","trusted":false},"cell_type":"code","source":"hbos_orig[:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b395bf04-5633-45f5-bb08-7a0c1c263d40","_uuid":"06e579203ef773adfada1cf43cfe97b4bf31194a"},"cell_type":"markdown","source":"You can see that the 'hbos' column(anomaly score of HBOS) is added on the right."},{"metadata":{"_cell_guid":"1e0eb3bf-0a6b-4c64-845a-61321b88336d","_uuid":"a02938572efea323661f5257b75ce5b59217057b"},"cell_type":"markdown","source":"#### 8.4 Sort by HBOS anomaly score and take top 1000 data for evaluation"},{"metadata":{"_cell_guid":"cf6c006a-f8bd-4632-b943-956ffbb457cc","collapsed":true,"_uuid":"cde0943567e40718db7b0d87804dc430e1505815","trusted":false},"cell_type":"code","source":"hbos_top1000_data = hbos_orig.sort_values(by=['hbos'],ascending=False)[:1000]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0057244b-314f-4b68-93c8-c146ce4467e9","_uuid":"6889ee8551660f6670b6c6f1c49175fe64e577c4"},"cell_type":"markdown","source":"#### 8.5 View hbos_top1000_data"},{"metadata":{"_cell_guid":"082296cc-89b8-4946-aa3b-186003cc0ab5","collapsed":true,"_uuid":"2f50518bc27fb858287a5f2b626d1cc82793f1d7","trusted":false},"cell_type":"code","source":"hbos_top1000_data[:15]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b511bf14-00b1-4b3c-b7b9-80972a312c42","_uuid":"69baebc30379d3fd1ac025fcefa8bc28d4bd14e0"},"cell_type":"markdown","source":"We can see that 4 anomalies(Class=1) are there."},{"metadata":{"_cell_guid":"b5b4033a-3367-484f-85cb-7799252ebf04","_uuid":"78e6da53ad71556573d37c22e79a3a1772b99d9f"},"cell_type":"markdown","source":"#### 8.6 How many anomalies can we find in the top 1000 data?"},{"metadata":{"_cell_guid":"2e1c94bc-349d-47a1-b181-2869bfb95e4a","collapsed":true,"_uuid":"86730640ee09dd043515310bba3112abb176cde4","trusted":false},"cell_type":"code","source":"print(len(hbos_top1000_data[lambda x:x['Class']==1]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f220c21c-77f2-4e98-8bdb-4c9c557459ad","_uuid":"8203dab5a7bd34edd9a053137d427a284259add6"},"cell_type":"markdown","source":"#### 8.7 Calculate AUC-ish score and plot 'How many anomalies can we find in the top N data ( N=1... 1000 )?'"},{"metadata":{"_cell_guid":"4b6a732a-64e1-47ad-97b6-30f1a55946e8","collapsed":true,"_uuid":"7f4ec2a5cd1029411740908a5a21fcc63a033e6a","trusted":false},"cell_type":"code","source":"from matplotlib import pyplot as plt\nprint(hbos_top1000_data['Class'].cumsum().sum())\nplt.scatter(range(1000),hbos_top1000_data['Class'].cumsum(),marker='1')\nplt.xlabel('Top N data')\nplt.ylabel('Anomalies found')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"848801fe-0246-4a52-853f-de1855da1b37","_uuid":"a0f6a9d684d00cbc89d6d629b2d52eb78a259a33"},"cell_type":"markdown","source":"### 9 Execute XBOS"},{"metadata":{"_cell_guid":"05f2dec6-1e8b-40b7-b404-bb90ca08cef2","_uuid":"5e38149b730a0c56144d6d3dee95a2ba3b525ccf"},"cell_type":"markdown","source":"#### 9.1 Execute XBOS as same as HBOS"},{"metadata":{"_cell_guid":"7ed03721-e584-43ac-9f66-9a50af95d6a9","collapsed":true,"_uuid":"59b8c46d3c932ec26f6e0f6a715c298981f34874","trusted":false},"cell_type":"code","source":"xbos = XBOS(n_clusters=15,max_iter=1)\nxbos_result = xbos.fit_predict(dataset)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"50ef4135-d6ea-40cb-bb13-534054833e3d","_uuid":"a45cd6ac066599e6def9729f894f8b79bc27ee2c"},"cell_type":"markdown","source":"#### 9.2 View XBOS result\nIn XBOS, The lower the score, the more it is abnormal."},{"metadata":{"_cell_guid":"f79d453b-1112-414a-ac3e-7fba1ff206e7","collapsed":true,"_uuid":"0e3eac130919076218f668f7aa52b0a093373da7","trusted":false},"cell_type":"code","source":"xbos_result[:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c0af6f9c-7b72-4c78-aa25-ae30f8572535","_uuid":"3174a418ad388bd2e0b6844221796e105fa6a024"},"cell_type":"markdown","source":"#### 9.3 Merge XBOS result with labeled data for evaluation"},{"metadata":{"_cell_guid":"c79a10a4-b46f-40ce-a3b6-268a4856c7f5","collapsed":true,"_uuid":"943c9257352c7648c573466b7fd00cf6c02cff03","trusted":false},"cell_type":"code","source":"xbos_orig = orig.copy()\nxbos_orig['xbos'] = xbos_result","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0d771af6-86c9-45a0-99ac-342ec77df12f","_uuid":"e11f0308826574d178fe707ffa95a75be74d456a"},"cell_type":"markdown","source":"#### 9.4 View merged data"},{"metadata":{"_cell_guid":"2fd36b65-ac7c-4c0b-97b9-f3231f8b784e","collapsed":true,"_uuid":"6ffd53eba777729031be058f6e087903d57a6d79","trusted":false},"cell_type":"code","source":"xbos_orig[:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"124d15af-c8f4-4baf-bd0d-f9e391c8780c","_uuid":"484ae3d87edcdbdc474ceb53c1dc9bfc2fc66b4a"},"cell_type":"markdown","source":"You can see that the 'xbos' column(anomaly score of XBOS) is added on the right."},{"metadata":{"_cell_guid":"abed7e1e-633a-4cf6-b2a3-790379334653","_uuid":"652f5e36a151c2a68d4676d51e1de2bcb101d026"},"cell_type":"markdown","source":"#### 9.5 Sort by XBOS anomaly score and take top 1000 data for evaluation"},{"metadata":{"_cell_guid":"2e3f9e76-bfe3-4949-87eb-7b803b0b2e55","collapsed":true,"_uuid":"7312205265e0b7ccdfd7a525ac4b7829046a0777","trusted":false},"cell_type":"code","source":"xbos_top1000_data=xbos_orig.sort_values(by=['xbos'],ascending=True)[:1000]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4181704c-5ff6-46df-80ff-2608556cbb39","_uuid":"4b53b66bf87a29f06933afe071f98ac4f8ade5ad"},"cell_type":"markdown","source":"#### 9.6 View XBOS top 1000 data"},{"metadata":{"_cell_guid":"bca58a57-2775-43b7-8a8c-d00507370602","collapsed":true,"_uuid":"70e63e941c407a773b5d3c694d54aeab0f2e9182","trusted":false},"cell_type":"code","source":"xbos_top1000_data[:15]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"559eda6b-3657-499e-bec0-5ad1558b2f1f","_uuid":"74f21560b69b6b4fb5913e21ad24dc64c7adbe34"},"cell_type":"markdown","source":"We can see that 12 anomalies(Class=1) are there."},{"metadata":{"_cell_guid":"106224fc-2d5d-4ce2-b5c0-2f97a184a5e5","_uuid":"fa1a431f084a13232eb893ff5de1629af7111877"},"cell_type":"markdown","source":"#### 9.5 How many anomalies can we find in the top 1000 data?"},{"metadata":{"_cell_guid":"8412a708-6f3c-474e-af84-19a0707af162","collapsed":true,"_uuid":"27830a2e7021952ed72d7f396114c5fe615510b6","trusted":false},"cell_type":"code","source":"len(xbos_top1000_data[lambda x:x['Class']==1])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a762672b-ccd0-408e-85ae-d8247377e68c","_uuid":"e68d5ee56adefa9c2bb9c9b2d4bef7a1e443a7d9"},"cell_type":"markdown","source":"#### 9.6 Calculate AUC-ish score and plot 'How many anomalies can we find in the top N data ( N=1... 1000 )?'"},{"metadata":{"scrolled":false,"_cell_guid":"1e4c0495-5692-483c-a750-757a7b8b5372","collapsed":true,"_uuid":"17447a6f9acdc95f9d2b0a214b4b0e5907dae25f","trusted":false},"cell_type":"code","source":"print(xbos_top1000_data['Class'].cumsum().sum())\nplt.scatter(range(1000),xbos_top1000_data['Class'].cumsum(),marker='1')\nplt.xlabel('Top N data')\nplt.ylabel('Anomalies found')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6af1fcfc-b3d2-45d2-922f-e9b86bf98a41","_uuid":"439cec35b449e451d00f6c207a55963d1239010d"},"cell_type":"markdown","source":"### 10 Execute Isolation Forest"},{"metadata":{"_cell_guid":"094f5bae-3942-4f08-a9a0-580f7fbcf693","_uuid":"e55f8e69ea35a67bfcf1b504b45e131115f89959"},"cell_type":"markdown","source":"#### 10.1 Execute Isolation forest"},{"metadata":{"_cell_guid":"d255b361-0f02-4b4f-bd13-82870c978873","collapsed":true,"_uuid":"7149246923ce7c339eb51654d46b8d7bbe46dbb4","trusted":false},"cell_type":"code","source":"iforest = IsolationForest()\niforest.fit(dataset)\niforest_result = iforest.decision_function(dataset)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"56b8e9bc-8982-45e6-8a51-95a97de85c9d","_uuid":"88bce398117d90cb49c874d0a77afd4bc7a89340"},"cell_type":"markdown","source":"#### 10.2 View IF result\nIn Isolation Forest, The lower the score, the more it is abnormal."},{"metadata":{"_cell_guid":"2e9c9962-5006-4ae0-add9-e26dd53497c0","collapsed":true,"_uuid":"5313ae1efa4017827cead6d35825683ea8719082","trusted":false},"cell_type":"code","source":"iforest_result[:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5db45bf1-bfbb-4186-8657-9218a9759e67","_uuid":"a24011819be82f2a75869794ba7bcddce7e7a14e"},"cell_type":"markdown","source":"#### 10.3 Merge IF result with labeled data for evaluation"},{"metadata":{"_cell_guid":"0169b6b8-d597-4c46-8f24-02b79a3e956b","collapsed":true,"_uuid":"47214a95debb12653fa6a47f9f7ab308c764d9f2","trusted":false},"cell_type":"code","source":"iforest_orig = orig.copy()\niforest_orig['if'] = iforest_result","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5c5b93d8-916b-4cdf-bf38-fe39ff2fce5b","_uuid":"29a9cf5e732132b162fe7a96c11d928119d38281"},"cell_type":"markdown","source":"#### 10.4 View merged data"},{"metadata":{"_cell_guid":"f57b6468-5dd4-499c-9ec8-3fdd66520e38","collapsed":true,"_uuid":"38a4ab977b23fb3bda95cacd62cbd594f7f947f7","trusted":false},"cell_type":"code","source":"iforest_orig[:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fee3f5bf-4c9d-4cc8-ad0c-77fad34834bb","_uuid":"12a1769343d3dcffdd9e1eb9bcb6fd183fe80e82"},"cell_type":"markdown","source":"You can see that the 'if' column(anomaly score of Isolation Forest) is added on the right."},{"metadata":{"_cell_guid":"4c1960ba-ad24-4733-98ef-41e00670fe14","_uuid":"76817e673b506fd42be9507de35a667e852e249a"},"cell_type":"markdown","source":"#### 10.5 Sort by IF anomaly score and take top 1000 data for evaluation"},{"metadata":{"_cell_guid":"81cc4371-1453-427e-95b5-9ee952875f15","collapsed":true,"_uuid":"6085316b48ba95e1a1a5237dad1ca3433b841409","trusted":false},"cell_type":"code","source":"iforest_top1000_data=iforest_orig.sort_values(by=['if'],ascending=True)[:1000]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"585832ef-7dd9-49b5-a358-411842155bf4","_uuid":"6cdbb5c549d3c61adc12e90eebf50248e2ff1338"},"cell_type":"markdown","source":"#### 10.6 View IF top 1000 data"},{"metadata":{"_cell_guid":"cb4f4692-293a-43f1-b9ab-4c4f6059237d","collapsed":true,"_uuid":"245908309171a5447be88b38b12c0cd9739fe3b3","trusted":false},"cell_type":"code","source":"iforest_top1000_data[:15]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7eec4d03-7d94-4d36-998c-33b1c01c7d62","_uuid":"a92dbc9c3f31928ffd969039924e77c351a56b3e"},"cell_type":"markdown","source":"We can see that 10 anomalies(Class=1) are there."},{"metadata":{"_cell_guid":"cc22f6af-9719-4e37-9d44-842d455a248c","_uuid":"1e8803b6a463cc62b4279a2a9b82591473528775"},"cell_type":"markdown","source":"#### 10.5 How many anomalies can we find in the top 1000 data?"},{"metadata":{"_cell_guid":"f5a2a256-bc14-4ccb-a365-a84a9522418a","collapsed":true,"_uuid":"2f000c3cc2c4873484aeccd6c93f8a89e63b9e5e","trusted":false},"cell_type":"code","source":"len(iforest_top1000_data[lambda x:x['Class']==1])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"11f47b16-d407-4906-91a7-1ce3f215a01b","_uuid":"59dd751959e0dec388fa7765cf4dec0bc63b014b"},"cell_type":"markdown","source":"#### 10.6 Calculate AUC-ish score and plot 'How many anomalies can we find in the top N data ( N=1... 1000 )?'"},{"metadata":{"scrolled":false,"_cell_guid":"4ab0ee22-a992-4d2c-b232-cdc5d401c6f5","collapsed":true,"_uuid":"6014a31ad1cd43c699e1e2533c1dc368a33933de","trusted":false},"cell_type":"code","source":"print(iforest_top1000_data['Class'].cumsum().sum())\nplt.scatter(range(1000),iforest_top1000_data['Class'].cumsum(),marker='1')\nplt.xlabel('Top N data')\nplt.ylabel('Anomalies found')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6cb96ab2-48cd-46a0-8461-0ec61f6442f0","_uuid":"e90ff02a39bfae21b486ff2dd08ed56471cd5a0c"},"cell_type":"markdown","source":"### 11 Compare XBOS / HBOS / Isolation Forest"},{"metadata":{"_cell_guid":"0ec487be-240f-4677-a40d-951849095684","_uuid":"4ba29a3f9453b3350a6f24187c5e9164139084d6","trusted":false,"collapsed":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nplt.scatter(range(1000),hbos_top1000_data['Class'].cumsum(),marker='1',label='HBOS')\nplt.scatter(range(1000),xbos_top1000_data['Class'].cumsum(),marker='1',label='XBOS')\nplt.scatter(range(1000),iforest_top1000_data['Class'].cumsum(),marker='1',label='IForest')\nplt.xlabel('Top N data')\nplt.ylabel('Anomalies found')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a0882e8c-2a14-4bda-9a4d-279a1e9a2d8f","_uuid":"72d32e9aa2b7dc4cc0da97a6a753884eb2d1d338"},"cell_type":"markdown","source":"XBOS shows good performance."},{"metadata":{"_cell_guid":"3c10fdb4-6325-4ebc-b7a3-ac4c72a0a96f","collapsed":true,"_uuid":"67ae28a57ade9ea14d62b3e9f12bb2e416197179","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}