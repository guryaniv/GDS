{"cells":[
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "%matplotlib inline\npd.set_option(\"max_rows\", 10)\nnp.set_printoptions(suppress=True)\n\nfrom seaborn import set_style\nset_style(\"darkgrid\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "train.head()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "train.info()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "train.describe()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "train.columns.equals(test.columns)\ntrain.columns.difference(test.columns)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "train[[\"Id\", \"Response\"]]\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "type(train[[\"Response\"]])"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "type(train[\"Response\"])"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "ax = train.groupby(\"Response\").size().plot(kind=\"barh\", figsize=(8, 8))\n\n# ax.set_xticklabels([])  # turn off x tick labels\n\n# resize y label\nylabel = ax.yaxis.get_label()\nylabel.set_fontsize(24)\n\n# resize x tick labels\nlabels = ax.yaxis.get_ticklabels()\n[label.set_fontsize(20) for label in labels];\n\n# resize y tick labels\nlabels = ax.xaxis.get_ticklabels()\n[label.set_fontsize(20) for label in labels]\n[label.set_rotation(-45) for label in labels];"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "g = sns.factorplot(\"Ins_Age\", \"BMI\", hue=\"Response\", col=\"Product_Info_2\", data=train)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn.cross_validation import cross_val_score\nfrom sklearn.cross_validation import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nimport numpy as np"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# combine train and test\nall_data = train.append(test)\n\n# Found at https://www.kaggle.com/marcellonegro/prudential-life-insurance-assessment/xgb-offset0501/run/137585/code\n# create any new variables    \nall_data['Product_Info_2_char'] = all_data.Product_Info_2.str[0]\nall_data['Product_Info_2_num'] = all_data.Product_Info_2.str[1]\n\n# factorize categorical variables\nall_data['Product_Info_2'] = pd.factorize(all_data['Product_Info_2'])[0]\nall_data['Product_Info_2_char'] = pd.factorize(all_data['Product_Info_2_char'])[0]\nall_data['Product_Info_2_num'] = pd.factorize(all_data['Product_Info_2_num'])[0]\n\nall_data['BMI_Age'] = all_data['BMI'] * all_data['Ins_Age']\n\nmed_keyword_columns = all_data.columns[all_data.columns.str.startswith('Medical_Keyword_')]\nall_data['Med_Keywords_Count'] = all_data[med_keyword_columns].sum(axis=1)\n\nall_data.fillna(-1, inplace=True)\n\n# fix the dtype on the label column\nall_data['Response'] = all_data['Response'].astype(int)\n\n# split train and test\ntrain = all_data[all_data['Response']>0].copy()\ntest = all_data[all_data['Response']<1].copy()\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn.cross_validation import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train, train['Response'], test_size=0.20, random_state=1)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\n\npipe_lr = Pipeline([('scl', StandardScaler()),\n            ('clf', LogisticRegression(random_state=1))])\n\npipe_lr.fit(X_train, y_train)\nprint('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))\ny_pred = pipe_lr.predict(X_test)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "submission = pd.DataFrame({\n        \"Id\": X_test[\"Id\"],\n        \"Response\": y_pred\n    })\nsubmission.to_csv('prudential_logisticRegression.csv', index=False)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "import numpy as np\nfrom sklearn.cross_validation import StratifiedKFold\n\nkfold = StratifiedKFold(y=y_train, \n                        n_folds=10,\n                        random_state=1)\n\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn.preprocessing import Imputer\nfrom sklearn.cross_validation import StratifiedKFold\n\nimp = Imputer(missing_values='NaN', strategy='median', axis=1) \nimp.fit(y_train)\n\ny_train = imp.fit_transform(y_train)\nkfold = StratifiedKFold(y=y_train, \n                        n_folds=10,\n                        random_state=1)\nscores = []\nfor k, (traink, testk) in enumerate(kfold):\n    a = X_train.iloc[traink]\n\n    b = y_train[traink]\n    c = X_train.iloc[testk]\n    d = y_train[testk]\n    pipe_lr.fit(a,b)\n    score = pipe_lr.score(c,d)\n    scores.append(score)\n    print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1, np.bincount(y_train[train]), score))\n    \nprint('\\nCV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
 }
],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}, "nbformat": 4, "nbformat_minor": 0}