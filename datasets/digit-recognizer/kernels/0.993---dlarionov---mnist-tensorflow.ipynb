{"cells":[{"metadata":{"_cell_guid":"9acdd291-1de1-4abb-a42b-a79290ea32b8","_uuid":"f6c4aa09e3d2817b56157413340bc0c3ea398e35"},"cell_type":"markdown","source":"MNIST TensorFlow solution with LeNet5 like network, learning rate decay, dropout and data augmentation."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\n\nimport tensorflow as tf\n\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n%matplotlib inline","execution_count":35,"outputs":[]},{"metadata":{"_cell_guid":"7c81e8b3-cf44-4d26-acf9-20a8db621968","_uuid":"e9e13df92d667d1c6839f20ade60527272e902ad","collapsed":true,"trusted":true},"cell_type":"code","source":"image_size = 28\nnum_labels = 10\nnum_channels = 1 # grayscale","execution_count":36,"outputs":[]},{"metadata":{"_cell_guid":"3e70fa62-d482-4f90-99ad-773fe17375ee","_uuid":"4245f2a4976fcf49b1ad2d6c49655b4514be2354","collapsed":true,"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')","execution_count":37,"outputs":[]},{"metadata":{"_cell_guid":"2d846da7-9543-421d-a0a0-1c8fff97dc34","_uuid":"856a2899e76161be0df7f83485830b798919c861"},"cell_type":"markdown","source":"Separate labels from *train_data*"},{"metadata":{"_cell_guid":"4dbec4e9-c9ce-4d45-9d4a-e639d4447f8b","_uuid":"1d6e9785a41691188cb1fb2326fd5e3f0c9a85ba","collapsed":true,"trusted":true},"cell_type":"code","source":"digit_labels = train_data[\"label\"]\ntrain_data = train_data.drop(labels = [\"label\"], axis = 1)","execution_count":38,"outputs":[]},{"metadata":{"_cell_guid":"6b1b65a1-ff8f-4b17-9577-ab773a88166f","_uuid":"487042ab239472b35cb3567f44f409f2b2fba1b2"},"cell_type":"markdown","source":"Convert labels to one-hot vector"},{"metadata":{"_cell_guid":"a0b01f87-0a53-477e-b028-3699ef8bb21d","_uuid":"309c016156bb6b6e6f77efdedd683816ab9641fb","trusted":true,"collapsed":true},"cell_type":"code","source":"Y = (np.arange(num_labels) == digit_labels[:,None]).astype(np.float32)","execution_count":39,"outputs":[]},{"metadata":{"_cell_guid":"c9f50db3-3e8c-4e11-be78-5ac9b6f2a273","_uuid":"8c7da0d5da94838bb8db58c6c126d9345e733461","trusted":true},"cell_type":"code","source":"print(digit_labels.shape)\nprint(Y.shape)","execution_count":40,"outputs":[]},{"metadata":{"_cell_guid":"cf888c6b-1310-4f29-b766-edda7a30d0c1","_uuid":"417531db87dafa1ef5304b8ad78b758514c6b102"},"cell_type":"markdown","source":"Reshape train and test data to image like shape. It allows using convolutions."},{"metadata":{"_cell_guid":"e47313fc-0e71-485a-913d-d83dd958f0b5","_uuid":"8f0281ae6cdae54b10d856b84455fdc3bee25745","collapsed":true,"trusted":true},"cell_type":"code","source":"X = train_data.values.reshape(-1, image_size, image_size, num_channels).astype(np.float32)\nX_test = test_data.values.reshape(-1, image_size, image_size, num_channels).astype(np.float32)","execution_count":41,"outputs":[]},{"metadata":{"_cell_guid":"78532187-a4c6-4403-bc22-47f883464446","_uuid":"8e733912da65ff06ea69c36848d556ba43f123da"},"cell_type":"markdown","source":"Normalize train and test data"},{"metadata":{"_cell_guid":"13105a12-61f6-491e-bdaa-3fe93b2841a6","_uuid":"4f51573596d7125a62ea1dc8745ae86d861d6658","collapsed":true,"trusted":true},"cell_type":"code","source":"X = X / 255.0\nX_test = X_test / 255.0","execution_count":42,"outputs":[]},{"metadata":{"_cell_guid":"f5ea7640-dd9b-43af-815a-c3f41df730dd","_uuid":"5e55f0d3580bf8a1813cc0e8c1c551b79f66d618"},"cell_type":"markdown","source":"Plot some images with the lables (titles)"},{"metadata":{"_cell_guid":"6c8d872d-794d-4a25-b43d-fdd27d086707","_uuid":"c5f1c67d8c45970a824b934da18b941170df1eb3","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,9))\nfor i in range(50):\n    plt.subplot(5,10,1+i)\n    plt.title(digit_labels[i])\n    plt.imshow(X[i].reshape(28,28), cmap=cm.binary)","execution_count":43,"outputs":[]},{"metadata":{"_cell_guid":"e7099055-ff30-4a60-a985-11f03aab36b8","_uuid":"849d4e0fd778c8d83a1cef51f534a09824472765"},"cell_type":"markdown","source":"Data augmentation by using rotation, shear, shift and zoom."},{"metadata":{"_cell_guid":"88a73c10-350b-4222-b2bf-841ec58305cc","_uuid":"57c5bef0deb71fad667ae95ab0c0f100397325fe","collapsed":true,"trusted":true},"cell_type":"code","source":"def augment_images(data, labels, copies = 1, rotation=True, shear=True, shift=True, zoom=True):\n    augmented_data = []\n    augmented_labels = []\n    \n    for i in range (0, labels.shape[0]):\n        augmented_data.append(data[i])\n        augmented_labels.append(labels[i])\n        \n        for j in range(1, copies):            \n            img = data[i]\n            lbl = labels[i]\n                        \n            if (rotation):\n                img = tf.contrib.keras.preprocessing.image.random_rotation(img, 15, row_axis=0, col_axis=1, channel_axis=2)\n            if (shear):\n                img = tf.contrib.keras.preprocessing.image.random_shear(img, 0.1, row_axis=0, col_axis=1, channel_axis=2)\n            if (shift):\n                img = tf.contrib.keras.preprocessing.image.random_shift(img, 0.15, 0.15, row_axis=0, col_axis=1, channel_axis=2)\n            if (zoom):\n                img = tf.contrib.keras.preprocessing.image.random_zoom(img, (0.9, 1.1), row_axis=0, col_axis=1, channel_axis=2)\n            \n            augmented_data.append(img)\n            augmented_labels.append(lbl)\n    \n    return np.array(augmented_data), np.array(augmented_labels)","execution_count":44,"outputs":[]},{"metadata":{"_cell_guid":"9883a5bd-2d49-48bc-b12e-d57c8a078e82","_uuid":"f010c8eb03fc3a58a13549104d31f07382927c9c"},"cell_type":"markdown","source":"To tune augmentation parameters (like rotation angle) plot some images and their augmented copies."},{"metadata":{"_cell_guid":"1c4fa018-3d00-432b-9dbe-cbe39dd4e468","_uuid":"d56473a04cc14c9cfbbe6389623161ab1d10401c","trusted":true},"cell_type":"code","source":"x = X[:10]\ny = Y[:10]\n\nx, y = augment_images(x, y, copies=10)\n\nplt.figure(figsize=(20,20))\nfor i in range(len(x)):\n    plt.subplot(10,10,1+i)\n    plt.imshow(x[i].reshape(28,28), cmap=cm.binary)\n    \ndel x\ndel y","execution_count":45,"outputs":[]},{"metadata":{"_cell_guid":"3dd9fc34-2f9a-4893-b602-4a3c29cbe471","_uuid":"797abee7c2416b260a6ee44cb2df64e531e0f8de"},"cell_type":"markdown","source":"Augment training data by making some additional copies for each image."},{"metadata":{"_cell_guid":"b8c32fdf-3fed-429e-9b8a-ce6e10409793","_uuid":"c3594f22a928534e5bc00057722927144a2f7f5f","trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(Y.shape)","execution_count":46,"outputs":[]},{"metadata":{"_cell_guid":"f723b9ef-351f-4697-b09b-36344afd12d5","_uuid":"8c60d6f98189c7e967abf98694f5186f76967d04","collapsed":true,"trusted":true},"cell_type":"code","source":"X, Y = augment_images(X, Y, copies=7)","execution_count":47,"outputs":[]},{"metadata":{"_cell_guid":"757aa34c-54bd-4606-80a2-3b65f07df402","_uuid":"f553b96495ddfd5b7ca5edadcf1dca78006389e4","trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(Y.shape)","execution_count":48,"outputs":[]},{"metadata":{"_cell_guid":"5be75969-9598-4dab-887b-8a27ee5f0bda","_uuid":"89e7d1120c8d0b6c80f756497485c428f3ac0a20"},"cell_type":"markdown","source":"Randomly split training data and lables for training and validation sets using sklearn.model_selection"},{"metadata":{"_cell_guid":"96f277da-8db7-4c28-9a11-a1e336d80063","_uuid":"4d96d7f745086d12eb8a3c852fdb2e3c283cce27","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\n\nX_train, X_valid, Y_train, Y_valid = model_selection.train_test_split(X, Y, test_size=0.1, random_state = 42)","execution_count":49,"outputs":[]},{"metadata":{"_cell_guid":"39738d37-61b9-4997-a7bf-20015f228318","_uuid":"9295a44bf1da842f979be1e97caeae3dca3a8e56","trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_valid.shape)\nprint(Y_valid.shape)\nprint(X_test.shape)","execution_count":50,"outputs":[]},{"metadata":{"_cell_guid":"2e0acecb-e9e1-4ceb-8fb7-c1b3364569b9","_uuid":"cb1437932f5c4f8e6b78e5b55fbfd3a56cc3c8e6","collapsed":true,"trusted":true},"cell_type":"code","source":"del train_data\ndel test_data\ndel X\ndel Y\ndel digit_labels","execution_count":51,"outputs":[]},{"metadata":{"_cell_guid":"4dcac645-1bc1-400b-9588-e61da315474b","_uuid":"c7ce057a101a83dab3cae8907e8573433d235138"},"cell_type":"markdown","source":"The model based on [codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist)"},{"metadata":{"_cell_guid":"6ba4b7b5-1284-4f89-a0dc-e27c0a01144e","_uuid":"bb790145e7ef95d8b187df7e81844d4f3a32e161","collapsed":true,"trusted":true},"cell_type":"code","source":"graph = tf.Graph()\nwith graph.as_default():\n    \n    X = tf.placeholder(tf.float32, shape=(None,image_size,image_size,num_channels))\n    Y_ = tf.placeholder(tf.float32, shape=(None,num_labels))\n    tf_step = tf.placeholder(tf.float32)\n    tf_pkeep = tf.placeholder(tf.float32)\n    \n    tf_test_dataset = tf.constant(X_test)\n    \n    K = 6  # first convolutional layer output depth\n    L = 12  # second convolutional layer output depth\n    M = 24  # third convolutional layer output depth\n    N = 200  # fully connected layer\n\n    W1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1))  # 6x6 patch, 1 input channel, K output channels\n    B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]))\n    W2 = tf.Variable(tf.truncated_normal([5, 5, K, L], stddev=0.1))\n    B2 = tf.Variable(tf.constant(0.1, tf.float32, [L]))\n    W3 = tf.Variable(tf.truncated_normal([4, 4, L, M], stddev=0.1))\n    B3 = tf.Variable(tf.constant(0.1, tf.float32, [M]))\n    W4 = tf.Variable(tf.truncated_normal([7 * 7 * M, N], stddev=0.1))\n    B4 = tf.Variable(tf.constant(0.1, tf.float32, [N]))\n    W5 = tf.Variable(tf.truncated_normal([N, 10], stddev=0.1))\n    B5 = tf.Variable(tf.constant(0.1, tf.float32, [10]))\n    \n    def model(data):\n        Y1 = tf.nn.relu(tf.nn.conv2d(data, W1, strides=[1, 1, 1, 1], padding='SAME') + B1) # output is 28x28\n        Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, 2, 2, 1], padding='SAME') + B2) # output is 14x14\n        Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, 2, 2, 1], padding='SAME') + B3)  # output is 7x7\n        Y3_flat = tf.reshape(Y3, shape=[-1, 7 * 7 * M])\n        Y4 = tf.nn.dropout(tf.nn.relu(tf.matmul(Y3_flat, W4) + B4), tf_pkeep)\n        return tf.matmul(Y4, W5) + B5\n    \n    logits = model(X)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y_))*100\n    \n    lr = 0.0001 + tf.train.exponential_decay(0.005, tf_step, 2000, 1/math.e)\n    optimizer = tf.train.AdamOptimizer(lr).minimize(loss)   \n    \n    Y = tf.nn.softmax(logits)\n    Y_test = tf.nn.softmax(model(tf_test_dataset))\n    \n    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1)), tf.float32))","execution_count":52,"outputs":[]},{"metadata":{"_cell_guid":"d4bf1239-1812-4d3c-a1d7-f7a3c02e832b","_uuid":"95e525e2e0833e46ce1bed9767721ae16a877d67"},"cell_type":"markdown","source":"Train the model with *num_steps* and *batch_size*. One epoch eqals  *train_size* / *batch_size* and this value should be less then *num_steps* (better be a multiple of it). *train_size* depends on data augmentation and number of copies."},{"metadata":{"_cell_guid":"168d2487-5a43-4431-ac39-666d3e2fdf0b","_uuid":"641a6352d42c662bc4f22e99b8257a454d8fba3f","trusted":true},"cell_type":"code","source":"num_steps = 30001\nbatch_size = 100\n\nacc = []\ncosts = []\nrates = []\n\nwith tf.Session(graph=graph) as session:\n    tf.global_variables_initializer().run()\n    \n    for step in range(num_steps):\n        offset = (step * batch_size) % (Y_train.shape[0] - batch_size)\n        batch_data = X_train[offset:(offset + batch_size), :, :, :]\n        batch_labels = Y_train[offset:(offset + batch_size), :]\n        \n        if (step % 100 == 0):\n            a, l, r = session.run([accuracy, loss, lr], feed_dict={\n                X : batch_data, \n                Y_ : batch_labels,\n                tf_pkeep : 1.0,\n                tf_step : step\n            })\n            print(str(step) + \": accuracy: \" + str(a) + \" loss: \" + str(l) + \" (lr:\" + str(r) + \")\")\n        \n        if (step % 500 == 0):\n            a, l = session.run([accuracy, loss], feed_dict={\n                X : X_valid, \n                Y_ : Y_valid,\n                tf_pkeep : 1.0\n            })\n            print(str(step) + \": validation accuracy: \" + str(a) + \" validation loss: \" + str(l))        \n        \n        _, a, l, r = session.run([optimizer, accuracy, loss, lr], feed_dict={\n            X : batch_data, \n            Y_: batch_labels,\n            tf_pkeep : 0.75,\n            tf_step : step\n        })\n        \n        if (step % 10 == 0):\n            costs.append(l)\n            rates.append(r)\n            acc.append(a)\n            \n    predictions = Y_test.eval({ tf_pkeep : 1.0 })","execution_count":53,"outputs":[]},{"metadata":{"_cell_guid":"5575817c-b06d-4893-957e-fdfec3db1257","_uuid":"56f344e7bd3f04dbe74a662bfaeabf677d5aa67c"},"cell_type":"markdown","source":"Visualize accuracy, loss and learning rate"},{"metadata":{"_cell_guid":"e41dfbc2-b369-4278-9b67-72e78bb3dfaa","_uuid":"27e7e56f1f3ceb6bdf94022c43dcc8fd873fd243","trusted":true},"cell_type":"code","source":"plt.plot(np.squeeze(acc))\nplt.ylabel('accuracy')\nplt.xlabel('iterations')\nplt.show()","execution_count":54,"outputs":[]},{"metadata":{"_cell_guid":"14193aaa-de9d-4315-843b-380e788e0816","_uuid":"a5bad876ca4f6d571273786ad39baeda832ddcaf","trusted":true},"cell_type":"code","source":"plt.plot(np.squeeze(costs))\nplt.ylabel('cost')\nplt.xlabel('iterations')\nplt.show()","execution_count":55,"outputs":[]},{"metadata":{"_cell_guid":"a5470059-3ad6-45df-a747-64fcb3f27d78","_uuid":"2a78924f71b44bc72ec740ab371c3d57e211cb54","trusted":true},"cell_type":"code","source":"plt.plot(np.squeeze(rates))\nplt.ylabel('learning rate')\nplt.xlabel('iterations')\nplt.show()","execution_count":56,"outputs":[]},{"metadata":{"_cell_guid":"a471bddb-d117-4587-93e6-2e827f0be7d4","_uuid":"f0c9a8b35a3bd8663773840e9b7ae929801267f9"},"cell_type":"markdown","source":"Export predictions to csv"},{"metadata":{"_cell_guid":"2a10af95-98ec-47c5-9714-ceff49c540f1","_uuid":"4d87d7a9ede64ef12c3ef4ebe24e5c70b3f973aa","collapsed":true,"trusted":true},"cell_type":"code","source":"results = pd.Series(np.argmax(predictions, axis = 1), name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"), results], axis = 1)\nsubmission.to_csv(\"mnist.csv\", index=False)","execution_count":57,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}