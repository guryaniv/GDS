{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3ad9a71c-829e-62cb-0ddd-7bb35a9a598e"
      },
      "source": [
        "This script adds a function to anokas script which removes feature vectors having the same values in the same order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "38b614a9-d799-4123-3788-50b75ebda07f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(1133)\n",
        "import itertools\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a3ec5e63-0bba-26d1-1546-9f77f37aaa8a"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('../input/train.csv')\n",
        "df_test = pd.read_csv('../input/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7151c826-2b17-d1ec-1696-75ee389ae2b6"
      },
      "outputs": [],
      "source": [
        "usable_columns = list(set(df_train.columns) - set(['ID', 'y']))\n",
        "\n",
        "y_train = df_train['y'].values\n",
        "id_test = df_test['ID'].values\n",
        "\n",
        "x_train = df_train[usable_columns]\n",
        "x_test = df_test[usable_columns]\n",
        "\n",
        "for column in usable_columns:\n",
        "    cardinality = len(np.unique(x_train[column]))\n",
        "    if cardinality == 1:\n",
        "        x_train.drop(column, axis=1) # Column with only one value is useless so we drop it\n",
        "        x_test.drop(column, axis=1)\n",
        "    if cardinality > 2: # Column is categorical\n",
        "        mapper = lambda x: sum([ord(digit) for digit in x])\n",
        "        x_train[column] = x_train[column].apply(mapper)\n",
        "        x_test[column] = x_test[column].apply(mapper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4ac9353b-624d-b8a4-d2c9-20c0157a32ee"
      },
      "outputs": [],
      "source": [
        "#code is from an old competition(santander)\n",
        "def remove_feat_identicals(data_frame):\n",
        "    # Find feature vectors having the same values in the same order and\n",
        "    # remove all but one of those redundant features.\n",
        "    print(\"\")\n",
        "    print(\"Delete these identical features...\")\n",
        "    n_features_originally = data_frame.shape[1]\n",
        "    # Find the names of identical features by going through all the\n",
        "    # combinations of features (each pair is compared only once).\n",
        "    feat_names_delete = []\n",
        "    for feat_1, feat_2 in itertools.combinations(\n",
        "            iterable=data_frame.columns, r=2):\n",
        "        if np.array_equal(data_frame[feat_1], data_frame[feat_2]):\n",
        "            feat_names_delete.append(feat_2)\n",
        "    feat_names_delete = np.unique(feat_names_delete)\n",
        "    # Delete the identical features\n",
        "    #data_frame = data_frame.drop(labels=feat_names_delete, axis=1)\n",
        "    n_features_deleted = len(feat_names_delete)\n",
        "    print(\"  - Delete %s / %s features (~= %.1f %%)\" % (\n",
        "        n_features_deleted, n_features_originally,\n",
        "        100.0 * (np.float(n_features_deleted) / n_features_originally)))\n",
        "    return feat_names_delete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "abe7b2bd-4a39-2bf8-52ff-0a9c3cab8986"
      },
      "outputs": [],
      "source": [
        "feature_to_delete = remove_feat_identicals(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "988ec628-98ac-21f7-89e6-14c19cc20b03"
      },
      "outputs": [],
      "source": [
        "#delete identical features \n",
        "\n",
        "\n",
        "x_train.drop(feature_to_delete, axis=1, inplace=True)\n",
        "x_test.drop(feature_to_delete, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3b109422-191c-bf16-beaf-6cffb17058d0"
      },
      "outputs": [],
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=4242)\n",
        "\n",
        "d_train = xgb.DMatrix(x_train, label=y_train)\n",
        "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
        "d_test = xgb.DMatrix(x_test)\n",
        "\n",
        "params = {}\n",
        "params['objective'] = 'reg:linear'\n",
        "params['eta'] = 0.02\n",
        "params['max_depth'] = 4\n",
        "params[\"objective\"] = \"reg:linear\"\n",
        "params[\"min_child_weight\"] = 1\n",
        "params[\"subsample\"] = 0.9\n",
        "params[\"colsample_bytree\"] = 0.8\n",
        "params[\"silent\"] = 1\n",
        "params[\"seed\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4a5a7245-d060-1d27-7a4d-0b0bda61c2a1"
      },
      "outputs": [],
      "source": [
        "\n",
        "def xgb_r2_score(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    return 'r2', r2_score(labels, preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d1c3d637-b46b-7318-e31b-9d9d2a148f22"
      },
      "outputs": [],
      "source": [
        "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
        "\n",
        "clf = xgb.train(params, d_train, 1000, watchlist, early_stopping_rounds=50, feval=xgb_r2_score, maximize=True, verbose_eval=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5294c4af-24da-280b-17ee-bb2868235547"
      },
      "outputs": [],
      "source": [
        "#do prediction\n",
        "p_test = clf.predict(d_test)\n",
        "\n",
        "sub = pd.DataFrame()\n",
        "sub['ID'] = id_test\n",
        "sub['y'] = p_test\n",
        "sub.to_csv('xgb_ord.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c70f3f47-ce12-0ac6-a5bd-9015091392fc"
      },
      "source": [
        "**Please upvote if you found this script useful!**"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}