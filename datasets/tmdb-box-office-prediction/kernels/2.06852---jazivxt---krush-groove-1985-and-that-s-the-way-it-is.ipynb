{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import *\nimport xgboost as xgb\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsub = pd.read_csv('../input/sample_submission.csv')\ntrain.shape, test.shape, sub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f28db0fb8c8d52f504c7e831ba924b94a6f55fe9"},"cell_type":"code","source":"#Additional feature columns for image or sentiment analysis, dropping for now\ntrain.drop(columns=['imdb_id', 'homepage', 'poster_path'], inplace=True)\ntest.drop(columns=['imdb_id', 'homepage', 'poster_path'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"321490240e23820cd19352734120585db03b4f9d"},"cell_type":"code","source":"def date_features(df):\n    df['release_date'] = pd.to_datetime(df['release_date'])\n    df['release_year'] = df['release_date'].dt.year\n    df['release_month'] = df['release_date'].dt.month\n    df['release_quarter'] = df['release_date'].dt.quarter\n    df['release_dow'] = df['release_date'].dt.dayofweek\n    df.drop(columns=['release_date'], inplace=True)\n    return df\n\ntrain = date_features(train)\ntest = date_features(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9c9b72463f0e9417319a052c60d90b69a15c0d5"},"cell_type":"code","source":"def get_dictionary(s):\n    try:\n        d = eval(s)\n    except:\n        d = {}\n    return d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"228586d14748f1f9d7958d56a1cdb67934ad038d"},"cell_type":"code","source":"#could test dummies but going with simple encoding\ntrain.belongs_to_collection = train.belongs_to_collection.map(lambda x: len(get_dictionary(x))).clip(0,1)\ntest.belongs_to_collection = test.belongs_to_collection.map(lambda x: len(get_dictionary(x))).clip(0,1)\n\n#pd.concat((train, train.genres.map(lambda x: sorted([d['id'] for d in get_dictionary(x)])).str.get_dummies(sep=',')), axis=1) #need to concat train/test first\ntrain.genres = train.genres.map(lambda x: sorted([d['id'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\ntest.genres = test.genres.map(lambda x: sorted([d['id'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n\ntrain.production_companies = train.production_companies.map(lambda x: sorted([d['id'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\ntest.production_companies = test.production_companies.map(lambda x: sorted([d['id'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n\ntrain.production_countries = train.production_countries.map(lambda x: sorted([d['iso_3166_1'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\ntest.production_countries = test.production_countries.map(lambda x: sorted([d['iso_3166_1'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n\ntrain.spoken_languages = train.spoken_languages.map(lambda x: sorted([d['iso_639_1'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\ntest.spoken_languages= test.spoken_languages.map(lambda x: sorted([d['iso_639_1'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n\ntrain.Keywords = train.Keywords.map(lambda x: sorted([d['id'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\ntest.Keywords = test.Keywords.map(lambda x: sorted([d['id'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n\nfor c in ['original_language', 'status', 'genres', 'production_companies', 'production_countries', 'spoken_languages', 'Keywords']:\n    lbl = preprocessing.LabelEncoder()\n    lbl.fit(list(train[c].fillna('').astype(str)) + list(test[c].fillna('').astype(str)))\n    train[c] = lbl.transform(train[c].fillna(''))\n    test[c] = lbl.transform(test[c].fillna(''))\n    print(c, len(lbl.classes_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dad59d94416e187944ce9a9e3aacc1219ef2de8b"},"cell_type":"code","source":"#dropping cast and crew but probably great graph features along with above dictionary items - analysis for another time\ntrain.drop(columns=['cast', 'crew'], inplace=True)\ntest.drop(columns=['cast', 'crew'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96e5a50398974d657638f70334d4cd468c074e3d"},"cell_type":"code","source":"#dropping text features for now\ndef standard_text_features(df):\n    for c in ['original_title', 'title', 'tagline', 'overview']:\n        df[c + '_len'] = df[c].map(lambda x: len(str(x)))\n        df[c + '_wlen'] = df[c].map(lambda x: len(str(x).split(' ')))\n    df.drop(columns=['original_title', 'title', 'tagline', 'overview'], inplace=True)\n    return df\n\ntrain = standard_text_features(train)\ntest = standard_text_features(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ca1d0c3bd2c50ce94d2822ff449bdc5ed0d3878"},"cell_type":"code","source":"col = [c for c in train.columns if c not in ['id', 'revenue']]\n\nparams = {'eta': 0.02, 'objective': 'reg:linear', 'max_depth': 6, 'subsample': 0.8, 'colsample_bytree': 0.8,  'eval_metric': 'rmse', 'seed': 1, 'silent': True}\nx1, x2, y1, y2 = model_selection.train_test_split(train[col].fillna(-1), np.log1p(train['revenue']), test_size=0.2, random_state=1)\nwatchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\nmodel = xgb.train(params, xgb.DMatrix(x1, y1), 2500,  watchlist, verbose_eval=100, early_stopping_rounds=200)\ntest['revenue'] = np.expm1(model.predict(xgb.DMatrix(test[col]), ntree_limit=model.best_ntree_limit))\ntest[['id', 'revenue']].to_csv('submission.csv', index=False)\nxgb.plot_importance(model, importance_type='weight', max_num_features=20)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}