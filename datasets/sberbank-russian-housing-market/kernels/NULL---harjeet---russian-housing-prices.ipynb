{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fc731463-8450-71bf-b59b-d8bb7b54113f"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5866e8bd-03e2-381b-93eb-2ac8cc0ef81b"
      },
      "outputs": [],
      "source": [
        "import matplotlib as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1aa099b8-9cfa-4dcf-fcfe-0c9de0db7f7d"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"../input/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eb136a48-813a-d166-86df-fc16adefc9c5"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(\"../input/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "82cf0f11-6bc1-d92a-432d-96dde650eed1"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5560ce44-0a5e-58d1-4a82-5b5452278a38"
      },
      "outputs": [],
      "source": [
        "train.isnull().sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "be212cec-dbac-94dc-56e8-b951f423716a"
      },
      "outputs": [],
      "source": [
        "macro = pd.read_csv(\"../input/macro.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "702b6a53-2f16-53a6-707e-067223ee7e44"
      },
      "outputs": [],
      "source": [
        "macro.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "31294539-d90e-43e9-865a-067bdfb13635"
      },
      "outputs": [],
      "source": [
        "train.dropna(axis=0, subset=['floor'], how='any', inplace=True)\n",
        "train.drop(train[train['floor'] == 0].index, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "88058099-d714-73ca-9c55-f0524600e4f5"
      },
      "outputs": [],
      "source": [
        "#Assuming Max_floor is equal to floor when it is not consistent.\n",
        "train['max_floor'] = train['max_floor'].fillna(0)\n",
        "train['max_floor'] = np.where(train['max_floor'] < train['floor'], train['floor'], train['max_floor'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fece6398-1eae-cc85-d809-8fefc0a4dc45"
      },
      "outputs": [],
      "source": [
        "# wierd values corrected\n",
        "train.set_value(train[train['state'] == 33].index, 'state', 4)\n",
        "train.set_value(train[train['build_year'] == 20052009].index, 'build_year', 2007)\n",
        "# 1 Outlier in full_Sq we will delete for the moment\n",
        "train.drop(train[train['full_sq'] > 2000].index, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da6282c5-99b8-6b7b-7a4d-9882a5953028"
      },
      "outputs": [],
      "source": [
        "#droping rows where lif_sq is greater than full_sq (22 records )\n",
        "train['bad_life'] = train['full_sq'] - train['life_sq']\n",
        "train.drop(train[train['bad_life'] < 0].index, inplace=True)\n",
        "\n",
        "#completing NaN values with mean ratio between Full and Life SQ\n",
        "train['r_life_ful_sq'] = train['bad_life'] / train['full_sq']\n",
        "mean_ratio = train['r_life_ful_sq'].mean()\n",
        "train.life_sq.fillna(train.full_sq *(1 - mean_ratio), inplace=True)\n",
        "\n",
        "# droping working columns\n",
        "train.drop(['bad_life', 'r_life_ful_sq'], axis=1, inplace=True)\n",
        "\n",
        "# Replacing life_sq < 5sq by mean ration full and life as for NaN\n",
        "train['life_sq'] = np.where(train['life_sq'] <=5, train['full_sq'] * (1 - mean_ratio), train['life_sq'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8c2b7c3d-1d54-822d-a017-47d09b620de8"
      },
      "outputs": [],
      "source": [
        "dftrain = pd.merge(train, macro, how='left', on='timestamp')\n",
        "dftest = pd.merge(test, macro, how='left', on='timestamp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "597c7912-0b25-49d5-6743-271c8f13a392"
      },
      "outputs": [],
      "source": [
        "# these variables are empty in test set or their feat importance is assumed small atm... \n",
        "# we will revisit later it will grow bigger for sure\n",
        "list_empty = ['grp','grp_growth','real_dispos_income_per_cap_growth', 'profitable_enterpr_share',\n",
        "              'unprofitable_enterpr_share','share_own_revenues','overdue_wages_per_cap', 'fin_res_per_cap',\n",
        "              'marriages_per_1000_cap','divorce_rate','construction_value', 'invest_fixed_assets_phys',\n",
        " 'pop_migration','pop_total_inc','housing_fund_sqm','lodging_sqm_per_cap', 'water_pipes_share', 'baths_share',\n",
        " 'sewerage_share','gas_share', 'hot_water_share', 'electric_stove_share', 'heating_share',\n",
        " 'old_house_share', 'infant_mortarity_per_1000_cap', 'perinatal_mort_per_1000_cap', 'incidence_population',\n",
        " 'load_of_teachers_preschool_per_teacher', 'child_on_acc_pre_school', 'provision_doctors',\n",
        " 'power_clinics', 'hospital_beds_available_per_cap', 'hospital_bed_occupancy_per_year',\n",
        " 'provision_retail_space_sqm', 'provision_retail_space_modern_sqm', 'theaters_viewers_per_1000_cap',\n",
        " 'museum_visitis_per_100_cap', 'population_reg_sports_share',\n",
        " 'students_reg_sports_share', 'apartment_build', 'modern_education_share', 'old_education_build_share', \n",
        "              'child_on_acc_pre_school']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "18a2421c-5348-50c4-0820-537aed571d8e"
      },
      "outputs": [],
      "source": [
        "x_train = dftrain.drop([\"id\", \"timestamp\"], axis=1)\n",
        "x_test = dftest.drop([\"id\", \"timestamp\"], axis=1)\n",
        "x_train.drop(list_empty, axis=1, inplace=True)\n",
        "x_test.drop(list_empty, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d1d349a7-9e24-e7d5-841c-5c8c68716fc4"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection,preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d133e96b-b9bf-f7e6-3d6d-008ebc1ceffc"
      },
      "outputs": [],
      "source": [
        "for c in x_train.columns:\n",
        "    if x_train[c].dtype == 'object':\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(x_train[c].values)) \n",
        "        x_train[c] = lbl.transform(list(x_train[c].values))\n",
        "        \n",
        "for c in x_test.columns:\n",
        "    if x_test[c].dtype == 'object':\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(x_test[c].values)) \n",
        "        x_test[c] = lbl.transform(list(x_test[c].values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b8a63f7a-df3e-4798-e19b-6a9e596b0a64"
      },
      "outputs": [],
      "source": [
        "def rmsle(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    assert len(preds) == len(labels)\n",
        "    labels = labels.tolist()\n",
        "    preds = preds.tolist()\n",
        "    terms_to_sum = [(math.log(labels[i] + 1) - math.log(max(0, preds[i]) + 1)) ** 2.0 for i, pred in enumerate(labels)]\n",
        "    return 'rmsle', (sum(terms_to_sum) * (1.0 / len(preds))) ** 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b0d4a14f-1fba-ed34-22f9-4e1ed24004d6"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "99d942f7-ffa8-6d58-6e8e-729de1f7b4ff"
      },
      "outputs": [],
      "source": [
        "xgb_params = {\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 8,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'objective': 'reg:linear',\n",
        "    'silent': 1\n",
        "}\n",
        "\n",
        "y_train = x_train[\"price_doc\"]\n",
        "x_train.drop('price_doc', axis=1, inplace=True)\n",
        "\n",
        "# Train/Valid split\n",
        "split = 27000\n",
        "xx_train, yy_train, xx_valid, yy_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
        "\n",
        "dtrain = xgb.DMatrix(xx_train, yy_train, feature_names=xx_train.columns.values)\n",
        "dvalid = xgb.DMatrix(xx_valid, yy_valid, feature_names=xx_valid.columns.values)\n",
        "\n",
        "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
        "model = xgb.train(dict(xgb_params), dtrain, 600, watchlist, feval=rmsle, early_stopping_rounds=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8ca45bb0-a6dc-90e8-a297-e8e804dd9548"
      },
      "outputs": [],
      "source": [
        "x_train.pr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9c6097de-1668-ce70-c434-8b9738fc82e3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}