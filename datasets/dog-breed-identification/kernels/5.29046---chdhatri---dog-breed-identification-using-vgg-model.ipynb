{"cells":[{"metadata":{"_uuid":"d81dfca1ab2c8262cdae106d2ba85ada5856f3a8"},"cell_type":"markdown","source":"**Loading packages and data**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport warnings\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n\n# keras imports\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Input\n\n# other imports\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport glob\nimport cv2\nimport h5py\nimport os\nimport datetime\nimport time\nimport re\nfrom tqdm import tqdm\n\n\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45f434e76ee5456f221d96e03d74abf89c6f1a61"},"cell_type":"markdown","source":"**Read the training images**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# path to training dataset\ntrain_path = '../input/train/'\nlabels = pd.read_csv('../input/labels.csv')\n\nmodel_dir = '../input/'\nlist_images = [train_path+f for f in os.listdir(train_path) if re.search('jpg|JPG', f)]\n\nprint(list_images[0:4])\ntrain_labels = os.listdir(train_path)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fe1a5e138aaa7d7a61de38d50bd81d6c14657d8"},"cell_type":"markdown","source":"Train samples"},{"metadata":{"trusted":true,"_uuid":"a4ec53020312b902da1253d1026911617906a5c1"},"cell_type":"code","source":"labels.head(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9d0f2b1e8b50dce67eb86386d5a3c1c82dfc022"},"cell_type":"code","source":"n = len(labels)\nbreed = set(labels['breed'])\nn_class = len(breed)\nclass_to_num = dict(zip(breed, range(n_class)))\nn_class = len(breed)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"935a1174e2fafd44bcdfe5ae6a7e2a203f149a5d"},"cell_type":"markdown","source":"number of samples in the train data"},{"metadata":{"trusted":true,"_uuid":"6e8627c163e234ea8b2b05192698da88b60c8023"},"cell_type":"code","source":"print(n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a01171ae24825de14537c862dd3de5d0858fa9a"},"cell_type":"markdown","source":"How many labels do we have?"},{"metadata":{"trusted":true,"_uuid":"3c1082b08da08e14375103d3521dd685a95e96aa"},"cell_type":"code","source":"print(n_class)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f458b886acb372a8b947c3b3ebd047f94f1fbcaa"},"cell_type":"markdown","source":"There are 120 - breeds that are available in training set "},{"metadata":{"_uuid":"d5a1682742d327fbb012ddbab7083a0ee6b0916a"},"cell_type":"markdown","source":"Breed count  per label"},{"metadata":{"trusted":true,"_uuid":"071fd0db6703ed558c1647270684db975361651b"},"cell_type":"code","source":"\nyy = pd.value_counts(labels['breed'])\nprint(yy[0:5])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63d1e6c1ca80d3d5937b80c9fb6de7f66a7d6f00"},"cell_type":"markdown","source":"Distribution of breeds"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"b3c0836e15cb0ea59e9d9a743b86b083bd3c6206"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfig, ax = plt.subplots()\nfig.set_size_inches(20,10)\nsns.set_style(\"whitegrid\")\n\nax = sns.barplot(x = yy.index, y = yy, data = labels)\nax.set_xticklabels(ax.get_xticklabels(), rotation = 90, fontsize = 10)\nax.set(xlabel='Dog Breed', ylabel='Count')\nax.set_title('Distribution of the Dog Breeds')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e871ed6fb4eabf70a87ebb9845bff05cdca81490"},"cell_type":"markdown","source":"From the above barplot we see relevant size of sample data, each breed is having count between 65-126., which seems to be reasonable size."},{"metadata":{"_uuid":"426aafdbbff69d13e11408a37f4a1b242558c03e"},"cell_type":"markdown","source":"Change the labels to one hot encodeded lables"},{"metadata":{"trusted":true,"_uuid":"0e472f8e87270d05f39ecbef2d4930cd07742f53"},"cell_type":"code","source":"targets_series = pd.Series(labels['breed'])\none_hot = pd.get_dummies(targets_series, sparse = True)\none_hot_labels = np.asarray(one_hot)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c26ec9b86c287e0fa7a8530885568d118d380b4c"},"cell_type":"markdown","source":"Resize the images"},{"metadata":{"trusted":true,"_uuid":"490697f115e15b93afb0c3c499aa02010e18ad86"},"cell_type":"code","source":"import cv2\nwidth = 224\norig_label = []\nX = np.zeros((n, width, width, 3), dtype=np.uint8)\ny = np.zeros((n, n_class), dtype=np.uint8)\norig_label = []\nfor i in tqdm(range(n)):\n    X[i] = cv2.resize(cv2.imread('../input/train/%s.jpg' % labels['id'][i]), (width, width))\n    y[i] = one_hot_labels[i]\n    orig_label.append(labels['breed'][i])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dee79c915c84a92b14092a1205af2d2af987bd2d"},"cell_type":"code","source":"print(orig_label[0:5])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"370adbb901d2eeaee7d238029655438f24ece42c"},"cell_type":"markdown","source":"How many samples and lables do we have"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"d4ac3eb03efdaeb0ef90fe0ae28b76a42c9524f9"},"cell_type":"code","source":"print(\"Number of Samples:\",X.shape[0])\nprint(y.shape)\nnum_class = y.shape[1]\nprint(\"Number of training lables:\",num_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd8d5ee1d70276a7ff90c3160006d5cafbc5b5a5"},"cell_type":"code","source":"import random\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nplt.figure(figsize=(12, 6))\nfor i in range(8):\n    random_index = random.randint(0, n-1)\n    plt.subplot(2, 4, i+1)\n    plt.imshow(X[random_index][:,:,::-1])\n    plt.title(orig_label[random_index])\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3565e9d862b808429447cde08a836832c1ee25ff"},"cell_type":"markdown","source":"Normalize the train data"},{"metadata":{"_uuid":"0001ab8de7d80ad125564199166f720e2ab101ae"},"cell_type":"markdown","source":"**Read the test data**"},{"metadata":{"trusted":true,"_uuid":"ebba331449a13815e344ad60f5adce18f55619ee"},"cell_type":"code","source":"df_test = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df814dd3a1a2529604d1e64b558f71ea03aa7a80"},"cell_type":"markdown","source":"**Load test images**"},{"metadata":{"_uuid":"95f39c36ee5a50d168a6b5cdb3d32d60b8a305e5"},"cell_type":"markdown","source":"Resize the test images same as train"},{"metadata":{"trusted":true,"_uuid":"9757d18f510bdfd0e5a8cd9c1fa456c0349ffd62"},"cell_type":"code","source":"n_test = len(df_test)\nX_test = np.zeros((n_test, width, width, 3), dtype=np.uint8)\nfor i in tqdm(range(n_test)):\n    X_test[i] = cv2.resize(cv2.imread('../input/test/%s.jpg' % df_test['id'][i]), (width, width))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c47114ac092af1e4cf51854d6a0c885f8a92b4f8"},"cell_type":"code","source":"print(len(X_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"134d9122bccada2b20fbd9b19ef66e7084ccbee8"},"cell_type":"markdown","source":"**Feature Extraction using VGG**"},{"metadata":{"trusted":true,"_uuid":"28a9bfccf6131b22510ac2455022e04859714741"},"cell_type":"code","source":"from keras.layers import *\nfrom keras.models import *\nfrom keras.applications import *\nfrom keras.optimizers import *\nfrom keras.regularizers import *\n\ndef get_features(MODEL, data=X):\n    cnn_model = MODEL(include_top=False, input_shape=(width, width, 3), weights='imagenet')\n    \n    inputs = Input((width, width, 3))\n    x = inputs\n    x = Lambda(preprocess_input, name='preprocessing')(x)\n    x = cnn_model(x)\n    x = GlobalAveragePooling2D()(x)\n    cnn_model = Model(inputs, x)\n\n    features = cnn_model.predict(data, batch_size=64, verbose=1)\n    return features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"890882e3a10cf393cf743dcc49d9b1aa7d7c6b37"},"cell_type":"code","source":"vgg16_features = get_features(VGG16, X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f6f58f8c79cf141ddf62a9bfd9f3ed88e237986"},"cell_type":"code","source":"inputs = Input(vgg16_features.shape[1:])\nx = inputs\nx = Dropout(0.5)(x)\nx = Dense(n_class, activation='softmax')(x)\nmodel = Model(inputs, x)\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nh = model.fit(vgg16_features, y, batch_size=128, epochs=10, validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c38d02f65dfc9e0255eb70fa0419da5e781f572c"},"cell_type":"code","source":"vgg16_feature_test = get_features(VGG16, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb401b612d368fec244e9eba8f16384bf3aec265"},"cell_type":"code","source":"y_pred = model.predict(vgg16_feature_test, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e39d8e8809b4818f3b83ea9191156f20ea003e23"},"cell_type":"code","source":"for b in breed:\n    df_test[b] = y_pred[:,class_to_num[b]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1934e9d840dabddaedffce343960e643b822ea3"},"cell_type":"code","source":" \ndf_test.to_csv('submission.csv', index=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}