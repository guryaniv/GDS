{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"path = '../input/'\nhist = pd.read_csv(path + 'historical_transactions.csv', parse_dates = ['purchase_date'])\nnew = pd.read_csv(path + 'new_merchant_transactions.csv', parse_dates = ['purchase_date'])\nmerchant = pd.read_csv(path + 'merchants.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e10d8b944006cd29dfbe82439e2f539ed1e0889d"},"cell_type":"markdown","source":"While revewing Kagglers kernels, one kernel caught my eyes! \n[https://www.kaggle.com/raddar/merchant-id-imputations](http://)\n\nActually he was trying to show that we can fill in NAs in `merchant_id` but I got an idea about feature engineering! Come with me :)\n"},{"metadata":{"trusted":true,"_uuid":"43c54928809dddb03675b4b51e6eca29aefcb8fa"},"cell_type":"code","source":"hist.loc[hist.card_id == 'C_ID_d57e4ddab0'].sort_values('purchase_date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"982c48791327d4967da81a4ff3378d403b3f6c40"},"cell_type":"code","source":"user_df = hist.loc[hist.card_id == 'C_ID_d57e4ddab0'].sort_values('purchase_date')\nuser_df.loc[user_df.merchant_id == 'M_ID_9139332ccc']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59ecae2ed8f3cbfe8487e426b288ff532748a7c6"},"cell_type":"markdown","source":"This card user ('C_ID_d57e4ddab0') has very unique purchasing tendency.\nWhen it comes to transaction with merchant_id '\tM_ID_9139332ccc', regular monthly puchase is notable  on 14th of every month ! \nDoes it imply regular subscription ???\nOkay! Now my goal is to find regular purchase date of every card user and make it as a feature! \nLet's go "},{"metadata":{"_uuid":"7d6cbd92a3e6bd534d04ae7632f3e050a855c335"},"cell_type":"markdown","source":"# Regular payment FE "},{"metadata":{"trusted":true,"_uuid":"993e48f61cd264d2d41ce33184988bc6cc596d75"},"cell_type":"code","source":"# making `purchase_d` column. Slicing date from `purchase_date` column and shifting its datatype into String\nhist['purchase_d'] = [x.strftime('%d') for x in pd.DatetimeIndex(hist.purchase_date).date]     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0a94e1510d54140fc9773991f8d80766deba918"},"cell_type":"code","source":"hist.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f635c455e59aeedeca18f44953539284da09f347"},"cell_type":"code","source":"# Counting frequency of each value from `purchase_d` column and counting values whose frequency is more than one\n# return value implies the frequency of regular monthly purchase \nfrom collections import Counter\ndef regular_cnt(series): \n    return sum(filter(lambda x: x > 1, Counter(series.tolist()).values()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bc36042951df082b4b9793f963b4f2e616d9742"},"cell_type":"code","source":"regular = hist.groupby(['card_id', 'merchant_id']).agg({'purchase_d': [regular_cnt]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdcaa622bb78e34eefd16ed9671e1f04fc87a526"},"cell_type":"code","source":"from scipy import stats\ndef mode(x):\n    return stats.mode(x)[1][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c764831441ef9eafae2ca7e069846607a6d08dfb"},"cell_type":"code","source":"regular_df = regular.groupby(['card_id']).agg(['sum', 'mean', 'min', 'max', 'nunique', 'size', mode])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"866b1dea8af47f042ba5a856d6939f24729bcd2e"},"cell_type":"code","source":"regular_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"551c1138f11eb66944dd6a6a5619b75d3c13d4fb"},"cell_type":"code","source":"regular_df.columns = ['hist_regular_sum','hist_regular_mean', 'hist_regular_min', 'hist_regular_max', 'hist_regular_nunique', 'hist_regular_size', 'hist_regular_mode']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b58e685449470b3433d77cea42404cb60da8c8c"},"cell_type":"code","source":"regular_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a605dee217fc8b7f6d003d080312f8d72600e91"},"cell_type":"code","source":"regular_df.to_csv('regular_FE.csv', index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3df4f5a926afd200c09c3678815a95edfe8e4a31"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}