{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# External Data Exploration - Microsoft Malware\nSo far, there are 4 published Kaggle datasets containing extra information for Microsoft Malware competition. In this kernel, we will explore them:  \n* [AvSigVersion Time Stamps][1]\n* [Census_OSVersion Time Stamps][2]\n* [Google Safe Browsing Report][3]\n* [AvSigVersion Threats][4]\n\nThese datasets have been uploaded to Kaggle by [Aditya Soni][5], [Chris Deotte][6], [Rob Rose][7], and [Rui Quintino][8]. They have discussion theads [here][9], [here][9], [here][10], and [here][11] respectively. And [here][12], [here][14], and [here][13] are kernels that explore time stamps. Let's load `train.csv`.\n  \n[1]: https://www.kaggle.com/cdeotte/malware-timestamps\n[2]: https://www.kaggle.com/cdeotte/malware-timestamps-2\n[3]: https://www.kaggle.com/robroseknows/google-safe-browsing-transparency-report-data/home\n[4]: https://www.kaggle.com/rquintino/malware-avsigversion-threats\n[5]: https://www.kaggle.com/adityaecdrid\n[6]: https://www.kaggle.com/cdeotte\n[7]: https://www.kaggle.com/robroseknows\n[8]: https://www.kaggle.com/rquintino\n[9]: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/78672\n[10]: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/80490\n[11]: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/81669\n[12]: https://www.kaggle.com/cdeotte/time-series-eda-malware-0-64\n[13]: https://www.kaggle.com/rquintino/2-months-train-1-month-public-1-day-private\n[14]: https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68"},{"metadata":{"trusted":true,"_uuid":"60daa4be31ee85d797ea0db58277d95ea18cc9fc"},"cell_type":"code","source":"import numpy as np, pandas as pd\nload = ['HasDetections', 'AvSigVersion', 'Census_OSVersion', 'OsBuildLab']\ndf_train = pd.read_csv('../input/microsoft-malware-prediction/train.csv',dtype='category',usecols=load)\ndf_train['HasDetections'] = df_train['HasDetections'].astype('int8')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Time Stamps\nVersion numbers in Microsoft Malware data are associated with time. Microsoft publishes time stamps for `AvSigVersion` and `Census_OSVersion`. Additionally we can deduce time stamps for `OsBuildLab` and `EngineVersion` (EngineVersion is associated with AvSigVersion). ([Here][1] and [here][3] are kernels that explore time stamps. [Here][2] is a kernel that explores time split validation.)  \n  \n[1]: https://www.kaggle.com/cdeotte/time-series-eda-malware-0-64\n[2]: https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68\n[3]: https://www.kaggle.com/rquintino/2-months-train-1-month-public-1-day-private"},{"metadata":{"trusted":true,"_uuid":"fe824cb6644a91cfedab52971d34a3ce41ac7255"},"cell_type":"code","source":"from datetime import datetime, date, timedelta\n\n# AS timestamp\ndatedictAS = np.load('../input/malware-timestamps/AvSigVersionTimestamps.npy')[()]\ndf_train['DateAS'] = df_train['AvSigVersion'].map(datedictAS)  \n\n# OS timestamp\ndatedictOS = np.load('../input/malware-timestamps-2/OSVersionTimestamps.npy')[()]\ndf_train['DateOS'] = df_train['Census_OSVersion'].map(datedictOS)  \n\n# BL timestamp\ndef convert(x):\n    try:\n        d = datetime.strptime(x.split('.')[4],'%y%m%d-%H%M')\n    except:\n        d = np.nan\n    return d\ndf_train['DateBL'] = df_train['OsBuildLab'].map(convert)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a7eec18865362fd028b02e44348fb772bf6bb44"},"cell_type":"markdown","source":"# Google Safe Browsing Report\n[Google][1] publishes information about malware on the internet over time. Let's load this externel dataset, display some rows, merge it with `df_train`, and perform EDA.  \n  \n[1]: https://transparencyreport.google.com/safe-browsing/overview\n"},{"metadata":{"trusted":true,"_uuid":"b793204bd331b3b18a7490d25c195de3ab4363c4"},"cell_type":"code","source":"data = pd.read_csv('../input/google-safe-browsing-transparency-report-data/data.csv')\ndata['WeekOf'] = data['WeekOf'].map(lambda x: datetime.strptime(x,'%Y-%m-%d').date())\ndatedictAS = np.load('../input/malware-timestamps/AvSigVersionTimestamps.npy')[()]\nweekdictAS={}\nfor x in datedictAS: \n    weekdictAS[x] = (datedictAS[x] - timedelta(days= -7+1+datedictAS[x].weekday())).date()\ndf_train['WeekOf'] = df_train['AvSigVersion'].map(weekdictAS)\ndf_train = pd.merge(df_train, data, on='WeekOf', how='left')\nprint('GOOGLE DATA')\ndata.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"38bdc6549b17bc584336e208c4a3f00447538731"},"cell_type":"code","source":"import math, calendar\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n# PARAMETERS\n# data : pandas.DataFrame : your data to plot\n# col  : str : which column to plot histogram for left y-axis\n# target : str : which column for mean/rate on right y-axis\n# bars : int : how many histogram bars to show (or less if you set show or min)\n# show : float : stop displaying bars after 100*show% of data is showing\n# minn : float : don't display bars containing under 100*minn% of data\n# sortby : str : either 'frequency', 'category', or 'rate'\n# verbose : int : display text summary 1=yes, 0=no\n# top : int : give this many bars nice color (and matches a subsequent dynamicPlot)\n# title : str : title of plot\n# asc : boolean : sort ascending (for category and rate)\n# dropna : boolean : include missing data as a category or not\n\ndef staticPlot(data, col, target='HasDetections', bars=10, show=1.0, sortby='frequency'\n               , verbose=1, top=5, title='',asc=False, dropna=False, minn=0.0):\n    # calcuate density and detection rate\n    cv = data[col].value_counts(dropna=dropna)\n    cvd = cv.to_dict()\n    nm = cv.index.values; lnn = len(nm); lnn2 = lnn\n    th = show * len(data)\n    th2 = minn * len(data)\n    sum = 0; lnn2 = 0\n    for x in nm[0:bars]:\n        lnn2 += 1\n        try: sum += cvd[x]\n        except: sum += cv[x]\n        if sum>th:\n            break\n        try:\n            if cvd[x]<th2: break\n        except:\n            if cv[x]<th2: break\n    if lnn2<bars: bars = lnn2\n    pct = round(100.0*sum/len(data),2)\n    lnn = min(lnn,lnn2)\n    ratio = [0.0]*lnn; lnn3 = lnn\n    if sortby =='frequency': lnn3 = min(lnn3,bars)\n    elif sortby=='category': lnn3 = 0\n    for i in range(lnn3):\n        if target not in data:\n            ratio[i] = np.nan\n        elif nan_check(nm[i]):\n            ratio[i] = data[target][data[col].isna()].mean()\n        else:\n            ratio[i] = data[target][data[col]==nm[i]].mean()\n    try: all = pd.DataFrame( {'category':nm[0:lnn],'frequency':[cvd[x] for x in nm[0:lnn]],'rate':ratio} )\n    except: all = pd.DataFrame( {'category':nm[0:lnn],'frequency':[cv[x] for x in nm[0:lnn]],'rate':ratio} )\n    if sortby=='rate': \n        all = all.sort_values(sortby, ascending=asc)\n    elif sortby=='category':\n        try: \n            all['temp'] = all['category'].astype('float')\n            all = all.sort_values('temp', ascending=asc)\n        except:\n            all = all.sort_values('category', ascending=asc)\n    if bars<lnn: all = all[0:bars]\n    if verbose==1 and target in data:\n        print('TRAIN.CSV variable',col,'has',len(nm),'categories')\n        print('The',min(bars,lnn),'bars displayed here contain',pct,'% of data.')\n        mlnn = data[col].isna().sum()\n        print(\"The data has %.1f %% NA. The plot is sorted by \" % (100.0*mlnn/len(data)) + sortby )\n    \n    # plot density and detection rate\n    fig = plt.figure(1,figsize=(15,3))\n    ax1 = fig.add_subplot(1,1,1)\n    clrs = ['red', 'green', 'blue', 'yellow', 'magenta']\n    barss = ax1.bar([str(x) for x in all['category']],[x/float(len(data)) for x in all['frequency']],color=clrs)\n    for i in range(len(all)-top):\n        barss[top+i].set_color('cyan')\n    if target in data:\n        ax2 = ax1.twinx()\n        if sortby!='category': infected = all['rate'][0:lnn]\n        else:\n            infected=[]\n            for x in all['category']:\n                if nan_check(x): infected.append( data[ data[col].isna() ][target].mean() )\n                elif cvd[x]!=0: infected.append( data[ data[col]==x ][target].mean() )\n                else: infected.append(-1)\n        ax2.plot([str(x) for x in all['category']],infected[0:lnn],'k:o')\n        #ax2.set_ylim(a,b)\n        ax2.spines['left'].set_color('red')\n        ax2.set_ylabel('Detection Rate', color='k')\n    ax1.spines['left'].set_color('red')\n    ax1.yaxis.label.set_color('red')\n    ax1.tick_params(axis='y', colors='red')\n    ax1.set_ylabel('Category Proportion', color='r')\n    if title!='': plt.title(title)\n    plt.show()\n    if verbose==1 and target not in data:\n        print('TEST.CSV variable',col,'has',len(nm),'categories')\n        print('The',min(bars,lnn),'bars displayed here contain',pct,'% of the data.')\n        mlnn = data[col].isna().sum()\n        print(\"The data has %.1f %% NA. The plot is sorted by \" % (100.0*mlnn/len(data)) + sortby )\n        \n# CHECK FOR NAN\ndef nan_check(x):\n    if isinstance(x,float):\n        if math.isnan(x):\n            return True\n    return False","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"a587270248ee831bb1d23875a544dfc61f3162cf"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport seaborn as sns, matplotlib.pyplot as plt\nfrom matplotlib import gridspec\n\n# KERNEL DENSITY BANDWITHS\nn = [1000,1000,50000,25000,50,1000,1e6,1e6,5,2]\n# DENSITY X RANGES\ns = [(1,10000),(0,0),(0,0),(700000,950000),(1,750),(1,10000),(1,2e7),(1,2e7),(0,0),(0,0)]\n# REMOVE NAN\ndf_train = df_train[ df_train['AvSigVersion']!='0.0.0.0' ]\n# TEXT FORMATTING\ndef cc(l):\n    for i in range(len(l)): \n        l[i] = '< ('+str(i)+') < '+str(l[i])\n    return l\n# DISCRETIZING FUNCTION FROM \n# https://www.kaggle.com/guoday/nffm-baseline-0-690-on-lb\ndef make_bucket(data,num=10):\n    data.sort()\n    bins=[]\n    for i in range(num):\n        bins.append(data[int(len(data)*(i+1)//num)-1])\n    return bins\n\nct=0\nfor col in list(data.columns)[1:]:\n    print('###############################################')\n    print('###     '+col)\n    print('###############################################')\n    \n    # TIME SERIES PLOT\n    plt.figure(figsize=(15,5))\n    plt.plot(data['WeekOf'],data[col])\n    plt.xlabel('Time')\n    plt.ylabel(col)\n    plt.title('\"'+col+'\" versus time')\n    plt.show()\n    \n    # HASDETECTION HISTOGRAM\n    bins = make_bucket(df_train[col].copy().values,num=20)\n    df_train['P']=np.digitize(df_train[col],bins=bins)\n    staticPlot(df_train[ df_train['P']!=20 ],'P',sortby='category',asc=True,bars=20,verbose=0,\n               title='HasDetections Rate versus \"'+col+'\" (Bars use left y-axis. Dotted line uses right)')\n    print('KEY TO BINS:',col,cc(bins))\n    \n    # DENSITY PLOT AND BOXPLOT\n    lines = [1, 0]\n    plt.figure(figsize=(15,5))\n    gs = gridspec.GridSpec(1, 2, width_ratios=[3, 1]) \n    plt.subplot(gs[0])\n    for line in lines:\n        subset = df_train[ (df_train['HasDetections'] == line) & (~df_train[col].isna())]\n        sns.kdeplot(subset[col], bw=n[ct],\n                     shade=True, linewidth=3, \n                     label = line)\n    plt.legend(prop={'size': 16}, title = 'HasDetections')\n    plt.title('Density Plot of HasDetections versus \"'+col+'\"')\n    plt.xlabel(col)\n    if s[ct][0]!=0: plt.xlim((s[ct][0],s[ct][1]))\n    plt.ylabel('Density')\n    ax = plt.subplot(gs[1])\n    df_train2 = df_train[ ~df_train[col].isna() ]\n    plt.boxplot([df_train2[ df_train2['HasDetections']==0][col],df_train2[ df_train2['HasDetections']==1][col]])\n    plt.title('Boxplot of \"'+col+'\"')\n    if s[ct][0]!=0: plt.ylim((s[ct][0],s[ct][1]))\n    ct += 1\n    plt.xlabel('HasDetections')\n    ax.set_xticklabels([0,1])\n    plt.show()\ndel df_train['P']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2854983c857c93650ffeee4b9f506a0ce8cf3394"},"cell_type":"markdown","source":"# AvSigVersion Threats\n[Microsoft][1] publishes malware threats. For each `AvSigVersion`, this external dataset lists all the known malware that was threatening it. (Note that for each point in time, all (95%) of computers use the same `AvSigVersion`, so threats on `AvSigVersion` can be interpreted as threats at a given time point.) There is a lot of information in this dataset, we will only add one new feature to `df_train`. For each `AvSigVersion`, we will count how many things were threatening it, and add a new varable, `ThreatCount`.  \n  \n[1]: https://www.microsoft.com/en-us/wdsi/definitions/antimalware-definition-release-notes?RequestVersion=1.277.43.0"},{"metadata":{"trusted":true,"_uuid":"abaefde7da940171df5ddc27f9bcf9379b569e44"},"cell_type":"code","source":"data2 = pd.read_csv('../input/malware-avsigversion-threats/AvSigversion_Threats.csv')\ncv = pd.DataFrame(data2.groupby('AvSigVersion')['index'].count()).rename({'index':'ThreatCount'},axis=1)\ndf_train = pd.merge(df_train,cv,on='AvSigVersion',how='left')\ndf_train['ThreatCount'].fillna(0,inplace=True)\nprint('THREAT DATA')\ndata2.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5af195ca779f875c35ce00be406f3a5a1afa8122"},"cell_type":"code","source":"df_train[['AvSigVersion','OsBuildLab','Census_OSVersion','HasDetections','ThreatCount']].sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"aa4a6ec50b176beaec8eeecadc495235711fcbf9"},"cell_type":"code","source":"staticPlot(df_train,'ThreatCount',sortby='category',asc=True,bars=10\n           ,title='Threat Count, 10 most frequent (65% of all data)(Bars use left y-axis. Dotted line uses right)',verbose=False)\nstaticPlot(df_train,'ThreatCount',sortby='category',asc=True,bars=100\n           ,title='Threat Count, 100 most frequent (90% of all data)(Bars use left y-axis. Dotted line uses right)',verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"c8cfc344cb87bcfbf3223d39bcb9761ed4005e24"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport seaborn as sns, matplotlib.pyplot as plt\nfrom matplotlib import gridspec\n\n# DENSITY PLOT AND BOXPLOT\ncol = 'ThreatCount'\nlines = [1, 0]\nplt.figure(figsize=(15,5))\ngs = gridspec.GridSpec(1, 2, width_ratios=[3, 1]) \nplt.subplot(gs[0])\nfor line in lines:\n    subset = df_train[ (df_train['HasDetections'] == line) & (~df_train[col].isna())]\n    sns.kdeplot(subset[col], bw=10,\n                   shade=True, linewidth=3, \n                   label = line)\nplt.legend(prop={'size': 16}, title = 'HasDetections')\nplt.title('Density Plot of HasDetections versus \"'+col+'\"')\nplt.xlabel(col)\nplt.xlim((-50,500))\nplt.ylabel('Density')\nax = plt.subplot(gs[1])\ndf_train2 = df_train[ ~df_train[col].isna() ]\nplt.boxplot([df_train2[ df_train2['HasDetections']==0][col],df_train2[ df_train2['HasDetections']==1][col]])\nplt.title('Boxplot of \"'+col+'\"')\nplt.ylim((-50,500))\nplt.xlabel('HasDetections')\nax.set_xticklabels([0,1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfd2b7bb54af7bdc954d9c98458628162f48166b"},"cell_type":"markdown","source":"# LGBM Feature Importance\nWe will now train an LGBM model on just variables from the 2 external datasets, Google data and Threat data. First we will delete all other variables."},{"metadata":{"trusted":true,"_uuid":"81a15fbbabc6ca9976cfb0cfb8507d6fe59d07e2"},"cell_type":"code","source":"del df_train['DateAS'], df_train['DateOS'], df_train['DateBL'], df_train['WeekOf'] \ndel df_train['AvSigVersion'], df_train['OsBuildLab'], df_train['Census_OSVersion']\nprint('TRAIN DATA')\ndf_train.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ef288f05e74105fcc57151e200b3edd234075ed"},"cell_type":"code","source":"import lightgbm as lgb,gc\n\n# CREATE TRAIN AND VALIDATE\nX_train = df_train.sample(frac=0.5)\nY_train = X_train['HasDetections']\nX_val = df_train[ ~df_train.index.isin(X_train.index) ]\nY_val = X_val['HasDetections']\ndel X_train['HasDetections'], X_val['HasDetections'], df_train\nx=gc.collect()\n\n# TRAIN LGBM\nmodel = lgb.LGBMClassifier(n_estimators=10000, colsample_bytree=0.7, objective='binary', num_leaves=32,\n            max_depth=-1, learning_rate=0.1)\nh=model.fit(X_train, Y_train, eval_metric='auc', eval_set=[(X_val, Y_val)], verbose=50,\n            early_stopping_rounds=100)\n\n# FEATURE IMPORTANCE\ndf = pd.DataFrame({\"mean\" : model.feature_importances_, \"feature\" : X_train.columns })\ndf.sort_values(\"mean\", inplace=True)\nax = df.plot(x=\"feature\", y=\"mean\", kind='barh',color='green', figsize=(12, 20)\n             , title='External Data LGBM Feature Importance')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e953ba8186504afe6b5cbeabff9fceebdd43dd0"},"cell_type":"markdown","source":"# Predict test.csv and submit"},{"metadata":{"trusted":true,"_uuid":"3b553625cf62015c48e03d2d2403092ff9715fff"},"cell_type":"code","source":"del X_train, X_val, Y_train, Y_val\n# LOAD TEST\nload = ['AvSigVersion', 'Census_OSVersion', 'OsBuildLab']\ndf_test = pd.read_csv('../input/microsoft-malware-prediction/test.csv',dtype='category',usecols=load)\n# GOOGLE DATA\ndf_test['WeekOf'] = df_test['AvSigVersion'].map(weekdictAS)\ndf_test = pd.merge(df_test, data, on='WeekOf', how='left')\n# THREAT DATA\ndf_test = pd.merge(df_test,cv,on='AvSigVersion',how='left')\ndf_test['ThreatCount'].fillna(0,inplace=True)\n# DELETE EXTRA\ndel df_test['WeekOf']\n# DELETE ORIGINAL\ndel df_test['AvSigVersion'], df_test['OsBuildLab'], df_test['Census_OSVersion']\nx=gc.collect()\nprint('TEST DATA')\ndf_test.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7601d37a1ee28cf894fa00c6e8890ef6d6b01c11"},"cell_type":"code","source":"# PREDICT IN CHUNKS FOR REDUCED MEMORY USAGE\nidx = 0; chunk = 2000000\npred_val = np.zeros(len(df_test))\nwhile idx < len(df_test):\n    idx2 = min(idx + chunk, len(df_test) )\n    idx = range(idx, idx2)\n    pred_val[idx] = model.predict_proba(df_test.iloc[idx])[:,1]\n    idx = idx2\nsubmit = pd.read_csv('../input/microsoft-malware-prediction/sample_submission.csv')\nsubmit['HasDetections'] = pred_val\nsubmit.to_csv('ExternalData.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83186e394e9a335b3d14fabbbefb0519a9d0324b"},"cell_type":"markdown","source":"![image](http://playagricola.com/Kaggle/sub22819.png)\n\n# Conclusion\nIn this kernel, we explored data from the 4 external Microsoft malware datasets. We attempted to predict Malware HasDetections from just the data contained therein but were not successful. We only achieved an LB of 0.500. The data in these datasets looks useful, so if we try other encodings, maybe we can gain some predictive power. I encorage others to fork this kernel and explore. If you make any discoveries or achieve a submission over LB 0.500, please share your work in the comments below."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}