{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5b37e32e-c960-fb69-64eb-89200f7dbfa1"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "957be98d-66df-2d71-7c96-4de7590c06f3"
      },
      "outputs": [],
      "source": [
        "def preprocessing(df):\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['build_year'] = np.where(df['build_year'] < 1500.0, np.nan, df['build_year'])\n",
        "    df['build_year'] = np.where(df['build_year'] > 2017.0, np.nan, df['build_year'])\n",
        "    df['build_year'] = 'Year_' + df['build_year'].astype(str)\n",
        "    df['build_year_flg'] = np.where(pd.isnull(df['build_year']), 'N', 'Y')\n",
        "    df['state'] = np.where(df['state'] > 4.0, np.nan, df['state'])\n",
        "    df['floor'] = np.where(df['floor'] < 10.0, np.nan, df['floor'])\n",
        "    df['num_room'] = np.where(df['num_room'] > 9.0, np.nan, df['num_room'])\n",
        "    #df['material'] = np.where(pd.isnull(df['material']), 7.0, df['material'])\n",
        "    df['material'] = 'Material_' + df['material'].astype(str)\n",
        "    #df['state'] = np.where(pd.isnull(df['state']), 5, df['state'])\n",
        "    df['state'] = 'State_' + df['state'].astype(str)\n",
        "    df['state_flg'] = np.where(pd.isnull(df['state']), 'N', 'Y')\n",
        "    df['hospital_beds_raion_flg'] = np.where(pd.isnull(df['hospital_beds_raion']), 'N', 'Y')\n",
        "    df['cafe_500_flg'] = np.where(pd.isnull(df['cafe_sum_500_min_price_avg']), 'N', 'Y')\n",
        "    df['floor_flg'] = np.where(pd.isnull(df['max_floor']), 'N', 'Y')\n",
        "    df['preschool_quota_flg'] = np.where(pd.isnull(df['preschool_quota']), 'N', 'Y')\n",
        "    df['school_quota_flg'] = np.where(pd.isnull(df['school_quota']), 'N', 'Y')\n",
        "    df['cafe_1000_flg'] = np.where(pd.isnull(df['cafe_sum_1000_min_price_avg']), 'N', 'Y')\n",
        "    df['life_sq_flg'] = np.where(pd.isnull(df['life_sq']), 'N', 'Y')\n",
        "    df['build_flg'] = np.where(pd.isnull(df['raion_build_count_with_material_info']), 'N', 'Y')\n",
        "    df['cafe_2000_flg'] = np.where(pd.isnull(df['cafe_sum_2000_min_price_avg']), 'N', 'Y')\n",
        "    df['cafe_3000_flg'] = np.where(pd.isnull(df['cafe_sum_3000_min_price_avg']), 'N', 'Y')\n",
        "    df['cafe_5000_flg'] = np.where(pd.isnull(df['cafe_sum_5000_min_price_avg']), 'N', 'Y')\n",
        "    df['metro_flg'] = np.where(pd.isnull(df['metro_min_walk']), 'N', 'Y')\n",
        "    df['prom_part_5000'] = np.where(pd.isnull(df['prom_part_5000']), 'N', 'Y')\n",
        "    df['floor_flg'] = np.where(pd.isnull(df['floor']), 'N', 'Y')\n",
        "\n",
        "    df['life_sq'] = np.where(df['life_sq'] > df['full_sq'], np.nan, df['life_sq'])\n",
        "    df['kitch_sq'] = np.where(df['kitch_sq'] > df['full_sq'], np.nan, df['kitch_sq'])\n",
        "    df['max_floor'] = np.where(df['floor'] > df['max_floor'], df['floor'], df['max_floor'])\n",
        "\n",
        "    df['year'] = pd.DatetimeIndex(df['timestamp']).year\n",
        "    df['month'] = pd.DatetimeIndex(df['timestamp']).month\n",
        "    df['day'] = pd.DatetimeIndex(df['timestamp']).day\n",
        "    df['weekday'] = pd.DatetimeIndex(df['timestamp']).weekday\n",
        "    object = []\n",
        "    for i in df.columns:\n",
        "        if (df[i].dtype == 'object'): object.append(i)\n",
        "\n",
        "    #dummies = pd.get_dummies(df[object])\n",
        "    number = LabelEncoder()\n",
        "    for i in object:\n",
        "        df[i] = number.fit_transform(df[i].astype(str))\n",
        "    #df = df.drop(object, axis=1)\n",
        "    #df = pd.concat([df, dummies], axis=1)\n",
        "    imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)  ## trying with Most frequent\n",
        "    ddfwotime = pd.to_numeric(df['timestamp'])\n",
        "    df = df.drop('timestamp', axis=1)\n",
        "    df_complete = pd.DataFrame(imp.fit_transform(df), columns= df.columns)\n",
        "    #df_complete = df\n",
        "    df_complete['timestamp'] = ddfwotime\n",
        "    return df_complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6e81d7d4-e7d3-944a-0a56-bd61537db20f"
      },
      "outputs": [],
      "source": [
        "def rmsle(y, y_pred):\n",
        "\tassert len(y) == len(y_pred)\n",
        "\tterms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
        "\treturn (sum(terms_to_sum) * (1.0/len(y))) ** 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "18f7eb52-0c34-ad71-af38-5f6d5a1b4b5c"
      },
      "outputs": [],
      "source": [
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(480, input_dim=480, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(1, kernel_initializer='normal'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1ff0c61b-372e-b519-2b96-55ce1dca3864"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn.preprocessing as st\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import Imputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import math\n",
        "import xgboost as xg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import fancyimpute as fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "204e69dc-2434-8afa-db45-df4fb283aa0d"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"../input/train.csv\",sep=',')\n",
        "test = pd.read_csv(\"../input/test.csv\",sep=',')\n",
        "macro = pd.read_csv(\"../input/macro.csv\",sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e7fc2056-f81f-092b-ab3e-8406e9f4e43d"
      },
      "outputs": [],
      "source": [
        "macro['child_on_acc_pre_school'] = macro['child_on_acc_pre_school'].str.replace(\",\",\"\")\n",
        "macro['old_education_build_share'] = macro['old_education_build_share'].str.replace(\",\",\".\")\n",
        "macro['modern_education_share'] = macro['modern_education_share'].str.replace(\",\",\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0c044965-0974-2680-021a-7a76e061a50a"
      },
      "outputs": [],
      "source": [
        "macro['timestamp'] = pd.to_datetime(macro['timestamp'])\n",
        "macro['child_on_acc_pre_school']= pd.to_numeric(macro['child_on_acc_pre_school'],errors='coerce')\n",
        "macro['old_education_build_share']= pd.to_numeric(macro['old_education_build_share'],errors='coerce')\n",
        "macro['modern_education_share']= pd.to_numeric(macro['modern_education_share'],errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "de60b84c-6ab5-d633-3b8d-2f944395cd8d"
      },
      "outputs": [],
      "source": [
        "print(macro[['modern_education_share','timestamp']].groupby(['modern_education_share']).agg(['count']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7df0b888-6736-9b3c-4ebc-5ae3c00d910d"
      },
      "outputs": [],
      "source": [
        "object =[]\n",
        "for i in macro.columns:\n",
        "    if(macro[i].dtype =='object'):\n",
        "        lst = []\n",
        "        print(i)\n",
        "        object.append(i)\n",
        "        lst.append(i)\n",
        "        lst.append('timestamp')\n",
        "        print(macro[lst].groupby([i]).agg(['count']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ad9a990c-7319-1cb3-7e72-091b9af5c74c"
      },
      "outputs": [],
      "source": [
        "print (object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b029944a-4c24-e624-a6fb-3b917d3ec2d6"
      },
      "outputs": [],
      "source": [
        "macro_wotimestamp = macro.drop(['timestamp'], axis = 1)\n",
        "tk = pd.DataFrame.as_matrix(macro_wotimestamp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d20884bb-392b-45db-a002-7ee1312a7aea"
      },
      "outputs": [],
      "source": [
        "X_filled_knn = fc.KNN(k=3).complete(tk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "637501b6-e54a-9086-2ac3-bf200ba0d9f7"
      },
      "outputs": [],
      "source": [
        "varnames = macro_wotimestamp.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e4e344b4-10c4-6406-4573-d6fadbcaa696"
      },
      "outputs": [],
      "source": [
        "print (varnames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cdf435a9-4ade-465c-8b53-edc59753a329"
      },
      "outputs": [],
      "source": [
        "macro_fill = pd.DataFrame(X_filled_knn, columns=varnames)\n",
        "macro_fill['timestamp'] = macro['timestamp']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "404b3b35-7b83-b5bc-01a1-7ed1756e2c0c"
      },
      "outputs": [],
      "source": [
        "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d44daf00-6eae-314f-daa7-0c4b40c48588"
      },
      "outputs": [],
      "source": [
        "macro = macro_fill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c3b21765-481a-cfef-358b-28397a66a42f"
      },
      "outputs": [],
      "source": [
        "np.sum(np.sum(pd.isnull(macro)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a8ecc6d5-6599-80bb-ce33-36777fb5686c"
      },
      "outputs": [],
      "source": [
        "timestam = pd.to_numeric(macro['timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7e125f57-217f-ae18-cde3-cca4a1257749"
      },
      "outputs": [],
      "source": [
        "\n",
        "macro['timestamp'] =timestam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aad04c30-e964-f134-be7e-19fc072e5a43"
      },
      "outputs": [],
      "source": [
        "macro.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5422757a-b9de-deb5-4c61-88e2f8295cd6"
      },
      "outputs": [],
      "source": [
        "df_complete = preprocessing(df)\n",
        "test_complete = preprocessing(test)\n",
        "df_complete_train = pd.merge(df_complete,macro,how ='left' ,on=['timestamp'])\n",
        "test_complete = pd.merge(test_complete,macro,how ='left' ,on=['timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3f4e4635-0435-d271-f514-34537719ed32"
      },
      "outputs": [],
      "source": [
        "target = df_complete_train.columns.tolist().index('price_doc')\n",
        "id = df_complete_train.columns.tolist().index('id')\n",
        "noofcol = len(df_complete_train.columns)\n",
        "r =  list(range(0,noofcol))\n",
        "del r[target]\n",
        "del r[id]\n",
        "features = df_complete_train.columns[r]\n",
        "data = df_complete_train.values\n",
        "#X_filled_knn = fc.KNN(k=3).complete(data)\n",
        "#data = X_filled_knn\n",
        "Y = data[:,target]\n",
        "y_log = np.log(data[:,target])\n",
        "X = data[:,r]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f1320f2e-552e-9365-0f89-393f7a5728bd"
      },
      "outputs": [],
      "source": [
        "np.sum(np.isnan(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8b74d806-0a57-0f26-7f61-908caa71c6ec"
      },
      "outputs": [],
      "source": [
        "testid = test_complete.columns.tolist().index('id')\n",
        "testcol = len(test_complete.columns)\n",
        "r =  list(range(0,testcol))\n",
        "del r[id]\n",
        "Test_features = test_complete.columns[r]\n",
        "testdata = test_complete.values\n",
        "#X_filled_knn = fc.KNN(k=3).complete(testdata)\n",
        "#testdata = X_filled_knn\n",
        "testX = testdata[:,r]\n",
        "#end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c53afb7e-9feb-57aa-c2e6-91dd8f941ef9"
      },
      "outputs": [],
      "source": [
        "np.sum(np.isnan(testX))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5fcf5d93-7411-1d2a-cb35-e73056b66123"
      },
      "outputs": [],
      "source": [
        "seed = 7\n",
        "test_size = 0.33\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_log, test_size=test_size, random_state=seed)\n",
        "\n",
        "estimators = []\n",
        "gbm = xg.XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=.7, gamma=0,\n",
        "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
        "       min_child_weight=1, missing=None, n_estimators=500, nthread=-1,\n",
        "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
        "       scale_pos_weight=1, seed=0, silent=True, subsample=.7)\n",
        "estimators.append(('standardize', st.RobustScaler()))\n",
        "estimators.append(('mlp', gbm))\n",
        "pipeline = Pipeline(estimators)\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "res = rmsle(np.exp(y_test),np.exp(y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a923880-d8b6-fe95-3a91-a19287cee6c7"
      },
      "outputs": [],
      "source": [
        "print (res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "36c164e9-e0b8-4f10-bd59-ec1b326d2c4f"
      },
      "outputs": [],
      "source": [
        "testy_pred = pipeline.predict(testX)\n",
        "pred_ytest = np.exp(testy_pred)\n",
        "ids = test_complete['id']\n",
        "\n",
        "results = pd.DataFrame(columns=list(['id','price_doc']))\n",
        "results['id'] = ids\n",
        "results['id'] = results['id'].astype(int)\n",
        "results['price_doc'] = pred_ytest\n",
        "results.to_csv(\"Results.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "af511a7c-5093-580a-3a61-35b70eccebfd"
      },
      "outputs": [],
      "source": [
        "rt = pd.read_csv(\"Results.csv\",sep=\",\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "29ba1490-6f17-35fd-fa5e-3e8819c34539"
      },
      "outputs": [],
      "source": [
        "print(rt)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}