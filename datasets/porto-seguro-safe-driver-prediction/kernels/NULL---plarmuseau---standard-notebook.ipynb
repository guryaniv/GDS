{"nbformat_minor": 1, "nbformat": 4, "metadata": {"language_info": {"pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.1"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "cells": [{"outputs": [], "metadata": {"scrolled": true, "collapsed": true, "_cell_guid": "2d929b28-96a4-435f-b3ad-f1cba55a4b40", "_uuid": "dc77766e5fe76a18b9231545af4c94031a317a82"}, "cell_type": "code", "execution_count": null, "source": ["import seaborn as sns\n", "\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "# read data into dataset variable\n", "train = pd.read_csv(\"../input/train.csv\") #[:20000]\n", "test = pd.read_csv(\"../input/test.csv\") #[:10000]\n", "#train=train.append(test)\n", "train.describe().T\n"]}, {"outputs": [], "metadata": {"scrolled": false, "collapsed": true, "_cell_guid": "712e741e-eb19-4a00-9b1c-af590e80bd57", "_uuid": "1a6ca37710a82df873c2425bbcd66e60c0878bc5"}, "cell_type": "code", "execution_count": null, "source": ["from sklearn.linear_model import OrthogonalMatchingPursuit,RANSACRegressor,LogisticRegression,ElasticNetCV,HuberRegressor, Ridge, Lasso,LassoCV,Lars,BayesianRidge,SGDClassifier,LogisticRegressionCV,RidgeClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.preprocessing import MinMaxScaler,PolynomialFeatures\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.ensemble import RandomForestClassifier\n", "\n", "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}\n", "\n", "\n", "X = train.drop('target',axis=1).fillna(0) \n", "\n", "def rmsle(y_predicted, y_real):\n", "    return np.sqrt(np.mean(np.power(np.log1p(y_predicted)-np.log1p(y_real), 2)))\n", "def procenterror(y_predicted, y_real):\n", "     return np.round( np.mean(np.abs(y_predicted-y_real) )/ np.mean(y_real) *100 ,1)\n", "\n", "    \n", "\n", "\n", "Y=train['target'].fillna(0)\n", "scaler = MinMaxScaler()\n", "scaler.fit(X)\n", "X=scaler.transform(X)\n", "#poly = PolynomialFeatures(2)\n", "#X=poly.fit_transform(X)\n", "\n", "#print(X)\n", "\n", "names = [\n", "         #'ElasticNet',\n", "         #'SVC',\n", "         #'kSVC',\n", "         #'KNN',\n", "         'DecisionTree',\n", "         'RandomForestClassifier',\n", "         #'GridSearchCV',\n", "         #'HuberRegressor',\n", "         #'Ridge',\n", "         #'Lasso',\n", "         #'LassoCV',\n", "         #'Lars',\n", "         #'BayesianRidge',\n", "         #'SGDClassifier',\n", "         #'RidgeClassifier',\n", "         #'LogisticRegression',\n", "         #'OrthogonalMatchingPursuit',\n", "         #'RANSACRegressor',\n", "         ]\n", "\n", "classifiers = [\n", "    #ElasticNetCV(cv=10, random_state=0),\n", "    #SVC(),\n", "    #SVC(kernel = 'rbf', random_state = 0),\n", "    #KNeighborsClassifier(n_neighbors = 1),\n", "    DecisionTreeClassifier(),\n", "    RandomForestClassifier(n_estimators = 200),\n", "    #GridSearchCV(SVC(),param_grid, refit = True, verbose = 1),\n", "    #HuberRegressor(fit_intercept=True, alpha=0.0, max_iter=100,epsilon=2.95),\n", "    #Ridge(fit_intercept=True, alpha=0.0, random_state=0, normalize=True),\n", "    #Lasso(alpha=0.05),\n", "    #LassoCV(),\n", "    #Lars(n_nonzero_coefs=10),\n", "    #BayesianRidge(),\n", "    #SGDClassifier(),\n", "    #RidgeClassifier(),\n", "    #LogisticRegression(),\n", "    #OrthogonalMatchingPursuit(),\n", "    #RANSACRegressor(),\n", "]\n", "correction= [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n", "\n", "temp=zip(names,classifiers,correction)\n", "#print(temp)\n", "\n", "for name, clf,correct in temp:\n", "    regr=clf.fit(X,Y)\n", "    #print( name,'% errors', abs(regr.predict(X)+correct-Y).sum()/(Y.sum())*100)\n", "    print(name,'%error',procenterror(regr.predict(X),Y),'rmsle',rmsle(regr.predict(X),Y))\n", "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score, precision_score, recall_score\n", "\n", "    # Confusion Matrix\n", "    print(name,'Confusion Matrix')\n", "    print(confusion_matrix(Y, np.round(regr.predict(X) ) ) )\n", "    print('--'*40)\n", "\n", "    # Classification Report\n", "    print('Classification Report')\n", "    print(classification_report(Y,np.round( regr.predict(X) ) ))\n", "\n", "    # Accuracy\n", "    print('--'*40)\n", "    logreg_accuracy = round(accuracy_score(Y, np.round( regr.predict(X) ) ) * 100,2)\n", "    print('Accuracy', logreg_accuracy,'%')\n", "    \n", "    # Create a submission file\n", "    sub = pd.DataFrame()\n", "    sub['id'] = test['id']\n", "    sub['target'] = regr.predict(test)\n", "    sub.to_csv(name, index=False)\n", "\n", "    print(sub.head())\n", "\n", "    "]}]}