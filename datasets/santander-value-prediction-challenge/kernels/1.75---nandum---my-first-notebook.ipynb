{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"805d678f3635a98ec6a06c3f3b58d404f131379b"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8e256f1737d0f35356e49a2110e65428186fa5d"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25d91d0313f9fc698d54f131f73d8059f8f5ed1d"},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb6fa2ef4df5604973104868d46df1d150052e16"},"cell_type":"markdown","source":"Curse of dimensionality!!!! "},{"metadata":{"trusted":true,"_uuid":"75df7437d01e9d2104d7420459681892a61c6e14"},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56b3f9cce0cead79e2587d4dc3ad474525933837"},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.distplot(train['target'] , bins = 25 )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d33bc8e386054aed372e392ee8b95fe78da47ed"},"cell_type":"markdown","source":"The target histogram is right-skewed one . Let's try plotting the log10 histogram of the target variable"},{"metadata":{"trusted":true,"_uuid":"a15624aba3fd4c6b7ddff68ac39fc276c9d0a8a0"},"cell_type":"code","source":"plt.figure(figsize=(10,12))\nsns.distplot(np.log10( 1 + train['target'].values) , bins=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f4194a1b3f7c46557c87e9bdf08aca7393646f3"},"cell_type":"code","source":"train.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b0ffac9323fbfa20129dc127ff0ce68dd4604b1"},"cell_type":"markdown","source":"No missing data in training dataset"},{"metadata":{"trusted":true,"_uuid":"6305d89f055448e7527b34a6949c4ec6b8e9f9db"},"cell_type":"code","source":"cols = list(train.columns)\ncols.remove('ID')\ncols.remove('target')\nlen(cols)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ccb6df1f3515558acdaba202692674ab4f50f342"},"cell_type":"markdown","source":"Since the number of training data is limited when compared to number of features , we need to reduces the number of features. My thoughts on how to do the same are :- \n1.  Remove highly correlated features\n2. Remove columns having same value\n3. Use dimensionality reduction techniques like PCA"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5cb9acb9a1a0f619b7c60f6d0b22d1b26a09adaa"},"cell_type":"code","source":"correlations = train[cols].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bb20260ed387914faa5e16b2a46f026d519d660"},"cell_type":"code","source":"corr_with_target = []\nfor col in cols:\n        corr_with_target.append(np.corrcoef(train[col].values , train['target'].values)[0,1])\ncorrelation_matrix = pd.DataFrame({'cols' : cols , 'correlation_value' : corr_with_target})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"517ea182919858e2077c68bd98a32060c2a34e86"},"cell_type":"markdown","source":"Let's first consider those features having good correlation with the target variable"},{"metadata":{"trusted":true,"_uuid":"a7be4070ff9d39e3b5ffa33f5211bb00a715e406"},"cell_type":"code","source":"print(\"no:of columns with corr value > 0.1 : \" +str(len(correlation_matrix[(correlation_matrix['correlation_value'] > 0.1) | (correlation_matrix['correlation_value'] < -0.1)])))\nprint(\"no:of columns with corr value > 0.2 : \" +str(len(correlation_matrix[(correlation_matrix['correlation_value'] > 0.2) | (correlation_matrix['correlation_value'] < -0.2)])))\nprint(\"no:of columns with corr value > 0.3 : \" +str(len(correlation_matrix[(correlation_matrix['correlation_value'] > 0.3) | (correlation_matrix['correlation_value'] < -0.3)])))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f9533db43501fb985f8444d241bacc7c554ec18"},"cell_type":"markdown","source":"Let's see how a model will behave with those features who has correlation more than 0.15 and analyse the result"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7d2f9262e91a5dec731fc4e70e4c36fb0c7e572f"},"cell_type":"code","source":"features = list(correlation_matrix.cols[(correlation_matrix['correlation_value'] > 0.15) | (correlation_matrix['correlation_value'] < -0.15)].values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bea11027c752f10c02ca1d9cb8afa583f7ff6425"},"cell_type":"markdown","source":"Now let's remove columns having only one value"},{"metadata":{"trusted":true,"_uuid":"d59c155f39e4897d9cf7330563087143fb544f44"},"cell_type":"code","source":"unique_df = train[features].nunique().reset_index()\nunique_df.columns = [\"col_name\" , \"count\"]\nunique_df[unique_df['col_name'] == 1].shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb3bc1fe3d13979dea96b3187ec4ef793500e507"},"cell_type":"markdown","source":"Looks like the reduced features dosen't have columns with only one value"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c73421def442d7b1157278f4044fde93ede716b7"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cross_validation import cross_val_score\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4e620a8f7345e25b36177f47020bc37f042e7ed3"},"cell_type":"code","source":"def execute_rf_model(train_x, train_y, val_x, val_y , test_final):\n    rf_clf = RandomForestRegressor(n_estimators=200, min_samples_split= 50, n_jobs=-1 , random_state=0)\n    rf_clf.fit(train_x , train_y)\n    val_predicted = rf_clf.predict(val_x)\n    print(\"MSE :\"+ str(mean_squared_error(val_y , val_predicted)))\n    y_pred = rf_clf.predict(test_final)\n    return y_pred , rf_clf\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2e41eb2831ef201442663806c6774de1f28a778c"},"cell_type":"code","source":"X_train = train[features]\ny_train = np.log(1+train['target'].values)\ntrain_x , val_x, train_y , val_y = train_test_split(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"957658d5b2fbfb1007d0c8e3ee9ec4191a9d2c33"},"cell_type":"code","source":"y_final_rf, rf_model = execute_rf_model(train_x, train_y, val_x, val_y, test[features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81e7f04e3729bb39741a99b3318f85de3b4c8820","collapsed":true},"cell_type":"code","source":"lgb_params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\",\n        \"num_leaves\" : 50,\n        \"learning_rate\" : 0.01,\n        \"bagging_fraction\" : 0.6,\n        \"bagging_frequency\" : 5,\n        \"bagging_seed\" : 2000\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b024bcbb83bea7d419ccfc91f9a5cd91fdd9a691"},"cell_type":"code","source":"def execute_lgbmodel(params , train_x , train_y , val_x , val_y , test_final):\n    train_lgb = lgb.Dataset(train_x, label=train_y)\n    test_lgb = lgb.Dataset(val_x, label=val_y)\n    evals_result = {}\n    model = lgb.train(params, train_lgb, 5000, \n                      valid_sets=[test_lgb], \n                      early_stopping_rounds=100, \n                      evals_result=evals_result)\n    \n    pred_test_y = model.predict(test_final, num_iteration=model.best_iteration)\n    return pred_test_y, model, evals_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"201fb9873318fdcedc6d3808151def07ea9c5ae5","scrolled":true},"cell_type":"code","source":"y_final_lgb, _ , _ = execute_lgbmodel(lgb_params , train_x , train_y , val_x , val_y , test[features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7b6c8b161eefe103fd788ed3b146b297736b2d4"},"cell_type":"code","source":"y_final_lgb = np.exp(1 + y_final_lgb)\ny_final_rf = np.exp(1 + y_final_rf)\n\ny_final = 0.75*y_final_lgb + 0.25*y_final_rf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"207b443a0631b80fb0ce234ae67e1e20bf112be3","collapsed":true},"cell_type":"code","source":"test['target'] = y_final\ntest[['ID' , 'target']].to_csv('./sub1.csv' , index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"95793157f7da89c46a42dc53ea48dc5b102b9f3f"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7b079e4af460f0dbae1696abb8c282b200d0c1ea"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}