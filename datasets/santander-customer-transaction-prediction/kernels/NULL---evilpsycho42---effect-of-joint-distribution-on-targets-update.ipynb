{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31c4660c022942fa782e115db96f0b61116b660b"},"cell_type":"markdown","source":"## 1. Take a look at effect of joint distribution on Targets"},{"metadata":{"trusted":true,"_uuid":"df29064198a761943401569d4b313c54a9fca65e"},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntest_df  = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbbb72b2aca61e56383553085235167d966c616a"},"cell_type":"code","source":"def corr_plot(v1, v2, n=10):\n    new = pd.DataFrame()\n    new[v1] = pd.cut(train_df[v1], 10, labels=[v1 + '_' + str(i) for i in range(1, 11)])\n    new[v2] = pd.cut(train_df[v2], 10, labels=[v2 + '_' + str(i) for i in range(1, 11)])\n    new['target'] = train_df['target']\n    new = new.groupby([v1, v2])['target'].mean().reset_index()\n    new = pd.pivot_table(index=[v1], columns=[v2], values=['target'], data=new)\n#     plt.figure(figsize=(10,8))\n    sns.heatmap(new)\n    plt.show()\n    return new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96fdc7434aee838d875f2c23587f175b931f5961"},"cell_type":"code","source":"corr_plot('var_108', 'var_154')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"058bfc938a42accb2510543a1fd334664755098b"},"cell_type":"markdown","source":"## It seems work, some joint encode have a high targets mean value.\n## 2. Let's check the information gains from joint encode."},{"metadata":{"trusted":true,"_uuid":"5ad1ca2a203390a6eb908adc0b741b603cc8135f"},"cell_type":"code","source":"df = pd.concat([train_df, test_df], axis=0, sort=False).reset_index(drop=True)\n# add variable category decode\ndf_decode = pd.DataFrame()\nn_cut = 10\nfeatures = [c for c in train_df.columns if c not in ['ID_code', 'target']]\nfor col in features:\n    col_decode = col + '_' + 'decode'\n    df_decode[col_decode] = pd.cut(df[col], n_cut, labels=range(0, n_cut))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13ea2619af491a475603e925a859b50531453781"},"cell_type":"code","source":"def add_joint(v1, v2):\n    return df_decode[v1 + '_' + 'decode'].astype(str) + df_decode[v2 + '_' + 'decode'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d90aded8f83c6fcc6f6c4948c275edaebef24cd7"},"cell_type":"code","source":"def entropy(x):\n    uniq, counts = np.unique(x, return_counts=True)\n    uniq_prob = counts / counts.sum()\n    entr = -np.sum(uniq_prob * np.log2(uniq_prob))\n    return entr\n\ndef condEntropy(cond, target):\n    cond_df = pd.DataFrame({'cond': cond, 'target': target}).dropna()\n    entr = cond_df.groupby('cond')['target'].apply(entropy)\n    prob = cond_df.groupby('cond')['target'].apply(lambda x: x.count() / cond_df.shape[0])\n    return np.sum(entr * prob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31f8555e4d7235ebb30eb46ab6c6b71e991a9b1c"},"cell_type":"code","source":"origin_target_entropy = entropy(train_df.target)\nvar108_cond_entropy = condEntropy(df_decode['var_108_decode'].iloc[:200000], train_df.target)\nvar154_cond_entropy = condEntropy(df_decode['var_154_decode'].iloc[:200000], train_df.target)\njoint_cond_entropy = condEntropy(add_joint('var_108', 'var_154').iloc[:200000], train_df.target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f884e2ad33cc51d07f9ffe4afd9e2e3dced90bf"},"cell_type":"code","source":"print(origin_target_entropy, var108_cond_entropy, var154_cond_entropy, joint_cond_entropy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e435d0d80f8cd0f47524e05b8c60245ea5129e15"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3cbe4d24956289aa83e0a5f1e580274232dbf6a8"},"cell_type":"markdown","source":"## emmmm  have a higher information gain indeed\n## 3. find the Top K combination"},{"metadata":{"trusted":true,"_uuid":"967b060ea4217cf9adb38aeb55b6ac2d4343cb46"},"cell_type":"code","source":"from itertools import combinations\ncombs = list(combinations([col for col in train_df if col not in ['ID_code', 'target']], 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0bfef918db882774213ade1b6e5f531571339ed"},"cell_type":"code","source":"print(combs[0])\nprint(len(combs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd409c507819433ba31fc1f0c9d58be3db968415"},"cell_type":"code","source":"%%time\njoint_cond_entropy = condEntropy(add_joint('var_108', 'var_154').iloc[:200000], train_df.target)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7e073de77c31bc7c06bb8ef7112a974419942f1"},"cell_type":"markdown","source":"### This will take nearly 3.5 hours"},{"metadata":{"trusted":true,"_uuid":"02969b7100b9f3612a7c56151d0a025a3a63ca2d"},"cell_type":"code","source":"df_decode = df_decode.iloc[:2000000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"027e0bd2bbee9a0c16bf8ab8a16c83c889c8e9f3"},"cell_type":"code","source":"%%time\nfrom tqdm import tqdm\n\nresult = dict()\nfor c in tqdm(combs):\n    ce  = condEntropy(add_joint(c[0], c[1]), train_df.target)\n    result[c] = ce\nresult = pd.Series(result).reset_index()\nresult.columns = ['v1', 'v2', 'entropy']\nresult = result.sort_values('entropy', ascending=True)\nresult.to_csv('joint_cond_entropy.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7201ea3161080b09d495122047b1ad179ade1b0d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}