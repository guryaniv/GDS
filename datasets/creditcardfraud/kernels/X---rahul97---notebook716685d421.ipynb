{"metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "mimetype": "text/x-python", "file_extension": ".py", "name": "python", "version": "3.6.2"}}, "nbformat": 4, "nbformat_minor": 1, "cells": [{"metadata": {"collapsed": true}, "source": ["import seaborn as sns\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import missingno as ms"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["**Description:**\n", "\n", "<img src = 'desc.png'/>"], "cell_type": "markdown"}, {"metadata": {}, "source": ["df = pd.read_csv('../input/creditcard.csv')\n", "df.head()"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"scrolled": true}, "source": ["ms.matrix(df)"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["* Great!, No Missing values in the dataset."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "source": ["fraud = df[df['Class'] == 1]\n", "not_fraud = df[df['Class'] == 0]"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true}, "source": ["col = list(df.columns)\n", "vectors = col[1:-2]"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"scrolled": true}, "source": ["\n", "for i in vectors:\n", "    \n", "    sns.FacetGrid(df, hue = 'Class', size = 4) \\\n", "       .map(sns.distplot, i) \\\n", "       .add_legend()\n", "    title = \"Feature \" + i\n", "    plt.title(title)\n", "    plt.show()"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["#### Observations:\n", "\n", "* Most of the feature distributions overlap when potted differentiating on the two classes.\n", "* The distribution plots of **V3, V4, V9, V10, V11, V12, V14, V16, V17, V18, V19** are not so much overlapping as the remaining features.\n", "\n", "\n", "\n"], "cell_type": "markdown"}, {"metadata": {"scrolled": true}, "source": ["sel_col = ['V3', 'V4', 'V9', 'V10', 'V11', 'V12', 'V16', 'V17', 'V18','Class']\n", "for i in sel_col[:-1]:\n", "    counts, bin_edges = np.histogram(fraud[i], bins=30, \n", "                                 density = True)\n", "\n", "    pdf = counts/(sum(counts))\n", "\n", "\n", "#compute CDF\n", "    cdf = np.cumsum(pdf)\n", "    plt.plot(bin_edges[1:],pdf)\n", "    plt.plot(bin_edges[1:], cdf)\n", "\n", "    counts, bin_edges = np.histogram(not_fraud[i], bins=30, \n", "                                 density = True)\n", "\n", "    pdf = counts/(sum(counts))\n", "\n", "\n", "#compute CDF\n", "    cdf = np.cumsum(pdf)\n", "    plt.plot(bin_edges[1:],pdf)\n", "    plt.plot(bin_edges[1:], cdf)\n", "    plt.legend(['fraud_pdf', 'fraud_cdf','not_fraud_pdf', 'not_fraud_cdf'])\n", "    plt.title(\"Feature {0} distributions\".format(i))\n", "\n", "    plt.show();"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["**Observations:**\n", "* Simple conditioned models can be made from the above distribution plots by placing few **constraints** on the various **features**."], "cell_type": "markdown"}, {"metadata": {"scrolled": true}, "source": ["sel_col = ['V3', 'V4', 'V9', 'V10', 'V11', 'V12', 'V14', 'V16', 'V17', 'V18', 'V19','Class']\n", "sel_data = df[sel_col]\n", "print(sel_data.head())\n", "g = sns.pairplot(sel_data, hue = 'Class', size = 5)\n", "g.savefig(\"pairplot.png\")"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["**Observations:**\n", "\n", "* The following relationship scactter plots are more **clustered** than remaining **pair scatter plot - relationships.**"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "source": ["col_dic =  {'V28': ['V18', 'V17'],\n", "         'V27': ['V18', 'V17', 'V11', 'V12'],\n", "         'V25':['V17', 'V12'],\n", "          'V24':['V18', 'V17'],\n", "          'V23': ['V19', 'V18', 'V17', 'V14', 'V12', 'V11'],\n", "          'V22': ['V18', 'V17', 'V11'],\n", "           'V21': ['V18', 'V16'],\n", "            'V20': ['V18', 'V17', 'V11'],\n", "        'V18': ['V23', 'V21', 'V20', 'V17', 'V16'],\n", "        'V17': ['V18'],\n", "        'V16': ['V18', 'V17', 'V12'],\n", "        'V14': ['V23', 'V20', 'V10', 'V6'],\n", "         'V12': ['V23'],\n", "        'V11': ['V27', 'V23', 'V12'],\n", "        'V8':['V18', 'V17', 'V14', 'V11'],\n", "        'V7':['V18', 'V11'],\n", "        'V6': ['V10', 'V9', 'V8', 'V7'],\n", "         'V5': ['V6', 'V5'],\n", "        'V4': ['V3'],\n", "        'V2':['V1'],\n", "        'V1':['V2']}"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"scrolled": true}, "source": ["for i in col_dic:\n", "    aga = col_dic[i]\n", "    for j in aga:\n", "        sns.lmplot(x=i, y=j, data = df, hue = 'Class', size = 5, fit_reg= False)\n", "        plt.show()"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["**Observations:**\n", "* These are the plots where the **fraud** observations tend to lie along a **line**.\n", "* Most values of the **fraud** observations tend to lie around **zero**."], "cell_type": "markdown"}, {"metadata": {}, "source": ["sns.FacetGrid(df, hue = 'Class', size = 6) \\\n", "       .map(sns.distplot, 'Time') \\\n", "       .add_legend()\n", "plt.show()"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["counts, bin_edges = np.histogram(fraud['Time'], bins=30, \n", "                                 density = True)\n", "\n", "pdf = counts/(sum(counts))\n", "\n", "\n", "#compute CDF\n", "cdf = np.cumsum(pdf)\n", "plt.plot(bin_edges[1:],pdf)\n", "plt.plot(bin_edges[1:], cdf)\n", "\n", "counts, bin_edges = np.histogram(not_fraud['Time'], bins=30, \n", "                                 density = True)\n", "\n", "pdf = counts/(sum(counts))\n", "\n", "\n", "#compute CDF\n", "cdf = np.cumsum(pdf)\n", "plt.plot(bin_edges[1:],pdf)\n", "plt.plot(bin_edges[1:], cdf)\n", "plt.legend(['fraud_pdf', 'fraud_cdf','not_fraud_pdf', 'not_fraud_cdf'])\n", "plt.title('Time distributions')\n", "\n", "plt.show();"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["sns.FacetGrid(df, hue = 'Class', size = 6) \\\n", "       .map(sns.distplot, 'Amount') \\\n", "       .add_legend()\n", "plt.show()"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["counts, bin_edges = np.histogram(fraud['Amount'], bins=30, \n", "                                 density = True)\n", "\n", "pdf = counts/(sum(counts))\n", "\n", "\n", "#compute CDF\n", "cdf = np.cumsum(pdf)\n", "plt.plot(bin_edges[1:],pdf)\n", "plt.plot(bin_edges[1:], cdf)\n", "\n", "counts, bin_edges = np.histogram(not_fraud['Amount'], bins=30, \n", "                                 density = True)\n", "\n", "pdf = counts/(sum(counts))\n", "\n", "\n", "#compute CDF\n", "cdf = np.cumsum(pdf)\n", "plt.plot(bin_edges[1:],pdf)\n", "plt.plot(bin_edges[1:], cdf)\n", "plt.legend(['fraud_pdf', 'fraud_cdf','not_fraud_pdf', 'not_fraud_cdf'])\n", "plt.title(\"Amount distributions\")\n", "\n", "plt.show();"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["**Observations:**\n", "\n", "* Fraud **CDF Time distribtion** of **fraud** is always on top of **not fraud CDF**, therefore we can conclude that the **fraud member** takes large intervals of time than the **not fraud** member.\n", "* The **fraud** members transaction amount is less than the amount of **not fraud** and decreases immediately  to **zero**."], "cell_type": "markdown"}, {"metadata": {"scrolled": true}, "source": ["print(\"The shape of the dataset is: \", df.shape)"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["* The dataset has **284807** observaions, and **31** attributes."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "source": ["col = list(df.columns)\n", "vec = col"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true}, "source": ["df_vec = df[vec]"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["df_vec.head()"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["* Since computing the metrics for each of the observations in the dataset is computationally expensive, I have choosen random 10 observations using **np.random.randint** function of **Numpy**. "], "cell_type": "markdown"}, {"metadata": {}, "source": ["## Computing cosine-similiarity."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "source": ["np.random.seed(101)"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["choice = np.random.randint(0, 284807, size = 30)\n", "print(\"These are my randomly choosen observation indcies: \",choice)"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["* Let's make the randomly choosen observation indices as columns for the new DataFrame for storing the **metrics**."], "cell_type": "markdown"}, {"metadata": {}, "source": ["met_df = pd.DataFrame(columns = choice)\n", "met_df"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["* Created the metric Dataframe under the name **met_df** for storing the metrics."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "source": ["# Iterating through all the randomly choosen Observations/Vectors.\n", "for i in choice:\n", "    '''\n", "        i          - Loop variable.\n", "        \n", "        multiplier - The ith observation values in the dataset that is randomly choosen.\n", "        \n", "        drop_df    - The dataframe obtained by removing the ith observation.\n", "        \n", "        metric     - This metric is computed taking each row in the \"drop_df\" DataFrame and dot product with \"multiplier\" and divided\n", "                     by product of length of \"multiplier\" and length of each \"observation\". This variable is a pandas series.\n", "                 \n", "        met_df     - This DataFrame consists of all the calculated metrics.\n", "        \n", "        The lambda function leveraged most of the work in the whole calculation.\n", "    ''' \n", "    multiplier = list(df_vec.iloc[i])\n", "    drop_df = df_vec.drop(df.index[i])\n", "    metric = drop_df.apply(lambda x: np.dot(multiplier, x) / (len(multiplier) * len(x)), axis = 1) \n", "    met_df[i] = sorted(metric)"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["print(\"The shape of the met_df is: \",met_df.shape)"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["* The number of observations in the **met_df** DataFrame is one less than the actual number of observations in the data set due to the metrics calculated in the way of **one-many** relationship.\n", "* Saving the **met_df** dataframe for the future use."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "source": ["met_df.to_csv('metrics.csv')"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["* Calculating the lowest 10 observations and storing into **lowest_10** DataFrame."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "source": ["lowest_10 = met_df.iloc[:10]"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["lowest_10"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"scrolled": true}, "source": ["low_10 = list(lowest_10.columns)\n", "\n", "for i in low_10:\n", "    print(\"\\n\\nThe Class value of {0} is {1}\".format(i, df.loc[i]['Class']))\n", "    print(\"The lowest 10 values of {0} index observations, are {1} \\n\".format(i, lowest_10[i].values))\n", "    "], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["**Done!**"], "cell_type": "markdown"}]}