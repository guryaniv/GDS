{"cells":[{"metadata":{"_uuid":"adacec501a5910dcbb2a61758a435bbb4d8b8f90"},"cell_type":"markdown","source":"## Importing required libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport numpy as np\n\nfrom PIL import Image\n\nimport torch\nfrom torch import nn, optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\n\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mplimg\nfrom matplotlib.pyplot import imshow\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e21e024d06b69a988f680897b10daa48441f330"},"cell_type":"markdown","source":"## Checking the gpu availability"},{"metadata":{"trusted":true,"_uuid":"c65427ecc4eaf682522f12206bdba4646d16fc9d"},"cell_type":"code","source":"# gpu test\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab26d8d9d45dc3af1bb589a2f853fd6194e19ce6"},"cell_type":"markdown","source":"## Loading the training csv"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# lets load the train.csv\ntrain_df = pd.read_csv(\"../input/train.csv\")\nle = LabelEncoder()\ntrain_df['target'] = le.fit_transform(train_df['Id'])\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04df19ca6a13bb005a8b2ebfc3469ea062bf2f1c"},"cell_type":"markdown","source":"## Visualizing images"},{"metadata":{"trusted":true,"_uuid":"88b242a483c2ffbfc70db9ff7a06aa60895d4099"},"cell_type":"code","source":"# lets plot some images\nfig = plt.figure(figsize=(25, 10))\nfor idx, img in enumerate(np.random.choice(os.listdir(\"../input/train\"), 10)):\n    ax = fig.add_subplot(2, 10//2, idx+1, xticks=[], yticks=[])\n    im = Image.open(\"../input/train/\" + img)\n    plt.imshow(im)\n    lab = train_df.loc[train_df.Image == img, 'Id'].values[0]\n    ax.set_title(f'Label: {lab}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b455af92eb26a8dd577ee2370a021ffeb24f011"},"cell_type":"markdown","source":"## Prearing data set for pytorch data loader\nPytorch does required image classes in different folders. But this data set contains all images in one folder. So we need to customise Dataset class of pytorch."},{"metadata":{"trusted":true,"_uuid":"daebf96072f50ba4529bb287020ba4a6297a4ae2"},"cell_type":"code","source":"class HW_Dataset(Dataset):\n    def __init__(self,filepath,train_df,transform=None):\n        self.file_path = filepath\n        self.df = train_df\n        self.transform = transform\n        self.image_list = [x for x in os.listdir(self.file_path)]\n        \n    def __len__(self):\n        return(len(self.image_list))\n    \n    def __getitem__(self,idx):\n        img_path = os.path.join(self.file_path,self.df.Image[idx])\n        img = Image.open(img_path).convert('RGB')\n        img = self.transform(img)\n        target = self.df.target[idx]\n        return (img,target)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86c6dce7f5d4e3a2eb87f2644d02b2e86e52b874"},"cell_type":"markdown","source":"## Data loading to Data loader"},{"metadata":{"trusted":true,"_uuid":"b3f250fe2ebf31b69627e8f6e9423d303decf31a"},"cell_type":"code","source":"transform = transforms.Compose([transforms.RandomResizedCrop(224), \n                                transforms.RandomHorizontalFlip(), \n                                transforms.ToTensor(),\n                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n\ntrain_dataset = HW_Dataset(filepath='../input/train/',train_df=train_df,transform=transform)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8bcff62ff4f729b77c6d342bab3d2ec826ab792"},"cell_type":"markdown","source":"## Pretrained Model"},{"metadata":{"trusted":true,"_uuid":"01ae74f962275c481ebe8161db9bb034a568252b"},"cell_type":"code","source":"model = models.resnet18(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd08aedda8b5f3e4d850c924a347dbfffc77f81b"},"cell_type":"markdown","source":"## Model building"},{"metadata":{"trusted":true,"_uuid":"1a10457ee1fef8f424996073d9238e3cac945717"},"cell_type":"code","source":"from collections import OrderedDict\nclassifier = nn.Sequential(OrderedDict([\n                          ('do1', nn.Dropout(0.2)),\n                          ('fc1', nn.Linear(512, 5005))\n                          ]))\n    \nmodel.fc = classifier\n\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nscheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb1fc5a20acbdf9a5a7834fe35ee84d3ac53f0df"},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true,"_uuid":"0b0e324a4c7245a598e5c97a4e31c4965e7aa96a"},"cell_type":"code","source":"n_epochs = 30\nvalid_loss_min = np.Inf\n\nfor epoch in range(1, n_epochs+1):\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    train_acc = 0.0\n    valid_acc = 0.0\n    ###################\n    # train the model #\n    ###################\n    model.train()\n    \n    scheduler.step()\n    running_loss = 0.0\n    running_corrects = 0\n\n    for data, target in train_loader:\n        # move tensors to GPU if CUDA is available\n        #print(target.data)\n        data, target = data.to(device), target.to(device)\n        \n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        \n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        _, preds = torch.max(output, 1)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        running_loss += loss.item() * data.size(0)\n        running_corrects += torch.sum(preds == target.data)\n    epoch_loss = running_loss / len(train_dataset)\n    epoch_acc = running_corrects.double() / len(train_dataset)\n    print('Epoch: {} \\t{:.6f} \\t {:.0%}'.format( epoch, epoch_loss, epoch_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"673fd4f5d9654df5fe2d1f778c1f3e37e039ae6d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}