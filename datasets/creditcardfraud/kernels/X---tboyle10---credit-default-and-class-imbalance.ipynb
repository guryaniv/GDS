{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"df = pd.read_csv('../input/creditcard.csv')\n\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7d92ecec94ee2633bd378b3d55100c6b9362636","trusted":false,"collapsed":true},"cell_type":"code","source":"print(df.Class.value_counts())\n\nsns.countplot(df.Class)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"460b8fbc891a865d755de263e832474d22718577"},"cell_type":"markdown","source":"From the plot above, we can see we have a very imbalanced class.  \n\nBy working through the tutorial found here:  https://elitedatascience.com/imbalanced-classes we can effective ways to deal with class imbalance."},{"metadata":{"_uuid":"876d7f98c708ae91ce22f728d63abdbb1c573fac","trusted":false,"collapsed":true},"cell_type":"code","source":"# Separate input features and target\ny = df.Class\nX = df.drop('Class', axis=1)\n\n# first setting up testing and training sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3326dfa795f14d1f4357881c3dde02f84b5574dd","trusted":false,"collapsed":true},"cell_type":"code","source":"# Modeling the data as is\n# Train model\ntake_0 = LogisticRegression().fit(X_train, y_train)\n \n# Predict on training set\ntake_0_y_ = take_0.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df5a5a9588b0d0ee1d9b80e94d1c63885718976d","trusted":false,"collapsed":true},"cell_type":"code","source":"# Checking accuracy\naccuracy_score(y_test, take_0_y_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64afcae23af7b0903f10fa0d2992de3a137e2c10","trusted":false,"collapsed":true},"cell_type":"code","source":"# Checking unique values\npredictions = pd.DataFrame(take_0_y_)\npredictions[0].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dffefb9a7656b70369b1392747345f1b7c5ad830","collapsed":true},"cell_type":"markdown","source":"We have a very high accuracy score of 0.999 but that is only because the model is predicting mostly no fraud cases.  We can attempt to deal with this in several different ways.\n\n## 1. Up-sample Minority Class"},{"metadata":{"_uuid":"e48e7eb85c4b0a67c3f096726fef7b472e6b293d","trusted":false,"collapsed":true},"cell_type":"code","source":"from sklearn.utils import resample","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd10e5f5f96a9c3fe607d0fb35475fe62fa75675","trusted":false,"collapsed":true},"cell_type":"code","source":"# separate minority and majority classes\nnot_fraud = df[df.Class==0]\nfraud = df[df.Class==1]\n\n# upsample minority\nfraud_upsampled = resample(fraud,\n                          replace=True, # sample with replacement\n                          n_samples=284315, # match number in majority class\n                          random_state=27) # reproducible results\n\n# combine majority and upsampled minority\nupsampled = pd.concat([not_fraud, fraud_upsampled])\n\n# check new class counts\nupsampled.Class.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48e16be49fbda450115a2d169d3edc5979f633c0","trusted":false,"collapsed":true},"cell_type":"code","source":"# trying logistic regression again with the balanced dataset\n\ny = upsampled.Class\nX = upsampled.drop('Class', axis=1)\n\n# setting up testing and training sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n\ntake_1 = LogisticRegression().fit(X_train, y_train)\n\ntake_1_y_ = take_1.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24f541f7a98c359d213baf5e6463b6245369fc74","trusted":false,"collapsed":true},"cell_type":"code","source":"# Checking accuracy\naccuracy_score(y_test, take_1_y_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe80a5385a4ab11c0c54796b64c2f9e46126f745","trusted":false,"collapsed":true},"cell_type":"code","source":"# Checking unique values\npredictions['Prediction'] = pd.DataFrame(take_1_y_)\npredictions.Prediction.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0b5c7e2b673baac682bb89d9484ad9f7fbea16e"},"cell_type":"markdown","source":"Our accuracy score decreased after upsampling, but the model is now predicting both classes more equally, making it a better model.\n\n## 2. Down-sample Majority Class"},{"metadata":{"_uuid":"15c289c9551acca877a3ca824c6b2f074daccce6","trusted":false,"collapsed":true},"cell_type":"code","source":"# still using our separated classes fraud and not_fraud from above\n\n# downsample majority\nnot_fraud_downsampled = resample(not_fraud,\n                                replace = False, # sample without replacement\n                                n_samples = 492, # match minority n\n                                random_state = 27) # reproducible results\n\n# combine minority and downsampled majority\ndownsampled = pd.concat([not_fraud_downsampled, fraud])\n\n# checking counts\ndownsampled.Class.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"339ff5f558175b8daf2a4536d4749978e7e7c4fd","trusted":false,"collapsed":true},"cell_type":"code","source":"# trying logistic regression again with the balanced dataset\n\ny = downsampled.Class\nX = downsampled.drop('Class', axis=1)\n\n# setting up testing and training sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n\ntake_2 = LogisticRegression().fit(X_train, y_train)\n\ntake_2_y_ = take_2.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4808d815c2531edfbb93ad420a40bf2aa4c85f4","trusted":false,"collapsed":true},"cell_type":"code","source":"# Checking accuracy\naccuracy_score(y_test, take_2_y_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f79a91effffd12bec83359230618af1c7ed23f3","trusted":false,"collapsed":true},"cell_type":"code","source":"# Checking unique values\npredictions['Prediction'] = pd.DataFrame(take_2_y_)\npredictions.Prediction.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0cdac5de057cf831e81f8766b539834accf46663"},"cell_type":"markdown","source":"Downsampling produced a higher accuracy than upsampling!  My concern here is the small number of total samples we had to train the model on.  I'm not sure if this method is truely better than upsampling?\n\n## 3.  Change the performance metric"},{"metadata":{"_uuid":"216f90a50e08df92e0b76a88c606f205d05df53a","trusted":false,"collapsed":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60ee03ae8890fff81189a82135558b6d5f033adb","trusted":false,"collapsed":true},"cell_type":"code","source":"take_2_y_ = take_2.predict_proba(X_test)\n\ntake_2_y_ = [p[1] for p in take_2_y_]\n\nroc_auc_score(y_test, take_2_y_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d8da9fb3ab83e275a3c0c7903d0419c3c1f93d9","collapsed":true},"cell_type":"markdown","source":"## 4. Tree Based Algorithms"},{"metadata":{"_uuid":"e6ae6bd16df017f3afba574959d03b4436ec636a","trusted":false,"collapsed":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"91cce39e7c4552ea8a29ccb73546af9c495b0f1a"},"cell_type":"code","source":"# Separate input features and target\ny = df.Class\nX = df.drop('Class', axis=1)\n\n# setting up testing and training sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"732b7f4fe64b1607af83cc63dcdb008d24f6bce7","trusted":false,"collapsed":true},"cell_type":"code","source":"# train model\ntake_4 = RandomForestClassifier().fit(X_train, y_train)\n\n# predict on test set\ntake_4_y_ = take_4.predict(X_test)\n\naccuracy_score(y_test, take_4_y_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa12cb6a1bd8b8f6b961f10381b28007c6a761f5","trusted":false,"collapsed":true},"cell_type":"code","source":"# Checking unique values\npredictions['Prediction'] = pd.DataFrame(take_4_y_)\npredictions.Prediction.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bde53447fef057292a1d52b62978e53b7d44f8f"},"cell_type":"markdown","source":"The Random Forest has an accuracy score of 0.9995 - which is higher than our first model!  This seems to be the best option for this dataset!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}