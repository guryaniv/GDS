{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np\nnp.random.seed(42)\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nfrom keras.models import Model\nfrom keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D\nfrom keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import Callback\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nos.environ['OMP_NUM_THREADS'] = '4'\n\n\n#Text Cleaning\nimport spacy #load spacy\nfrom nltk import word_tokenize          \nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nimport re\nfrom string import punctuation\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nfrom spacy.lang.en.stop_words import STOP_WORDS\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nprint(os.listdir(\"../input/fast-text-crwal-300d-2m/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"EMBEDDING_FILE = '../input/fast-text-crwal-300d-2m/fasttext-crawl-300d-2m/crawl-300d-2M.vec'","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"16ccdbaa-d0b1-484a-833f-41453d0feef8","_uuid":"42f62a38b30e289cdcfe7327fb720d76af3addca","trusted":false},"cell_type":"code","source":"train = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\ntest = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')\nsubmission = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"fc17dd51-f238-49ef-ae5f-c41207090fb4","_uuid":"0ebf600a2c46662aa8eaebeea2a6d351389d61cc","trusted":false},"cell_type":"code","source":"def text_to_wordlist(text, remove_stop_words=True, stem_words=False):\n    #Lower text\n    text = text.lower()\n    # Remove punctuation from text\n    text = ''.join([c for c in text if c not in punctuation])\n    \n    # Optionally, remove stop words\n    if remove_stop_words:\n        text = text.split()\n        text = [w for w in text if not w in stop]\n        text = \" \".join(text)\n    \n    # Optionally, shorten words to their stems\n    if stem_words:\n        text = text.split()\n        stemmer = SnowballStemmer('english')\n        stemmed_words = [stemmer.stem(word) for word in text]\n        text = \" \".join(stemmed_words)\n    \n    # Return a list of words\n    return(text)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"7a938f52-3ce8-41da-af23-b3575333aec8","_uuid":"86bec64f72c8ceae76e06752c27c997c72102d8d","trusted":false},"cell_type":"code","source":"train['comment_text_Clean'] = train['comment_text'].apply(text_to_wordlist)\ntest['comment_text_Clean'] = test['comment_text'].apply(text_to_wordlist)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bbef1170-2a5a-4635-b62f-9e1671731aa6","_uuid":"a37b12ddb5d4fd66e1e475c99dfe432d09143d62","trusted":false,"collapsed":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"6f1c5a36-2dec-4573-bad0-f53f719cfa6d","_uuid":"efb415d500d09d3e9a898a689b0d9a934fa86c23","trusted":false},"cell_type":"code","source":"train['comment_text_Clean'] = train['comment_text_Clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (STOP_WORDS)]))\ntest['comment_text_Clean'] = test['comment_text_Clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (STOP_WORDS)]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8dc739b1-fa49-4bb9-a678-4e9378af4d62","_uuid":"c257191a6ca7a43a50a8c2babcdb8b6b7e1333da","trusted":false,"collapsed":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"c0333682-827d-414b-ad2f-dd1c5698c397","_uuid":"540b125dc6083502ca0d06422834cee104dfca56","trusted":false},"cell_type":"code","source":"X_train = train[\"comment_text_Clean\"].fillna(\"fillna\").values\ny_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\nX_test = test[\"comment_text_Clean\"].fillna(\"fillna\").values\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"96ed8001-11e2-48d2-a651-2dde5870f945","_uuid":"a0759233666acde4d5d9dcbdd4792eb08ba6ce28","trusted":false},"cell_type":"code","source":"max_features = 100000\nmaxlen = 200\nembed_size = 300","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"801f034f-8db4-4fbe-9fcc-fcbfb68e1c0b","_uuid":"90e01e7d8aeb7b4430dd85cbde1ea5b7866e5071","trusted":false},"cell_type":"code","source":"tokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(X_train) + list(X_test))\nX_train = tokenizer.texts_to_sequences(X_train)\nX_test = tokenizer.texts_to_sequences(X_test)\nx_train = sequence.pad_sequences(X_train, maxlen=maxlen)\nx_test = sequence.pad_sequences(X_test, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"123f9ef7-e000-456f-a4c1-c0f1e6f2f51a","_uuid":"7459e5363a6cc07de0ba89271e0f74025aa8d401","trusted":false},"cell_type":"code","source":"def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\nembeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"0b48fe03-26d9-4f22-a1d1-2c909fcca1a3","_uuid":"826396901e6999d5006d0b5ef62df779485d8cad","trusted":false},"cell_type":"code","source":"word_index = tokenizer.word_index\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.zeros((nb_words, embed_size))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"d169e081-1c08-4df8-b353-5915cf8fc42a","_uuid":"61edc548542b8dba6b0a46b03f21b6144ef2708e","trusted":false},"cell_type":"code","source":"for word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"21ed61b3-930c-44c6-b683-ff396e4cda67","_uuid":"9e0d309b429e58274a9e71f6a059de4666c9b2ec","trusted":false},"cell_type":"code","source":"class RocAucEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"a0d40c1b-7d0c-4188-ab05-806b2759a049","_uuid":"73ad4c97e8cca88dcd973dfc18123c791a15dca8","trusted":false},"cell_type":"code","source":"def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"51a60f01-eabe-45c5-90ff-a550890cedf9","_uuid":"6092bfd6335d25456c4770f28480d0705348df09","trusted":false},"cell_type":"code","source":"filter_sizes = [1,2,3,5]\nnum_filters = 32","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"56db8f42-ebd8-4fea-8f21-34774886b69d","_uuid":"95abecc762d978fe3078425d5cb89aff9e9e19e1","trusted":false},"cell_type":"code","source":"def get_model():    \n    inp = Input(shape=(maxlen, ))\n    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n    x = SpatialDropout1D(0.4)(x)\n    x = Reshape((maxlen, embed_size, 1))(x)\n    \n    conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embed_size), kernel_initializer='normal',\n                                                                                    activation='elu')(x)\n    conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embed_size), kernel_initializer='normal',\n                                                                                    activation='elu')(x)\n    conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embed_size), kernel_initializer='normal',\n                                                                                    activation='elu')(x)\n    conv_3 = Conv2D(num_filters, kernel_size=(filter_sizes[3], embed_size), kernel_initializer='normal',\n                                                                                    activation='elu')(x)\n    \n    maxpool_0 = MaxPool2D(pool_size=(maxlen - filter_sizes[0] + 1, 1))(conv_0)\n    maxpool_1 = MaxPool2D(pool_size=(maxlen - filter_sizes[1] + 1, 1))(conv_1)\n    maxpool_2 = MaxPool2D(pool_size=(maxlen - filter_sizes[2] + 1, 1))(conv_2)\n    maxpool_3 = MaxPool2D(pool_size=(maxlen - filter_sizes[3] + 1, 1))(conv_3)\n        \n    z = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, maxpool_3])   \n    z = Flatten()(z)\n    z = Dropout(0.1)(z)\n        \n    outp = Dense(6, activation=\"sigmoid\")(z)\n    \n    model = Model(inputs=inp, outputs=outp)\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"7aedddf5-0cf8-4211-8585-52b66fb2d716","_uuid":"bb342b3fd46dc0ff454aa42533ebf004f53ca2fc","trusted":false},"cell_type":"code","source":"model = get_model()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"29dafbe2-76cc-434d-9025-6a3c890b8f42","_uuid":"8f87fa41684a6721067722bc4d5faab40c102d23","trusted":false,"collapsed":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"f769fedb-427b-4703-913f-a6038c4fa2ca","_uuid":"ad1b60287353eca15711eb16dcf075d7664d4f53","trusted":false},"cell_type":"code","source":"batch_size = 256\nepochs = 3","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"1c0e2fa2-1328-4d1c-966b-3d57c08d6d77","_uuid":"0439b34268e87fc6844e9f1e2e24761a1724c262","trusted":false},"cell_type":"code","source":"X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)\nRocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5b1218cb-107a-461d-bbb9-e86cc4ac45b3","_uuid":"b895f475eab2a8d134092fb048c6ecff90abcdbd","trusted":false,"collapsed":true},"cell_type":"code","source":"hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n                 callbacks=[RocAuc], verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"2442b3a8-541d-4d48-a008-6981ab52869a","_uuid":"b32bf592230e7ef8635e11b930a4cde1c5f67690","trusted":false},"cell_type":"code","source":"y_pred = model.predict(x_test, batch_size=1024)\nsubmission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\nsubmission.to_csv('../input/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0ad44148-720a-43b5-804b-23f63210487e","_uuid":"f7e8ef52e102fd0d412459388ca3748c65cf00d5"},"cell_type":"markdown","source":"From @ https://www.kaggle.com/yekenot/textcnn-2d-convolution/code"},{"metadata":{"collapsed":true,"_cell_guid":"2a5712f7-f1c1-404a-8059-bbc167d5c8bf","_uuid":"91b3caf1261b17c9ae62696e960ddcb4b7794c7e","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}