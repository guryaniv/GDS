{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport re\nfrom collections import Counter\nimport nltk\n#from nltk.util import ngrams\nimport collections\nimport spacy\nimport matplotlib\nimport matplotlib.pyplot as plt # for plotting\nimport seaborn as sns\n%env JOBLIB_TEMP_FOLDER=/tmp\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/train.tsv\",sep='\\t') ##Load full data\ntest_data = pd.read_csv(\"../input/test.tsv\",sep='\\t') ##Load full data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2f8296e163502a31c8afe1412366c1dd00d118d","collapsed":true},"cell_type":"code","source":"print(\"Train\",train_data.shape,\"Test\",test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31cc89dc694f3f74ff9f85f9cb23246f331454e4","collapsed":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"12ce18d7fad7fcd3cb16564922f811bfc4d5274b","collapsed":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"783b2d996e703096be19210fbf72aa6fbf64048b","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"count = train_data['Sentiment'].value_counts().plot(kind=\"pie\",shadow=True,startangle=90,autopct='%1.1f%%',figsize=(7,7))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb454670dcb12090968dcc8d37a247de683e2447"},"cell_type":"markdown","source":"* Target\n* * Negative - 0\n* * Somewhat negative - 1\n* * Neutral - 2\n* * Somewhat positive - 3\n* * Positive - 4\n*"},{"metadata":{"_uuid":"8c834140063b511f17aef533c796f63276c48150"},"cell_type":"markdown","source":"**EDA On Text**"},{"metadata":{"trusted":true,"_uuid":"6e430174945ab8c72f4079944f7190ccbf8a8768","collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"train_word_counter = collections.Counter([word for sentence in train_data['Phrase'] for word in sentence.split()])\ntest_word_counter = collections.Counter([word for sentence in test_data['Phrase'] for word in sentence.split()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21c49fc762ac7ba8fdc1e862d9ba852703b3a2cf","collapsed":true},"cell_type":"code","source":"print('{} Words in Training dataset.'.format(len([word for sentence in train_data['Phrase'] for word in sentence.split()])))\nprint('{} unique words in Training dataset.'.format(len(train_word_counter)))\nprint('20 Most common words in the Training dataset:')\nprint('\"' + '\" \"'.join(list(zip(*train_word_counter.most_common(30)))[0]) + '\"')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f3bd5125a1dc06fa4165fba79a09bfc0c6b0abd","collapsed":true},"cell_type":"code","source":"print('{} Words in Training dataset.'.format(len([word for sentence in test_data['Phrase'] for word in sentence.split()])))\nprint('{} unique words in Training dataset.'.format(len(test_word_counter)))\nprint('20 Most common words in the Training dataset:')\nprint('\"' + '\" \"'.join(list(zip(*train_word_counter.most_common(30)))[0]) + '\"')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08f446f64c391a653f9a21c4b0da1cd4d2d8bfec"},"cell_type":"markdown","source":"**Well..STOPWORDs!!! and Punctions \n**\n"},{"metadata":{"_uuid":"b2ed8a372a61fc1822f107eb630c0afc81f5a879"},"cell_type":"markdown","source":"This one from @ Andews kaernal"},{"metadata":{"trusted":true,"_uuid":"77d2f6a1aa4bb855bdacea88e4901f7c65d6eff2","collapsed":true},"cell_type":"code","source":"print('Average count of phrases per review in train is {0:.0f}.'.format(train_data.groupby('SentenceId')['Phrase'].count().mean()))\nprint('Average count of phrases per review in test is {0:.0f}.'.format(test_data.groupby('SentenceId')['Phrase'].count().mean()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"349825ab3fdbd7b0b2822dafaf0e5736c624f99c"},"cell_type":"markdown","source":"**Lemmatitation and Stopwords Removal - Spacy**"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4f8ac4fffca8a08b94a670e5e69f82ccbec96ca8","_kg_hide-input":true},"cell_type":"code","source":"import spacy #load spacy\nnlp = spacy.load(\"en\", disable=['parser', 'tagger', 'ner'])\nfrom nltk.corpus import stopwords\nstops = stopwords.words(\"english\")\n\n\n\ndef normalize(comment, lowercase, remove_stopwords):\n    if lowercase:\n        comment = comment.lower()\n    comment = nlp(comment)\n    lemmatized = list()\n    for word in comment:\n        lemma = word.lemma_.strip()\n        if lemma:\n            if not remove_stopwords or (remove_stopwords and lemma not in stops):\n                lemmatized.append(lemma)\n    return \" \".join(lemmatized)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e887767babcfd5379fa8c8abaf517310dab19e54","collapsed":true},"cell_type":"code","source":"train_data['Phrase_Clean'] = train_data['Phrase'].apply(normalize, lowercase=True, remove_stopwords=True)\ntest_data['Phrase_Clean'] = test_data['Phrase'].apply(normalize, lowercase=True, remove_stopwords=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"501a0e67cb814f1c145e59cfaa5bdfb070afd009","collapsed":true},"cell_type":"code","source":"train_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afd587f8951a87f9767f56c8eede65a25150c400","collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"def cleaning(s):\n    \n    s = str(s)\n    #s = s.split(s)\n    s = s.lower()\n    s = re.sub('\\s\\W',' ',s)\n    s = re.sub('\\W,\\s',' ',s)\n    s = re.sub(r'[^\\w]', ' ', s)\n    #s = re.sub(\"\\d+\", \"\", s)\n    s = re.sub('\\s+',' ',s)\n    s = re.sub('[!@#$_]', '', s)\n    s = s.replace(\",\",\"\")\n    s = s.replace(\"[\\w*\",\" \")\n    s = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', s, flags=re.MULTILINE)\n    s = re.sub(r'\\<a href', ' ', s)\n    s = re.sub(r'&amp;', '', s) \n    s = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', s)\n    s = re.sub(r'[^\\x00-\\x7f]',r'',s) #removes arabic\n    s = re.sub(r'<br />', ' ', s)\n    s = re.sub(r'\\'', ' ', s)\n    s = re.sub(r\"agh\",\"are not gonna happen\",s)\n    s = re.sub(r\"wtf\",\"what the fuck\",s)\n    s = re.sub(r\"asap\",\"as soon as possible\",s)\n    s = re.sub(r\"lol\",\"lots of laughs\",s)\n    s = re.sub(r\"[0-9]+\", '',s)\n    s = re.sub(r\" s\", '',s)\n    \n    return s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d13b30c7155621de45c0a31fe6d056fadcfbf8e","collapsed":true},"cell_type":"code","source":"train_data['Phrase_Clean'] = [cleaning(s) for s in train_data['Phrase_Clean']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa6d4262f3e09711eca4c2d67af9667751f5a5df","collapsed":true},"cell_type":"code","source":"train_data['Phrase_Clean'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5d892babd31a18bd99831fa1587125c84a9840b8","collapsed":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a7d5bae669cf407439ea98bd834b0f89a976db49"},"cell_type":"code","source":"train_data = train_data[train_data.Phrase_Clean !='']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae9c8a153f4b000af7c2937505f1c11c9c0b695c","collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"from nltk import ngrams\ntext = ' '.join(train_data.loc[train_data.Sentiment == 0, 'Phrase_Clean'].values)\nNegativeSentence = [i for i in ngrams(text.split(), 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"122369b9b2d5046e080954fe6f4bbe9352af9904","collapsed":true},"cell_type":"code","source":"print(\"Top NegativeSentence Words in Training Dataset\",Counter(NegativeSentence).most_common(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27f89b6152e58b57670b66872e0f47d1a5bd13c9","collapsed":true},"cell_type":"code","source":"text = ' '.join(train_data.loc[train_data.Sentiment == 1, 'Phrase_Clean'].values)\nSomewhatnegative = [i for i in ngrams(text.split(), 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd73d1b4a938ec12db5b89eaca41e39b20b545c5","collapsed":true},"cell_type":"code","source":"print(\"Top Somewhatnegative Words in Training Dataset\",Counter(Somewhatnegative).most_common(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"907cd7b8e2cdc578d8baeefaff0af9754332c1bf"},"cell_type":"code","source":"text = ' '.join(train_data.loc[train_data.Sentiment == 2, 'Phrase_Clean'].values)\nNeutral = [i for i in ngrams(text.split(), 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a7f8a84db7f8a62b514bd24b154e8ed0db6d8b8","collapsed":true},"cell_type":"code","source":"print(\"Top Neutral Words in Training Dataset\",Counter(Neutral).most_common(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ea65026193a4fab9d583e78bd989b3c6a0673ec4"},"cell_type":"code","source":"text = ' '.join(train_data.loc[train_data.Sentiment == 3, 'Phrase_Clean'].values)\nSomewhatpositive = [i for i in ngrams(text.split(), 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3b83b74e2839b05d5d82265add2d19c433e2b99","collapsed":true},"cell_type":"code","source":"print(\"Top Somewhatpositive Words in Training Dataset\",Counter(Somewhatpositive).most_common(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e054413729ded56ef8450898297ffb4ca685bd59"},"cell_type":"code","source":"text = ' '.join(train_data.loc[train_data.Sentiment == 4, 'Phrase_Clean'].values)\nPostive = [i for i in ngrams(text.split(), 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1041f73b7f27d3952e391e9a3cf369891877ef15","collapsed":true},"cell_type":"code","source":"print(\"Top Postive Words in Training Dataset\",Counter(Postive).most_common(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1fae106e868923eabf728f847d9ce86d7a245d4a","_kg_hide-input":true},"cell_type":"code","source":"#SVC\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.sparse import hstack, csr_matrix\nimport tqdm\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import accuracy_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"344838b8db85e2d26c6ca3ff2f47309fa1799a86","collapsed":true},"cell_type":"code","source":"from sklearn.pipeline import FeatureUnion\nvectorizer = FeatureUnion([\n('word_vectorizer',  TfidfVectorizer(\nsublinear_tf=True,\nstop_words = 'english',\nanalyzer='word',\ntoken_pattern=r'\\w{1,}',\nngram_range =(1,3),\nmax_features=35000)),\n\n('char_vectorizer', TfidfVectorizer(\nsublinear_tf=True,\nstop_words = 'english',\nanalyzer='char',\nngram_range=(1,3),\nmax_features=80000))\n ])\nvectorizer.fit(train_data['Phrase_Clean'])\ntrain_features = vectorizer.fit_transform(train_data['Phrase_Clean'])\ntest_features = vectorizer.transform(test_data['Phrase_Clean'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a7ca53906fdf67e591dbb0a472513c4325b34473","_kg_hide-input":true},"cell_type":"code","source":"Target = train_data[\"Sentiment\"]\nseed = 101 \nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1a1a3f11e57300126e51f9b9b34c369186f63288","collapsed":true},"cell_type":"code","source":"#Data Split\nX_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(train_features, Target,stratify=Target,random_state=seed)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a06aed4bce54ac6e753ccd6bfbaf3da958c2fc3a","collapsed":true},"cell_type":"code","source":"from sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\n\nmodel_svm_new = SVC(C=200, # penalty parameter, setting it to a larger value \n                     kernel='rbf', # kernel type, rbf working fine here\n                     degree=3, # default value, not tuned yet\n                     gamma=4, # kernel coefficient, not tuned yet\n                     coef0=1, # change to 1 from default value of 0.0\n                     shrinking=True, # using shrinking heuristics\n                     tol=0.001, # stopping criterion tolerance \n                     probability=False, # no need to enable probability estimates\n                     cache_size=200, # 200 MB cache size\n                     class_weight='balanced', # all classes are treated equally \n                     verbose=False, # print the logs \n                     max_iter=-1, # no limit, let it run\n                     decision_function_shape='ovr', # will use one vs rest explicitly \n                     random_state=True)\n\nsvc_model = OneVsRestClassifier(model_svm_new, n_jobs=4)\n\n\n%time\nsvc_model.fit(train_features,Target)\nsvc_predit = svc_model.predict(X_test_tfidf)\naccuracy_tfidf_svc =accuracy_score(y_test_tfidf,svc_predit)\nprint(accuracy_tfidf_svc)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef385b7637692204db54d0db39c51ff6cb1d4d23","collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.metrics import log_loss,confusion_matrix,classification_report,roc_curve,auc\n\ntarget_name = train_data['Sentiment'].unique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50d8a45d5e952c6be1d6547d130b07b7b409b2d1","scrolled":true,"collapsed":true},"cell_type":"code","source":"confusion_matrix(y_test_tfidf,svc_predit,labels=target_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efe424512853ca0e65dac7bfca8407bd4cf02187","collapsed":true},"cell_type":"code","source":"print(classification_report(y_test_tfidf,svc_predit))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8cf8cc3a59d65fedef103889b0a85a3d75c3ac9a","_kg_hide-input":true},"cell_type":"code","source":"Test\ntest_fit = svc_model.predict(test_features)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c7c3854257b26d8a9c1e4342c8fefcbb0b99252","collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"sub = pd.read_csv('../input/sampleSubmission.csv')\nsub['Sentiment'] =  test_fit\nsub.to_csv(\"SVC.csv\", index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a89b2dbb569ac70f7c288a11d6aee7f60f69bdb","collapsed":true},"cell_type":"code","source":"'''from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.naive_bayes import MultinomialNB\n\nfrom sklearn.model_selection import cross_val_score\n\nmodels = [\n    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n    LinearSVC(multi_class='ovr',class_weight='balanced'),\n    MultinomialNB(),\n    LogisticRegression(solver=\"sag\", max_iter=500,multi_class = 'ovr'),\n]\nCV = 5\ncv_df = pd.DataFrame(index=range(CV * len(models)))\nentries = []\nfor model in models:\n  model_name = model.__class__.__name__\n  accuracies = cross_val_score(model, train_features, Target, scoring='accuracy', cv=CV)\n  for fold_idx, accuracy in enumerate(accuracies):\n    entries.append((model_name, fold_idx, accuracy))\ncv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f981f5617224ce73c4bf80246265da690ec2360","collapsed":true},"cell_type":"code","source":"'''import seaborn as sns\n\nsns.boxplot(x='model_name', y='accuracy', data=cv_df)\nsns.stripplot(x='model_name', y='accuracy', data=cv_df, \n              size=15, linewidth=2)\nplt.show()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18c76fa09b37ffe837c64f44dcdf220f2ef045b7","collapsed":true},"cell_type":"code","source":"'''cv_df.groupby('model_name').accuracy.mean()''''''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"89beebcad554909371a02f3a46f2515571eeda7e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}