{"cells":[{"metadata":{"_uuid":"9280afbd77603b0fc22bc38458e9da36b47bea45"},"cell_type":"markdown","source":"### Create the four parameters required for Bayesian optimization:\n1.  Domain(space)\n2. Objective function\n3. Optimization Algorithym\n4. Results history"},{"metadata":{"_uuid":"b75991b6b827d4506af8e4c8528b8323053dad88"},"cell_type":"markdown","source":"**Import the required packages**"},{"metadata":{"trusted":true,"_uuid":"ad6e0966d342110e5306d6c74a63f682e164e6a4"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport seaborn as sns\nfrom hyperopt import hp\nimport csv\nfrom hyperopt import STATUS_OK\nfrom timeit import default_timer as timer\nfrom hyperopt.pyll.stochastic import sample\nfrom hyperopt import tpe\nfrom hyperopt import Trials\nfrom hyperopt import fmin\nimport ast\nimport json\n\nnfolds = 5\nmax_eval = 5","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67b9ffc3f7d291e366ba51a6a961c7412e37891d"},"cell_type":"markdown","source":"**Import the Dataset**"},{"metadata":{"trusted":true,"_uuid":"7d46f3c242a588fb69fd805188cbb262bf2b619e"},"cell_type":"code","source":"# Import the train dataset\ntrain = pd.read_csv('../input/home-credit-default-risk/application_train.csv')\n\n# Create the sample data\ntrain = train.sample(n = 16000, random_state = 42)\n# Select numeric variables for Bayesian optimization\ntrain = train.select_dtypes('number')\n\n# Create the label and \nlabels = train['TARGET'].values.astype(np.int32).reshape((-1, ))\ntrain = train.drop(columns = ['TARGET', 'SK_ID_CURR'])\n\n# Split into training and testing data\nX_train, X_test, y_train, y_test = train_test_split(train, labels, test_size = 0.3, random_state = 42, stratify = labels)\n\nprint('Train shape: ', X_train.shape)\nprint('Test shape: ', X_test.shape)\n\ntrain.head()\n\n# Create the train dataset in lightgbm format\nX_train_lgb = lgb.Dataset(X_train, label = y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb8bfa9e9db6db9de0c37cceab6b2c55ccd2563b"},"cell_type":"markdown","source":"**Create the file and Open the connection for track record or can be used later in Bayesian optimization**"},{"metadata":{"trusted":true,"_uuid":"653874fcca053ea0c789d1d6fd8843f4c76a5465"},"cell_type":"code","source":"OUT_FILE = 'Bayesian_v1.csv'\nof_connection = open(OUT_FILE, 'w')\nwriter = csv.writer(of_connection)\n\nITERATION = 0\n\n# Write column names\nheaders = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\nwriter.writerow(headers)\nof_connection.close()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33fad2de4892355b63e2295e790eb2ea927fb5e3"},"cell_type":"markdown","source":"**1) Create the Domain (space)**"},{"metadata":{"trusted":true,"_uuid":"3cee939cc6c7142cee71bed18ae72709d157a5b5"},"cell_type":"code","source":"space = {\n    'boosting_type': hp.choice('boosting_type', \n                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1.0)}, \n                                             {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1.0)},\n                                             {'boosting_type': 'goss', 'subsample': 1.0}]),\n    'num_leaves': hp.quniform('num_leaves', 20, 150, 1),\n    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n    'is_unbalance': hp.choice('is_unbalance', [True, False]),\n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72927e6bdeff2111033a2a611847b75da5aa5372"},"cell_type":"markdown","source":"**2) Create the Objective function (probability model)**"},{"metadata":{"trusted":true,"_uuid":"1e47fb9f2ab9e6e7d45641e13a1b96168bc5fe30"},"cell_type":"code","source":"def Objective_function(hyperparameters):\n    # Keep the track record\n    global ITERATION\n    ITERATION += 1\n    \n    # We are calculating the n_estimators as per early stopping. Hence, it has to be updated after every iteration\n    if \"n_estimators\" in hyperparameters:\n        del hyperparameters[\"n_estimators\"]\n        \n    # Extract the boosting type and subsample in proper format\n    subsample = hyperparameters[\"boosting_type\"].get(\"subsample\", 1.0)\n    hyperparameters[\"boosting_type\"] = hyperparameters[\"boosting_type\"][\"boosting_type\"]\n    \n    # Make sure all parameters are integers form\n    for i in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n        hyperparameters[i] = int(hyperparameters[i])\n    \n    start = timer()\n    # Create the lightgbm model alog with cross validation\n    model = lgb.cv(hyperparameters, \n                   X_train_lgb, \n                   num_boost_round=10000, \n                   metrics =\"auc\",\n                   nfold = nfolds\n              )\n    \n    # Run time of model\n    run_time = timer() - start\n    \n    # best score \n    best_score = model[\"auc-mean\"][-1]\n    \n    # loss\n    loss = 1-best_score\n    \n    # Assigned n_estimators in hyperparameter as per the iterations in model\n    hyperparameters[\"n_estimators\"] = len(model[\"auc-mean\"])\n    \n    # Write to the csv file ('a' means append)\n    OUT_FILE = \"Bayesian_v1.csv\"\n    of_connection = open(OUT_FILE, 'a')\n    writer = csv.writer(of_connection)\n    writer.writerow([loss, hyperparameters, ITERATION, run_time, best_score])\n    of_connection.close()\n\n    # Dictionary with information for evaluation\n    return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n            'train_time': run_time, 'status': STATUS_OK}\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac777fc3c83709161d43e0d751844548966b7741"},"cell_type":"markdown","source":"**3) Create Optimization algorithym**"},{"metadata":{"trusted":true,"_uuid":"5c33d18601fd7a9211e34351bf8cbf6b3ae0fbc5"},"cell_type":"code","source":"# Create the algorithm\ntpe_algorithm = tpe.suggest","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"474f0f6308ecc63cba6e8f1c3f226e926af28e47"},"cell_type":"markdown","source":"**4) Create Result history**"},{"metadata":{"trusted":true,"_uuid":"2835ca15fe2d5050162d119b191297918be88599"},"cell_type":"code","source":"# Record results\ntrials = Trials()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a12a75cdebcca1d79d62b644b21afe0738fa01f"},"cell_type":"markdown","source":"**5) Create the Automated function for optimization**"},{"metadata":{"trusted":true,"_uuid":"61c1dff17f82f41f143070d10233eeb2f52212bc"},"cell_type":"code","source":"# Global variable\nglobal  ITERATION\n\nITERATION = 0\n\n# Run optimization\nbest = fmin(fn = Objective_function, space = space, algo = tpe.suggest, trials = trials,\n            max_evals = max_eval)\n\nbest","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eba9bd24a9935e19a2363ba5404cd063c6210545"},"cell_type":"markdown","source":"**Sort the trials with lowest loss (highest AUC) first**"},{"metadata":{"trusted":true,"_uuid":"535f1eb9f0a3adc7f5d89f3ec4fbe18ba1878150"},"cell_type":"code","source":"trials_dict = sorted(trials.results, key = lambda x: x['loss'])\ntrials_dict[:1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06913db193c02ab3612ab270c90e12bdf77f9943"},"cell_type":"markdown","source":"**Read the history in the csv format**"},{"metadata":{"trusted":true,"_uuid":"3718a29f6665b1966429adb0cb4387de44c10ef5"},"cell_type":"code","source":"results = pd.read_csv(OUT_FILE)\nnew_results = results.copy()\n# String to dictionary\nnew_results['hyperparameters'] = new_results['hyperparameters'].map(ast.literal_eval)\n    \n# Sort with best values on top\nnew_results = new_results.sort_values('score', ascending = False).reset_index(drop=True)\n    \n# Print out cross validation high score\nprint('The highest cross validation score from Bayesian was {:.5f} found on iteration {}.'.format(new_results.loc[0, 'score'], new_results.loc[0, 'iteration']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b111e6c824826a0954f4a5263ab479c443e451cb"},"cell_type":"markdown","source":"**Make predictions using best parameters**"},{"metadata":{"trusted":true,"_uuid":"32e5534ab36227665d5241c6aaa47518b04b19e4"},"cell_type":"code","source":"# Use best hyperparameters to create a model\nhyperparameters = new_results.loc[0, 'hyperparameters']\nmodel = lgb.LGBMClassifier(**hyperparameters)\n    \n# Train and make predictions\nmodel.fit(X_train, y_train)\npreds = model.predict_proba(X_test)[:, 1]\n    \nprint('ROC AUC from Bayesian on test data = {:.5f}.'.format(roc_auc_score(y_test, preds)))\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f125277dd2aa08c8b9d8484c17dc2f82fcd20adf"},"cell_type":"markdown","source":"**Save the Trials(history) in json format for later use**"},{"metadata":{"trusted":true,"_uuid":"4c709787592e1716386c5832ba3ba345d9a7ae79"},"cell_type":"code","source":"# Save the trial results\nwith open('trials.json', 'w') as f:\n    f.write(json.dumps(trials_dict))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c74269a4549d21a7ce8ed7e2b863040d77d7c192"},"cell_type":"markdown","source":"To start the training from where it left off, simply load in the `Trials` object and pass it to an instance of `fmin`. (You might even be able to tweak the hyperparameter distribution and continue searching with the `Trials` object because the algorithm does not maintain an internal state. Someone should check this and let me know in the comments!)."},{"metadata":{"trusted":true,"_uuid":"4e3f5f06fe20d5085f09b554db701ca642e38b40"},"cell_type":"code","source":"# MAX_EVALS = 1000\n\n# # Create a new file and open a connection\n# OUT_FILE = 'bayesian_trials_1000.csv'\n# of_connection = open(OUT_FILE, 'w')\n# writer = csv.writer(of_connection)\n\n# # Write column names\n# headers = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\n# writer.writerow(headers)\n# of_connection.close()\n\n# # Record results\n# trials = Trials()\n\n# global ITERATION\n\n# ITERATION = 0 \n\n# best = fmin(fn = objective, space = space, algo = tpe.suggest,\n#             trials = trials, max_evals = MAX_EVALS)\n\n# # Sort the trials with lowest loss (highest AUC) first\n# trials_dict = sorted(trials.results, key = lambda x: x['loss'])\n\n# print('Finished, best results')\n# print(trials_dict[:1])\n\n# # Save the trial results\n# with open('trials.json', 'w') as f:\n#     f.write(json.dumps(trials_dict))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}