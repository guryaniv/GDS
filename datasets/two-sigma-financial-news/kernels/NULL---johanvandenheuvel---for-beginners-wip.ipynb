{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pylab as plt # for plotting, pylab is very similiar to pyplot\n\n# following examples as shown in:\n# https://www.kaggle.com/dster/two-sigma-news-official-getting-started-kernel\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Loading in the data"},{"metadata":{"trusted":true,"_uuid":"b9fd4785261254d8b57486be9fc212fe3051dc0e"},"cell_type":"code","source":"(df_market, df_news) = env.get_training_data()\n# df_market = pd.read_csv('../input/marketdata_sample.csv', sep=',')\n# df_news = pd.read_csv('../input/news_sample.csv', sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff15c88f56bf1378074622500b479f4f84154846"},"cell_type":"code","source":"df_market","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2801709a4f3d88220b2f748fe065102c291c3856"},"cell_type":"code","source":"df_news","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7124eed2faff6be6769147a8dcc4acab7662f5e"},"cell_type":"markdown","source":"# Data Processing\n\nAfter loading in the date we process it into something more usefull. First for the market data we will combine the different measures of value into just one. This is expresive enough to do some elementary analysis and makes it much more easy to understand what it going on. "},{"metadata":{"_uuid":"990bc9f01f8421eb91df31299d37ad56b6426611"},"cell_type":"markdown","source":"## Market\nFirst we look at the stock data"},{"metadata":{"trusted":true,"_uuid":"ab216612652a8153f77b7a73af00b559c1364b63"},"cell_type":"code","source":"df_market['price'] = np.mean((df_market['close'].values, df_market['open'].values), axis=0)\ndf_market = df_market.drop(['close', 'open',\n                           'assetCode', 'universe',#asset code not important, dont know what universe means in this context\n                           'returnsClosePrevRaw1', # don't know difference between Raw and Mktres, also dont know how relevant\n                           'returnsOpenPrevRaw1',\n                           'returnsClosePrevMktres1',\n                           'returnsOpenPrevMktres1',\n                           'returnsClosePrevRaw10',\n                           'returnsOpenPrevRaw10',\n                           'returnsClosePrevMktres10',\n                           'returnsOpenPrevMktres10',\n                           'returnsOpenNextMktres10'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d29bdc07e59f1b7af2dfd024edbffeabc37a9a8","scrolled":true},"cell_type":"code","source":"df_market","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16eb707325561c4ee818405c4d046669298107ea"},"cell_type":"markdown","source":"## News\nSecond we look at the news"},{"metadata":{"trusted":true,"_uuid":"f5f46acefdfda98f6d11b674c9d471105c12f705"},"cell_type":"code","source":"df_news = df_news.drop(['noveltyCount12H','noveltyCount24H','noveltyCount3D','noveltyCount5D', 'noveltyCount7D',\n                       'volumeCounts12H', 'volumeCounts24H', 'volumeCounts3D', 'volumeCounts5D', 'volumeCounts7D'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db6ea81263aee12df00e73d11e1174727cfc7585"},"cell_type":"code","source":"df_news['sentiment'] = df_news['sentimentNeutral'].values - df_news['sentimentNegative'].values + df_news['sentimentPositive'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"956411e3995a3328414aa623d48934790a9f5422"},"cell_type":"code","source":"df_news = df_news.drop(['sentimentNeutral', 'sentimentNegative', 'sentimentPositive',\n                       'sentimentClass', # we dont need the sign of the sentiment as we use a scalar. Have to investigave is a scalar is precise enough vs just using the sign. \n                       'sentenceCount', # wordCount should contain at least similiar information as sentenceCount\n                       'assetCodes', # we use assetName\n                       'sourceTimestamp', 'firstCreated', 'sourceId', 'takeSequence', 'firstMentionSentence'], axis=1)\n# df_news","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f5dabbc3008dc19db7079ac0cdb4bbe4517167d"},"cell_type":"markdown","source":"We plot bodySize vs wordCount to see if they are correlated, if yes we can drop one as they should include very similiar information."},{"metadata":{"trusted":true,"_uuid":"ee5c8469566c36f37d7e5958a862211db7b06872"},"cell_type":"code","source":"df = pd.read_csv('../input/news_sample.csv', sep=',')\n\nplt.plot(df['bodySize'])\nplt.plot(df['wordCount'])\nplt.legend(['bodySize', 'wordCount'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"adb11509690d962aad92671977fecdad6d472313"},"cell_type":"markdown","source":"As we can see in the plot above indeed bodySize and wordCount are both a measure of the same thing. We can do four things: do nothing, remove bodyCount, remove wordCount, and combine them both into one feature. For sake of simplimplicity we drop bodySize."},{"metadata":{"trusted":true,"_uuid":"5f54bce2ab86adf8b36b5830d478804c8083d8e8"},"cell_type":"code","source":"df_news = df_news.drop(['bodySize'], axis=1)\n# df_news","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92f5fc73389a32bdffb5af1fea3716f21fefdf88"},"cell_type":"markdown","source":"## Combine market and news"},{"metadata":{"trusted":true,"_uuid":"55345907b804520a270e34734c0d29d0e655be6e"},"cell_type":"code","source":"df_market","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0f2c4312d09e9ba6493a9cd92bb4e504f5cd1a4"},"cell_type":"code","source":"df_news","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22675e5fdac1355fc5112e2ed8d1cba2aedd319e"},"cell_type":"code","source":"df = pd.merge(df_market, df_news, on='assetName')\ndf #seems to only merge a small part, need to figure out how to get more then 100 rows in each dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c27735fdb638746d8e40dcd6a437d942e5fb63e4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}