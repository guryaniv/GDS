{"cells":[{"metadata":{"_uuid":"8f51ab02fb00c89d664cdad626ce4446f3546fe0"},"cell_type":"markdown","source":"# Digit Recognization with Keras"},{"metadata":{"_uuid":"dacedfc149b6d72994ef226cfe707c2bbdc017cd"},"cell_type":"markdown","source":"> ## 0. Setup"},{"metadata":{"_uuid":"b8d35297801da246a31863cb865423136e91cb5a"},"cell_type":"markdown","source":">> ### 0.1 Libraries\n\n* NumPy and pandas are used for normalization and reshaping the data\n* matplotlib is used for visualizing the normalized data\n* sklearn.model_selection is used for train/test split\n* Keras is used for the neural network"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom ipywidgets import interact\nimport ipywidgets as widgets","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af12dc5e11a4b2b1e36101455603dcd922f20a84"},"cell_type":"markdown","source":">> ### 0.2 Loading the Data\n\n>> * After loading the training and test sets to the memory, copying them recursively with the `copy()` function because we don't want changes to be reflected to the original data frame. After that, displaying the dimensions and the columns of the data sets\n* The training set have one extra column called label which is the label of the digit. This column has to be separated from the `df_train`\n* The other columns are the pixels of 28x28 images"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train_orig = pd.read_csv('../input/train.csv')\ndf_test_orig = pd.read_csv('../input/test.csv')\n\ndf_train = df_train_orig.copy(deep=True)\ndf_test = df_test_orig.copy(deep=True)\n\nprint('Number of Training Examples = {}'.format(df_train.shape[0]))\nprint('Number of Test Examples = {}'.format(df_test.shape[0]))\nprint('Training Input Shape = {}'.format(df_train.shape))\nprint('Training Output Shape = {}'.format(df_train.shape[0]))\nprint('Test Input Shape = {}'.format(df_test.shape))\nprint('Test Output Shape = {}'.format(df_test.shape[0]))\nprint(df_train.columns)\nprint(df_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7998efc87c52c40bc7f2a4f2fe2114450a2a820f"},"cell_type":"markdown","source":"> ##  1 Preprocessing"},{"metadata":{"_uuid":"bdb18246577a5ebd36dfdd3b2778cffb5bc8aa88"},"cell_type":"markdown","source":"\n>> ###  1.1 Normalization\n* First, the label column is dropped because it is categorical data\n* Each of the values of pixels are divided by 255. Since the max value of a grayscale pixel can be 255, this will scale the values of pixels between 0 and 1\n* The label column is stored in `Y_train`\n* Finally, checking the dimensions of X_train and X_test are matching"},{"metadata":{"trusted":true,"_uuid":"1d4856064dae334b6b4f99199b22719574a4a3b1"},"cell_type":"code","source":"X_train = df_train.drop(columns=['label'], axis=0).astype('float32').values / 255.0\nX_test = df_test.astype('float32').values / 255.0\nY_train = df_train_orig['label'].astype('float32').values\n\nassert(X_train.shape[1] == X_test.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be3efa461b2581e93e08dea4f1084bac5cca9687"},"cell_type":"markdown","source":">> ###  1.2 Reshape\n* X_train and X_test are in the flattened vector form (784, 1), In order to use a CNN, we need to reshape them back to image form (28, 28, 1)\n* The depth is specified as 1 because the dataset is greyscale"},{"metadata":{"trusted":true,"_uuid":"48c07c3182618bb7a6ac5146f8034b4296b47545"},"cell_type":"code","source":"X_train = X_train.reshape(-1,28,28,1)\nX_test = X_test.reshape(-1,28,28,1)\n\nprint('Training Input Shape = {}'.format(X_train.shape))\nprint('Test Input Shape = {}'.format(X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34aff281cc8647f6c3cb28c19c546de95f45f9e0"},"cell_type":"markdown","source":">> ###  1.3 Sanity Check\n*  `visualize_digit` function can plot any example from training set and their label. This function is useful when we need to look for a specific record.\n* Checking the distributions of each label. "},{"metadata":{"trusted":true,"_uuid":"7202ba0416905fe1b3b84e5d971c75dcdae35b9c"},"cell_type":"code","source":"def visualize_digit(index):\n    # Plots the training example at the given index\n    plt.imshow(X_train[index][:, :, 0])\n    print(\"Visualizing {}th training example and the label is = {}\".format(index + 1, str(Y_train[index])))\n    \ninteract(visualize_digit, index=(0, X_train.shape[0] - 1, 1));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f400d8cecbbc0459eafaf2155fb23e1c7fde6373"},"cell_type":"code","source":"# Checking the data distribution\ndf_train_orig['label'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7faa492b8e591280897c5ec79e7a1fcee91b59ab"},"cell_type":"markdown","source":">> ###  1.4 Train / Validation Split\n* Splitting the training set into training and validation sets with a fixed seed\n* The split rates are 90% and 10%. (Training Set %90 / Validation Set %10)"},{"metadata":{"trusted":true,"_uuid":"a8923a767c0e288461adcddc11cc2989ee1d2474"},"cell_type":"code","source":"Y_train = keras.utils.to_categorical(Y_train, num_classes=10)\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=0)\n\nprint('Training Input Shape = {}'.format(X_train.shape))\nprint('Validation Input Shape = {}'.format(X_val.shape))\nprint('Training Output Shape = {}'.format(Y_train.shape))\nprint('Validation Output Shape = {}'.format(Y_val.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98debdbb75ca38e9a00a87a02bdb4e4112196a5e"},"cell_type":"markdown","source":"> ##  2 . Machine Learning"},{"metadata":{"_uuid":"b12ec5b78796bcadde7ad63903a948a0589319ad"},"cell_type":"markdown","source":">> ### 2.1 Layers\n* I used 2 convolution layers followed by a max pooling layer 2 times\n* The activation function of the convolution layers are relu\n* Finally using softmax activation function on the final layer because it is a multi-class classification problem"},{"metadata":{"trusted":true,"_uuid":"dfa5a6c6828f21eb50f44e2b558b8d3f2e32b829"},"cell_type":"code","source":"model = keras.models.Sequential([\n    keras.layers.Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu', input_shape=(28, 28, 1)),\n    keras.layers.Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu'),\n    keras.layers.MaxPool2D(pool_size=(2, 2)),\n    keras.layers.Dropout(0.25),\n    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation ='relu'),\n    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation ='relu'),\n    keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n    keras.layers.Dropout(0.25),\n    keras.layers.Flatten(),\n    keras.layers.Dense(256, activation=\"relu\"),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(10, activation=\"softmax\")\n])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d421ed2988939ef2050ffcb736cce1c4587d073b"},"cell_type":"markdown","source":">> ###  2.2 Optimizer, Loss Function, Metrics and Callbacks\n* The optimizer is RMSprop with default parameters\n* The loss function is categorical cross-entropy which is also called softmax loss\n* Using accuracy for the metric\n* Creating a callback function which reduces the learning rate, If accuracy doesn't increase in 3 epochs."},{"metadata":{"trusted":true,"_uuid":"9105def312fc6587c2afdcedccadebe940ef3705"},"cell_type":"code","source":"optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\nloss = 'categorical_crossentropy'\nmetrics = ['accuracy']\n\nlearning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40eb756e89128c75b2a911d6da80c080844eb125"},"cell_type":"code","source":"epochs = 30\nbatch_size = 86\n\nmodel.fit(X_train, Y_train, \n          epochs=epochs, \n          batch_size=batch_size, \n          callbacks=[learning_rate_reduction], \n          validation_data=(X_val, Y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1ba7ddb2ad160bc257affcf39728a2f07e84504"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c44c0d5ad94f5fdb4e3dd6923fd1b5339a49a94"},"cell_type":"markdown","source":"> ##  3 . Result"},{"metadata":{"_uuid":"4def5d1fa6f3396fa06fdf76e54264f10e8d9e4f"},"cell_type":"markdown","source":">> ###  3.1 Predicting with the Trained Model\n* Predicting the labels of X_test with the model trained earlier\n*  `visualize_prediction` function can plot any example from test set and its predicted label"},{"metadata":{"trusted":true,"_uuid":"f83d8abd4cb85015b90dbaae03de2e2ef688af0e"},"cell_type":"code","source":"Y_hat = model.predict(X_test, batch_size=None, verbose=0, steps=None)\nY_hat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1c64173c5f8cd3fcef835703935e7cf7c9f4031"},"cell_type":"code","source":"def visualize_prediction(index):\n    # Plots the predicted example from X_test at given index\n    plt.imshow(X_test[index].reshape(28, 28))\n    print(\"Visualizing {}th test example and the predicted label is = {}\".format(index + 1, str(np.argmax(Y_hat[index]))))\n    \ninteract(visualize_prediction, index=(0, X_test.shape[0] - 1, 1));","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"520f6e8ac709bd938c9c68935cf6497007ab4959"},"cell_type":"markdown","source":"> ##  4 . Submission"},{"metadata":{"trusted":true,"_uuid":"f38254d5f553d5fb4f811cc54fa9dd465f13893a"},"cell_type":"code","source":"submission_df = pd.DataFrame(columns=['ImageId', 'Label'])\nsubmission_df['ImageId'] = list(range(1,len(Y_hat) + 1))\nsubmission_df['Label'] = [np.argmax(Y_hat[i]) for i in range(len(Y_hat))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dccbd3ba3ec510e79aa70fa0a88f355537fa8f63"},"cell_type":"code","source":"submission_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88d480b2f68af9c9f05fa13fa1309f55d9d1cb6f"},"cell_type":"code","source":"submission_df.to_csv('submission.csv', header=True, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}