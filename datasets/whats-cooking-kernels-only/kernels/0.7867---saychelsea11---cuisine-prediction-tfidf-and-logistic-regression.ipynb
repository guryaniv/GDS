{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"'''\nImport train and test data\n'''\n\ntrain_data = pd.read_json('../input/train.json')\ntest_data = pd.read_json('../input/test.json')\n\n#Making copies of original dataset for future use\ntest_data_copy = test_data\ntrain_data_copy = train_data\ntrain_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2422f91ac5047589c0d9437d3e13dbab549ffe56"},"cell_type":"code","source":"#Exporting train and test datasets as dataframes\ntrain_data.to_csv(\"train.csv\",index=False)\ntest_data.to_csv(\"test.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d384c05f3a674c593d353114d378d90648f8bfc"},"cell_type":"code","source":"'''\nExploratory Data Analysis\n'''\nimport nltk\nimport matplotlib.pyplot as plt\n\n#Total entries\nprint (\"Total number of recipes: \",len(train_data))\n#Total number of cuisines\nprint (\"Total number of cuisines: \",len(nltk.FreqDist(train_data[\"cuisine\"]).keys()))\n\n#Visualizing frequency of each cuisine\nplt.figure(figsize=(12,8))\nplt.bar(nltk.FreqDist(train_data[\"cuisine\"]).keys(),nltk.FreqDist(train_data[\"cuisine\"]).values(),alpha=0.8,width=0.8,align=\"center\")\nplt.xlabel(\"Cuisine\",size=15)\nplt.ylabel(\"Frequency\",size=15)\nplt.title(\"Train data cuisine distribution\",size=20)\nplt.xticks(rotation=45,size=12)\nplt.show()\n\n'''\nDetermining the highest and lowest occurring words\n'''\n\n#Collecting all the words and creating a frequency distribution \ntotal_words = []\nfor i in range(len(train_data)):\n    total_words.extend(train_data.iloc[i,2])\nwords_freq = nltk.FreqDist(total_words)\n\n#Total number of words \nprint (len(total_words))\nprint ('')\nwords_freq_sorted = sorted(words_freq.items(),key=lambda x: x[1])\n\n#Highest occurring words\nprint ('Highest occurring ingredients in the dataset')\nprint (words_freq_sorted[-20:])\nprint ('')\n\n#Lowest occurring words\nprint ('20 Lowest occurring ingredients in the dataset')\nprint (words_freq_sorted[:20])\nprint ('')\n\n#Visualizing frequency of highest occurring words\nplt.figure(figsize=(12,8))\n#plt.bar(list(list(zip(*words_freq_sorted[-20:]))[0]),list(list(zip(*words_freq_sorted[-20:]))[1]),alpha=0.8,width=0.8,align=\"center\")\nplt.barh(list(list(zip(*words_freq_sorted[-20:]))[0]),list(list(zip(*words_freq_sorted[-20:]))[1]),alpha=0.8,align=\"center\",color='red')\nplt.ylabel(\"Words\",size=15)\nplt.xlabel(\"Frequency\",size=15)\nplt.title(\"Frequency of highest occurring ingredients\",size=20)\nplt.xticks(rotation=90,size=12)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1df282d4bd6c1f3cc0dba25b159707b342da81d6"},"cell_type":"code","source":"'''\nAdding new feature that contains the number of ingredients in each recipe\n'''\nnum_ingredients_train = train_data[\"ingredients\"].apply(len)\nnum_ingredients_test = test_data[\"ingredients\"].apply(len)\nprint (len(num_ingredients_train))\n\n#Will add this feature to the modeling dataset later following vectorizing ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5add48cbc284cac5671d14ae21007e6d3d095190"},"cell_type":"code","source":"'''\nPre-processing train data\n'''\nfrom nltk.stem.porter import PorterStemmer\n\n#Function to combine a list of strings into a sentence for text modeling\ndef join_strings_to_sentence(x):\n    result = ' '.join(x)\n    return result\n\n#Similar to the 'join_strings_to_sentence' function except this function joins ingredients with\n#with a space in between into a single word\ndef combine_and_stem(x):\n    x = pd.Series(x)\n    stemmer = PorterStemmer().stem\n    x = x.apply(stemmer)\n    x = x.apply(lambda k: ''.join(k.split(' ')))\n    x = ' '.join(list(x))\n    return x\n\n#Separating the words in each document to form sentences for vectorization\ntrain_data[\"ingredients\"] = train_data[\"ingredients\"].apply(combine_and_stem)\ntest_data[\"ingredients\"] = test_data[\"ingredients\"].apply(combine_and_stem)\n\n\n#train_data[\"ingredients\"] = train_data[\"ingredients\"].apply(join_strings_to_sentence)\ntrain_data = train_data.drop(\"id\",axis=1)\ntest_data_id = test_data[\"id\"]\ntest_data = test_data.drop(\"id\",axis=1)\n\n#Printing both datasets to make sure that the ingredients have been processed appropriately\nprint (train_data.head(10))\nprint (\"\")\nprint (test_data.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d3c22c6cd45d8ad2e13f6c1ceb28165d94878e6"},"cell_type":"code","source":"'''\nFunction to add a new feature to the document-term matrix following vectorization\n'''\ndef add_feature(X, feature_to_add):\n    \"\"\"\n    Returns sparse feature matrix with added feature.\n    feature_to_add can also be a list of features.\n    \"\"\"\n    from scipy.sparse import csr_matrix, hstack\n    return hstack([X, csr_matrix(feature_to_add).T], 'csr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e96fe57b4fec7a72281fab0e303c70abbf6af596"},"cell_type":"code","source":"'''\nCount Vectorizer Fit - using every single word as separate features\n'''\n'''\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n#Creating a document-term matrix using Count Vectorizer modeling and fitting train and test data\nvect = CountVectorizer().fit(train_data[\"ingredients\"])\ntrain_data_vect = vect.transform(train_data[\"ingredients\"])\n\n#Adding the number of ingredients variable to the dataset\ntrain_data_vect_new = add_feature(train_data_vect,num_ingredients_train)\n\n#Total number of features\nprint (\"Number of unique features: \",len(vect.get_feature_names()))\n\nprint (train_data_vect_new.shape)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b48ed3d8757dc0e541dd51e80a69792194810606"},"cell_type":"code","source":"'''\nSplitting train data into further train and test for modeling\n'''\n'''\nfrom sklearn.model_selection import train_test_split\nfrom scipy.sparse import csr_matrix, find\n\nX_train,X_test,y_train,y_test = train_test_split(train_data_vect_new,train_data[\"cuisine\"],random_state=0,train_size=0.9)\n\n#Unique features\nprint (vect.get_feature_names())\n\n#Document-term matrix\nprint (X_train)\n'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb9a555fee8a74bcabe4eaed76147b04c3ab1b37"},"cell_type":"code","source":"'''\nLogistic Regression Modeling\n'''\n'''\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score,accuracy_score\n\n#Creating model and fitting\nlogreg = LogisticRegression(C=1)\nmodel = logreg.fit(X_train,y_train)\n\n#Prediction and score\ny_predict = model.predict(X_test)\nscore = accuracy_score(y_test,y_predict)\n\nprint (score)\nprint (y_predict)\nprint (y_test)\n'''\n\n'''\nScores using CountVectorizer\n'''\n'''\nScores with features represented as individual words\n'''\n#0.7938 with C=1 - best score with individual words as features\n#0.7921 with C=3\n\n'''\nScores with features represented as entire terms as opposed to single words\n'''\n#0.7905 with C=1\n#0.7931 with C=2\n#0.7941 with C=3 - the best score with considering multiple word ingredients as a single term\n#0.7926 with C=4\n#0.7913 with C=5\n#0.7863 with C=10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d92121d1184f38cb6258849810f82ae58833e99"},"cell_type":"code","source":"'''\nTFIDF Vectorizer\n'''\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#vect = TfidfVectorizer(min_df=2).fit(train_data[\"ingredients\"].append(test_data[\"ingredients\"]))\nvect = TfidfVectorizer(min_df=2).fit(train_data[\"ingredients\"])\ntrain_data_vect = vect.transform(train_data[\"ingredients\"])\ntest_data_vect = vect.transform(test_data[\"ingredients\"])\n\n#Adding the number of ingredients variable to the dataset\ntrain_data_vect_new = add_feature(train_data_vect,num_ingredients_train)\ntest_data_vect_new = add_feature(test_data_vect,num_ingredients_test)\n\n'''\nTrain Test Split\n'''\nX_train,X_test,y_train,y_test = train_test_split(train_data_vect_new,train_data[\"cuisine\"],random_state=0,train_size=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4c5d428a3f0dea81edb4aac7fb5a316f654a7ba"},"cell_type":"code","source":"'''\nLogistic Regression with TFIDF\n'''\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score,accuracy_score\n\n#Creating model and fitting\nlogreg = LogisticRegression(C=6)\nmodel = logreg.fit(X_train,y_train)\n\n#Prediction and score\ny_predict = model.predict(X_test)\nscore = accuracy_score(y_test,y_predict)\n\nprint (score)\n\nresults = pd.DataFrame()\nresults[\"y_test\"] = y_test\nresults[\"y_predict\"] = y_predict\nprint (results)\n\n'''\nScores with features represented as entire terms as opposed to single words\n'''\n#0.78 with C=1 and min_df=1\n#0.7797 with C=1 and min_df=5\n#0.77 with C=1 and min_df=10\n#0.7911 with C=10 and min_df=10\n#0.7948 with C=4 and min_df=5\n#0.7966 with C=5 and min_df=5 - best score with TFIDF and using ingredient terms as features\n#0.7963 with C=6 and min_df=5\n#0.7966 with C=10 and min_df=5\n#0.7941 with C=15 and min_df=5\n\n'''\nScores with stemming\n'''\n#0.795 with C=5 and min_df=5\n#0.7963 with C=6 and min_df=5\n#0.7948 with C=7 and min_df=5\n#0.7981 with C=6 and min_df=1\n#0.7986 with C=7 and min_df=1\n#0.7983 with C=8 and min_df=1\n#0.7986 with C=8 and min_df=2\n#0.7993 with C=7 and min_df=2\n#0.8006 with C=6 and min_df=2 - best score with ingredient terms as features and stemming\n#0.7986 with C=5 and min_df=2\n#0.7998 with C=5 and min_df=3\n#0.7961 with C=4 and min_df=4\n#0.7998 with C=5 and min_df=4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"439d9ebe4878b79fa974a98b7aa952f661464807"},"cell_type":"code","source":"'''\nAnalyzing the results\n'''\n\n#The best results appears to be 0.7938 with the default CountVectorizer\n#parameters such as min_fd, max_df, analyzer, max_features, ngram_range did not improve the result\n#Adding the extra feature with the number of tokens in each document did not affect the result\n\nresults = pd.DataFrame()\nresults[\"test\"] = y_test\nresults[\"predict\"] = y_predict\nresults_incorrect = results[results[\"test\"]!=results[\"predict\"]]\nresults_correct = results[results[\"test\"]==results[\"predict\"]]\n\n#Cuisine pairs that were predicted correctly and incorrectly\nprint (\"Number of cuisines not predicted correctly :\",len(results_incorrect))\nprint (\"Number of cuisines predicted correctly :\",len(results_correct))\nprint (\"\")\nprint (\"Pairs of incorrect predictions\")\nprint (results_incorrect)\n\n#Visualizing how many times each cuisine was predict correctly\nplt.figure(figsize=(12,8))\nplt.bar(nltk.FreqDist(results_correct[\"test\"]).keys(),nltk.FreqDist(results_correct[\"test\"]).values(),alpha=0.8,width=0.8,align=\"center\")\nplt.xlabel(\"Cuisine\",size=15)\nplt.ylabel(\"Frequency\",size=15)\nplt.title(\"Frequency of cuisines predicted correctly\",size=20)\nplt.xticks(rotation=45,size=12)\nplt.show()\n\n#Visualizing how many times each cuisine was predicted incorrectly\nplt.figure(figsize=(12,8))\nplt.bar(nltk.FreqDist(results_incorrect[\"test\"]).keys(),nltk.FreqDist(results_incorrect[\"test\"]).values(),alpha=0.8,width=0.8,align=\"center\")\nplt.xlabel(\"Cuisine\",size=15)\nplt.ylabel(\"Frequency\",size=15)\nplt.title(\"Frequency of cuisines predicted incorrectly\",size=20)\nplt.xticks(rotation=45,size=12)\nplt.show()\n\n#Determining which cuisines were predicted incorrectly the most\nprint (\"Number of times each cuisine was incorrectly predicted\")\nprint ((results_incorrect.groupby(\"test\").apply(len)))\n\n#Looking at the results, French, Italian, Southern US and Mexican cuisines were predicted incorrectly\n#the most. Although, it is to be noted that these are 4 of the highest occurring cuisines \n#occurring in the original data set. Therefore, a percentage value may be more helpful\n\n#The case is similar for correctly predicted cuisines with French being the exception\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"139e27515fc618dd5cb99d22c22dea64c19080f5"},"cell_type":"code","source":"'''\nCross-Validation\n'''\n'''\nfrom sklearn.model_selection import cross_val_score\n\ncv_score = cross_val_score(logreg,train_data_vect_new,train_data[\"cuisine\"],cv=5,scoring='accuracy')\n\ncv_score\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9130d5b93cb811c343abcd566e073825e5b5580"},"cell_type":"code","source":"'''\nDetermine important features for Logistic Regression classifier\n'''\nfeature_names = np.array(vect.get_feature_names())\nsorted_coef_index = model.coef_[0].argsort()\n\nprint (\"Most important features\")\nprint (feature_names[sorted_coef_index[:10]])\nprint ('')\nprint (\"Least important features\")\nprint (feature_names[sorted_coef_index[-10:]])\n\n#Although good to know, these feature importances do not provide too much insight as this is a\n#multi-class model. Feature importance would be more useful for sentiment analysis or spam \n#detection, hence binary classification. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"931fd23be0105d72f9b2044139583970999f1da2"},"cell_type":"code","source":"'''\nMultinomial Naive Bayes Classifier with TFIDF\n'''\n'''\nfrom sklearn.naive_bayes import MultinomialNB\n\n#Modeling and fitting\nmnb = MultinomialNB(alpha=0.1)\nmodel = mnb.fit(X_train,y_train)\n\n#Prediction and score\ny_predict = model.predict(X_test)\nscore = accuracy_score(y_test,y_predict)\n\nprint (score)\n\nmodel.get_params()\n'''\n'''\nRepresenting features represented as entire terms as opposed to single words\n'''\n#0.7584 with min_df=5 and alpha=0.1\n#0.7536 with min_df=5\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3ac776a642025c12de7cc8d108b97fc4bb7eb1e"},"cell_type":"code","source":"'''\nBernoulli Naive Bayes Classifier\n'''\n'''\nfrom sklearn.naive_bayes import BernoulliNB\n\n#Modeling and fitting\nmnb = BernoulliNB(alpha=0.1)\nmodel = mnb.fit(X_train,y_train)\n\n#Prediction and score\ny_predict = model.predict(X_test)\nscore = accuracy_score(y_test,y_predict)\n\nprint (score)\n\nmodel.get_params()\n\n#0.7644 with alpha=0.1 - better than MNB\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6847ce375d30eea4277910eb25ff76769aee905b"},"cell_type":"code","source":"'''\nSupport Vector Machines\n'''\n'''\nfrom sklearn.svm import SVC\n\n#Creating model and fitting\nsvc = SVC(kernel='linear',C=6)\nmodel = svc.fit(X_train,y_train)\n\n#Prediction and score\ny_predict = model.predict(X_test)\nscore = accuracy_score(y_test,y_predict)\nprint (score)\nprint (y_predict)\nprint (y_test)\n\n'''\nScore using CountVectorizer\n'''\n#SVC is taking a long time to execute\n#SVC with kernel as 'linear' is returning a score of 0.7772\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c5575570609ad6298793c5e2da7332ec97f1a70"},"cell_type":"code","source":"'''\nTest Data Prediction - Logistic Regression \n'''\n\n#Prediction and score\ny_predict = model.predict(test_data_vect_new)\n\nprint (y_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"336202d5f7db8af58fb4a79241fdd47c3b2a61c5"},"cell_type":"code","source":"'''\nPresenting prediction results\n'''\nprediction_results = pd.DataFrame()\nprediction_results[\"id\"] = test_data_copy[\"id\"]\nprediction_results[\"cuisine\"] = y_predict\n\nprediction_results.to_csv(\"cuisine_prediction.csv\",index=False)\nprediction_results_svm = prediction_results","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}