{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "_cell_guid": "328a17d7-e6d0-3e76-eacb-dd5145bb2b5c",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as pl\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport xgboost as xgb\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n# Pretty display for notebooks\n%matplotlib inline\n\n# Any results you write to the current directory are saved as output.",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "_cell_guid": "aea04415-07e4-4ff7-f2df-cf01529d1b52",
        "_active": false
      },
      "outputs": [],
      "source": "data = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\nprices = data['price_doc']\nfeatures_raw = data.drop(['price_doc','id'], axis =1)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "_cell_guid": "9b0f0e81-670e-8d8d-07a5-7aac7b99bc69",
        "_active": false
      },
      "outputs": [],
      "source": "data.info()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "_cell_guid": "fd56772c-b47e-495b-e4f5-3550b79bf5bf",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "# Import sklearn.preprocessing.StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfeatures_raw.fillna(0, inplace =True)\n# Initialize a scaler, then apply it to the features\nscaler = MinMaxScaler((0,1e6))\nnumerical = features_raw.select_dtypes(include=['float64','int64']).keys()\nfeatures_raw[numerical] = scaler.fit_transform(features_raw[numerical])\n\n# Show an example of a record with scaling applied\nprint (features_raw.head(n = 1))",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "_cell_guid": "8e506b51-f2b6-a6dc-89ae-99c1e6015f85",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "#One-hot encode the 'features' data using pandas.get_dummies()\nobjects = features_raw.select_dtypes(include=['object']).keys()\nlbl = LabelEncoder()\nfor col in objects:\n        lbl.fit(list(features_raw[col].values)) \n        features_raw[col] = lbl.transform(list(features_raw[col].values))\n# remove boolean with _no\nfeatures = features_raw\nfeatures = features.drop(features.filter(regex='_no', axis=1),axis=1)\nfeatures.drop('timestamp',axis=1,inplace =True)\n# Print the number of features after one-hot encoding\nencoded = list(features.columns)\nprint (\"{} total features after one-hot encoding.\".format(len(encoded)))\n\n# Uncomment the following line to see the encoded feature names\nprint (encoded)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "_cell_guid": "fd2698f2-037e-b827-6f14-b52ee41614b9",
        "_active": false
      },
      "outputs": [],
      "source": "#Minimum price of the data\nminimum_price = np.min(prices)\n\n#Maximum price of the data\nmaximum_price = np.max(prices)\n\n#Mean price of the data\nmean_price = np.mean(prices)\n\n#Median price of the data\nmedian_price = np.median(prices)\n\n#Standard deviation of prices of the data\nstd_price = np.std(prices)\n\n# Show the calculated statistics\nprint (\"Statistics for russian housing dataset:\\n\")\nprint (\"Minimum price: Rub {:,.2f}\".format(minimum_price))\nprint (\"Maximum price: Rub {:,.2f}\".format(maximum_price))\nprint (\"Mean price: Rub {:,.2f}\".format(mean_price))\nprint (\"Median price Rub {:,.2f}\".format(median_price))\nprint (\"Standard deviation of prices: Rub {:,.2f}\".format(std_price))\n#added statistic for critica alfa = 0.05 double tailed cutover\n#calculating standard error using correction for sample size n = 100\nalfa_c = (std_price/99)*1.96\nprint (\"critical alfa score for sample size of 100: Rub {:,.2f}\".format(alfa_c))",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "_cell_guid": "51b345e9-4d4a-d1dd-5d81-c61f593f6c85",
        "_active": false
      },
      "outputs": [],
      "source": "from sklearn.metrics import r2_score\ndef performance_metric(y_true, y_predict):\n    \"\"\" Calculates and returns the performance score between \n        true and predicted values based on the metric chosen. \"\"\"\n    score = r2_score(y_true, y_predict) \n    return score",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "_cell_guid": "61021e34-754a-cc1b-c8b7-7ccb948f92cb",
        "_active": false
      },
      "outputs": [],
      "source": null,
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "_cell_guid": "0d2ab7da-e11c-a9b3-4712-3a2ca565ec1b",
        "_active": false
      },
      "outputs": [],
      "source": "from sklearn.model_selection import train_test_split\n#Shuffle and split the data into training and testing subsets\nX_train, X_test, y_train, y_test = train_test_split(features,prices, test_size =0.2, random_state = 33)\nprint (\"Training and testing split was successful.\")",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "_cell_guid": "186fd04e-683d-022a-58ac-81166f3286cc",
        "_active": false
      },
      "outputs": [],
      "source": "# Produce learning curves for varying training set sizes and maximum depths\nfrom sklearn.model_selection import ShuffleSplit, train_test_split,\nfrom sklearn.model_selection import learning_curve as curves\n\nfrom sklearn.tree import DecisionTreeRegressor\ndef ModelLearning(X, y):\n    \"\"\" Calculates the performance of several models with varying sizes of training data.\n        The learning and testing scores for each model are then plotted. \"\"\"\n    \n    # Create 10 cross-validation sets for training and testing\n    cv = ShuffleSplit(n_splits = 10, test_size = 0.2, random_state = 0)\n\n    # Generate the training set sizes increasing by 50\n    train_sizes = np.rint(np.linspace(1, X.shape[0]*0.8 - 1, 9)).astype(int)\n\n    # Create the figure window\n    fig = pl.figure(figsize=(10,7))\n\n    # Create three different models based on max_depth\n    for k, depth in enumerate([1,3,6,10]):\n        \n        # Create a Decision tree regressor at max_depth = depth\n        regressor = DecisionTreeRegressor(max_depth = depth)\n\n        # Calculate the training and testing scores\n        sizes, train_scores, test_scores = curves(regressor, X, y, \\\n            cv = cv, train_sizes = train_sizes, scoring = 'r2')\n        \n        # Find the mean and standard deviation for smoothing\n        train_std = np.std(train_scores, axis = 1)\n        train_mean = np.mean(train_scores, axis = 1)\n        test_std = np.std(test_scores, axis = 1)\n        test_mean = np.mean(test_scores, axis = 1)\n\n        # Subplot the learning curve \n        ax = fig.add_subplot(2, 2, k+1)\n        ax.plot(sizes, train_mean, 'o-', color = 'r', label = 'Training Score')\n        ax.plot(sizes, test_mean, 'o-', color = 'g', label = 'Testing Score')\n        ax.fill_between(sizes, train_mean - train_std, \\\n            train_mean + train_std, alpha = 0.15, color = 'r')\n        ax.fill_between(sizes, test_mean - test_std, \\\n            test_mean + test_std, alpha = 0.15, color = 'g')\n        \n        # Labels\n        ax.set_title('max_depth = %s'%(depth))\n        ax.set_xlabel('Number of Training Points')\n        ax.set_ylabel('Score')\n        ax.set_xlim([0, X.shape[0]*0.8])\n        ax.set_ylim([-0.05, 1.05])\n    \n    # Visual aesthetics\n    ax.legend(bbox_to_anchor=(1.05, 2.05), loc='lower left', borderaxespad = 0.)\n    fig.suptitle('Decision Tree Regressor Learning Performances', fontsize = 16, y = 1.03)\n    fig.tight_layout()\n    fig.show()",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c53d19ee-04b4-58ed-0ed6-0850e06409c5",
        "_active": false
      },
      "source": "### Number of training points\nit looks that the number of training points is sufficient for the model since we can see it's plateauing ",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "_cell_guid": "6a7caf93-9b41-161b-1b22-7670e5ef30d0",
        "_active": false
      },
      "outputs": [],
      "source": "ModelLearning(features, prices)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "_cell_guid": "b9e0e09c-1f55-b6bb-359e-6d7c8a08b9e1",
        "_active": false
      },
      "outputs": [],
      "source": "from sklearn.model_selection import validation_curve\ndef ModelComplexity(X, y):\n    \"\"\" Calculates the performance of the model as model complexity increases.\n        The learning and testing errors rates are then plotted. \"\"\"\n    \n    # Create 10 cross-validation sets for training and testing\n    cv = ShuffleSplit(n_splits = 10, test_size = 0.2, random_state = 0)\n\n    # Vary the max_depth parameter from 1 to 10\n    max_depth = np.arange(1,11)\n\n    # Calculate the training and testing scores\n    train_scores, test_scores = validation_curve(DecisionTreeRegressor(), X, y, \\\n        param_name = \"max_depth\", param_range = max_depth, cv = cv, scoring = 'r2')\n\n    # Find the mean and standard deviation for smoothing\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n\n    # Plot the validation curve\n    pl.figure(figsize=(7, 5))\n    pl.title('Decision Tree Regressor Complexity Performance')\n    pl.plot(max_depth, train_mean, 'o-', color = 'r', label = 'Training Score')\n    pl.plot(max_depth, test_mean, 'o-', color = 'g', label = 'Validation Score')\n    pl.fill_between(max_depth, train_mean - train_std, \\\n        train_mean + train_std, alpha = 0.15, color = 'r')\n    pl.fill_between(max_depth, test_mean - test_std, \\\n        test_mean + test_std, alpha = 0.15, color = 'g')\n    \n    # Visual aesthetics\n    pl.legend(loc = 'lower right')\n    pl.xlabel('Maximum Depth')\n    pl.ylabel('Score')\n    pl.ylim([-0.05,1.05])\n    pl.show()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "_cell_guid": "a94c8c66-816e-c46b-367b-4efc9137578d",
        "_active": false
      },
      "outputs": [],
      "source": "ModelComplexity(X_train, y_train)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "_cell_guid": "fa521173-cecc-585e-3a03-be4f9be0b656",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "xgb_params = {\n    'eta': 0.05,\n    'max_depth': 5,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\ndtrain = xgb.DMatrix(features, prices)",
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "0857f1c7-29e7-c632-f696-0f47d18d3430",
        "_active": false,
        "collapsed": false
      },
      "source": "cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n    verbose_eval=50, show_stdv=False)\ncv_output[['train-rmse-mean', 'test-rmse-mean']].plot()",
      "execution_count": 43,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "522f97b6-cd7a-e981-180d-8b589427dc58",
        "_active": false,
        "collapsed": false
      },
      "source": "num_boost_rounds = len(cv_output)\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round= num_boost_rounds)",
      "execution_count": 44,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "5172d7e2-7f96-365f-8475-45173982d5f5",
        "_active": false,
        "collapsed": false
      },
      "source": "fig, ax = pl.subplots(1, 1, figsize=(8, 13))\nxgb.plot_importance(model, max_num_features=50, height=0.5, ax=ax)",
      "execution_count": 45,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "_cell_guid": "451eca06-2f98-5208-9e9e-4480f3048567",
        "_active": true,
        "collapsed": false
      },
      "outputs": [],
      "source": "#prepare test data:\ntest_data = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\nid_test = test_data.id\ntest_features_raw = test_data.drop(['id'], axis =1)\ntest_features_raw.fillna(0, inplace =True)\ntest_features_raw[numerical] = scaler.transform(test_features_raw[numerical])\nfor col in objects:\n        lbl.fit(list(test_features_raw[col].values)) \n        test_features_raw[col] = lbl.transform(list(test_features_raw[col].values))\n# remove boolean with _no\ntest_features = test_features_raw\ntest_features = test_features.drop(test_features.filter(regex='_no', axis=1),axis=1)\ntest_features.drop('timestamp',axis=1,inplace =True)\nTest_matrix = xgb.DMatrix(test_features)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "_cell_guid": "e9a8d91f-db17-f1cd-4e4f-bc6a5ab2ce75",
        "_active": false
      },
      "outputs": [],
      "source": "test_features.head()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "_cell_guid": "6a336b42-908d-6214-c4e0-2e9f194f8154",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "y_pred = model.predict(Test_matrix)\n\ndf_submit = pd.DataFrame({'id': id_test, 'price_doc': y_pred})\n\ndf_submit.to_csv('submit.csv', index=False)",
      "execution_state": "idle"
    }
  ]
}