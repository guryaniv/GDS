{"cells":[{"metadata":{"_uuid":"6011c533ea723c7c4072f69f84882fd4fc614697"},"cell_type":"markdown","source":"# Starter Code : EDA and LGBM Baseline "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"import warnings\nimport itertools\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, log_loss\n\nwarnings.simplefilter(action='ignore')\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"358db589356453dc15fb0eb724b4819e4efbdbbb"},"cell_type":"markdown","source":"## 1 - Loading the Data"},{"metadata":{"trusted":true,"_uuid":"112a709baa698f2d74073266f1cba588d33dd6ed","_kg_hide-input":true},"cell_type":"code","source":"dtypes = {\"crew\": \"int8\",\n          \"experiment\": \"category\",\n          \"time\": \"float32\",\n          \"seat\": \"int8\",\n          \"eeg_fp1\": \"float32\",\n          \"eeg_f7\": \"float32\",\n          \"eeg_f8\": \"float32\",\n          \"eeg_t4\": \"float32\",\n          \"eeg_t6\": \"float32\",\n          \"eeg_t5\": \"float32\",\n          \"eeg_t3\": \"float32\",\n          \"eeg_fp2\": \"float32\",\n          \"eeg_o1\": \"float32\",\n          \"eeg_p3\": \"float32\",\n          \"eeg_pz\": \"float32\",\n          \"eeg_f3\": \"float32\",\n          \"eeg_fz\": \"float32\",\n          \"eeg_f4\": \"float32\",\n          \"eeg_c4\": \"float32\",\n          \"eeg_p4\": \"float32\",\n          \"eeg_poz\": \"float32\",\n          \"eeg_c3\": \"float32\",\n          \"eeg_cz\": \"float32\",\n          \"eeg_o2\": \"float32\",\n          \"ecg\": \"float32\",\n          \"r\": \"float32\",\n          \"gsr\": \"float32\",\n          \"event\": \"category\",\n         }","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\", dtype=dtypes)\ntest_df = pd.read_csv(\"../input/test.csv\", dtype=dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"424dd33b5b3415d157f7e6861a7d654e89126c1e"},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b75b8b2aa7b5fc812ee30a71e56889b587b22bf"},"cell_type":"markdown","source":"No missing values."},{"metadata":{"trusted":true,"_uuid":"f86c914cb91d9adac5746f189bcb64ae9fc2560d"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e6bb98ee63f6d406f6f017eb79b287d1a491022"},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f668315367b6bf16c5e872ba8e06cfe7aa324500"},"cell_type":"markdown","source":"## 2 - EDA"},{"metadata":{"_uuid":"cdaf195bef3e9f737cde0f70ccdb5102a53df91a"},"cell_type":"markdown","source":"### Target & Experiment\n\nThe pilots experienced distractions intended to induce one of the following three cognitive states:\n\n- Channelized Attention (CA) is, roughly speaking, the state of being focused on one task to the exclusion of all others. This is induced in benchmarking by having the subjects play an engaging puzzle-based video game.\n- Diverted Attention (DA) is the state of having one’s attention diverted by actions or thought processes associated with a decision. This is induced by having the subjects perform a display monitoring task. Periodically, a math problem showed up which had to be solved before returning to the monitoring task.\n- Startle/Surprise (SS) is induced by having the subjects watch movie clips with jump scares.\n\nSamples are labelled the following way : \n- A = baseline\n- B = SS\n- C = CA\n- D = DA"},{"metadata":{"trusted":true,"_uuid":"e1232a0fc3cd139ce8d98bcbfabcd3872b8cc489"},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.countplot(train_df['event'])\nplt.xlabel(\"State of the pilot\", fontsize=12)\nplt.ylabel(\"Count\", fontsize=12)\nplt.title(\"Target repartition\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73ed16fa93bf5650be16c9176f674ab31237366f"},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.countplot('experiment', hue='event', data=train_df)\nplt.xlabel(\"Experiment and state of the pilot\", fontsize=12)\nplt.ylabel(\"Count (log)\", fontsize=12)\nplt.yscale('log')\nplt.title(\"Target repartition for different experiments\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff5c1e507133757dadb5b43fdc14382be794caee"},"cell_type":"markdown","source":"The experiment of the test set is LOFT (Line Oriented Flight Training), which is a full flight (take off, flight, and landing) in a flight simulator. "},{"metadata":{"_uuid":"604253799b7a1cb8f78d1188ede41946a23c5897"},"cell_type":"markdown","source":"### Seat\nWhich seat the pilot is sitting in.\n- 0 : left seat\n- 1 : right seat\n\nThis probably has nothing to do with the outcome of the experiment though."},{"metadata":{"trusted":true,"_uuid":"da63b54a38f627e271d2bafb0346898c1ea70abf"},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.countplot('event', hue='seat', data=train_df)\nplt.xlabel(\"Seat and state of the pilot\", fontsize=12)\nplt.ylabel(\"Count (log)\", fontsize=12)\nplt.yscale('log')\nplt.title(\"Left seat or right seat ?\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42d30f1a6f3ae4131696b104bbbfdfc65e4a7db8"},"cell_type":"markdown","source":"### Time of the experiment"},{"metadata":{"trusted":true,"_uuid":"be5fa5870ca99b0a4c899342109abd88d0061984"},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.violinplot(x='event', y='time', data=train_df.sample(50000))\nplt.ylabel(\"Time (s)\", fontsize=12)\nplt.xlabel(\"Event\", fontsize=12)\nplt.title(\"Which time do events occur at ?\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1703fcef0081a8017816c4a066174e588631d1bb"},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.distplot(test_df['time'], label='Test set')\nsns.distplot(train_df['time'], label='Train set')\nplt.legend()\nplt.xlabel(\"Time (s)\", fontsize=12)\nplt.title(\"Reparition of the time feature\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29369d33f917a7480d12727e59ffc15ee8147c95"},"cell_type":"markdown","source":"The repartition of events is interesting. However, we can't use this feature because time in the flight simulator has nothing to do with time in the experiments. \nIt's a shame because take-off and landing could have been exploited."},{"metadata":{"_uuid":"5d8994b040c6e7f956513b8e4d45ede9e835b837"},"cell_type":"markdown","source":"### Electroencephalogram recordings"},{"metadata":{"trusted":true,"_uuid":"1ce1c2ff455e2c47200dc3252280dab7bbbefba2"},"cell_type":"code","source":"eeg_features = [\"eeg_fp1\", \"eeg_f7\", \"eeg_f8\", \"eeg_t4\", \"eeg_t6\", \"eeg_t5\", \"eeg_t3\", \"eeg_fp2\", \"eeg_o1\", \"eeg_p3\", \"eeg_pz\", \"eeg_f3\", \"eeg_fz\", \"eeg_f4\", \"eeg_c4\", \"eeg_p4\", \"eeg_poz\", \"eeg_c3\", \"eeg_cz\", \"eeg_o2\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22cdf9fb51fc3a6b54fb8254f9dd7e7a7479d6bd"},"cell_type":"code","source":"plt.figure(figsize=(20,25))\ni = 0\n\nfor egg in eeg_features:\n    i += 1\n    plt.subplot(5, 4, i)\n    sns.boxplot(x='event', y=egg, data=train_df.sample(50000), showfliers=False)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80e4c0e060e5312110289e0b6840beb2bc809c70"},"cell_type":"markdown","source":"We Also check if features have the same distribution on the test and train set"},{"metadata":{"trusted":true,"_uuid":"2f62cd64bfe238aa1e85ca4d4a7ff53d860e4c89"},"cell_type":"code","source":"plt.figure(figsize=(20,25))\nplt.title('Eeg features distributions')\ni = 0\n\nfor eeg in eeg_features:\n    i += 1\n    plt.subplot(5, 4, i)\n    sns.distplot(test_df.sample(10000)[eeg], label='Test set', hist=False)\n    sns.distplot(train_df.sample(10000)[eeg], label='Train set', hist=False)\n    plt.xlim((-500, 500))\n    plt.legend()\n    plt.xlabel(eeg, fontsize=12)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"735e38937e75eac6848ac7debcb96f6ebff8fdf4"},"cell_type":"markdown","source":"Reparitions seem consistent :  Gaussians with a sinusoïdal noise centered at 0. Note that the variance is larger on the test set."},{"metadata":{"_uuid":"0c7f7696cad5db2b1bfca5b87380fba81a7a9375"},"cell_type":"markdown","source":"### Electrocardiogram\n- 3-point Electrocardiogram signal. The sensor had a resolution/bit of .012215 µV and a range of -100mV to +100mV. The data are provided in microvolts."},{"metadata":{"trusted":true,"_uuid":"881f7235401f16fc88adf3d526642f703946d0c5"},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.violinplot(x='event', y='ecg', data=train_df.sample(50000))\nplt.ylabel(\"Electrocardiogram Signal (µV)\", fontsize=12)\nplt.xlabel(\"Event\", fontsize=12)\nplt.title(\"Electrocardiogram signal influence\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8068c2e4f64175abe10daf7bb65e018155ca1550"},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.distplot(test_df['ecg'], label='Test set')\nsns.distplot(train_df['ecg'], label='Train set')\nplt.legend()\nplt.xlabel(\"Electrocardiogram Signal (µV)\", fontsize=12)\nplt.title(\"Electrocardiogram Signal Distribution\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d0870cac49a7604013996db2ed6df3b91cb0842"},"cell_type":"markdown","source":"Except foir the >20000-ish samples, train/test repartitions are similar."},{"metadata":{"_uuid":"db52190ed75af7ee9322b459eb9e42b597eb2632"},"cell_type":"markdown","source":"### Respiration \n- A measure of the rise and fall of the chest. The sensor had a resolution/bit of .2384186 µV and a range of -2.0V to +2.0V. The data are provided in microvolts."},{"metadata":{"trusted":true,"_uuid":"a654a8e6d29bd4ad06f9bf9696c1ec47694c5a80"},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.violinplot(x='event', y='r', data=train_df.sample(50000))\nplt.ylabel(\"Respiration Signal (µV)\", fontsize=12)\nplt.xlabel(\"Event\", fontsize=12)\nplt.title(\"Respiration influence\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c33ca37f86c115bceba3dc0b3eed27e0be7ade9"},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.distplot(test_df['r'], label='Test set')\nsns.distplot(train_df['r'], label='Train set')\nplt.legend()\nplt.xlabel(\"Respiration Signal (µV)\", fontsize=12)\nplt.title(\"Respiration Signal Distribution\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e30fa71a8bedea5f77858c41609d3c0d8fc12391"},"cell_type":"markdown","source":"Nothing much to say here, the test set has a bunch of sample with lower values though."},{"metadata":{"_uuid":"e0ce0eaf7057cf7d8e1106f2a33c281002858768"},"cell_type":"markdown","source":"### Galvanic Skin Response\n - A measure of electrodermal activity. The sensor had a resolution/bit of .2384186 µV and a range of -2.0V to +2.0V. The data are provided in microvolts.\n > \"The galvanic skin response (GSR, which falls under the umbrella term of electrodermal activity, or EDA) refers to changes in sweat gland activity that are reflective of the intensity of our emotional state, otherwise known as emotional arousal.\""},{"metadata":{"trusted":true,"_uuid":"93b77b5eab8b763fb413634448437aae6ddbca73"},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.violinplot(x='event', y='gsr', data=train_df.sample(50000))\nplt.ylabel(\"Electrodermal activity measure (µV)\", fontsize=12)\nplt.xlabel(\"Event\", fontsize=12)\nplt.title(\"Electrodermal activity influence\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c8e8accb1316906fc55722ae7c7271398528436"},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.distplot(test_df['gsr'], label='Test set')\nsns.distplot(train_df['gsr'], label='Train set')\nplt.legend()\nplt.xlabel(\"Electrodermal activity measure (µV)\", fontsize=12)\nplt.title(\"Electrodermal activity Distribution\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bbeebe28e155d3683479e05f6c1358c6aec963e2"},"cell_type":"markdown","source":"Again, quite similar."},{"metadata":{"_uuid":"2db337adcb15835faaf1c13bac6425e180a8609f"},"cell_type":"markdown","source":"## 3 - Gradient Boosting"},{"metadata":{"_uuid":"bc51baac210a623cd5027d80dbc2288d70542675"},"cell_type":"markdown","source":"### Normalizing \n\nBecause of earlier remarks, we normalize our features. \n\nI do believe the following features depend a lot of the person, therefore I apply a Min/Max Scaler for each pilot."},{"metadata":{"trusted":true,"_uuid":"c8ffc3dd6cb73ba2e490721e330a7c7fe40f0a41"},"cell_type":"code","source":"features_n = [\"eeg_fp1\", \"eeg_f7\", \"eeg_f8\", \"eeg_t4\", \"eeg_t6\", \"eeg_t5\", \"eeg_t3\", \"eeg_fp2\", \"eeg_o1\", \"eeg_p3\", \"eeg_pz\", \"eeg_f3\", \"eeg_fz\", \"eeg_f4\", \"eeg_c4\", \"eeg_p4\", \"eeg_poz\", \"eeg_c3\", \"eeg_cz\", \"eeg_o2\", \"ecg\", \"r\", \"gsr\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f2ec6400444ab65794ae9ec737d05d76d3636ed"},"cell_type":"code","source":"train_df['pilot'] = 100 * train_df['seat'] + train_df['crew']\ntest_df['pilot'] = 100 * test_df['seat'] + test_df['crew']\n\nprint(\"Number of pilots : \", len(train_df['pilot'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdcf6644ee8bdb1ebc35e84139ac1c969d1fe120"},"cell_type":"code","source":"def normalize_by_pilots(df):\n    pilots = df[\"pilot\"].unique()\n    for pilot in tqdm(pilots):\n        ids = df[df[\"pilot\"] == pilot].index\n        scaler = MinMaxScaler()\n        df.loc[ids, features_n] = scaler.fit_transform(df.loc[ids, features_n])\n        \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b4b60baf0099f0e771bc398c313269c5209eb5e"},"cell_type":"code","source":"train_df = normalize_by_pilots(train_df)\ntest_df = normalize_by_pilots(test_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4f0a594f9474fda8920312f04caeebed4c6d73d"},"cell_type":"markdown","source":"### Train / Test split"},{"metadata":{"trusted":true,"_uuid":"042c436d74a3cb28fa8d0a6df80e255518a96b8d"},"cell_type":"code","source":"train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=420)\nprint(f\"Training on {train_df.shape[0]} samples.\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78cdb7fb5df729452e18d13a52f74930ab900c76"},"cell_type":"markdown","source":"### Model\nNote that I did not bother tweaking the parameters yet."},{"metadata":{"trusted":true,"_uuid":"7e347178cf9ff1748522e24c53b5e8d2218c7772"},"cell_type":"code","source":"features = [\"crew\", \"seat\"] + features_n\n      \ndef run_lgb(df_train, df_test):\n    # Classes as integers\n    dic = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n    try:\n        df_train[\"event\"] = df_train[\"event\"].apply(lambda x: dic[x])\n        df_test[\"event\"] = df_test[\"event\"].apply(lambda x: dic[x])\n    except: \n        pass\n    \n    params = {\"objective\" : \"multiclass\",\n              \"num_class\": 4,\n              \"metric\" : \"multi_error\",\n              \"num_leaves\" : 30,\n              \"min_child_weight\" : 50,\n              \"learning_rate\" : 0.1,\n              \"bagging_fraction\" : 0.7,\n              \"feature_fraction\" : 0.7,\n              \"bagging_seed\" : 420,\n              \"verbosity\" : -1\n             }\n    \n    lg_train = lgb.Dataset(df_train[features], label=(df_train[\"event\"]))\n    lg_test = lgb.Dataset(df_test[features], label=(df_test[\"event\"]))\n    model = lgb.train(params, lg_train, 1000, valid_sets=[lg_test], early_stopping_rounds=50, verbose_eval=100)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"519c568fe098bcdb622d423ae3f8b920be610c1a"},"cell_type":"code","source":"model = run_lgb(train_df, val_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a27228312379f6b4a14cf1b47897d035db10978"},"cell_type":"markdown","source":"### Feature importance"},{"metadata":{"trusted":true,"_uuid":"6fb7d1cd460838580f89ec0850b1656cce69d3cf"},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,10))\nlgb.plot_importance(model, height=0.8, ax=ax)\nax.grid(False)\nplt.ylabel('Feature', size=12)\nplt.xlabel('Importance', size=12)\nplt.title(\"Importance of the Features of our LightGBM Model\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3308f3210916c8ca93718a08e02692d32479391d"},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true,"_uuid":"6b7c49a636351c7c98115285fe91f144593138fc"},"cell_type":"code","source":"pred_val = model.predict(val_df[features], num_iteration=model.best_iteration)\n#pred_train = model.predict(train_df[features], num_iteration=model.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2935e56653caa342582eabc57859d523822a491"},"cell_type":"code","source":"print(\"Log loss on validation data :\", round(log_loss(np.array(val_df[\"event\"].values), pred_val), 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dfcf700f63ede147043aeb00f344ea3947ae1c3","_kg_hide-input":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes, title='Confusion matrix', normalize=False, cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    fmt = '.2f' if normalize else 'd'\n\n    fig, ax = plt.subplots(figsize=(15, 10))\n    ax.imshow(cm, interpolation='nearest', cmap=cmap)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, size=15)\n    plt.colorbar()\n    plt.grid(False)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = (cm.max()+cm.min()) / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', size=12)\n    plt.xlabel('Predicted label', size=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b1033ff7f9a38e3232309fb74d5f7c1db8592ea"},"cell_type":"code","source":"conf_mat_val = confusion_matrix(np.argmax(pred_val, axis=1), val_df[\"event\"].values)\nplot_confusion_matrix(conf_mat_val, [\"A\", \"B\", \"C\", \"D\"], title='Confusion matrix on Validation data', normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fc289527b4d9019e2234ad1e9fbe74c55d32f49"},"cell_type":"markdown","source":"### Submission"},{"metadata":{"trusted":true,"_uuid":"0eeb0d61db636116ea6d08bc3ef420c346368ee0"},"cell_type":"code","source":"pred_test = model.predict(test_df[features], num_iteration=model.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"344bd657586f43a8786ca1622b9ca9e468d6c5d8"},"cell_type":"code","source":"submission = pd.DataFrame(np.concatenate((np.arange(len(test_df))[:, np.newaxis], pred_test), axis=1), columns=['id', 'A', 'B', 'C', 'D'])\nsubmission['id'] = submission['id'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cb7d71904610cb67a231077f9ba362979d892da"},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b73c3ea57f106bdd4957f657c2e3e311d356c407"},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03871a0024f52e6cd96122af5303384517b7504e"},"cell_type":"markdown","source":"Any feedback is always appreciated ! \n\n### *Thanks for reading !*\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}