{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\n\nenv = twosigmanews.make_env()\n(market_data,news_data) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"faa769c8cbb579958b510bee6bf0f77d08ad4964"},"cell_type":"code","source":"# output the shape of the data\nprint(market_data.shape)\nprint(news_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7de5899148762b6252aa4cb3e34b3f5a38ef102a"},"cell_type":"code","source":"market_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63ad94f8a8680c2070ca373ab9c4724bcc9f58e0"},"cell_type":"code","source":"news_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"959a8e980e4c1f5ebe7dc4dbbc2464bf7308e7a9"},"cell_type":"code","source":"# look at missing data\nimport matplotlib.pyplot as plt\ndef mis_value_graph(data):\n    data.isnull().sum().plot(kind=\"bar\",figsize=(20,10),fontsize=20)\n    plt.xlabel(\"Columns\")\n    plt.ylabel(\"Missing Value Count\")\n    plt.title(\"the number of null data of all column\")\n    plt.show()\nmis_value_graph(market_data)\nmis_value_graph(news_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60836222c05ce34391d31726f9da87f8dbaa70f8"},"cell_type":"code","source":"# handle missing data about market_data\nfrom sklearn.preprocessing import StandardScaler\n\nID_col = ['assetCode']\nTarget_col = ['returnsOpenNextMktres10']\nCat_col = ['assetCode']\nNum_cols = ['volume','close','open','returnsClosePrevRaw1','returnsOpenPrevRaw1','returnsClosePrevMktres1'\n           ,'returnsOpenPrevMktres1','returnsClosePrevRaw1','returnsOpenPrevRaw10',\n           'returnsClosePrevMktres10','returnsOpenPrevMktres10','returnsOpenNextMktres10']\n# def HandleCatData(encoder,x):\n#     len_encoder=len(encoder)\n#     try:\n#         id = encoder[x]\n#     except KeyError:\n#         return id\n# encoders = [{} for cat in Cat_col]\n# for i,cat in enumerate(Cat_col):\n#     print('encoding %s ...'%cat,end='')\n#     encoders[i] = {1:id for id,i in enumerate(market_data.loc[market_data,cat].astype(str).unique())}\n#     market_data[cat] = market_data[cat].astype(str).apply(lambda x:HandleCatData(encoders[i],x))\n#     print('Done')\n\n# embed_sizes = [len(HandleCatData) +1 for encode in encoders]\n\n# handle num data\nmarket_data[Num_cols] = market_data[Num_cols].fillna(0)\nprint(\"scaling numerical columns\")\n\nscaler = StandardScaler()\nmarket_data[Num_cols] = scaler.fit_transform(market_data[Num_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9045c7943b2f196f81e140b71623cc3b4d3afb70"},"cell_type":"code","source":"market_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd4581b551ce7d1472aebefade18947cf0cb1eaf"},"cell_type":"code","source":"# create train model\n# news data contact to marker data by using assetCode\nassetCodeList = news_data['assetCodes']\nCodeList = []\nfor item in assetCodeList:\n    item = assetCodeList[0].replace('\\'','')\n    item = item[1:len(item)-1]\n    arrList = item.split(',');\n    CodeList.append(arrList)\nprint(len(CodeList))\n\n# get News data by using assetCode\ndef getNewsData(assetCode):\n    for i in range(len(CodeList)):\n        for j in range(CodeList[i]):\n            if(assetCode==CodeList[i][j]):\n                return i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f426b5f3893e099676cb7f1e552060cba855259a"},"cell_type":"code","source":"# handle fulldata list\ncols = ['sentenceCount','wordCount','firstMentionSentenct','relevance','sentimentClass','sentimentNegative',\n       'sentimentNeutral','sentimentPositive','sentimeWordCount','noveltyCount12H',\n       'noveltyCount24H','noveltyCount5D','noveltyCount7D','volumeCounts12H',\n       'volumeCounts3D','volumnCounts5D','volumeCounts7D']\ndef getFullData(market_data,news_data):\n    news_data = news_data[cols]\n    connactData = []\n    for assetcode in market_data.assetCode:\n        index = getNewsData(assetcode)\n        connactData.append(news_data[index])\n    np.hstack((market_data[Num_cols],connactData))\nfullData = getFullData(market_data,news_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6394e2261bfac4e03dc8803df1149ccfbb26c8f"},"cell_type":"code","source":"# split all data as train and test data\n# the rate of the test data is 20%\nfrom sklearn.model_selection import train_test_split\ntrain_data,test_data = train_test_split(fullData.index.values,test_size=0.2,random_state=0)\nprint(train_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95dd8616a72248cdb96b2f6feaf73e09e88f6b0b"},"cell_type":"code","source":"# show some descriptions of target variable\nmarket_data.returnsOpenNextMktres10.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97454a2ec7677ae6ee5b2502ab421ccd30a58d54"},"cell_type":"code","source":"# look at the distribution of target variable\nplt.figure(figsize=(10,5))\nprint(\"skew\",market_data.returnsOpenNextMktres10.skew())\nimport seaborn as sns\nsns.distplot(market_data['returnsOpenNextMktres10'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20f8b5b8c83f055a1198532d7b271c3047ebbe3c"},"cell_type":"code","source":"# create train model\n# way 1 : NN model\nfrom keras.models import Sequential,load_model\nfrom keras.layers import LSTM,Dropout,Dense\ndef  get_lstm(data):\n    '''\n    function: created an RNN forecasting model\n    :param data:\n    :return:\n    '''\n    model = Sequential()\n    model.add(LSTM(data[1],input_shape=(data[0],1),return_sequences=True))\n    model.add(Dropout(0.2))\n    model.add(Dense(data[3],activation='linear'))\n    return model\nmodel = get_lstm(fullData)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a6af4957b8d19e69a0ede0b8ba12a584f20a930"},"cell_type":"code","source":"# train model\ndef train_model(model,x_train,y_train,config):\n    model.compile(loss='mse', optimizer='rmsprop', metrics=['mape'])\n    hist = model.fit(x_train,y_train,\n                     batch_size=config[\"batch\"],\n                     epochs=config[\"epochs\"],\n                     validation_split=0.05)\n    model.save('model/lstm.h5')\n    df = pd.DataFrame.from_dict(hist.history)\n    df.to_csv('model/lstm loss.csv',encoding='utf-8',index=False)\nconfig = {\"batch\":32,\"epochs\":10}\ntrain_model(model,train_data-train_data.returnsOpenNextMktres10,train_data.returnsOpenNextMktres10,config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0455fc3e97e4cb3cbea4cbad2eb8c309d3b27e8a"},"cell_type":"code","source":"# predict\ndef predict(X):\n    lstm = load_model('model/lstm.h5')\n    predictd = lstm.predict(X)\n    return predictd\ndays = env.get_prediction_days()\npredictd = []\nfor day in days:\n    predictd.append(predict(days))\n# look at the distribution of predict variable\nplt.figure(figsize=(10,5))\nprint(\"skew\",predictd.skew())\nimport seaborn as sns\nsns.distplot(predictd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e8e6803342e1988598a248b8b4a8921a1e82c18"},"cell_type":"code","source":"# fourth : Evaluate model\ndef calculate_loss(x_test,y_test):\n    from sklearn import linear_model\n    lm = linear_model.LinearRegression()\n    from sklearn.model_selection import cross_val_score\n    scores = -cross_val_score(lm,x_train,y_train,cv=5,scoring='neg_mean_absolute_error')\n    error = np.mean(scores)\n    return error'\nerror = calculate_loss(test_data-test_data.returnsOpenNextMktres10,test_data.returnsOpenNextMktres10)\n# look at the distribution of target variable\nplt.figure(figsize=(10,5))\nprint(\"skew\",error.skew())\nimport seaborn as sns\nsns.distplot(error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97e2159d9ccb89d93e7f135e9f6f9c2db4f47726"},"cell_type":"code","source":"# write the result into submission.csv\nsub = pd.DataFrame.from_dict(predictd)\n# submit the final result\nsub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}