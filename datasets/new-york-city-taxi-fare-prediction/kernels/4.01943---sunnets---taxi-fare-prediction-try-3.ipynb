{"cells":[{"metadata":{"_uuid":"202e10c43907e5fdc7264a2c328aa0a53ed73a10"},"cell_type":"markdown","source":"### Dependencies"},{"metadata":{"_uuid":"6b918c27019644a30cb9bdd9e4474f481778f2c7"},"cell_type":"markdown","source":"Bellow we setup path to the datasets and import the libraries that are gonna be used"},{"metadata":{"trusted":true,"_uuid":"a14acd63db3c68103946ce39c012db419a32ebf3"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization, LSTM\nfrom keras.callbacks import EarlyStopping\nfrom keras import optimizers\nfrom keras import regularizers\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import backend\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\n\nTRAIN_PATH = '../input/new-york-city-taxi-fare-prediction/train.csv'\nSUBMISSION_NAME = 'submissiontry_water.csv'\n\nTRAINMEHRAK_PATH = '../input/taxipredictiondata8m/trainMehrak.csv'\nTESTMEHRAK_PATH = '../input/taxipredictiondata8m/testMehrak.csv'\nTEST_PATH = '../input/new-york-city-taxi-fare-prediction/test.csv'\n\n# Model parameters\nBATCH_SIZE = 1000\nEPOCHS = 100\nLEARNING_RATE = 0.5\nDATASET_SIZE = 8000000\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fb8304aad05cc5c7fb4ab80da856edfe34e0916"},"cell_type":"markdown","source":"This is the function to clean the outliers"},{"metadata":{"trusted":true,"_uuid":"83a75fbb961ab45d2f32d9cb58acb7e78916d84c"},"cell_type":"code","source":"def clean(df):\n    \n    print(' Old size: %d' % len(df))\n    # remove any null data\n    df = df.dropna(how = 'any', axis = 'rows')\n    print(' New size after dropna: %d' % len(df))  \n    \n        # Remove inconsistent values\n    df = df[(df['dropoff_longitude'] != df['pickup_longitude']) & (df['dropoff_latitude'] != df['pickup_latitude'])]\n    print(' New size after removing same long lat: %d' % len(df))                 \n    \n    df = df[(df['dropoff_longitude'] != 0) & (df['pickup_longitude'] != 0) & (df['dropoff_latitude'] != 0) & (df['pickup_latitude'] != 0)] \n    print(' New size after removing 0 long lat: %d' % len(df))                          \n    #MinMax = (-74.5, -72.8, 40.5, 41.8)\n    MinMax = (-74.1, -73.87, 40.6, 41.0)\n\n    #-72.986532\t41.709555\t-72.990963\t41.696683\n    # Delimiter lats and lons to NY only\n    df = df[(MinMax[0] <= df['pickup_longitude']) & (df['pickup_longitude'] <= MinMax[1])]\n    df = df[(MinMax[0] <= df['dropoff_longitude']) & (df['dropoff_longitude'] <= MinMax[1])]\n    df = df[(MinMax[2] <= df['pickup_latitude']) & (df['pickup_latitude'] <= MinMax[3])]\n    df = df[(MinMax[2] <= df['dropoff_latitude']) & (df['dropoff_latitude'] <= MinMax[3])]\n       \n\n    print(' New size after NYC lang lot: %d' % len(df))         \n    \n    df = df[(df['pickup_latitude'] != 0)]\n    df = df[(df['pickup_latitude'] != 0)]\n    df = df[(df['dropoff_longitude']!= 0)]\n    df = df[(df['dropoff_latitude'] != 0)]\n    \n    print(' New size after lang lot > 0: %d' % len(df))         \n\n    df = df[((df['pickup_latitude'] - df['dropoff_latitude']).abs() > 0.001)]\n    df = df[((df['pickup_longitude'] - df['dropoff_longitude']).abs() > 0.001)]\n    \n    print(' New size after lang - lot > 0.001: %d' % len(df))         \n    \n    print(' New size after only NYC: %d' % len(df)) \n    \n    df = df[(0 < df['fare_amount']) & (df['fare_amount'] <= 50)]\n    \n    print(' New size after removing outliers: %d' % len(df)) \n    \n    df = df[(df['passenger_count'] > 0) & (df['passenger_count'] < 50)]\n    print(' New size after removing 6=>passenger_count > 0 : %d' % len(df)) \n    #print(' New size after removing passenger_count > 0: %d' % len(df)) \n    \n    \n    \n    # Remove airports\n    \n    nyc_coord = (40.7141667,-74.0063889) \n    fk_coord = (40.639722, -73.778889)\n    ewr_coord = (40.6925, -74.168611)\n    lga_coord = (40.77725, -73.872611)\n    sol_coord = (40.6892,-74.0445) # Statue of Liberty\n    \n             \n\n    #ny\n    df = df[(nyc_coord[1] != df['pickup_longitude']) & (df['pickup_latitude'] != nyc_coord[0])]\n    df = df[(nyc_coord[1] != df['dropoff_longitude']) & (df['dropoff_latitude'] != nyc_coord[0])]\n    \n    print(' New size after NY airport: %d' % len(df))\n    \n    #jfk\n    df = df[(fk_coord[1] != df['pickup_longitude']) & (df['pickup_latitude'] != fk_coord[0])]\n    df = df[(fk_coord[1] != df['dropoff_longitude']) & (df['dropoff_latitude'] != fk_coord[0])]\n    \n    print(' New size after jfk airport: %d' % len(df))\n    \n    #ewr\n    df = df[(ewr_coord[1] != df['pickup_longitude']) & (df['pickup_latitude'] != ewr_coord[0])]\n    df = df[(ewr_coord[1] != df['dropoff_longitude']) & (df['dropoff_latitude'] != ewr_coord[0])]\n    \n    print(' New size after ewr airport: %d' % len(df))\n    #lgr\n    df = df[(lga_coord[1] != df['pickup_longitude']) & (df['pickup_latitude'] != lga_coord[0])]\n    df = df[(lga_coord[1] != df['dropoff_longitude']) & (df['dropoff_latitude'] != lga_coord[0])]\n    \n\n    print(' New size after lgr airport: %d' % len(df))\n             \n    #sol\n    df = df[(sol_coord[1] != df['pickup_longitude']) & (df['pickup_latitude'] != sol_coord[0])]\n    df = df[(sol_coord[1] != df['dropoff_longitude']) & (df['dropoff_latitude'] != sol_coord[0])]\n    \n\n    print(' New size after sol removed: %d' % len(df))             \n    \n            \n    print('Old size: %d' % len(df))\n    df = remove_datapoints_from_water(df)\n    print('New size: %d' % len(df))\n    \n        \n    print(' New size: %d' % len(df))\n    \n       \n    return df\n    \n   \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75607a7a3c2bedb93c77eed3d7daa8c34cb94822"},"cell_type":"markdown","source":"Helper methods"},{"metadata":{"trusted":true,"_uuid":"b51e800aad07d5913e92726be9b24e56c17e60ee"},"cell_type":"code","source":"# Helper methods\ndef remove_datapoints_from_water(df):\n    def lonlat_to_xy(longitude, latitude, dx, dy, BB):\n        return (dx*(longitude - BB[0])/(BB[1]-BB[0])).astype('int'), \\\n               (dy - dy*(latitude - BB[2])/(BB[3]-BB[2])).astype('int')\n\n    # define bounding box\n    BB = (-74.5, -72.8, 40.5, 41.8)\n    \n    # read nyc mask and turn into boolean map with\n    # land = True, water = False\n    nyc_mask = plt.imread('https://aiblog.nl/download/nyc_mask-74.5_-72.8_40.5_41.8.png')[:,:,0] > 0.9\n    \n    # calculate for each lon,lat coordinate the xy coordinate in the mask map\n    pickup_x, pickup_y = lonlat_to_xy(df.pickup_longitude, df.pickup_latitude, \n                                      nyc_mask.shape[1], nyc_mask.shape[0], BB)\n    dropoff_x, dropoff_y = lonlat_to_xy(df.dropoff_longitude, df.dropoff_latitude, \n                                      nyc_mask.shape[1], nyc_mask.shape[0], BB)    \n    # calculate boolean index\n    idx = nyc_mask[pickup_y, pickup_x] & nyc_mask[dropoff_y, dropoff_x]\n    \n    # return only datapoints on land\n    return df[idx]\n    \ndef late_night (row):\n     if (row['hour'] <= 3) or (row['hour'] >= 0):\n        return 1\n     else:\n        return 0\n\n\ndef night (row):\n    if ((row['hour'] > 20) and (row['hour'] > 0)) and (row['weekday'] < 5):\n        return 1\n    else:\n        return 0\n    \ndef rush_hour (row):\n    if ((row['hour'] <= 20) and (row['hour'] >= 16)) and (row['weekday'] < 5):\n        return 1\n    else:\n        return 0   \n    \ndef manhattan(pickup_lat, pickup_long, dropoff_lat, dropoff_long):\n    return np.abs(dropoff_lat - pickup_lat) + np.abs(dropoff_long - pickup_long)\n\n\ndef add_time_features(df):\n    df['pickup_datetime'] =  pd.to_datetime(df['pickup_datetime'], format='%Y-%m-%d %H:%M:%S %Z')\n    df['year'] = df['pickup_datetime'].apply(lambda x: x.year)\n    df['month'] = df['pickup_datetime'].apply(lambda x: x.month)\n    df['day'] = df['pickup_datetime'].apply(lambda x: x.day)\n    df['hour'] = df['pickup_datetime'].apply(lambda x: x.hour)\n    df['minute'] = df['pickup_datetime'].apply(lambda x: x.minute)\n    df['second'] = df['pickup_datetime'].apply(lambda x: x.second)\n    \n    return df\n\n\ndef add_coordinate_features(df):\n    lat1 = df['pickup_latitude']\n    lat2 = df['dropoff_latitude']\n    lon1 = df['pickup_longitude']\n    lon2 = df['dropoff_longitude']\n    \n    # Add new features\n    df['latdiff'] = (lat1 - lat2)#.abs()\n    df['londiff'] = (lon1 - lon2)#.abs()\n    \n    \n    return df\n\n\ndef add_distances_features(df):\n    \n    lat1 = df['pickup_latitude']\n    lat2 = df['dropoff_latitude']\n    lon1 = df['pickup_longitude']\n    lon2 = df['dropoff_longitude']\n    \n    df['manhattan'] = manhattan(lat1, lon1, lat2, lon2)\n    #df['distance'] = np.sqrt(np.abs(df['pickup_longitude']-df['dropoff_longitude'])**2 + np.abs(df['pickup_latitude']-df['dropoff_latitude'])**2)\n    df['distance'] = distance(lat1, lon1, lat2, lon2)\n    #df['distance_miles'] = distance(df['pickup_latitude'], df['pickup_longitude'], df['dropoff_latitude'], df['dropoff_longitude'])\n    \n  \n    return df\n\n# This function is based on https://stackoverflow.com/questions/27928/\n# calculate-distance-between-two-latitude-longitude-points-haversine-formula \n# return distance in miles\ndef distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295 # Pi/180\n    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a)) # 2*R*asin...\n# This function is based on https://stackoverflow.com/questions/27928/\n# calculate-distance-between-two-latitude-longitude-points-haversine-formula \n# return distance in miles\ndef distanceP(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295 # Pi/180\n    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a)) # 2*R*asin...\n    \ndef output_submission(raw_test, prediction, id_column, prediction_column, file_name):\n    df = pd.DataFrame(prediction, columns=[prediction_column])\n    df[id_column] = raw_test[id_column]\n    df[[id_column, prediction_column]].to_csv((file_name), index=False)\n    print('Output complete')\n    \n    \ndef plot_loss_accuracy_rmse(history):\n    \n    plt.figure(figsize=(20,10))\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper right')\n    plt.show()\n    \n    \n    plt.figure(figsize=(20,10))\n    plt.plot(history.history['rmse'])\n    plt.plot(history.history['val_rmse'])\n    plt.title('Model rmse')\n    plt.ylabel('rmse')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper right')\n    plt.show()\n    \ndef plot_on_map(df, BB, nyc_map, s=10, alpha=0.2):\n    fig, axs = plt.subplots(1, 2, figsize=(16,10))\n    axs[0].scatter(df.pickup_longitude, df.pickup_latitude, zorder=1, alpha=alpha, c='r', s=s)\n    axs[0].set_xlim((BB[0], BB[1]))\n    axs[0].set_ylim((BB[2], BB[3]))\n    axs[0].set_title('Pickup locations')\n    axs[0].imshow(nyc_map, zorder=0, extent=BB)\n\n    axs[1].scatter(df.dropoff_longitude, df.dropoff_latitude, zorder=1, alpha=alpha, c='r', s=s)\n    axs[1].set_xlim((BB[0], BB[1]))\n    axs[1].set_ylim((BB[2], BB[3]))\n    axs[1].set_title('Dropoff locations')\n    axs[1].imshow(nyc_map, zorder=0, extent=BB)    \n    \n\ndef rmse(y_true, y_pred):\n\treturn backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n\ndef rmse(y_true, y_pred):\n\treturn backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\ndef mean_absolute_percentage_error(y_true, y_pred): \n    return backend.mean(backend.abs((y_true - y_pred) / y_true)) * 100\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ed50cf790d627958e5f8960a48abf8e9d52e7ce"},"cell_type":"markdown","source":"import data"},{"metadata":{"trusted":true,"_uuid":"b7682ac4f92b34ca75bf4caa3d39871ce4f5865a","scrolled":false},"cell_type":"code","source":"# Load values in a more compact form\ndatatypes = {'key': 'str', \n              'fare_amount': 'float32',\n              'pickup_datetime': 'str', \n              'pickup_longitude': 'float32',\n              'pickup_latitude': 'float32',\n              'dropoff_longitude': 'float32',\n              'dropoff_latitude': 'float32',\n              'passenger_count': 'uint8'}\n\ntrain_df = pd.read_csv(TRAINMEHRAK_PATH, nrows=DATASET_SIZE, dtype=datatypes, usecols=[1,2,3,4,5,6,7])\ntest_df = pd.read_csv(TESTMEHRAK_PATH, nrows=DATASET_SIZE, dtype=datatypes, usecols=[1,2,3,4,5,6,7])\ntestKaggle = pd.read_csv(TEST_PATH)   \n\nprint('Done with importing data')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe6516765fcb4e7f3edbdda9468b57488e590d04"},"cell_type":"markdown","source":"running some statistics on train and test set, as well as plot scatter and histagram"},{"metadata":{"trusted":true,"_uuid":"dc9fc336dbb5af2a5aa2c6795e3e55467de2964b"},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9561bf594bf7e7823d5f8be578981a8aeeda6f89"},"cell_type":"code","source":"test_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9ee2c5a19fec193935c7474c8f42de74b129e93"},"cell_type":"code","source":"train_df = train_df.dropna(how = 'any', axis = 'rows')\ntest_df = test_df.dropna(how = 'any', axis = 'rows')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb8039bec66fcf47ab89d2fc982c5c015d389224"},"cell_type":"code","source":"plot = train_df.plot.scatter('pickup_longitude', 'fare_amount')\nplot = train_df.plot.scatter('pickup_latitude', 'fare_amount')\nplot = train_df.plot.scatter('dropoff_longitude', 'fare_amount')\nplot = train_df.plot.scatter('dropoff_latitude', 'fare_amount')\nplot = train_df.plot.scatter('passenger_count', 'fare_amount')\nplot = train_df.plot.scatter('fare_amount', 'fare_amount')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"560f540a58b42ec41afa1964bff6577bf5e9b5f2"},"cell_type":"code","source":"plot = test_df.plot.scatter('pickup_longitude', 'fare_amount')\nplot = test_df.plot.scatter('pickup_latitude', 'fare_amount')\nplot = test_df.plot.scatter('dropoff_longitude', 'fare_amount')\nplot = test_df.plot.scatter('dropoff_latitude', 'fare_amount')\nplot = test_df.plot.scatter('passenger_count', 'fare_amount')\nplot = test_df.plot.scatter('fare_amount', 'fare_amount')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ac12110796c73ebee57d116748381b5db4cadcf"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['pickup_longitude'])\nplt.xlabel(\"pickup_longitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1620afc6ed539dfe78bafe446a2e3b6cb639634"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['pickup_latitude'])\nplt.xlabel(\"pickup_latitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d74e045c59f6a9569b671d8637a619ec52bdcc3a"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['dropoff_longitude'])\nplt.xlabel(\"dropoff_longitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74ebd8f351e2ff28d9af2352ffd3c22d8520f37b"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['dropoff_latitude'])\nplt.xlabel(\"dropoff_latitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"decec9c03b9619ea6fce962b28beb4fc910b00d7"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['passenger_count'])\nplt.xlabel(\"passenger_count\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"652f70f85d34d015a9431d7c4dc4425756a4258d"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['fare_amount'])\nplt.xlabel(\"fare_amount\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca20b7bdd4427aff2531b37b1b202ee8f9b7b4ce"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(test_df['pickup_longitude'])\nplt.xlabel(\"pickup_longitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2058f901b65cfda00214cf1a79a4ac9129ee0808"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(test_df['pickup_latitude'])\nplt.xlabel(\"pickup_latitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8baf2722b8d13366d9b538d871f65a8b721c3317"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(test_df['dropoff_longitude'])\nplt.xlabel(\"droppoff_longitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8346844701983bfa66f0a3120fcda862b3ed307"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(test_df['dropoff_latitude'])\nplt.xlabel(\"dropoff_latitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4478dc8563cda1e12c2def38d96832ffdedcce32"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(test_df['passenger_count'])\nplt.xlabel(\"passenger_count\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff782068596dee93a901489e3099449c3e41f781"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(test_df['fare_amount'])\nplt.xlabel(\"fare_amount\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6a70142576ce5fc5764667c9d04831a4c052bd8"},"cell_type":"markdown","source":"Calling the function to clean the outliers"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"# Only a fraction of the whole data\n\ntrain_df = clean(train_df)\ntest_df = clean(test_df)\n\nprint('Done with cleaning data')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50ad8ac5ab8977a06a4cb4cd48616ab34ac7a433"},"cell_type":"markdown","source":"Another group of scatter plots and histagram to display the data after cleanup"},{"metadata":{"trusted":true,"_uuid":"c088c8fc7d1530eff1b2f183e630eaaa2ef65f7f"},"cell_type":"code","source":"plot = train_df.plot.scatter('pickup_longitude', 'fare_amount')\nplot = train_df.plot.scatter('pickup_latitude', 'fare_amount')\nplot = train_df.plot.scatter('dropoff_longitude', 'fare_amount')\nplot = train_df.plot.scatter('dropoff_latitude', 'fare_amount')\nplot = train_df.plot.scatter('passenger_count', 'fare_amount')\nplot = train_df.plot.scatter('fare_amount', 'fare_amount')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6913e01b9ec1bbf0cad1605cbad1af0634c9ddeb"},"cell_type":"code","source":"plot = test_df.plot.scatter('pickup_longitude', 'fare_amount')\nplot = test_df.plot.scatter('pickup_latitude', 'fare_amount')\nplot = test_df.plot.scatter('dropoff_longitude', 'fare_amount')\nplot = test_df.plot.scatter('dropoff_latitude', 'fare_amount')\nplot = test_df.plot.scatter('passenger_count', 'fare_amount')\nplot = test_df.plot.scatter('fare_amount', 'fare_amount')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b67bd37654b42871befb5715d803543dec43efd"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['pickup_longitude'])\nplt.xlabel(\"pickup_longitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dde691e624665933d11dbfad6f179786ec7a3ae4"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['pickup_latitude'])\nplt.xlabel(\"pickup_latitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0121bd1823f61143044fa41ed2bb37659419b2e0"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['dropoff_longitude'])\nplt.xlabel(\"dropoff_longitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f06c704d9c8033baf5c7a7345e2352d0e08e9fcb"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['dropoff_latitude'])\nplt.xlabel(\"dropoff_latitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30f26fbac72225124a47232f830b05565c97124e"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['passenger_count'])\nplt.xlabel(\"passenger_count\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7dcdd55160fc31f347f78ea5f66cfb5b3892d591"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['fare_amount'])\nplt.xlabel(\"fare_amount\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e0688684f3ff34f6b9eb8f94bf1d1bfd89b6dcd"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(test_df['pickup_longitude'])\nplt.xlabel(\"pickup_longitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"768c14de0323a5c59e83734c988e79ed540e1468"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(test_df['pickup_latitude'])\nplt.xlabel(\"pickup_latitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8f4673b79e265a4ae943053c0194a1ba9cc8b38"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(test_df['dropoff_longitude'])\nplt.xlabel(\"droppoff_longitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97f678f318b83f14803b36ab1791865db63b8bfd"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(test_df['dropoff_latitude'])\nplt.xlabel(\"dropoff_latitude\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a77bbbdaed54726186dba62fcdc5953fdfdf05ab"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(test_df['passenger_count'])\nplt.xlabel(\"passenger_count\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b93113b62df8359c0b14ef62b189185392f5e2f"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(test_df['fare_amount'])\nplt.xlabel(\"fare_amount\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9683ad8b9dbf64e54d37c88898b856b25b89aac"},"cell_type":"markdown","source":"Adding time features such as Year, month, day, hour, minute and second"},{"metadata":{"trusted":true,"_uuid":"15582d9482f82559d05ebf7039253eec9c1318a9"},"cell_type":"code","source":"print('train_df add_time_features')\ntrain_df = add_time_features(train_df)\nprint('test_df add_time_features')\ntest_df = add_time_features(test_df)\nprint('testKaggle add_time_features')\ntestKaggle = add_time_features(testKaggle)\n\nprint('Done with add_time_features')\n  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"928a936a5ac40b6cc66483f54710aa0096a52cff"},"cell_type":"markdown","source":"Adding lat and long diff features"},{"metadata":{"trusted":true,"_uuid":"2c4de940f3721ea883266935c1ece04f09757cb5","scrolled":false},"cell_type":"code","source":"print('train_df add_coordinate_features')\nadd_coordinate_features(train_df)\nprint('test_df add_coordinate_features Disabled!')\nadd_coordinate_features(test_df)\nprint('testKaggle add_coordinate_features')\nadd_coordinate_features(testKaggle)\n\nprint('Done with add_coordinate_features')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a09de08cc39f1296b465e2eaa7aa9dbfd26afe11"},"cell_type":"markdown","source":"Adding distance features"},{"metadata":{"trusted":true,"_uuid":"80331ee180a7308865abc9904eae3d6a8e361488","scrolled":true},"cell_type":"code","source":"print('train_df add_distances_features')\ntrain_df = add_distances_features(train_df)\nprint('test_df add_distances_features')\ntest_df = add_distances_features(test_df)\nprint('testKaggle add_distances_features')\ntestKaggle = add_distances_features(testKaggle)\n\nprint('Done with add_distances_features')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0b3f994b0bf21592f7b0e77d1a22949da5aee87"},"cell_type":"code","source":"print('Done with Adding features')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8211d5a78b6fc0bb4c828443f02af55e32c7addc"},"cell_type":"markdown","source":"plot the new engineered features"},{"metadata":{"trusted":true,"_uuid":"cfc6bad7b3adfe7dff20bbbe437a6deedbbf9b28"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['manhattan'])\nplt.xlabel(\"manhattan\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"072cee54589ea01cbc27c92846830873f05c976a"},"cell_type":"code","source":"plot = train_df.plot.scatter('year', 'year')\nplot = train_df.plot.scatter('month', 'month')\nplot = train_df.plot.scatter('day', 'day')\nplot = train_df.plot.scatter('hour', 'hour')\nplot = train_df.plot.scatter('minute', 'minute')\nplot = train_df.plot.scatter('second', 'second')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf665a912b38eb60c75c4cc377a6f858f859c6dc"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(train_df['distance'])\nplt.xlabel(\"distance\")\n_ = plt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2dc5532395897af969c1f894acc2e26189933c0"},"cell_type":"markdown","source":"Drop extra columns from feature set"},{"metadata":{"trusted":true,"_uuid":"d7da49590533dcceb30ec71eb75176c5b09c4445","scrolled":true},"cell_type":"code","source":"\n# Drop unwanted columns\ndropped_columns = ['pickup_datetime']\n\ntrain_df = train_df.drop(dropped_columns, axis=1)\ntest_df = test_df.drop(dropped_columns, axis=1)\n\ntestKaggle_clean = testKaggle.drop(dropped_columns + ['key'], axis=1)\n\nprint('Done with dropped_columns')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3fd21f9c45b980f97fd8949d0bd3109a858d5496"},"cell_type":"markdown","source":"Data normalization"},{"metadata":{"trusted":true,"_uuid":"64a86450474d975fe6f9ae9d2b6c9143325ce947"},"cell_type":"code","source":"train_df_scaled = train_df\ntest_df_scaled = test_df\ntestKaggle_scaled = testKaggle_clean\n\nscaler = preprocessing.MinMaxScaler()\ntrain_df_scaled[['pickup_longitude']] = scaler.fit_transform(train_df[['pickup_longitude']])\ntest_df_scaled['pickup_longitude'] = scaler.transform(test_df[['pickup_longitude']])\ntestKaggle_scaled['pickup_longitude'] = scaler.transform(testKaggle_clean[['pickup_longitude']])\n\n\ntrain_df_scaled[['pickup_latitude']] = scaler.fit_transform(train_df[['pickup_latitude']])\ntest_df_scaled['pickup_latitude'] = scaler.transform(test_df[['pickup_latitude']])\ntestKaggle_scaled['pickup_latitude'] = scaler.transform(testKaggle_clean[['pickup_latitude']])\n\n\ntrain_df_scaled[['dropoff_latitude']] = scaler.fit_transform(train_df[['dropoff_latitude']])\ntest_df_scaled['dropoff_latitude'] = scaler.transform(test_df[['dropoff_latitude']])\ntestKaggle_scaled['dropoff_latitude'] = scaler.transform(testKaggle_clean[['dropoff_latitude']])\n\ntrain_df_scaled[['dropoff_longitude']] = scaler.fit_transform(train_df[['dropoff_longitude']])\ntest_df_scaled['dropoff_longitude'] = scaler.transform(test_df[['dropoff_longitude']])\ntestKaggle_scaled['dropoff_longitude'] = scaler.transform(testKaggle_clean[['dropoff_longitude']])\n\ntrain_df_scaled[['passenger_count']] = scaler.fit_transform(train_df[['passenger_count']])\ntest_df_scaled['passenger_count'] = scaler.transform(test_df[['passenger_count']])\ntestKaggle_scaled['passenger_count'] = scaler.transform(testKaggle_clean[['passenger_count']])\n\ntrain_df_scaled[['manhattan']] = scaler.fit_transform(train_df[['manhattan']])\ntest_df_scaled['manhattan'] = scaler.transform(test_df[['manhattan']])\ntestKaggle_scaled['manhattan'] = scaler.transform(testKaggle_clean[['manhattan']])\n\ntrain_df_scaled[['distance']] = scaler.fit_transform(train_df[['distance']])\ntest_df_scaled['distance'] = scaler.transform(test_df[['distance']])\ntestKaggle_scaled['distance'] = scaler.transform(testKaggle_clean[['distance']])\n\ntrain_df_scaled[['latdiff']] = scaler.fit_transform(train_df[['latdiff']])\ntest_df_scaled['latdiff'] = scaler.transform(test_df[['latdiff']])\ntestKaggle_scaled['latdiff'] = scaler.transform(testKaggle_clean[['latdiff']])\n\n\ntrain_df_scaled[['londiff']] = scaler.fit_transform(train_df[['londiff']])\ntest_df_scaled['londiff'] = scaler.transform(test_df[['londiff']])\ntestKaggle_scaled['londiff'] = scaler.transform(testKaggle_clean[['londiff']])\n\n\ntrain_df_scaled[['year']] = scaler.fit_transform(train_df[['year']])\ntest_df_scaled['year'] = scaler.transform(test_df[['year']])\ntestKaggle_scaled['year'] = scaler.transform(testKaggle_clean[['year']])\n\ntrain_df_scaled[['month']] = scaler.fit_transform(train_df[['month']])\ntest_df_scaled['month'] = scaler.transform(test_df[['month']])\ntestKaggle_scaled['month'] = scaler.transform(testKaggle_clean[['month']])\n\n\ntrain_df_scaled[['day']] = scaler.fit_transform(train_df[['day']])\ntest_df_scaled['day'] = scaler.transform(test_df[['day']])\ntestKaggle_scaled['day'] = scaler.transform(testKaggle_clean[['day']])\n\ntrain_df_scaled[['hour']] = scaler.fit_transform(train_df[['hour']])\ntest_df_scaled['hour'] = scaler.transform(test_df[['hour']])\ntestKaggle_scaled['hour'] = scaler.transform(testKaggle_clean[['hour']])\n\n\ntrain_df_scaled[['minute']] = scaler.fit_transform(train_df[['minute']])\ntest_df_scaled['minute'] = scaler.transform(test_df[['minute']])\ntestKaggle_scaled['minute'] = scaler.transform(testKaggle_clean[['minute']])\n\ntrain_df_scaled[['second']] = scaler.fit_transform(train_df[['second']])\ntest_df_scaled['second'] = scaler.transform(test_df[['second']])\ntestKaggle_scaled['second'] = scaler.transform(testKaggle_clean[['second']])\n\nprint('Done with data normalization')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f8878e60c46be38a6cdbedda6041c44c033a5ed"},"cell_type":"markdown","source":"Plot features after normalization"},{"metadata":{"trusted":true,"_uuid":"03112efd5915f7f2210dad00e128a2ce329b9b61"},"cell_type":"code","source":"plot = train_df.plot.scatter('pickup_longitude', 'pickup_longitude')\nplot = train_df.plot.scatter('pickup_latitude', 'pickup_latitude')\nplot = train_df.plot.scatter('dropoff_longitude', 'dropoff_longitude')\nplot = train_df.plot.scatter('dropoff_latitude', 'dropoff_latitude')\nplot = train_df.plot.scatter('passenger_count', 'passenger_count')\nplot = train_df.plot.scatter('year', 'year')\nplot = train_df.plot.scatter('month', 'month')\nplot = train_df.plot.scatter('day', 'day')\nplot = train_df.plot.scatter('hour', 'hour')\nplot = train_df.plot.scatter('minute', 'minute')\nplot = train_df.plot.scatter('second', 'second')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52c0f41bfbae43260746b69002c445e61eca2c00"},"cell_type":"markdown","source":"Split Training and Validation Data"},{"metadata":{"trusted":true,"_uuid":"180f40f4f5f142ba075414641c68257e92b4e811","scrolled":true},"cell_type":"code","source":"train_df_scaled, validation_df_scaled = train_test_split(train_df_scaled, test_size=0.10, random_state=1)\n\nprint('Done with splitiong data')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b0ca55198e130208fc08751000388671c7b9e37"},"cell_type":"markdown","source":"Create Label data set for training, validation and test datasets"},{"metadata":{"trusted":true,"_uuid":"beb28a02c07b9134e721e85145dd9c2f591cbdd1","scrolled":true},"cell_type":"code","source":"# Get labels\ntrain_labels = train_df_scaled['fare_amount'].values\nvalidation_labels = validation_df_scaled['fare_amount'].values\ntest_labels = test_df_scaled['fare_amount'].values\n\ntrain_df_scaled = train_df_scaled.drop(['fare_amount'], axis=1)\nvalidation_df_scaled = validation_df_scaled.drop(['fare_amount'], axis=1)\ntest_df_scaled = test_df_scaled.drop(['fare_amount'], axis=1)\n\nprint('Done with Labels')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"874ff00cbd099be37e026daf77a92808ef3575ed"},"cell_type":"markdown","source":"Building and fitting the model and saving the best model"},{"metadata":{"trusted":true,"_uuid":"11f45a8667d4e63b38bdd34ba9c4ad2c9fec3e61","scrolled":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(filepath='my_model.h5', verbose=1, save_best_only=True)\nmodel = Sequential()\nmodel.add(Dense(256, activation='linear', input_dim=train_df_scaled.shape[1], activity_regularizer=regularizers.l1(0.01)))\n#model.add(BatchNormalization())\nmodel.add(Dense(128, activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(Dense(64, activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(Dense(32, activation='relu'))\n#model.add(BatchNormalization())\n#model.add(Dense(16, activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(Dense(8, activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(Dense(1,activation='linear'))\n\nadam = optimizers.adam(lr=LEARNING_RATE)\nmodel.compile(loss='mean_squared_error', optimizer=adam, metrics=['mae', rmse, 'mse', mean_absolute_percentage_error])\n\nprint('Dataset size: %s' % DATASET_SIZE)\nprint('Epochs: %s' % EPOCHS)\nprint('Learning rate: %s' % LEARNING_RATE)\nprint('Batch size: %s' % BATCH_SIZE)\nprint('Input dimension: %s' % train_df_scaled.shape[1])\nprint('Features used: %s' % train_df_scaled.columns)\nmodel.summary()\n\nhistory = model.fit(x=train_df_scaled, y=train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, \n                    verbose=1, callbacks=[checkpoint], validation_data=(validation_df_scaled, validation_labels), \n                    shuffle=True)\n\t\t    \nprint('Done with Fit the model')    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5c05293554fa40f5a2a333a51ee040a344ce06a"},"cell_type":"markdown","source":"Creatong SVG diagram of the model"},{"metadata":{"trusted":true,"_uuid":"39220e9fa6003b1bdad8547f6841cb0604bfc607"},"cell_type":"code","source":"SVG(model_to_dot(model).create(prog='dot', format='svg'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de4efbf3def94f53b7f09b97f772c14bfee44f64"},"cell_type":"markdown","source":"plot  the loss and rmse diagram"},{"metadata":{"trusted":true,"_uuid":"cfcac2376ede0985e8d0ac26a428bf03193cc69c","scrolled":false},"cell_type":"code","source":"plot_loss_accuracy_rmse(history)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"207c0c5e998104da5e16e4d8ceb0a99505afa184"},"cell_type":"markdown","source":"Evaluate model on training set"},{"metadata":{"trusted":true,"_uuid":"95771130ea5ff73c2009f3ebf8087733bccaa549"},"cell_type":"code","source":"score = model.evaluate(train_df_scaled, train_labels, verbose=1)\nprint(score)\nprint('train mean_squared_error:', score[0])\nprint('train mae:', score[1])\nprint('train rmse:', score[2])\nprint('train mse:', score[3])\nprint('train msep:', score[4])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"779ce7ffe361ed23b7b4afc2f4ef1818f713dd8d"},"cell_type":"markdown","source":"Evaluate model on validation  set"},{"metadata":{"trusted":true,"_uuid":"f1683ec9e3f829bb257ea9eb6757420bb8351bcf","scrolled":false},"cell_type":"code","source":"score = model.evaluate(validation_df_scaled, validation_labels, verbose=1)\nprint(score)\nprint('Validation mean_squared_error:', score[0])\nprint('Validation mae:', score[1])\nprint('Validation rmse:', score[2])\nprint('Validation mse:', score[3])\nprint('Validation msep:', score[4])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7c37e0d85f4dd034641d5c0bddf4b1943e8895b"},"cell_type":"markdown","source":"Evaluate model on test set, this is how we know how good our model can predict on a set of data it never saw."},{"metadata":{"trusted":true,"_uuid":"372daf4f37d87d3c9b1941bbc6f98ceda28b442f","scrolled":false},"cell_type":"code","source":"score = model.evaluate(test_df_scaled, test_labels, verbose=1)\nprint(score)\nprint('Test mean_squared_error:', score[0])\nprint('Test mae:', score[1])\nprint('Test rmse:', score[2])\nprint('Test mse:', score[3])\nprint('Test msep:', score[4])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d50faa862565ad96faabc36313c318e945e1721"},"cell_type":"markdown","source":"    "},{"metadata":{"_uuid":"3dce89c9bd85f8a54670bfd68b36a253b224af51"},"cell_type":"markdown","source":"Here as well we jyust visualize the prediction on validation data"},{"metadata":{"trusted":true,"_uuid":"6cf5e141ae9fb8ce952554ede41dfd84c614b9d5","scrolled":false},"cell_type":"code","source":"validation_predictions = model.predict(validation_df_scaled).flatten()\n\nplt.scatter(validation_labels, validation_predictions)\nplt.xlabel('True Values')\nplt.ylabel('Predictions')\nplt.axis('equal')\nplt.xlim(plt.xlim())\nplt.ylim(plt.ylim())\n_ = plt.plot([validation_predictions.min(), validation_predictions.max()], [validation_predictions.min(), validation_predictions.max()], 'k--', lw=4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d6a7841aebf10dd881b2b0648b9f4109b6519fc"},"cell_type":"markdown","source":"Here as well we jyust visualize the prediction on test data"},{"metadata":{"trusted":true,"_uuid":"87b651cf8142d83ffaa46123aa1b0bad4a0621da"},"cell_type":"code","source":"test_predictions = model.predict(test_df_scaled).flatten()\n\nplt.scatter(test_labels, test_predictions)\nplt.xlabel('True Values')\nplt.ylabel('Predictions')\nplt.axis('equal')\nplt.xlim(plt.xlim())\nplt.ylim(plt.ylim())\n_ = plt.plot([test_predictions.min(), test_predictions.max()], [test_predictions.min(), test_predictions.max()], 'k--', lw=4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"761ee9d95f4e85c906701737ef7eb61ff591b538"},"cell_type":"markdown","source":"Spot checking Max and Min Prediction with actual value on test set"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6899e41c37c79f02f5ffc6a948d0c6850e859dce"},"cell_type":"code","source":"print('Index of max fare_amount:', np.argmax(test_predictions))\nprint('value of max fare_amount predicted:',test_predictions[np.argmax(test_predictions)])\nprint('value of max fare_amount actual:',test_labels[np.argmax(test_predictions)])\ntest_df.iloc[np.argmax(test_predictions)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46cba4980d89afbaf8b91bef4ce6a62eb0d50982"},"cell_type":"code","source":"print('Index of min fare_amount:',np.argmin(test_predictions))\nprint('value of min fare_amount predicted:',test_predictions[np.argmin(test_predictions)])\nprint('value of min fare_amount actual:',test_labels[np.argmin(test_predictions)])\ntest_df.iloc[np.argmin(test_predictions)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cee583dccaf843b05fad00fcef6a97a48285c701","scrolled":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(test_labels, test_predictions)\nax.plot([test_labels.min(), test_labels.max()], [test_labels.min(), test_labels.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d12344ef12e7af62392d6c0c2291e6a02a552413"},"cell_type":"markdown","source":"Comparing the actual fare_amount and predicted values"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"558c60c44a67db65d709cfe77dd137427363150c"},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.plot(validation_labels[:100])\nplt.plot(validation_predictions[:100])\nplt.title('Valdation Data Prediction vs Actual')\nplt.ylabel('Fare Amount')\nplt.xlabel('Transaction')\nplt.legend(['Actual', 'prediction'], loc='upper right')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8578781e1d586110ce7cb498b16f405eb9c7cfc","scrolled":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.plot(test_labels[:100])\nplt.plot(test_predictions[:100])\nplt.title('Test Data Prediction vs Actual')\nplt.ylabel('Fare Amount')\nplt.xlabel('Transaction')\nplt.legend(['Actual', 'prediction'], loc='upper right')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0121044cc8b911a023e069d3d7509395dda40c0d"},"cell_type":"code","source":"print(\"test actual mean:\" ,np.mean(test_labels))\nprint(\"test prediction mean:\" ,np.mean(test_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccedc9b87ff02bbc153ff5f3527db921894ff3fa"},"cell_type":"code","source":"print(\"test actual std:\" ,np.std(test_labels))\nprint(\"test prediction std:\" ,np.std(test_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1e51e0688d959a481f259729b25c153ad545a51","scrolled":false},"cell_type":"code","source":"predictionKaggle = model.predict(testKaggle_scaled, batch_size=128, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d6f8af471e96adfc387e3243817993086639025"},"cell_type":"code","source":"predictionKaggle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d48a2902d08e76fbc0e192c4f45990a7bf8d19f3","scrolled":false},"cell_type":"code","source":"# output prediction\n\noutput_submission(testKaggle, predictionKaggle, 'key', 'fare_amount', SUBMISSION_NAME)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"466caa229f0b098d05724ee8f246b570e7861e47"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}