{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":false,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":77,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"7022fc9ac19096f0d076d800949e92d13f4a5081"},"cell_type":"code","source":"seed = 7\nnp.random.seed(seed)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout","execution_count":78,"outputs":[]},{"metadata":{"_uuid":"c8abeb09ea636f4e5f325bd13d3c31aacd41eaa5"},"cell_type":"markdown","source":"Read csv file to DataFrame"},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"6064bb2de7178e459d5d0cbd4ab297cb83256b8e"},"cell_type":"code","source":"df = pd.read_csv('../input/creditcard.csv')\ndf.head()","execution_count":79,"outputs":[]},{"metadata":{"_uuid":"d2de4ba9afecf1771943bb25704274dd9b40c792"},"cell_type":"markdown","source":"Count each class, class = 1 (fraud detected) is very rare."},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"94b9e533012c17ebdf33c1bd6f155cf811da676c"},"cell_type":"code","source":"# make dataset more balance by randomly removing majority class\ndf_major = df[df['Class']==0]\ndf_minor = df[df['Class']==1]\nmajor_count, minor_count = df.Class.value_counts()\nprint(major_count)\nprint(minor_count)\nprint('ratio imbalance dataset:',major_count/minor_count)","execution_count":80,"outputs":[]},{"metadata":{"_uuid":"10fbec0c6b973ccabb20b16154526dde44f102f5"},"cell_type":"markdown","source":"It is highly imbalance data set. I need to rebalance the data set before train the system.\nFirst, I random split minor class to 80% train and 20% test."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"3063d8b6d94b6cdcaa5133e9816531736164bbc0"},"cell_type":"code","source":"# shuffle both major and minor classes\ndf_major = shuffle(df_major, random_state=42)\ndf_minor = shuffle(df_minor, random_state=42)\n\n# split minor class into train 80% and dev 20%\nperc = 0.8\nminor_data_train = int(perc*minor_count)\ndf_minor_train = df_minor[0:minor_data_train]\ndf_minor_dev = df_minor[minor_data_train:]","execution_count":81,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"1a39432204d9a7c97f58f4b2520af78c227b1b62"},"cell_type":"code","source":"# rebalance training set into the ratio\nratio_imb = 2.0\nmajor_data_train = int(ratio_imb*minor_data_train)\ndf_major_train = df_major[0:major_data_train]\ndf_major_dev = df_major[major_data_train:int(ratio_imb*major_data_train)]\ndf_major_test = df_major[int(ratio_imb*major_data_train):]","execution_count":86,"outputs":[]},{"metadata":{"_uuid":"f2ab0c55876e1e3050826c6b1bcd6879aa9bd8dd"},"cell_type":"markdown","source":"Now, the ratio is 2.0 for training set"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"9e030ded93234258f7875658ccf18f65087d227c"},"cell_type":"code","source":"major_c = df_major_train.Class.value_counts()\nminor_c = df_minor_train.Class.value_counts()\nprint('ratio imbalance dataset:',int(major_c)/int(minor_c))","execution_count":87,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"3a316bc0fd74758f3bc8c38177c37ead1b932e54"},"cell_type":"code","source":"# concat to make df_train, df_dev and df_test\ndf_train = pd.concat([df_major_train, df_minor_train], axis=0)\ndf_dev = pd.concat([df_major_dev, df_minor_dev], axis=0)\ndf_test = pd.concat([df_major_test, df_minor_dev], axis=0)\n# shuffle agian make sure they are not orderical\ndf_train = shuffle(df_train, random_state=42)\ndf_dev = shuffle(df_dev, random_state=42)\ndf_test = shuffle(df_test, random_state=42)","execution_count":88,"outputs":[]},{"metadata":{"_uuid":"b94d7e096c0528d098d8a1448457f33ca087ae61"},"cell_type":"markdown","source":"As all input is PCA, I do not drop any input features expect Time and Amount we do not use as features."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"e9041ab0d3b14254995d3ee8e83a3c9e48a60842"},"cell_type":"code","source":"feature_train = df_train.drop(['Time', 'Amount'], axis=1)\ntarget_train = df_train['Class']\nfeature_dev = df_dev.drop(['Time', 'Amount'], axis=1)\ntarget_dev = df_dev['Class']","execution_count":90,"outputs":[]},{"metadata":{"_uuid":"967e1b2e761f2f36480359df2871e9361be68997"},"cell_type":"markdown","source":"Normalize features by using standard method"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"b3bd6eb233d9facbb816af355081ae9c0225c744"},"cell_type":"code","source":"scalar = StandardScaler()\nscalar.fit(feature_train)\nX_train = scalar.transform(feature_train)\ny_train = target_train\nX_dev = scalar.transform(feature_dev)\ny_dev = target_dev","execution_count":91,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16ebdc70c21d972b71be903b8003dd0d9afc1d38"},"cell_type":"code","source":"X_train.shape","execution_count":92,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc351f1069ca4e81b90055d4f2ef18f35543e002"},"cell_type":"code","source":"y_train.shape","execution_count":93,"outputs":[]},{"metadata":{"_uuid":"30407a94cfe89d9eaf2b1ec1b6bcc4154df7b078"},"cell_type":"markdown","source":"I use Deep Learning with three layers NN and dropout for deruce overfitting"},{"metadata":{"trusted":true,"_uuid":"813b659abab92e6e820d6dcffbc40568bcb5608e"},"cell_type":"code","source":"# create model three layers\nmodel = Sequential()\nmodel.add(Dense(100, input_dim=29, kernel_initializer='uniform',  activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(100, kernel_initializer='uniform',  activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1,kernel_initializer='uniform', activation='sigmoid'))\n\n# compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# fit model\ntrain_history = model.fit(X_train, y_train, epochs=50, batch_size=128, verbose=0)\nplt.plot(train_history.history['acc'])","execution_count":94,"outputs":[]},{"metadata":{"_uuid":"15d119f1b3371ba935d0f7fd99fe3c7184417f32"},"cell_type":"markdown","source":"Look like overfit, so I test dev set"},{"metadata":{"trusted":true,"_uuid":"9b695536443fcccfd7c820b741a56183ee1c4dc4"},"cell_type":"code","source":"X_dev.shape","execution_count":95,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cad19d2cae5fb2ee04fa4891dd6317dbc45cac8a"},"cell_type":"code","source":"y_dev.shape","execution_count":96,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"93a56a8a5d7e7225bcd8c4e264e2e6a41f44cc19"},"cell_type":"code","source":"prediction = model.predict_classes(X_dev)\nprint(classification_report(y_dev, prediction))\nprint(confusion_matrix(y_dev, prediction))","execution_count":102,"outputs":[]},{"metadata":{"_uuid":"a40c5d7ad3ab15111acc4abac26ebf58ca3150f8"},"cell_type":"markdown","source":"It is a good prediction because there is no false fruad detection (class1 predict as 0)"},{"metadata":{"_uuid":"6ad526ba10627dc207a80db90acc587904c31071"},"cell_type":"markdown","source":"**Expand to use larger data set**"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"97777a8d6224bc3ea6314b123481ca292be85b77"},"cell_type":"code","source":"feature_test = df_test.drop(['Time', 'Amount'], axis=1)\ntarget_test = df_test['Class']\nX_test = scalar.transform(feature_test)\ny_test = target_test","execution_count":99,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"36efb3d00529506466232d9b1be00523d996f49c"},"cell_type":"code","source":"X_test.shape","execution_count":100,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86830fed67066fa108cd8adf36d2f68d79bd80c5"},"cell_type":"code","source":"y_test.shape","execution_count":101,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f56a46bdd9d51eaa62c1b613f897f53a801fe11"},"cell_type":"code","source":"prediction_test = model.predict_classes(X_test)\nprint(classification_report(y_test, prediction_test))\nprint(confusion_matrix(y_test, prediction_test))","execution_count":103,"outputs":[]},{"metadata":{"_uuid":"a3922105dbd3cc5d220969c7ca516eca079e2a2a"},"cell_type":"markdown","source":"Conclusion\n1. undersample is good strategy to handle imbalance dataset \n2. in this case can train small data set to apply to largar data set efficiently.\n3. good predictor because there is no false fraud detection.\n4. in test set has 99 transections from fruad credit card, the predictor can all detect\n5. the predictor detects transections that from normal credit card as fruad, it is OK (human can check them later)\n"},{"metadata":{"_uuid":"16b00324ffa39abfe1c4d896f02f20623462e169"},"cell_type":"markdown","source":"Thank You!"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"b9e99d720c1cbaa3f10c38f7d93a221b2663e51d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}