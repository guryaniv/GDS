{"cells": [{"metadata": {"_uuid": "81a342f3f618e5a5aa962da1f211d18432f28ea1", "_cell_guid": "6700f168-bbea-438e-be85-c9cf4a59aa00"}, "cell_type": "code", "source": ["import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from catboost import CatBoostRegressor\n", "from tqdm import tqdm\n", "import gc\n", "import datetime as dt\n", "\n", "print('Loading Properties ...')\n", "properties2016 = pd.read_csv('../input/properties_2016.csv', low_memory = False)\n", "properties2017 = pd.read_csv('../input/properties_2017.csv', low_memory = False)\n", "\n", "print('Loading Train ...')\n", "train2016 = pd.read_csv('../input/train_2016_v2.csv', parse_dates=['transactiondate'], low_memory=False)\n", "train2017 = pd.read_csv('../input/train_2017.csv', parse_dates=['transactiondate'], low_memory=False)\n", "\n", "def add_date_features(df):\n", "    df[\"transaction_year\"] = df[\"transactiondate\"].dt.year\n", "    df[\"transaction_month\"] = (df[\"transactiondate\"].dt.year - 2016)*12 + df[\"transactiondate\"].dt.month\n", "    df[\"transaction_day\"] = df[\"transactiondate\"].dt.day\n", "    df[\"transaction_quarter\"] = (df[\"transactiondate\"].dt.year - 2016)*4 +df[\"transactiondate\"].dt.quarter\n", "    df.drop([\"transactiondate\"], inplace=True, axis=1)\n", "    return df\n", "\n", "train2016 = add_date_features(train2016)\n", "train2017 = add_date_features(train2017)\n", "\n", "print('Loading Sample ...')\n", "sample_submission = pd.read_csv('../input/sample_submission.csv', low_memory = False)\n", "\n", "print('Merge Train with Properties ...')\n", "train2016 = pd.merge(train2016, properties2016, how = 'left', on = 'parcelid')\n", "train2017 = pd.merge(train2017, properties2017, how = 'left', on = 'parcelid')\n", "\n", "print('Tax Features 2017  ...')\n", "train2017.iloc[:, train2017.columns.str.startswith('tax')] = np.nan\n", "\n", "print('Concat Train 2016 & 2017 ...')\n", "train_df = pd.concat([train2016, train2017], axis = 0)\n", "test_df = pd.merge(sample_submission[['ParcelId']], properties2016.rename(columns = {'parcelid': 'ParcelId'}), how = 'left', on = 'ParcelId')\n", "\n", "del properties2016, properties2017, train2016, train2017\n", "gc.collect();\n", "\n", "print('Remove missing data fields ...')\n", "\n", "missing_perc_thresh = 0.98\n", "exclude_missing = []\n", "num_rows = train_df.shape[0]\n", "for c in train_df.columns:\n", "    num_missing = train_df[c].isnull().sum()\n", "    if num_missing == 0:\n", "        continue\n", "    missing_frac = num_missing / float(num_rows)\n", "    if missing_frac > missing_perc_thresh:\n", "        exclude_missing.append(c)\n", "print(\"We exclude: %s\" % len(exclude_missing))\n", "\n", "del num_rows, missing_perc_thresh\n", "gc.collect();\n", "\n", "print (\"Remove features with one unique value !!\")\n", "exclude_unique = []\n", "for c in train_df.columns:\n", "    num_uniques = len(train_df[c].unique())\n", "    if train_df[c].isnull().sum() != 0:\n", "        num_uniques -= 1\n", "    if num_uniques == 1:\n", "        exclude_unique.append(c)\n", "print(\"We exclude: %s\" % len(exclude_unique))\n", "\n", "print (\"Define training features !!\")\n", "exclude_other = ['parcelid', 'logerror','propertyzoningdesc']\n", "train_features = []\n", "for c in train_df.columns:\n", "    if c not in exclude_missing \\\n", "       and c not in exclude_other and c not in exclude_unique:\n", "        train_features.append(c)\n", "print(\"We use these for training: %s\" % len(train_features))\n", "\n", "print (\"Define categorial features !!\")\n", "cat_feature_inds = []\n", "cat_unique_thresh = 1000\n", "for i, c in enumerate(train_features):\n", "    num_uniques = len(train_df[c].unique())\n", "    if num_uniques < cat_unique_thresh \\\n", "       and not 'sqft' in c \\\n", "       and not 'cnt' in c \\\n", "       and not 'nbr' in c \\\n", "       and not 'number' in c:\n", "        cat_feature_inds.append(i)\n", "        \n", "print(\"Cat features are: %s\" % [train_features[ind] for ind in cat_feature_inds])\n", "\n", "print (\"Replacing NaN values by 0 !!\")\n", "train_df.fillna(0, inplace=True)\n", "test_df.fillna(0, inplace=True)\n", "\n", "\n", "print (\"remove outliers\")\n", "train_df=train_df[ train_df.logerror > -0.4 ]\n", "train_df=train_df[ train_df.logerror < 0.419 ]\n", "\n", "\n", "print (\"Training time !!\")\n", "X_train = train_df[train_features]\n", "y_train = train_df.logerror\n", "print(X_train.shape, y_train.shape)\n", "\n", "test_df['transactiondate'] = pd.Timestamp('2016-12-01') \n", "test_df = add_date_features(test_df)\n", "X_test = test_df[train_features]\n", "print(X_test.shape)\n", "\n", "num_ensembles = 5\n", "y_pred = 0.0\n", "for i in tqdm(range(num_ensembles)):\n", "    model = CatBoostRegressor(\n", "        iterations=630, learning_rate=0.03,\n", "        depth=6, l2_leaf_reg=3,\n", "        loss_function='MAE',\n", "        eval_metric='MAE',\n", "        random_seed=i)\n", "    model.fit(\n", "        X_train, y_train,\n", "        cat_features=cat_feature_inds)\n", "    y_pred += model.predict(X_test)\n", "y_pred /= num_ensembles\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "submission = pd.DataFrame({\n", "    'ParcelId': test_df['ParcelId'],\n", "})\n", "test_dates = {\n", "    '201610': pd.Timestamp('2016-10-01'),\n", "    '201611': pd.Timestamp('2016-11-01'),\n", "    '201612': pd.Timestamp('2016-12-01'),\n", "    '201710': pd.Timestamp('2017-10-01'),\n", "    '201711': pd.Timestamp('2017-11-01'),\n", "    '201712': pd.Timestamp('2017-12-02')\n", "}\n", "for label, test_date in test_dates.items():\n", "    print(\"Predicting for: %s ... \" % (label))\n", "    submission[label] = y_pred\n", "\n", "print( \"\\nCombined XGB/LGB/baseline/OLS predictions:\" )\n", "print( submission.head() )\n", "\n", "submission.to_csv('final_solution_0.csv', float_format='%.6f',index=False)"], "execution_count": null, "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "14061a2f-217d-4c87-85f6-b95f079f9226", "_uuid": "08edbdaedf1ee155eb22aa4d941a88988156fb17"}, "cell_type": "code", "source": [], "execution_count": null, "outputs": []}], "nbformat": 4, "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"mimetype": "text/x-python", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "version": "3.6.3", "file_extension": ".py", "nbconvert_exporter": "python"}}, "nbformat_minor": 1}