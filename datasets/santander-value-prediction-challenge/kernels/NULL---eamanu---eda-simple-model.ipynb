{"cells":[{"metadata":{"_uuid":"6f0c05f1bb148fa92845f78760350f2bf3678119"},"cell_type":"markdown","source":"# TOC TOC\n1. [Importing neccesary modules ](#importing-necessary-modules)\n2. [Loading data](#loading-data)\n3. [Exploring data](#exploring-data)\n    1. [Target](#target)\n    2. [Sparsity of the dataset](#sparsity-of-the-dataset)\n    3. [Zero variance and dupllicate date](#zero-variance-and-duplicate)\n4. [Dimensionality Reduction](#dimensionality-reduction)\n5. [Modeling](#modeling)\n    1. [OLS](#ols)"},{"metadata":{"_uuid":"f1c9b9cc57c31712c5ebe5e46913649da3f4219b"},"cell_type":"markdown","source":"# Importing necesary modules<a name=\"importing-neccesary-modules\"></a>\nIn this sections will import necessary modules for the kernel\n"},{"metadata":{"trusted":true,"_uuid":"02601e0c5f8afde7fbb7c207f510f33b4e867fca"},"cell_type":"code","source":"#%matplotlib inline\n\n# for seaborn issue:\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import linear_model\n\nprint(os.listdir(\"../input\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Loading data <a name=\"loading-data\"></a>\nIn this section we will load the data to use.  We just have 2 file, the train file and the test file (also the sample submission file).\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c57bed5b378e1a11757e73e24026848a42c2fff0"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e98d824defcfa8bd94e93eb05fb951a07f6f75b2"},"cell_type":"markdown","source":"# Exploring data <a name=\"exploring-data\"></a>\nI will start exploring the train data file. The only data. \n### Train\nLet's see the train data"},{"metadata":{"trusted":true,"_uuid":"835a6270aff5ab2c7cd9293c8b4d1ec9fded9007","collapsed":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3693147a4f34e08a21f8ec100c9d639953e08cef","collapsed":true},"cell_type":"code","source":"print(train.columns)\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b7b0804889165777d6077574b170818b5e8e93f"},"cell_type":"markdown","source":"Ok, the columns names are wired. Let's the more information about the data set."},{"metadata":{"trusted":true,"_uuid":"37a77e8b39ac50505744ea78f73b9b3137ba3ebb","collapsed":true},"cell_type":"code","source":"print(train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27570c8b997fd21a0613ac815393f047380da7b9","collapsed":true},"cell_type":"code","source":"# Null values?\nnulls_data = train.isnull().sum().sum()\nprint(\"There are {} null data on the dataset\".format(nulls_data))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42a97d9593d9292047bf2e9433fa4ab01b23bf75"},"cell_type":"markdown","source":"We see that the dataset have 4993 columns and 4459 entries. We don't have more information about the features, just that 1845 are float, 3147 are int and just 1 is string (the ID).  How we could explore this data if we don't know what relationship could are between columns?\n\n### Test \nLet's see the test data"},{"metadata":{"trusted":true,"_uuid":"012c4db4a2d0beb9aef1279efa42748a83d6160c","collapsed":true},"cell_type":"code","source":"test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4e890c9e3d46681a2ecb86c2fd80032778415cf","collapsed":true},"cell_type":"code","source":"print(test.columns)\nprint(test.shape)\nprint('test info:')\nprint(test.info())\n# Null values?\nnulls_data = test.isnull().sum().sum()\n\nprint(\"There are {} null data on the dataset\".format(nulls_data))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc45e5c75d81104589c48420afc3fe1e20b0e17e"},"cell_type":"markdown","source":"## Target <a name=\"target\"></a>"},{"metadata":{"trusted":true,"_uuid":"e9f3b7810337c8fe39540eff7a319d7bb7e9190e","collapsed":true},"cell_type":"code","source":"print(train.target.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b62289cd57011cb53801888abf06da386881da07","collapsed":true},"cell_type":"code","source":"train.target.plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"669b110b7177438f856c129f748d4276b5d731f5"},"cell_type":"markdown","source":"The target on train dataset is right-skewed"},{"metadata":{"trusted":true,"_uuid":"db265eb4bb0825b5d30235726e8c18c6426a0ab9","collapsed":true},"cell_type":"code","source":"target_log = np.log(train.target)\ntarget_subx = 1/train.target\ntarget_square = np.square(train.target)\nprint(target_log.skew())\n\nprint(target_square.skew())\ntarget_log.plot.hist()\ntrain.target = target_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8cc115c56b413c4067abf0e02f5ce740f61d0eeb","collapsed":true},"cell_type":"markdown","source":"## Sparsity of the dataset <a name=\"sparsity-of-the-dataset\"></a>\nVarious public kernels show that there are many zeros on the dataset. "},{"metadata":{"trusted":true,"_uuid":"c5c5ae0fd041cdb300b1389581131339500ffb7f","collapsed":true},"cell_type":"code","source":"columns = train.columns\nprint(len(train[train[columns[2]] == 0])/len(train[columns[2]]))\nprint(len(train[columns[2]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d129c36554fc8593540f33839e10b2f9fb7abad","collapsed":true},"cell_type":"code","source":"list_zeros = [len(train[train[d] == 0])/4459. for d in columns]\n# list_zeros = []\n#for d in columns:\n#    zeros = len(train[train[d] == 0])\n#    total = 4459.\n#    list_zeros.append(zeros/total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ebf82e2b509a6e051d1e681ad4461f10960e55b","collapsed":true},"cell_type":"code","source":"sns.distplot(list_zeros, bins=100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef34534bbe92031ce16284b410faac21118d06b0"},"cell_type":"markdown","source":"## Zero variance and duplicate features<a name=\"#zero-variance-and-duplicate\"></a>\nI will remove  the zero variance features and duplicated columns."},{"metadata":{"trusted":true,"_uuid":"2517a65463e47f600cd63176a3a8dadcdc30b674"},"cell_type":"code","source":"# df = df.loc[:, df.var() == 0.0]\n# obj_df = train.select_dtypes(include=['object'])\nobj_df = train.iloc[:, :2]\n# num_df = train.select_dtypes(exclude=['object'])\nnum_df = train.iloc[:,2:]\nvar = num_df.var()\nl_keys_notzeros = []\nl_values_notzeros = []\nfor k, v in var.items():\n    if v != 0.0:\n        l_keys_notzeros.append(k)\n        l_values_notzeros.append(v)\n# foo = num_df.loc[:, num_df.var() != 0.0]\nfoo = num_df[l_keys_notzeros]\nnew_train_without_zeros = pd.concat([obj_df, foo], axis=1) # new data without zero variance\nprint(new_train_without_zeros.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2cff65754ee1dad9ce7a8d19c665fff9923ffcc"},"cell_type":"code","source":"obj_df = test.iloc[:, :1]\nnum_df = test.iloc[:,1:]\nfoo = num_df[l_keys_notzeros]\nnew_test_without_zeros = pd.concat([obj_df, foo], axis=1) # new data without zero variance\nprint(new_test_without_zeros.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"94354d7b500fa56bf96e55e4b758779d3154cd14"},"cell_type":"code","source":"del obj_df\ndel num_df\ndel foo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a00b5e8eaa18bd111e22523836ece8b53c451d61"},"cell_type":"code","source":"# Remove duplicated columns\ncol_to_remove = list()\ncol_scanned = list()\ndup_list = dict()\n\ncols = new_train_without_zeros.columns\n\nfor i in range(len(cols) - 1):\n    v = new_train_without_zeros[cols[i]].values\n    dup_cols = list()\n    for j in range(i+1, len(cols)):\n        if np.array_equal(v, new_train_without_zeros[cols[j]].values):\n            col_to_remove.append(cols[j])\n            if cols[j] not in col_scanned:\n                dup_cols.append(cols[j]) \n                col_scanned.append(cols[j])\n                dup_list[cols[i]] = dup_cols\nprint(col_to_remove)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa9bb8d2380fb127a6cc2fee40254e5799451727","collapsed":true},"cell_type":"code","source":"cols = [c for c in cols if c not in col_to_remove]\ncols_test = [c for c in cols if c != 'target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5faec85788ca6fec60d8ce806a3589dbb3c2d45a","scrolled":true},"cell_type":"code","source":"new_train = new_train_without_zeros[cols]\nnew_test = new_test_without_zeros[cols_test]\n\nprint(new_train.shape)\nprint(new_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"46c0677ff5143f3d70ab3ad749827d742ef625e2","collapsed":true},"cell_type":"code","source":"del new_train_without_zeros\ndel new_test_without_zeros\ndel train\ndel test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7682ebe3f7ed9ce21e93a430f810d95beeffc8c9"},"cell_type":"code","source":"del col_to_remove\ndel col_scanned\ndel dup_list\ndel cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"edbba772d1f114a96c6019f5e3939984d10fc16f"},"cell_type":"markdown","source":"# Dimensionality Reduction <a name=\"dimensionality-reduction\"></a>\nI will try to reduce the dataset dimension"},{"metadata":{"trusted":true,"_uuid":"42d24dcb9a44e13241329a97719077c224d0eb01","collapsed":true},"cell_type":"code","source":"id_target_train = new_train.iloc[:,:2]\nnew_train = new_train.iloc[:,2:].values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"97c99cac2e6c888f8e59ae3afb5e14317bf24656"},"cell_type":"code","source":"id_test = new_test.iloc[:,:1]\nnew_test = new_test.iloc[:, 1:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d71226ecfee0f714b508087530fbe4d495c1081","scrolled":true},"cell_type":"code","source":"print('Shape of train: ',new_train.shape)\nprint('Shape of test: ', new_test.shape)\n#print('Shape of target: ',log_target.shape)\n#print('Shape of test: ',test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d449a0df99e80d0f30d8f76a2f56e00cbacfe5e5"},"cell_type":"code","source":"def transform (dataframe):\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(dataframe)\n    return pd.DataFrame(scaled_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"784b96f5ebf2914506b6decd9a2de9175d3a3eb1","collapsed":true},"cell_type":"code","source":"new_train = transform(new_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76329870ee06ccd198141fc0072d8ea7c9808636","collapsed":true},"cell_type":"code","source":"new_test = transform(new_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f39deac17f27e8000864e9adcfb8a80e40e74e62"},"cell_type":"code","source":"# num_data = ttrain.select_dtypes(exclude='object')\nnum_data = new_train\npca = PCA(copy=True, n_components=2000, whiten=False)\nnew = pca.fit(num_data).transform(num_data)\nprint(pca.explained_variance_ratio_) \nlen_pca = len(pca.explained_variance_ratio_)\nprint(\"The first {} PCA explain {}\".format(len_pca, pca.explained_variance_ratio_.sum()*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59ac3c7b2e8e6bf3d82b8758c13c3b8b0d17c39e"},"cell_type":"code","source":"# var=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=3)*100)\nvar = pca.explained_variance_ratio_.cumsum()\nplt.ylabel('% Variance Explained')\nplt.xlabel('# of Features')\nplt.title('PCA Analysis')\nplt.style.context('seaborn-whitegrid')\n\nplt.plot(var)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cb251f325fa3189cb0d6be9ecf045a34e9e9390"},"cell_type":"code","source":"pca_train = pd.DataFrame(data=new, columns=['pca{}'.format(i) for i in range(2000)])\npca_train = pd.concat([id_target_train[['ID','target']], pca_train], axis = 1)\nprint(pca_train.head(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de7dc5be4af23bd81265d754bbf17bd03dd72ef7"},"cell_type":"code","source":"num_data = new_test\nnew = pca.transform(num_data)\npca_test = pd.DataFrame(data=new, columns=['pca{}'.format(i) for i in range(2000)])\npca_test = pd.concat([id_test[['ID']], pca_test], axis=1)\nprint(pca_test.head(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"57dfc8fdc1cee25676c2101a6eec6b231581947b"},"cell_type":"markdown","source":"# Modeling <a name=\"modeling\"></a>\nNow, I think that we could start create some models\n\n## OLS <a name=\"ols\"></a>\nWe will start with a very simply model: _Ordinary Least Squares_"},{"metadata":{"trusted":true,"_uuid":"855128af0f5253b93ca1ddcd2ea6655f5b055d0d","collapsed":true},"cell_type":"code","source":"x_train = pca_train.iloc[:, 2:]\ny_train = pca_train.iloc[:, 1:2]\n\nx_test = pca_test.iloc[:, 1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec0d7252a61a8f81f8b4fa0f165336a852806b50"},"cell_type":"code","source":"linear_regression = linear_model.LinearRegression()\nlinear_regression.fit(x_train, y_train)\nprint(linear_regression.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e6a74ba8d4f901cf6f535c329ea247e64ea70598"},"cell_type":"code","source":"target_test  = linear_regression.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00144fb14c9930d3687653eca38fc3de88158996"},"cell_type":"code","source":"target_test = pd.DataFrame(data=target_test, columns=['target'])\nprint(target_test.head(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ef0af910efed0a7e21a3b4af0ff164a3d378cd6"},"cell_type":"code","source":"to_submit = pd.concat([pca_test['ID'], target_test['target']], axis=1)\nprint(to_submit.head(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f7a2e2e682a1cdea2227ee8c79ea7e0d627123de"},"cell_type":"code","source":"to_submit.to_csv('ols.csv', columns=['ID','target'], index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}