{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#importing standard libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n#Importing Keras so that I can apply CNN\nimport keras\nfrom keras import optimizers\nfrom keras import backend as K\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten\nfrom keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D \nfrom keras.utils import plot_model\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.callbacks import EarlyStopping\n\n#importing libraries for data processing\nfrom tqdm import tqdm\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer \nimport os, re, csv, math, codecs\n\nsns.set_style(\"whitegrid\")\nnp.random.seed(0)\n#Setting path for kaggle data.\nDATA_PATH = '../input/'\nEMBEDDING_DIR = '../input/'\n\nMAX_NB_WORDS = 100000\ntokenizer = RegexpTokenizer(r'\\w+')\nstop_words = set(stopwords.words('english'))\nstop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bd0e0ab9-d1be-4ccf-bd0c-6c969c6822c8","_uuid":"823cb33a6a43567f55118a6f1fb0cb23e1174bd1","trusted":true},"cell_type":"code","source":"#load embeddings\nembeddings_index = {}\n#Have downloaded fastext pretrained embeddings. So loading it here\nf = codecs.open('../input/fasttext2/wiki.simple.vec', encoding='utf-8')\nprint(f)\nfor line in tqdm(f):\n    values = line.rstrip().rsplit(' ')\n    word = values[0]\n    #print(word)\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e78217f4-251a-43d5-8faa-aa6283442f68","collapsed":true,"_uuid":"f8a6d417efe2c7336459ab78a03df42526119ebc","trusted":true},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"f6944c97cbaf39e3faf4ba30dba09874cba3124c"},"cell_type":"code","source":"max(train_df['doc_len'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"528e3f80a7d4bf86616d062fd1b3c584b9998dec"},"cell_type":"code","source":"processed_docs_train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7846d14e09e2f435bcb29610e77d9b3699e7a18"},"cell_type":"code","source":"raw_docs_train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7790ff9a80a5c371390fd914591dcf6fa3cc297f"},"cell_type":"code","source":"tokenizer_train","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c677df59-6026-4737-98da-6617547fcb02","_uuid":"82e147279b37950e3e89bdaba2228c7789b33b2d","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge' + '/train.csv', sep=',', header=0)\nlabel_names = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n    # separate explanatory and dependent variables\ny = train_df[label_names].values\n    \nraw_docs_train = train_df['comment_text'].tolist()\n    # split for cross-validation (train-60%, validation 20% and test 20%)\n\n\nnum_classes = len(label_names)\n\nprint(num_classes)\n\nprocessed_docs_train = []\nfor doc in tqdm(raw_docs_train):\n    tokens = tokenizer.tokenize(doc)\n    filtered = [word for word in tokens if word not in stop_words]\n    processed_docs_train.append(\" \".join(filtered))\n        \n        \n#Tokenizing data.\n\ntokenizer_train = Tokenizer(num_words=MAX_NB_WORDS, lower=True, char_level=False)\ntokenizer_train.fit_on_texts(processed_docs_train)  #leaky\n\nprint(type(tokenizer_train))\n\nword_seq_train = tokenizer_train.texts_to_sequences(processed_docs_train)\nword_index = tokenizer_train.word_index\nprint(\"dictionary size: \", len(word_index))\n\ntrain_df['doc_len'] = train_df['comment_text'].apply(lambda words: len(words.split(\" \")))\nmax_seq_len = np.round(train_df['doc_len'].mean() + train_df['doc_len'].std()).astype(int)\n\n    #So here we are padding the sequnce so that I will work ML algorithms because\n    #it should have same length\nword_seq_train = sequence.pad_sequences(word_seq_train, maxlen=max_seq_len)\n\nX_train, X_test, y_train, y_test = train_test_split(word_seq_train, y, test_size=0.4, random_state=123)\n\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c72de7777080646457cacbb8e802ce9051f179a2"},"cell_type":"code","source":"word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"675b2f85301b218311c13608ef70c14f3eedcce0"},"cell_type":"code","source":"word_seq_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26d5cfecd36bdc20bc5cdfd5a493159dea9aab81"},"cell_type":"code","source":"nb_words","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a9be2de8-b4d7-4629-80b3-d1453619b316","_uuid":"fa90765b71533e92a2fb4daf50b3afcab441d1b3","trusted":true},"cell_type":"code","source":"#training params\nbatch_size = 256 \nnum_epochs = 20 \n\n#model parameters\nnum_filters = 64 \nembed_dim = 300 \nweight_decay = 1e-4","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e9d40ad8-95ab-4763-89fc-a5d9c28850cb","_uuid":"021ed88e6328ea70adc416a5943a3550772b96db","trusted":true},"cell_type":"code","source":"#embedding matrix\nwords_not_found = []\nnb_words = min(MAX_NB_WORDS, len(word_index))\nembedding_matrix = np.zeros((nb_words, embed_dim))\nfor word, i in word_index.items():\n    if i >= nb_words:\n        continue\n    embedding_vector = embeddings_index.get(word)\n    if (embedding_vector is not None) and len(embedding_vector) > 0:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix[i] = embedding_vector\n    else:\n        words_not_found.append(word)\nprint('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"428340f0-78fb-4644-b7fa-e861009a688f","_uuid":"3a2e6106f18c874033ed4d44e4d58faab5bcc8b9","trusted":true},"cell_type":"code","source":"print(\"Words not found in the embedding: \", np.random.choice(words_not_found, 50))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a0c46fbf73cccd2ffafc6c01a120913626bceee"},"cell_type":"code","source":"len(word_seq_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c4d868e7fd36186ddd693904cdf30ae09f65a61"},"cell_type":"code","source":"len(words_not_found)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55fa8299124989eccad8ad7cd833af7678b46562"},"cell_type":"code","source":"max_seq_len","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f9a0c109-ee6f-4316-862a-332f62b54c8c","_uuid":"e74cf2b1c79b22b998ba355f0b98051006cae4ba","trusted":true},"cell_type":"code","source":"#CNN model training\nmodel = Sequential()\nmodel.add(Embedding(nb_words, embed_dim,\n          weights=[embedding_matrix], input_length=max_seq_len, trainable=False))\nmodel.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\nmodel.add(MaxPooling1D(2))\nmodel.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Dense(num_classes, activation='sigmoid'))  #multi-label (k-hot encoding)\n\nadam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\nmodel.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ae11805c-8607-4f51-9166-2dca0160e10f","_uuid":"37a158641ade6b5bbbde2936fd6e3469edd71982","trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\ncallbacks_list = [early_stopping]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6336593f-d20f-4b50-971a-185fa444a289","_uuid":"eb08862ba67db8e76b0e5fb69db5da406238e321","trusted":true},"cell_type":"code","source":"#sending the data to CNN to train the model\n#hist = model.fit(word_seq_train, y_train, batch_size=batch_size, epochs=num_epochs, callbacks=callbacks_list, validation_split=0.1, shuffle=True, verbose=2)\nhist = model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, callbacks=callbacks_list, validation_data = (X_val,y_val), shuffle=True, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7462ff86-6f7d-460c-a7a5-686ec47768a6","_uuid":"8c0dc93bad0c09180ac3536a8c07dac6a3f37008","trusted":true},"cell_type":"code","source":"\n# Predict on train, val and test datasets\npred_train = model.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ec3cf98c-9480-4fc6-9f27-82169ef2bf52","_uuid":"f86796a5b5da56b9bd597bbde422ba12d8a21582","trusted":true},"cell_type":"code","source":"pred_test = model.predict(X_test)\npred_val = model.predict(X_val)\n\nAUC = np.zeros((3,6))\nAUC","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c4dea901-74df-4d37-ad13-858f2175d0c8","_uuid":"aef9b91e8460ab306c7db44131da13b9786a2962","trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfor i,x in enumerate(label_names):\n    auc = np.array([metrics.roc_auc_score(y_train[:,i], pred_train[:,i]),\n                    metrics.roc_auc_score(y_val[:,i], pred_val[:,i]),\n                    metrics.roc_auc_score(y_test[:,i], pred_test[:,i])])\n    print(x,\"Train AUC:\",auc[0],\", Val AUC:\",auc[1],\", Test AUC:\",auc[2])\n    AUC[:,i] = auc\n    \navg_auc = AUC.mean(axis=1)\nprint(\"Average Train AUC:\",avg_auc[0],\", Average Val AUC:\",avg_auc[1],\", Average Test AUC:\",avg_auc[2])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2133bb35-6bde-42c7-afef-8315ec85709a","_uuid":"16493dea4e9efc5d42aa7055075e2e6a68cb4c83","trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(hist.history['acc'], lw=2.0, color='b', label='train')\nplt.plot(hist.history['val_acc'], lw=2.0, color='r', label='val')\nplt.title('CNN sentiment')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8f9e5f90-2e3d-4ab5-89d8-3b4028fe6c6a","collapsed":true,"_uuid":"12ef31a9c00f108610d6bc790a1b02e3a978675f","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8b8b99a9-e600-4f6f-a5fd-a1ba2daf200b","collapsed":true,"_uuid":"2104931f5bcf6106fc3f7116a4cd0c53c7075570","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f2f2687c-4d1f-4555-881c-8c86d4ab3eea","collapsed":true,"_uuid":"3c344e63141533de38107f242e85ee1727fb04f7","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}