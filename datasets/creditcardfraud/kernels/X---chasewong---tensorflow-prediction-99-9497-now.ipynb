{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8509666d-6c09-69b0-d458-f56c75ceb608"
      },
      "source": [
        "Predict precision equal to 99.947%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "428edbb6-1493-620e-26db-39bce4fd5178"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "def one_hot_encoding(array):\n",
        "    length=len(array)\n",
        "    mirror=[]\n",
        "    for i in range(length):\n",
        "        if array[i]==1:\n",
        "            mirror.append(0)\n",
        "        else:\n",
        "            mirror.append(1)\n",
        "    result=np.column_stack((array,np.array(mirror)))\n",
        "    return result\n",
        "        \n",
        "\n",
        "def import_data():\n",
        "    #raw=pd.read_csv('c:\\Users\\lenove\\Desktop\\datafile\\creditcard.csv')\n",
        "    #raw=pd.read_csv('C:\\\\Users\\\\lenove\\\\Desktop\\\\datafile\\\\creditcard.csv')\n",
        "    raw=pd.read_csv('/usr/local/creditcard/creditcard.csv')\n",
        "    raw['Amount'] = StandardScaler().fit_transform(raw['Amount'].reshape(-1, 1))\n",
        "    raw = raw.drop(['Time'],axis=1)\n",
        "    data_is_one=raw[raw['Class']==1].values\n",
        "    data_is_zero=raw[raw['Class']==0].values\n",
        "    trainX_len_one=math.floor(data_is_one.shape[0]*0.7)\n",
        "    trainX_len_zero=math.floor(data_is_zero.shape[0]*0.7)\n",
        "    train_one=data_is_one[:trainX_len_one]\n",
        "    train_zero=data_is_zero[:trainX_len_zero]\n",
        "    #train_zero=train_zero[:50]\n",
        "    train=np.concatenate((train_one,train_zero),axis=0)\n",
        "    np.random.shuffle(train)\n",
        "    trainX=train[:,:-1]\n",
        "    trainY=train[:,-1]\n",
        "    trainY=one_hot_encoding(trainY)\n",
        "    test_one=data_is_one[trainX_len_one:]\n",
        "    test_zero=data_is_zero[trainX_len_zero:]\n",
        "    test=np.concatenate((test_one,test_zero),axis=0)\n",
        "    np.random.shuffle(test)\n",
        "    testX=test[:,:-1]\n",
        "    testY=test[:,-1]\n",
        "    testY=one_hot_encoding(testY)\n",
        "    return trainX,trainY,testX,testY\n",
        "\n",
        "trainX,trainY,testX,testY=import_data()\n",
        "\n",
        "def next_batch(num, data1,data2):\n",
        "    idx = np.arange(0, len(data1))  \n",
        "    np.random.shuffle(idx)  \n",
        "    idx = idx[0:num]  \n",
        "    data_shuffle_x = [data1[i] for i in idx]\n",
        "    data_shuffle_y=[data2[i] for i in idx]\n",
        "    data_shuffle_x = np.asarray(data_shuffle_x)  \n",
        "    data_shuffle_y = np.asarray(data_shuffle_y)\n",
        "\n",
        "    return data_shuffle_x,data_shuffle_y\n",
        "\n",
        "\n",
        "feature_num=trainX.shape[1]\n",
        "labels=2\n",
        "\n",
        "steps=100000\n",
        "\n",
        "learningrate=tf.train.exponential_decay(learning_rate=0.001,\n",
        "                                        global_step=1,\n",
        "                                        decay_steps=trainX.shape[0],\n",
        "                                        decay_rate=0.95,\n",
        "                                        staircase=True)\n",
        "\n",
        "X=tf.placeholder(tf.float32,shape=[None,feature_num])\n",
        "Y=tf.placeholder(tf.float32,shape=[None,labels])\n",
        "\n",
        "Weights=tf.Variable(tf.random_normal([feature_num,150],\n",
        "                                     mean=0,stddev=0.1),name='weight')\n",
        "bias=tf.Variable(tf.random_normal([1,150],\n",
        "                                  mean=0,stddev=0.1),name='bias')\n",
        "\n",
        "wmux=tf.matmul(X,Weights)\n",
        "wmux_plus_b=tf.add(wmux,bias)\n",
        "layer1=tf.nn.relu(wmux_plus_b)\n",
        "\n",
        "\n",
        "def add_layer_relu(x,input_size,output_size):\n",
        "    Weights=tf.Variable(tf.random_normal([input_size,output_size],\n",
        "                                     mean=0,stddev=0.1))\n",
        "    bias=tf.Variable(tf.random_normal([1,output_size],\n",
        "                                  mean=0,stddev=0.1))\n",
        "    wmux=tf.matmul(x,Weights)\n",
        "    wmux_plus_b=tf.add(wmux,bias)\n",
        "    activation=tf.nn.relu(wmux_plus_b)\n",
        "    return activation\n",
        "\n",
        "def add_layer_tanh(x,input_size,output_size):\n",
        "    Weights=tf.Variable(tf.random_normal([input_size,output_size],\n",
        "                                     mean=0,stddev=0.1))\n",
        "    bias=tf.Variable(tf.random_normal([1,output_size],\n",
        "                                  mean=0,stddev=0.1))\n",
        "    wmux=tf.matmul(x,Weights)\n",
        "    wmux_plus_b=tf.add(wmux,bias)\n",
        "    activation=tf.nn.tanh(wmux_plus_b)\n",
        "    return activation\n",
        "\n",
        "def add_layer_softmax(x,input_size,output_size):\n",
        "    Weights=tf.Variable(tf.random_normal([input_size,output_size],\n",
        "                                     mean=0,stddev=0.1))\n",
        "    bias=tf.Variable(tf.random_normal([1,output_size],\n",
        "                                  mean=0,stddev=0.1))\n",
        "    wmux=tf.matmul(x,Weights)\n",
        "    wmux_plus_b=tf.add(wmux,bias)\n",
        "    activation=tf.nn.softmax(wmux_plus_b)\n",
        "    return activation\n",
        "\n",
        "layer2=add_layer_relu(layer1,150,60)\n",
        "layer3=add_layer_relu(layer2,60,30)\n",
        "activation=add_layer_relu(layer3,30,2)\n",
        "\n",
        "\n",
        "\n",
        "cost=tf.nn.l2_loss(activation-Y,name=\"squared_error_cost\")\n",
        "train=tf.train.AdamOptimizer(learningrate).minimize(cost)\n",
        "\n",
        "sess=tf.Session()\n",
        "init=tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "correct_prediction_op=tf.equal(tf.argmax(activation,1),tf.argmax(Y,1))\n",
        "acc_op=tf.reduce_mean(tf.cast(correct_prediction_op,'float'))\n",
        "cost_value=0\n",
        "diff=1\n",
        "train_acc=0\n",
        "for i in range(steps):\n",
        "    if train_acc>1:\n",
        "        print('diff convergence',diff)\n",
        "        break\n",
        "    else:\n",
        "        batch_x,batch_y=next_batch(5000,trainX,trainY)\n",
        "        #batch_y=batch_y.reshape(batch_y.shape[0],1)\n",
        "        #trainY=trainY.reshape(trainY.shape[0],1)\n",
        "        step=sess.run(train,feed_dict={X:batch_x,Y:batch_y})\n",
        "    if i%10 is 0:\n",
        "        train_acc,newcost=sess.run([acc_op,cost],feed_dict={X:batch_x,Y:batch_y})\n",
        "        diff=abs(newcost-cost_value)\n",
        "        test_acc=sess.run(acc_op,feed_dict={X:testX,Y:testY})\n",
        "        cost_value=newcost\n",
        "        print('step',i,'train_acc',train_acc,'cost',newcost,'test acc',test_acc)\n",
        "testY=testY.reshape(testY.shape[0],1)    \n",
        "\n",
        "test_acc=sess.run(acc_op,feed_dict={X:testX,Y:testY})\n",
        "\n",
        "print('test_acc',test_acc)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}