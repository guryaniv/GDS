{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "21bc65ff-f0c3-d24b-850b-3414d02730c3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "43eaed92-ecbb-3715-7fd4-5db729432ad9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "\n",
        "rng = np.random.RandomState(100)\n",
        "\n",
        "datum = pd.read_csv(\"../input/creditcard.csv\")\n",
        "print(\"Data Shape is \",datum.shape)\n",
        "data = datum.values\n",
        "msec = int(data[:,0].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "669ea5f9-400e-3d03-75c9-95ae26d6d553"
      },
      "source": [
        "Isolation Forest classifier seems to have memory limitation problems and so the data \n",
        "was split into day 1 and day2.  A lot of features were removed after visual observation, \n",
        "unfortunately reproducing the graphics took too much time and resources (a whole day \n",
        "despite each feature being split into 4 parts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45b378e5-75a1-9f12-49c0-112eddbf6534"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTotal listed seconds dataset is \", msec)\n",
        "print(\"The total seconds in a day is 24 * 3600 = 86,400\")\n",
        "print(\"The data set will be split into day 1 and 2 due to classifier memory limitations\")\n",
        "\n",
        "d1 = np.where(data[:,0] == 86400); d2 = int(d1[0]); d3 = len(data)\n",
        "print(\"Day 1 ends at index \",d2,\"dataset is at index\",d3)\n",
        "data1 = data[0:d2]; data2 = data[d2:d3]\n",
        "\n",
        "x2 = ([1, 6, 8, 13, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
        "xy = x2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "12a53359-547f-fbbf-8ff5-18175c511910"
      },
      "source": [
        "The data was then split into legitimate transactions and fraudulent transactions so that the forecasts can be measured separately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f08e1c5e-c725-7bfb-807b-62b5464399ed"
      },
      "outputs": [],
      "source": [
        "m1 = np.where(data1[:,30] == 0)\n",
        "norm1 = data1[m1];\n",
        "norm1 = np.delete(norm1,30,1)\n",
        "norm1 = np.delete(norm1,xy,1)\n",
        "y1 = norm1.shape[0]\n",
        "norm1a = np.ones((y1,1), dtype = np.float16)\n",
        "\n",
        "m2 = np.where(data2[:,30] == 0)\n",
        "norm2 = data2[m2];\n",
        "norm2 = np.delete(norm2,30,1)\n",
        "norm2 = np.delete(norm2,xy,1)\n",
        "y2 = norm2.shape[0]\n",
        "norm2a = np.ones((y2,1), dtype = np.float16)\n",
        "\n",
        "n1 = np.where(data1[:,30] == 1)\n",
        "out1 = data1[n1];\n",
        "out1 = np.delete(out1,30,1)\n",
        "out1 = np.delete(out1,xy,1)\n",
        "y1 = out1.shape[0]\n",
        "out1a = np.ones((y1,1), dtype = np.float16)#set outliers output to 1 (not(0)\n",
        "out1a = -1 * out1a#reset outliers output to -1\n",
        "\n",
        "n2 = np.where(data2[:,30] == 1)\n",
        "out2 = data2[n2];\n",
        "out2 = np.delete(out2,30,1)\n",
        "out2 = np.delete(out2,xy,1)\n",
        "y2 = out2.shape[0]\n",
        "out2a = np.ones((y2,1), dtype = np.float16)#set outliers output to 1 (not(0)\n",
        "out2a = -1 * out2a#reset outliers output to -1\n",
        "\n",
        "data1 = np.delete(data1,30,1); data1 = np.delete(data1,xy,1)\n",
        "data2 = np.delete(data2,30,1); data2 = np.delete(data2,xy,1)\n",
        "\n",
        "print(\"\\nDay 1 transactions - Legitimate Transactions - Fraudulent Transactions\")\n",
        "print(data1.shape, norm1a.shape, out1a.shape)\n",
        "print(\"Day 2 transactions - Legitimate Transactions - Fraudulent Transactions\")\n",
        "print(data2.shape, norm2a.shape, out2a.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "441b7d36-8d5a-6e40-193f-fd5ae7a12b48"
      },
      "source": [
        "Initial runs that produced very good fraudulent forecasts (approximately 95%) but also produced a high percentage of legitimate transcations being classed as fraudulent (approximately 50%).  I have chosen to pursue a more pragmatic approach in terms of balancing a good predictor of fraudulent transactions and a manageable misclassification of legitimate transactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c015f48d-86c8-2b67-190f-9846e5d06e0d"
      },
      "outputs": [],
      "source": [
        "ct = 0.11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e4fe01ec-61f4-3d12-ff04-89501f23ac26"
      },
      "source": [
        "The contamination setting of 0.11 produces good performances of approximately 90% of fraudulent \n",
        "transaction being predicted but 90% of legitimate transaction are classified correctly leaving \n",
        "10% of transactions  being classified as fraudulent which is quite high, considering the \n",
        "volumes of credit card transactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b32e0c84-8d20-fb5b-b261-3c973e47d890"
      },
      "outputs": [],
      "source": [
        "print(\"\\nRunning Isolation Classifier with \", ct,\"contamination\")\n",
        "clf = IsolationForest(max_samples=120000,  contamination= ct, random_state=rng)\n",
        "\n",
        "clf.fit(data1)#2\n",
        "nm1 = clf.predict(norm1); ot1 = clf.predict(out1)\n",
        "nm1a = nm1[nm1 == -1].size; ot1a = ot1[ot1 == 1].size\n",
        "\n",
        "clf.fit(data2)#2\n",
        "nm2 = clf.predict(norm2); ot2 = clf.predict(out2)\n",
        "nm2a = nm2[nm2 == -1].size; ot2a = ot2[ot2 == 1].size\n",
        "\n",
        "\n",
        "print(\"\\nDay 1 data\")\n",
        "print(\"Legitimate transactions - Fraudulent Transactions\")\n",
        "print(len(norm1), len(out1))\n",
        "print(\"Legitimate transactions classed as fraudulent - \",nm1a)\n",
        "print(\"Fraudulent transcations classed as legitimate \", ot1a)\n",
        "print('\\nLegitimate transactions accuracy is ',accuracy_score(nm1,norm1a))\n",
        "print('Fraudulent transactions (Outliers) accuracy is ',accuracy_score(ot1,out1a))\n",
        "\n",
        "print(\"\\nDay 2 data\")\n",
        "print(\"Legitimate transactions - Fraudulent Transactions\")\n",
        "print(len(norm2), len(out2))\n",
        "print(\"Legitimate transactions classed as fraudulent - \",nm2a)\n",
        "print(\"Fraudulent transcations classed as legitimate \", ot2a)\n",
        "print('\\nLegitimate transactions accuracy is ',accuracy_score(nm2,norm2a))\n",
        "print('Fraudulent transactions (Outliers) accuracy is ',accuracy_score(ot2,out2a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "577714bc-082d-73bf-0ad7-60fe07a5481f"
      },
      "outputs": [],
      "source": [
        "ct = 0.011"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8f7c53c7-f769-50e3-002a-aba290f02abe"
      },
      "source": [
        "The contamination setting of 0.011 produces good performances of approximately 80% of fraudulent \n",
        "transaction being predicted but 99% of legitimate transaction are classified correctly leaving \n",
        "1% of transactions  being classified as fraudulent which is not that bad, considering the \n",
        "volumes of credit card transactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "519973cf-db56-0de2-784c-824d96313e12"
      },
      "outputs": [],
      "source": [
        "print(\"\\nRunning Isolation Classifier with \", ct,\"contamination\")\n",
        "clf = IsolationForest(max_samples=120000,  contamination= ct, random_state=rng)\n",
        "\n",
        "clf.fit(data1)#2\n",
        "nm1 = clf.predict(norm1); ot1 = clf.predict(out1)\n",
        "nm1a = nm1[nm1 == -1].size; ot1a = ot1[ot1 == 1].size\n",
        "\n",
        "clf.fit(data2)#2\n",
        "nm2 = clf.predict(norm2); ot2 = clf.predict(out2)\n",
        "nm2a = nm2[nm2 == -1].size; ot2a = ot2[ot2 == 1].size\n",
        "\n",
        "print(\"\\nDay 1 data\")\n",
        "print(\"Legitimate transactions - Fraudulent Transactions\")\n",
        "print(len(norm1), len(out1))\n",
        "print(\"Legitimate transactions classed as fraudulent - \",nm1a)\n",
        "print(\"Fraudulent transcations classed as legitimate \", ot1a)\n",
        "print('Legitimate transactions accuracy is ',accuracy_score(nm1,norm1a))\n",
        "print('Fraudulent transactions (Outliers) accuracy is ',accuracy_score(ot1,out1a))\n",
        "\n",
        "print(\"\\nDay 2 data\")\n",
        "print(\"Legitimate transactions - Fraudulent Transactions\")\n",
        "print(len(norm2), len(out2))\n",
        "print(\"Legitimate transactions classed as fraudulent - \",nm2a)\n",
        "print(\"Fraudulent transcations classed as legitimate \", ot2a)\n",
        "print('Legitimate transactions accuracy is ',accuracy_score(nm2,norm2a))\n",
        "print('Fraudulent transactions (Outliers) accuracy is ',accuracy_score(ot2,out2a))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "539aa278-5639-a2f3-9e25-3a5e089eef8a"
      },
      "source": [
        "Using Random Forest, a good fraud predictor was obtained without a high proportion of misclassed legitimate transactions.  The entire dataset is used this time, 75% for training and 25% for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "66543ca4-557e-c4ea-f7d5-e76025ff471f"
      },
      "outputs": [],
      "source": [
        "print(\"\\nRandom Forest \")\n",
        "ln = 0.75\n",
        "ln1 = int(ln * len(data))\n",
        "dattn = data[:ln1]\n",
        "dattt = data[ln1:]\n",
        "\n",
        "trainip = dattn[:,:-1]; trainop = dattn[:,-1]\n",
        "testip = dattt[:,:-1]; testop = dattt[:,-1]\n",
        "\n",
        "x1 = ([1, 6, 8, 13, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
        "\n",
        "trainip = np.delete(trainip,x1,1)\n",
        "testip = np.delete(testip,x1,1)\n",
        "print(\"\\nInitial dataset \", data.shape)\n",
        "print(\"Features indices removed are \", x1)\n",
        "print(\"Training set shape + Output, Test set shape + output\")\n",
        "print(trainip.shape, trainop.shape, testip.shape, testop.shape)\n",
        "\n",
        "rf = RandomForestClassifier(max_features=10, max_depth=10,\n",
        "                            min_samples_split=4,n_estimators=200) # initialize\n",
        "\n",
        "#Locate the indices of test set that is non-fraud\n",
        "x = np.where(testop[:] == 0)\n",
        "iner = testip[x]\n",
        "iner1 = np.zeros((len(iner),1), dtype = np.float16)\n",
        "#print(len(x), len(iner), len(iner1))\n",
        "\n",
        "#Locate the indices of test set that is fraudulent\n",
        "x = np.where(testop[:] == 1)\n",
        "outer = testip[x]\n",
        "outer1 = np.ones((len(outer),1), dtype = np.float16)\n",
        "\n",
        "\n",
        "rf.fit(trainip, trainop)#2\n",
        "answ = rf.predict(testip)\n",
        "print('Test set Accuracy is ',accuracy_score(testop,answ))\n",
        "\n",
        "answn = rf.predict(iner)\n",
        "print(\"\\nTest set legitimate transactions is \", len(iner),\"Accuracy is \",accuracy_score(iner1,answn))\n",
        "\n",
        "answo = rf.predict(outer)\n",
        "print(\"Test set fraudulent transactions (outliers) is \", len(outer),\"Accuracy is \",accuracy_score(outer1,answo))\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}