{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n#following the tutorial from https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction \n# to get a better understanding of kaggle and how to use different frameworks/languages \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# sklearn preprocessing for dealing with categorical variables\nfrom sklearn.preprocessing import LabelEncoder\n\n# File system manangement\nimport os\n\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')\n\n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a3124e9fc21b1ab2ee976c2d68c043010bbafc3"},"cell_type":"code","source":"app_train = pd.read_csv('../input/application_train.csv')\nprint('Training data shape: ', app_train.shape)\napp_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"app_test = pd.read_csv('../input/application_test.csv')\nprint('Testing data shape: ', app_test.shape)\napp_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0615c5868c12f4ed263da5be8fd2ef38e308cae7"},"cell_type":"code","source":"app_train['TARGET'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d359afffb8d699394c59f226b3e88d40909e3a9"},"cell_type":"code","source":"app_train['TARGET'].astype(int).plot.hist();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"286463bcaf6048d330bc18d6e4df21839b88ffe5"},"cell_type":"code","source":"def missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"054f5f94a02bf03327c439c948fad86038502933"},"cell_type":"code","source":"# Missing values statistics\nmissing_values = missing_values_table(app_train)\nmissing_values.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4275ff4b9ae995d0329c42bf8ae588c6df68439"},"cell_type":"code","source":"app_train.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e33b7ed1a62796f6f5fe1ebc65f47f61cdcd1afb"},"cell_type":"code","source":"app_train.select_dtypes('object').apply(pd.Series.nunique, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"782d5b5597ebdf7d14d04540853c5993b10eb914"},"cell_type":"code","source":"le = LabelEncoder()\nle_count = 0\n\n# Iterate through the columns\nfor col in app_train:\n    if app_train[col].dtype == 'object':\n        # If 2 or fewer unique categories\n        if len(list(app_train[col].unique())) <= 2:\n            # Train on the training data\n            le.fit(app_train[col])\n            # Transform both training and testing data\n            app_train[col] = le.transform(app_train[col])\n            app_test[col] = le.transform(app_test[col])\n            \n            # Keep track of how many columns were label encoded\n            le_count += 1\n            \nprint('%d columns were label encoded.' % le_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f4f9299ceae9206097b2eb4c2bf9652853cce246"},"cell_type":"code","source":"# one-hot encoding of categorical variables\napp_train = pd.get_dummies(app_train)\napp_test = pd.get_dummies(app_test)\n\nprint('Training Features shape: ', app_train.shape)\nprint('Testing Features shape: ', app_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a40ed0533a57547de6d57219489a12e82dc8bfba"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acf10c6af6a66b5b6f42eac13a2a7adcab186612"},"cell_type":"code","source":"train_labels = app_train['TARGET']\n\n# Align the training and testing data, keep only columns present in both dataframes\napp_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n\n# Add the target back in\napp_train['TARGET'] = train_labels\n\nprint('Training Features shape: ', app_train.shape)\nprint('Testing Features shape: ', app_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1b58582132cb96af81ebcd4721cde54b66911dd"},"cell_type":"code","source":"(app_train['DAYS_BIRTH'] / -365).describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3e505c114614ee60fc878ec0b83247936b389a7"},"cell_type":"code","source":"(app_train['DAYS_BIRTH']).describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b70e96db64abf2ada04fde320bcdd6f26ca8410"},"cell_type":"code","source":"(app_train['DAYS_EMPLOYED']/ 365).describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60bde8c21ae8b40b9355714a46a1717b562719e1"},"cell_type":"code","source":"anom = app_train[app_train['DAYS_EMPLOYED'] == 365243]\nnon_anom = app_train[app_train['DAYS_EMPLOYED'] != 365243]\nprint('The non-anomalies default on %0.2f%% of loans' % (100 * non_anom['TARGET'].mean()))\nprint('The anomalies default on %0.2f%% of loans' % (100 * anom['TARGET'].mean()))\nprint('There are %d anomalous days of employment' % len(anom))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"039b8a9c4dfa5d809ec57fe6e55dd56c641f69ff","scrolled":true},"cell_type":"code","source":"app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n\n# Replace the anomalous values with nan\napp_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n\napp_train['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram');\nplt.xlabel('Days Employment');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0679166f522f00275e7542dbec3254d0a8eec0f8"},"cell_type":"code","source":"(app_train[\"DAYS_EMPLOYED\"] == 365243).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ecdc06cfc0b087383835cbc4781e77f8c73c1cc","scrolled":true},"cell_type":"code","source":"app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\napp_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\n\nprint('There are %d anomalies in the test data out of %d entries' % (app_test[\"DAYS_EMPLOYED_ANOM\"].sum(), len(app_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e77bf63fab4f8bc7e91a7e12acadc5e1875b136f"},"cell_type":"code","source":"correlations = app_train.corr()['TARGET'].sort_values()\n\n# Display correlations\nprint('Most Positive Correlations:\\n', correlations.tail(15))\nprint('\\nMost Negative Correlations:\\n', correlations.head(15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0f1c29bdafe750f0f53453aaeeaff2293203fa1"},"cell_type":"code","source":"app_train['DAYS_BIRTH'] = abs(app_train['DAYS_BIRTH'])\napp_train['DAYS_BIRTH'].corr(app_train['TARGET'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4efe7dcaf327f15f01535d2be6be682f63f4e2cd"},"cell_type":"code","source":"# Set the style of plots\nplt.style.use('fivethirtyeight')\n\n# Plot the distribution of ages in years\nplt.hist(app_train['DAYS_BIRTH'] / 365, edgecolor = 'green', bins = 25)\nplt.title('Age of Client'); plt.xlabel('Age (years)'); plt.ylabel('Count');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a54e8dff688fa2cb7114df82b1bd6fc04ab343d"},"cell_type":"code","source":"plt.figure(figsize = (10, 8))\n\n# KDE plot of loans that were repaid on time\nsns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365, label = 'target == 0')\n\n# KDE plot of loans which were not repaid on time\nsns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365, label = 'target == 1')\n\n# Labeling of plot\nplt.xlabel('Age (years)'); plt.ylabel('Density'); plt.title('Distribution of Ages');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8aa95a4d7bcb118025ddcf72838b4cb1755a54c9"},"cell_type":"code","source":"age_data = app_train[['TARGET', 'DAYS_BIRTH']]\nage_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / 365\n\n# Bin the age data\nage_data['YEARS_BINNED'] = pd.cut(age_data['YEARS_BIRTH'], bins = np.linspace(20, 70, num = 11))\nprint(age_data['YEARS_BINNED'])\nage_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d4a4a5866eebfc07617456cc7bb5fb936c664a8"},"cell_type":"code","source":"age_groups = age_data.groupby(\"YEARS_BINNED\").mean()\nage_groups","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"916e284199f8dd2e73fba3d597b7cf8759a4c0d7"},"cell_type":"code","source":"\nplt.figure(figsize = (8, 8))\n\n# Graph the age bins and the average of the target as a bar plot\nplt.bar(age_groups.index.astype(str), 100 * age_groups['TARGET'])\n\n# Plot labeling\nplt.xticks(rotation = 75); \nplt.xlabel('Age Group (years)'); \nplt.ylabel('Failure to Repay (%)')\nplt.title('Failure to Repay by Age Group')\n\n#the bar graph shows a clear trend between age and failure to repay;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bd9207b1235c4dd78f16350defec9dfd85fa1f7"},"cell_type":"code","source":"#looking at our correlations from before we see EXT1, EXT2, and EXT3 have highest negative correlations\n\next_data = app_train[['TARGET', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\next_data\next_data_corrs = ext_data.corr()\next_data_corrs\n\n#gives correlation with each other","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c99a574afa1d9ec1541af8b90233d3bda76f561e"},"cell_type":"code","source":"plt.figure(figsize = (8, 6))\n\n# Heatmap of correlations\nsns.heatmap(ext_data_corrs, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\nplt.title('Correlation Heatmap');\n#all negatively correlated with the target as EXT_Source value increases more likely to repay the loan\n#does days birth have something to do with the EXT_SOURCE1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53bb2de1ade5a2818a710a4df1d522e399ab6e23","scrolled":true},"cell_type":"code","source":"plt.figure(figsize = (10, 12))\n\n# iterate through the sources\nfor i, source in enumerate(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']):\n    \n    print(\"enumerated \", i, \" \", source)\n    # create a new subplot for each source\n    plt.subplot(3, 1, i + 1)\n    # plot repaid loans\n    sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, source], label = 'target == 0')\n    # plot loans that were not repaid\n    sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, source], label = 'target == 1')\n    \n    # Label the plots\n    plt.title('Distribution of %s by Target Value' % source)\n    plt.xlabel('%s' % source); plt.ylabel('Density');\n    \nplt.tight_layout(h_pad = 2.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a057ddb603cc7e4a9c455498dd9636a6e45c00e"},"cell_type":"code","source":"# Copy the data for plotting\nplot_data = ext_data.drop(columns = ['DAYS_BIRTH']).copy()\n\n# Add in the age of the client in years\nplot_data['YEARS_BIRTH'] = age_data['YEARS_BIRTH']\n\n# Drop na values and limit to first 100000 rows\nplot_data = plot_data.dropna().loc[:100000, :]\n\n# Function to calculate correlation coefficient between two columns\ndef corr_func(x, y, **kwargs):\n    r = np.corrcoef(x, y)[0][1]\n    ax = plt.gca()\n    ax.annotate(\"r = {:.2f}\".format(r),\n                xy=(.2, .8), xycoords=ax.transAxes,\n                size = 20)\n    \n# Create the pairgrid object\ngrid = sns.PairGrid(data = plot_data, size = 3, diag_sharey=False,\n                    hue = 'TARGET', \n                    vars = [x for x in list(plot_data.columns) if x != 'TARGET'])\n\n# Upper is a scatter plot\ngrid.map_upper(plt.scatter, alpha = 0.2)\n\n# Diagonal is a histogram\ngrid.map_diag(sns.kdeplot)\n\n# Bottom is density plot\ngrid.map_lower(sns.kdeplot, cmap = plt.cm.OrRd_r);\n\nplt.suptitle('Ext Source and Age Features Pairs Plot', size = 32, y = 1.05);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc57fa3d57181246343780eb914f062da4f1efb1"},"cell_type":"code","source":"#Logisitic Regression Implementation\n\nfrom sklearn.preprocessing import MinMaxScaler, Imputer\n\n# Drop the target from the training data\nif 'TARGET' in app_train:\n    train = app_train.drop(columns = ['TARGET'])\nelse:\n    train = app_train.copy()\n    \n# Feature names\nfeatures = list(train.columns)\n\n# Copy of the testing data\ntest = app_test.copy()\n\n# Median imputation of missing values\nimputer = Imputer(strategy = 'median')\n\n# Scale each feature to 0-1\nscaler = MinMaxScaler(feature_range = (0, 1))\n\n# Fit on the training data\nimputer.fit(train)\n\n# Transform both training and testing data\ntrain = imputer.transform(train)\ntest = imputer.transform(app_test)\n\n# Repeat with the scaler\nscaler.fit(train)\ntrain = scaler.transform(train)\ntest = scaler.transform(test)\n\nprint('Training data shape: ', train.shape)\nprint('Testing data shape: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f869f0323bb68cbe1995bac5ad86b30f4bbe65a"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Make the model with the specified regularization parameter\nlog_reg = LogisticRegression(C = 0.0001)\n\n# Train on the training data\nlog_reg.fit(train, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46c426400de40b05151712b0e02b5f0d9bc86fc4"},"cell_type":"code","source":"log_reg_pred = log_reg.predict_proba(test)[:, 1]\n\nsubmit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = log_reg_pred\n\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bfeb406581c342e0fa9dad84ab2df13927235711"},"cell_type":"code","source":"submit.to_csv('log_reg_baseline.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d78191cb57acb0a49f3d5d62222b9ddb2effeb18"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"59a50866910272d77fc478a01e828b535e66712e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fc5310eea647468ed96079e3d598374e2b20d59d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"258112e37843811e474a7d34a9753c5b0f551ab8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"667ed333c51e2f7c98c464744ffb9ccd72b3dc23"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"34dc28d7a998d43e837352ae7185a5da2bff1357"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1d61e63a109b25e46b55f0180b4a20d0dd530df2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9674105c3bdff60b715b596ac2de017314e27c98"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9b9a240e7751ac65243a7156f8355806a1b8fdf9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"55ada72afecb8bbfae0f6cf0d923bf588972ed28"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"46fc0c596a7c77b4e49faee55f2f85c111810aab"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"919a9e7ef1fe948794e904105d6d6e5645f207f3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e292aad78e51dc79c22f6e2840fd528c59b31381"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}