{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0755d776-05d4-18fa-503e-28da63bf4b46"
      },
      "source": [
        "# Lets Explore the Zillow Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9061c36d-96bd-f355-4217-77f2e3fa7d0b"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c25d80a3-1896-155b-565c-fc72a1af1dfc"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca3cc796-7a7e-f261-f27c-dfc5c045862d"
      },
      "outputs": [],
      "source": [
        "# Import Data\n",
        "train = pd.read_csv('../input/train_2016.csv', index_col='parcelid')\n",
        "properties = pd.read_csv('../input/properties_2016.csv', index_col='parcelid', low_memory=False)\n",
        "#data_dictionary = pd.read_excel('../data/zillow_data_dictionary.xlsx')\n",
        "sample_submission = pd.read_csv('../input/sample_submission.csv', index_col='ParcelId')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e8610307-d00d-2cd7-677c-24161c887ed0"
      },
      "outputs": [],
      "source": [
        "# Join train and details\n",
        "joined_train = train.join(properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "149a413b-9b70-6550-827a-0ea505bbff83"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "629e5e7b-23f9-f707-39ec-166c261654fa"
      },
      "outputs": [],
      "source": [
        "train['logerror'].hist(figsize = [10,5], bins = 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1064232c-b04c-9677-8e45-2ddb200fe6c3"
      },
      "outputs": [],
      "source": [
        "# Data Shapes\n",
        "print(sample_submission.shape)\n",
        "print(properties.shape)\n",
        "print(train.shape)\n",
        "print(joined_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "62f7a3cb-7e27-51bf-5f18-2913bf3c9f11"
      },
      "outputs": [],
      "source": [
        "joined_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "81595672-de1f-ecbc-3f8c-88798acf4124"
      },
      "source": [
        "# Make First Baseline Submission\n",
        "Find the average `logerror` and create a submission doucment with everything as the mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2de94bde-14b7-b03a-d56d-65018638d17e"
      },
      "outputs": [],
      "source": [
        "avg_error = train.mean()\n",
        "avg_error = avg_error[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3e04a7b6-3dda-c7ed-8387-ea8676e6298e"
      },
      "outputs": [],
      "source": [
        "# Replace with average error\n",
        "baseline_preds = sample_submission\n",
        "\n",
        "sample_submission = sample_submission.replace(to_replace=0, value=avg_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "80ec334c-6c2b-8f0b-5352-b05d9f799318"
      },
      "outputs": [],
      "source": [
        "# sample_submission.to_csv('../submissions/baseline_submission_052717.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a850bd5f-11d6-ff1f-e332-3d34c476fe5c"
      },
      "source": [
        "# Analize the Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a1f3d9d3-1834-fdb4-a869-756918d46f53"
      },
      "outputs": [],
      "source": [
        "# Describe the data\n",
        "joined_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4adc70d2-87d1-172d-9046-cb10973337f4"
      },
      "outputs": [],
      "source": [
        "var_counts = pd.DataFrame(joined_train.count(), columns=['Count'])\n",
        "var_counts.loc[var_counts['Count'] > 80000].sort_values(by=['Count'], ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6fe503d9-2b0d-1376-7db2-8b1de83c628f"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "104705a3-b27e-6526-e5fa-a83d6a0ba96d"
      },
      "outputs": [],
      "source": [
        "main_features = ['roomcnt','bedroomcnt','bathroomcnt',\n",
        "                 'fips','landtaxvaluedollarcnt','taxvaluedollarcnt',\n",
        "                 'taxamount','regionidzip','yearbuilt','finishedsquarefeet12','lotsizesquarefeet']\n",
        "output_vars = ['transactiondate','logerror']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dcb0d794-dde9-8bbd-d24d-b5888c7f24e6"
      },
      "outputs": [],
      "source": [
        "df = joined_train.loc[:,main_features+output_vars]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "febb7d29-7a7e-2aae-f2d8-77b07c384cba"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0aedf199-0e5f-8898-8b74-1a053a852574"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df.loc[:,['roomcnt','bedroomcnt','bathroomcnt','yearbuilt','logerror','fips']].dropna(),\n",
        "            hue='fips')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9c916b60-e020-21dd-0d5c-2dc1abace220"
      },
      "source": [
        "# Test submission mean of each FIPS number (county)\n",
        "From the scatterplot above it looks like the logerrors are clumped by FIPS. Maybe because some counties have difference in variability? I don't think this will help my score, but I'm going to try and split up by fips and find the average value of the log error for each and use that for my second baseline submittal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "534b23c1-877b-fdc2-1b9c-476b0bf2b9ca"
      },
      "outputs": [],
      "source": [
        "properties['fips'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6d9bfe57-9dcf-6cbc-8e27-8555aafcb5af"
      },
      "outputs": [],
      "source": [
        "fips_means = df.groupby('fips', as_index=False)['logerror'].mean()\n",
        "fips_means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e1a1a998-e361-cde7-ee26-88b795de0c66"
      },
      "outputs": [],
      "source": [
        "properties.groupby('fips', as_index=False).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "441936f9-1fcc-d629-92bb-bb18b70554fe"
      },
      "outputs": [],
      "source": [
        "# fips_means['logerror'].loc(:,[fips_means['fips'] == 6037.0])\n",
        "fips_means.loc[fips_means['fips'] == 6037.0, 'logerror'].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "68eb9ca9-132d-da8a-3f0d-ad1a63d4465e"
      },
      "outputs": [],
      "source": [
        "def fips_mean (row):    \n",
        "    '''Function that goes through each fips code and assigns to the average\n",
        "    logerror for that fips. If a NaN fips code then it returns the average of \n",
        "    all properties'''\n",
        "    if row['fips'] == 6037 :\n",
        "        return fips_means.loc[fips_means['fips'] == 6037.0, 'logerror'].iloc[0]\n",
        "    if row['fips'] == 6059 :\n",
        "        return fips_means.loc[fips_means['fips'] == 6059.0, 'logerror'].iloc[0]\n",
        "    if row['fips'] == 6111 :\n",
        "        return fips_means.loc[fips_means['fips'] == 6111.0, 'logerror'].iloc[0]\n",
        "    else:\n",
        "        return avg_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c21c1808-c9ac-65aa-488a-5c9a9a0910b3"
      },
      "outputs": [],
      "source": [
        "### THIS TAKES A LONG TIME ##\n",
        "# Creat a guess erorr vector which is just the average of each fips\n",
        "#guess_error = properties.apply (lambda row: fips_mean (row),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c7d3e736-5d28-fb93-64ee-d829187307dc"
      },
      "outputs": [],
      "source": [
        "#guess_error.shape\n",
        "#sample_submission['201610']=guess_error\n",
        "#sample_submission['201611']=guess_error\n",
        "#sample_submission['201612']=guess_error\n",
        "#sample_submission['201710']=guess_error\n",
        "#sample_submission['201711']=guess_error\n",
        "#sample_submission['201712']=guess_error\n",
        "#sample_submission.to_csv('../submissions/baseline_submission_fipsaverages_052817.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da6f55a7-b785-1f62-4bd9-abaecf928ac6"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}