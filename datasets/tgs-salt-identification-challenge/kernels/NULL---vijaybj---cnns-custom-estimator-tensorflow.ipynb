{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nimport tensorflow as tf\nimport random\nimport math\nimport warnings\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib.ticker as ticker\n\nfrom tqdm import tqdm\nfrom itertools import chain\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Set some parameters\nIMG_SIZE = 101\n\nIMG_CHANNELS = 3\n\npath_train = '../input/train'\n\npath_test = '../input/test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1eb5c4c38bbf7aa92066b12d748929e95c61115"},"cell_type":"code","source":"train_ids = next(os.walk(path_train + \"/images\"))[2]\ntest_ids = next(os.walk(path_test + \"/images\"))[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2ccb4283c3b6cd54d7d543d63b8e84e2748f3af"},"cell_type":"code","source":"# Get and resize train images and masks\ntrain_images = np.zeros((len(train_ids), IMG_SIZE, IMG_SIZE, IMG_CHANNELS), dtype=np.float32)\ntrain_labels = np.zeros((len(train_ids), IMG_SIZE, IMG_SIZE, 1), dtype=np.bool)\n\ntest_images = np.zeros((len(test_ids), IMG_SIZE, IMG_SIZE, IMG_CHANNELS), dtype=np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27f6a1ff20cd206c46377ff5367fa2010f502ad5"},"cell_type":"code","source":"print('Getting and resizing train images and masks without padding ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    img = imread(path_train + \"/images/\" + id_)[:,:,:IMG_CHANNELS]\n    train_images[n] = img\n    \n    mask = imread(path_train + \"/masks/\" + id_)\n    mask = np.expand_dims(mask, axis = -1)\n\n    train_labels[n] = mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2d281428e94818ea61a968d355285b32756b568"},"cell_type":"code","source":"for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    img = imread(path_test + \"/images/\" + id_)[:,:,:IMG_CHANNELS]\n    test_images[n] = img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3026d150c2ae836371c0265c3f945d683e23cea1"},"cell_type":"code","source":"def deconv2d(input_tensor, filter_size, output_size, out_channels, in_channels, name, strides = [1, 1, 1, 1]):\n    dyn_input_shape = tf.shape(input_tensor)\n    batch_size = dyn_input_shape[0]\n    out_shape = tf.stack([batch_size, output_size, output_size, out_channels])\n    filter_shape = [filter_size, filter_size, out_channels, in_channels]\n    w = tf.get_variable(name=name, shape=filter_shape)\n    return tf.nn.conv2d_transpose(input_tensor, w, out_shape, strides, padding='VALID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8bd8afee355b444414bc50213b10eb1f7572dcb"},"cell_type":"code","source":"def conv2d(input_tensor, depth, kernel, name, strides=(1, 1), padding=\"VALID\"):\n    return tf.layers.conv2d(input_tensor, filters=depth, kernel_size=kernel, strides=strides, padding=padding, activation=None, name=name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"911f6cdf65aba02d32a133aa2e94e429c50c779c"},"cell_type":"code","source":"def cnn_model_fn(features, labels, mode):\n    \n    \"\"\"CNN with five conv layers, and six transpose conv layers.\"\"\"\n    net = conv2d(features, 32, 1, \"Y0\") #101\n    net = tf.nn.relu(net)\n\n    net = conv2d(net, 40, 3, \"Y1\", strides=(2, 2)) #50\n    net = tf.nn.relu(net)\n\n    net = conv2d(net, 48, 2, \"Y2\", strides=(2, 2)) #25\n    net = tf.nn.relu(net)\n\n    net = conv2d(net, 64, 3, \"Y3\", strides=(2, 2)) #12\n    net = tf.nn.relu(net)\n\n    net = conv2d(net, 64, 2, \"Y4\") #11\n    net = tf.nn.relu(net)\n\n\n    net = deconv2d(net, 1, 11, 64, 64, \"Y5_deconv\") #11\n    net = tf.nn.relu(net)\n\n    net = deconv2d(net, 2, 12, 64, 64, \"Y4_deconv\") #12\n    net = tf.nn.relu(net)\n\n    net = deconv2d(net, 3, 25, 48, 64, \"Y3_deconv\", strides=[1, 2, 2, 1]) #25\n    net = tf.nn.relu(net)\n\n    net = deconv2d(net, 2, 50, 40, 48, \"Y2_deconv\", strides=[1, 2, 2, 1]) #50\n    net = tf.nn.relu(net)\n\n    net = deconv2d(net, 3, 101, 32, 40, \"Y1_deconv\", strides=[1, 2, 2, 1]) #101\n\n    logits = deconv2d(net, 1, 101, 1, 32, \"Y0_deconv\") #101\n\n    \n    predictions = {\n        'logits': logits\n    }\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n    \n    # Calculate Loss (for both TRAIN and EVAL modes)\n    loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=labels, logits=logits)\n\n    # Configure the Training Op (for TRAIN mode)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.0005)\n        train_op = optimizer.minimize(\n            loss=loss,\n            global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ddf2d287b8cd7190228ec1a0fab7ca7f3708375"},"cell_type":"code","source":"# Create the Estimator\ncnn_classifier = tf.estimator.Estimator(\n    model_fn=cnn_model_fn, model_dir=\"/tmp/convnet_40_0005_model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a151ad81cae21992e50d7e3b803862de55e492a"},"cell_type":"code","source":"# Train the model\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x=train_images,\n    y=train_labels,\n    batch_size=40,\n    num_epochs=None,\n    shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df9ca0b830fb561a6ed6e42260c4e2d008fca05f"},"cell_type":"code","source":"cnn_classifier.train(\n    input_fn=train_input_fn,\n    steps=15000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbcf4c0e16dcad81bbaf42e22266f27a54ee03f3"},"cell_type":"code","source":"# Predict input fuction\npred_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x=test_images,\n    batch_size=1,\n    shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c669bad08c9fa68a83a4bc8fad81efda80adf052"},"cell_type":"code","source":"pred_result = cnn_classifier.predict(input_fn=pred_input_fn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce335e69a5808fdc4ae481c018d9b2496c0ad763"},"cell_type":"code","source":"predicted_mask = next(pred_result)[\"logits\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbf16ca5a7d2b33c1e64c6fc6dcc1963a1448f1e"},"cell_type":"code","source":"def sigmoid(x):\n    return 1 / (1 + math.exp(-x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c12a8d42e19ff1fc9d7f754db0a80b69e7a1cdcb"},"cell_type":"code","source":"predicted_mask = np.reshape(np.squeeze(predicted_mask), [IMG_SIZE , IMG_SIZE, 1])\nfor i in range(IMG_SIZE):\n        for j in range(IMG_SIZE):\n                predicted_mask[i][j] = int(sigmoid(predicted_mask[i][j])*255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f97d9e72e61f9ed4addccd15f3e4bd45699ab2f6"},"cell_type":"code","source":"imshow(predicted_mask.astype(np.uint8).squeeze())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}