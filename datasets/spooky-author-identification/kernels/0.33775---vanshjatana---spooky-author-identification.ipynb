{"cells":[{"metadata":{"_cell_guid":"02adde30-2633-41f1-a672-af8ff83a1b02","_uuid":"22754d0cc0847be93bf947c7998d7fb65a2817d7"},"cell_type":"markdown","source":"**Objective of the competition:**\n\nThe competition dataset contains text from works of fiction written by spooky authors of the public domain: \n 1. Edgar Allan Poe (EAP)\n 2. HP Lovecraft (HPL)\n 3. Mary Wollstonecraft Shelley (MWS)\n \nThe objective  is to accurately identify the author of the sentences in the test set.\n\n**Objective of the notebook:**\n\nIn this notebook, let us try to create different features that will help us in identifying the spooky authors. \n\nAs a first step, we will do some basic data visualization and cleaning before we delve deep into the feature engineering part."},{"metadata":{"_cell_guid":"b31f62fb-bde8-410e-972c-3c092f22d497","_uuid":"0fcdf81ce439d2215892af58f839edfc0ca80a91","collapsed":true,"trusted":false},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import stopwords\nimport string\nimport xgboost as xgb\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn import ensemble, metrics, model_selection, naive_bayes\ncolor = sns.color_palette()\n\n%matplotlib inline\n\neng_stopwords = set(stopwords.words(\"english\"))\npd.options.mode.chained_assignment = None","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"add1b71c-e802-408f-8f62-7ea71ed155cf","_uuid":"ae86f9515b3be4956e223db4c2472c2c0c40d9fb","trusted":false},"cell_type":"code","source":"## Read the train and test dataset and check the top few lines ##\ntrain_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"35e22f81-77f9-438e-ba50-803aea15ad14","_uuid":"83a9dfc6af30753f82f07ef6162d3b9ba155b06d","trusted":false},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5bee9e9a-5fbf-4ee6-9e92-0c77821fe77d","_uuid":"d7682e0812990e3409db6076e7570ce984e466a1"},"cell_type":"markdown","source":"We can check the number of occurrence of each of the author to see if the classes are balanced. "},{"metadata":{"_cell_guid":"95529569-3380-4794-8248-caf5e8c67f6a","_uuid":"045fe5712b26a72855dad61f05c947ab829a295b","trusted":false},"cell_type":"code","source":"cnt_srs = train_df['author'].value_counts()\n\nplt.figure(figsize=(8,4))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Author Name', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bff5de3a-b92f-4192-b142-60d0367e1bb2","_uuid":"7b1ddc8bf782ae87ed5c24fdb6edbff986255d60"},"cell_type":"markdown","source":"This looks good. There is not much class imbalance. Let us print some lines of each of the authors to try and understand their writing style if possible."},{"metadata":{"_cell_guid":"6c85f84f-d0ee-444e-8b5f-2bf62452624a","_uuid":"cc6b841404940a0f84481c76f5c2328b373416e1","trusted":false},"cell_type":"code","source":"grouped_df = train_df.groupby('author')\nfor name, group in grouped_df:\n    print(\"Author name : \", name)\n    cnt = 0\n    for ind, row in group.iterrows():\n        print(row[\"text\"])\n        cnt += 1\n        if cnt == 5:\n            break\n    print(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"84398b75-325f-4259-90ea-bb6293cc5235","_uuid":"d5739c4a5967d2bcb9326d39529f84791c09dfb8"},"cell_type":"markdown","source":"Only thing I can see is that there are quite a few special characters present in the text data. So count of these special characters might be a good feature. Probably we can create them later.\n\nApart from that, I do not have much clue.. In case if you find any interesting styles (features which we can create), please add them in the comments. \n\n**Feature Engineering:**\n\nNow let us come try to do some feature engineering. This consists of two main parts.\n\n 1. Meta features - features that are extracted from the text like number of words, number of stop words, number of punctuations etc\n 2. Text based features - features directly based on the text / words like frequency, svd, word2vec etc.\n\n**Meta Features:**\n\nWe will start with creating meta featues and see how good are they at predicting the spooky authors. The feature list is as follows:\n1. Number of words in the text\n2. Number of unique words in the text\n3. Number of characters in the text\n4. Number of stopwords \n5. Number of punctuations\n6. Number of upper case words\n7. Number of title case words\n8. Average length of the words\n"},{"metadata":{"_cell_guid":"5758c1ff-ca4d-4c66-8c85-ac1725bd631b","_uuid":"ec015064f318cfd7d0a405bd28cd002f72724bbe","collapsed":true,"trusted":false},"cell_type":"code","source":"## Number of words in the text ##\ntrain_df[\"num_words\"] = train_df[\"text\"].apply(lambda x: len(str(x).split()))\ntest_df[\"num_words\"] = test_df[\"text\"].apply(lambda x: len(str(x).split()))\n\n## Number of unique words in the text ##\ntrain_df[\"num_unique_words\"] = train_df[\"text\"].apply(lambda x: len(set(str(x).split())))\ntest_df[\"num_unique_words\"] = test_df[\"text\"].apply(lambda x: len(set(str(x).split())))\n\n## Number of characters in the text ##\ntrain_df[\"num_chars\"] = train_df[\"text\"].apply(lambda x: len(str(x)))\ntest_df[\"num_chars\"] = test_df[\"text\"].apply(lambda x: len(str(x)))\n\n## Number of stopwords in the text ##\ntrain_df[\"num_stopwords\"] = train_df[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\ntest_df[\"num_stopwords\"] = test_df[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n\n## Number of punctuations in the text ##\ntrain_df[\"num_punctuations\"] =train_df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\ntest_df[\"num_punctuations\"] =test_df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n\n## Number of title case words in the text ##\ntrain_df[\"num_words_upper\"] = train_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\ntest_df[\"num_words_upper\"] = test_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n\n## Number of title case words in the text ##\ntrain_df[\"num_words_title\"] = train_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\ntest_df[\"num_words_title\"] = test_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n\n## Average length of the words in the text ##\ntrain_df[\"mean_word_len\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\ntest_df[\"mean_word_len\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"164b0d54-3d9e-4b58-ae7c-20c447efdc69","_uuid":"d79f96166a7fe609fd8431b341b2d5ad189ca07a"},"cell_type":"markdown","source":"Let us now plot some of our new variables to see of they will be helpful in predictions."},{"metadata":{"_cell_guid":"fe9a91d9-3df7-4e1b-9e69-f701cc714a15","_uuid":"51962b52791977deefab8b7991d59a51211c8a5e","trusted":false},"cell_type":"code","source":"train_df['num_words'].loc[train_df['num_words']>80] = 80 #truncation for better visuals\nplt.figure(figsize=(12,8))\nsns.violinplot(x='author', y='num_words', data=train_df)\nplt.xlabel('Author Name', fontsize=12)\nplt.ylabel('Number of words in text', fontsize=12)\nplt.title(\"Number of words by author\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"66833874-08f2-48b8-9561-b54de997071d","_uuid":"abe5dcadd42cd45169e44e3e299c303d5197b8ab","collapsed":true},"cell_type":"markdown","source":"EAP seems slightly lesser number of words than MWS and HPL. "},{"metadata":{"_cell_guid":"91514e74-d734-4642-a9dd-470cb8a65733","_uuid":"1c4c0950d33e29d270fbc021aa8c5ff0e7ab205b","trusted":false},"cell_type":"code","source":"train_df['num_punctuations'].loc[train_df['num_punctuations']>10] = 10 #truncation for better visuals\nplt.figure(figsize=(12,8))\nsns.violinplot(x='author', y='num_punctuations', data=train_df)\nplt.xlabel('Author Name', fontsize=12)\nplt.ylabel('Number of puntuations in text', fontsize=12)\nplt.title(\"Number of punctuations by author\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3a622bfc-da8b-4f13-b9d8-a63dd79a5218","_uuid":"240a9ac16cf5d342e6d01cb020f1d8cea670ec84"},"cell_type":"markdown","source":"This also seems to be somewhat useful. Now let us focus on creating some text based features. \n\nLet us first build a basic model to see how these meta features  are helping. "},{"metadata":{"_cell_guid":"d97fc321-32a9-429e-9135-ae52300332ec","_uuid":"c27a85339ef5cf5ac3c87527249f878b615d3996","collapsed":true,"trusted":false},"cell_type":"code","source":"## Prepare the data for modeling ###\nauthor_mapping_dict = {'EAP':0, 'HPL':1, 'MWS':2}\ntrain_y = train_df['author'].map(author_mapping_dict)\ntrain_id = train_df['id'].values\ntest_id = test_df['id'].values\n\n### recompute the trauncated variables again ###\ntrain_df[\"num_words\"] = train_df[\"text\"].apply(lambda x: len(str(x).split()))\ntest_df[\"num_words\"] = test_df[\"text\"].apply(lambda x: len(str(x).split()))\ntrain_df[\"mean_word_len\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\ntest_df[\"mean_word_len\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n\ncols_to_drop = ['id', 'text']\ntrain_X = train_df.drop(cols_to_drop+['author'], axis=1)\ntest_X = test_df.drop(cols_to_drop, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c4198d3f-5fad-41b1-9bcf-3b2faef2287f","_uuid":"1fddaea1621cba593f86d78851a26e1645f4954e"},"cell_type":"markdown","source":"We can train a simple XGBoost model. "},{"metadata":{"_cell_guid":"1534f55b-1334-4f1e-a597-d51e4d190fb3","_uuid":"7e736a33d7aefcc49edb0e629e57462f92e86c99","collapsed":true,"trusted":false},"cell_type":"code","source":"def runXGB(train_X, train_y, test_X, test_y=None, test_X2=None, seed_val=0, child=1, colsample=0.3):\n    param = {}\n    param['objective'] = 'multi:softprob'\n    param['eta'] = 0.1\n    param['max_depth'] = 3\n    param['silent'] = 1\n    param['num_class'] = 3\n    param['eval_metric'] = \"mlogloss\"\n    param['min_child_weight'] = child\n    param['subsample'] = 0.8\n    param['colsample_bytree'] = colsample\n    param['seed'] = seed_val\n    num_rounds = 2000\n\n    plst = list(param.items())\n    xgtrain = xgb.DMatrix(train_X, label=train_y)\n\n    if test_y is not None:\n        xgtest = xgb.DMatrix(test_X, label=test_y)\n        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=20)\n    else:\n        xgtest = xgb.DMatrix(test_X)\n        model = xgb.train(plst, xgtrain, num_rounds)\n\n    pred_test_y = model.predict(xgtest, ntree_limit = model.best_ntree_limit)\n    if test_X2 is not None:\n        xgtest2 = xgb.DMatrix(test_X2)\n        pred_test_y2 = model.predict(xgtest2, ntree_limit = model.best_ntree_limit)\n    return pred_test_y, pred_test_y2, model","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1effdaf3-faca-455d-a7a2-ae4d81b5c209","_uuid":"607c32af563879d1f7e011a438216ab8bea74ae3"},"cell_type":"markdown","source":"For the sake of kernel run time, we can just check the first fold in the k-fold cross validation for the scores. Please remove the 'break' line while running in local."},{"metadata":{"_cell_guid":"97965af9-da5a-4ccc-94c5-bc541ed00d49","_uuid":"441491131b9a7272863714494dd1303022c9d630","trusted":false},"cell_type":"code","source":"kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_X.loc[dev_index], train_X.loc[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    pred_val_y, pred_test_y, model = runXGB(dev_X, dev_y, val_X, val_y, test_X, seed_val=0)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n    break\nprint(\"cv scores : \", cv_scores)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ef5d6aa2-9d59-48e8-87ad-7ab254e0dc8a","_uuid":"6ebaf270a27c8b07455498111bd0a8b2c11b6b16"},"cell_type":"markdown","source":"We are getting a mlogloss of '0.987' using just the meta features. Not a bad score. Now let us see which of these features are important."},{"metadata":{"_cell_guid":"2856aa57-cce7-4f18-af56-a77ebd52eef7","_uuid":"506938cebfedaad3e70d531e4cad554abe2a3c55","trusted":false},"cell_type":"code","source":"### Plot the important variables ###\nfig, ax = plt.subplots(figsize=(12,12))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"739ce74e-af56-4fd6-a7b3-fe809f33bc54","_uuid":"25225b8d3a5ed46ec90308478b3788760eb5ea1d"},"cell_type":"markdown","source":"Number of characters, mean word length and number of unique words turn out to be the top 3 variables. Now let us focus on creating some text based features. \n\n**Text Based Features :**\n\nOne of the basic features which we could create is tf-idf values of the words present in the text. So we can start with that one.\n"},{"metadata":{"_cell_guid":"dd89dcab-b7a2-4b11-9564-ac8558f938e0","_uuid":"41b4430c7e9699bd7f430c471009082bf7449928","collapsed":true,"trusted":false},"cell_type":"code","source":"### Fit transform the tfidf vectorizer ###\ntfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\ntfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fb46183a-43b6-4785-823a-f017a0821b78","_uuid":"9c51efb2c3ff436baf8811a298b699b430b812bf"},"cell_type":"markdown","source":"Now that we have got the tfidf vector, here is the tricky part. The tfidf output is a sparse matrix and so if we have to use it with other dense features, we have couple of choices. \n1. We can choose to get the top 'n' features (depending on the system config) from the tfidf vectorizer, convert it into dense format and concat with other features. \n2. Build a model using just the sparse features and then use the predictions as one of the features along with other dense features.\n\nBased on the dataset, one might perform better than the other. Here we can use the second approach since there are some very [good scoring kernels](https://www.kaggle.com/the1owl/python-tell-tale-tutorial) using all the features of tfidf.\n\nAlso it seems that, [Naive Bayes is performing better](https://www.kaggle.com/thomasnelson/spooky-simple-naive-bayes-scores-0-399) in this dataset. So we could build a naive bayes model using tfidf features as it is faster to train."},{"metadata":{"_cell_guid":"7ce26604-5935-41cd-85ac-33e499a186f1","_uuid":"924a649ddf02867e7bd1e68d8cab33d3c36bb83e","collapsed":true,"trusted":false},"cell_type":"code","source":"def runMNB(train_X, train_y, test_X, test_y, test_X2):\n    model = naive_bayes.MultinomialNB()\n    model.fit(train_X, train_y)\n    pred_test_y = model.predict_proba(test_X)\n    pred_test_y2 = model.predict_proba(test_X2)\n    return pred_test_y, pred_test_y2, model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"caede0cb0a42bdc2e59e91b9d424ec0123a3fcc8"},"cell_type":"markdown","source":"**Naive Bayes on Word Tfidf Vectorizer:**"},{"metadata":{"_cell_guid":"61063815-507a-45f7-8866-5298da11e62d","_uuid":"c0ed8394d5fbcfb833efa2836509583a2ec79de1","trusted":false},"cell_type":"code","source":"cv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 5.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"404695a0-c33b-4cba-9dd1-bf2a5e8c12fc","_uuid":"e16c6d867d6bf1bb4e2661cc28841c672091fe0a"},"cell_type":"markdown","source":"We are getting a mlogloss of 0.844 using just tfidf vectorizer. Much better than the meta features. We can now create frequency features and see how it is performing.\n\n**Naive Bayes on Word Count Vectorizer:**"},{"metadata":{"_cell_guid":"92ab9f7c-8c2c-4233-a6dc-eaa12ca7d144","_uuid":"9cd43c20764c81a3216b8371c477ae5552e24c7d","collapsed":true,"trusted":false},"cell_type":"code","source":"### Fit transform the tfidf vectorizer ###\ntfidf_vec = CountVectorizer(stop_words='english', ngram_range=(1,3))\ntfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"48d68a84-6c6d-40b3-9069-d4c324355fc6","_uuid":"2e05fb42bcd850e74c767961f58400b0dac463ec"},"cell_type":"markdown","source":"Now let us build Multinomial NB model using count vectorizer based features.."},{"metadata":{"_cell_guid":"b7927348-b6b1-4960-b76c-ebf14fae37f0","_uuid":"4f9354473820d59076bf991b5110fc4dd309c204","trusted":false},"cell_type":"code","source":"cv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 5.\n\n# add the predictions as new features #\ntrain_df[\"nb_cvec_eap\"] = pred_train[:,0]\ntrain_df[\"nb_cvec_hpl\"] = pred_train[:,1]\ntrain_df[\"nb_cvec_mws\"] = pred_train[:,2]\ntest_df[\"nb_cvec_eap\"] = pred_full_test[:,0]\ntest_df[\"nb_cvec_hpl\"] = pred_full_test[:,1]\ntest_df[\"nb_cvec_mws\"] = pred_full_test[:,2]\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5a5d31ea-278c-432a-9840-ca9209410ff7","_uuid":"fb099e48fde5f3960bc2409d323749e855b2e269"},"cell_type":"markdown","source":"Wow. We got a cross validation mlogloss of 0.451 using count vectorizer inplace of tfidf vectorizer. LB score using this model is 0.468. \n\n** Naive Bayes on Character Count Vectorizer:**\n\nOne idea from the \"data eyeballing\" is that counting the special charaters might help. Instead of just counting the special characters, we can use the count vectorizer at character level to get some features. Again we can run Multinomial NB on top of it."},{"metadata":{"_cell_guid":"aed10880-e717-4a04-85b9-a77f8f58aee9","_uuid":"d26ba4563285c10418479465e10de172f527f2a5","trusted":false},"cell_type":"code","source":"### Fit transform the tfidf vectorizer ###\ntfidf_vec = CountVectorizer(ngram_range=(1,7), analyzer='char')\ntfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 5.\n\n# add the predictions as new features #\ntrain_df[\"nb_cvec_char_eap\"] = pred_train[:,0]\ntrain_df[\"nb_cvec_char_hpl\"] = pred_train[:,1]\ntrain_df[\"nb_cvec_char_mws\"] = pred_train[:,2]\ntest_df[\"nb_cvec_char_eap\"] = pred_full_test[:,0]\ntest_df[\"nb_cvec_char_hpl\"] = pred_full_test[:,1]\ntest_df[\"nb_cvec_char_mws\"] = pred_full_test[:,2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"442767184f5181c613cc2299a100c7568be9d9b6"},"cell_type":"code","source":"### Fit transform the tfidf vectorizer ###\ntfidf_vec = TfidfVectorizer(ngram_range=(1,5), analyzer='char')\ntfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 5.\n\n# add the predictions as new features #\ntrain_df[\"nb_tfidf_char_eap\"] = pred_train[:,0]\ntrain_df[\"nb_tfidf_char_hpl\"] = pred_train[:,1]\ntrain_df[\"nb_tfidf_char_mws\"] = pred_train[:,2]\ntest_df[\"nb_tfidf_char_eap\"] = pred_full_test[:,0]\ntest_df[\"nb_tfidf_char_hpl\"] = pred_full_test[:,1]\ntest_df[\"nb_tfidf_char_mws\"] = pred_full_test[:,2]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d17fb86b944703cd634c4e607ea64daf70c31adb"},"cell_type":"markdown","source":"**XGBoost model:**\n\nNow with the three new variables, we can re-run the xgboost model and evaluate the results."},{"metadata":{"_cell_guid":"7091aede-e589-45d9-9a85-1560af442725","_uuid":"633eb97dc8b15a7959b962c20222697590071af7","trusted":false},"cell_type":"code","source":"cols_to_drop = ['id', 'text']\ntrain_X = train_df.drop(cols_to_drop+['author'], axis=1)\ntest_X = test_df.drop(cols_to_drop, axis=1)\n\nkf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_X.loc[dev_index], train_X.loc[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    pred_val_y, pred_test_y, model = runXGB(dev_X, dev_y, val_X, val_y, test_X, seed_val=0, colsample=0.7)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n    break\nprint(\"cv scores : \", cv_scores)\n\nout_df = pd.DataFrame(pred_full_test)\nout_df.columns = ['EAP', 'HPL', 'MWS']\nout_df.insert(0, 'id', test_id)\nout_df.to_csv(\"sub_fe.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ed36de2b-e0bb-42e6-bed8-bbbdeb513ba5","_uuid":"ddefa6111b588449df9f2abbc541c0ca051174ab","trusted":false},"cell_type":"code","source":"### Plot the important variables ###\nfig, ax = plt.subplots(figsize=(12,12))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"nbformat":4,"nbformat_minor":1}