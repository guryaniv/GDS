{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport xgboost as xgb\n\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import normalize\n\nimport xgboost as xgb\n\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Read train and test files\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"119ab359d49d4fdb376c45a457d06e4ca0404bc1"},"cell_type":"code","source":"X_train = train_df.drop([\"ID\", \"target\"], axis=1)\ny_train = np.log1p(train_df[\"target\"].values)\n\nX_test = test_df.drop([\"ID\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80567702c22bf5b4bdadaa61e8882196153100c5","collapsed":true},"cell_type":"code","source":"print(\"Train set size: {}\".format(X_train.shape))\nprint(\"Test set size: {}\".format(X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfa7f56983f5145632fb8d53d2c52cfffafa9a98"},"cell_type":"markdown","source":"Remove constant features(std=0)"},{"metadata":{"trusted":true,"_uuid":"55d6d7aafd37108b2aef12e65dcdf4484429e3a8","collapsed":true},"cell_type":"code","source":"# check and remove constant columns\ncolsToRemove = []\nfor col in X_train.columns:\n    if X_train[col].std() == 0: \n        colsToRemove.append(col)\n        \n# remove constant columns in the training set\nX_train.drop(colsToRemove, axis=1, inplace=True)\n\n# remove constant columns in the test set\nX_test.drop(colsToRemove, axis=1, inplace=True) \n\nprint(\"Removed `{}` Constant Columns\\n\".format(len(colsToRemove)))\nprint(colsToRemove)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ea6e2b9b71b266adc917a2cfa0d28b023445a94","collapsed":true},"cell_type":"code","source":"gc.collect()\nprint(\"Train set size: {}\".format(X_train.shape))\nprint(\"Test set size: {}\".format(X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b175c02f8b4d85eb8ed0e0b15e586f617b6447c3"},"cell_type":"markdown","source":"REMOVE DUPLICATE COLOMNS"},{"metadata":{"trusted":true,"_uuid":"bd366fc3b56704123f7e8c0374996efe4e99719d","collapsed":true},"cell_type":"code","source":"%%time\n# The other way to drop duplicate columns is to transpose our DatFrame and use the pandas routine - drop_duplicates. \n# df.T.drop_duplicates().T. However, transposing is a bad idea when working with large DataFrames. But this option is fine in this case.\n# Check and remove duplicate columns\ncolsToRemove = []\ncolsScaned = []\ndupList = {}\n\ncolumns = X_train.columns\n\nfor i in range(len(columns)-1):\n    v = X_train[columns[i]].values\n    dupCols = []\n    for j in range(i+1,len(columns)):\n        if np.array_equal(v, X_train[columns[j]].values):\n            colsToRemove.append(columns[j])\n            if columns[j] not in colsScaned:\n                dupCols.append(columns[j]) \n                colsScaned.append(columns[j])\n                dupList[columns[i]] = dupCols\n                \n# remove duplicate columns in the training set\nX_train.drop(colsToRemove, axis=1, inplace=True) \n\n# remove duplicate columns in the testing set\nX_test.drop(colsToRemove, axis=1, inplace=True)\n\nprint(\"Removed `{}` Duplicate Columns\\n\".format(len(dupList)))\nprint(dupList)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"20ca7061a01244bd3f3ff370ea2512e38bad36c6"},"cell_type":"code","source":"def drop_sparse(train, test):\n    flist = [x for x in train.columns if not x in ['ID','target']]\n    for f in flist:\n        if len(np.unique(train[f]))<2:\n            train.drop(f, axis=1, inplace=True)\n            test.drop(f, axis=1, inplace=True)\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cac8a39067385da3e86cd6c479b59caefb09ae41","collapsed":true},"cell_type":"code","source":"%%time\nX_train, X_test = drop_sparse(X_train, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65456bc47fac54ac5c7c17db557a66a2f08230f0","collapsed":true},"cell_type":"code","source":"gc.collect()\nprint(\"Train set size: {}\".format(X_train.shape))\nprint(\"Test set size: {}\".format(X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2b6e0a38c11c45682c015d9afccf6732b3858264"},"cell_type":"code","source":"def add_SumZeros(train, test, features):\n    flist = [x for x in train.columns if not x in ['ID','target']]\n    if 'SumZeros' in features:\n        train.insert(1, 'SumZeros', (train[flist] == 0).astype(int).sum(axis=1))\n        test.insert(1, 'SumZeros', (test[flist] == 0).astype(int).sum(axis=1))\n    flist = [x for x in train.columns if not x in ['ID','target']]\n\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de63a2cfacb26327417b542762fede4cc7197545","collapsed":true},"cell_type":"code","source":"%%time\nX_train, X_test = add_SumZeros(X_train, X_test, ['SumZeros'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d2d5acdf0034d9ce7c81f0892ad89a4a7988474","collapsed":true},"cell_type":"code","source":"gc.collect()\nprint(\"Train set size: {}\".format(X_train.shape))\nprint(\"Test set size: {}\".format(X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6cd8c4af75490cd8c1b25867cd1d90cc7dc2741c"},"cell_type":"code","source":"def add_SumValues(train, test, features):\n    flist = [x for x in train.columns if not x in ['ID','target']]\n    if 'SumValues' in features:\n        train.insert(1, 'SumValues', (train[flist] != 0).astype(int).sum(axis=1))\n        test.insert(1, 'SumValues', (test[flist] != 0).astype(int).sum(axis=1))\n    flist = [x for x in train.columns if not x in ['ID','target']]\n\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"243dbe8adc158753f72a65dcba7de66cb4e36ffb","collapsed":true},"cell_type":"code","source":"%%time\nX_train, X_test = add_SumValues(X_train, X_test, ['SumValues'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9af4d46410bd15fc850df06099c0a30259d27d87","collapsed":true},"cell_type":"code","source":"gc.collect()\nprint(\"Train set size: {}\".format(X_train.shape))\nprint(\"Test set size: {}\".format(X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"445234d1ac99de118f4ae73f5509550b3d4cd880"},"cell_type":"code","source":"def add_OtherAgg(train, test, features):\n    flist = [x for x in train.columns if not x in ['ID','target','SumZeros','SumValues']]\n    if 'OtherAgg' in features:\n        train['Mean']   = train[flist].mean(axis=1)\n        train['Median'] = train[flist].median(axis=1)\n        train['Mode']   = train[flist].mode(axis=1)\n        train['Max']    = train[flist].max(axis=1)\n        train['Var']    = train[flist].var(axis=1)\n        train['Std']    = train[flist].std(axis=1)\n        \n        test['Mean']   = test[flist].mean(axis=1)\n        test['Median'] = test[flist].median(axis=1)\n        test['Mode']   = test[flist].mode(axis=1)\n        test['Max']    = test[flist].max(axis=1)\n        test['Var']    = test[flist].var(axis=1)\n        test['Std']    = test[flist].std(axis=1)\n    flist = [x for x in train.columns if not x in ['ID','target','SumZeros','SumValues']]\n\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b9822dbb01aeccae78e8656ddf540ab0663b839","collapsed":true},"cell_type":"code","source":"%%time\nX_train, X_test = add_OtherAgg(X_train, X_test, ['OtherAgg'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22b7bc1da4fc8c6371d2226bea7b8a2c11ab2142","collapsed":true},"cell_type":"code","source":"gc.collect()\nprint(\"Train set size: {}\".format(X_train.shape))\nprint(\"Test set size: {}\".format(X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a1dc95ecc97bb0ac2cb0e9893a8b8d7c20584b8d"},"cell_type":"code","source":"from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\nfrom sklearn.decomposition import TruncatedSVD, FastICA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02e17c68c3e2ae4f6bfe492cde88963b41335f25","collapsed":true},"cell_type":"code","source":"PERC_TRESHOLD = 0.98   ### Percentage of zeros in each feature ###\nN_COMP = 97            ### Number of decomposition components ###\n\nprint(\"tSVD\")\ntsvd = TruncatedSVD(n_components=N_COMP, random_state=17)\ntsvd_results_train = tsvd.fit_transform(X_train)\ntsvd_results_test = tsvd.transform(X_test)\nprint(\"Append decomposition components to datasets...\")\nfor i in range(1, N_COMP + 1):\n    X_train['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n    X_test['tsvd_' + str(i)] = tsvd_results_test[:, i - 1]\nprint('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ccc64167fd474b190d2112ef9665ce8164e9348d"},"cell_type":"code","source":"import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4bd645c1c66e25fcdcb42a557a6ab2b50eea3f8","collapsed":true},"cell_type":"code","source":"def run_lgb(train_X, train_y, val_X, val_y, test_X):\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\",\n        'boosting_type' : 'goss',\n        'max_depth' : 5,#-1\n        \"num_leaves\" : 20,#20\n        \"learning_rate\" : 0.01,#0.01\n        #\"bagging_fraction\" : 0.6,#0.7 #0.8 #0.3\n        \"feature_fraction\" : 0.6,#0.7 #0.5\n        #\"bagging_freq\" : 2, #10 #20\n        \"bagging_seed\" : 42, #2018\n        \"verbosity\" : -1,\n        'lambda_l2' : 0.000001,#0.1\n        'lambda_l1' : 0.00001,#0,\n        'max_bin' : 200 #default=250 #200 #170 #120 #90\n\n    }\n    \n    lgtrain = lgb.Dataset(train_X, label=train_y)\n    lgval = lgb.Dataset(val_X, label=val_y)\n    evals_result = {}\n    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, \n                      verbose_eval=200, evals_result=evals_result)\n    \n    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n    return pred_test_y, model, evals_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ac8752585768b284b8f28a6c8fe54a3a919189a","collapsed":true},"cell_type":"code","source":"# Training LGB\n#seeds = [42, 2018]\nseeds = [42]\npred_test_full_seed = 0\nfor seed in seeds:\n    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=seed)\n    pred_test_full = 0\n    for dev_index, val_index in kf.split(X_train):\n        dev_X, val_X = X_train.loc[dev_index,:], X_train.loc[val_index,:]\n        dev_y, val_y = y_train[dev_index], y_train[val_index]\n        pred_test, model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y, X_test)\n        pred_test_full += pred_test\n    pred_test_full /= 5.\n    pred_test_full = np.expm1(pred_test_full)\n    pred_test_full_seed += pred_test_full\n    print(\"Seed {} completed....\".format(seed))\npred_test_full_seed /= np.float(len(seeds))\n\nprint(\"LightGBM Training Completed...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42f1891142ad463c87daa26215d82effb54887f3","collapsed":true},"cell_type":"code","source":"# feature importance\nprint(\"Features Importance...\")\ngain = model.feature_importance('gain')\nfeatureimp = pd.DataFrame({'feature':model.feature_name(), \n                   'split':model.feature_importance('split'), \n                   'gain':100 * gain / gain.sum()}).sort_values('gain', ascending=False)\nprint(featureimp[:15])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b40d0e04f73d80045ba50bdd7e798b6d9e445411"},"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')\n\nsub_lgb = pd.DataFrame()\nsub_lgb[\"target\"] = pred_test_full_seed\nsub[\"target\"] = sub_lgb[\"target\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"850f550778844bbf5e7e67b22c664f4269395252","collapsed":true},"cell_type":"code","source":"print(sub.head())\nsub.to_csv('Ensemble9.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b25c86ecf1532b611d78944daf3622e62fa85cd9","collapsed":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d3169e118bd962828a11d9860d17e41f52e38694"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}