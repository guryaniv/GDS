{"nbformat_minor": 1, "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"file_extension": ".py", "nbconvert_exporter": "python", "name": "python", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "version": "3.6.1"}}, "nbformat": 4, "cells": [{"metadata": {"_uuid": "e857dc986846832b437e58fc5d4d4afe0719a2b2", "_cell_guid": "e2056289-5dea-4153-8f67-539b7fa44b8d", "_execution_state": "busy"}, "source": ["# **NEURAL NETWORK USING ADAM OPTIMIZER**\n", "by **Jean Carlo Codogno** - 09/10/2017\n", "\n", "<br/>\n", "\n", "+ **INTRODUCTION**\n", "+ **ADAM OPTIMIZER**\n", "\n", "\n", "## INTRODUCTION\n", "\n", "The propose this notebook is change the optimizer of this notebook (https://www.kaggle.com/jcodogno/neural-network-using-sgd-0-9897), changing the Stochastic Gradient Descent for Adam Optimizer.\n", "\n", "**For computional reason was used a little epochs, in my tests I used 30 epochs and I got 0.99071 in accuracy on public test**\n"], "cell_type": "markdown"}, {"metadata": {"_uuid": "7bcae0a7c40933c487ffa53fd08aabc8071b20ce", "collapsed": true, "_active": false, "_cell_guid": "86990557-b034-c88c-bc3e-0e0bb666606b", "_execution_state": "idle"}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import pandas as pd\n", "import numpy as np\n", "import time\n", "import sys\n", "\n", "seed = 782\n", "np.random.seed(seed)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "6c7855986fa68686cc3ef7317881a7d4b023ca0c", "collapsed": true, "_active": false, "_cell_guid": "48c61204-4638-a851-06da-2e07208e7b35", "_execution_state": "idle"}, "outputs": [], "source": ["df = pd.read_csv(\"../input/train.csv\")\n", "train = df.as_matrix()\n", "\n", "train_y = train[:,0].astype('int8')\n", "train_x = train[:,1:].astype('float64')\n", "\n", "train = None\n", "\n", "print(\"Shape Train Images: (%d,%d)\" % train_x.shape)\n", "print(\"Shape Labels: (%d)\" % train_y.shape)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "4cbffbc9c03709c5fe1b229d6a332c9d227caba4", "_cell_guid": "2662e464-988d-45b8-8de7-f3e3c7eba585"}, "outputs": [], "source": ["df = pd.read_csv(\"../input/test.csv\")\n", "test = df.as_matrix().astype('float64')\n", "print(\"Shape Test Images: (%d,%d)\" % train_x.shape)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "9d98b46d9d70692be12f54ca56901fda9c2b4d38", "_cell_guid": "0e9d8f99-8de1-49de-8e7f-5d2e3d47aad3", "_execution_state": "idle"}, "outputs": [], "source": ["train_x /=255\n", "test /= 255\n", "\n", "print(\"Min: %.2f\" % np.min(train_x))\n", "print(\"Max: %.2f\" % np.max(train_x))"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "ba67bbb6e2702b054d475e76fe0ff09e711f460b", "_cell_guid": "9beaa97d-9291-4f93-bd9d-8eb5a5e8d4bc"}, "outputs": [], "source": ["train_y = pd.get_dummies(train_y).as_matrix()\n", "print(train_y[0])"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "f9125249f805c751b61f73cccb5b4c110a53d4f6", "_cell_guid": "a69789fd-5692-4fdc-82d4-e9d922f7327f"}, "outputs": [], "source": ["def ReLu(x, derivative=False):\n", "    if(derivative==False):\n", "        return x*(x > 0)\n", "    else:\n", "        return 1*(x > 0)\n", "\n", "x = np.arange(20)-10\n", "relu = ReLu(x)\n", "\n", "plt.plot(x, relu)\n", "plt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "87260255c2ed0afa612d441e9f2912182849a195", "_cell_guid": "53a31cab-b171-42ef-9512-0942486c3dbb"}, "outputs": [], "source": ["def Softmax(x):\n", "    x -= np.max(x)\n", "    sm = (np.exp(x).T / np.sum(np.exp(x),axis=1)).T\n", "    return sm\n", "\n", "x = np.arange(20)-10\n", "softmax = Softmax([x])\n", "\n", "plt.plot(x, softmax[0])\n", "plt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "9fad3b5a8167b90b066156bffae8c6f9ab172b1a", "_cell_guid": "83226388-8e11-4ff0-ae6b-bcf416a3d759"}, "outputs": [], "source": ["def CreateWeights():\n", "    ##Initialization of the Weights and the Biases with the random gaussian function with mean zeron, and variance between 1/sqtr(num_inputs_layer)\n", "    \n", "    ninputs = 784\n", "    wl1 = 500 ##Number of neurons in the first layer\n", "    wl2 = 300 ##Number of neurons in the second layer\n", "    nclass = 10 ##Numer of the class, in this case it is the number of the digits.\n", "    \n", "    #layer1\n", "    w1 = np.random.normal(0, ninputs**-0.5, [ninputs,wl1])\n", "    b1 = np.random.normal(0, ninputs**-0.5, [1,wl1])\n", "    \n", "    #Layer2\n", "    w2 = np.random.normal(0, wl1**-0.5, [wl1,wl2])\n", "    b2 = np.random.normal(0, wl1**-0.5, [1,wl2])\n", "\n", "    #Layer3\n", "    w3 = np.random.normal(0, wl2**-0.5, [wl2,nclass])\n", "    b3 = np.random.normal(0, wl2**-0.5, [1,nclass])\n", "    \n", "    return [w1,w2,w3,b1,b2,b3]"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "a5382fc411ef29368fadc663e8585960ce81e6f6", "_cell_guid": "58f69a54-f2d4-4e28-8634-a857b0fa807b"}, "outputs": [], "source": ["def Dropout(x, keep_prop):\n", "    mask = np.random.binomial([np.ones_like(x)],(1-keep_prop))[0]  / (1-keep_prop)\n", "    return x*mask"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "796dbeed2aa96c51d93c1776f6c2303f32c7d387", "_cell_guid": "8321e098-6d5d-4388-8a49-587829c0799b"}, "outputs": [], "source": ["def predict(weights, x, keep_prop=0):\n", "    \n", "    w1,w2,w3,b1,b2,b3  = weights \n", "    \n", "    #1-Hidden Layer\n", "    first = ReLu(x@w1+b1)\n", "    first = Dropout(first, keep_prop)\n", "\n", "    #2-Hidden Layer\n", "    second = ReLu(first@w2+b2)\n", "    second = Dropout(second, keep_prop)\n", "    \n", "    #Output Layer\n", "    return [first, second, Softmax(second@w3+b3)]"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "23dd420a9a47d17072c6724b869dbf6b05527c26", "collapsed": true, "_active": false, "_cell_guid": "7f2c05ac-da5c-2513-fde6-27d85ffc3956", "_execution_state": "idle"}, "outputs": [], "source": ["def accuracy(output, y):\n", "    hit = 0\n", "    output = np.argmax(output, axis=1)\n", "    y = np.argmax(y, axis=1)\n", "    for y in zip(output, y):\n", "        if(y[0]==y[1]):\n", "            hit += 1\n", "\n", "    p = (hit*100)/output.shape[0]\n", "    return p"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "d122bb7bb80270688e4ec0b414402d594080b55a", "_cell_guid": "1f23f013-60e8-4d71-8110-e0c54381d48d"}, "outputs": [], "source": ["def log2(x):\n", "    if(x!=0):\n", "        return np.log(x)\n", "    else:\n", "        return -np.inf\n", "    \n", "def log(y):\n", "    return [[log2(nx) for nx in x]for x in y]\n", "\n", "def cost(Y_predict, Y_right):\n", "    \n", "    Loss = -np.mean((np.nan_to_num(Y_right*log(Y_predict)) + np.nan_to_num((1-Y_right)*log(1-Y_predict))),keepdims=True)\n", "    return Loss"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "6392f94a1182f9e28e6a223f4732bfe98a888d3b", "_cell_guid": "f86330c7-79a1-4c65-8a50-9bf74fc3390f"}, "outputs": [], "source": ["porcent_valid = 0.1\n", "VALID_SIZE = round(train_x.shape[0]*porcent_valid)\n", "\n", "index_data = np.arange(train_x.shape[0])\n", "np.random.shuffle(index_data)\n", "\n", "x_train = train_x[index_data[VALID_SIZE:]]\n", "x_valid = train_x[index_data[:VALID_SIZE]]\n", "\n", "\n", "d_train = train_y[index_data[VALID_SIZE:]]\n", "d_valid = train_y[index_data[:VALID_SIZE]]\n", "\n", "train_x = None\n", "train_y = None\n", "\n", "x_train.shape"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "673366714707df9b34eff7ef62cab729512c136d", "_cell_guid": "58719bf3-d2cf-4fc2-85f0-eccf813c2a7f"}, "source": ["## ADAM OPTIMIZER\n", "\n", "Adam optimizer was propose by Diederik P. Kingma, Jimmy Ba in *\"Adam: A Method for Stochastic Optimization\"*, 2015, the simplified weight update is:\n", "\n", "\n", "$$ m = beta1.m + (1-beta1).dw $$\n", "$$ mt = \\dfrac{m} {(1-beta1^t)} $$\n", "$$ v = beta2.v + (1-beta2).(dw^2) $$\n", "$$ vt = \\dfrac{v}{(1-beta2^t)}$$\n", "$$ w  -= \\eta . \\dfrac{m}{ (\\sqrt{v} + \\epsilon)} $$\n", "\n", "Where dw is the gradient. In the paper \"Adam: A Method for Stochastic Optimization\"* recommended values are \u03f5 = 1e-8, beta1 = 0.9, beta2 = 0.999.\n", "\n", "In the code need just some changes.\n", "\n", "\n", "Reference: http://cs231n.github.io/neural-networks-3/\n", "\n", "\n"], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_uuid": "25d47c0dad5d6a9bf2988963bcab72e9ed388101", "_cell_guid": "239358a6-b413-41db-b49d-34098edd58d9", "_execution_state": "idle"}, "outputs": [], "source": ["def ADAM(weights, x, t, outputs, eta, beta1, beta2, eps, i, nabla, cache=None):\n", "    \n", "    w1,w2,w3,b1,b2,b3  = weights\n", "    \n", "    \n", "    if(cache==None):\n", "            vw1 = np.zeros_like(w1)\n", "            mw1 = np.zeros_like(w1)\n", "            \n", "            vw2 = np.zeros_like(w2)\n", "            mw2 = np.zeros_like(w2)\n", "            \n", "            vw3 = np.zeros_like(w3)\n", "            mw3 = np.zeros_like(w3)\n", "            \n", "            vb1 = np.zeros_like(b1)\n", "            mb1 = np.zeros_like(b1)\n", "            \n", "            vb2 = np.zeros_like(b2)\n", "            mb2 = np.zeros_like(b2)\n", "            \n", "            vb3 = np.zeros_like(b3)\n", "            mb3 = np.zeros_like(b3)\n", "    else:\n", "        vw1,mw1,vw2,mw2,vw3,mw3,vb1,mb1,vb2,mb2,vb3,mb3 = cache\n", "    \n", "    first, second, y = outputs\n", "   \n", "    w3_delta = (t-y)/x.shape[0]\n", "    \n", "    w2_error = w3_delta@w3.T\n", "\n", "    w2_delta = w2_error * ReLu(second,derivative=True)\n", "\n", "    w1_error = w2_delta@w2.T\n", "    w1_delta = w1_error * ReLu(first,derivative=True)\n", "    \n", "    \n", "    dw3 = (second.T@w3_delta + nabla*2*w3)\n", "    mw3 = beta1*mw3 + (1-beta1)*dw3\n", "    mt = (mw3) / (1-beta1**i)\n", "    vw3 = beta2*vw3 + (1-beta2)*(dw3**2)\n", "    vt = (vw3) / (1-beta2**i)\n", "    w3 += eta * mt/(np.sqrt(vt) + eps)\n", "    \n", "    db3 = (w3_delta.sum(axis=0)+ nabla*2*b3)\n", "    mb3 = beta1*mb3 + (1-beta1)*db3\n", "    mt = (mb3) / (1-beta1**i)\n", "    vb3 = beta2*vb3 + (1-beta2)*(db3**2)\n", "    vt = (vb3) / (1-beta2**i)\n", "    b3 += eta * mt/(np.sqrt(vt) + eps)\n", "    \n", "    dw2 = (first.T@w2_delta + nabla*2*w2)\n", "    mw2 = beta1*mw2 + (1-beta1)*dw2\n", "    mt = (mw2) / (1-beta1**i)\n", "    vw2 = beta2*vw2 + (1-beta2)*(dw2**2)\n", "    vt = (vw2) / (1-beta2**i)\n", "    w2 += eta * mt/(np.sqrt(vt) + eps)\n", "    \n", "    db2 = (w2_delta.sum(axis=0) + nabla*2*b2)\n", "    mb2 = beta1*mb2 + (1-beta1)*db2\n", "    mt = (mb2) / (1-beta1**i)\n", "    vb2 = beta2*vb2 + (1-beta2)*(db2**2)\n", "    vt = (vb2) / (1-beta2**i)\n", "    b2 += eta * mt/(np.sqrt(vt) + eps)\n", "    \n", "    dw1 = (x.T@w1_delta + nabla*2*w1)\n", "    mw1 = beta1*mw1 + (1-beta1)*dw1\n", "    mt = (mw1) / (1-beta1**i)\n", "    vw1 = beta2*vw1 + (1-beta2)*(dw1**2)\n", "    vt = (vw1) / (1-beta2**i)\n", "    w1 += eta * mt/(np.sqrt(vt) + eps)\n", "    \n", "    db1 = (w1_delta.sum(axis=0) + nabla*2*b1)\n", "    mb1 = beta1*mb1 + (1-beta1)*db1\n", "    mt = (mb1) / (1-beta1**i)\n", "    vb1 = beta2*vb1 + (1-beta2)*(db1**2)\n", "    vt = (vb1) / (1-beta2**i)\n", "    b1 += eta * mt/(np.sqrt(vt) + eps)\n", "    \n", "    \n", "    weights = [w1,w2,w3,b1,b2,b3]\n", "    cache = [vw1,mw1,vw2,mw2,vw3,mw3,vb1,mb1,vb2,mb2,vb3,mb3]\n", "    \n", "    return weights, cache"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "5747a19626f4afe6f4f5af11e57467679b6ed544", "_cell_guid": "016426fd-ab73-4e4c-ad2a-8703c3c91bb3"}, "outputs": [], "source": ["from scipy.ndimage.interpolation import map_coordinates\n", "from scipy.ndimage.filters import gaussian_filter\n", "\n", "def elastic_transform(image, alpha, sigma, random_state=None):\n", "    \"\"\"Elastic deformation of images as described in [Simard2003]_.\n", "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n", "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n", "       Proc. of the International Conference on Document Analysis and\n", "       Recognition, 2003.\n", "    \"\"\"\n", "    if random_state is None:\n", "        random_state = np.random.RandomState(None)\n", "\n", "    shape = image.shape\n", "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n", "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n", "\n", "    x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]))\n", "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n", "\n", "    return map_coordinates(image, indices, order=1).reshape(shape)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "7bbc3ddcf83eb9003185d9fd8df72ad77ef283f1", "_cell_guid": "f78f9879-9e87-4476-ab42-6420300eacd2"}, "outputs": [], "source": ["x_t = np.array([elastic_transform(xx.reshape(28,28),15,3).reshape(784) for xx in x_train[0:10]])\n", "plt.subplot(1,2,1)\n", "plt.imshow(x_t[0].reshape(28,28))\n", "plt.subplot(1,2,2)\n", "plt.imshow(x_train[0].reshape(28,28))\n", "plt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "be8bea97cddcadbc2ee018101373ff2937943a88", "collapsed": true, "_active": false, "_cell_guid": "c421dda0-0e37-9d62-8a8d-7660befa4bdd", "_execution_state": "idle"}, "outputs": [], "source": ["def run(weights, x_train, y_train, x_valid, y_valid, epochs = 10, nbatchs=25, alpha = 1e-3, decay = 0, beta1=0.9, beta2=0.999, eps=1e-8, l2 = 0.001, keep_prop = 0):\n", "    \n", "    pross = x_train.shape[0]*0.05\n", "    \n", "    history = [[],[]]\n", "    \n", "    index = np.arange(x_train.shape[0])\n", "    cache = None\n", "    print(\"Train data: %d\" % (x_train.shape[0]))\n", "    print(\"Validation data: %d \\n\" % (x_valid.shape[0]))\n", "    mtime = 0\n", "    inter_adam = 1\n", "    \n", "    for j in range(epochs):\n", "        np.random.shuffle(index)\n", "        t = 0\n", "        iterations = round(x_train.shape[0]/nbatchs)\n", "        prog = \"\"\n", "        sacurr = 0\n", "        sloss = 0\n", "        sys.stdout.write(\"\\nEpochs: %2d \\ %2d \\n\"% (j+1,epochs))\n", "        stime = 0\n", "        timeIT = time.time()\n", "        for i in range(iterations):\n", "            timeI = time.time()\n", "            f = i*nbatchs\n", "            l = f+nbatchs\n", "            \n", "            if(l>(x_train.shape[0]-1)):\n", "                l = x_train.shape[0]\n", "                \n", "            x = np.array([elastic_transform(xx.reshape(28,28),15,3).reshape(784) for xx in x_train[index[f:l]]])\n", "            y = y_train[index[f:l]]\n", "\n", "            outputs = predict(weights, x, keep_prop)\n", "            \n", "            loss = cost(outputs[-1], y)+ l2 * (np.mean(weights[0],keepdims=True)**2+np.mean(weights[1],keepdims=True)**2+np.mean(weights[2],keepdims=True)**2)/3\n", "            \n", "            \n", "            accuracy_t = accuracy(outputs[-1], y)\n", "            \n", "            sacurr += accuracy_t\n", "            sloss += loss\n", "            \n", "            accuracy_train = sacurr/(i+1)\n", "            loss_train = sloss/(i+1)\n", "            \n", "            weights, cache = ADAM(weights, x, y, outputs, alpha, beta1, beta2, eps, inter_adam, l2, cache)\n", "            \n", "            t+= x.shape[0]\n", "            \n", "            qtd = round(t/pross)\n", "            prog = \"[\"\n", "            for p in range(20):\n", "                if(p<qtd-1):\n", "                    prog += \"=\"\n", "                elif(p==qtd-1):\n", "                    prog += \">\"\n", "                else:\n", "                    prog += \".\"\n", "            prog += \"]\"\n", "\n", "            \n", "            stime += time.time()-timeI\n", "            mtime = stime/(i+1)\n", "            mTimeT = mtime * (iterations-i-1)\n", "            \n", "            sys.stdout.write(\"\\r%5d/%5d %s ETA: %3d s - loss: %.4f  acc: %.4f\" % (t, x_train.shape[0], prog, mTimeT, loss_train, accuracy_train))\n", "            \n", "            history[0].append([loss_train, accuracy_train])\n", "            inter_adam += 1\n", "        mtime = time.time()-timeIT\n", "        alpha = alpha - (alpha*decay)\n", "        \n", "        outputs = predict(weights, x_valid)\n", "        \n", "        loss_valid = cost(outputs[-1], y_valid)+ l2 * (np.mean(weights[0],keepdims=True)**2+np.mean(weights[1],keepdims=True)**2+np.mean(weights[2],keepdims=True)**2)/3\n", "        accuracy_valid = accuracy(outputs[-1], y_valid)\n", "        \n", "        sys.stdout.write(\"\\r%5d/%5d %s ETA: %3d s loss: %.4f  acc: %.4f - lossValid: %.4f  accValid: %.4f \" % ( t, x_train.shape[0], prog, mtime, loss_train, accuracy_train, loss_valid, accuracy_valid))\n", "        history[1].append([loss_valid, accuracy_valid])\n", "        \n", "    return weights, history"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "scrolled": false, "_uuid": "5cb3502552ff369cb0870625d4c11cd5282bfc7a", "_cell_guid": "8935ff94-fd2a-4e19-9d4e-c31a47fda938", "_execution_state": "idle"}, "outputs": [], "source": ["weights = CreateWeights()\n", "\n", "alpha = 1e-3\n", "epochs = 18\n", "nbatchs = 100\n", "weights, history = run(weights, \n", "              x_train, d_train, \n", "              x_valid, d_valid, \n", "              epochs = epochs,\n", "              nbatchs=nbatchs, \n", "              alpha = alpha, \n", "              decay = 0.1, \n", "              beta1=0.9, \n", "              beta2=0.999,\n", "              eps=1e-8,\n", "              l2 = 1e-7, \n", "              keep_prop = 0.25)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "71791cb7135886bb2dacb34c78925efb278e4fcb", "_cell_guid": "ad2396a3-ebe5-46f9-9d26-3e097e4a449d"}, "outputs": [], "source": ["train_history = np.array(history[0])\n", "t_loss = train_history[:,:1]\n", "t_acc = train_history[:,1:2]"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "b80b3eae0e0dc66a73547c6e5bbba30203730e42", "_cell_guid": "614bc2a5-a316-47b5-a468-8f5524a354df"}, "outputs": [], "source": ["valid_history = np.array(history[1])\n", "train_history.shape\n", "v_loss = valid_history[:,:1]\n", "v_acc = valid_history[:,1:2]"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "7b391d16c2f9d089188d95f0b55591fa454cf403", "_cell_guid": "ef9209f3-797e-42d6-bea2-893d6ef65f7a"}, "outputs": [], "source": ["plt.figure(figsize=(12,10))\n", "\n", "plt.subplot(2, 1, 1)\n", "x = np.arange(epochs)*int(x_train.shape[0]/nbatchs)\n", "plt.plot(x,v_acc)\n", "plt.plot(t_acc)\n", "\n", "plt.subplot(2, 1, 2)\n", "plt.plot(x,v_loss)\n", "plt.plot(t_loss)\n", "\n", "plt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "211321cf0c18e8d90f2e4f3f950b46f9054e0cf4", "_cell_guid": "2536ea72-bc6d-4ecb-9129-90ea5187605d"}, "outputs": [], "source": ["def plot_confusion_matrix(cm, classes,\n", "                          normalize=False,\n", "                          title='Confusion matrix',\n", "                          cmap=plt.cm.Blues):\n", "    \"\"\"\n", "    This function prints and plots the confusion matrix.\n", "    Normalization can be applied by setting `normalize=True`.\n", "    \"\"\"\n", "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n", "    plt.title(title)\n", "    plt.colorbar()\n", "    tick_marks = np.arange(len(classes))\n", "    plt.xticks(tick_marks, classes, rotation=45)\n", "    plt.yticks(tick_marks, classes)\n", "\n", "    if normalize:\n", "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n", "\n", "    thresh = cm.max() / 2.\n", "    for i in range(cm.shape[0]):\n", "        for j in range(cm.shape[1]):\n", "            plt.text(j, i, cm[i, j],\n", "                     horizontalalignment=\"center\",\n", "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n", "\n", "    plt.tight_layout()\n", "    plt.ylabel('True label')\n", "    plt.xlabel('Predicted label')"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "399eb8da2804358c64f6196f8ca4fe8c7e1f5667", "_cell_guid": "082ab351-e29a-4af8-bf81-04ea38378885"}, "outputs": [], "source": ["outputs = predict(weights, x_valid)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "ccb608f239c49f4387c0e27470d23af2b302006c", "_cell_guid": "cd8797da-5a85-4220-9a21-f75f7c83ddad"}, "outputs": [], "source": ["p = np.argmax(outputs[-1],axis=1)\n", "predict_dummies = pd.get_dummies(p).as_matrix().astype('int8')\n", "\n", "cm = np.zeros((10,10)).astype(np.int64)\n", "\n", "d_valid_int = np.argmax(d_valid, axis=1)\n", "\n", "for i in range(predict_dummies.shape[0]):\n", "    cm[d_valid_int[i]] += predict_dummies[i]\n", "\n", "print(cm)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "686c0ef9f9fc15fdb3da3ce5ab172e21b038ee17", "_cell_guid": "ad306933-a0e8-4b1c-89c2-fefa324b439f"}, "outputs": [], "source": ["plot_confusion_matrix(cm, range(10))"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "e08978bdb37185c1bedd73ea32aadb027c74075a", "_cell_guid": "b1ebcbf3-caec-450a-9d15-0eddd841477d"}, "outputs": [], "source": ["s_cm = np.sum(cm,axis=0)\n", "for i in range(10):\n", "    p = cm[i][i]/s_cm[i]\n", "    print(\"%d - %.3f %%\" % (i,p))\n", "    "], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "ae65308113e168f8c59963271dec4720a8b07ef7", "_cell_guid": "fff7a62f-1b77-4f1a-8579-4f44fb5c469c", "_execution_state": "idle"}, "outputs": [], "source": ["w1,w2,w3,b1,b2,b3  = weights"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "scrolled": true, "_uuid": "90f3a35e646c16048876584a7ba1e99213393c87", "_cell_guid": "eb64115d-6e72-44e2-ad9b-ddc5495af573", "_execution_state": "idle"}, "outputs": [], "source": ["%matplotlib inline\n", "plt.figure(figsize=(12,10))\n", "\n", "y, x = 4,10\n", "for i in range(0,(y*x)):\n", "    ni = np.random.randint(0,w1.shape[1],1)[0]\n", "    plt.subplot(y, x, i+1)\n", "    plt.imshow(w1[:,ni].reshape((28,28)))\n", "\n", "plt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "f9d1e571519c9e144dea458d8c7766f4c4630305", "_cell_guid": "156fa5f4-99fb-41f2-8b5f-e7ea1f7554da", "_execution_state": "idle"}, "outputs": [], "source": ["%matplotlib inline\n", "plt.figure(figsize=(12,10))\n", "\n", "y, x = 4,10\n", "for i in range(0,(y*x)):\n", "    ni = np.random.randint(0,w2.shape[1],1)[0]\n", "    plt.subplot(y, x, i+1)\n", "    plt.imshow(w2[:,ni].reshape((20,25)))\n", "\n", "plt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "6cfb3e3a8869a9e2f74ca63a3ac9c62ebdde2ad0", "_cell_guid": "5e1b7099-c480-4ce6-a83d-e21b8932c437", "_execution_state": "idle"}, "outputs": [], "source": ["%matplotlib inline\n", "plt.figure(figsize=(12,10))\n", "\n", "y, x = 1,10\n", "for i in range(0,(y*x)):\n", "    plt.subplot(y, x, i+1)\n", "    plt.imshow(w3[:,i].reshape((20,15)))\n", "\n", "plt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "3e9bc190fb7f15b43a449600ee77f9be7c4deaba", "_cell_guid": "751a050e-2838-4b8f-a528-c49d50e585ff", "_execution_state": "idle"}, "outputs": [], "source": ["outputs = predict(weights, test)\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "d804ca60bee49063a1875eb57e4d966f80e23b68", "_cell_guid": "1bd72876-518a-44ff-a4d8-b6655bb043f0", "_execution_state": "idle"}, "outputs": [], "source": ["d = np.argmax(outputs[-1],axis=1)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "4d411779ef4acaabf4853e064995f3fb97259e79", "_cell_guid": "706f81ff-1c50-4394-bf66-598824347064"}, "outputs": [], "source": ["\n", "\n", "def show_image(image, shape, label=\"\", cmp=None):\n", "    img = np.reshape(image,shape)\n", "    plt.imshow(img,cmap=cmp, interpolation='none')\n", "    plt.title(label)\n", "    \n", "\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "e2a3dbcaaadd8a3c85a0a51d8f75da8b721507cf", "_cell_guid": "d5131c97-26b6-41bc-b8bb-440c4353df67", "_execution_state": "idle"}, "outputs": [], "source": ["%matplotlib inline\n", "plt.figure(figsize=(20,12))\n", "\n", "y, x = 5,11\n", "for i in range(0,(y*x)):\n", "    plt.subplot(y, x, i+1)\n", "    ni = np.random.randint(0,test.shape[0],1)[0]\n", "    v = str(d[ni])\n", "    show_image(test[ni],(28,28), v, cmp=\"gray\")\n", "plt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "49dca1ec26ac9b6f3c7e5425a74d1f9472a66f61", "_cell_guid": "9ee8814b-6ade-499e-94c5-050e85801e0b", "_execution_state": "idle"}, "outputs": [], "source": ["#ImageId,Label\n", "\n", "pd.DataFrame({\"ImageId\": list(range(1,len(d)+1)), \"Label\": d}).to_csv('output.csv', index=False, header=True)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "7ba2dc5e498f5913d188f20f41a29c2896d5963a", "_cell_guid": "b4d15e48-bd8b-4471-9f7f-16770a9f7a28", "_execution_state": "idle"}, "source": ["## REFERENCES\n", "\n", "http://cs231n.github.io/neural-networks-3/"], "cell_type": "markdown"}]}