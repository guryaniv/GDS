{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3ede2b94-76f2-b9d3-7c89-8f0075c7c039"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
        "GradientBoostingClassifier, ExtraTreesClassifier)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cross_validation import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "047b8123-5dfd-23a3-59b3-df1af8a3c604"
      },
      "outputs": [],
      "source": [
        "#Print you can execute arbitrary python code\n",
        "train = pd.read_csv(\"../input/train.csv\", dtype={\"Age\": np.float64}, )\n",
        "test = pd.read_csv(\"../input/test.csv\", dtype={\"Age\": np.float64}, )\n",
        "PassengerId = test['PassengerId']\n",
        "combine = [train, test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5a981aaa-04c3-0507-dc63-9cfdf37cc2d4"
      },
      "outputs": [],
      "source": [
        "#Method for finding substrings\n",
        "def substrings_in_string(big_string, substrings):\n",
        "    for substring in substrings:\n",
        "        if substring in big_string:\n",
        "            return substring\n",
        "    return np.nan\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f9cd6778-e575-56f8-693a-55bdc4f1f00f"
      },
      "outputs": [],
      "source": [
        "#Mappings\n",
        "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n",
        "                    'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\n",
        "                    'Don', 'Jonkheer']\n",
        "\n",
        "cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\n",
        "\n",
        "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bf1183a7-284a-f0be-cc89-5d82ea991313"
      },
      "outputs": [],
      "source": [
        "#Passenger Class is 3, so fill nan row with the mode\n",
        "fare_mode = test[test['Pclass']==3]['Fare'].mode()\n",
        "test['Fare'] = test['Fare'].fillna(fare_mode[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "44dddfda-846f-1194-d6ce-141414ee5f51"
      },
      "outputs": [],
      "source": [
        "#Find the mode of embarked of passengers with the same class and similar fare\n",
        "emb_mode = train[(train['Pclass']==1)&(train['Fare']<=85)&(train['Fare']>75)]['Embarked'].mode()\n",
        "train['Embarked'] = train['Embarked'].fillna(emb_mode[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "55240904-aacc-114b-24a8-78606e6075ad"
      },
      "outputs": [],
      "source": [
        "for df in combine:\n",
        "    # Convert the male and female groups to integer form\n",
        "    df[\"Sex\"][df[\"Sex\"] == \"male\"] = 0\n",
        "    df[\"Sex\"][df[\"Sex\"] == \"female\"] = 1\n",
        "    \n",
        "    #Map and Create Title Feature\n",
        "    df['Title'] = df['Name'].astype(str).map(lambda x: substrings_in_string(x, title_list))\n",
        "    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
        " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
        "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
        "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
        "    df['Title'] = df['Title'].map(title_mapping)\n",
        "    df['Title'] = df['Title'].fillna(0)\n",
        "    \n",
        "    #Map and Create Deck feature\n",
        "    df['Deck'] = df['Cabin'].astype(str).map(lambda x: substrings_in_string(x, cabin_list))\n",
        "    df[\"Deck\"][df[\"Deck\"] == \"A\"] = 1\n",
        "    df[\"Deck\"][df[\"Deck\"] == \"B\"] = 2\n",
        "    df[\"Deck\"][df[\"Deck\"] == \"C\"] = 3\n",
        "    df[\"Deck\"][df[\"Deck\"] == \"D\"] = 4\n",
        "    df[\"Deck\"][df[\"Deck\"] == \"E\"] = 5\n",
        "    df[\"Deck\"][df[\"Deck\"] == \"F\"] = 6\n",
        "    df[\"Deck\"][df[\"Deck\"] == \"G\"] = 7\n",
        "    df[\"Deck\"][df[\"Deck\"] == \"T\"] = 8\n",
        "    df[\"Deck\"] = df[\"Deck\"].fillna(0)\n",
        "    \n",
        "    #Create Family size, Fare per person, and isAlone features\n",
        "    df['Family_size'] = df['SibSp']+df['Parch']+1\n",
        "    \n",
        "    #Create isAlone feature based off family size\n",
        "    df['isAlone']=0\n",
        "    df.loc[df['Family_size']==1, 'isAlone'] = 1\n",
        "    \n",
        "    # Convert the Embarked classes to integer form\n",
        "    df[\"Embarked\"][df[\"Embarked\"] == \"S\"] = 0\n",
        "    df[\"Embarked\"][df[\"Embarked\"] == \"C\"] = 1\n",
        "    df[\"Embarked\"][df[\"Embarked\"] == \"Q\"] = 2\n",
        "\n",
        "    #Impute Age based off random numbers in one standard deviation from the mean\n",
        "    age_avg = df['Age'].mean()\n",
        "    age_std = df['Age'].std()\n",
        "    age_null_count = df['Age'].isnull().sum()\n",
        "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
        "    df['Age'][np.isnan(df['Age'])] = age_null_random_list\n",
        "    \n",
        "    # Mapping Age and removing child feature\n",
        "    df.loc[ df['Age'] <= 16, 'Age'] \t\t\t\t\t= 0\n",
        "    df.loc[(df['Age'] > 16) & (df['Age'] <= 32), 'Age'] = 1\n",
        "    df.loc[(df['Age'] > 32) & (df['Age'] <= 48), 'Age'] = 2\n",
        "    df.loc[(df['Age'] > 48) & (df['Age'] <= 64), 'Age'] = 3\n",
        "    df.loc[ df['Age'] > 64, 'Age']                      = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fa402556-7252-0649-51d9-47ea1398eb0c"
      },
      "outputs": [],
      "source": [
        "#Create target feature set\n",
        "excl = ['PassengerId', 'Ticket', 'Cabin', 'Name', 'SibSp', 'Parch']\n",
        "train = train.drop(excl, axis = 1)\n",
        "test  = test.drop(excl, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "069917c4-ea61-c5d9-719c-2826f21626e1"
      },
      "outputs": [],
      "source": [
        "corr = train.corr()\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(corr, vmax=1, annot=True, square=True)\n",
        "plt.title('feature correlations')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e3f6b3d0-f346-84a2-de02-a3f588055405"
      },
      "outputs": [],
      "source": [
        "#Set parameters for ensembling\n",
        "ntrain = train.shape[0]\n",
        "ntest = test.shape[0]\n",
        "seed = 10\n",
        "nfolds = 5\n",
        "kf = KFold(ntrain, n_folds = nfolds, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "556bb52e-a7a2-e459-2d5d-188835aa4a15"
      },
      "outputs": [],
      "source": [
        "#Sklearn custom class\n",
        "\n",
        "class SklearnHandler(object):\n",
        "    def __init__(self, clf, seed=0, params=None):\n",
        "        params['random_state'] = seed\n",
        "        self.clf = clf(**params)\n",
        "        \n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "        \n",
        "    def predict(self, x):\n",
        "        return self.clf.predict(x)\n",
        "    \n",
        "    def fit(self, x, y):\n",
        "        return self.clf.fit(x,y)\n",
        "    \n",
        "    def feature_importances(self, x, y):\n",
        "        return self.clf.fit(x, y).feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5aac09bf-107e-6710-488a-fdbc57ec5392"
      },
      "outputs": [],
      "source": [
        "#Class to get out-of-fold predictions\n",
        "def get_oof(clf, x_train, y_train, x_test):\n",
        "    oof_train = np.zeros((ntrain,))\n",
        "    oof_test = np.zeros((ntest,))\n",
        "    oof_test_skf = np.empty((nfolds, ntest))\n",
        "    \n",
        "    for i, (train_index, test_index) in enumerate(kf):\n",
        "        x_tr = x_train[train_index]\n",
        "        y_tr = y_train[train_index]\n",
        "        x_te = x_train[test_index]\n",
        "        \n",
        "        clf.train(x_tr, y_tr)\n",
        "        \n",
        "        oof_train[test_index] = clf.predict(x_te)\n",
        "        oof_test_skf[i, :] = clf.predict(x_test)\n",
        "        \n",
        "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
        "    return oof_train.reshape(-1,1), oof_test.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f282ee5f-a851-03c9-a562-4f04bb214bf2"
      },
      "outputs": [],
      "source": [
        "#Create parameters for all classifiers\n",
        "#Random Forest parameters\n",
        "rf_params = {\n",
        "    'n_jobs': -1,\n",
        "    'n_estimators': 1000,\n",
        "    'warm_start': True,\n",
        "    'max_depth': 6,\n",
        "    'min_samples_leaf': 2,\n",
        "    'max_features' : 'sqrt',\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "#Extra Trees Parameters\n",
        "et_params = {\n",
        "    'n_jobs': -1,\n",
        "    'n_estimators':1000,\n",
        "    'max_depth': 9,\n",
        "    'min_samples_split': 6,\n",
        "    'min_samples_leaf': 4,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "#AdaBoost parameters\n",
        "ada_params = {\n",
        "    'n_estimators': 1000,\n",
        "    'learning_rate' : 0.75\n",
        "}\n",
        "\n",
        "#Gradient Boosting parameters\n",
        "gb_params = {\n",
        "    'n_estimators': 1000,\n",
        "    'max_depth': 5,\n",
        "    'min_samples_leaf': 2,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "#Support Vector Classifier parameters \n",
        "svc_params = {\n",
        "    'kernel' : 'linear',\n",
        "    'C' : 0.025\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fb04b468-8ba0-df57-a941-6e15ffde3c8c"
      },
      "outputs": [],
      "source": [
        "#Create models\n",
        "rf = SklearnHandler(clf=RandomForestClassifier, seed=seed, params=rf_params)\n",
        "et = SklearnHandler(clf=ExtraTreesClassifier, seed=seed, params=et_params)\n",
        "ada = SklearnHandler(clf=AdaBoostClassifier, seed=seed, params=ada_params)\n",
        "gb = SklearnHandler(clf=GradientBoostingClassifier, seed=seed, params=gb_params)\n",
        "svc = SklearnHandler(clf=SVC, seed=seed, params=svc_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f0b958c1-6af0-4522-cb0f-5dc7965ac16f"
      },
      "outputs": [],
      "source": [
        "#Create arrays for the models\n",
        "y_train = train['Survived'].ravel()\n",
        "train = train.drop(['Survived'], axis=1)\n",
        "x_train = train.values\n",
        "x_test = test.values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2d448d88-b787-9794-6bb9-82e8c0e26a27"
      },
      "outputs": [],
      "source": [
        "#Create our OOF train and test predictions. These base results will be used as new features\n",
        "et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\n",
        "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
        "ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \n",
        "gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\n",
        "svc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier\n",
        "\n",
        "print(\"Training is complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "27e32edf-a85b-39ce-fdb5-e20c0ed65444"
      },
      "outputs": [],
      "source": [
        "rf_feature = rf.feature_importances(x_train,y_train)\n",
        "et_feature = et.feature_importances(x_train, y_train)\n",
        "ada_feature = ada.feature_importances(x_train, y_train)\n",
        "gb_feature = gb.feature_importances(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "03eb4c4b-03d9-7e34-f664-0af573b7cf4d"
      },
      "outputs": [],
      "source": [
        "cols = train.columns.values\n",
        "#Create a dataframe with features\n",
        "feature_dataframe = pd.DataFrame( {'features': cols,\n",
        "     'Random Forest feature importances': rf_feature,\n",
        "     'Extra Trees  feature importances': et_feature,\n",
        "      'AdaBoost feature importances': ada_feature,\n",
        "    'Gradient Boost feature importances': gb_feature\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "330228b3-0659-2e33-1755-55c52a43f5d3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(feature_dataframe['features'], feature_dataframe['Random Forest feature importances'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "98bf73c3-62ca-7982-d1e3-4853a3ac35c2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(feature_dataframe['features'], feature_dataframe['Extra Trees  feature importances'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2e8262cd-2c01-af94-8d50-84259f5fd615"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(feature_dataframe['features'], feature_dataframe['AdaBoost feature importances'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "443bb8e7-a739-c623-0e1c-7da80eade7c3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(feature_dataframe['features'], feature_dataframe['Gradient Boost feature importances'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c66797b2-804e-2e0c-a2a3-569772da07a5"
      },
      "outputs": [],
      "source": [
        "#Create the new column containing the average of values\n",
        "\n",
        "feature_dataframe['mean'] = feature_dataframe.mean(axis= 1) # axis = 1 computes the mean row-wise\n",
        "feature_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2ecbd240-5e33-ec80-3f06-4d355f3430ab"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(feature_dataframe['features'], feature_dataframe['mean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a4ff943-89b9-2a6f-2d30-955cf9c339e7"
      },
      "outputs": [],
      "source": [
        "base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n",
        "     'ExtraTrees': et_oof_train.ravel(),\n",
        "     'AdaBoost': ada_oof_train.ravel(),\n",
        "      'GradientBoost': gb_oof_train.ravel()\n",
        "    })\n",
        "base_predictions_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "36f8f61b-c951-a151-d613-96e6393f9ede"
      },
      "outputs": [],
      "source": [
        "corr = base_predictions_train.astype(float).corr()\n",
        "plt.figure(figsize=(15,15))\n",
        "sns.heatmap(corr, vmax=1, annot=True, square=True)\n",
        "plt.title('feature correlations')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1654b26e-bc85-4389-a298-12ec669ce17b"
      },
      "outputs": [],
      "source": [
        "x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)\n",
        "x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aa2dc209-c188-2207-5a90-cb388122d837"
      },
      "outputs": [],
      "source": [
        "gbm = xgb.XGBClassifier(\n",
        " n_estimators= 2000,\n",
        " max_depth= 4,\n",
        " min_child_weight= 2,\n",
        " gamma=0.9,                        \n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " objective= 'binary:logistic',\n",
        " nthread= -1,\n",
        " scale_pos_weight=1).fit(x_train, y_train)\n",
        "predictions = gbm.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7c4f921a-a763-22a9-1b12-38fb9f93a6f4"
      },
      "outputs": [],
      "source": [
        "# Generate Submission File \n",
        "StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,\n",
        "                            'Survived': predictions })\n",
        "StackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}