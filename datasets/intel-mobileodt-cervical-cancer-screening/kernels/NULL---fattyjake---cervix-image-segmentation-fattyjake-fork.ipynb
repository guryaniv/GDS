{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3ea0b9dd-1db1-38a9-dd94-6abeb8ea2846"
      },
      "source": [
        "# Cervix Image Segmentation\n",
        "\n",
        "I'd first like to say thank you to \n",
        "\n",
        "1. https://www.kaggle.com/philschmidt/intel-mobileodt-cervical-cancer-screening/cervix-eda/notebook\n",
        "2. Those competing in the Lung Cancer detection competition for the masking idea\n",
        "3. All those I have learned from in the Kaggle community and outside \n",
        "\n",
        "I hope you learn from this script and is improved upon. This is my first Kaggle kernel so please give feedback where you see appropriate :D\n",
        "\n",
        "**IF YOU KNOW A BETTER WAY TO DO A CLUSTER CROP, PLEASE LET ME KNOW :)**\n",
        "\n",
        "One of the first things I noticed about the images is that there are borders of a \"random\" width/height that contain no \"information\". We really want to reduce the data to just the necessary components, ie. the cervix in this instance. AFAIK, all other parts of the picture provide no information that will help our classifier.\n",
        "\n",
        "From here I looked into medical imaging but saw k-means clustering with cv2 seemed to handle the task pretty well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "25a8d891-7d0e-7edd-1886-8b5f3423ea33"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from skimage.io import imread, imshow\n",
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "from subprocess import check_output\n",
        "\n",
        "\n",
        "TRAIN_DATA = \"../input/train\"\n",
        "type_1_files = glob(os.path.join(TRAIN_DATA, \"Type_1\", \"*.jpg\"))\n",
        "type_1_ids = np.array([s[len(os.path.join(TRAIN_DATA, \"Type_1\"))+1:-4] for s in type_1_files])\n",
        "type_2_files = glob(os.path.join(TRAIN_DATA, \"Type_2\", \"*.jpg\"))\n",
        "type_2_ids = np.array([s[len(os.path.join(TRAIN_DATA, \"Type_2\"))+1:-4] for s in type_2_files])\n",
        "type_3_files = glob(os.path.join(TRAIN_DATA, \"Type_3\", \"*.jpg\"))\n",
        "type_3_ids = np.array([s[len(os.path.join(TRAIN_DATA, \"Type_3\"))+1:-4] for s in type_3_files])\n",
        "\n",
        "\n",
        "\n",
        "TEST_DATA = \"../input/test\"\n",
        "test_files = glob(os.path.join(TEST_DATA, \"*.jpg\"))\n",
        "test_ids = np.array([s[len(TEST_DATA)+1:-4] for s in test_files])\n",
        "\n",
        "\n",
        "ADDITIONAL_DATA = \"../input/additional\"\n",
        "additional_type_1_files = glob(os.path.join(ADDITIONAL_DATA, \"Type_1\", \"*.jpg\"))\n",
        "additional_type_1_ids = np.array([s[len(os.path.join(ADDITIONAL_DATA, \"Type_1\"))+1:-4] for s in additional_type_1_files])\n",
        "additional_type_2_files = glob(os.path.join(ADDITIONAL_DATA, \"Type_2\", \"*.jpg\"))\n",
        "additional_type_2_ids = np.array([s[len(os.path.join(ADDITIONAL_DATA, \"Type_2\"))+1:-4] for s in additional_type_2_files])\n",
        "additional_type_3_files = glob(os.path.join(ADDITIONAL_DATA, \"Type_3\", \"*.jpg\"))\n",
        "additional_type_3_ids = np.array([s[len(os.path.join(ADDITIONAL_DATA, \"Type_3\"))+1:-4] for s in additional_type_3_files])\n",
        "\"\"\"\n",
        "CROP_DATA = \"../input/to_crop\"\n",
        "crop_type_1_files = glob(os.path.join(CROP_DATA, \"Type_1\", \"*.jpg\"))\n",
        "crop_type_1_ids = np.array([s[len(os.path.join(CROP_DATA, \"Type_1\"))+1:-4] for s in crop_type_1_files])\n",
        "crop_type_2_files = glob(os.path.join(CROP_DATA, \"Type_2\", \"*.jpg\"))\n",
        "crop_type_2_ids = np.array([s[len(os.path.join(CROP_DATA, \"Type_2\"))+1:-4] for s in crop_type_2_files])\n",
        "crop_type_3_files = glob(os.path.join(CROP_DATA, \"Type_3\", \"*.jpg\"))\n",
        "crop_type_3_ids = np.array([s[len(os.path.join(CROP_DATA, \"Type_3\"))+1:-4] for s in crop_type_3_files])\n",
        "\n",
        "CROP_EDGE_DATA = \"../input/to_crop_edge\"\n",
        "crop_edge_type_1_files = glob(os.path.join(CROP_EDGE_DATA, \"Type_1\", \"*.jpg\"))\n",
        "crop_edge_type_1_ids = np.array([s[len(os.path.join(CROP_EDGE_DATA, \"Type_1\"))+1:-4] for s in crop_edge_type_1_files])\n",
        "crop_edge_type_2_files = glob(os.path.join(CROP_EDGE_DATA, \"Type_2\", \"*.jpg\"))\n",
        "crop_edge_type_2_ids = np.array([s[len(os.path.join(CROP_EDGE_DATA, \"Type_2\"))+1:-4] for s in crop_edge_type_2_files])\n",
        "crop_edge_type_3_files = glob(os.path.join(CROP_EDGE_DATA, \"Type_3\", \"*.jpg\"))\n",
        "crop_edge_type_3_ids = np.array([s[len(os.path.join(CROP_EDGE_DATA, \"Type_3\"))+1:-4] for s in crop_edge_type_3_files])\n",
        "\n",
        "\n",
        "Only do the first 20 for computational constraint reasons\n",
        "\"\"\"\n",
        "type_1_ids = type_1_ids[:20]\n",
        "#crop_type_1_ids = crop_type_1_ids[:30]\n",
        "\n",
        "def get_filename(image_id, image_type):\n",
        "    \"\"\"\n",
        "    Method to get image file path from its id and type   \n",
        "    \"\"\"\n",
        "    if image_type == \"Type_1\" or \\\n",
        "        image_type == \"Type_2\" or \\\n",
        "        image_type == \"Type_3\":\n",
        "        data_path = os.path.join(TRAIN_DATA, image_type)\n",
        "    elif image_type == \"Test\":\n",
        "        data_path = TEST_DATA\n",
        "    elif image_type == \"AType_1\" or \\\n",
        "          image_type == \"AType_2\" or \\\n",
        "          image_type == \"AType_3\":\n",
        "        data_path = os.path.join(ADDITIONAL_DATA, image_type)\n",
        "    else:\n",
        "        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n",
        "\n",
        "    ext = 'jpg'\n",
        "    return os.path.join(data_path, \"{}.{}\".format(image_id, ext))\n",
        "\n",
        "def get_image_data(image_id, image_type):\n",
        "    \"\"\"\n",
        "    Method to get image data as np.array specifying image id and type\n",
        "    \"\"\"\n",
        "    fname = get_filename(image_id, image_type)\n",
        "    img = cv2.imread(fname)\n",
        "    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\"\"\"\n",
        "crop_type_1_ids = ['176' '810' '102' '1468' '1464' '1251' '1202' '1226' '991' '846' '873'\n",
        " '539' '1014' '1393' '764' '643' '1427' '1019' '551' '769' '891' '484'\n",
        " '160' '471' '802' '578' '205' '928' '677' '1027' '787' '523' '809' '1194'\n",
        " '759' '262' '763' '342' '649' '387' '1061' '48' '1239' '536' '446' '311'\n",
        " '1326' '791' '663' '12' '518' '1070' '1190' '338' '379' '685' '895' '739'\n",
        " '972' '7' '245' '1314' '1273' '401' '441' '265' '558' '906' '55' '732'\n",
        " '1026' '1134' '1279' '138' '1285' '965' '814' '1384' '593' '1093' '645'\n",
        " '334' '1223' '623' '1131' '516' '230' '1105' '984' '576' '1056' '497'\n",
        " '1077' '1229' '930' '239' '104' '109' '349' '709' '908' '668' '376' '683'\n",
        " '454' '333' '215' '144' '1033' '469' '1100' '532' '1245' '1136' '1199'\n",
        " '1389' '1040' '879' '356' '880' '725' '267' '1024' '1308' '35' '836' '298'\n",
        " '281' '1220' '745' '620' '855' '817' '1288' '1281' '478' '1320' '553'\n",
        " '142' '653' '596' '208' '619' '47' '1274' '560' '1154' '580' '624' '1059'\n",
        " '308' '57' '982' '434' '1324' '1071' '481' '470' '821' '1161' '1437' '562'\n",
        " '579' '10' '887' '1440' '416' '1346' '1204' '667' '783' '14' '605' '1414'\n",
        " '0' '708' '713' '779' '1013' '396' '1179' '805' '1174' '1344' '641' '765'\n",
        " '248' '41' '254' '34' '660' '513' '463' '901' '1473' '27' '700']\n",
        " \"\"\"\n",
        "def plt_st(l1,l2):\n",
        "    plt.figure(figsize=(l1,l2))\n",
        "\n",
        "#tile_size = (256, 256)\n",
        "#tile_size=(54, 54) # last_good\n",
        "tile_size=(34,34)\n",
        "n = 15\n",
        "\n",
        "print(check_output([\"ls\", \"../input/train\"]).decode(\"utf8\"))\n",
        "print(len(additional_type_1_files), len(additional_type_2_files), len(additional_type_2_files))\n",
        "print(\"Type 1\", additional_type_1_ids[:10])\n",
        "print(\"Type 2\", additional_type_2_ids[:10])\n",
        "print(\"Type 3\", additional_type_3_ids[:10])\n",
        "#print(crop_type_1_ids) # from manually selecting images that are not solely the cervix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3115f95a-89ad-470d-dde2-e17f8b1cec48"
      },
      "outputs": [],
      "source": [
        "def mask_black_bkgd(img):\n",
        "    #Invert the image to be white on black for compatibility with findContours function.\n",
        "\n",
        "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    #Binarize the image and call it thresh.\n",
        "    ret, thresh = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    #Find all the contours in thresh. In your case the 3 and the additional strike\n",
        "    im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    #Calculate bounding rectangles for each contour.\n",
        "    rects = [cv2.boundingRect(cnt) for cnt in contours]\n",
        "\n",
        "    #Calculate the combined bounding rectangle points.\n",
        "    top_x = min([x for (x, y, w, h) in rects])\n",
        "    top_y = min([y for (x, y, w, h) in rects])\n",
        "    bottom_x = max([x+w for (x, y, w, h) in rects])\n",
        "    bottom_y = max([y+h for (x, y, w, h) in rects])\n",
        "\n",
        "    #Draw the rectangle on the image\n",
        "    out = cv2.rectangle(img, (top_x, top_y), (bottom_x, bottom_y), (0, 255, 0), 2)\n",
        "    crop = img[top_y:bottom_y,top_x:bottom_x]\n",
        "    return crop #thresh\n",
        "    \n",
        "complete_images = []\n",
        "for k, type_ids in enumerate([type_1_ids]): #, type_2_ids, type_3_ids]):\n",
        "    m = int(np.floor(len(type_ids) / n))\n",
        "    complete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n",
        "    train_ids = sorted(type_ids)\n",
        "    counter = 0\n",
        "    for i in range(m):\n",
        "        ys = i*(tile_size[1] + 2)\n",
        "        ye = ys + tile_size[1]\n",
        "        for j in range(n):\n",
        "            xs = j*(tile_size[0] + 2)\n",
        "            xe = xs + tile_size[0]\n",
        "            image_id = train_ids[counter]; counter+=1\n",
        "            img = get_image_data(image_id, 'Type_%i' % (k+1))\n",
        "            img = cv2.resize(img, dsize=tile_size)\n",
        "            #img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255, 255, 255), thickness=3)\n",
        "            complete_image[ys:ye, xs:xe] = cv2.resize(mask_black_bkgd(img[:,:,:]), dsize=tile_size)\n",
        "    complete_images.append(complete_image)\n",
        "\n",
        "plt_st(20, 20)\n",
        "plt.imshow(complete_images[0])\n",
        "plt.title(\"Training dataset of type %i\" % (1))\n",
        "\n",
        "complete_images = []\n",
        "for k, type_ids in enumerate([type_1_ids]): #, type_2_ids, type_3_ids]):\n",
        "    m = int(np.floor(len(type_ids) / n))\n",
        "    complete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n",
        "    train_ids = sorted(type_ids)\n",
        "    counter = 0\n",
        "    for i in range(m):\n",
        "        ys = i*(tile_size[1] + 2)\n",
        "        ye = ys + tile_size[1]\n",
        "        for j in range(n):\n",
        "            xs = j*(tile_size[0] + 2)\n",
        "            xe = xs + tile_size[0]\n",
        "            image_id = train_ids[counter]; counter+=1\n",
        "            img = get_image_data(image_id, 'Type_%i' % (k+1))\n",
        "            img = cv2.resize(img, dsize=tile_size)\n",
        "            #img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255, 255, 255), thickness=3)\n",
        "            complete_image[ys:ye, xs:xe] = img[:,:,:]\n",
        "    complete_images.append(complete_image)\n",
        "\n",
        "plt_st(20, 20)\n",
        "plt.imshow(complete_images[0])\n",
        "plt.title(\"Training dataset of type %i\" % (1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c98f9f85-87e5-0aa1-7bff-8c075eb21f31"
      },
      "source": [
        "Thanks @Allunia. Looking into gaussian mixtures now. Kernels seem to be acting up. Images arent coming out now when I publish and restarting duplicates my code"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}