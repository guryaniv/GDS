{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d9f1d173-44d1-e7b8-ade3-aca0d125c53a"
      },
      "source": [
        "This code trains decision tree, neural networks and random forest to distinguish between fraud and non-fraud credit card transations. The code is divided in three parts:\n",
        "\n",
        " 1. Analyse the data directly and study the accuracy, confusion matrix and F1 score\n",
        " 2. Analyse part of the data, generating a symmetric data (# fraud=#non-fraud)\n",
        " 3. Drop features which are not adding information to the data\n",
        "\n",
        "The fit quality of point 2. and 3. are also calculated using cross validation of each method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "582aea97-1c8d-4391-8885-9324e013eaf9"
      },
      "source": [
        "# Part 1:\n",
        "Analyse the data directly and study the accuracy, confusion matrix and F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "801bc995-36ed-9e31-5a74-41a65845278e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "23f32d74-930a-6ac5-5d90-a6018c7d0766"
      },
      "source": [
        "Open the data file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0cb23dd6-eb4a-a0c2-844c-1ee9cf945282"
      },
      "outputs": [],
      "source": [
        "data_df = pd.read_csv('../input/creditcard.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eaa58b14-9680-70c7-1508-b5466ad5743a"
      },
      "outputs": [],
      "source": [
        "data_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "24b0cfe5-e33f-78f8-0548-45b78165551c"
      },
      "outputs": [],
      "source": [
        "#check if the df contains any NaN values\n",
        "\n",
        "data_df.isnull().values.any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "944558e1-4c31-ba6f-30c8-96c4542f52a7"
      },
      "source": [
        "First, lets identify how many classes there are and how many correspond to each"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a977b7d4-d996-7718-e56a-1bb4661be498"
      },
      "outputs": [],
      "source": [
        "classes = data_df.Class.unique()\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b201f2d3-0a23-2c95-59ce-c9e75b67940d"
      },
      "outputs": [],
      "source": [
        "print('class corresponding to non-fraud', classes[0],': ', len(data_df[data_df.Class==classes[0]]))\n",
        "print('class corresponding to fraud', classes[1],': ', len(data_df[data_df.Class==classes[1]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ea61baa3-cca9-8cfe-2b2d-3d6788cd8e73"
      },
      "source": [
        "There is such a large asymmetry between 'fraud' and 'non-fraud',that the algorithm will be completely biased for class 0. This will give us an amazing accuracy, as most of the data points will be confused by 'non-fraud' after running the algorith. This can be seen looking at the confusion matrix and F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "74db69cb-56a0-1840-a5c2-1f4f606a4fec"
      },
      "outputs": [],
      "source": [
        "#transform the dataframe to an array\n",
        "data = data_df.as_matrix()\n",
        "\n",
        "X_data = data[:,:(data_df.shape[1]-1)]\n",
        "y_data = data[:,(data_df.shape[1]-1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6813f4a3-67cb-8c53-6b34-05266848b4fd"
      },
      "outputs": [],
      "source": [
        "#split the data into training and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_data_train, X_data_test, y_data_train, y_data_test = train_test_split(X_data, y_data, test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "17e4b1fe-fd4f-7067-a860-5ab7dea4b66f"
      },
      "outputs": [],
      "source": [
        "#scale the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_data_train = scaler.fit_transform(X_data_train)\n",
        "X_data_test = scaler.fit_transform(X_data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2e41112f-cf81-d552-0d50-1631dd7b9720"
      },
      "outputs": [],
      "source": [
        "#train using neural networks\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "#fit decision tree classifier\n",
        "model_nn = MLPClassifier(hidden_layer_sizes=2, max_iter=2000)\n",
        "model_nn.fit(X_data_train, y_data_train)\n",
        "\n",
        "#predict 'y' for test data\n",
        "y_data_pred_test = model_nn.predict(X_data_test)\n",
        "\n",
        "#score\n",
        "print('Accuracy: ', accuracy_score(y_data_test, y_data_pred_test))\n",
        "print('confusion matrix:', confusion_matrix(y_data_test, y_data_pred_test))\n",
        "print('F1:', f1_score(y_data_test, y_data_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "22db7da6-d686-f9e9-1d12-2d5ffecbacda"
      },
      "source": [
        "The accuracy is pretty good (as expected). Nevertheless the F1 score can be substantially improved. \n",
        "But what happens if we reduce the amount of 'non-fraud' data for symmetry?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "156404d2-2a4b-8d0e-f1cb-b12182493217"
      },
      "source": [
        "# Part 2:\n",
        "Analyse part of the data, generating a symmetric data (# fraud=#non-fraud)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "94bb0ddc-b5cf-a28a-4394-6830e6cd3b7e"
      },
      "outputs": [],
      "source": [
        "#this is the data corresponding to fraud\n",
        "data_fraud_df = data_df[data_df.Class==classes[1]]\n",
        "data_fraud_df = data_fraud_df.reset_index(drop=True)\n",
        "data_fraud = data_fraud_df.as_matrix()\n",
        "\n",
        "\n",
        "#this is the data corresponding to non-fraud\n",
        "data_nonfraud_df = data_df[data_df.Class==classes[0]]\n",
        "data_nonfraud_df = data_nonfraud_df.reset_index(drop=True)\n",
        "data_red_nonfraud_df = \\\n",
        "    data_nonfraud_df.ix[np.random.random_integers(1, max(data_nonfraud_df.index),max(data_fraud_df.index)+1)]\n",
        "data_red_nonfraud_df = data_red_nonfraud_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06ab2f16-48b0-1eae-534e-ddd70fddbf28"
      },
      "outputs": [],
      "source": [
        "#now lets join both fraud and non-fraud of the same length\n",
        "data_red_df = pd.concat([data_red_nonfraud_df, data_fraud_df])\n",
        "data_red = data_red_df.as_matrix()\n",
        "\n",
        "X_data_red = data_red[:,:(data_red_df.shape[1]-1)]\n",
        "y_data_red = data_red[:,(data_red_df.shape[1]-1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "58ba6720-1650-9eca-dc4e-9806c0caa2c4"
      },
      "outputs": [],
      "source": [
        "#define train and test of the symmetric data\n",
        "X_data_red_train, X_data_red_test, y_data_red_train, y_data_red_test =\\\n",
        "            train_test_split(X_data_red, y_data_red, test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3fa7ee41-14a5-2d86-0922-c28114ce9c5d"
      },
      "outputs": [],
      "source": [
        "#scale the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_data_red_train = scaler.fit_transform(X_data_red_train)\n",
        "X_data_red_test = scaler.fit_transform(X_data_red_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ece7899a-11cb-b9cd-e446-4fd9800c1550"
      },
      "outputs": [],
      "source": [
        "#again, lets use neural networks\n",
        "\n",
        "model_nn.fit(X_data_red_train, y_data_red_train)\n",
        "\n",
        "#predict 'y' for test data\n",
        "y_data_red_pred_test = model_nn.predict(X_data_red_test)\n",
        "\n",
        "#score\n",
        "print('Accuracy: ', accuracy_score(y_data_red_test, y_data_red_pred_test))\n",
        "print('confusion matrix:', confusion_matrix(y_data_red_test, y_data_red_pred_test))\n",
        "print('F1:', f1_score(y_data_red_test, y_data_red_pred_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "89d307a6-8cc5-fed9-142d-16c313953766"
      },
      "outputs": [],
      "source": [
        "#lets look at the cross validation\n",
        "from sklearn.cross_validation import cross_val_score, KFold\n",
        "from scipy.stats import sem\n",
        "\n",
        "cv = KFold(len(y_data_red_pred_test), 5, shuffle=True, random_state=0)\n",
        "# by default the score used is the one returned by score method of the estimator (accuracy)\n",
        "scores = cross_val_score(model_nn, X_data_red_test, y_data_red_pred_test, cv=cv)\n",
        "print(scores)\n",
        "print(\"Mean score: {0:.3f} (+/-{1:.3f})\".format(np.mean(scores), sem(scores)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a4f3987e-78f9-1759-ef09-79608a6f7687"
      },
      "source": [
        "The F1 and confusion matrix have already improved. Furthermore, the cv looks pretty good already! Nevertheless, lets look if this can still be further improved. \n",
        "\n",
        "It is interesting to visualise the data to see if there are particular features which can improve the classification. Hence\n",
        "\n",
        " - We will reduce the dimension of the features to visualize how good the classification currently is\n",
        " - We will visualise the different features and chose the ones which can improve the classification and drop all the other features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0b33b073-c87f-e5c5-3d5d-324548065a91"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import Isomap\n",
        "iso = Isomap(n_neighbors=30, n_components=2)\n",
        "\n",
        "#project the data to 2-dimension features\n",
        "iso.fit(X_data_red_train[:50,:])\n",
        "Xdata_red_projected = iso.transform(X_data_red_train)\n",
        "\n",
        "#visualise the data\n",
        "plt.scatter(Xdata_red_projected[:, 0], Xdata_red_projected[:, 1], c=y_data_red_train,\n",
        "            edgecolor='none', alpha=0.5,\n",
        "            cmap=plt.cm.get_cmap('nipy_spectral'))\n",
        "\n",
        "plt.clim(-0.5, 9.5);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0927f0f3-35dd-9f5a-7f9d-5adaa108b5a6"
      },
      "source": [
        "# Part 3: Feature reduction\n",
        "Will this improve our result?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bc2384e7-2e71-b3e4-bd29-a5e6eb5a2c3b"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns; sns.set()\n",
        "sns.pairplot(data_red_df, hue='Class',vars=['Time', 'Amount']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1f6f27a0-389b-0a74-d0c9-48d4c6673dea"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data_red_df, hue='Class',vars=['V1','V2','V3','V4', 'V5', 'V6','V7','V8','V9','V10']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b2b87c40-c5ba-ee16-b7f7-20e4fed3a6ee"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data_red_df, hue='Class',vars=[ 'V11', 'V12','V13','V14','V15','V16','V17','V18','V19','V20','V21']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a4d8308d-2dde-eb70-0cba-ce0f8976e237"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data_red_df, hue='Class',vars=[ 'V22','V23','V24','V25','V26','V27','V28']);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3e027361-9808-f4a3-2386-6aa4f9b3d064"
      },
      "source": [
        "It seems that the best features are 'V10', 'V14', 'V16', 'V17'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ef031a9e-e2fd-02ff-6912-89d566c9ff1c"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data_red_df, hue='Class',vars=['V10','V14','V16','V17']);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "91750bab-2112-2fba-f490-656e0fcd5aef"
      },
      "source": [
        "Lets take just these columns to fit our algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4105dc97-891f-1e81-1ba7-3fa6f2fc9365"
      },
      "outputs": [],
      "source": [
        "data_card_df = pd.concat([data_red_df['V10'],data_red_df['V16'],data_red_df['V14'],\\\n",
        "                            data_red_df['V17'],data_red_df['Class']],axis=1)\n",
        "\n",
        "\n",
        "data_card = data_card_df.as_matrix()\n",
        "\n",
        "X = data_card[:,:(data_card_df.shape[1]-1)]\n",
        "y = data_card[:,(data_card_df.shape[1]-1)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a435e578-b478-48c0-899e-be3b8353c13c"
      },
      "outputs": [],
      "source": [
        "iso.fit(X[:50,:])\n",
        "data_projected = iso.transform(X)\n",
        "data_projected.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fd15be2e-a09e-9501-301d-5b6c4534ef73"
      },
      "outputs": [],
      "source": [
        "plt.scatter(data_projected[:, 0], data_projected[:, 1], c=y,\n",
        "            edgecolor='none', alpha=0.5,\n",
        "            cmap=plt.cm.get_cmap('nipy_spectral'))\n",
        "\n",
        "plt.clim(-0.5, 9.5);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "71f7e8f3-a1ba-0d40-1b88-a6565705e90a"
      },
      "source": [
        "It does not look as this has strongly improved the result... actually looks worse!!\n",
        "Lets now divide the data into training and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0faa8d08-2403-62f7-716b-ffe9c8728089"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c5c63e65-1863-d681-9fc5-14f5ff570e17"
      },
      "source": [
        "# Decision Tree classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5ee2ce09-4502-093f-3fdd-e30b21acc99c"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#fit decision tree classifier\n",
        "model_dt = DecisionTreeClassifier()\n",
        "model_dt.fit(X_train, y_train)\n",
        "\n",
        "#predict 'y' for test data\n",
        "y_pred_test_dt = model_dt.predict(X_test)\n",
        "\n",
        "#score\n",
        "print(confusion_matrix(y_test, y_pred_test_dt))\n",
        "print(f1_score(y_test, y_pred_test_dt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bc77a294-8a75-3b65-79e0-e37a236ac024"
      },
      "source": [
        "# Neural networks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1e8836dc-2be9-44a1-5321-6a0edd6c868d"
      },
      "outputs": [],
      "source": [
        "#fit data\n",
        "model_nn.fit(X_train, y_train)\n",
        "\n",
        "#predict y\n",
        "y_pred_test_nn = model_nn.predict(X_test)\n",
        "\n",
        "#score\n",
        "print(confusion_matrix(y_test, y_pred_test_nn))\n",
        "print(f1_score(y_test, y_pred_test_nn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e8c87465-7de2-5126-2e2c-eb589b9eae74"
      },
      "source": [
        "# Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5ce20f2f-7428-8339-e964-81450507c7ae"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#fit\n",
        "model_rf = RandomForestClassifier(criterion='entropy')\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "#predict y\n",
        "y_pred_test_rf = model_rf.predict(X_test)\n",
        "\n",
        "#score\n",
        "print(confusion_matrix(y_test, y_pred_test_rf))\n",
        "print(f1_score(y_test, y_pred_test_rf))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "758139da-6cac-72c5-a639-cf068074dd5a"
      },
      "source": [
        "As expected, the results don't improve much.\n",
        "Lets look at the cross valudation accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1a253739-b933-137e-25a8-0d225e0cb5ac"
      },
      "outputs": [],
      "source": [
        "cv = KFold(len(y), 5, shuffle=True, random_state=0)\n",
        "\n",
        "scores_dt = cross_val_score(model_dt, X, y, cv=cv)\n",
        "print(scores_dt)\n",
        "print(\"Mean score decision tree: {0:.3f} (+/-{1:.3f})\".format(np.mean(scores_dt), sem(scores_dt)))\n",
        "\n",
        "\n",
        "scores_nn = cross_val_score(model_nn, X, y, cv=cv)\n",
        "print(scores_nn)\n",
        "print(\"Mean score neural networks: {0:.3f} (+/-{1:.3f})\".format(np.mean(scores_nn), sem(scores_nn)))\n",
        "scores_rf = cross_val_score(model_rf, X, y, cv=cv)\n",
        "print(scores_rf)\n",
        "print(\"Mean score random forest: {0:.3f} (+/-{1:.3f})\".format(np.mean(scores_rf), sem(scores_rf)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9257b5b3-837f-69a7-5ce3-92c1d8cf3cac"
      },
      "source": [
        "Hence, just by generating a symmetric data, the result is already very good!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8cde431a-70f0-86c3-98ea-38c4834b69d6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}