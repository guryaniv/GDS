{"cells":[{"metadata":{"_uuid":"362fb5399a41c1871888a983d2a2bf2b04952eb0"},"cell_type":"markdown","source":"# Init"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"from fastai.imports import *\n#from fastai.structured import *  # Removed from the v1.0 library. Copied the code in the below hidden cell\n\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom IPython.display import display\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"692fbe545075a8fb4fa18d979a4c69c5d9a2cf52","_kg_hide-input":true},"cell_type":"code","source":"# copied from https://github.com/fastai/fastai/blob/master/old/fastai/structured.py\n#from .imports import *\n\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype\nfrom sklearn.ensemble import forest\nfrom sklearn.tree import export_graphviz\n\n\ndef set_plot_sizes(sml, med, big):\n    plt.rc('font', size=sml)          # controls default text sizes\n    plt.rc('axes', titlesize=sml)     # fontsize of the axes title\n    plt.rc('axes', labelsize=med)    # fontsize of the x and y labels\n    plt.rc('xtick', labelsize=sml)    # fontsize of the tick labels\n    plt.rc('ytick', labelsize=sml)    # fontsize of the tick labels\n    plt.rc('legend', fontsize=sml)    # legend fontsize\n    plt.rc('figure', titlesize=big)  # fontsize of the figure title\n\ndef parallel_trees(m, fn, n_jobs=8):\n        return list(ProcessPoolExecutor(n_jobs).map(fn, m.estimators_))\n\ndef draw_tree(t, df, size=10, ratio=0.6, precision=0):\n    \"\"\" Draws a representation of a random forest in IPython.\n\n    Parameters:\n    -----------\n    t: The tree you wish to draw\n    df: The data used to train the tree. This is used to get the names of the features.\n    \"\"\"\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n                      special_characters=True, rotate=True, precision=precision)\n    IPython.display.display(graphviz.Source(re.sub('Tree {',\n       f'Tree {{ size={size}; ratio={ratio}', s)))\n\ndef combine_date(years, months=1, days=1, weeks=None, hours=None, minutes=None,\n              seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):\n    years = np.asarray(years) - 1970\n    months = np.asarray(months) - 1\n    days = np.asarray(days) - 1\n    types = ('<M8[Y]', '<m8[M]', '<m8[D]', '<m8[W]', '<m8[h]',\n             '<m8[m]', '<m8[s]', '<m8[ms]', '<m8[us]', '<m8[ns]')\n    vals = (years, months, days, weeks, hours, minutes, seconds,\n            milliseconds, microseconds, nanoseconds)\n    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)\n               if v is not None)\n\ndef get_sample(df,n):\n    \"\"\" Gets a random sample of n rows from df, without replacement.\n\n    Parameters:\n    -----------\n    df: A pandas data frame, that you wish to sample from.\n    n: The number of rows you wish to sample.\n\n    Returns:\n    --------\n    return value: A random sample of n rows of df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    >>> get_sample(df, 2)\n       col1 col2\n    1     2    b\n    2     3    a\n    \"\"\"\n    idxs = sorted(np.random.permutation(len(df))[:n])\n    return df.iloc[idxs].copy()\n\ndef add_datepart(df, fldname, drop=True, time=False):\n    \"\"\"add_datepart converts a column of df from a datetime64 to many columns containing\n    the information from the date. This applies changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas data frame. df gain several new columns.\n    fldname: A string that is the name of the date column you wish to expand.\n        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n    drop: If true then the original date column will be removed.\n    time: If true time features: Hour, Minute, Second will be added.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({ 'A' : pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000'], infer_datetime_format=False) })\n    >>> df\n\n        A\n    0   2000-03-11\n    1   2000-03-12\n    2   2000-03-13\n\n    >>> add_datepart(df, 'A')\n    >>> df\n\n        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n    \"\"\"\n    fld = df[fldname]\n    fld_dtype = fld.dtype\n    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n        fld_dtype = np.datetime64\n\n    if not np.issubdtype(fld_dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n    targ_pre = re.sub('[Dd]ate$', '', fldname)\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n    if time: attr = attr + ['Hour', 'Minute', 'Second']\n    for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n    df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9\n    if drop: df.drop(fldname, axis=1, inplace=True)\n\ndef is_date(x): return np.issubdtype(x.dtype, np.datetime64)\n\ndef train_cats(df):\n    \"\"\"Change any columns of strings in a panda's dataframe to a column of\n    categorical values. This applies the changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category\n    \"\"\"\n    for n,c in df.items():\n        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()\n\ndef apply_cats(df, trn):\n    \"\"\"Changes any columns of strings in df into categorical variables using trn as\n    a template for the category codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values. The category codes are determined by trn.\n\n    trn: A pandas dataframe. When creating a category for df, it looks up the\n        what the category's code were in trn and makes those the category codes\n        for df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category {a : 1, b : 2}\n\n    >>> df2 = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['b', 'a', 'a']})\n    >>> apply_cats(df2, df)\n\n           col1 col2\n        0     1    b\n        1     2    a\n        2     3    a\n\n    now the type of col is category {a : 1, b : 2}\n    \"\"\"\n    for n,c in df.items():\n        if (n in trn.columns) and (trn[n].dtype.name=='category'):\n            df[n] = pd.Categorical(c, categories=trn[n].cat.categories, ordered=True)\n\ndef fix_missing(df, col, name, na_dict):\n    \"\"\" Fill missing data in a column of df with the median, and add a {name}_na column\n    which specifies if the data was missing.\n\n    Parameters:\n    -----------\n    df: The data frame that will be changed.\n\n    col: The column of data to fix by filling in missing data.\n\n    name: The name of the new filled column in df.\n\n    na_dict: A dictionary of values to create na's of and the value to insert. If\n        name is not a key of na_dict the median will fill any missing data. Also\n        if name is not a key of na_dict and there is no missing data in col, then\n        no {name}_na column is not created.\n\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({'col1' : [1, np.NaN, 3], 'col2' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df['col1'], 'col1', {})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1     2    2    True\n    2     3    2   False\n\n\n    >>> df = pd.DataFrame({'col1' : [1, np.NaN, 3], 'col2' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df['col2'], 'col2', {})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n\n    >>> df = pd.DataFrame({'col1' : [1, np.NaN, 3], 'col2' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df['col1'], 'col1', {'col1' : 500})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1   500    2    True\n    2     3    2   False\n    \"\"\"\n    if is_numeric_dtype(col):\n        if pd.isnull(col).sum() or (name in na_dict):\n            df[name+'_na'] = pd.isnull(col)\n            filler = na_dict[name] if name in na_dict else col.median()\n            df[name] = col.fillna(filler)\n            na_dict[name] = filler\n    return na_dict\n\ndef numericalize(df, col, name, max_n_cat):\n    \"\"\" Changes the column col from a categorical type to it's integer codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. df[name] will be filled with the integer codes from\n        col.\n\n    col: The column you wish to change into the categories.\n    name: The column name you wish to insert into df. This column will hold the\n        integer codes.\n\n    max_n_cat: If col has more categories than max_n_cat it will not change the\n        it to its integer codes. If max_n_cat is None, then col will always be\n        converted.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> numericalize(df, df['col2'], 'col3', None)\n\n       col1 col2 col3\n    0     1    a    1\n    1     2    b    2\n    2     3    a    1\n    \"\"\"\n    if not is_numeric_dtype(col) and ( max_n_cat is None or len(col.cat.categories)>max_n_cat):\n        df[name] = col.cat.codes+1\n\ndef scale_vars(df, mapper):\n    warnings.filterwarnings('ignore', category=sklearn.exceptions.DataConversionWarning)\n    if mapper is None:\n        map_f = [([n],StandardScaler()) for n in df.columns if is_numeric_dtype(df[n])]\n        mapper = DataFrameMapper(map_f).fit(df)\n    df[mapper.transformed_names_] = mapper.transform(df)\n    return mapper\n\ndef proc_df(df, y_fld=None, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None,\n            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n    \"\"\" proc_df takes a data frame df and splits off the response variable, and\n    changes the df into an entirely numeric dataframe.\n\n    Parameters:\n    -----------\n    df: The data frame you wish to process.\n\n    y_fld: The name of the response variable\n\n    skip_flds: A list of fields that dropped from df.\n\n    ignore_flds: A list of fields that are ignored during processing.\n\n    do_scale: Standardizes each column in df. Takes Boolean Values(True,False)\n\n    na_dict: a dictionary of na columns to add. Na columns are also added if there\n        are any missing values.\n\n    preproc_fn: A function that gets applied to df.\n\n    max_n_cat: The maximum number of categories to break into dummy values, instead\n        of integer codes.\n\n    subset: Takes a random subset of size subset from df.\n\n    mapper: If do_scale is set as True, the mapper variable\n        calculates the values used for scaling of variables during training time (mean and standard deviation).\n\n    Returns:\n    --------\n    [x, y, nas, mapper(optional)]:\n\n        x: x is the transformed version of df. x will not have the response variable\n            and is entirely numeric.\n\n        y: y is the response variable\n\n        nas: returns a dictionary of which nas it created, and the associated median.\n\n        mapper: A DataFrameMapper which stores the mean and standard deviation of the corresponding continuous\n        variables which is then used for scaling of during test-time.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> x, y, nas = proc_df(df, 'col1')\n    >>> x\n\n       col2\n    0     1\n    1     2\n    2     1\n\n    >>> data = DataFrame(pet=[\"cat\", \"dog\", \"dog\", \"fish\", \"cat\", \"dog\", \"cat\", \"fish\"],\n                 children=[4., 6, 3, 3, 2, 3, 5, 4],\n                 salary=[90, 24, 44, 27, 32, 59, 36, 27])\n\n    >>> mapper = DataFrameMapper([(:pet, LabelBinarizer()),\n                          ([:children], StandardScaler())])\n\n    >>>round(fit_transform!(mapper, copy(data)), 2)\n\n    8x4 Array{Float64,2}:\n    1.0  0.0  0.0   0.21\n    0.0  1.0  0.0   1.88\n    0.0  1.0  0.0  -0.63\n    0.0  0.0  1.0  -0.63\n    1.0  0.0  0.0  -1.46\n    0.0  1.0  0.0  -0.63\n    1.0  0.0  0.0   1.04\n    0.0  0.0  1.0   0.21\n    \"\"\"\n    if not ignore_flds: ignore_flds=[]\n    if not skip_flds: skip_flds=[]\n    if subset: df = get_sample(df,subset)\n    else: df = df.copy()\n    ignored_flds = df.loc[:, ignore_flds]\n    df.drop(ignore_flds, axis=1, inplace=True)\n    if preproc_fn: preproc_fn(df)\n    if y_fld is None: y = None\n    else:\n        if not is_numeric_dtype(df[y_fld]): df[y_fld] = df[y_fld].cat.codes\n        y = df[y_fld].values\n        skip_flds += [y_fld]\n    df.drop(skip_flds, axis=1, inplace=True)\n\n    if na_dict is None: na_dict = {}\n    else: na_dict = na_dict.copy()\n    na_dict_initial = na_dict.copy()\n    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n    if len(na_dict_initial.keys()) > 0:\n        df.drop([a + '_na' for a in list(set(na_dict.keys()) - set(na_dict_initial.keys()))], axis=1, inplace=True)\n    if do_scale: mapper = scale_vars(df, mapper)\n    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n    df = pd.get_dummies(df, dummy_na=True)\n    df = pd.concat([ignored_flds, df], axis=1)\n    res = [df, y, na_dict]\n    if do_scale: res = res + [mapper]\n    return res\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\ndef set_rf_samples(n):\n    \"\"\" Changes Scikit learn's random forests to give each tree a random sample of\n    n random rows.\n    \"\"\"\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n))\n\ndef reset_rf_samples():\n    \"\"\" Undoes the changes produced by set_rf_samples.\n    \"\"\"\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n_samples))\n\ndef get_nn_mappers(df, cat_vars, contin_vars):\n    # Replace nulls with 0 for continuous, \"\" for categorical.\n    for v in contin_vars: df[v] = df[v].fillna(df[v].max()+100,)\n    for v in cat_vars: df[v].fillna('#NA#', inplace=True)\n\n    # list of tuples, containing variable and instance of a transformer for that variable\n    # for categoricals, use LabelEncoder to map to integers. For continuous, standardize\n    cat_maps = [(o, LabelEncoder()) for o in cat_vars]\n    contin_maps = [([o], StandardScaler()) for o in contin_vars]\n    return DataFrameMapper(cat_maps).fit(df), DataFrameMapper(contin_maps).fit(df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f56330bd252e6d46103316c3b9ee545b037c06c3"},"cell_type":"code","source":"PATH_INPUT = \"/kaggle/input/\"\nPATH_WORKING = \"/kaggle/working/\"\nPATH_TMP = \"/tmp/\"\nNROWS=5_000_000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abc9f8fd5523f5026493d7de54c59c3ad2268dad"},"cell_type":"code","source":"!ls -lh {PATH_INPUT}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c09fc3b565605cfe88ebb834558f6b2419ddbd2"},"cell_type":"code","source":"!wc -l {PATH_INPUT}train.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73e5a6e9d40077cf05953536e7b9fa64296d9dde"},"cell_type":"code","source":"!head {PATH_INPUT}train.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f1f6b661250965cddb19c63b68669e2e8369c37"},"cell_type":"code","source":"col_datetime = [\"pickup_datetime\"]\ncol_types = {\"key\": \"object\",\n             \"fare_amount\": \"float32\",\n             \"pickup_logitude\": \"float32\",\n             \"pickup_latitude\": \"float32\",\n             \"dropoff_longitude\": \"float32\",\n             \"dropoff_latitude\": \"float32\",\n             \"passenger_count\": \"int8\"}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14349ea3ebabb854d4f6f9b27f70e147474339c5"},"cell_type":"code","source":"%%time\ndf_raw = pd.read_csv(f'{PATH_INPUT}train.csv',\n                     parse_dates = col_datetime,\n                     dtype = col_types,\n                     infer_datetime_format = True,\n                     nrows=NROWS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ecca7b428efbcb49af7b90234436c59ae8f90b9"},"cell_type":"code","source":"df_test_raw = pd.read_csv(f'{PATH_INPUT}test.csv',\n                          parse_dates = col_datetime,\n                          dtype = col_types,\n                          infer_datetime_format = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4381b9a8a53d891579d13eaa7ea517e352800635"},"cell_type":"code","source":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"923d277d0372e7009a448473a8fdc914435b0f37"},"cell_type":"code","source":"display_all(df_raw.describe(include='all'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd5daca1ccbfe0bcc7247e8610e523f6dc8118ec"},"cell_type":"code","source":"display_all(df_test_raw.describe(include='all'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9800130767fbb2c3912ce94fc7ca7b04c2cf84f2"},"cell_type":"code","source":"df_raw.to_feather(f'{PATH_TMP}train_raw')\ndf_test_raw.to_feather(f\"{PATH_TMP}test_raw\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55affc0d065d5516e25546976f9c65641040df24","scrolled":true},"cell_type":"code","source":"#df_raw = pd.read_feather(f'{PATH_TMP}train_raw')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1650be1c7c6379f50418473aa501b98e23ea668"},"cell_type":"markdown","source":"# Pre-processing"},{"metadata":{"_uuid":"64c8dacf3bbe040d0d713528a0e5d6f6fbfa11f3"},"cell_type":"markdown","source":"## Cleaning"},{"metadata":{"trusted":true,"_uuid":"0b85b6c7a9a23dc488e406f27c7d0c7a4d37a746"},"cell_type":"code","source":"df_raw.drop(index=df_raw[df_raw.fare_amount <= 2.5].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d94338e14a9301d67a5f7d161dd32c30503e37e"},"cell_type":"code","source":"df_raw.drop(index=df_raw[df_raw.passenger_count <= 0].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"051114cccec232405171750a237adc973131e4b4"},"cell_type":"code","source":"df_raw.drop(index=df_raw[(df_raw.pickup_longitude <= -75) \n                         | (df_raw.pickup_longitude >= -72) \n                         | (df_raw.dropoff_longitude <= -75) \n                         | (df_raw.dropoff_longitude >= -72)\n                         | (df_raw.pickup_latitude <= 39)\n                         | (df_raw.pickup_latitude >= 42)\n                         | (df_raw.dropoff_latitude <= 39)\n                         | (df_raw.dropoff_latitude >= 42)].index, inplace=True)\n\ndf_raw.reset_index(inplace=True, drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc4aa7637cef64ba929e758bcc5298894571ce82"},"cell_type":"code","source":"df_raw.isnull().sum().sort_values(ascending=False)/len(df_raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc4aa7637cef64ba929e758bcc5298894571ce82"},"cell_type":"code","source":"df_test_raw.isnull().sum().sort_values(ascending=False)/len(df_test_raw)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5b36e9e5be27c2ef4b3d1c932c013663f6999df"},"cell_type":"markdown","source":"## Feature engineering"},{"metadata":{"trusted":true,"_uuid":"509be0afb2a890755f8381735675f1acfe73a26b"},"cell_type":"code","source":"add_datepart(df_raw, 'pickup_datetime', time=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"026e60bdd46fb171f15523d504fd54df5b2012d9"},"cell_type":"code","source":"df_raw.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aed8df635bf716e51d0e5585535682c0b94b7a53"},"cell_type":"code","source":"def add_travel_vector_features(df):\n    df[\"lat_diff\"] = np.abs(df.dropoff_latitude - df.pickup_latitude)\n    df[\"lon_diff\"] = np.abs(df.dropoff_longitude - df.pickup_longitude)\n    df['distance'] = ((df.lat_diff)**2 + (df.lon_diff)**2)**.5\n\nadd_travel_vector_features(df_raw)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d721fbabac7fa883466dca83be3be69d507b0b62"},"cell_type":"markdown","source":"## End processing"},{"metadata":{"trusted":true,"_uuid":"1261d0ff5fce39cd381c6be82245fdcfecb6ef24"},"cell_type":"code","source":"df, y, _ = proc_df(df_raw, 'fare_amount', skip_flds=[\"key\"], subset=100000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d5f6ccd8f1da54774af90fe867f070f94ec2c23"},"cell_type":"code","source":"print(df.shape, y.shape, df_raw.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24892ae87a95ad1c31257ccb9bb3c221694ca2ee"},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true,"_uuid":"aa0934208ac98f22800043fe98d13a7a3451f8e1"},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(df, y, test_size=0.2)\nprint(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45c97583bd25465722c0802ef731158ae21be8eb"},"cell_type":"code","source":"def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n\ndef print_score(m):\n    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d82aa468ba48a12273fc3f6f997adb0b07bbaa49"},"cell_type":"code","source":"%%time\nm = RandomForestRegressor(n_estimators=10, n_jobs=-1)\nm.fit(X_train, y_train)\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c12b5cbc3c13935d0a5da1e1a4c6722d55040919"},"cell_type":"markdown","source":"* 100,000 samples: [1.792594290612869, 4.114752003268763, 0.9656926105298179, 0.8229538003980035]\n* 10,000,000 samples: [1.5972439409249253, 3.727606761144474, 0.9729915591731986, 0.8516836099031339]"},{"metadata":{"trusted":true,"_uuid":"0fd05a49e2e5f30a216e817caaccb1e60096756a"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a08c09ccdfff4055847dc5b33568f2ae4e91312"},"cell_type":"markdown","source":"## Tuning"},{"metadata":{"trusted":true,"_uuid":"d3dbd75d45305bced074fd6329c98d9e3deefa3b"},"cell_type":"code","source":"set_rf_samples(20000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d82aa468ba48a12273fc3f6f997adb0b07bbaa49"},"cell_type":"code","source":"%%time\nm = RandomForestRegressor(n_estimators=40, n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d82aa468ba48a12273fc3f6f997adb0b07bbaa49"},"cell_type":"code","source":"%%time\nm = RandomForestRegressor(n_estimators=80, max_features=0.5, n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d82aa468ba48a12273fc3f6f997adb0b07bbaa49"},"cell_type":"code","source":"%%time\nm = RandomForestRegressor(n_estimators=80, max_features=0.5, min_samples_leaf=3, n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d82aa468ba48a12273fc3f6f997adb0b07bbaa49"},"cell_type":"code","source":"%%time\nm = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31cf2cd8ae36e5bb64c26bb7791dc8e1a29f17cd"},"cell_type":"markdown","source":"Base on this model and work on the features removing"},{"metadata":{"trusted":true,"_uuid":"36819f1c1aaf03ef93b33188217efca94c8189f8"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7d84bdd821e4160ce3d47ebf8822a8c46579576"},"cell_type":"markdown","source":"## Features Importance"},{"metadata":{"trusted":true,"_uuid":"7c57a86dc7b8ea5b22dee911081e9d9657663a96"},"cell_type":"code","source":"fi = rf_feat_importance(m, df); fi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af0b847383b61241cc92d7892014626532a79ae4"},"cell_type":"code","source":"def plot_fi(fi): return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d7e88ad3bbc8313bca59431ee50e3e798e3e203"},"cell_type":"code","source":"plot_fi(fi)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15d9a1d71e750d9c7c6d68e01a89faf10dba27a0"},"cell_type":"markdown","source":"### Remove features"},{"metadata":{"trusted":true,"_uuid":"743cc0008527e1db71af61a9786586bd1f4db5d6"},"cell_type":"code","source":"cols_keep = fi[fi.imp>1.5e-03].cols; len(cols_keep)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbe16e4303554793aa81022ac3bc664b5d992e39"},"cell_type":"code","source":"print(cols_keep)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc443227e856b7c76300042ce4700b4419f6d6f6"},"cell_type":"code","source":"X_train_copy = X_train.copy()\nX_valid_copy = X_valid.copy()\nprint(X_train_copy.shape, X_valid_copy.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9959dec70401b38c534b01b9d414b751e536c0e"},"cell_type":"code","source":"X_train = X_train_copy[cols_keep].copy()\nX_valid = X_valid_copy[cols_keep].copy()\nprint(X_train.shape, X_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d82aa468ba48a12273fc3f6f997adb0b07bbaa49"},"cell_type":"code","source":"%%time\nm = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f36680140a82db345fba6419be28da4a9a8caff"},"cell_type":"markdown","source":"## Redundant Features"},{"metadata":{"trusted":true,"_uuid":"c6ec4286d85985de62b1aea8c5bd06f3343fe93a"},"cell_type":"code","source":"from scipy.cluster import hierarchy as hc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"8465dc21cd73e45ce1c9eec871438cb065ce019b"},"cell_type":"code","source":"corr = np.round(scipy.stats.spearmanr(X_train).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method='average')\nfig = plt.figure(figsize=(16,10))\ndendrogram = hc.dendrogram(z, labels=X_train.columns, orientation='left', leaf_font_size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68fcd9079e2416117f9d4767eedf9fa05c43003c"},"cell_type":"code","source":"def get_oob(X):\n    m = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1, oob_score=True)\n    m.fit(X, y_train)\n    return m.oob_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2685d7e14ec3d29dbf5f1a03f8fac6ac27401c5f"},"cell_type":"code","source":"get_oob(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a26f74a0db7e5a7ef78d1f7179a399b8e10177cc"},"cell_type":"code","source":"for col in [\"pickup_datetimeMonth\", \"pickup_datetimeDayofyear\", \"pickup_datetimeWeek\", \"pickup_datetimeYear\", \"pickup_datetimeElapsed\"]:\n    print(col, get_oob(X_train.drop(labels=col, axis=1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a565bb2dae59df295543dce5f846d32552fbd18"},"cell_type":"code","source":"cols_drop = [\"pickup_datetimeDayofyear\", \"pickup_datetimeYear\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9ed0ebf79b55bc2da54ace705ee94caf7d497d1"},"cell_type":"code","source":"get_oob(X_train.drop(labels=cols_drop, axis=1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70f60ae7f9065398a53d2e7af0b9fed68a61efe3"},"cell_type":"markdown","source":"Freeze the features"},{"metadata":{"trusted":true,"_uuid":"ad28a5ae66751b0b50e87fe36af30e93f84c3782"},"cell_type":"code","source":"X_train.drop(labels=cols_drop, axis=1, inplace=True)\nX_valid.drop(labels=cols_drop, axis=1, inplace=True)\nprint(X_train.shape, X_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2c1deaf7db336c5c1290f76d9667435f07ac78d"},"cell_type":"code","source":"np.save(f'{PATH_TMP}features_keep.npy', np.array(X_train.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18765da032f307be71c8c40c4c204032dcf8fa77"},"cell_type":"code","source":"features_keep = np.load(f'{PATH_TMP}features_keep.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"116d4baef21c51eaf5eda91b4ba27c41a99d4c28"},"cell_type":"code","source":"%%time\nm = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47010b5fa54671accfd10ef15d5fede3e47f3108"},"cell_type":"markdown","source":"## Extrapolation"},{"metadata":{"trusted":true,"_uuid":"8ce72bfee9ebcc2e328aef8f0fa47eb21a91487f"},"cell_type":"code","source":"df, y, _ = proc_df(df_raw, skip_flds=[\"key\"], subset=None)\ndf = df[features_keep].copy()\ny = np.array([0]*df.shape[0])  #default to 0\nprint(df.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa0934208ac98f22800043fe98d13a7a3451f8e1"},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(df, y, test_size=0.2)\nprint(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"730da7dc279bfa26e8881e1233aa97389c13a423"},"cell_type":"code","source":"y[X_valid.index] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9268c80998aeb8a919353d32e766acbfafd55d7c"},"cell_type":"code","source":"m = RandomForestClassifier(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\nm.fit(df, y)\nprint(m.oob_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1aca337c49f38e6565d36fe24070412586879bc5"},"cell_type":"code","source":"fi = rf_feat_importance(m, df); fi","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56b87a5ef2204da5f103d9375f339ddc5a9bbdff"},"cell_type":"markdown","source":"Looks good"},{"metadata":{"_uuid":"008b6ec665e6ed0991e8938c082ec22253e18457"},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true,"_uuid":"0e245cecbc9a0b44c3895a3af7c576c23597fb6a"},"cell_type":"code","source":"reset_rf_samples()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1261d0ff5fce39cd381c6be82245fdcfecb6ef24"},"cell_type":"code","source":"df, y, _ = proc_df(df_raw, 'fare_amount', skip_flds=[\"key\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"22db880ec60a3b4ffc775745c82cefede58992ea"},"cell_type":"code","source":"df = df[features_keep].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa0934208ac98f22800043fe98d13a7a3451f8e1"},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(df, y, test_size=0.2)\nprint(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d82aa468ba48a12273fc3f6f997adb0b07bbaa49"},"cell_type":"code","source":"%%time\nm = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1, oob_score=False)\nm.fit(X_train, y_train)\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"332aa81bea83ed9b7c0d127acb6498bc19e935ab"},"cell_type":"code","source":"keys = df_test_raw[\"key\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a60d30e2ce288f7292dde83d118e4872bb0215b"},"cell_type":"code","source":"add_datepart(df_test_raw, 'pickup_datetime', time=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a9581a51506121a8d7414256f3429f925b54ca6"},"cell_type":"code","source":"add_travel_vector_features(df_test_raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e54bc188d4b6b375df4c6b20c129c774a76bcdb3"},"cell_type":"code","source":"df_test, _, _ = proc_df(df_test_raw[features_keep])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18b2b00ed688336910a21aa711c12f83baf8802e"},"cell_type":"code","source":"preds = m.predict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e4de73a090312153a849efcf1620e4af8c7bcf7"},"cell_type":"code","source":"submission = pd.DataFrame({\"key\": keys, \"fare_amount\": preds})\nsubmission.to_csv(f'{PATH_WORKING}submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47962e9883045c5089b79b223b4fff8539692c6e"},"cell_type":"code","source":"!head {PATH_WORKING}submission.csv","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}