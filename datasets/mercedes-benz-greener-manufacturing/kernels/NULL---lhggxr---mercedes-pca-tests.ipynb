{"nbformat": 4, "nbformat_minor": 0, "metadata": {"_change_revision": 0, "_is_fork": false, "language_info": {"pygments_lexer": "ipython3", "name": "python", "nbconvert_exporter": "python", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "version": "3.6.0"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "cells": [{"execution_count": null, "metadata": {"_uuid": "7c2707703a9312d6004f8c40cb97c1c16b4ecebe", "_cell_guid": "d0a037a6-6e20-ab59-2455-c6e28ae3d056"}, "cell_type": "markdown", "outputs": [], "source": ["# PCA to determine relevant features"]}, {"execution_count": null, "metadata": {"_uuid": "8a591a08b5d0d19f3f836f57e9d698823615b145", "_cell_guid": "cf98585a-c141-0f8b-ba57-53b9c1ca280f"}, "cell_type": "code", "outputs": [], "source": ["# Importing main packages and settings\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "from sklearn.decomposition import PCA\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.pipeline import make_pipeline\n", "from sklearn.linear_model import Ridge, RidgeCV, ElasticNetCV, OrthogonalMatchingPursuitCV"]}, {"execution_count": null, "metadata": {"_uuid": "fbacfc88a97a65cbfd6e73f609672447848ad917", "_cell_guid": "3c7ac824-d471-b8ff-cb4d-21789c95f11c"}, "cell_type": "code", "outputs": [], "source": ["# Function for plotting the scores for different alphas used in Ridge regression\n", "def display_plot(cv_scores, cv_scores_std):\n", "    fig = plt.figure()\n", "    ax = fig.add_subplot(1,1,1)\n", "    ax.plot(alpha_space, cv_scores)\n", "\n", "    std_error = cv_scores_std / np.sqrt(10)\n", "\n", "    ax.fill_between(alpha_space, cv_scores + std_error, cv_scores - std_error, alpha=0.2)\n", "    ax.set_ylabel('CV Score +/- Std Error')\n", "    ax.set_xlabel('Alpha')\n", "    ax.axhline(np.max(cv_scores), linestyle='--', color='.5')\n", "    ax.set_xlim([alpha_space[0], alpha_space[-1]])\n", "    ax.set_xscale('log')\n", "    plt.show()"]}, {"execution_count": null, "metadata": {"_uuid": "3c5b3fddbd1ad5a4025438a1865db99205ad1e55", "_cell_guid": "80fd3180-ef43-b147-0213-b6896dfa44ad"}, "cell_type": "markdown", "outputs": [], "source": ["# Loading and formatting the data"]}, {"execution_count": null, "metadata": {"_uuid": "c9b6f30361882bfad7f57c2b568013e4afc93748", "_cell_guid": "63babe32-7650-0ab2-ccaa-4c7ba2655366"}, "cell_type": "code", "outputs": [], "source": ["# Loading the training dataset\n", "df_train = pd.read_csv('../input/train.csv')\n", "df_test = pd.read_csv('../input/test.csv')"]}, {"execution_count": null, "metadata": {"_uuid": "e0dff8d9d79d4f75bc75a0f4c33cf0032c180618", "_cell_guid": "7aa8abd6-5992-a0ed-79c6-f78fe3cd0cfc"}, "cell_type": "code", "outputs": [], "source": ["# turning object features into dummy variables\n", "df_train_dummies = pd.get_dummies(df_train, drop_first=True)\n", "df_test_dummies = pd.get_dummies(df_test, drop_first=True)\n", "\n", "# dropping ID and the target variable\n", "df_train_dummies = df_train_dummies.drop(['ID','y'], axis=1)\n", "df_test_dummies = df_test_dummies.drop('ID', axis=1)\n", "\n", "print(\"Clean Train DataFrame With Dummy Variables: {}\".format(df_train_dummies.shape))\n", "print(\"Clean Test DataFrame With Dummy Variables: {}\".format(df_test_dummies.shape))"]}, {"execution_count": null, "metadata": {"_uuid": "10cc325ad7b0f78bfa9e3b401ffc285a8541cd9b", "_cell_guid": "213c956f-57a7-d2b9-ba1d-3a78f1c16423"}, "cell_type": "code", "outputs": [], "source": ["# concatenate to only include columns in both data sets\n", "# the number should be based on the number of columns. Original is 30471. Now set to 15471 after outlier handling etc.\n", "df_temp = pd.concat([df_train_dummies, df_test_dummies], join='inner')\n", "df_temp_train = df_temp[:len(df_train.index)]\n", "df_temp_test = df_temp[len(df_train.index):]\n", "\n", "# check shapes of combined df and split out again\n", "print(df_temp.shape)\n", "print(df_temp_train.shape)\n", "print(df_temp_test.shape)"]}, {"execution_count": null, "metadata": {"_uuid": "f7dc8101a48dcc574d3a313448e179b95d41daee", "_cell_guid": "f7f3b97d-ca55-a9d9-d65e-6c51e56a826b"}, "cell_type": "code", "outputs": [], "source": ["# defining X and y\n", "X = df_temp_train\n", "test_X = df_temp_test\n", "y = df_train['y']"]}, {"execution_count": null, "metadata": {"_uuid": "1cef066717608ce0362ec25d7ba5fe86cb43ac15", "_cell_guid": "9e0b678d-5139-603f-fc53-ec7f671c87e4"}, "cell_type": "code", "outputs": [], "source": ["X.head()"]}, {"execution_count": null, "metadata": {"_uuid": "f7a54f8cd4b145cf0f8db671f1f511475fc758a2", "_cell_guid": "1fb92394-a97d-cffa-f647-487804b732b1"}, "cell_type": "markdown", "outputs": [], "source": ["# First PCA Test\n", "Showing variance explained by PCA features"]}, {"execution_count": null, "metadata": {"_uuid": "a13990dba0cde5af7b143369497937d5535dbf10", "_cell_guid": "02156de0-ab4f-7411-0b7a-59f0b7d5ae19"}, "cell_type": "code", "outputs": [], "source": ["# Create a PCA instance: pca\n", "pca = PCA()\n", "\n", "# Fit the pca to 'samples'\n", "pca.fit(X)\n", "\n", "# Plot the explained variances\n", "features = range(pca.n_components_)\n", "plt.bar(features, pca.explained_variance_)\n", "plt.xlabel('PCA feature')\n", "plt.ylabel('variance')\n", "plt.xticks(features)\n", "plt.show()"]}, {"execution_count": null, "metadata": {"_uuid": "837c0f451f5096f0f763459b00d65274a19f65b6", "_cell_guid": "2ed040ec-3e00-2750-dafe-311b4c81795e"}, "cell_type": "markdown", "outputs": [], "source": ["# Second PCA Test\n", "Showing variance explained by top n components (50) and transforming the original data sets"]}, {"execution_count": null, "metadata": {"_uuid": "622dd756c53060253f5dec1e4cc3370d8886fe95", "_cell_guid": "d1afd178-4286-fa57-a474-136b290cdc2c"}, "cell_type": "code", "outputs": [], "source": ["# Create a PCA instance: pca\n", "pca2 = PCA(n_components=50)\n", "\n", "# Fit the pca to 'samples'\n", "pca2.fit(X)\n", "\n", "pca_X = pca2.transform(X)\n", "pca_test_X = pca2.transform(test_X)\n", "\n", "# Plot the explained variances\n", "features = range(pca2.n_components_)\n", "plt.bar(features, pca2.explained_variance_)\n", "plt.xlabel('PCA feature')\n", "plt.ylabel('variance')\n", "plt.xticks(features)\n", "plt.show()"]}, {"execution_count": null, "metadata": {"_uuid": "62a8e96a4c0488720ea963c41671b7b6b07f548c", "_cell_guid": "8e7d5460-ff5b-f8fd-daee-2665fc0c23dc"}, "cell_type": "code", "outputs": [], "source": ["print(pca_features.shape)"]}, {"execution_count": null, "metadata": {"_uuid": "1dddacffff7d3a82d3b2f2bdd41182ef4a05849e", "_cell_guid": "f629ef56-9872-0237-0e22-245d8d0e4555"}, "cell_type": "markdown", "outputs": [], "source": ["# Impact of PCA on alphas used in Ridge regression\n", "Top chart shows the original Ridge regression with the impact of alpha on scores\n", "Second chart shows the Ridge regression on the PCA transformed data set with the impact of alpha on scores"]}, {"execution_count": null, "metadata": {"_uuid": "3aeea0048f5e0d0742ff4d8d4227d905b7030fce", "_cell_guid": "3279464c-c33d-c0b4-a131-249d08118b70"}, "cell_type": "code", "outputs": [], "source": ["# Setup the array of alphas and lists to store scores\n", "alpha_space = np.logspace(-4, 0, 20)\n", "ridge_scores = []\n", "ridge_scores_std = []\n", "\n", "# Create a ridge regressor: ridge\n", "ridge = Ridge(normalize=True)\n", "\n", "# Compute scores over range of alphas\n", "for alpha in alpha_space:\n", "\n", "    # Specify the alpha value to use: ridge.alpha\n", "    ridge.alpha = alpha\n", "    \n", "    # Perform 10-fold CV: ridge_cv_scores\n", "    ridge_cv_scores = cross_val_score(ridge, X, y, cv=5)\n", "    \n", "    # Append the mean of ridge_cv_scores to ridge_scores\n", "    ridge_scores.append(np.mean(ridge_cv_scores))\n", "    \n", "    # Append the std of ridge_cv_scores to ridge_scores_std\n", "    ridge_scores_std.append(np.std(ridge_cv_scores))\n", "\n", "# Display the plot\n", "display_plot(ridge_scores, ridge_scores_std)"]}, {"execution_count": null, "metadata": {"_uuid": "dc83957d15e4145023058509a5d44a7b26084bf4", "_cell_guid": "e16fe7ef-c650-d472-0c07-02b3fc0a7f28"}, "cell_type": "code", "outputs": [], "source": ["# Setup the array of alphas and lists to store scores\n", "alpha_space = np.logspace(-4, 0, 20)\n", "ridge_scores = []\n", "ridge_scores_std = []\n", "\n", "# Create a ridge regressor: ridge\n", "ridge = Ridge(normalize=True)\n", "\n", "# Compute scores over range of alphas\n", "for alpha in alpha_space:\n", "\n", "    # Specify the alpha value to use: ridge.alpha\n", "    ridge.alpha = alpha\n", "    \n", "    # Perform 10-fold CV: ridge_cv_scores\n", "    ridge_cv_scores = cross_val_score(ridge, pca_X, y, cv=5)\n", "    \n", "    # Append the mean of ridge_cv_scores to ridge_scores\n", "    ridge_scores.append(np.mean(ridge_cv_scores))\n", "    \n", "    # Append the std of ridge_cv_scores to ridge_scores_std\n", "    ridge_scores_std.append(np.std(ridge_cv_scores))\n", "\n", "# Display the plot\n", "display_plot(ridge_scores, ridge_scores_std)"]}, {"execution_count": null, "metadata": {"_uuid": "2546561c3b12bbe4e905c05cecc004843511d21e", "_cell_guid": "25b420d1-298d-f917-8804-9f2e7a3f3967"}, "cell_type": "code", "outputs": [], "source": ["# instantiating different regressors\n", "rcv = RidgeCV()\n", "ecv = ElasticNetCV()\n", "ompcv = OrthogonalMatchingPursuitCV()"]}, {"execution_count": null, "metadata": {"_uuid": "a171e7448b7f8f39ce145d76800a69049c7eb6fa", "_cell_guid": "c0935627-202c-7bb9-165a-d48f4e15908e"}, "cell_type": "code", "outputs": [], "source": ["# bad for but just for now:\n", "import warnings\n", "warnings.filterwarnings(\"ignore\")\n", "\n", "# Compute 10-fold cross-validation scores: cv_scores\n", "cv_scores_rcv = cross_val_score(rcv, X, y, cv=5)\n", "cv_scores_ecv = cross_val_score(ecv, X, y, cv=5)\n", "cv_scores_ompcv = cross_val_score(ompcv, X, y, cv=5)\n", "\n", "# Compute 10-fold cross-validation scores: cv_scores\n", "cv_scores_pca_rcv = cross_val_score(rcv, pca_X, y, cv=5)\n", "cv_scores_pca_ecv = cross_val_score(ecv, pca_X, y, cv=5)\n", "cv_scores_pca_ompcv = cross_val_score(ompcv, pca_X, y, cv=5)\n", "\n", "# Print the 10-fold cross-validation scores\n", "print(cv_scores_rcv)\n", "print(cv_scores_ecv)\n", "print(cv_scores_ompcv)\n", "print(cv_scores_pca_rcv)\n", "print(cv_scores_pca_ecv)\n", "print(cv_scores_pca_ompcv)\n", "\n", "print(\"Average 5-Fold RidgeCV CV Score: {}\".format(np.mean(cv_scores_rcv)))\n", "print(\"Average 5-Fold ElasticNetCV CV Score: {}\".format(np.mean(cv_scores_ecv)))\n", "print(\"Average 5-Fold OrthogonalMatchingPursuitCV CV Score: {}\".format(np.mean(cv_scores_ompcv)))\n", "print(\"Average 5-Fold PCA RidgeCV CV Score: {}\".format(np.mean(cv_scores_pca_rcv)))\n", "print(\"Average 5-Fold PAC ElasticNetCV CV Score: {}\".format(np.mean(cv_scores_pca_ecv)))\n", "print(\"Average 5-Fold PCA OrthogonalMatchingPursuitCV CV Score: {}\".format(np.mean(cv_scores_pca_ompcv)))"]}, {"execution_count": null, "metadata": {"_uuid": "58d822cfed4c0c772d36270b2379031c2322a979", "_cell_guid": "f3a078dc-0d6c-8bea-1ce3-d2aa2a68c702"}, "cell_type": "code", "outputs": [], "source": ["# Create a PCA instance: pca\n", "pca10 = PCA(n_components=10)\n", "pca20 = PCA(n_components=20)\n", "pca50 = PCA(n_components=50)\n", "pca100 = PCA(n_components=100)\n", "pca200 = PCA(n_components=200)\n", "pca300 = PCA(n_components=300)\n", "\n", "# Fit the pca to 'samples'\n", "pca10.fit(X)\n", "pca20.fit(X)\n", "pca50.fit(X)\n", "pca100.fit(X)\n", "pca200.fit(X)\n", "pca300.fit(X)\n", "\n", "pca10_X = pca10.transform(X)\n", "pca20_X = pca20.transform(X)\n", "pca50_X = pca50.transform(X)\n", "pca100_X = pca100.transform(X)\n", "pca200_X = pca200.transform(X)\n", "pca300_X = pca300.transform(X)"]}, {"execution_count": null, "metadata": {"_uuid": "09b858c97593a4fd4bb53fbd37b2841cbbe49d88", "_cell_guid": "89b219a1-a2bd-33ac-5bd8-ae6afb0ebfdf"}, "cell_type": "code", "outputs": [], "source": ["# bad for but just for now:\n", "import warnings\n", "warnings.filterwarnings(\"ignore\")\n", "\n", "# Compute 5-fold cross-validation scores: cv_scores\n", "cv_scores_pca10_ecv = cross_val_score(ecv, pca10_X, y, cv=5)\n", "cv_scores_pca20_ecv = cross_val_score(ecv, pca20_X, y, cv=5)\n", "cv_scores_pca50_ecv = cross_val_score(ecv, pca50_X, y, cv=5)\n", "cv_scores_pca100_ecv = cross_val_score(ecv, pca100_X, y, cv=5)\n", "cv_scores_pca200_ecv = cross_val_score(ecv, pca200_X, y, cv=5)\n", "cv_scores_pca300_ecv = cross_val_score(ecv, pca300_X, y, cv=5)\n", "cv_scores_nopca_ecv = cross_val_score(ecv, X, y, cv=5)\n", "\n", "print(\"Average 5-Fold 10 PCA ElasticNetCV CV Score: {}\".format(np.mean(cv_scores_pca10_ecv)))\n", "print(\"Average 5-Fold 20 PCA ElasticNetCV CV Score: {}\".format(np.mean(cv_scores_pca20_ecv)))\n", "print(\"Average 5-Fold 50 PCA ElasticNetCV CV Score: {}\".format(np.mean(cv_scores_pca50_ecv)))\n", "print(\"Average 5-Fold 100 PCA ElasticNetCV CV Score: {}\".format(np.mean(cv_scores_pca100_ecv)))\n", "print(\"Average 5-Fold 200 PCA ElasticNetCV CV Score: {}\".format(np.mean(cv_scores_pca200_ecv)))\n", "print(\"Average 5-Fold 300 PCA ElasticNetCV CV Score: {}\".format(np.mean(cv_scores_pca300_ecv)))\n", "print(\"Average 5-Fold No PCA ElasticNetCV CV Score: {}\".format(np.mean(cv_scores_nopca_ecv)))"]}, {"execution_count": null, "metadata": {"_uuid": "7af1c77b60bcc218f626c910aa93165e0028ff77", "_cell_guid": "1bb02d72-0743-d651-0359-f9416681dadc"}, "cell_type": "code", "outputs": [], "source": ""}]}