{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\nimport json\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nprint(os.listdir(\"../input/train/\"))\n# print(os.listdir(\"../input/train_metadata/\"))\n# print(os.listdir(\"../input/train_sentiment/\"))\n# print(os.listdir(\"../input/train_images/\"))\n\nprint(os.listdir(\"../input/test/\"))\n# print(os.listdir(\"../input/test_sentiment/\"))\n# print(os.listdir(\"../input/test_metadata/\"))\n# print(os.listdir(\"../input/test_images/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":" ## explore the trianing set data"},{"metadata":{"trusted":true,"_uuid":"583a1b080a3f4280d04fc178c6335bc3bbd39180"},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/train/train.csv\")\ndf_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b852e2b574b544414622788a492a89fc2442756f"},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac89b59868af647f49e0f55f8dd12057183a53f6"},"cell_type":"markdown","source":"How do the numeric attribute`as look over the population? "},{"metadata":{"trusted":true,"_uuid":"3e733ea1a93db2c2688a02b26759e0f28e1ae00f"},"cell_type":"code","source":"df_train.hist(figsize=(15,15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84d5b7f721f6ac35e16cce28bc8559de34fe0980"},"cell_type":"code","source":"# let's create some convenience constants\nDISCREET_COLS = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'State', ]\nSCALAR_COLS = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt', ]\nTEXT_COLS = ['Name', 'RescuerID', 'Description', 'PetID', ]\nTARGET_COL = 'AdoptionSpeed'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1de1e8e35f18f0703e798f54ae2273671a204d8"},"cell_type":"code","source":"corr = df_train.corr()\nsns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"016bd0fc1bc0ae08ddc2ce38a1c0ae2234f515bc"},"cell_type":"markdown","source":"Not surprisingly, vaccination, sterilization and deworming travel together as those are all vet services.  I'm not sure why quantity and gender or color and gender seem to correlate.\n\nLet's compare how each discreet column relates to adoption speed."},{"metadata":{"trusted":true,"_uuid":"fc55f071406625bfcec3cf5919dbea9e5f774013"},"cell_type":"code","source":"for c in DISCREET_COLS:\n    df_g = df_train[[c, 'AdoptionSpeed', ]].groupby([c, 'AdoptionSpeed', ]).size().unstack()\n    df_g.div(df_g.sum(1), axis=0).plot.bar(figsize=(12,5), colormap='tab20', stacked=True).legend(loc='center left', bbox_to_anchor=(1, 0.5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60691e7a58cc1404493908fc2febad88be5a22bf"},"cell_type":"markdown","source":"So each discreet column has some variability, but the breed, color, health and state seem to have the most.  All of them are likely to be relevant, though.  Let's look at the scalars vs adoption:"},{"metadata":{"trusted":true,"_uuid":"00feba6e7d0bd7b79fdf0a5a074c4b83dd582fe6"},"cell_type":"code","source":"for c in SCALAR_COLS:\n    plt.figure()\n    df_g = df_train[[c, 'AdoptionSpeed', ]].groupby([c, 'AdoptionSpeed', ]).size().unstack().fillna(0)\n    df_g.apply(lambda x: np.average(range(5), weights=x), axis=1).plot.line(figsize=(12,5), legend=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5660ef16580b1b7d4d3ae251122c75367cdc82d6"},"cell_type":"markdown","source":"This isn't incredibly useful especially since the data gets pretty sparse at the extremes, but there seems to some relationship at the lower end of age (people love puppies) and quantity (not sure why).  Also, a few pictures and videos seem to help."},{"metadata":{"trusted":true,"_uuid":"7b0be450e23ec5a9dfc52dbdceaf2767b44ec4fc"},"cell_type":"markdown","source":"## compare the train and test data"},{"metadata":{"trusted":true,"_uuid":"f5bf12d5fc4fdc76f054afc95eed601902cc0594"},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/test/test.csv\")\ndf_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af8bf1f90a4ca09306848050453e33cd8710eb8f"},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cddd766062d61fc4ce0f2c96018e698dc950da13"},"cell_type":"code","source":"def compare_discreet_column(col, train, test):\n    print('\\nComparing column {0}'.format(col))\n    s_trn = train[col]\n    s_tst = test[col]\n    # check for extra values\n    train_vals = set(s_trn.unique())\n    test_vals = set(s_tst.unique())\n    print(\"extra values in train: {0}\".format(train_vals - test_vals))\n    print(\"extra values in test: {0}\".format(test_vals - train_vals))\n    # check for major changes in representation\n    if len(train_vals) < 10:\n        trn_rep = s_trn.groupby(s_trn).size() / len(s_trn)\n        tst_rep = s_tst.groupby(s_tst).size() / len(s_tst)\n        df_temp = pd.concat([trn_rep, tst_rep], axis=1)\n        df_temp.columns = ['Train', 'Test']\n        print(df_temp)\n    else:\n        print(\"too many values to compare representation\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c02f802482ae9291dc3dad0090017cf189dc965"},"cell_type":"code","source":"for c in DISCREET_COLS:\n    compare_discreet_column(c, df_train, df_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3fdb47e5a779914824b7704a4bf5ae8366b7ef70"},"cell_type":"markdown","source":"The train and test sets seem to have fairly similar representations of each discreet column value.  We need to be careful about the breed columns, however, since there are unique values in each of train and test.  Let's see what percentage of the test population these values represent."},{"metadata":{"trusted":true,"_uuid":"7af1b168de057d08212eb487ee0317d28788cc21"},"cell_type":"code","source":"extra_breed_1 = set(df_test['Breed1'].unique()) - set(df_train['Breed1'].unique())\nprint(\"% of test set with Breed1 not in train: {0:0.2f}%\".format(len(df_test[df_test['Breed1'].isin(extra_breed_1)])/len(df_test)*100))\nextra_breed_2 = set(df_test['Breed2'].unique()) - set(df_train['Breed2'].unique())\nprint(\"% of test set with Breed2 not in train: {0:0.2f}%\".format(len(df_test[df_test['Breed2'].isin(extra_breed_1)])/len(df_test)*100))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"add6a8b06674cbb4a9dc4326594738d163f05b6b"},"cell_type":"markdown","source":"So less than 1% for each; we'll treat as outliers."},{"metadata":{"_uuid":"79cad40437ced227e50e97da830d6b2ff4c16f99"},"cell_type":"markdown","source":"## exploring the image data"},{"metadata":{"trusted":true,"_uuid":"deae025d9f74f718c1df336316270c1d422a2105"},"cell_type":"code","source":"fpatt = re.compile(\"([0-9a-zA-Z]+)-(\\d+)\\.(.+)\")\nFACE_ANNOTATION_FIELDS = ['angerLikelihood','blurredLikelihood','detectionConfidence','joyLikelihood','sorrowLikelihood','surpriseLikelihood','underExposedLikelihood']\ndef get_image_info(image_path, meta_path):\n    image_info = {}\n    # create a dictionary to represent the image data\n    for filename in os.listdir(image_path):\n        if filename.endswith(\".jpg\"): \n            res = fpatt.match(filename)\n            if res.group(1) in image_info:\n                image_info[res.group(1)][res.group(2)] = {}\n            else:\n                image_info[res.group(1)] = {}\n                image_info[res.group(1)][res.group(2)] = {}\n    \n    for filename in os.listdir(meta_path):\n        if filename.endswith(\".json\"): \n            with open(os.path.join(meta_path, filename)) as json_file:  \n                jsond = json.load(json_file)\n                res = fpatt.match(filename)\n                assert res.group(1) in image_info\n                pet_record = image_info[res.group(1)]\n                if res.group(2) in pet_record:\n                    img_record = pet_record[res.group(2)]\n                    # face annotation\n                    if 'faceAnnotations' in jsond:\n                        img_record['face'] = {}\n                        for f in FACE_ANNOTATION_FIELDS:\n                            img_record['face'][f] = jsond['faceAnnotations'][0][f]\n                    else:\n                        img_record['face'] = None\n                    # label annotations\n                    if 'labelAnnotations' in jsond:\n                        img_record['labels'] = [x['description'] for x in jsond['labelAnnotations']]\n                    else:\n                        img_record['labels'] = []\n                else:\n                    print(\"DIAG: missing {0} for {1}\".format(res.group(2), res.group(1)))\n                    break\n                \n    return image_info\n\ntrain_image_info = get_image_info('../input/train_images/', '../input/train_metadata/')\ntest_image_info = get_image_info('../input/test_images/', '../input/test_metadata/')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19313ccceea97559ed0b17556f8c288e636ef8a3"},"cell_type":"markdown","source":"How many pets have images?"},{"metadata":{"trusted":true,"_uuid":"6db90b35e1ff37aee5a5473d3abf5b13d1535bb6"},"cell_type":"code","source":"s_img = df_train['PetID'].isin(train_image_info.keys())\nprint(\"Train set image prevalence:\\n{0}\".format(s_img.groupby(s_img).size() / len(s_img)))\ns_img = df_test['PetID'].isin(test_image_info.keys())\nprint(\"Test set image prevalence:\\n{0}\".format(s_img.groupby(s_img).size() / len(s_img)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6912becc955c8cbc274af917fb8dccbfb260a87e"},"cell_type":"markdown","source":"Great - more than 95% of the listings have images.  We'll want to include this in our analysis.  The image_info contains some extracted metadata, specifically around face detection, image quality and labels."},{"metadata":{"_uuid":"b259f743b0bfbeab147f5cdcf7fbd8f38dac2aad"},"cell_type":"markdown","source":"Let's extract some of the metadata around the first image (profile picture) into a DF for analysis."},{"metadata":{"trusted":true,"_uuid":"69d5207cabbf68d0805f02d9155b5854d4d9267d"},"cell_type":"code","source":"df_train_pix = pd.DataFrame(index=df_train.index, columns=['angerLikelihood','blurredLikelihood','detectionConfidence','joyLikelihood','sorrowLikelihood','surpriseLikelihood','underExposedLikelihood','rec_cat','rec_dog'])\ndf_train_pix['PetID'] = df_train['PetID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"680042dca936f463d09bb5e5f9eb11eb1eec24c9"},"cell_type":"code","source":"for idx, row in df_train_pix.iterrows():\n    if row['PetID'] in train_image_info:\n        pet_record = train_image_info[row['PetID']]\n        image_record = pet_record[\"1\"]\n        data = []\n        if image_record['face']:\n            for faf in FACE_ANNOTATION_FIELDS:\n                data.append(image_record['face'][faf])\n        else:\n            for faf in FACE_ANNOTATION_FIELDS:\n                data.append(None)\n\n        if 'cat' in image_record['labels']:\n            data.append(True)\n        else:\n            data.append(False)\n        \n        if 'dog' in image_record['labels']:\n            data.append(True)\n        else:\n            data.append(False)\n        \n        df_train_pix.loc[idx,0:9] = data\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87260a4ef65e056421f6939fc2912999965948ac"},"cell_type":"code","source":"df_train_pix[TARGET_COL] = df_train[TARGET_COL]\ndf_train_pix['Type'] = df_train['Type']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d07fce2809905b533de6230fb1fd961f3181cbd7"},"cell_type":"code","source":"for c in FACE_ANNOTATION_FIELDS:\n    print(\"{0}:{1}\".format(c, df_train_pix[c].unique()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38e4d0927abad9337fd7363278497f3f5747ac59"},"cell_type":"markdown","source":"There might be some interesting effect if humans interpret sorrow, joy or anger.  Let's use this."},{"metadata":{"trusted":true,"_uuid":"8271d4deabdcee066273c3d9d9c3a432d5c19d1a"},"cell_type":"code","source":"print('Misrec dogs: {0}'.format(len(df_train_pix[(df_train_pix['Type'] == 1)&(df_train_pix['rec_dog'] == False)])))\nprint('Misrec cats: {0}'.format(len(df_train_pix[(df_train_pix['Type'] == 2)&(df_train_pix['rec_cat'] == False)])))\n\nprint(\"Mean adoption time: {0:0.2f} vs misrec dog pix adotion time: {1:0.2f}\".format(\n    df_train[df_train_pix['Type'] == 1][TARGET_COL].mean(),\n    df_train[(df_train_pix['Type'] == 1)&(df_train_pix['rec_dog'] == False)][TARGET_COL].mean()\n))\n\nprint(\"Mean adoption time: {0:0.2f} vs misrec cat pix adotion time: {1:0.2f}\".format(\n    df_train[df_train_pix['Type'] == 2][TARGET_COL].mean(),\n    df_train[(df_train_pix['Type'] == 2)&(df_train_pix['rec_cat'] == False)][TARGET_COL].mean()\n))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f2aff9441922ee9450c50934effad3741e0c3bc"},"cell_type":"markdown","source":"The labeling seems to be pretty accurate.  There seems to be a bit of a negative impact on adoption time with mis-rec pictures, so we should include that as a feature.\n"},{"metadata":{"trusted":true,"_uuid":"73876480434383233dc52000030b3ad0107ba465"},"cell_type":"markdown","source":"## explore sentiment"},{"metadata":{"trusted":true,"_uuid":"330a1addb5919f1f6fff789d82af9ce750b2620e"},"cell_type":"code","source":"fspatt = re.compile(\"([0-9a-zA-Z]+)\\.(.+)\")\ndef get_sentiment_info(sentiment_path):\n    sentiment_info = {}\n    for filename in os.listdir(sentiment_path):\n        if filename.endswith(\".json\"): \n            res = fspatt.match(filename)\n            sentiment_info[res.group(1)] = {}    \n            with open(os.path.join(sentiment_path, filename)) as json_file:  \n                jsond = json.load(json_file)\n                sentiment_info[res.group(1)]['score'] = jsond['documentSentiment']['score']\n                sentiment_info[res.group(1)]['magnitude'] = jsond['documentSentiment']['magnitude']     \n    return sentiment_info\n\ntrain_sentiment_info = get_sentiment_info('../input/train_sentiment/')\ntest_sentiment_info = get_sentiment_info('../input/test_sentiment/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1647675647787340ad2017a249df033f31796e37"},"cell_type":"code","source":"s_sen = df_train['PetID'].isin(train_sentiment_info.keys())\nprint(\"Train set image prevalence:\\n{0}\".format(s_sen.groupby(s_sen).size() / len(s_sen)))\ns_sen = df_test['PetID'].isin(test_sentiment_info.keys())\nprint(\"Test set image prevalence:\\n{0}\".format(s_sen.groupby(s_sen).size() / len(s_sen)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3ec64311c97b4325f35c174dbe2927213ca1d4b"},"cell_type":"markdown","source":"Great, most pets have a sentiment score.  Let's see what they look like..."},{"metadata":{"trusted":true,"_uuid":"5fb8a497303f0e52b20a1bc580b3e313fdadaf37"},"cell_type":"code","source":"df_train_sentiment = pd.DataFrame(index=df_train.index, columns=['score','magnitude'])\ndf_train_sentiment['PetID'] = df_train['PetID']\nfor idx, row in df_train_sentiment.iterrows():\n    if row['PetID'] in train_sentiment_info:\n        pet_record = train_sentiment_info[row['PetID']]\n        data = []\n        data.append(pet_record['score'])\n        data.append(pet_record['magnitude'])\n        df_train_sentiment.loc[idx,0:2] = data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1defbb9615d0a4913bcb241c64ae2fb21a03f82a"},"cell_type":"code","source":"df_train_sentiment.fillna(0.0, inplace=True)\ndf_train_sentiment[TARGET_COL] = df_train[TARGET_COL]\ndf_train_sentiment['Type'] = df_train['Type']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7c588dd30c321801d12be24e16ac78deeec0bbf"},"cell_type":"code","source":"df_train_sentiment[['score', 'AdoptionSpeed']].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cad14b19b938bda4c5caa0972c26599eebe9d8f0"},"cell_type":"code","source":"def calc_full_sentiment(score, magnitude):\n    if (score < 0 ) and (magnitude > 0.25):\n        return -2\n    elif (score < 0 ):\n        return -1\n    elif score == 0:\n        return 0\n    elif score > 0 and magnitude > 0.25:\n        return 2\n    else:\n        return 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84c77109c289f4e81e7bec7c56bac4e14c55681f"},"cell_type":"code","source":"df_train_sentiment['sent_agg'] = df_train_sentiment.apply(lambda x: calc_full_sentiment(x['score'],x['magnitude']), axis=1)\ndf_g = df_train_sentiment[['sent_agg', 'AdoptionSpeed', ]].groupby(['sent_agg', 'AdoptionSpeed', ]).size().unstack()\ndf_g.div(df_g.sum(1), axis=0).plot.bar(figsize=(12,5), colormap='tab20', stacked=True).legend(loc='center left', bbox_to_anchor=(1, 0.5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"221dbc9495d185b61c5cdb8da3759ed4393ffa4b"},"cell_type":"markdown","source":"Hmmm.  Even though score and adoption speed don't seem to correlate strongly there's clearly some impact to adoption rate, especially with \"mildly negative\" sentiments.  Let's use this.  "},{"metadata":{"trusted":true,"_uuid":"401827380d10456660afcda672aa006f2b83c4d8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}