{"nbformat_minor": 1, "cells": [{"source": ["import pandas as pd\n", "import numpy as np\n", "import xgboost as xgb\n", "import time\n", "\n", "def change_datatype(df):\n", "    for col in list(df.select_dtypes(include=['int']).columns):\n", "        if np.max(df[col]) <= 127 and np.min(df[col]) >= -128:\n", "            df[col] = df[col].astype(np.int8)\n", "        elif np.max(df[col]) <= 255 and np.min(df[col]) >= 0:\n", "            df[col] = df[col].astype(np.uint8)\n", "        elif np.max(df[col]) <= 32767 and np.min(df[col]) >= -32768:\n", "            df[col] = df[col].astype(np.int16)\n", "        elif np.max(df[col]) <= 65535 and np.min(df[col]) >= 0:\n", "            df[col] = df[col].astype(np.uint16)\n", "        elif np.max(df[col]) <= 2147483647 and np.min(df[col]) >= -2147483648:\n", "            df[col] = df[col].astype(np.int32)\n", "        elif np.max(df[col]) <= 4294967296 and np.min(df[col]) >= 0:\n", "            df[col] = df[col].astype(np.uint32)\n", "    for col in list(df.select_dtypes(include=['float']).columns):\n", "        df[col] = df[col].astype(np.float32)\n", "        \n", "def count_words(key):\n", "    return len(str(key).split())\n", "\n", "def count_numbers(key):\n", "    return sum(c.isalpha() for c in key)\n", "\n", "def count_upper(key):\n", "    return sum(c.isupper() for c in key)\n", "\n", "def get_mean(df, name, target, alpha=0):\n", "    group = df.groupby(name)[target].agg([np.sum, np.size])\n", "    mean = train[target].mean()\n", "    series = (group['sum'] + mean*alpha)/(group['size']+alpha)\n", "    series.name = name + '_mean'\n", "    return series.to_frame().reset_index()\n", "\n", "def add_words(df, name, length):\n", "    x_data = []\n", "    for x in df[name].values:\n", "        x_row = np.ones(length, dtype=np.uint16)*0\n", "        for xi, i in zip(list(str(x)), np.arange(length)):\n", "            x_row[i] = ord(xi)\n", "        x_data.append(x_row)\n", "    return pd.concat([df, pd.DataFrame(x_data, columns=[name+str(c) for c in range(length)]).astype(np.uint16)], axis=1)\n", "\n", "start_time = time.time()\n", "c_categories = ['name', 'category_name', 'brand_name', 'item_description']\n", "c_means = ['category_name', 'item_condition_id', 'brand_name']\n", "c_texts = ['name', 'item_description']\n", "c_ignors = ['name', 'item_description', 'brand_name', 'category_name', 'train_id', 'test_id', 'price']\n", "\n", "train = pd.read_csv('../input/train.tsv', sep='\\t')\n", "test = pd.read_csv('../input/test.tsv', sep='\\t')\n", "test['price'] = -1\n", "\n", "df = pd.concat([train, test]).reset_index()\n", "change_datatype(df)\n", "df = df.fillna('')\n", "df = add_words(df, 'name', 43) \n", "df = add_words(df, 'item_description', 60)\n", "for c in c_categories:\n", "     df[c+'_cat'] = pd.factorize(df[c])[0]\n", "\n", "for c in c_texts:\n", "    df[c + '_c_words'] = df[c].apply(count_words)\n", "    df[c + '_c_upper'] = df[c].apply(count_upper)\n", "    df[c + '_c_numbers'] = df[c].apply(count_numbers)\n", "    df[c + '_len'] = df[c].str.len()\n", "    df[c + '_mean_len_words'] = df[c + '_len']/df[c + '_c_words']\n", "    df[c + '_mean_upper'] = df[c + '_len']/df[c + '_c_upper']\n", "    df[c + '_mean_numbers'] = df[c + '_len']/df[c + '_c_numbers']\n", "    \n", "#------- begin feature engineering (Leandro dos Santos Coelho)\n", "df['fe001'] = np.square(df[\"name_mean_len_words\"])\n", "df['fe002'] = np.square(df[\"item_description_mean_len_words\"])\n", "df['fe003'] = np.tanh(df[\"name_mean_len_words\"])\n", "df['fe004'] = np.tanh(df[\"item_description_mean_len_words\"])\n", "df['fe005'] = df[\"name_mean_len_words\"]**2.37\n", "df['fe006'] = df[\"item_description_mean_len_words\"]**2.15\n", "#------- end feature engineering (Leandro dos Santos Coelho)\n", "    \n", "test = df[df['price'] == -1]\n", "train = df[df['price'] != -1]\n", "del df\n", "\n", "train, valid = np.split(train.sample(frac=1), [int(.75*train.shape[0])])\n", "\n", "for c in c_means:\n", "    mean = get_mean(train, c, 'price')\n", "    test = test.merge(mean, on=[c], how='left')\n", "    train = train.merge(mean, on=[c], how='left')\n", "    valid = valid.merge(mean, on=[c], how='left')\n", "\n", "col = [c for c in train.columns if c not in c_ignors]\n", "\n", "dtrain = xgb.DMatrix(train[col], train['price'])\n", "dvalid  = xgb.DMatrix(valid[col],  valid['price'])\n", "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n", "params = {'min_child_weight': 20, 'eta': 0.015, 'colsample_bytree': 0.48, 'max_depth': 14,\n", "            'subsample': 0.91, 'lambda': 2.01, 'nthread': 4, 'booster' : 'gbtree', 'silent': 1,\n", "            'eval_metric': 'rmse', 'objective': 'reg:linear','tree_method': 'hist'}\n", "model = xgb.train(params, dtrain, 1000, watchlist, verbose_eval=10, early_stopping_rounds=20)\n", "test['price'] = model.predict(xgb.DMatrix(test[col]), ntree_limit=model.best_ntree_limit)\n", "test.loc[test['price'] < 0, 'price'] = 0\n", "test['test_id'] = test['test_id'].astype(int)\n", "test[['test_id', 'price']].to_csv(\"sample.csv\", index = False)\n", "print(\"Finished ...\")\n", "tt = (time.time() - start_time)/60\n", "print(\"Total time %s min\" % tt)"], "outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "11f04a05-ceb3-45f2-bf87-20f94dd289cb", "_kg_hide-output": false, "_uuid": "d0b7ec16e0d07064fdb865c652c0a270a8c7c598"}, "execution_count": null}], "nbformat": 4, "metadata": {"language_info": {"file_extension": ".py", "name": "python", "nbconvert_exporter": "python", "mimetype": "text/x-python", "version": "3.6.3", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}}