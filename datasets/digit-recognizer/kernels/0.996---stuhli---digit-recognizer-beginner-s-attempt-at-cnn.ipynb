{"cells":[{"metadata":{"_uuid":"0dbfca01abfcd039ca5e9e0b614a032561fd078c"},"cell_type":"markdown","source":"An attempt at building a Convolutional Neural Network (CNN) for automatic digit classification using the MNIST dataset.\n\nThis is my first attempt at image recognition. Sources that I used for inspiration/guidance/lookup when I got stuck were:\n\n[https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6](https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6)\n\n[https://www.kaggle.com/toregil/welcome-to-deep-learning-cnn-99](https://www.kaggle.com/toregil/welcome-to-deep-learning-cnn-99)\n\nRunning time on GPU: 5 min"},{"metadata":{"_uuid":"78e23a9c9d0511fc10528cfeec5065010a9bb685"},"cell_type":"markdown","source":"**Importing Libraries**\n\n\nFirst of all, the necessary libraries need to be imported."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# importing libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting graphs\nimport matplotlib.image as mpimg # plotting images\n%matplotlib inline\nimport seaborn as sns # more graphs\n\n# some machine learning tools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n# neural network tools\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.preprocessing.image import ImageDataGenerator # for data augmentation\nfrom keras.callbacks import ReduceLROnPlateau, LearningRateScheduler # for adapting learning rate\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf8337aa8740314518d189dcc4aa9d6089c55fd8"},"cell_type":"code","source":"# adapting plot style\nsns.set(style='white', context='notebook', palette='deep')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7bb5749594d6e274b4e9905e66a4675155e2c46b"},"cell_type":"markdown","source":"**The Data**\n\nTime to load in the training and test datasets."},{"metadata":{"trusted":true,"_uuid":"f9e7fafc741f13d7adf7ade8e9180476a165cb6b"},"cell_type":"code","source":"# Load data\nX_train = pd.read_csv('../input/train.csv')\nX_test = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9016e7cd0dcfe278705917a4db746f8e714d3fc"},"cell_type":"markdown","source":"Now for a first glance at the datasets:"},{"metadata":{"trusted":true,"_uuid":"ac174a8daef5399ea91f4c1937907ae435c006d3"},"cell_type":"code","source":"# training dataset\nprint(X_train.shape)\nprint(X_train.info())\nprint(X_train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4c02ab24530ae2709fbe4c38740a2aa9c235b7b"},"cell_type":"code","source":"# test dataset\nprint(X_test.shape)\nprint(X_test.info())\nprint(X_test.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f431510fb8964bab979cd44bbe21dbd67c780cd0"},"cell_type":"markdown","source":"So the training dataset has one additional column \"label\". This is what we're expected to predict on the test set. The correct labels need to be dropped from the training set and stored as the expected training output:"},{"metadata":{"trusted":true,"_uuid":"b012fc4349703a3a5f2704f26ba110580cb3a034"},"cell_type":"code","source":"# drop label column and store it as expected output\ny_train = X_train.pop('label')\n\n# double check\nprint(y_train.shape)\nprint(X_train.shape, X_test.shape)\nprint(X_train.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae34a8b9e2b1d7334d78b06c49a73c4277aa68d1"},"cell_type":"markdown","source":"Are any of the classes over- or underrepresented?"},{"metadata":{"trusted":true,"_uuid":"d5b2393791f015161f28ee9456a1fc0f65a74806"},"cell_type":"code","source":"y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29dec1b06e47fae1048fe05704b18d3dd432afcc"},"cell_type":"markdown","source":"Good enough. Are there any missing or other NaN values? NaNs inside X_train or X_test could indicate a corrupted image file and NaNs inside y_train would be missing classification labels"},{"metadata":{"trusted":true,"_uuid":"ae807f600600ebdd723ef015a9fc4c554b1c488b"},"cell_type":"code","source":"# NaN in training input\nprint(X_train.isnull().values.any())\n# NaN in test input\nprint(X_test.isnull().values.any())\n# NaN in training expected output\nprint(y_train.isnull().values.any())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9cd8805e2c31b9b7ba0a55a2f284c7396bc98331"},"cell_type":"markdown","source":"No, none. \n\nSo what about the image data? What values represent the pixels?"},{"metadata":{"trusted":true,"_uuid":"e13f405b2e4207fd2771e35127e43ede51e4145a"},"cell_type":"code","source":"print(X_train.apply(pd.value_counts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e3939f2d756dc47b83863d8aed3182d61e37dda"},"cell_type":"markdown","source":"Values between 0 and 255. That's a dataset of grayscale images. We should perform grayscale normalization to get values between 0 and 1 as that's easier to work with and will speed up the model too."},{"metadata":{"trusted":true,"_uuid":"eadfd9b1e9571b3f2c5f7329ae74e1b22d88b9c5"},"cell_type":"code","source":"X_train = X_train / 255.0\nX_test = X_test / 255.0\n\n# check values\n# print(X_train.apply(pd.value_counts))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93afcfe432991bf51b3606da7030f999233dbb77"},"cell_type":"markdown","source":"Next we need to reshape the images."},{"metadata":{"trusted":true,"_uuid":"7488c70a6e34cd633f4610b7ee012c18f0cb2adc"},"cell_type":"code","source":"# the shape should be 28x28x1 as keras requires an additional dimension for the canal\nX_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)\n\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63fee4508807a5de6101c1faf076da91048d537a"},"cell_type":"markdown","source":"Right now the labels in y_train are single digit values ranging from 0 to 9. The model will work with one-hot vectors as its output though, so we need to change the encoding:"},{"metadata":{"trusted":true,"_uuid":"fa80ea5df61c15a3580c15f4cb217ed9cda5e585"},"cell_type":"code","source":"y_train = to_categorical(y_train, num_classes=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b993c5332ca8f646d736c3d6bfeb26ef30e7931"},"cell_type":"markdown","source":"Next we will split the X_train input and y_train expected output into a training and a validation set."},{"metadata":{"trusted":true,"_uuid":"0ed00b0958dc146beebefc71c5540032d2863424"},"cell_type":"code","source":"## For now we will use a small training set (and consequently a large validation set)\n## to speed up the running time during prototyping\n## This will need to be changed before tuning the hyperparameters\n## \n## temporary split\n#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.9, random_state=42)\n## replace with final split\n\n# final train-test split\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f65af5ed76b64ce57b41dc84b5eaf170b73aa836"},"cell_type":"markdown","source":"**The Model**\n\nNow we can finally build and train the model. Since we are dealing with images a convolutional neural network (CNN) seems like a good choice. CNNs generally perform well at image recognition tasks. As the classification of an image does not depend on any previous input we can stick with a conventional non-recurrent CNN. This is easily done in keras by instantiating a Sequential object and adding layers to it:"},{"metadata":{"trusted":true,"_uuid":"9bf72d94af445f510e0300165fcb8319f84b56c2"},"cell_type":"code","source":"# create model\nmodel = Sequential()\n\n# (Conv2D -> BatchNormalization) * 2 -> MaxPool2D -> Dropout\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', \n                 input_shape=(28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(4,4), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n# repeat above sequence\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(4,4), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n# Flatten -> Dense -> Dropout -> Dense\nmodel.add(Flatten())\nmodel.add(Dense(units=128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(units=10, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97789fc296d3ac53cdaaae4d742bdf56715ea04a"},"cell_type":"markdown","source":"Next we need to define an optimizer:"},{"metadata":{"trusted":true,"_uuid":"5b47641b4b251d9bf50eb1c554f22755e0860975"},"cell_type":"code","source":"# the default parameter settings of RMSprop should work fine\n# but maybe the learning rate needs to be changed later\noptimizer = RMSprop()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24e27a28e959761fb977c73885923dd5e2c1b90c"},"cell_type":"markdown","source":"Now the model can be compiled:"},{"metadata":{"trusted":true,"_uuid":"5c8e1a9efe6bb1bef153f90619922a0cf1c4c4a9"},"cell_type":"code","source":"model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38dfe660231473e7b9d91263473cfb103977d6f0"},"cell_type":"markdown","source":"To make the CNN converge faster and more efficiently, we will set a decreasing learning rate. The built-in callback ReduceLROnPlateau from keras automatically reduces the learning rate when a metric has stopped improving."},{"metadata":{"trusted":true,"_uuid":"21d5d2ea329950710cba0f47fe4a6dce82e6af1c"},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n                              patience=2, min_lr=0.000001, verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb1539ff51d08a80268b0fe6b2dad3d6f745bc76"},"cell_type":"code","source":"# some additional parameter settings for the model\nepochs = 30\nbatch_size = 86\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a5dbb23eb039c0148edbb60721a409495d7c11c"},"cell_type":"markdown","source":"**Data Augmentation**\n\nWhen it comes to digit recognition or other computer vision tasks the robustness of a neural network - that is its ability to classify new input - depends a great deal on the size and quality of the training set. If all digits in the training set were written by the same person, the model would perform poorly on test images of digits in the handwriting of somebody else. However we want our model to translate well to handwritings not seen before during training. To increase its performance we need a large and varied training set.\n\nIf, for example, training images contain digits that are not always perfectly centered, that are rotated to the left or right, of different size etc. the network will focus on learning important features of the digits' form rather than their positions. One way to improve the model's ability to capture such variability in handwriting is to automatically create modifications of existing images and add them to the training set.\n\nKeras offers a simple way to do this with the ImageDataGenerator class:"},{"metadata":{"trusted":true,"_uuid":"e152b321f577eb57111cdf1fcbba2ecb73019bf5"},"cell_type":"code","source":"datagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, \n                             height_shift_range=0.1, zoom_range=0.1, \n                             fill_mode='nearest')\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e68b8c446e9f07a2475f452738fd934990001937"},"cell_type":"markdown","source":"Now we can fit the training dataset:"},{"metadata":{"trusted":true,"_uuid":"ed49d8216576513b2e87e534ee39b73543640371"},"cell_type":"code","source":"fit_model = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n                                epochs=epochs, validation_data=(X_val, y_val), verbose=2,\n                                steps_per_epoch=X_train.shape[0] // batch_size, \n                                callbacks=[reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"582049d2555659d167587c9a21ffbc6188416fe2"},"cell_type":"markdown","source":"**Evaluation**\n\nLet's have a closer look at how the model performed during training."},{"metadata":{"trusted":true,"_uuid":"28f242ed586251663ceec5df1b2bb4a57ae5641e"},"cell_type":"code","source":"# plot the loss functions\nplt.plot(fit_model.history['loss'], color='b', label='Training loss')\nplt.plot(fit_model.history['val_loss'], color='r', label='Validation loss')\nplt.title('Loss functions')\nplt.legend()\nplt.show()\n\n# plot the development of the model's accuracy\nplt.plot(fit_model.history['acc'], color='b', label='Training accuracy')\nplt.plot(fit_model.history['val_acc'], color='r', label='Validation accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"046583909af57a7c93ba3d26503ccd6b87676803"},"cell_type":"markdown","source":"The loss functions don't look too bad. The model saturates after just a couple of epochs and the curves flatten out.\n\nThe accuracy seems to be rather satisfying as well for a first attempt."},{"metadata":{"_uuid":"3b02fc71205da10568f42a57c87eed5ca9fba230"},"cell_type":"markdown","source":"Next we should have a look at the confusion matrix to see which digits are misclassified by the model and for which digits they were mistaken."},{"metadata":{"trusted":true,"_uuid":"e67edcbd7ada4dd46567d65586edf9c45852ea3e"},"cell_type":"code","source":"def create_model_confusion_matrix(model, X_input, y_expected):\n    \"\"\"\n    This function creates the confusion matrix and plots it.\n    \"\"\"\n    # let the model predict the output given X_input\n    y_predicted = model.predict(X_input)\n    # convert predicted and expected output from one-hot vector to label\n    y_predicted_classes = np.argmax(y_predicted, axis=1)\n    y_expected_classes = np.argmax(y_expected, axis=1)\n    \n    # calculate the confusion matrix and convert it\n    # to a DataFrame object for plotting\n    cm = confusion_matrix(y_expected_classes, y_predicted_classes)\n    df_cm = pd.DataFrame(cm, range(10), range(10))\n    \n    # plot the confusion matrix\n    ax = sns.heatmap(df_cm)\n    ax.set(xlabel='expected', ylabel='predicted')\n    ax.set_title('Confusion Matrix')\n    plt.show()\n    \n    return df_cm\n\ncreate_model_confusion_matrix(model, X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad6ca994b4b7abf280563894e690abcb3ba0fc9b"},"cell_type":"markdown","source":"This pretty much cofirms the findings of the accuracy curves above: The vast majority of digits is classified correctly. \n\nThere are a couple of mistakes though. 9 and 4 seem to be confused on occasion as are 6 and 5 or 7 and 1. These digits can indeed look similiar in some people's handwriting. "},{"metadata":{"trusted":true,"_uuid":"1398e3faa2dc8dc03cdc76c35c928a5df3b9dbbf"},"cell_type":"markdown","source":"Maybe we should have a look at some random images and how they were classified by the CNN:"},{"metadata":{"trusted":true,"_uuid":"cad1327d2887dcaa52390712acfea1d7dfa04adb"},"cell_type":"code","source":"# the necessary functions for plotting images along with their \n# predicted and expected labels\n\ndef plot_labeled_images(model, X_input, y_expected, mode='random'):\n    \"\"\"\n    This function plots a total of 9 images from the given set \n    along with their predicted and expected labels.\n    \n    The function has two modes: 'random' and 'errors'.\n    If mode is set to 'random', random images are plotted.\n    If mode is set to 'errors', only images are plotted where the predicted \n    label does not match the expected one.\n    \"\"\"\n    num = 9\n    if mode == 'random':\n        selected_digits = get_random_digits(model, X_input, y_expected, num)\n    elif mode == 'errors':\n        selected_digits = get_error_digits(model, X_input, y_expected, num)\n    else:\n        raise ValueError(\"Unknown value for mode. Only 'random' and 'errors' are accepted.\")\n    \n    # plot the digits\n    n = 0\n    rows = 3\n    cols = 3\n    fig, ax = plt.subplots(rows, cols ,sharex=True, sharey=True)\n    plt.subplots_adjust(top=1.5) \n    for row in range(rows):\n        for col in range(cols):\n            ax[row, col].imshow(selected_digits[n][0].reshape((28, 28)))\n            ax[row, col].set_title(\"Predicted label: {}\\nExpected label: {}\".format(\n                selected_digits[n][1], selected_digits[n][2]\n            ))\n            n +=1\n\ndef get_random_digits(model, X_input, y_expected, num):\n    \"\"\"\n    This function returns a total of num random digits from the dataset.\n    The output is a len(num) tuple of tuples containing an input array, \n    predicted label and expected label each.\n    \"\"\"\n    # let the model predict the output given X_input\n    y_predicted = model.predict(X_input)\n    # convert predicted and expected output from one-hot vector to label\n    y_predicted_classes = np.argmax(y_predicted, axis=1)\n    y_expected_classes = np.argmax(y_expected, axis=1)\n    \n    # get num random digits (image, predicted label, expected label)\n    digit_sets = get_digit_sets(\n        num, X_input, y_expected_classes, y_predicted_classes\n    )\n    \n    return digit_sets\n\ndef get_error_digits(model, X_input, y_expected, num):\n    \"\"\"\n    This function returns a total of num random digits from the dataset\n    where the predicted label does not match the expected one.\n    The output is a len(num) tuple of tuples containing an input array, \n    predicted label and expected label each.\n    \"\"\"\n    # let the model predict the output given X_input\n    y_predicted = model.predict(X_input)\n    # convert predicted and expected output from one-hot vector to label\n    y_predicted_classes = np.argmax(y_predicted, axis=1)\n    y_expected_classes = np.argmax(y_expected, axis=1)\n    \n    # pick only instances where predicted and expected labels don't match\n    errors = (y_predicted_classes - y_expected_classes != 0)\n    y_predicted_classes_errors = y_predicted_classes[errors]\n    y_expected_classes_errors = y_expected_classes[errors]\n    X_input_errors = X_input[errors]\n    \n    # get num random digits (image, predicted label, expected label)\n    digit_sets = get_digit_sets(\n        num, X_input_errors, \n        y_expected_classes_errors, y_predicted_classes_errors\n    )\n    \n    return digit_sets\n    \ndef get_digit_sets(num, X_possible, y_expected_classes, y_predicted_classes):\n    \"\"\"\n    This function returns a tuple of len(num) containing random digit images\n    along with their expected and predicted labels. \n    \n    Each entry of the tuple is itself a tuple of the form \n    (image, y_predicted, y_expected).\n    \"\"\"\n    indices = np.random.randint(X_possible.shape[0], size=num)\n    digit_sets = tuple((X_possible[i], y_predicted_classes[i], y_expected_classes[i])\n                      for i in indices)\n    return digit_sets\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0b21c762dd5d171daf34d87c340862ec351dd20"},"cell_type":"code","source":"# plot some random images to see whether they are labeled correctly\nplot_labeled_images(model, X_val, y_val, mode='random')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c407d8f5931148c7fb0edc2044a32a2eb074c6e"},"cell_type":"markdown","source":"This seems good enough. These digits are usually classified as they should be.\n\nSo let's have a look at some images that were misclassified:"},{"metadata":{"trusted":true,"_uuid":"e557f3b13b739c7da0c5e85f8ce8da138e4bc7d2"},"cell_type":"code","source":"plot_labeled_images(model, X_val, y_val, mode='errors')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8bbf8eb14b7236908cd933309cdc571b4956587"},"cell_type":"markdown","source":"Most of the misclassified digits seem to be rather tricky indeed. More often than not even a human reader could struggle with them."},{"metadata":{"_uuid":"97e4909d7f2138c7db1e0a6b0f2fd086a58ab9d3"},"cell_type":"markdown","source":"**Submitting Predictions**\n\nTime to finally submit the results:"},{"metadata":{"trusted":true,"_uuid":"c1752c97eb48be1c8da9b0b11ac1277513bf4e03"},"cell_type":"code","source":"# predict results\ny_test_pred = model.predict(X_test)\n\n# select the indices with the highest probability\n# these are our predicted labels\ny_test_pred = np.argmax(y_test_pred, axis=1)\n\n# convert to DataFrame object\ny_test_pred = pd.Series(y_test_pred, name=\"Label\")\n\n# convert to CSV file as required\nsubmission = pd.concat([pd.Series(range(1, 28001), name=\"ImageId\"), y_test_pred], axis=1)\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}