{"cells": [{"execution_count": null, "cell_type": "code", "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.model_selection import train_test_split\n", "from keras.models import Sequential\n", "from keras.layers.core import Dense, Activation, Dropout\n", "from keras.layers.embeddings import Embedding\n", "from keras.utils import np_utils\n", "from keras.preprocessing.text import Tokenizer\n", "from keras.preprocessing.sequence import pad_sequences\n", "from sklearn import preprocessing\n", "from keras.utils import to_categorical\n", "from keras.layers.recurrent import LSTM\n", "from keras.layers import Dense, GlobalAveragePooling1D, Embedding\n", "from keras.layers import Bidirectional\n", "from keras.layers.normalization import BatchNormalization\n", "from keras import regularizers\n", "from keras.callbacks import EarlyStopping\n", "import time\n", "\n", "#read the data\n", "train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')\n"], "metadata": {"_uuid": "8a72d0f0d29657e818fcc1e8954e7538ea584526", "_cell_guid": "f6dcd221-0263-4b47-95cf-2c764248db8a"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["content1=[] #train_content\n", "content2=[] #test content\n", "\n", "for i in range(train.shape[0]):\n", "    mytext=train.iloc[i,1]\n", "    content1.append(mytext)\n", "for i in range(test.shape[0]):\n", "    mytext=test.iloc[i,1]\n", "    content2.append(mytext)\n", "\n", "#word embedding,got x\n", "tokenizer = Tokenizer(num_words=None)\n", "tokenizer.fit_on_texts(content1 + content2)\n", "train_seq= tokenizer.texts_to_sequences(content1)\n", "test_seq=tokenizer.texts_to_sequences(content2)\n", "train_pad = pad_sequences(train_seq,maxlen=256,padding='post') #pad to the same length\n", "test_pad = pad_sequences(test_seq,maxlen=256,padding='post')\n", "print('train input data')\n", "print(train_pad)"], "metadata": {}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["#y one hot"], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["label= preprocessing.LabelEncoder()\n", "label_y= label.fit_transform(train.author.values)\n", "y = to_categorical(label_y,num_classes=3)\n", "print(y)"], "metadata": {}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["train_x, test_x, train_y, test_y = train_test_split(train_pad,y,random_state=42,test_size=0.2)\n", "time_start=time.time()"], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["model = Sequential()\n", "model.add(Embedding(len(tokenizer.word_index) + 1, 256))\n", "model.add(Bidirectional(LSTM(256,dropout=0.3,kernel_regularizer=regularizers.l2(0.03),return_sequences=True)))\n", "model.add(Bidirectional(LSTM(256,dropout=0.3,kernel_regularizer=regularizers.l2(0.03))))\n", "model.add(Dropout(0.2))\n", "model.add(Dense(3))\n", "model.add(Activation('softmax'))\n", "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n", "model.summary()\n", "earlystop = EarlyStopping(monitor='val_loss', patience=2)\n", "hist=model.fit(train_x, train_y,batch_size=16,epochs=25,validation_data=(test_x, test_y),callbacks=[earlystop])"], "metadata": {}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": [], "metadata": {"collapsed": true}}], "nbformat": 4, "nbformat_minor": 1, "metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "version": "3.6.3", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}}