{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bc7bf112-d1c2-364c-0279-316987ced52c"
      },
      "source": [
        "# An exploration of using some classifiers to predict survival\n",
        "\n",
        "I'm new to Kaggle and have tried to apply some recommended techniques. However, I seem to be obtaining dismal results (unless I use an earlier approach which got me to the leaderboard).\n",
        "\n",
        "Perhaps some grand masters can point me in the right direction?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cc3d6f60-0fe0-2f9f-2e6e-e39a87eb12c0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import uuid\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import preprocessing\n",
        "from sklearn.svm import SVC\n",
        "import re\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def dictize(data_frame, full_data, columns):\n",
        "    names = set([])\n",
        "    for column in columns:\n",
        "        names = names.union(list(full_data[column].unique()))\n",
        "    names = list(enumerate(names))\n",
        "    dictionary = { name: i for i, name in names }\n",
        "\n",
        "    for column in columns:\n",
        "        data_frame[column] = data_frame[column].map( dictionary )\n",
        "    return dictionary\n",
        "\n",
        "def grid_search(clf_rf, param_grid, X_train, y_train, X_test, y_test, cv=3):\n",
        "    print ('Training Classifier...')\n",
        "\n",
        "    clf = GridSearchCV(clf_rf, param_grid, cv=cv)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()\n",
        "    return clf.best_params_\n",
        "    \n",
        "def accuracy(y_pred, y_true):\n",
        "    correct = 0\n",
        "    for i in range(len(y_pred)):\n",
        "        if y_pred[i] == y_true[i]:\n",
        "            correct = correct + 1\n",
        "    return float(correct) / float(len(y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f7f674e2-cf57-32a3-ad34-a80eac7e2895"
      },
      "source": [
        "Let do some exploratory data analysis to find out more about the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e1145ff5-d9de-0a94-dbd6-cdb279d52e89"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"../input/train.csv\")\n",
        "\n",
        "embarked_dict = { 'S': 0, 'C': 1, 'Q': 2}\n",
        "\n",
        "# Replace Sex with 1 for male and 0 for female\n",
        "train_df[\"Sex\"] = train_df[\"Sex\"].map(lambda x: 1 if x == \"male\" else 0)\n",
        "train_df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
        "train_df[\"Embarked\"] = train_df[\"Embarked\"].map(embarked_dict)\n",
        "train_df[\"FamilySize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\n",
        "\n",
        "\n",
        "test_df = pd.read_csv(\"../input/test.csv\")\n",
        "# Replace Sex with 1 for male and 0 for female\n",
        "test_df[\"Sex\"] = train_df[\"Sex\"].map(lambda x: 1 if x == \"male\" else 0)\n",
        "test_df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
        "test_df[\"Embarked\"] = test_df[\"Embarked\"].map(embarked_dict)\n",
        "test_df[\"FamilySize\"] = test_df[\"SibSp\"] + test_df[\"Parch\"] + 1\n",
        "\n",
        "combined_df = train_df.drop('Survived', axis=1).append(test_df)\n",
        "\n",
        "# Let's look at the combined test and train data frame\n",
        "combined_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "31931254-5cd7-55a2-9593-e1e6fa615d5a"
      },
      "source": [
        "Age and sex should be important factors in survival, after all, a ship is evacuated with \"Women and Children first\". So, we need to classify passengers as children or women.\n",
        "\n",
        "Number of Siblings and Spouses (SibSp), number of parents and children (Parch), the title of the person (for example \"Master\", \"Miss\", \"Mr\", etc.), the Age and the Sex should be an important feature for this classification.\n",
        "\n",
        "However, age is missing for a lot of rows, so we will need to impute it.\n",
        "\n",
        "Only one Fare is missing so we can impute that with the median fare.\n",
        "\n",
        "Below, we add the missing Fare entry, add another column for title:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d2c99db5-eef7-3997-baab-0e317e436014"
      },
      "outputs": [],
      "source": [
        "# 1. Add the missing fare entry in the frames\n",
        "median_fare = combined_df['Fare'].dropna().median()\n",
        "train_df.Fare.fillna(median_fare, inplace=True)\n",
        "test_df.Fare.fillna(median_fare, inplace=True)\n",
        "combined_df.Fare.fillna(median_fare, inplace=True)\n",
        "\n",
        "# Functions that returns the title from a name. All the name in the dataset has the format \"Surname, Title. Name\"\n",
        "def get_title(name):\n",
        "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
        "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "    # If the title exists, extract and return it.\n",
        "    if title_search:\n",
        "        return title_search.group(1)\n",
        "    return \"\"\n",
        "\n",
        "train_df[\"Title\"] = train_df.Name.map(get_title)\n",
        "test_df[\"Title\"] = train_df.Name.map(get_title)\n",
        "combined_df[\"Title\"] = train_df.Name.map(get_title)\n",
        "\n",
        "combined_df[\"Title\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "70f1b0b8-f8d5-ac03-d0a7-ad33fbb2c5f8"
      },
      "source": [
        "Next, we can standardise the less frequent titles to Mr, Mrs, Miss, Master, Dr, Rev, and Col:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6ca9ab34-f6f8-0a14-93dc-3420c342bc1f"
      },
      "outputs": [],
      "source": [
        "title_mapping = {\n",
        "    \"Mr\": 1,        # A man\n",
        "    \"Miss\": 2,      # An unmarried lady\n",
        "    \"Mrs\": 3,       # An married lady\n",
        "    \"Master\": 4,    # A young man\n",
        "    \"Dr\": 5,        # A doctor\n",
        "    \"Rev\": 6,       # A priest\n",
        "    \"Major\": 7,     # An army man\n",
        "    \"Col\": 7,       # An army man\n",
        "    \"Mlle\": 2,      # An unmarried lady\n",
        "    \"Mme\": 3,       # An married lady\n",
        "    \"Don\": 1,       # A man\n",
        "    \"Dona\":3,       # A married lady\n",
        "    \"Lady\": 3,      # An married lady\n",
        "    \"Countess\": 3,  # An married lady\n",
        "    \"Jonkheer\": 3,  # An married lady\n",
        "    \"Sir\": 1,       # A man\n",
        "    \"Capt\": 7,      # An army man\n",
        "    \"Ms\": 3}        # A divorced lady\n",
        "train_df[\"Title\"] = train_df['Title'].map(title_mapping)\n",
        "test_df[\"Title\"] = test_df['Title'].map(title_mapping)\n",
        "combined_df[\"Title\"] = combined_df['Title'].map(title_mapping)\n",
        "\n",
        "combined_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "10c7aec7-7fd3-c05c-2aaf-d7324cd5af8e"
      },
      "source": [
        "Let us now impute age based on the 1046 rows with age present in the train and test combined frame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8eddc08d-880e-97d6-0262-9fe08ea11cbb"
      },
      "outputs": [],
      "source": [
        "et_regressor = ExtraTreesRegressor(n_estimators=200)\n",
        "rf_regressor = RandomForestRegressor(n_estimators=200)\n",
        "\n",
        "predictors = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Title', 'Fare', 'Title']\n",
        "\n",
        "X_train = combined_df[combined_df['Age'].notnull()][predictors]\n",
        "Y_train = combined_df[combined_df['Age'].notnull()]['Age']\n",
        "X_test = combined_df.loc[combined_df.Age.isnull(), predictors]\n",
        "\n",
        "et_regressor.fit(X_train, np.ravel(Y_train))\n",
        "rf_regressor.fit(X_train, np.ravel(Y_train))\n",
        "predictions_et = et_regressor.predict(X_test)\n",
        "predictions_rf = rf_regressor.predict(X_test)\n",
        "\n",
        "predictions = (predictions_et + predictions_rf) / 2\n",
        "\n",
        "imputed_frame = combined_df.copy()\n",
        "imputed_frame.loc[combined_df.Age.isnull(), ['Age']] = predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6baf4d7c-fc96-dd5e-5876-a2a6a20e75ee"
      },
      "outputs": [],
      "source": [
        "# Clear any previous plots\n",
        "plt.clf()\n",
        "# Let's look at the distribution of the imputed ages\n",
        "#fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "predictions_frame = pd.DataFrame(predictions)\n",
        "predictions_frame.columns = ['Age']\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "predictions_frame['Age'].plot(kind='hist', title='Imputed Age Distribution')\n",
        "plt.subplot(1, 2, 2)\n",
        "combined_df[combined_df['Age'].notnull()]['Age'].plot(kind='hist', title='Actual Age Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "acfab1a8-6b78-ae61-ca6b-d4c74e524c99"
      },
      "source": [
        "We can see from the above two graphs, that the imputation matches the existing distibution of ages. \n",
        "\n",
        "Next, we merge the the imputed values into the train and test dataframe and add column features to detect if a person is a child or is a mother."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9d539b14-9eb6-e546-5a32-8b9b43a71bd4"
      },
      "outputs": [],
      "source": [
        "train_df_imputed = pd.merge(train_df, imputed_frame[['PassengerId', 'Age']], on='PassengerId')\n",
        "train_df_imputed.drop('Age_x', axis=1, inplace=True)\n",
        "train_df_imputed.rename(columns={'Age_y': 'Age'}, inplace=True)\n",
        "\n",
        "test_df_imputed = pd.merge(test_df, imputed_frame[['PassengerId', 'Age']], on='PassengerId')\n",
        "test_df_imputed.drop('Age_x', axis=1, inplace=True)\n",
        "test_df_imputed.rename(columns={'Age_y': 'Age'}, inplace=True)\n",
        "\n",
        "combined_df_imputed = pd.merge(combined_df, imputed_frame[['PassengerId', 'Age']], on='PassengerId')\n",
        "combined_df_imputed.drop('Age_x', axis=1, inplace=True)\n",
        "combined_df_imputed.rename(columns={'Age_y': 'Age'}, inplace=True)\n",
        "\n",
        "def is_mother(row):\n",
        "    index, item = row\n",
        "    age = item['Age']\n",
        "    title = item['Title']\n",
        "    sex = item['Sex']\n",
        "    parch = item['Parch']\n",
        "    if age > 18 and title != title_mapping[\"Miss\"] and sex == 0 and parch > 1:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "    \n",
        "def is_child(row):\n",
        "    index, item = row\n",
        "    age = item['Age']\n",
        "    if age < 18:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "    \n",
        "train_df_imputed['IsMother'] = [is_mother(row) for row in train_df_imputed.iterrows()]\n",
        "test_df_imputed['IsMother'] = [is_mother(row) for row in test_df_imputed.iterrows()]\n",
        "combined_df_imputed['IsMother'] = [is_mother(row) for row in combined_df_imputed.iterrows()]\n",
        "\n",
        "train_df_imputed['IsChild'] = [is_child(row) for row in train_df_imputed.iterrows()]\n",
        "test_df_imputed['IsChild'] = [is_child(row) for row in test_df_imputed.iterrows()]\n",
        "combined_df_imputed['IsChild'] = [is_child(row) for row in combined_df_imputed.iterrows()]\n",
        "\n",
        "combined_df_imputed.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e66c64d4-f386-7a94-328e-1fea99405815"
      },
      "source": [
        "Let us now look at the proportion of males to females who survived:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4be4f4b1-676a-833b-9353-49e146795f5b"
      },
      "outputs": [],
      "source": [
        "survivors = train_df_imputed[train_df_imputed['Survived'] == 1]\n",
        "male_survivors = survivors[survivors['Sex'] == 1]\n",
        "female_survivors = survivors[survivors['Sex'] == 0]\n",
        "\n",
        "dead = train_df_imputed[train_df_imputed['Survived'] == 0]\n",
        "males_dead = dead[dead['Sex'] == 1]\n",
        "females_dead = dead[dead['Sex'] == 0]\n",
        "\n",
        "print (\"Male:Female survival ratio is {}:{}\".format(male_survivors['PassengerId'].count(), female_survivors['PassengerId'].count()))\n",
        "print (\"Male:Female death ratio is {}:{}\".format(males_dead['PassengerId'].count(), females_dead['PassengerId'].count()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6734aa96-071d-759e-6e7b-d63672b4428d"
      },
      "source": [
        "Does family size affect survival?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "747c9b00-730e-62b6-4b6f-53939f7755f5"
      },
      "outputs": [],
      "source": [
        "family_sizes_survived = pd.DataFrame(train_df_imputed[train_df_imputed['Survived'] == 1]['FamilySize'].value_counts()).reset_index()\n",
        "family_sizes_survived.columns = ['Family Size', 'Survived']\n",
        "\n",
        "family_sizes_perished = pd.DataFrame(train_df_imputed[train_df_imputed['Survived'] == 0]['FamilySize'].value_counts()).reset_index()\n",
        "family_sizes_perished.columns = ['Family Size', 'Perished']\n",
        "\n",
        "family_size = pd.merge(family_sizes_survived, family_sizes_perished, on=\"Family Size\")\n",
        "\n",
        "family_size.sort_values(by='Family Size', axis=0, inplace=True)\n",
        "\n",
        "plt.clf()\n",
        "family_size.plot(kind='bar', x='Family Size', title='Family Size Analysis')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7cbc97c7-9083-3778-3b4d-55b1b071c8c1"
      },
      "source": [
        "Single people have a greater tendency to perish. Let us categorise family size as:\n",
        "\n",
        "- Size 1 = 1\n",
        "- 1 < Size < 5 = 2\n",
        "- Size >= 5 = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "becdd886-6435-707c-9129-b3070218712b"
      },
      "outputs": [],
      "source": [
        "def size_categorize(size):\n",
        "    if size == 1:\n",
        "        return 1\n",
        "    elif size > 1 and size < 5:\n",
        "        return 2\n",
        "    else:\n",
        "        return 3\n",
        "\n",
        "train_df_imputed['FamilySizeCategory'] = train_df_imputed['FamilySize'].map(size_categorize)\n",
        "test_df_imputed['FamilySizeCategory'] = test_df_imputed['FamilySize'].map(size_categorize)\n",
        "combined_df_imputed['FamilySizeCategory'] = combined_df_imputed['FamilySize'].map(size_categorize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "002b8c57-09e5-3b2b-8739-a1a5f5ca2f89"
      },
      "source": [
        "We add a feature/predictor for surname to investigate whether families survived or died together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "76957f14-7aa0-282f-61ff-d17c621294e0"
      },
      "outputs": [],
      "source": [
        "def get_family_id(row):\n",
        "    index, item = row\n",
        "    pclass = item['Pclass']\n",
        "    parch = item['Parch']\n",
        "    sibsp = item['SibSp']\n",
        "    name = item['Name']\n",
        "    \n",
        "    family_size = parch + sibsp + 1\n",
        "    \n",
        "    if family_size > 1:\n",
        "        return name.split(',')[0].lower() + \"_\" + str(pclass) + \"_\" + str(family_size)\n",
        "    else:\n",
        "        return name.split(',')[0].lower() + \"_\" + str(pclass) + \"_\" + str(uuid.uuid4())\n",
        "    \n",
        "combined_df_imputed['FamilyId'] = [get_family_id(row) for row in combined_df_imputed.iterrows()]\n",
        "test_df_imputed['FamilyId'] = np.nan\n",
        "train_df_imputed['FamilyId'] = np.nan\n",
        "\n",
        "family_id_dict = dictize(train_df_imputed, combined_df_imputed, ['FamilyId'])\n",
        "\n",
        "test_df_with_family = pd.merge(test_df_imputed, combined_df_imputed[['PassengerId', 'FamilyId']], on='PassengerId')\n",
        "test_df_with_family.drop('FamilyId_x', axis=1, inplace=True)\n",
        "test_df_with_family.rename(columns={'FamilyId_y': 'FamilyId'}, inplace=True)\n",
        "\n",
        "train_df_with_family = pd.merge(train_df_imputed, combined_df_imputed[['PassengerId', 'FamilyId']], on='PassengerId')\n",
        "train_df_with_family.drop('FamilyId_x', axis=1, inplace=True)\n",
        "train_df_with_family.rename(columns={'FamilyId_y': 'FamilyId'}, inplace=True)\n",
        "\n",
        "family_id_dict = dictize(test_df_with_family, combined_df_imputed, ['FamilyId'])\n",
        "family_id_dict = dictize(train_df_with_family, combined_df_imputed, ['FamilyId'])\n",
        "\n",
        "# If a family member (other than self) survived, it is likely that more than one family member survived\n",
        "survived_families = list(train_df_with_family[train_df_with_family['Survived'] == 1]['FamilyId'])\n",
        "survived_passengers = list(train_df_with_family[train_df_with_family['Survived'] == 1]['PassengerId'])\n",
        "\n",
        "def has_family_member_survived(row):\n",
        "    index, item = row\n",
        "    if item['PassengerId'] not in survived_passengers and item['FamilyId'] in survived_families:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "train_df_with_family['FamilyMemberSurvived'] = [has_family_member_survived(row) for row in train_df_with_family.iterrows()]\n",
        "test_df_with_family['FamilyMemberSurvived'] = [has_family_member_survived(row) for row in test_df_with_family.iterrows()]\n",
        "combined_df_imputed['FamilyMemberSurvived'] = [has_family_member_survived(row) for row in combined_df_imputed.iterrows()]\n",
        "\n",
        "combined_df_imputed.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0de3643a-79a2-a598-68bc-8e975ad28e7c"
      },
      "source": [
        "Define variables for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dbca02a7-cedb-d1b4-a5b6-3cf16d5d8993"
      },
      "outputs": [],
      "source": [
        "predictors = ['Pclass', 'Sex', 'SibSp', 'Parch',\n",
        "                'Fare', 'Embarked', 'Title', 'IsMother', 'IsChild',\n",
        "                'FamilySizeCategory', 'FamilyMemberSurvived', 'FamilyId']\n",
        "\n",
        "train = train_df_with_family.copy()\n",
        "test = test_df_with_family.copy()\n",
        "\n",
        "y_true = train['Survived'].values\n",
        "X_data = train[predictors].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "33a472d6-3b19-dc69-5037-6bf9fa69af07"
      },
      "source": [
        "Let's look for good features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b8373f48-a0c4-9cf6-60d7-526acbdb55b4"
      },
      "outputs": [],
      "source": [
        "# Identify best features\n",
        "# All the predictors in the model\n",
        "\n",
        "# For ET - {'min_samples_split': 2, 'n_estimators': 200, 'min_samples_leaf': 4}\n",
        "# For RF - {'min_samples_split': 2, 'n_estimators': 300, 'min_samples_leaf': 8}\n",
        "\n",
        "ft = ExtraTreesClassifier(n_jobs=4, min_samples_split=2, n_estimators=200, min_samples_leaf=4, random_state=3)\n",
        "ft.fit(X_data, y_true)\n",
        "\n",
        "ftr = RandomForestClassifier(n_jobs=4, min_samples_split=2, n_estimators=300, min_samples_leaf=8, random_state=1)\n",
        "ftr.fit(X_data, y_true)\n",
        "\n",
        "importances_et = ft.feature_importances_\n",
        "importance_et_df = pd.DataFrame(importances_et).reset_index()\n",
        "importance_et_df.columns = ['Feature', 'Importance']\n",
        "importance_et_df['Feature'] = importance_et_df['Feature'].map(lambda x: predictors[x])\n",
        "importance_et_df.sort_values(by='Importance', axis=0, inplace=True, ascending = False)\n",
        "\n",
        "importances_rf = ftr.feature_importances_\n",
        "importance_rf_df = pd.DataFrame(importances_rf).reset_index()\n",
        "importance_rf_df.columns = ['Feature', 'Importance']\n",
        "importance_rf_df['Feature'] = importance_rf_df['Feature'].map(lambda x: predictors[x])\n",
        "importance_rf_df.sort_values(by='Importance', axis=0, inplace=True, ascending = False)\n",
        "\n",
        "plt.clf()\n",
        "plt.figure()\n",
        "importance_et_df.plot(kind='bar', x='Feature', title='Feature Analysis (ExtraTrees)')\n",
        "importance_rf_df.plot(kind='bar', x='Feature', title='Feature Analysis (RandomForest)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "27d2e95f-475c-8b86-3a23-1718e24d8507"
      },
      "outputs": [],
      "source": [
        "# Perform feature selection\n",
        "selector = SelectKBest(f_classif, k=10)\n",
        "selector.fit(train[predictors], train[\"Survived\"])\n",
        "\n",
        "# Get the raw p-values for each feature, and transform from p-values into scores\n",
        "scores = -np.log10(selector.pvalues_)\n",
        "\n",
        "# Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
        "plt.bar(range(len(predictors)), scores)\n",
        "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5264bd5b-3362-976d-ede2-684a7d039bb2"
      },
      "source": [
        "Next, we optimise the classifiers for the training data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7a520833-6394-eb9c-dfe9-9ce439fa6eb0"
      },
      "outputs": [],
      "source": [
        "top_features_et = ['Sex', 'Pclass', 'Fare', 'FamilyMemberSurvived', 'IsChild']\n",
        "top_features_rf = ['Title', 'Fare', 'Pclass', 'FamilyId', 'FamilySizeCategory']\n",
        "top_features_svm = ['Pclass', 'Sex', 'Fare', 'Title', 'FamilyMemberSurvived']\n",
        "\n",
        "X_data_et = train[top_features_et].values\n",
        "X_data_rf = train[top_features_rf].values\n",
        "X_data_svm = preprocessing.scale(train[top_features_svm].values)\n",
        "\n",
        "# Divide records in training and testing sets.\n",
        "X_train_et, X_test_et, y_train_et, y_test_et = train_test_split(X_data_et, y_true, test_size=0.3, random_state=3, stratify=y_true)\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_data_rf, y_true, test_size=0.3, random_state=3, stratify=y_true)\n",
        "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_data_svm, y_true, test_size=0.3, random_state=3, stratify=y_true)\n",
        "\n",
        "print (\"Tagged records were split into training and test sets\")\n",
        "\n",
        "param_grid = [\n",
        "      {'n_estimators': [1000], \n",
        "       'min_samples_split': [2, 4, 6, 8],\n",
        "       'min_samples_leaf': [2, 4, 6, 8]\n",
        "      }\n",
        "    ]\n",
        "\n",
        "clf_et = ExtraTreesClassifier(random_state=1, n_jobs=4)\n",
        "clf_rf = RandomForestClassifier(random_state=1, n_jobs=4)\n",
        "clf_svm = SVC(random_state=1, probability=True)\n",
        "\n",
        "optimal_et = grid_search(clf_et, param_grid, X_train_et, y_train_et, X_test_et, y_test_et, cv=5)\n",
        "optimal_rf = grid_search(clf_rf, param_grid, X_train_rf, y_train_rf, X_test_rf, y_test_rf, cv=5)\n",
        "clf_svm.fit(X_train_svm, y_train_svm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a7b33e3a-1a75-bd41-67cb-c9f88829c8b4"
      },
      "source": [
        "Let's look at the Area Under ROC as a metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "165bbef0-8c29-7118-600e-458f42318c37"
      },
      "outputs": [],
      "source": [
        "# Fit to training data\n",
        "clf_et.fit(X_train_et, y_train_et)\n",
        "clf_rf.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "# Plot the results.\n",
        "colors = ['b', 'r', 'g']\n",
        "classifiers = ['ExtraTrees', 'RandomForest', 'SVC']\n",
        "plt.figure(figsize=(20,10))\n",
        "for i, cl in enumerate([clf_et, clf_rf, clf_svm]):\n",
        "    if i == 0:\n",
        "        y_test_roc = y_test_et\n",
        "        probas_ = cl.predict_proba(X_test_et)\n",
        "    elif i ==1:\n",
        "        y_test_roc = y_test_rf\n",
        "        probas_ = cl.predict_proba(X_test_rf)\n",
        "    else:\n",
        "        y_test_roc = y_test_svm\n",
        "        probas_ = cl.predict_proba(X_test_svm)\n",
        "    fpr, tpr, thresholds = roc_curve(y_test_roc, probas_[:, 1])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=1, label=classifiers[i]+' (AUC = %0.2f)' % (roc_auc))\n",
        "    \n",
        "plt.plot([0, 1], [0, 1], '--', color=colors[i], label='Random (AUC = 0.50)')\n",
        "plt.xlim([-0.05, 1.05])\n",
        "plt.ylim([-0.05, 1.05])   \n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.axes().set_aspect(1)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "435ac8da-5f3a-7366-72fa-c9dd3ae93da6"
      },
      "source": [
        "Create the submission frame ad get the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "98b2d564-b9ed-e230-37f8-1f659f8c4a5e"
      },
      "outputs": [],
      "source": [
        "# Get accuracy on the training data\n",
        "#{'min_samples_split': 2, 'n_estimators': 300, 'min_samples_leaf': 4}\n",
        "clf_et = ExtraTreesClassifier(random_state=1, n_jobs=-1, min_samples_split=optimal_et[\"min_samples_split\"], min_samples_leaf=optimal_et[\"min_samples_leaf\"], n_estimators=optimal_et[\"n_estimators\"])\n",
        "clf_et.fit(X_data_et, y_true)\n",
        "\n",
        "clf_rf = RandomForestClassifier(random_state=1, n_jobs=-1, min_samples_split=optimal_rf[\"min_samples_split\"], min_samples_leaf=optimal_rf[\"min_samples_leaf\"], n_estimators=optimal_rf[\"n_estimators\"])\n",
        "clf_rf.fit(X_data_rf, y_true)\n",
        "\n",
        "clf_svm = SVC(random_state=1, probability=True)\n",
        "clf_svm.fit(X_data_svm, y_true)\n",
        "\n",
        "y_pred_et = clf_et.predict(X_data_et)\n",
        "y_pred_rf = clf_rf.predict(X_data_rf)\n",
        "y_pred_svm = clf_svm.predict(X_data_svm)\n",
        "\n",
        "y_pred = (y_pred_rf + y_pred_svm) / 2.0\n",
        "\n",
        "y_pred = [1 if y > 0.5 else 0 for y in y_pred]\n",
        "\n",
        "print (\"Accuracy {}\".format(accuracy(y_pred, y_true)))\n",
        "\n",
        "passenger_ids = test[\"PassengerId\"]\n",
        "\n",
        "X_test_et = test[top_features_et].values\n",
        "y_pred_et = clf_et.predict(X_test_et)\n",
        "\n",
        "X_test_rf = test[top_features_rf].values\n",
        "y_pred_rf = clf_rf.predict(X_test_rf)\n",
        "\n",
        "X_test_svm = preprocessing.scale(test[top_features_svm].values)\n",
        "y_pred_svm = clf_svm.predict(X_test_svm)\n",
        "\n",
        "y_pred = (y_pred_rf  + y_pred_svm) / 2.0\n",
        "\n",
        "y_pred = [1 if y > 0.5 else 0 for y in y_pred]\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": passenger_ids,\n",
        "        \"Survived\": y_pred\n",
        "    })\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2c8fcc89-0409-dd30-42bb-9872eebb2a5c"
      },
      "outputs": [],
      "source": [
        "print (\"{} predicted survivors out of {}\".format(submission[\"Survived\"].sum(), submission[\"Survived\"].count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7065e028-53ee-480d-52e9-906a7e7569a0"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('titanic.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ab1d8a64-ed2a-6d4e-679f-96ac1e99ca5f"
      },
      "source": [
        "This strategy was adapted from the excellent analysis presented in R:\n",
        "https://www.kaggle.com/tylerph3/titanic/exploring-survival-on-the-titanic/run/416227"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}