{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "245ef931-521d-1315-3b79-a59db1f05e41"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import csv\n",
        "import math\n",
        "from collections import defaultdict, OrderedDict\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def clean_html(raw_html):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', raw_html)\n",
        "    return cleantext\n",
        "\n",
        "\n",
        "def get_words(text):\n",
        "    word_split = re.compile('[^a-zA-Z0-9_\\\\+\\\\-/]')\n",
        "    return [word.strip().lower() for word in word_split.split(text)]\n",
        "\n",
        "\n",
        "def process_text(doc, idf, text):\n",
        "    tf = OrderedDict()\n",
        "    word_count = 0.\n",
        "\n",
        "    for word in get_words(text):\n",
        "        if word not in stop_words and word.isalpha():\n",
        "\n",
        "            if word not in tf:\n",
        "                tf[word] = 0\n",
        "            tf[word] += 1\n",
        "            idf[word].add(doc)\n",
        "            word_count += 1.\n",
        "\n",
        "    for word in tf:\n",
        "        tf[word] = tf[word] / word_count\n",
        "\n",
        "    return tf, word_count\n",
        "\n",
        "\n",
        "def main():\n",
        "    data_path = \"../input/\"\n",
        "    in_file = open(data_path + \"test.csv\")\n",
        "    out_file = open(\"tf_idf.csv\", \"w\")\n",
        "\n",
        "    reader = csv.DictReader(in_file)\n",
        "    writer = csv.writer(out_file)\n",
        "    writer.writerow(['id', 'tags'])\n",
        "\n",
        "    docs = []\n",
        "\n",
        "    # Calculate TF and IDF per document\n",
        "    idf = defaultdict(set)\n",
        "    tf = {}\n",
        "    word_counts = defaultdict(float)\n",
        "\n",
        "    print(\"Counting words..\")\n",
        "    for row in reader:\n",
        "        doc = int(row['id'])\n",
        "        docs.append(doc)\n",
        "\n",
        "        text = clean_html(row[\"title\"]) + ' ' + clean_html(row[\"content\"])\n",
        "        tf[doc], word_counts[doc] = process_text(doc, idf, text)\n",
        "\n",
        "    in_file.close()\n",
        "\n",
        "    # Calculate TF-IDF\n",
        "    nr_docs = len(docs)\n",
        "    for doc in docs:\n",
        "\n",
        "        for word in tf[doc]:\n",
        "            tf[doc][word] *= math.log(nr_docs / len(idf[word]))\n",
        "\n",
        "    # Write predictions\n",
        "    print(\"Writing predictions..\")\n",
        "    for doc in docs:\n",
        "\n",
        "        # Sort words with frequency from high to low.\n",
        "        pred_tags = sorted(tf[doc], key=tf[doc].get, reverse=True)[:3]\n",
        "\n",
        "        # Write predictions\n",
        "        writer.writerow([doc, \" \".join(sorted(pred_tags))])\n",
        "\n",
        "    in_file.close()\n",
        "    out_file.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting program.\")\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}