{"metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language": "python", "language_info": {"nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "version": "3.6.3", "file_extension": ".py", "pygments_lexer": "ipython3", "mimetype": "text/x-python"}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"metadata": {"_uuid": "dd721c7133b689012690882247041583e6ac4389", "_cell_guid": "c5029d6e-b10b-4ff9-8abd-1f267e6bc59c"}, "cell_type": "markdown", "source": ["# Data Exploration: Toxic Comments"]}, {"metadata": {"_uuid": "9457c7e9db507f4ae2c65bb7ad8cacd467b34750", "_cell_guid": "d1d6e4cf-44c2-45c1-8b22-7746c2d3e072"}, "cell_type": "markdown", "source": ["This kernel intends to explore and summarize the Wikipedia Toxic Comments Data Set. The summary focuses \n", "on correlations between the types of comment labels, missing / weird data, and most common terms in toxic\n", "comments."]}, {"metadata": {"_uuid": "74312ab88cdd05b7bb43a593c69143290c4de1ac", "_cell_guid": "8f912756-adb8-4303-9f75-b17cae56bfb7"}, "cell_type": "markdown", "source": ["## Set Up: Load modules and training data"]}, {"metadata": {"_uuid": "134fb99b69266da41140ed9444e40aa2e566f639", "collapsed": true, "_cell_guid": "effabef8-ea0a-41ee-afce-ff76b0e3d4fd"}, "execution_count": null, "cell_type": "code", "source": ["import numpy as np\n", "import pandas as pd\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "\n", "train = pd.read_csv(\"../input/train.csv\")"], "outputs": []}, {"metadata": {"_uuid": "b68e7d8c261e0479fda22edca4754264baad2120", "_cell_guid": "11724040-8a2f-4cc8-bebb-e97d83fc64ec"}, "cell_type": "markdown", "source": ["## Label Exploration"]}, {"metadata": {"_uuid": "e90d286446d85c1badc24eaaa8d49994212a8d77", "_cell_guid": "3ecf8f5d-628b-4910-92cb-55243b815248"}, "cell_type": "markdown", "source": ["First we need to learn about the class labels. Let's count the toxic comments for starters."]}, {"metadata": {"_uuid": "433388e99244f5673d78eda8ff74fb11ee8fa326", "collapsed": true, "_cell_guid": "d565048c-950a-4ad2-8410-16446bfb3147"}, "execution_count": null, "cell_type": "code", "source": ["train.toxic.value_counts()"], "outputs": []}, {"metadata": {"_uuid": "9878734f7244410bc4abc6123200d7345ad598a8", "_cell_guid": "f98fbc5c-58d3-4eae-aefd-5e18802a5206"}, "cell_type": "markdown", "source": ["The good news here is that, even though it might feel worse, the percentage of toxic \n", "comments is not too high."]}, {"metadata": {"_uuid": "c6540043440acf0c9ca01fdb68292c51e6ca4a8f", "collapsed": true, "_cell_guid": "235988a4-8603-480b-ba53-0845b459cd38"}, "execution_count": null, "cell_type": "code", "source": ["pd.crosstab(train.toxic, train.severe_toxic)\n"], "outputs": []}, {"metadata": {"_uuid": "a95e1a5603a2f45642c3be9591acb5bb866ebaf8", "_cell_guid": "243f928e-8002-473f-a910-e0fa67890ee9"}, "cell_type": "markdown", "source": ["As we might expect, all severely toxic comments are also toxic comments, but not all toxic \n", "comments are severe."]}, {"metadata": {"_uuid": "4fbc46d5c879eced84d68075cdfa9ba760697e5c", "collapsed": true, "_cell_guid": "3e49804f-5de6-462d-bfbd-6afc2ffb1037"}, "execution_count": null, "cell_type": "code", "source": ["pd.crosstab(train.toxic, [train.obscene, train.threat, train.insult, train.identity_hate])"], "outputs": []}, {"metadata": {"_uuid": "805bbd8a6af22a1b623f76bcf9ff5e31e4e0b5e2", "_cell_guid": "f56fcd2c-f0db-484e-be91-b109feaef693"}, "cell_type": "markdown", "source": ["Interestingly, over a third of comments are \"civilly\" toxic, meaning they are neither obscene, \n", "insult, threat, nor identity hate, yet they are still disruptive. However, adding these labels \n", "greatly increases the prevalence of toxicity. The worst cases, the 58 comments that are all \n", "four of the above, are 100% toxic. "]}, {"metadata": {"_uuid": "a130755051786ea0761372e902d134f1f8378f3c", "collapsed": true, "_cell_guid": "1bb83a87-9189-496e-ac49-f51228ce4916"}, "execution_count": null, "cell_type": "code", "source": ["pd.crosstab(train.severe_toxic, [train.obscene, train.threat, train.insult, train.identity_hate])"], "outputs": []}, {"metadata": {"_uuid": "ed3fe9e65770dc83b15b71e373ade52a4961554c", "_cell_guid": "747ee7b7-1334-45a5-9ed3-ea7fc6ecab46"}, "cell_type": "markdown", "source": ["The cases of \"civil\" severely toxic comments are much rarer - there are only 22. Generally, a \n", "smaller portion of comments are severely toxic, no matter what other labels we condition on. \n", "Even in the worst cases, only 20 of the 58 obscene + threat + insult + identity hate comments \n", "are severely toxic."]}, {"metadata": {"_uuid": "8416bc0b8899d4a08595de10472c66d7054306f4", "collapsed": true, "_cell_guid": "159e52c0-f767-4d9c-9e33-5a8dfacfe5a3"}, "execution_count": null, "cell_type": "code", "source": ["train.iloc[:, 2:8].corr()"], "outputs": []}, {"metadata": {"_uuid": "3af340b6e9a484ff73240c2fe1ecd06df3b49b33", "_cell_guid": "138c25fb-f2a0-4fa8-8e8f-62ac3e89d0b4"}, "cell_type": "markdown", "source": ["The correlation matrix is another way of summarizing the relationships between labels,\n", "although here we only see pair-wise correlations rather than the full cross-tabulation.\n", "The story stays the same - all the correlations are positive, and the correlations for \n", "severe_toxic are always smaller than for toxic. \n", "\n", "The correlation matrix will make for a good sanity check later when making multi-class \n", "predicitons. We should expect the correlation matrix of the predicted probabilities to look \n", "very similar to this one, else something is likely awry. "]}, {"metadata": {"_uuid": "5652e4805b3aebae34ecf8cd8529e98e0705e784", "_cell_guid": "89ebd4ae-497e-4657-a82f-ddf18a2a6341"}, "cell_type": "markdown", "source": ["## What makes a comment toxic?"]}, {"metadata": {"_uuid": "d4d647426b9399b359346ebd121f7577758d41cc", "_cell_guid": "84f0ffdf-0e45-444e-b568-4bca21e7b178"}, "cell_type": "markdown", "source": ["Let's start out with an overview of the comments' structures."]}, {"metadata": {"_uuid": "61ed778f01c3bb11af902efa9242fd437d2fcc76", "collapsed": true, "_cell_guid": "81af0bbc-db0f-461e-9342-cdfb023c6d72"}, "execution_count": null, "cell_type": "code", "source": ["train[train.comment_text.isnull()]"], "outputs": []}, {"metadata": {"_uuid": "48e899718ebd675967cabb37b4fe59c89d7390aa", "_cell_guid": "f2d06efe-93c9-478f-a383-36675b36e2f2"}, "cell_type": "markdown", "source": ["There are no missing values for the comment texts, so let's check for empty strings."]}, {"metadata": {"_uuid": "5641fd9478aa6fea2f561173e65d9dcfbb61eca7", "collapsed": true, "_cell_guid": "cfdb234b-0dab-4240-ba66-3fcc9d3cc3c5"}, "execution_count": null, "cell_type": "code", "source": ["train[train.comment_text == '']"], "outputs": []}, {"metadata": {"_uuid": "ee8929dde6628a3436312e611acbecd4b306550c", "_cell_guid": "f3eb2a88-e6dc-4cae-bef6-d306bb20780a"}, "cell_type": "markdown", "source": ["Looks okay. If we find secretly missing values later we can deal with them then."]}, {"metadata": {"_uuid": "08ca1083d7a55dbe467a98e22402b533a08e4eb6", "collapsed": true, "_cell_guid": "1f7a2cc2-4542-4a2b-9f58-da1af4aa7127"}, "execution_count": null, "cell_type": "code", "source": ["train['comment_length'] = train.comment_text.str.len()\n", "train.comment_length.describe()"], "outputs": []}, {"metadata": {"_uuid": "c6ff0567ef3c25542ea9742927fa501848ad0e0b", "_cell_guid": "258846f6-88a4-4084-9f99-fa4b89954e02"}, "cell_type": "markdown", "source": ["The mean is about double the median, so there are some huge comments skewing the data. The \n", "largest comment is 5000 characters, while the inter-quartile range is only 96 to 435 characters. Let's look at the longest comments and see if they are naughty or nice."]}, {"metadata": {"_uuid": "88ee9e933a66333957fec2fd70f4c4ac4dc568d0", "collapsed": true, "_cell_guid": "03d8fb46-ae30-4191-a6fa-8f736fe60440"}, "execution_count": null, "cell_type": "code", "source": ["train = train.sort_values(by=\"comment_length\", ascending=False)\n", "pd.set_option('display.max_colwidth', -1)\n", "train.comment_text.head(1)"], "outputs": []}, {"metadata": {"_uuid": "d77e7494d69c33ba9bf3b429d19247fb45cfe9db", "_cell_guid": "f7cf4997-62b4-4568-bfd4-d7da5f9f09c8"}, "cell_type": "markdown", "source": ["Well, I've only displayed 1 comment, but change this to head(10) or so, and you'll see for\n", "yourself these are very vulgar and spammy. You could probably target these basic spam posts\n", "by targeting a low ratio of unique words to comment length. For the record, you and I both \n", "surely do not want Jimmy Wales to die!"]}, {"metadata": {"_uuid": "5c3d3bec9763fccf0c3efca23868403de2a48dec", "collapsed": true, "_cell_guid": "386d4bb2-a3ac-450f-b663-2ca69490eace"}, "execution_count": null, "cell_type": "code", "source": ["one_percent = int(np.ceil(train.shape[0] / 100))\n", "train_sub = train.iloc[0:one_percent, :]\n", "train_sub.toxic.value_counts()"], "outputs": []}, {"metadata": {"_uuid": "cbfc8747efc5ee1d27f7e32711b5882f87801cd0", "_cell_guid": "809d9b16-dd62-4d20-88c2-7bc47193179a"}, "cell_type": "markdown", "source": ["Long comments in general aren't especially toxic. In the above 1% longest comments, still over\n", "80% are not toxic."]}, {"metadata": {"_uuid": "37cc807d77dbae6516601ee4ee2ab8e43fa001df", "_cell_guid": "d0d88822-abd4-482f-b2b6-ede74f460f58"}, "cell_type": "markdown", "source": ["## Most common terms in toxic comments"]}, {"metadata": {"_uuid": "1aa426a27ddf2bbf7cad4e755040eaa2d8942fa2", "_cell_guid": "d08465a5-3b60-444c-8e99-fed42b5ca063"}, "cell_type": "markdown", "source": ["Let's use the TfidfVectorizer class from scikit-learn to analyze common words in the \n", "toxic comments. I'll pass it the list of common English stop-words, but otherwize let's \n", "not worry about cleaning up much. This should give us an idea of which words appear most\n", "commonly in toxic comments, but not so much in general (An advantage over simple counting)"]}, {"metadata": {"_uuid": "c63c27c551d3db888b25ed246edc1a8bb3fb7299", "collapsed": true, "_cell_guid": "f5969b32-95d8-4b53-b325-a23adc35a5ef"}, "execution_count": null, "cell_type": "code", "source": ["train = train.sort_values(by='toxic', ascending=False)\n", "vectorizer = TfidfVectorizer(stop_words='english')\n", "vectorizer.fit(train.comment_text)\n", "X = vectorizer.transform(train.comment_text)\n", "X_toxic = X[0:9237, :]"], "outputs": []}, {"metadata": {"_uuid": "1fd04bdb747f9350a7262fd9d68d0095bb280866", "collapsed": true, "_cell_guid": "397fa7d3-b8d0-43bd-b920-5d49de33118c"}, "execution_count": null, "cell_type": "code", "source": ["means = np.asarray(np.mean(X_toxic, axis=0))\n", "top_ten = np.argsort(-means)[:10]\n", "\n", "for ind in range(10):\n", "    print(ind + 1, \":\", vectorizer.get_feature_names()[top_ten[0, ind]])\n", "# vectorizer.get_feature_names()[np.argmax(means)]"], "outputs": []}, {"metadata": {"_uuid": "61b496a870e5f7d9261bc021c8d1d2f06f28f069", "_cell_guid": "f548af8b-5723-4bf4-aac1-d9d90f411341"}, "cell_type": "markdown", "source": ["No major surprises there, eh? It makes sense that most folks using the F word on \n", "wikipedia are not terribly contructive in their comments. Interestingly wikipedia still\n", "shows up in the list even re-weighting with IDF. That's all for now but maybe I'll be back\n", "with some visualization soon."]}, {"metadata": {"_uuid": "5d56f2a0911a52187c2c270a6b2c5c9c3fdfc180", "collapsed": true, "_cell_guid": "a0a53be6-3185-4896-af03-856d5bf48a6d"}, "execution_count": null, "cell_type": "code", "source": [], "outputs": []}, {"metadata": {"_uuid": "a700c65bd920512363e25d2e73c516e145590aa1", "collapsed": true, "_cell_guid": "37f8e988-8f22-4126-b4c7-e423ed52ffd7"}, "execution_count": null, "cell_type": "code", "source": [], "outputs": []}]}