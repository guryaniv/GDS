{"cells":[{"metadata":{"_uuid":"a850dfac27e85d335ce55e39dc271ebd3911693a"},"cell_type":"markdown","source":"## Introduction"},{"metadata":{"_uuid":"41161effebdd456ac5ef74c82da763f28f1c89d4"},"cell_type":"markdown","source":" Here, we need to  identify which questions asked on Quora are duplicates of questions that have already been asked. This could be useful, for example, to instantly provide answers to questions that have already been answered. We are tasked with predicting whether a pair of questions are duplicates or not, and submitting a binary prediction against the logloss metric."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\npal = sns.color_palette()\n\nprint('# File sizes')\nfor f in os.listdir('../input'):\n    if 'zip' not in f:\n        print(f.ljust(30) + str(round(os.path.getsize('../input/' + f) / 1000000, 2)) + 'MB')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"# Reading training data\ndf_train = pd.read_csv('../input/train.csv')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1955634964ebd20c06b284e119a9cb85126d788","collapsed":true},"cell_type":"code","source":"# Reading test data\ndf_test = pd.read_csv('../input/test.csv')\ndf_test.head() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d33e746b530be3f3c5e3300ce99b86d7d4c1bfba"},"cell_type":"markdown","source":"It's worth noting that there is a lot more testing data than training data. This could be a sign that some of the test data is dummy data designed to deter hand-labelling, \n\nLet's open up one train datasets"},{"metadata":{"trusted":true,"_uuid":"468682c6dd1dae48d25208fc4e587b3a20306d6b","collapsed":true},"cell_type":"code","source":"# checking null values in training & testing data  \ndf_test[df_test.isnull().any(axis=1)]  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7450a70adda042ee00d5e51396ab98bf4f1a7039","collapsed":true},"cell_type":"code","source":"df_train[df_train.isnull().any(axis=1)] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"df237f2e85a224677d6168a85fc182650d48861c"},"cell_type":"code","source":"# Adding the string empty to null values  \ndf_train = df_train.fillna('empty') \ndf_test = df_test.fillna('empty')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1376bf7241b1a8147d8db6854f824d1ce9d761e"},"cell_type":"markdown","source":"## Basic EDA of train dataset"},{"metadata":{"trusted":true,"_uuid":"e357ec734ebb5fb8390ab03346ea8fb99e1d6cd3","collapsed":true},"cell_type":"code","source":"print('Total number of question pairs for training: {}'.format(len(df_train)))\nprint('Duplicate pairs: {}%'.format(round(df_train['is_duplicate'].mean()*100, 2)))\nqids = pd.Series(df_train['qid1'].tolist() + df_train['qid2'].tolist())\nprint('Total number of questions in the training data: {}'.format(len(\n    np.unique(qids))))\nprint('Number of questions that appear multiple times: {}'.format(np.sum(qids.value_counts() > 1)))\n\nplt.figure(figsize=(12, 5))\nplt.hist(qids.value_counts(), bins=50)\nplt.yscale('log', nonposy='clip')\nplt.title('Log-Histogram of question appearance counts')\nplt.xlabel('Number of occurences of question')\nplt.ylabel('Number of questions')\nprint() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18828c2811abdc7ccc3aa6b3681ea2ad65ef44d8"},"cell_type":"markdown","source":" Most questions only appear a few times, with very few questions appearing several times (and a few questions appearing many times). One question appears more than 160 times, but this is an outlier.\n\nWe can see that we have a 37% positive class in this dataset. Since we are using the LogLoss metric, and LogLoss looks at the actual predicts as opposed to the order of predictions, we should be able to get a decent score by creating a submission predicting the mean value of the label"},{"metadata":{"_uuid":"0232077eaf1b5c367ffcc30aec4030913c0cd70c"},"cell_type":"markdown","source":"## Making prediction based on mean values to create a baseline score  "},{"metadata":{"trusted":true,"_uuid":"15bac06cb37d5ca09dd75bc43d244afa267b23b0","collapsed":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\n\np = df_train['is_duplicate'].mean() # Our predicted probability\nprint('Predicted score:', log_loss(df_train['is_duplicate'], np.zeros_like(df_train['is_duplicate']) + p))\n\ndf_test = pd.read_csv('../input/test.csv')\nsub = pd.DataFrame({'test_id': df_test['test_id'], 'is_duplicate': p}) \nsub.to_csv('naive__mean_submission.csv', index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91b624915915ccfabbcc0e26f870b481892fbdde"},"cell_type":"markdown","source":"submission 1 : 0.55 on the leaderboard! Score!"},{"metadata":{"_uuid":"674d65faca43943e41a6ede092830c6af50b5056"},"cell_type":"markdown","source":"##  Test Set "},{"metadata":{"trusted":true,"_uuid":"c963ea6448a37e0560489c2d0bf8ea39a9e28634","collapsed":true},"cell_type":"code","source":"print('Total number of question pairs for testing: {}'.format(len(df_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fcbab493844868a5ad40bf5dd310d23299dfe26"},"cell_type":"markdown","source":"It is also worth pointing out that the actual number of test rows are likely to be much lower than 2.3 million. According to the data page, most of the rows in the test set are using auto-generated questions to pad out the dataset, and deter any hand-labelling. This means that the true number of rows that are scored could be very low.\n\nWe can actually see in the head of the test data that some of the questions are obviously auto-generated, as we get delights such as \"How their can I start reading?\" and \"What foods fibre?\". Truly insightful questions.\n\nNow onto the good stuff - the text data!"},{"metadata":{"_uuid":"b072561e311b3427be98a6e0402229a180c88813"},"cell_type":"markdown","source":"# Text Analysis"},{"metadata":{"_uuid":"821e3fbcb5e02a2cb7a16ef8de04a38e86835504"},"cell_type":"markdown","source":"First off, some quick histograms to understand what we're looking at. Most analysis here will be only on the training set, to avoid the auto-generated questions"},{"metadata":{"trusted":true,"_uuid":"09727f7e29086b67931201e5af058b1e71cf0999","collapsed":true},"cell_type":"code","source":"# Histogram of character count in train & test questions \n\ntrain_qs = pd.Series(df_train['question1'].tolist() + df_train['question2'].tolist()).astype(str)\ntest_qs = pd.Series(df_test['question1'].tolist() + df_test['question2'].tolist()).astype(str)\n\ndist_train = train_qs.apply(len)\ndist_test = test_qs.apply(len)\nplt.figure(figsize=(15, 10))\nplt.hist(dist_train, bins=200, range=[0, 200], color=pal[2], normed=True, label='train')\nplt.hist(dist_test, bins=200, range=[0, 200], color=pal[1], normed=True, alpha=0.5, label='test')\nplt.title('Normalised histogram of character count in questions', fontsize=15)\nplt.legend()\nplt.xlabel('Number of characters', fontsize=15)\nplt.ylabel('Probability', fontsize=15)\n\nprint('mean-train {:.2f} std-train {:.2f} mean-test {:.2f} std-test {:.2f} max-train {:.2f} max-test {:.2f}'.format(dist_train.mean(), \n                          dist_train.std(), dist_test.mean(), dist_test.std(), dist_train.max(), dist_test.max()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edb0adf9d6c75caacd851eeccd64f3a70b1f3c17"},"cell_type":"markdown","source":"We can see that most questions have anywhere from 15 to 150 characters in them. It seems that the test distribution is a little different from the train one, but not too much so (I can't tell if it is just the larger data reducing noise, but it also seems like the distribution is a lot smoother in the test set).\n\nOne thing that catches my eye is the steep cut-off at 150 characters for the training set, for most questions, while the test set slowly decreases after 150. Could this be some sort of Quora question size limit?\n\nIt's also worth noting that I've truncated this histogram at 200 characters, and that the max of the distribution is at just under 1200 characters for both sets - although samples with over 200 characters are very rare.\n\nLet's do the same for word count. I'll be using a naive method for splitting words (splitting on spaces instead of using a serious tokenizer), although this should still give us a good idea of the distribution.\n\n"},{"metadata":{"trusted":true,"_uuid":"8dbb40adf4028e80a8dbf49a241f83ea9ae56af2","collapsed":true},"cell_type":"code","source":"# Histogram of  word count in train & test questions \ndist_train = train_qs.apply(lambda x: len(x.split(' ')))\ndist_test = test_qs.apply(lambda x: len(x.split(' ')))\n\nplt.figure(figsize=(15, 10))\nplt.hist(dist_train, bins=50, range=[0, 50], color=pal[2], normed=True, label='train')\nplt.hist(dist_test, bins=50, range=[0, 50], color=pal[1], normed=True, alpha=0.5, label='test')\nplt.title('Normalised histogram of word count in questions', fontsize=15)\nplt.legend()\nplt.xlabel('Number of words', fontsize=15)\nplt.ylabel('Probability', fontsize=15)\n\nprint('mean-train {:.2f} std-train {:.2f} mean-test {:.2f} std-test {:.2f} max-train {:.2f} max-test {:.2f}'.format(dist_train.mean(), \n                          dist_train.std(), dist_test.mean(), dist_test.std(), dist_train.max(), dist_test.max()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49bcfe5e3191e0442eab07044915fe57204c2a95"},"cell_type":"markdown","source":"We see a similar distribution for word count, with most questions being about 10 words long. It looks to me like the distribution of the training set seems more \"pointy\", while on the test set it is wider. Nevertheless, they are quite similar."},{"metadata":{"_uuid":"602afa07330a307823edca85efa189846f348c68"},"cell_type":"markdown","source":"# Word Cloud of most common words in training set"},{"metadata":{"trusted":true,"_uuid":"f231d61515aee669a46b451da246322b7a025cec","collapsed":true},"cell_type":"code","source":"from wordcloud import WordCloud\ncloud = WordCloud(width=1440, height=1080).generate(\" \".join(train_qs.astype(str)))\nplt.figure(figsize=(20, 15))\nplt.imshow(cloud)\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"225cc686c06c68ffd854e29419058e2752c44c6f"},"cell_type":"markdown","source":"# Text cleaning "},{"metadata":{"trusted":true,"_uuid":"d97440d0e083ba3d3a0fca5aa5348bbb0683220e","collapsed":true},"cell_type":"code","source":"from nltk.corpus import stopwords \nfrom string import punctuation \nimport re\n\nstops = set(stopwords.words(\"english\")) \npunctuation = set(punctuation) \nstops_final = stops.union(punctuation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"66feb5dc94b315b229b3b448fe4053e32a84ba5b"},"cell_type":"code","source":"import re \nimport nltk \ndef clean(text,remove_stop_words=True,stem_words=False):\n    text = str(text)\n    text = text.lower() \n    text = re.sub(r\"\\b([A-Za-z]+)'re\\b\", '\\\\1 are', text)\n    text = re.sub(r\"\\b([A-Za-z]+)'s\\b\", '\\\\1 is', text) \n    text = re.sub(r\"\\b([A-Za-z]+)'m\\b\", '\\\\1 am', text) \n    text = re.sub(r\"\\b([A-Za-z]+)'ve\\b\", '\\\\1 have', text) \n    text = re.sub(r\"\\b([A-Za-z]+)'ll\\b\", '\\\\1 will', text) \n    text = re.sub(r\"\\b([A-Za-z]+)'t\\b\", '\\\\1 not', text) \n    text = re.sub(r\"[\\'?,\\.]\", ' ', text) \n    text = re.sub(r\"\\s+\", ' ', text)  \n    text = re.sub(r\"quikly\", \"quickly\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"\\busa\\b\", \"America\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"\\buk\\b\", \"England\", text,flags=re.IGNORECASE) \n    text = re.sub(r\"imrovement\", \"improvement\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"intially\", \"initially\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"\\bdms\\b\", \"direct messages \", text,flags=re.IGNORECASE)  \n    text = re.sub(r\"demonitization\", \"demonetization\", text,flags=re.IGNORECASE) \n    text = re.sub(r\"actived\", \"active\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"kms\", \" kilometers \", text,flags=re.IGNORECASE)\n    text = re.sub(r\"\\bcs\\b\", \"computer science\", text,flags=re.IGNORECASE) \n    text = re.sub(r\"\\bupvotes\\b\", \"bup votes\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"\\biPhone\\b\", \"phone\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"\\0rs \", \" rs \", text,flags=re.IGNORECASE) \n    text = re.sub(r\"calender\", \"calendar\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"ios\", \"operating system\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"gps\", \"GPS\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"gst\", \"GST\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"programing\", \"programming\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"bestfriend\", \"best friend\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"dna\", \"DNA\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"III\", \"3\", text,flags=re.IGNORECASE) \n    text = re.sub(r\"the US\", \"America\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"Astrology\", \"astrology\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"Method\", \"method\", text,flags=re.IGNORECASE)\n    text = re.sub(r\"Find\", \"find\", text,flags=re.IGNORECASE) \n    text = re.sub(r\"banglore\", \"Banglore\", text,flags=re.IGNORECASE) \n    \n    #Remove punctuation and stopwords: \n    text = ' '.join([c for c in text.split(' ') if c not in stops_final]) \n   \n    if stem_words:\n        text = text.split(' ')\n        stemmer = SnowballStemmer('english')\n        stemmed_words = [stemmer.stem(word) for word in text]\n        text = \" \".join(stemmed_words)\n\n    # Return a list of words. \n    return text \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"036ac826790272462f2d60d8f1ad7b449d5e8cd1"},"cell_type":"code","source":"# Function to call clean function \ndef process_questions(questions,clean_questions):\n    for question in questions:\n        clean_questions.append(clean(question))\n        if len(clean_questions) % 100000 == 0:\n           progress = len(clean_questions)/len(questions) *100\n           print(\"Progress is {}% complete\".format(round(progress,1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c01722a3c0533dd2e754b8152a91a17cb39239d8","collapsed":true},"cell_type":"code","source":"# Cleaning Questions on Training Data\n\ndf_train_qs1_clean = []\ndf_train_qs2_clean = []\nprocess_questions(df_train.question1,df_train_qs1_clean) \nprocess_questions(df_train.question2,df_train_qs2_clean)   \n\ndf_train.question1 = df_train_qs1_clean\ndf_train.question2 = df_train_qs2_clean\n\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1320729dfaf876a5e3571dc0ae08127c1b7b9eb8","collapsed":true},"cell_type":"code","source":"df_test_qs1_clean = []\ndf_test_qs2_clean = []\n\n# cleaning question1 column in test data\nprocess_questions(df_test.question1,df_test_qs1_clean)  \n\n# cleaning question2 column2 in test data\nprocess_questions(df_test.question2,df_test_qs2_clean)  \n\n# replacing original data \ndf_test.question1 = df_test_qs1_clean\ndf_test.question2 = df_test_qs2_clean \n\n# new test data looks like\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c1e8cc83a8375616255b5e02f9c3f13d010fdd0"},"cell_type":"markdown","source":"## Initial Feature Analysis   \n### 1st Feature : word_share_count"},{"metadata":{"trusted":true,"_uuid":"d4fb90e27b43c53405976052647bcdbd5860a7c0","collapsed":true},"cell_type":"code","source":"from nltk.corpus import stopwords\n\nstops = set(stopwords.words(\"english\"))\n\ndef word_match_share(row):\n    q1words = {}\n    q2words = {}\n    for word in str(row['question1']).lower().split():\n        if word not in stops:\n            q1words[word] = 1\n    for word in str(row['question2']).lower().split():\n        if word not in stops:\n            q2words[word] = 1\n    if len(q1words) == 0 or len(q2words) == 0:\n        # The computer-generated chaff includes a few questions that are nothing but stopwords\n        return 0\n    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n    return R\n\nplt.figure(figsize=(15, 5))\ntrain_word_match = df_train.apply(word_match_share, axis=1, raw=True)\nplt.hist(train_word_match[df_train['is_duplicate'] == 0], bins=20, normed=True, label='Not Duplicate')\nplt.hist(train_word_match[df_train['is_duplicate'] == 1], bins=20, normed=True, alpha=0.7, label='Duplicate')\nplt.legend()\nplt.title('Label distribution over word_match_share', fontsize=15)\nplt.xlabel('word_match_share', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1d8402dade0b776e5fc1d93ce80bac6a902fd41"},"cell_type":"markdown","source":"Here we can see that this feature has quite a lot of predictive power, as it is good at separating the duplicate questions from the non-duplicate ones. Interestingly, it seems very good at identifying questions which are definitely different, but is not so great at finding questions which are definitely duplicates."},{"metadata":{"_uuid":"6a8cd83694bdaec4513cc77d601bdb5657809323"},"cell_type":"markdown","source":"### 2nd Feature : tfidf_word_share_count  \n\nI'm now going to try to improve this feature, by using something called TF-IDF (term-frequency-inverse-document-frequency). This means that we weigh the terms by how uncommon they are, meaning that we care more about rare words existing in both questions than common one. This makes sense, as for example we care more about whether the word \"exercise\" appears in both than the word \"and\" - as uncommon words will be more indicative of the content.\n\nYou may want to look into using sklearn's TfidfVectorizer to compute weights if you are implementing this yourself, but as I am too lazy to read the documentation I will write a version in pure python with a few changes which I believe should help the score."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"24a4e9d56ac7c6d702aaa5f58057fd6c2e6884e9"},"cell_type":"code","source":"\ntrain_qs = pd.Series(df_train['question1'].tolist() + df_train['question2'].tolist()).astype(str)\ntest_qs = pd.Series(df_test['question1'].tolist() + df_test['question2'].tolist()).astype(str)\n\nfrom collections import Counter\n\n# If a word appears only once, we ignore it completely (likely a typo)\n# Epsilon defines a smoothing constant, which makes the effect of extremely rare words smaller\ndef get_weight(count, eps=10000, min_count=2):\n    if count < min_count:\n        return 0\n    else:\n        return 1 / (count + eps)\n\neps = 5000 \nwords = (\" \".join(train_qs)).lower().split()\ncounts = Counter(words)\nweights = {word: get_weight(count) for word, count in counts.items()}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2d3eaa16c8dbe5ac5ff5ca6919360380f0f924a","collapsed":true},"cell_type":"code","source":"print('Most common words and weights: \\n')\nprint(sorted(weights.items(), key=lambda x: x[1] if x[1] > 0 else 9999)[:10])\nprint('\\nLeast common words and weights: ')\n(sorted(weights.items(), key=lambda x: x[1], reverse=True)[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"373d722964d6257042facdd88208f7b0576776f5"},"cell_type":"code","source":"def tfidf_word_match_share(row):\n    q1words = {}\n    q2words = {}\n    for word in str(row['question1']).lower().split():\n        if word not in stops:\n            q1words[word] = 1\n    for word in str(row['question2']).lower().split():\n        if word not in stops:\n            q2words[word] = 1\n    if len(q1words) == 0 or len(q2words) == 0:\n        # The computer-generated chaff includes a few questions that are nothing but stopwords\n        return 0\n    \n    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n    \n    R = np.sum(shared_weights) / np.sum(total_weights)\n    return R","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ffe84a1d9c664f6cd45075c7ae28f6443351a39","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\ntfidf_train_word_match = df_train.apply(tfidf_word_match_share, axis=1, raw=True)\nplt.hist(tfidf_train_word_match[df_train['is_duplicate'] == 0].fillna(0), bins=20, normed=True, label='Not Duplicate')\nplt.hist(tfidf_train_word_match[df_train['is_duplicate'] == 1].fillna(0), bins=20, normed=True, alpha=0.7, label='Duplicate')\nplt.legend()\nplt.title('Label distribution over tfidf_word_match_share', fontsize=15)\nplt.xlabel('word_match_share', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d82198054643b374f4ef5c1536337a8d52cb3b2d","collapsed":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nprint('Original AUC:', roc_auc_score(df_train['is_duplicate'], train_word_match))\nprint('   TFIDF AUC:', roc_auc_score(df_train['is_duplicate'], tfidf_train_word_match.fillna(0)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"109bb7aab833f327ee06dcd87b2abebec582a97e"},"cell_type":"markdown","source":"So it looks like our TF-IDF actually got worse in terms of overall AUC, which is a bit disappointing. (I am using the AUC metric since it is unaffected by scaling and similar, so it is a good metric for testing the predictive power of individual features."},{"metadata":{"_uuid":"cd5261763f315966ef53581853dbb6d94c271181"},"cell_type":"markdown","source":"Our next job is to combine these features and use it to make a prediction. For this, I will use our old friend XGBoost,Logistic Regression to make a classification model.\n\n"},{"metadata":{"_uuid":"9f1fc235e38c7457e5371afd25e8152e214a2eef"},"cell_type":"markdown","source":"## Rebalancing the Data\nHowever, before I do this, I would like to rebalance the data that XGBoost receives, since we have 37% positive class in our training data, and only 17% in the test data. By re-balancing the data so our training set has 17% positives, we can ensure that XGBoost outputs probabilities that will better match the data on the leaderboard, and should get a better score (since LogLoss looks at the probabilities themselves and not just the order of the predictions like AUC)"},{"metadata":{"_uuid":"8c94cc00bce1350719c47de4a7c0d6cfcf07125d"},"cell_type":"markdown","source":"we need 500K more negative samples (is_duplicate = 0) to rebalance training set with 17% positives"},{"metadata":{"trusted":true,"_uuid":"f70c4c643f021318620fdeb64c7b6119df8fa496","collapsed":true},"cell_type":"code","source":"pos_boostrap_sample = df_train[df_train[\"is_duplicate\"] == 0].sample(n = 500000, replace = True)\ndf_train_rebalanced = pd.concat((pos_boostrap_sample, df_train)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a071e918d901e392a1d6929f4697e8bf4992e99c","collapsed":true},"cell_type":"code","source":"# Recalculating word_share_features  on rebalanced dataset \ntfidf_train_word_match_rebalanced = df_train_rebalanced.apply(tfidf_word_match_share, axis=1, raw=True) \ntrain_word_match_rebalanced = df_train_rebalanced.apply(word_match_share, axis=1, raw=True) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fdba96355dea2519a9f9dbc20ab9398063b70cd"},"cell_type":"markdown","source":"## 2nd submission using word_share_features and XGB as a classifier"},{"metadata":{"trusted":true,"_uuid":"b6b09c35ec85185e414de4058553b755b08eca3a","collapsed":true},"cell_type":"code","source":"#First Lets create training & testing data :\nx_train = pd.DataFrame() \nx_test = pd.DataFrame() \nx_train['word_match'] =train_word_match_rebalanced\nx_train['tfidf_word_match'] = tfidf_train_word_match_rebalanced \nx_test['word_match'] = df_test.apply(word_match_share,axis=1,raw=True) \nx_test['tfidf_word_match'] = df_test.apply(tfidf_word_match_share,axis=1,raw=True) \n\ny_train = df_train_rebalanced['is_duplicate'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d222a48de7e8432904dd5307795e2141a721943","collapsed":true},"cell_type":"code","source":"# Finally, we split some of the data off for validation\nfrom sklearn.cross_validation import train_test_split\n\nx_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=4242) \nimport xgboost as xgb\n\n# Set our parameters for xgboost\nparams = {}\nparams['objective'] = 'binary:logistic'\nparams['eval_metric'] = 'logloss'\nparams['eta'] = 0.02\nparams['max_depth'] = 4\n\nd_train = xgb.DMatrix(x_train, label=y_train)\nd_valid = xgb.DMatrix(x_valid, label=y_valid)\n\nwatchlist = [(d_train, 'train'), (d_valid, 'valid')]\n\nbst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"590dd736e1535ff22d3c0852362856bcfda79952"},"cell_type":"code","source":"d_test = xgb.DMatrix(x_test)\np_test = bst.predict(d_test)\n\nsub = pd.DataFrame()\nsub['test_id'] = df_test['test_id']\nsub['is_duplicate'] = p_test\nsub.to_csv('simple_xgb.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b62c4953883136973ea8418df1ce6829e8e86d8d"},"cell_type":"markdown","source":"## 3rd submission using Bag of words features"},{"metadata":{"trusted":true,"_uuid":"ad29f934e7235ddff10515641fb2affc9b3cdbc7","collapsed":true},"cell_type":"code","source":"# create dictionary and extract BOW features from questions \nimport time \n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer  \n\nfeatureExtractionStartTime = time.time() \n\nmaxNumfeatures = 300\n\n#bag of letter sequences (chars) \nBagOfWordsExtractor = CountVectorizer(max_df=0.999 , min_df=50,max_features= maxNumfeatures,analyzer='char',ngram_range=(1,2),binary=True,lowercase=True) \n\n# Concating training question (1 & 2)\ntrain_qs = pd.Series(df_train_rebalanced['question1'].tolist() + df_train_rebalanced['question2'].tolist()).astype(str)\n\nBagOfWordsExtractor.fit(train_qs) \n\ntrain_qs1_BOW = BagOfWordsExtractor.transform(pd.Series(df_train_rebalanced['question1'].tolist())) \ntrain_qs2_BOW = BagOfWordsExtractor.transform(pd.Series(df_train_rebalanced['question2'].tolist())) \n\nfeatureExtractorDurationInMinutes = (time.time() - featureExtractionStartTime)/60.0 \n\nprint('feature extraction took {:.2f} minutes'.format(featureExtractorDurationInMinutes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c91c994c1e394723669772506b36a8c25c35fc8","collapsed":true},"cell_type":"code","source":"# Lets look at some of the feature generated by countVectorizer\nBagOfWordsExtractor.get_feature_names()[:50]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59375f2a5ef306c6df7cbd846e5f2111f3b57529"},"cell_type":"markdown","source":"\n   ** possible feature using bag of word can be  ** :\n   -  take the value \" 0\" if the particular letter sequence is either present or not present in both questions \n   - take the value \"-1\" if the particular letter sequence is present in one question but not the other question"},{"metadata":{"trusted":true,"_uuid":"51996b85b24db50c8670948f9c60557d9de72ac8","collapsed":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn import linear_model\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import roc_auc_score\n\n\n\ncrossValidayionStartTime = time.time() \n\nnumCVSplits = 8 \nnumSplitsToBreakAfter = 2 \n\nX = -(train_qs1_BOW != train_qs2_BOW).astype(int)  \n\n\nlables = np.array(pd.Series(df_train_rebalanced['is_duplicate']).astype(int)) \ny = lables \n\nlogisticRegressor = linear_model.LogisticRegression(C= 0.1 ,solver = 'sag') \n\nlogRegAccuracy = [] \nlogRegLogLoss = [] \nlogRegAUC = [] \n\nprint('---------------------------------------------------------') \n\nstratifiedCV = model_selection.StratifiedKFold(n_splits = numCVSplits , random_state =2) \nfor k , (trainInds,validInds) in enumerate(stratifiedCV.split(X,y)):\n    foldTrainingStartTime = time.time() \n    \n    X_train_cv = X[trainInds,:] \n    X_valid_cv = X[validInds,:] \n    \n    y_train_cv = y[trainInds] \n    y_valid_cv = y[validInds] \n    \n    logisticRegressor.fit(X_train_cv,y_train_cv) \n    \n    y_train_hat = logisticRegressor.predict_proba(X_train_cv)[:,1]\n    y_valid_hat = logisticRegressor.predict_proba(X_valid_cv)[:,1] \n    \n    logRegAccuracy.append(accuracy_score(y_valid_cv,(np.array(y_valid_hat > 0.5).astype(int)))) \n    logRegLogLoss.append(log_loss(y_valid_cv,y_valid_hat)) \n    logRegAUC.append(roc_auc_score(y_valid_cv,y_valid_hat)) \n    \n    foldTrainingDurationInMinutes = (time.time() - foldTrainingStartTime)/60.0  \n    \n    print(' fold {:d} took {:.2f} minutes : accuracy = {:.3f} ,log loss = {:.4f} , AUC = {:.3f}'.format(k+1,foldTrainingDurationInMinutes,logRegAccuracy[-1],logRegLogLoss[-1],logRegAUC[-1])) \n    \n    if(k+1)>= numSplitsToBreakAfter:\n        break\n        \ncrossValidationDurationInMinutes = (time.time() - crossValidayionStartTime)/60.0 \n\nprint('-------------------------------------------------------') \n\nprint('cross validation took {:2f} minutes'.format(crossValidationDurationInMinutes)) \nprint('mean CV: accuracy = {:.3f},logloss = {:.4f},AUC = {:.3f}'.format(np.array(logRegAccuracy).mean(),np.array(logRegLogLoss).mean(),np.array(logRegAUC).mean())) \nprint('------------------------------------------------------')\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea8923100897868129f4cf9ddfc832f8668cb411"},"cell_type":"markdown","source":"## Feature importance of Bag of words feature"},{"metadata":{"trusted":true,"_uuid":"7758cd52dedc6aa43164254aa2aa9debc0e6f32f","collapsed":true},"cell_type":"code","source":"#%% show prediction distribution and \"feature importance\"\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport networkx as nx\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (10,10)\n\nplt.figure(); \nsns.kdeplot(y_valid_hat[y_valid_cv==0], shade=True, color=\"b\", bw=0.01)\nsns.kdeplot(y_valid_hat[y_valid_cv==1], shade=True, color=\"g\", bw=0.01)\nplt.legend(['non duplicate','duplicate'],fontsize=24)\nplt.title('Validation Accuracy = %.3f, Log Loss = %.4f, AUC = %.3f' %(logRegAccuracy[-1],\n                                                                      logRegLogLoss[-1],\n                                                                      logRegAUC[-1]))\nplt.xlabel('Prediction'); plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\n\n\nnumFeaturesToShow = 30\n\nsortedCoeffients = np.sort(logisticRegressor.coef_)[0]\nfeatureNames = BagOfWordsExtractor.get_feature_names()\nsortedFeatureNames = [featureNames[x] for x in list(np.argsort(logisticRegressor.coef_)[0])]\n\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (10,12)\n\nplt.figure()\nplt.suptitle('Feature Importance',fontsize=24)\nax = plt.subplot(1,2,1); plt.title('top non duplicate predictors'); \nplt.xlabel('minus logistic regression coefficient')\nax.barh(range(numFeaturesToShow), -sortedCoeffients[:numFeaturesToShow][::-1], align='center'); \nplt.ylim(-1,numFeaturesToShow); ax.set_yticks(range(numFeaturesToShow)); \nax.set_yticklabels(sortedFeatureNames[:numFeaturesToShow][::-1],fontsize=20)\n\nax = plt.subplot(1,2,2); plt.title('top duplicate predictors'); \nplt.xlabel('logistic regression coefficient')\nax.barh(range(numFeaturesToShow), sortedCoeffients[-numFeaturesToShow:], align='center'); \nplt.ylim(-1,numFeaturesToShow); ax.set_yticks(range(numFeaturesToShow)); \nax.set_yticklabels(sortedFeatureNames[-numFeaturesToShow:],fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66fa30bce9a8e02f0689ce7403f0b2752fac4ffe"},"cell_type":"markdown","source":"## Training using logistic Regression classifier on Bag of words features"},{"metadata":{"trusted":true,"_uuid":"b67c2af1329797c8aac7cfe1986f70206cfcf71f","collapsed":true},"cell_type":"code","source":"#%% train on full training data\n\ntrainingStartTime = time.time()\n\nlogisticRegressor = linear_model.LogisticRegression(C=0.1, solver='sag', \n                                                    class_weight={1: 0.46, 0: 1.32})\nlogisticRegressor.fit(X, y)\n\ntrainingDurationInMinutes = (time.time()-trainingStartTime)/60.0\nprint('full training took %.2f minutes' % (trainingDurationInMinutes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c041029eb54cf30e5435d14e5796c6933ba5151d","collapsed":true},"cell_type":"code","source":"0#%% load test data, extract features and make predictions\n\ntestPredictionStartTime = time.time()\n\n\ntestQuestion1_BOW_rep = BagOfWordsExtractor.transform(df_test.loc[:,'question1'])\ntestQuestion2_BOW_rep = BagOfWordsExtractor.transform(df_test.loc[:,'question2'])\n\nX_test = -(testQuestion1_BOW_rep != testQuestion2_BOW_rep).astype(int)\n\n\n#fix to avoid memory errors\nseperators= [750000,1500000]\ntestPredictions1 = logisticRegressor.predict_proba(X_test[:seperators[0],:])[:,1]\ntestPredictions2 = logisticRegressor.predict_proba(X_test[seperators[0]:seperators[1],:])[:,1]\ntestPredictions3 = logisticRegressor.predict_proba(X_test[seperators[1]:,:])[:,1]\ntestPredictions = np.hstack((testPredictions1,testPredictions2,testPredictions3))\n\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (9,9)  \n\nplt.figure(); \nplt.subplot(2,1,1); sns.kdeplot(y_valid_hat, shade=True, color=\"b\", bw=0.01); \nplt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\nplt.title('mean valid prediction = ' + str(np.mean(y_valid_hat)))\nplt.subplot(2,1,2); sns.kdeplot(testPredictions, shade=True, color=\"b\", bw=0.01);\nplt.xlabel('Prediction'); plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\nplt.title('mean test prediction = ' + str(np.mean(testPredictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fb78b3ed06e6862f50671da026bd4a722ddeb162"},"cell_type":"code","source":"#%% create a submission\nsubmissionName = 'bag_of_words'\nsubmission = pd.DataFrame()\nsubmission['test_id'] = df_test['test_id']\nsubmission['is_duplicate'] = testPredictions\nsubmission.to_csv('bag_of_words' + '.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c42f65af0bd6848254798ad0b5fa5e98bd867afe"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}