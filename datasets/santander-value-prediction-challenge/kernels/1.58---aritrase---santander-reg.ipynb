{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":52,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input/\"]).decode(\"utf8\"))","execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc1bd12d93aa6469e2ad842014a02ecff2b5f30f"},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\nprint(\"Train rows and columns : \", train_df.shape)\nprint(\"Test rows and columns : \", test_df.shape)","execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d60b026b50c757c6ce5f673b14df77a7b504640"},"cell_type":"code","source":"y = train_df['target'].copy()\nX = train_df.drop(labels=['target','ID'],axis=1)\nX_test = test_df.drop(labels=['ID'],axis=1)\n#X.head()\nprint(type(y))\nprint(X.shape)\nprint(X_test.shape)","execution_count":64,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c97176fd8e7b439b158cd598b2e867918948194b"},"cell_type":"code","source":"#\ndef missing_values_table(df): \n        mis_val = df.isnull().sum()\n        mis_val_percent = 100 * df.isnull().sum()/len(df)\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        return mis_val_table_ren_columns","execution_count":59,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48476233855833f3275d793e6f58e140f726f94a"},"cell_type":"code","source":"mis_val_table_ren_columns = missing_values_table(X)\n#print(mis_val_table_ren_columns)\nnan_col = list(mis_val_table_ren_columns[mis_val_table_ren_columns['% of Total Values']> 95].index)\nprint(nan_col) # no missing values column","execution_count":60,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fd1c86aa1a068977071bf265f42c2d9c3f92f4c"},"cell_type":"code","source":"# 256 cols with no variation\nfor col in X.columns.values:\n    if(len(X[col].unique()) == 1):\n        nan_col.append(col)\nprint(len(nan_col))","execution_count":61,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e083c541d15abf486b7f2e7eceab82d62d21c85"},"cell_type":"code","source":"# Drop these columns\nX.drop(nan_col,inplace = True ,axis=1)\nX_test.drop(nan_col,inplace = True ,axis=1)\nprint(X.shape)\nprint(X_test.shape)\nprint(type(X))\nprint(type(X_test))","execution_count":62,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"904ae5cde32f0d6b84f65e38341526bfb9bb85b9"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn import preprocessing, model_selection, metrics\nimport lightgbm as lgb\n\ncolor = sns.color_palette()\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 9999","execution_count":65,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9240aeb94bf1e7bf8fb1103949ebcc52521aca35"},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.distplot( y, bins=50, kde=False)\nplt.xlabel('Target', fontsize=12)\nplt.title(\"Log of Target Histogram\", fontsize=14)\nplt.show()","execution_count":66,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82ff4bfa14b2a56da80275d88cd580084b1934ad"},"cell_type":"code","source":"print(y)\ny = np.log1p(y)\nprint(y)\nplt.figure(figsize=(12,8))\nsns.distplot( y, bins=50, kde=False)\nplt.xlabel('Target', fontsize=12)\nplt.title(\"Log of Target Histogram\", fontsize=14)\nplt.show()","execution_count":68,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bf69379a55aca7639135bcfe0e434b1ee7b27e2e"},"cell_type":"code","source":"# Feature Scaling - StandardScaler\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX = sc_X.fit_transform(X)\nX_test = sc_X.transform(X_test)","execution_count":69,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"385eafe08ccad44894049729c9b5c843010ecc56","collapsed":true},"cell_type":"code","source":"\"\"\"# Fitting Simple Linear Regression to the Training set\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X, y)\n# Predicting the Test set results\ny_pred = regressor.predict(X_test)\n#y_pred = np.expm1(y_pred)\"\"\"","execution_count":48,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff6319f029cfd03b0adcf0117945c0a3e50660b6"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n\nprint(X_train.shape, y_train.shape)\nprint(X_val.shape, y_val.shape)\nprint(X_test.shape)","execution_count":71,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0e14ddf3377f5e49083ba45c4b54af88406482b"},"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error,mean_squared_error\n#from catboost import CatBoostRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nrf_model = RandomForestRegressor(n_estimators=400, n_jobs=-1,oob_score = True,random_state =1, max_depth=8,\n                                 max_features = \"auto\",verbose=1,bootstrap=True,max_leaf_nodes=31)\nrf_model.fit(X_train, y_train)\nRMSLE=np.sqrt(mean_squared_error(y_val,rf_model.predict(X_val)))\nprint(RMSLE)","execution_count":72,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97c142d374d5846262f264b42c7ea9358b12c34e"},"cell_type":"code","source":"pred_rf=np.expm1(rf_model.predict(X_test))\npred_rf","execution_count":73,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e7b2e8aba5200f85e989c3fa39f8c8f4f201b047"},"cell_type":"code","source":"# Making a submission file #\nsub_df = pd.DataFrame({\"ID\":test_df[\"ID\"].values})\nsub_df[\"target\"] = pred_rf\nsub_df.to_csv(\"submission_rf.csv\", index=False)","execution_count":75,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"098019923548cd825f78ab05a94a65567095229f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}