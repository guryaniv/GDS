{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# Intro\n\nIn many of the audio files there are silent parts. My guess is that there is not much useful information.\n\nIn this kernel we will try to explore that assumption and see if it is a good idea to crop the silent parts."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nfrom tqdm import tqdm\nimport IPython.display as ipd\nfrom scipy.io import wavfile\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d27e5ad3-4669-4ae2-973d-384af408edb9","_uuid":"6cc98985efb440d0da4dfbce5c2f77710fa8a289","collapsed":true,"trusted":true},"cell_type":"code","source":"TRAIN_PATH = '../input/audio_train/'\ntrain_ids = next(os.walk(TRAIN_PATH))[2]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ec5bbe8c-bb40-4a88-8302-478c31001afa","_uuid":"aa19f72201071b77c5975a1b7a5c53e083278b97"},"cell_type":"markdown","source":"We will look on one example"},{"metadata":{"_cell_guid":"20ddce0c-510a-4658-b1f6-9a545887faf6","_uuid":"7cfd670fc6b673b786bea9d8ad53af1d5dfb0e6f","collapsed":true,"trusted":true},"cell_type":"code","source":"ipd.Audio(TRAIN_PATH + \"31440023.wav\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5372768c-6b14-4647-8e41-5a169d267cee","_uuid":"1fcf1be8eba06bf3ad549fb230af54314116e497","collapsed":true},"cell_type":"markdown","source":"As you can hear, most of he time there is no sound at all.\n\nNow lets look at signal in time domain"},{"metadata":{"_cell_guid":"ee7e56af-427f-41e7-ad6e-1ec108564ee5","_uuid":"87402cb7c67516692870653ec2dcc9e6fb49dce6","collapsed":true,"trusted":true},"cell_type":"code","source":"sample_rate, audio = wavfile.read(TRAIN_PATH + \"31440023.wav\")\n\nplt.plot(audio);","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"45a4209b-35a5-4b3a-9f6b-c462444bc2d0","_uuid":"d256b440de6ae7d9a2d4e657e692639451553e04"},"cell_type":"markdown","source":"So the idea is to crop and segment the audio files and leave only the part that contain information.\n\nFirst wi will normalize the data to be between -1 and 1:\n\nNote that not all audio values are between -32768 and 32768"},{"metadata":{"_cell_guid":"18528a5c-e21b-4aaa-8bb8-87d04bf3797c","_uuid":"dea55b83dd6130f40dc93cfd610ada2204db1744","collapsed":true,"trusted":true},"cell_type":"code","source":"def normalize_audio(audio):\n    #audio = (audio + 32768) / 65535\n    audio = audio / max(np.abs(audio))\n    return audio","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"026f9c51-97a5-4a85-b143-ab30915157a5","_uuid":"22c8979301daa32c5d2b6673987c1cb29c66a1ce"},"cell_type":"markdown","source":"We will implement a sliding window that measures the power in each segment and based on that decides if this part is a noise.\n\nFinally the function returns the start and stop of each segment in the audio."},{"metadata":{"_cell_guid":"8d8cb5a7-f5ba-4815-8ffe-6ff5e26594b2","_uuid":"a8cc2f1794bc266a5e212dca1f6821c4a3242996","collapsed":true,"trusted":true},"cell_type":"code","source":"def divide_audio(audio, resolution=100, window_duration=0.1, minimum_power=0.001, sample_rate=44100):    \n    duration = len(audio) / sample_rate #in seconds\n    itterations = int(duration * resolution)\n    step = int(sample_rate / resolution)\n    window_length = np.floor(sample_rate*window_duration)\n    audio_power = np.square(normalize_audio(audio)) / window_length #Normalized power to window duration\n    \n    start = np.array([])\n    stop = np.array([])\n    is_started = False\n    \n    for n in range(itterations):\n        power = np.sum(audio_power[n*step : int(n*step+window_length)])\n        if not is_started and power > minimum_power:\n            start = np.append(start, n*step+window_length/2)\n            is_started = True\n        elif is_started and (power <= minimum_power or n == itterations-1):\n            stop = np.append(stop, n*step+window_length/2)\n            is_started = False\n    \n    if start.size == 0:\n        start = np.append(start, 0)\n        stop = np.append(stop, len(audio))\n        \n    start = start.astype(int)\n    stop = stop.astype(int)\n    return start, stop","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8f9669d2-ddc8-41e3-a2cc-06d4316a5f1c","_uuid":"fb4626705f174564e4a62031ce55734cfc5e5266","collapsed":true,"trusted":true},"cell_type":"code","source":"start, stop =  divide_audio(audio)\nprint(start)\nprint(stop)\nplt.plot(audio[start[0]:stop[0]]);","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cba7a651-9878-42e9-8e06-2ef823ecbca3","_uuid":"3fdb889c4ad1463080a23a0f590228315102f9ba"},"cell_type":"markdown","source":"After some manual tunning it seems that the it works\n\nNow lets briefly look on more examples:\n\nLoop logic taken from: [https://www.kaggle.com/codename007/a-very-extensive-freesound-exploratory-analysis](http://www.kaggle.com/codename007/a-very-extensive-freesound-exploratory-analysis)"},{"metadata":{"_cell_guid":"9be6479d-fd1e-4e80-b18c-e14ea9fd17f2","_uuid":"3314ee9dc008620769e1e56f40eed8891aab0ee7","collapsed":true,"trusted":true},"cell_type":"code","source":"columns = ['File Name', 'Audio Duration', 'Segment Number']\naudio_segments = pd.DataFrame(columns=columns)\n\nfig, ax = plt.subplots(10, 4, figsize = (12, 16))\nfor i in tqdm(range(40), total=40):\n    random_audio_idxs = np.random.randint(len(train_ids)+1, size=1)[0]\n    _, tmp = wavfile.read(TRAIN_PATH + train_ids[random_audio_idxs])\n    start, stop = divide_audio(tmp)\n    \n    audio_segments = audio_segments.append({'File Name': train_ids[random_audio_idxs],\n                                            'Audio Duration': len(tmp)/sample_rate,\n                                            'Segment Number': len(start)}, ignore_index=True)\n    \n    ax[i//4, i%4].plot(tmp)\n    ax[i//4, i%4].set_title(train_ids[random_audio_idxs])\n    ax[i//4, i%4].get_xaxis().set_ticks([])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c72f862f-6cc4-4832-9708-bd59a3e9a1e6","_uuid":"f8ac2854dc8a25807b8e2d751bc9f55e415ce7d1","collapsed":true,"trusted":true},"cell_type":"code","source":"audio_segments","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4e34f2a9-8e03-49c9-bac3-a52ded8a4f13","_uuid":"9963290b4a9afe6b05bb6d114e38c5c336cc4a7c"},"cell_type":"markdown","source":"After some more manual tuning it seems that the code can sufficiently segment and remove the noise.\n\nTo create a new training set, run the following code:"},{"metadata":{"_cell_guid":"924bedfc-e38f-462b-99e8-ca8388e06a80","_uuid":"1e6412134add0fd3a736fbceaaa661ff0c0d800d","collapsed":true,"trusted":true},"cell_type":"code","source":"#train = pd.read_csv('../input/train.csv')\n#new_train = pd.DataFrame(columns=train.columns)\n\n#if not os.path.exists(TRAIN_PATH + 'segmented'):\n#    os.makedirs(TRAIN_PATH + 'segmented')\n\n#for n in tqdm(range(len(train_ids)), total=len(train_ids)):\n#    _, tmp = wavfile.read(TRAIN_PATH + train_ids[n])\n#    start, stop = divide_audio(tmp, window_duration=0.1, minimum_power=0.001)\n#    new_path = TRAIN_PATH + 'segmented/' + train_ids[n]\n    \n#    if len(start) <= 1:\n#        wavfile.write(new_path, sample_rate, tmp[start[0]:stop[0]])\n#        new_train = new_train.append(train.iloc[n])\n#    else:\n#        for m in range(len(start)):\n#            wavfile.write(new_path[:-4] + '_' + str(m) + '.wav', sample_rate, tmp[start[m]:stop[m]])\n#            new_train = new_train.append({train.columns[0]: train.iloc[n][train.columns[0]][:-4] + '_' + str(m) + '.wav',\n#                                          train.columns[1]: train.iloc[n][train.columns[1]],\n#                                          train.columns[2]: train.iloc[n][train.columns[2]],}, ignore_index=True)\n            \n#new_train.to_csv(TRAIN_PATH + 'segmented/train.csv', index=False)","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"a69bbd2d-8bf4-4d96-a8f9-a73c640f24f3","_uuid":"b3a5bf8b8ee617ce97f766286396606860229abd"},"cell_type":"markdown","source":"I did not have the chance to check this new test set on a NN.\n\nI will continue update here."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}