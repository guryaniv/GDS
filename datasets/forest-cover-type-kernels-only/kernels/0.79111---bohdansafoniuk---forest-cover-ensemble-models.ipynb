{"cells":[{"metadata":{"trusted":false,"_uuid":"24f09ac57ff799cb5f2f453c82b1ad90ac13f964"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n\nimport random\nimport itertools\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom time import time\nfrom scipy import stats\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler\n\n%pylab inline\npylab.rcParams['figure.figsize'] = (10, 6)\nsns.set(style='white', context='notebook', palette='deep')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"855f079bc3c9a317d1eeae284b64409642c68811"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\nX_test = pd.read_csv('../input/test.csv')\n\nY_train = train['Cover_Type']\nX_train = train.drop('Cover_Type', axis=1)\ntest_id = X_test['Id']\n\ndel train","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6ba5f0f5a0d55e3214a2594371a6ccd4861876e0"},"cell_type":"code","source":"def preprocess(df):\n    df = df.drop('Id', axis=1)\n\n    wilderness_types = [f'Wilderness_Area{i}' for i in range(1, 5)]\n    df[wilderness_types] = df[wilderness_types].multiply(range(1, 5), axis=1)\n    df['wilderness_types'] = df[wilderness_types].sum(axis=1)\n    df = df.drop(wilderness_types, axis=1)\n\n    soil_types = [f'Soil_Type{i}' for i in range(1, 41)]\n    df[soil_types] = df[soil_types].multiply(range(1, 41), axis=1)\n    df['soil_type'] = df[soil_types].sum(axis=1)\n    df = df.drop(soil_types, axis=1)\n    \n    df['HF1'] = abs(df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Fire_Points'])\n    df['HF2'] = abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Fire_Points'])\n    df['HR1'] = abs(df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Roadways'])\n    df['HR2'] = abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Roadways'])\n    df['FR1'] = abs(df['Horizontal_Distance_To_Fire_Points'] + df['Horizontal_Distance_To_Roadways'])\n    df['FR2'] = abs(df['Horizontal_Distance_To_Fire_Points'] - df['Horizontal_Distance_To_Roadways'])\n\n    df['slope_hyd'] = (df['Horizontal_Distance_To_Hydrology'] ** 2 + df['Vertical_Distance_To_Hydrology'] ** 2) ** 0.5\n    df['slope_hyd'] = df['slope_hyd'].map(lambda x: 0 if np.isinf(x) else x)\n\n    df['Mean_Amenities'] = (df['Horizontal_Distance_To_Fire_Points'] +\n                          df['Horizontal_Distance_To_Hydrology'] +\n                          df['Horizontal_Distance_To_Roadways']) / 3  \n    df['Mean_Fire_Hyd'] = (df['Horizontal_Distance_To_Fire_Points'] + df['Horizontal_Distance_To_Hydrology']) / 2\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c9c467ada92a6889603aa1e94046545f0a328099"},"cell_type":"code","source":"def get_random_state():\n    return random.randint(1, 1000)\n\ndef get_split_coef():\n    return round(random.uniform(0.1, 0.35), 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"67a5121b9bbe33bb19a57eed39eaa38e49ea83d8"},"cell_type":"code","source":"X_train = preprocess(X_train)\nX_test = preprocess(X_test)\n\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"301fb1c1786610a2f77adf694c0e7c98303f036c"},"cell_type":"code","source":"target_names = {\n    1: 'Spruce/Fir',\n    2: 'Lodgepole Pine',\n    3: 'Ponderosa Pine',\n    4: 'Cottonwood/Willow',\n    5: 'Aspen',\n    6: 'Douglas-fir',\n    7: 'Krummholz'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b720db749b3a0e6d935d961623fb92dd60f99a31"},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b84f1b5dd0d38903be552515877be37012db939d"},"cell_type":"code","source":"rand_state = get_random_state()\nsplit_coef = get_split_coef()\n\nx_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train,\n                                                      test_size=split_coef,\n                                                      random_state=rand_state)\nprint(f'training samples: {x_train.shape[0]}, validating samples: {x_valid.shape[0]}')\n\nmodel_rf1 = RandomForestClassifier(n_estimators=2000, n_jobs=3, criterion='entropy', random_state=rand_state)\n\nstart = time.time()\n\nmodel_rf1.fit(x_train, y_train)\nmodel_rf1_output = pd.DataFrame({'Id': test_id, 'Cover_Type': model_rf1.predict(X_test)})\n\nprint(f'Runtime for RandomForestClassifier1: {time.time() - start}')\nprint(f'Total accuracy: {accuracy_score(y_valid, model_rf1.predict(x_valid))}')\nprint(classification_report(y_valid, model_rf1.predict(x_valid), target_names=list(target_names.values())))\nmodel_rf1_output.to_csv('rf1_predictions.csv', index=False)\n\nconf_matr = confusion_matrix(y_valid, model_rf1.predict(x_valid))\nplot_confusion_matrix(conf_matr, classes = target_names.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"18c68c788cf0d2e43b19e6bfca65437213e373b3"},"cell_type":"code","source":"rand_state = get_random_state()\nsplit_coef = get_split_coef()\n\nx_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train,\n                                                      test_size=split_coef,\n                                                      random_state=rand_state)\nprint(f'training samples: {x_train.shape[0]}, validating samples: {x_valid.shape[0]}')\n\nmodel_rf2 = RandomForestClassifier(n_estimators=2000, n_jobs=3, criterion='entropy', random_state=rand_state)\n\nstart = time.time()\n\nmodel_rf2.fit(x_train, y_train)\nmodel_rf2_output = pd.DataFrame({'Id': test_id, 'Cover_Type': model_rf2.predict(X_test)})\n\nprint(f'Runtime for RandomForestClassifier2: {time.time() - start}')\nprint(f'Total accuracy: {accuracy_score(y_valid, model_rf2.predict(x_valid))}')\nprint(classification_report(y_valid, model_rf2.predict(x_valid), target_names=list(target_names.values())))\nmodel_rf2_output.to_csv('rf2_predictions.csv', index=False)\n\nconf_matr = confusion_matrix(y_valid, model_rf2.predict(x_valid))\nplot_confusion_matrix(conf_matr, classes = target_names.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0b758d88b00525cb067b688fb2dfc21bdbc677e9"},"cell_type":"code","source":"rand_state = get_random_state()\nsplit_coef = get_split_coef()\n\nx_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train,\n                                                      test_size=split_coef,\n                                                      random_state=rand_state)\nprint(f'training samples: {x_train.shape[0]}, validating samples: {x_valid.shape[0]}')\n\nmodel_rf3 = RandomForestClassifier(n_estimators=2000, n_jobs=3, criterion='entropy', random_state=rand_state)\n\nstart = time.time()\n\nmodel_rf3.fit(x_train, y_train)\nmodel_rf3_output = pd.DataFrame({'Id': test_id, 'Cover_Type': model_rf3.predict(X_test)})\n\nprint(f'Runtime for RandomForestClassifier3: {time.time() - start}')\nprint(f'Total accuracy: {accuracy_score(y_valid, model_rf3.predict(x_valid))}')\nprint(classification_report(y_valid, model_rf3.predict(x_valid), target_names=list(target_names.values())))\nmodel_rf3_output.to_csv('rf3_predictions.csv', index=False)\n\nconf_matr = confusion_matrix(y_valid, model_rf3.predict(x_valid))\nplot_confusion_matrix(conf_matr, classes = target_names.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"48a7da34df2a39d166fec1f57f68c23e2385eb58"},"cell_type":"code","source":"rand_state = get_random_state()\nsplit_coef = get_split_coef()\n\nx_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train,\n                                                      test_size=split_coef,\n                                                      random_state=rand_state)\nprint(f'training samples: {x_train.shape[0]}, validating samples: {x_valid.shape[0]}')\n\nmodel_extra1 = ExtraTreesClassifier(n_estimators=2000, n_jobs=3, bootstrap=True, random_state=rand_state)\n\nstart = time.time()\n\nmodel_extra1.fit(x_train, y_train)\nmodel_extra1_output = pd.DataFrame({'Id': test_id, 'Cover_Type': model_extra1.predict(X_test)})\n\nprint(f'Runtime for ExtraTreesClassifier: {time.time() - start}')\nprint(f'Total accuracy: {accuracy_score(y_valid, model_extra1.predict(x_valid))}')\nprint(classification_report(y_valid, model_extra1.predict(x_valid), target_names=list(target_names.values())))\nmodel_extra1_output.to_csv('extra1_predictions.csv', index=False)\n\nconf_matr = confusion_matrix(y_valid, model_extra1.predict(x_valid))\nplot_confusion_matrix(conf_matr, classes = target_names.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"33d82e7c92549b92a3436738d4b4d1e68d7528eb"},"cell_type":"code","source":"rand_state = get_random_state()\nsplit_coef = get_split_coef()\n\nx_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train,\n                                                      test_size=split_coef,\n                                                      random_state=rand_state)\nprint(f'training samples: {x_train.shape[0]}, validating samples: {x_valid.shape[0]}')\n\nmodel_extra2 = ExtraTreesClassifier(n_estimators=2000, n_jobs=3, bootstrap=True, random_state=rand_state)\n\nstart = time.time()\n\nmodel_extra2.fit(x_train, y_train)\nmodel_extra2_output = pd.DataFrame({'Id': test_id, 'Cover_Type': model_extra2.predict(X_test)})\n\nprint(f'Runtime for ExtraTreesClassifier: {time.time() - start}')\nprint(f'Total accuracy: {accuracy_score(y_valid, model_extra2.predict(x_valid))}')\nprint(classification_report(y_valid, model_extra2.predict(x_valid), target_names=list(target_names.values())))\nmodel_extra2_output.to_csv('extra2_predictions.csv', index=False)\n\nconf_matr = confusion_matrix(y_valid, model_extra2.predict(x_valid))\nplot_confusion_matrix(conf_matr, classes = target_names.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"36640801dfb68570a2d83d4fcdfa2947d79db4e7"},"cell_type":"code","source":"rand_state = get_random_state()\nsplit_coef = get_split_coef()\n\nx_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train,\n                                                      test_size=split_coef,\n                                                      random_state=rand_state)\nprint(f'training samples: {x_train.shape[0]}, validating samples: {x_valid.shape[0]}')\n\nmodel_extra3 = ExtraTreesClassifier(n_estimators=2000, n_jobs=3, bootstrap=True, random_state=rand_state)\n\nstart = time.time()\n\nmodel_extra3.fit(x_train, y_train)\nmodel_extra3_output = pd.DataFrame({'Id': test_id, 'Cover_Type': model_extra3.predict(X_test)})\n\nprint(f'Runtime for ExtraTreesClassifier: {time.time() - start}')\nprint(f'Total accuracy: {accuracy_score(y_valid, model_extra3.predict(x_valid))}')\nprint(classification_report(y_valid, model_extra3.predict(x_valid), target_names=list(target_names.values())))\nmodel_extra3_output.to_csv('extra3_predictions.csv', index=False)\n\nconf_matr = confusion_matrix(y_valid, model_extra3.predict(x_valid))\nplot_confusion_matrix(conf_matr, classes = target_names.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"920e72f051dc0e64b2bc4ab3b17bc7bfa14c3561"},"cell_type":"code","source":"rand_state = get_random_state()\nsplit_coef = get_split_coef()\n\nx_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train,\n                                                      test_size=split_coef,\n                                                      random_state=rand_state)\nprint(f'training samples: {x_train.shape[0]}, validating samples: {x_valid.shape[0]}')\n\nmodel_extra4 = ExtraTreesClassifier(n_estimators=2000, n_jobs=3, bootstrap=True, random_state=rand_state)\n\nstart = time.time()\n\nmodel_extra4.fit(x_train, y_train)\nmodel_extra4_output = pd.DataFrame({'Id': test_id, 'Cover_Type': model_extra4.predict(X_test)})\n\nprint(f'Runtime for ExtraTreesClassifier: {time.time() - start}')\nprint(f'Total accuracy: {accuracy_score(y_valid, model_extra4.predict(x_valid))}')\nprint(classification_report(y_valid, model_extra4.predict(x_valid), target_names=list(target_names.values())))\nmodel_extra4_output.to_csv('extra4_predictions.csv', index=False)\n\nconf_matr = confusion_matrix(y_valid, model_extra4.predict(x_valid))\nplot_confusion_matrix(conf_matr, classes = target_names.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"137bbb88d8317e6ad3c3c083eb8dcc8a854a8973"},"cell_type":"code","source":"rand_state = get_random_state()\nsplit_coef = get_split_coef()\n\nx_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train,\n                                                      test_size=split_coef,\n                                                      random_state=rand_state)\nprint(f'training samples: {x_train.shape[0]}, validating samples: {x_valid.shape[0]}')\n\nmodel_extra5 = ExtraTreesClassifier(n_estimators=2000, n_jobs=3, bootstrap=True, random_state=rand_state)\n\nstart = time.time()\n\nmodel_extra5.fit(x_train, y_train)\nmodel_extra5_output = pd.DataFrame({'Id': test_id, 'Cover_Type': model_extra5.predict(X_test)})\n\nprint(f'Runtime for ExtraTreesClassifier: {time.time() - start}')\nprint(f'Total accuracy: {accuracy_score(y_valid, model_extra5.predict(x_valid))}')\nprint(classification_report(y_valid, model_extra5.predict(x_valid), target_names=list(target_names.values())))\nmodel_extra5_output.to_csv('extra5_predictions.csv', index=False)\n\nconf_matr = confusion_matrix(y_valid, model_extra5.predict(x_valid))\nplot_confusion_matrix(conf_matr, classes = target_names.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"02fd8fee7073e4c61918318b7bf18b121cb42f34"},"cell_type":"code","source":"rand_state = get_random_state()\nsplit_coef = get_split_coef()\n\nx_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train,\n                                                      test_size=split_coef,\n                                                      random_state=rand_state)\nprint(f'training samples: {x_train.shape[0]}, validating samples: {x_valid.shape[0]}')\n\nmodel_extra6 = ExtraTreesClassifier(n_estimators=2000, n_jobs=3, bootstrap=True, random_state=rand_state)\n\nstart = time.time()\n\nmodel_extra6.fit(x_train, y_train)\nmodel_extra6_output = pd.DataFrame({'Id': test_id, 'Cover_Type': model_extra6.predict(X_test)})\n\nprint(f'Runtime for ExtraTreesClassifier: {time.time() - start}')\nprint(f'Total accuracy: {accuracy_score(y_valid, model_extra6.predict(x_valid))}')\nprint(classification_report(y_valid, model_extra6.predict(x_valid), target_names=list(target_names.values())))\nmodel_extra6_output.to_csv('extra6_predictions.csv', index=False)\n\nconf_matr = confusion_matrix(y_valid, model_extra6.predict(x_valid))\nplot_confusion_matrix(conf_matr, classes = target_names.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b61a25136627e874687622e75b35e121eebc0574"},"cell_type":"code","source":"final_predictions = pd.DataFrame({'Id': test_id,\n                                  'Cover_Type_rf1': model_rf1_output['Cover_Type'],\n                                  'Cover_Type_rf2': model_rf2_output['Cover_Type'],\n                                  'Cover_Type_rf3': model_rf3_output['Cover_Type'],\n                                  'Cover_Type_extra1': model_extra1_output['Cover_Type'],\n                                  'Cover_Type_extra2': model_extra2_output['Cover_Type'],\n                                  'Cover_Type_extra3': model_extra3_output['Cover_Type'],\n                                  'Cover_Type_extra4': model_extra4_output['Cover_Type'],\n                                  'Cover_Type_extra5': model_extra5_output['Cover_Type'],\n                                  'Cover_Type_extra6': model_extra6_output['Cover_Type']})\npredictions = ['Cover_Type_rf1', 'Cover_Type_rf2', 'Cover_Type_rf3',\n               'Cover_Type_extra1', 'Cover_Type_extra2', 'Cover_Type_extra3',\n               'Cover_Type_extra4', 'Cover_Type_extra5', 'Cover_Type_extra6']\nfinal_predictions['Cover_Type'] = stats.mode(final_predictions[predictions], axis=1).mode\nfinal_predictions = final_predictions.drop(predictions, axis=1)\nfinal_predictions.to_csv('final_predictions.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}