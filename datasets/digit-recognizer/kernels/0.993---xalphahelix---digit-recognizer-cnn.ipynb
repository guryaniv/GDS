{"cells":[{"metadata":{"_cell_guid":"f00d8645-38a2-489f-859d-ce8bfaa84068","_uuid":"1bc716375ec6b7ae75cd072f1a24dc2c2dff3303","collapsed":true,"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8ea12bc7-af42-4a0f-93ee-c1bda941b4db","_uuid":"8aa9ed5580340dc9d1c4bab2ee9543c5edb40ae4","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nprint('Train shape: {}'.format(train.shape))\nprint('Test shape: {}'.format(test.shape)) # Test data does not contain the \"label\" column\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3ac2d6d0-1190-4030-ad2c-897eaf92ae31","_uuid":"3863d19cf02ac1db09455f2086cb492f08814032","collapsed":true,"trusted":true},"cell_type":"code","source":"Y_train = train['label']\nX_train = train.drop(labels=['label'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b6479720-a9eb-48e4-b280-185446c4416b","_uuid":"b742986715ff5379df1c71369940e4b0d7cc7cf3","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.hist(Y_train)\nplt.title('Frequency Histogram of Digits')\nplt.xlabel('Digit')\nplt.ylabel('Frequency')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"485a4cd2-595a-45c8-93bc-a7eb59b21f61","_uuid":"09c4237484ed641546c43b240fd2b44cfb71548d","collapsed":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3, 3, figsize=(10, 6))\n# Plot the first 9 digits in the training set\nfor i in range(9):\n    data = X_train.iloc[i].values\n    n = math.ceil((i+1)/3) - 1\n    m = [0, 1, 2] * 3\n    ax[m[i], n].imshow(data.reshape(28, 28), cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"638405c3-d53d-4a70-9f0b-833b2cb91ab4","_uuid":"fd6c348a3021beb4e9c709d295126064c1e1f792","collapsed":true,"trusted":true},"cell_type":"code","source":"# Normalize the data\nX_train = X_train.astype('float32') / 255\ntest = test.astype('float32') / 255","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3d927939-bd33-4303-9066-fe40a3a13f34","_uuid":"0ff81031c5637d0d6daf03491be21f1c91773e43","collapsed":true,"trusted":true},"cell_type":"code","source":"# One-hot-encoding\nY_train = to_categorical(Y_train, num_classes=10)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"469c047b-1581-49b9-a9d8-936f419de57f","_uuid":"f4f98361c72db114cb77dbcf1d7e13770e77c752","collapsed":true,"trusted":true},"cell_type":"code","source":"# Reshape image in 3 dimensions\n# Keras requires an extra dimension, which is a channel\n# Gray-scaled images use only 1 channel, while RGB images use 3 channels\nX_train = X_train.values.reshape(-1, 28, 28, 1)\ntest = test.values.reshape(-1, 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fc4ea2ec-3489-4bb6-b5b7-70036b42e91e","_uuid":"9d4cae159868a4bc41b0cb27a0c24278db02d2e1","collapsed":true,"trusted":true},"cell_type":"code","source":"# Split the data into a training and a validation set to evaluate model performance\nseed = 42\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, \n                                                  random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0977cad3-ac6e-4746-8797-a837c12e164c","_uuid":"9a16bbae7796e2852c03a8c29d807d164efb6d14","collapsed":true,"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', \n                 input_shape=(28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(strides=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu', \n                 input_shape=(28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(strides=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"24867f4542ec4332941dba29fef8c32621b12d95"},"cell_type":"code","source":"batch_size = 32\nepochs = 20","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"04a6e896-27bb-4c1e-80b5-fcc2166562f8","_uuid":"f352093f9a43ce4c1827ada2e79e4a9c9ef83a49","collapsed":true,"trusted":true},"cell_type":"code","source":"optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n#optimizer = Adam()\nmodel.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"13ae6b45-6d61-4405-925a-aeec46e34040","_uuid":"02b344c74ee3deb26c23e591c92c4940663a3ac0","collapsed":true,"trusted":true},"cell_type":"code","source":"annealer = ReduceLROnPlateau(monitor='val_acc', patience=3, factor=0.5, min_lr=1e-5)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"collapsed":true,"trusted":true,"_uuid":"19a8acc17bbd530622eca8a4f0903bb621ec6d8a"},"cell_type":"code","source":"# Data augmentation\n# Generates more training data by applying small transformations to images\ndatagen = ImageDataGenerator(featurewise_center=False,\n                            samplewise_center=False,\n                            featurewise_std_normalization=False,\n                            samplewise_std_normalization=False,\n                            rotation_range=10,\n                            width_shift_range=0.1,\n                            height_shift_range=0.1,\n                            zoom_range=0.1)\n# Compute quantities required for featurewise normalization\ndatagen.fit(X_train)\n# Fits the model on batches with real-time data augmentation\nhistory = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n                    epochs=epochs, \n                    verbose = 2,\n                    callbacks=[annealer],\n                    validation_data = (X_val, Y_val),\n                    steps_per_epoch=X_train.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"a37170fcc1cc5c4a130b34fbcb0d48bdcb9121db"},"cell_type":"code","source":"# Check performance on entire validation set\nfinal_loss, final_accuracy = model.evaluate(X_val, Y_val)\nprint('Final Loss: {:.4f}, Final Accuracy: {:.4f}'.format(final_loss, final_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"4302bf8a5011dbf210f87437fa4d78146c946847"},"cell_type":"code","source":"plt.plot(history.history['loss'], color='b')\nplt.plot(history.history['val_loss'], color='r')\nplt.title('Training vs. Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Training Loss', 'Validation Loss'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"e5ee08f3de8c483c958317f1cb9c959792de967f"},"cell_type":"code","source":"plt.plot(history.history['acc'], color='b')\nplt.plot(history.history['val_acc'], color='r')\nplt.title('Training vs. Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['Training Accuracy', 'Validation Accuracy'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"3e21bea7e2457022f8e1548ca2a39c501fc72cf9"},"cell_type":"code","source":"Y_pred = model.predict(X_val)\n# Convert predictions to one-hot vectors\nY_pred = np.argmax(Y_pred, axis=1)\nY_true = np.argmax(Y_val, axis=1)\ncm = confusion_matrix(Y_true, Y_pred)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"cbb6aff5811446d73ecdef20dadf08a3880712d7"},"cell_type":"code","source":"predictions = model.predict(test)\npredictions = np.argmax(predictions, axis=1)\nresults = [[i, predictions[i-1]] for i in range(1, 28001)]\nsubmission = pd.DataFrame(results, columns=['ImageId', 'Label'])\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}