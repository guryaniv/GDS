{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.svm import SVC\nimport pandas as pd\nimport json\nfrom random import shuffle\n# Dataset Preparation\nprint (\"Read Dataset ... \")\ndef read_dataset(path):\n\treturn json.load(open(path)) \ntrain = read_dataset('../input/train.json')\ntest = read_dataset('../input/test.json')\n\nshuffle(train)\nshuffle(train)\n# Text Data Features\nprint (\"Prepare text data of Train and Test ... \")\ndef generate_text(data):\n\ttext_data = [\" \".join(doc['ingredients']).lower() for doc in data]\n\treturn text_data \n\ntrain_text = generate_text(train)\ntest_text = generate_text(test)\ntarget = [doc['cuisine'] for doc in train]\n\n# Feature Engineering \nprint (\"TF-IDF on text data ... \")\ntfidf = TfidfVectorizer(binary=True)\ndef tfidf_features(txt, flag):\n    if flag == \"train\":\n    \tx = tfidf.fit_transform(txt)\n    else:\n\t    x = tfidf.transform(txt)\n    x = x.astype('float16')\n    return x \n\nX = tfidf_features(train_text, flag=\"train\")\nX_test = tfidf_features(test_text, flag=\"test\")\n\n# Label Encoding - Target \nprint (\"Label Encode the Target Variable ... \")\nlb = LabelEncoder()\ny = lb.fit_transform(target)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print (\"Label Encode the Target Variable ... \")\nlb = LabelEncoder()\ny = lb.fit_transform(target)\nprint (\"TF-IDF on text data ... \")\ntfidf = TfidfVectorizer(binary=True)\ndef tfidf_features(txt, flag):\n    if flag == \"train\":\n    \tx = tfidf.fit_transform(txt)\n    else:\n\t    x = tfidf.transform(txt)\n    #x = x.astype('float16')\n    return x \n\nX = tfidf_features(train_text, flag=\"train\")\nX_test = tfidf_features(test_text, flag=\"test\")\n\n# Label Encoding - Target \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afa7ce0c8fd873c5a12a7b0bda09c68ae7a858e8"},"cell_type":"code","source":"X=X.toarray().tolist()\nX_test = X_test.toarray().tolist()\nprint(y[1:3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37ff027dfd13851bbfe7f44a3179791ab4865a42"},"cell_type":"code","source":"'''length1 = len(X)\nlength2=  len(X_test)\nxlines=X[:]+X_test[:]\nlength3=len(xlines)\nprint(length1, length2, length3)\nLENGTH=2000\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2,f_classif, mutual_info_classif\nfrom sklearn import decomposition\nf=SelectKBest(chi2, k=LENGTH)\nX = f.fit_transform(X,y)\nmast=f.get_support()\n\nfeachers=[]\ni=0\nfor bool in mast:\n    if bool:\n        feachers.append(i)\n    i+=1\n\nX_test= [[j[i] for i in feachers] for j in X_test]'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b47cefa55a583ffc24348f25d1f3210477d6a59"},"cell_type":"code","source":"'''LENGTH= 2000\npca = decomposition.PCA(n_components=LENGTH)\npca.fit(xlines)\nxlines = pca.transform(xlines)\nxlines=xlines.tolist()\nprint(len(xlines[0]))\nX = xlines[0: length1]\nX_test = xlines[length1:]\nprint(len(X), len(X_test))'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c353d97691d6b77a614fb0e05898b9c9548d7dc4"},"cell_type":"code","source":"from keras.utils import np_utils\nimport numpy as np\nfrom sklearn.utils import class_weight\nY=y#np_utils.to_categorical(y)\n\nclass_weight_ = class_weight.compute_class_weight('balanced',\n                                                 np.unique(y),\n                                                 y)\nclass_weights={}\nfor i in range(len(class_weight_)):\n    class_weights[i]=100/class_weight_[i]\nX=np.array(X)\nX_test=np.array(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5defce37547ae7aaa0f9e340f79745e159756fe"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout ,ActivityRegularization,LeakyReLU\nfrom keras.regularizers import l1_l2,l1\nfrom keras import optimizers\nfrom keras import regularizers\nmodel = Sequential()\nmodel.add(Dense(500, activation='relu',input_shape=(3010,)))\nmodel.add(Dropout(0.25))\n##model.add(Dense(500, activation='relu'))\n#model.add(Dropout(0.25))\n#model.add(Dense(1000, activation='relu'))\n#model.add(Dense(100, activation='relu'))\nmodel.add(Dense(100, activation='relu'))\n#model.add(LeakyReLU(alpha=.2))\n#model.add(Dense(250, activation='linear'))\n#model.add(LeakyReLU(alpha=.2))\n#model.add(ActivityRegularization(l2=0.1))\n\n#model.add(LeakyReLU(alpha=.2))\n#model.add(ActivityRegularization(l2=0.1))\n#model.add(Dense(100, activation='relu'))\n#model.add(LeakyReLU(alpha=.2))\n#model.add(ActivityRegularization(l2=0.1))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(len(Y[0]), activation='softmax'))\nsgd = optimizers.SGD(lr=.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(optimizer='nadam',\n          loss='categorical_crossentropy',\n          metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"3df9d09a75979e81c13c08415a770a44df0c4f3f"},"cell_type":"code","source":"'''from keras.callbacks import ModelCheckpoint\npath_model='model_simple_keras_starter.h5' \ncheckpointer = ModelCheckpoint('model_simple_keras_starter.h5',monitor='val_acc', verbose=1, save_best_only=True)\nmodel.fit(X,Y,epochs=20, \n            verbose=20,\n          batch_size=10,\n            validation_data=(X[33000:],Y[33000:]),\n            shuffle=True ,\n          callbacks=[\n                checkpointer,\n            ]\n         )\ncallbacks=[\n                checkpointer,\n            ]'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34d4d0d2b36f1889e94b3d6dbb024812d5b14021"},"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12286e95e859133d0ef7845b20a1ae4d4e380564"},"cell_type":"code","source":"model = DecisionTreeClassifier(criterion = \"gini\", random_state = 1000,\n                               max_depth=1000, min_samples_leaf=1)\nmodel.fit(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e6d934e494cb2184985e8088902748e0e4ef8dd","scrolled":true},"cell_type":"code","source":"#model.load_weights('model_simple_keras_starter.h5')\nscore = model.score(X[33000:],Y[33000:])\nprint('Test accuracy:', score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8330953fbf6b051436b13975c70e1e42920622cf","collapsed":true},"cell_type":"code","source":"\nAns= model.predict(X_test)\nprint(Ans[0])\n#Ans=[ np.argmax(i) for i in Ans]\nAns=  lb.inverse_transform(Ans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2d28268268ee443d75ec5300cb43c73577d0d6c","collapsed":true},"cell_type":"code","source":"print (\"Generate Submission File ... \")\ntest_id = [doc['id'] for doc in test]\nsub = pd.DataFrame({'id': test_id, 'cuisine': Ans}, columns=['id', 'cuisine'])\nsub.to_csv('svm_output.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}