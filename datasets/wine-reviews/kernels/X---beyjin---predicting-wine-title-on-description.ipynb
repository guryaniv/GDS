{"nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "file_extension": ".py", "version": "3.6.4", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat": 4, "cells": [{"execution_count": null, "cell_type": "code", "source": ["import numpy as np\n", "import pandas as pd\n", "import re\n", "\n", "wine = pd.read_csv(\"../input/winemag-data-130k-v2.csv\")"], "outputs": [], "metadata": {"_uuid": "a487f4120e93e26a79c964864200caa8f5698b22", "_cell_guid": "b574a734-9305-4541-aa64-11dafcb6523f", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["# review wine dataset\n", "wine.head()"], "outputs": [], "metadata": {"_uuid": "768303aad98d6f3766cfacaa581a4fd303054625", "_cell_guid": "75672143-a5e9-4661-88ab-98bca54ba1ff"}}, {"execution_count": null, "cell_type": "code", "source": ["# make sure that each potential input / output does have values \n", "# drop every NaN / Null which occur in the necessary data. \n", "wine.info()"], "outputs": [], "metadata": {"_uuid": "cc594ca9cc7d11d5434c534d34cc1a6259254e9a", "_cell_guid": "202832aa-85d8-4bdf-a9e3-ec4cc77067d0"}}, {"cell_type": "markdown", "source": ["**Fetch the necessary information for the input (question) and output (answer)**\n", "\n", "From the info - we can see that the *description* (input) and *title* (output do not have any NaN \n", "Secondly check if there are any duplicates as well as how many wines do have more than 1 entry. \n", "\n", "**Reasoning why checking the count of 'title' entries: **\n", "To validate the results of our NLP / Deep Learning we do need some kind of Testset. If we take each entry into account - we will run into the issue that we might not be able to automatically test our machine learning algorithm based on existing \"data-inputs\". By validating the training / test-set later on we can also validate if there is a potential solution of generating an Natural Language Model based on this dataset -- the accuracy of correct \"findings\" in the test-set. "], "metadata": {"_uuid": "2c6c533a28a33577ccd3b0c0928ab8b63e0de3f4", "_cell_guid": "ee9feaf5-3b9e-4f1b-b5c2-9c112cad8bc3"}}, {"execution_count": null, "cell_type": "code", "source": ["# remove duplicate descriptions \n", "wine.drop_duplicates(subset = ['description', 'title'], inplace = True)"], "outputs": [], "metadata": {"_uuid": "7f9da85e9b7c85bf87668d57209356c17e549d4e", "_cell_guid": "5c019bde-0428-4a3f-9161-bc4153a2a452", "collapsed": true}}, {"cell_type": "markdown", "source": ["Evaluate the amount of wines which have at least 2 descriptions per title"], "metadata": {"_uuid": "7dbd04f8b96baa505bac5359ea83b210ea3bb7b9", "_cell_guid": "155c3fab-580e-4729-b60a-9fd70305bb56"}}, {"execution_count": null, "cell_type": "code", "source": ["wine_title_count = wine['title'].value_counts().reset_index().rename(columns = {'index':'title', 'title':'count'})\n", "boolWines = wine_title_count[wine_title_count['count'] > 1]\n", "wine_titles = list(boolWines['title'])"], "outputs": [], "metadata": {"_uuid": "e7fc9d4478bb6df5f91619811286bdea4b412215", "_cell_guid": "d4222a73-5227-4611-ac4d-dc7d1c6792c0", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["# Drop all indexes which do not have enough descriptions\n", "wine_cleaned = pd.DataFrame(columns = wine.columns.values)\n", "for title in wine_titles:\n", "    boolTitle = wine['title'] == title\n", "    wine_cleaned = wine_cleaned.append(wine[boolTitle == True], ignore_index= True)\n", "            \n", "len(wine_cleaned.index)"], "outputs": [], "metadata": {"_uuid": "86c9ebe5b6767bac525b06181ac8049dd4b51fcf", "_cell_guid": "38249634-2e59-4b85-a800-02d44ae43b07"}}, {"execution_count": null, "cell_type": "code", "source": ["len(wine_cleaned['title'].value_counts())"], "outputs": [], "metadata": {"_uuid": "9bbbe69cd60f720a1e94ee29c20194c864120466", "_cell_guid": "23979526-224f-4d8a-b1f6-723740f4f9dc"}}, {"cell_type": "markdown", "source": ["Now we have drastically reduced the number of inputs to an index of 2082 and 934 different wines. \n", "It is an immense reduction to the basic data set of having a dataset which is based on 130k information rows. \n", "\n", "This reduction resulted by eliminating duplicates and to filter titles with at least 2 entries"], "metadata": {"_uuid": "3d6f0e52e1141438cf4f0055d8674e2a75e372f6", "_cell_guid": "1d6790f4-ad33-42b3-96b6-67e7452cdab4"}}, {"cell_type": "markdown", "source": ["## Now we\u00b4re starting the fun by preparing everything for our model "], "metadata": {"_uuid": "129e4050eff3c470690cde425379e6f6e03b66a4", "_cell_guid": "340200ab-e7b4-4610-a5f7-88eb21b64495"}}, {"execution_count": null, "cell_type": "code", "source": ["# create input list and output list \n", "questions = list(wine_cleaned['description'])\n", "answers = list(wine_cleaned['title'])"], "outputs": [], "metadata": {"_uuid": "e0b1d0cb807e3a6e4dcac491d9760e07ec9a52ee", "_cell_guid": "b2dc1eda-e42f-410f-b52b-cf68e75f791f", "collapsed": true}}, {"cell_type": "markdown", "source": ["We will keep the answers as they and only prepare the questions for to be more machine understandable as well as improving the performance. \n", "\n", "Straight questions / answer input has been finished - Lets check an example for the status quo. Afterwards we can compare the status quo with the cleaned text (machine friendly input)"], "metadata": {"_uuid": "89f35aa8aba595538002afaa84147440847e1d25", "_cell_guid": "66a9ae65-0cd8-42ec-b4a6-a5811cf9f1b0"}}, {"execution_count": null, "cell_type": "code", "source": ["import nltk \n", "from nltk.corpus import stopwords\n", "from nltk.stem.porter import PorterStemmer\n", "porterStemmer = PorterStemmer()"], "outputs": [], "metadata": {"_uuid": "ac25293cde6fc8e0c46241976d5ce6a07417c9af", "_cell_guid": "591becef-01c5-46a0-a318-d0d9a9386d62", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["def clean_text(text):\n", "    # put everything into lower_case\n", "    text = text.lower()\n", "    \n", "    # sub everything out except of the words of alphabet in lower case. The description of the\n", "    # wines do allow us to only keep that lower case alphabet - depending on some text analyzing\n", "    # e.g. technical data analysis -- having the value (numbers) might be quite important\n", "    text = re.sub('[^a-z]', ' ', text)\n", "    \n", "    # split the whole description in single words\n", "    text = text.split()\n", "    # reduce the number of words to only necessary words - by using stopwords from nltk\n", "    # we can easily kick out words such as \"is\" \"and\" to reduce the input on our model later on and\n", "    # keep focus on relevant words\n", "    # also we will rewrite some words which may be written in plural to - e.g. \"loved\" to \"love\"\n", "    text = [porterStemmer.stem(word) for word in text if not word in set(stopwords.words('english'))]\n", "    text = ' '.join(text)\n", "    return text"], "outputs": [], "metadata": {"_uuid": "4403c6f404d0519a4f41c10b2649072bde3b9e94", "_cell_guid": "e9e201ef-fabf-42ba-bbc9-257a62a95f7f", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["questions_nlp = []\n", "for question in questions:\n", "    questions_nlp.append(clean_text(question))"], "outputs": [], "metadata": {"_uuid": "5619ba5213363c33639a7c7c811d9219642e9790", "_cell_guid": "17231211-05b1-488e-80a3-ed711fd2f04b", "collapsed": true}}, {"cell_type": "markdown", "source": ["Lets compare the original questions with the cleaned questions"], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["questions[0:4]"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["questions_nlp[0:4]"], "outputs": [], "metadata": {"_uuid": "80c48ba233a7800cee728b3f5f9fe0a94785bd57", "_cell_guid": "a3d2e665-1b20-4f30-ab11-fe3f6e599a10"}}, {"cell_type": "markdown", "source": ["Since we do have at least a count of 2 Descriptions per title which means that we will have a test and train set of each 50%. This also means that we have only one train set per title. This may be quite a low number. Still I\u00b4m curious in what the outcome of the training will be. I\u00b4ll be using the Naive Bayes to classify the wine based on the description. But before we do that - lets Vectorize the questions and prepare the train and test-sets"], "metadata": {"_uuid": "c8ed80420196c3f6629fd9b88fe37b2660105f8f", "_cell_guid": "5d3ed679-f6a2-4cc6-8b7d-acc44ef65564", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["# create a dataframe to easilier prepare the correct sets\n", "questions_and_answers = pd.DataFrame(columns = ['questions', 'answers'])\n", "questions_and_answers['questions'] = questions_nlp\n", "questions_and_answers['answers'] = answers\n", "questions_and_answers = questions_and_answers.sort_values(by = 'answers')"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["questions_and_answers.head(n = 10)"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["Lets remind what we did. First we reviewed the data and found some titles which only occured once. Those title were dropped because we can\u00b4t validate them later on per machinel input. Therefore we kept each title which occurs at least twice. This sums up. In order to easily separate test and train - we have sorted the questions and answers by title. \n", "As you can see above - we have all descriptions and answers sorted.  \n", "Now we can Vectorize the questions because they\u00b4re aligned with the new answers now. \n", "\n", "* Our next steps: \n", "* Vectorize our questions and then we will split our dataset into train and test set"], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["questions_final = questions_and_answers['questions']\n", "answers_final = questions_and_answers['answers']"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["from sklearn.feature_extraction.text import CountVectorizer\n", "cv = CountVectorizer()"], "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["questions_ML = cv.fit_transform(questions_final).toarray()\n", "answers_ML = answers_final\n", "len(questions_ML[0])"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["len(questions_ML)"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["len(answers_ML)"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# number of unique classes\n", "answers_ML.nunique()"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["We do have 2082 entries in answers and questions. The questions do have in total 3416 different words which may be an answer on which wine we are searching for. \n", "Now: Split Dataset"], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# Split the data into train and test set\n", "questions_train = []\n", "questions_test = []\n", "answers_train = []\n", "answers_test = []\n", " # dividing the whole set by 50% - since the answers were sorted - \n", " # we will have each title at least once in a test and train set\n", "for row in range(0, len(answers_ML)):\n", "    if row % 2 == 0:\n", "        answers_train.append(answers_ML[row])\n", "        questions_train.append(questions_ML[row])\n", "    else:\n", "        answers_test.append(answers_ML[row])\n", "        questions_test.append(questions_ML[row])\n", "        \n"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["Lets start the learning and review the results in the first attempt."], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["from sklearn.naive_bayes import GaussianNB\n", "classifier = GaussianNB()\n", "classifier.fit(questions_train, answers_train)"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["y_pred = classifier.predict(questions_test)"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["Evaluation = pd.DataFrame(columns = ['prediction', 'testvalues'])\n", "Evaluation['prediction'] = y_pred\n", "Evaluation['testvalues'] = answers_test"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["Evaluation.head(n = 15)"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["Evaluation['prediction_output'] = Evaluation['prediction'] == Evaluation['testvalues']"], "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["Evaluation['prediction_output'].value_counts()"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["Well I would say that the first Iteration was a full disaster. Based on my course of action I\u00b4ve come to some conclusions: \n", "* I did shrink the dataset really low to around 2100 rows of around 130k - Thats a huge sum\n", "* We trained the dataset on a basis of 50 / 50 --> Now I would say that I need much more different descriptions for one wine\n", "* I did try to classify 934 different wines just based on the description. Unfortunately the results are much more worse than I expected. Another solution could be the use of e.g. Decision Tree / Random Forest\n", "* Add additional information to the predictor - e.g.\n", "* taster : each taster has a different sense of writing what he\u00b4s tasting\n", "* variety: might help to get a better classification\n", "\n", "\n", "**Conclusion for now:** \n", "Based on the Description of some wines which I read - I think that the wording of descriptions based on a wine vary quite drastically. The test and train set have been prepared and several different models can be tested. Maybe my thinking of dividing it that way might\u00b4ve been wrong. "], "metadata": {}}]}