{"cells":[{"metadata":{"trusted":true,"_uuid":"11b21b7140fbf3d3472e7db676d45531be1bf7fa"},"cell_type":"markdown","source":"This kernel contain just some basic pipeline with scikit-learn \"pipeline\" building, cross-validation (with implemented contest metric) and some memory tricks.\n\n# Environment preparation"},{"metadata":{"trusted":true,"_uuid":"4dc5ac2f50d0868ffa137e1fbb02d693ac697305","_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\n\ndef reduce_mem_usage(df):\n    \"\"\"\n    Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n    \"\"\"\n    for col in df.columns:\n        col_type = df[col].dtype\n        col_typename = str(col_type)\n        is_numeric = col_typename.startswith('int') or \\\n            col_typename.startswith('float') or \\\n            col_typename.startswith('bool')\n        if is_numeric:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if col_typename.startswith('int') or col_typename.startswith('bool'):\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b453bd9fc2dcdb2203b108d8b8ccea2ecdf190ab"},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nimport gc\n\nenv = twosigmanews.make_env()\nenv._var07 = reduce_mem_usage(env._var07)\nenv._var10 = reduce_mem_usage(env._var10)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd5efc5bce826bd83c819ba45e9e32b1d683a774"},"cell_type":"markdown","source":"In my case, at this stage it used ~5.5Gb memory instead of 7-8Gb without reducing dataframes. \n\n# scikit-learn \"utilities\" functions"},{"metadata":{"_uuid":"8f9038d5802f4f9721bee1d3ea2db4f9d56c3a0a","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import TimeSeriesSplit, cross_val_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.metrics import make_scorer\n\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.preprocessing import FunctionTransformer, LabelBinarizer, StandardScaler\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.decomposition import TruncatedSVD\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6378a4e5f84a7096988a7da3ccb3ca672c29409"},"cell_type":"markdown","source":"## Validation approach\n\nI'll use validation based on time-series splitting of dates. So it'll work next way:\n- split dates to N ranges\n- when on each range:\n  - fit on dates before edge\n  - validate on later dates\n\nBut:\n- I need to predict sign of 10-day returns, not returns\n- in metric funtion I can pass only predictions and real values. \n\nAnd to calculate metric value I need more information then just true returns and predicted. I also need \"universe\" feature and dates, which can't be passed to scorer. So I'll make next thing:\n- create wrapper \"estimator\", which:\n  - fit wrapped model to predict returns sign\n  - after building prediction:\n    - calculate ```recordMetric = confidenceValue * returns * universe```\n    - then aggregate daily metric: ```dailyMetric = sum(recordMetric[day] for day in dates)```\n    - return such aggregated metric instead of prediction\n- then in scoring function I'll calculate next thing: ```metric = mean(dailyMetric) / std(dailyMetric)```\n\nFinally, I'll wrap all this things usage in cross-validation function.\n  "},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"_uuid":"1c353f10851146434baeee9025dfca35ac5614a8"},"cell_type":"code","source":"class DateSplit(TimeSeriesSplit):\n    def split(self, X, y, *args, **kwargs):\n        assert isinstance(X, pd.DataFrame)\n        dates = sorted(X['date'].unique())\n        for train_idx, _ in super(self.__class__, self).split(dates):\n            train_before = dates[train_idx[-1]]\n            train_mask = (X['date'] <= train_before).values\n            val_mask = (X['date'] > train_before).values\n            yield np.where(train_mask)[0], np.where(val_mask)[0]\n            \n            \ndef metric_aggregation(_, daily_metrics):\n    return daily_metrics.mean() / daily_metrics.std()\n\n\nclass DailyMetricEstimator(BaseEstimator):\n    def __init__(self, base_model, pass_collumns=None):\n        self.base_model = base_model\n        self.pass_collumns = pass_collumns\n        \n    def _get_numeric_columns(self, df):\n        columns = []\n        for column in df.columns:\n            typename = str(df[column].dtype)\n            if typename.startswith('int') or typename.startswith('float') or typename.startswith('bool'):\n                columns.append(column)\n        return columns\n                \n    def _get_pass_collumns(self, X):\n        if self.pass_collumns is not None:\n            pass_collumns = self.pass_collumns\n        else:\n            pass_collumns = self._get_numeric_columns(X)\n        return pass_collumns        \n    \n    def fit(self, X, y):\n        assert isinstance(X, pd.DataFrame)\n        pass_collumns = self._get_pass_collumns(X)\n        y_classes = 1.0 * (y > 0.0)\n        self.base_model.fit(X[pass_collumns], y_classes)\n    \n    def predict(self, X):\n        assert isinstance(X, pd.DataFrame)\n        X = X.copy(deep=False)\n        pass_collumns = self._get_pass_collumns(X)\n        X['confidenceValue'] = 2.0 * self.base_model.predict(X[pass_collumns]) - 1.0\n        X['metric'] = X['returnsOpenNextMktres10'] * X['universe'] * X['confidenceValue']\n        metric = X.groupby('date')['metric'].sum().values\n        return metric\n\n\ndef twosigma_cross_val_score(model, X, y, pass_collumns=None):\n    decorated_model = DailyMetricEstimator(model, pass_collumns)\n    return cross_val_score(decorated_model, X, y, cv=DateSplit(), scoring=make_scorer(metric_aggregation))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8de5671bed02f1aca68caca09525579f79ac3b7"},"cell_type":"markdown","source":"## Pipeline-friendly LabelBinarizer\n\nStandard```scikit-learn```'s ```LabelBinarizer``` gets fit-arguments related exception if you're trying to use it as feature extractor in ```Pipeline```. Here you could see customized class."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"25c60907737bf5692ca1a7749bff467114c37f2c"},"cell_type":"code","source":"class LabelBinarizerPipelineFriendly(LabelBinarizer):\n    def fit(self, X, y=None):\n        \"\"\"this would allow us to fit the model based on the X input.\"\"\"\n        super(LabelBinarizerPipelineFriendly, self).fit(X)\n        \n    def transform(self, X, y=None):\n        return super(LabelBinarizerPipelineFriendly, self).transform(X)\n    \n    def fit_transform(self, X, y=None):\n        return super(LabelBinarizerPipelineFriendly, self).fit(X).transform(X)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a868fbf4c329bda3fd912e5b37afdfe912a38f46"},"cell_type":"markdown","source":"## repeater \"Estimator\"\nI'm using next class to build pipelines like\n```\nPipeline([\n    ('features', FeatureUnion([\n        ('feature1pipeline', Pipeline([\n            ...\n        ]),\n        ('feature2pipeline', Pipeline([\n            ...\n        ]),\n    ])),\n    ('clf', Predictor()),\n])\n```\nwithout it - building of ```feature1pipeline``` and ```feature2pipeline``` will be failed (seems like ```Pipeline``` must have extimator at last stage, not transformer).\nIt could be usefull when we're going to apply different complex pipelines to different features.\nE.g. :\n- encode embeddings for categorical features\n- scale numeric feature"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"482b7cf627a6e20fcd782be216d61991718dce15"},"cell_type":"code","source":"class Repeater(BaseEstimator):\n    def fit(self, *args, **kwargs):\n        return self\n    \n    def predict(self, X, *args, **kwargs):\n        return X\n    \n    def transform(self, X, *args, **kwargs):\n        return X\n    \n    def fit_transform(self, X, *args, **kwargs):\n        return self.fit(X).transform(X)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"042bc7c79d6eaa9daca795aede03805ce971451b"},"cell_type":"markdown","source":"## Building submission\n\nFinally, next function will train model on your dataset and build submission. It's consuming next params:\n\n- model\n- dataframe with features and target (see description below)\n- function that consume market data and news data and return such dataframe\n- list of collumns used by model"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"7fc422b156146877425fa87741970299e527950d"},"cell_type":"code","source":"def make_submission(model, X, extract_features, pass_collumns=None):\n    def get_numeric_columns(df):\n        columns = []\n        for column in df.columns:\n            typename = str(df[column].dtype)\n            if typename.startswith('int') or typename.startswith('float') or typename.startswith('bool'):\n                columns.append(column)\n        return columns\n                \n    if pass_collumns is None:\n        pass_collumns = get_numeric_columns(X)\n    \n    y = 1.0 * (X['returnsOpenNextMktres10'] > 0.0)\n    \n    model.fit(X, y)\n    for market_obs_df, news_obs_df, predictions_template_df in env.get_prediction_days():\n        X_val = extract_features(market_obs_df, news_obs_df)\n        confidence = model.predict(X_val) * 2.0 - 1.0\n        prediction = pd.DataFrame({\n            'assetCode': X_val['assetCode'],\n            'confidenceValue': confidence,\n        })\n        env.predict(prediction)\n    env.write_submission_file()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"644748020f3d3e2a598d1339b0f325fe0e3226ba"},"cell_type":"markdown","source":"# Extracting features\n\nBelow I'll define feature-extraction function (now it'll only use market data) and extract features for train set:"},{"metadata":{"trusted":true,"_uuid":"3cb4fb0f59f91407ef0b7ec3a2723aae52bdf310"},"cell_type":"code","source":"def extract_features(market_df, news_df):\n    market_df['date'] = pd.to_datetime(market_df['time'].dt.date)\n    news_df['date'] = pd.to_datetime(news_df['time'].dt.date)\n    return reduce_mem_usage(market_df)\n\n\ndf = extract_features(*env.get_training_data())\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8b17bf0bd88948057e6e05aff92cbc00fd9b204"},"cell_type":"markdown","source":"# Dummy model\n\nFirstly I'll check DummyClassifier to check cross-validation works:"},{"metadata":{"trusted":true,"_uuid":"74e161a21704585d512e60ea7d405be6ab48e87a"},"cell_type":"code","source":"twosigma_cross_val_score(DummyClassifier(), df, df['returnsOpenNextMktres10'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d745bbf471d8a80311f6f0a2176a11cb3c0f0755"},"cell_type":"markdown","source":"# XGBoost baseline\n\nNext one is baseline with xgboost on market data. Note few things (at least, it was in my case):\n- training isn't fast enough, so maybe you'll need to work next way:\n  - cross-validate model\n  - then if yound score good enought - comment call for cross-validation and save score before commiting your work"},{"metadata":{"trusted":true,"_uuid":"7f5f1bc6fc1f3f9df201cf7a9c058b2376c0ac0e"},"cell_type":"code","source":"market_numeric_features = ['volume', 'close', 'open', 'returnsClosePrevRaw1',\n                           'returnsOpenPrevRaw1', 'returnsClosePrevMktres1',\n                           'returnsOpenPrevMktres1', 'returnsClosePrevRaw10',\n                           'returnsOpenPrevRaw10', 'returnsClosePrevMktres10',\n                           'returnsOpenPrevMktres10']\npass_collumns = market_numeric_features + ['assetCode']\nclf = Pipeline([\n    ('features', FeatureUnion([\n        ('assetCodeEncoder', Pipeline([\n            ('selector', FunctionTransformer(lambda X: X['assetCode'], \n                                             validate=False)),\n            ('label', LabelBinarizerPipelineFriendly(sparse_output=True)),\n            ('t-svd', TruncatedSVD(10)),\n            ('repeater', Repeater()),\n        ])),\n        ('numericFeatures', Pipeline([\n            ('selector', FunctionTransformer(lambda X: X[market_numeric_features], \n                                             validate=False)),\n            ('fillNa', FunctionTransformer(lambda X: X.fillna(0), \n                                           validate=False)),\n            ('scale', StandardScaler()),\n            ('repeater', Repeater()),\n        ]))\n    ])),\n    ('classifier', XGBClassifier(n_estimators=50, tree_kind='hist'))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79020dedd8089de0716b0177ca6d6537ed1d8de6"},"cell_type":"code","source":"twosigma_cross_val_score(clf, df, df['returnsOpenNextMktres10'], pass_collumns=pass_collumns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d59e03855a9d89f725d9224486deb71bc294a8a2"},"cell_type":"markdown","source":"# Building final submission"},{"metadata":{"trusted":true,"_uuid":"2c158d4fc86920c80b1770b27d6dd4bc852abe48"},"cell_type":"code","source":"make_submission(clf, df, extract_features, pass_collumns)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}