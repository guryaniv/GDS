{"cells": [{"metadata": {"_cell_guid": "5aa21b7b-6288-4970-b95f-af76030794b7", "_uuid": "69020ca293aa56504d47c26ecdd86796da9ceb06"}, "source": ["# Summary\n", "1. Introduction\n", "    1. Importing Modules\n", "    1. Defining Score Metric\n", "1. Feature Selection\n", "    1. Data Analysis\n", "    1. Data Manipulation\n", "1. Classification\n", "1. Submission\n", "1. Results\n", "1. The Team"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "07608deb-e5c9-4652-85cf-688b31423371", "_uuid": "02327fc3581ab98149854769b68b465e75e04e97"}, "source": ["# 1. Introduction\n", "\n", "This is a complete notebook on how to develop a working solution for [Porto Seguro](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction) competition. It is based on self highlights, as well as highlights from other kernels. The goal is to provide an beginner friendly Kernel with exploratory and visual considerations about why the good kernels do what they do on the data."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "7652f966-8950-4ffe-90b5-fdb2be260fd6", "_uuid": "5f18b846d7d2504b493f9eac87e440dc12836094"}, "source": ["## 1.A. Importing Modules"], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "a8665e9a-1488-4f15-ba0c-ca55a30cd13a", "_uuid": "0a6d65608e54b23724015d8e775a6d5855ebf2c2"}, "execution_count": null, "outputs": [], "source": ["# data mining\n", "import numpy as np\n", "import pandas as pd\n", "\n", "# data visualization\n", "import seaborn as sns\n", "import missingno as msno\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "# machine learning\n", "from lightgbm import LGBMClassifier\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.model_selection import cross_val_score\n", "\n", "from subprocess import check_output \n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"], "cell_type": "code"}, {"metadata": {"_cell_guid": "5b8894dd-fff6-4e48-a01e-67d5c2749cf5", "_uuid": "6b4743256bd3825d466930fb22652193268e90be"}, "source": ["## 1.B. Defining Score Metric\n", "This competition will be using the Normalized Gini Coeficient to calculate our predictions score. A better understanding of this metric can be obtained [here](https://www.kaggle.com/batzner/gini-coefficient-an-intuitive-explanation)."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "40bcc83b-f261-4bce-ae4f-7823f62b824e", "_uuid": "27f07943df1b4d8230f928604fc42a99da88b000"}, "execution_count": null, "outputs": [], "source": ["def gini(actual, pred):\n", "    assert (len(actual) == len(pred))\n", "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n", "    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n", "    totalLosses = all[:, 0].sum()\n", "    giniSum = all[:, 0].cumsum().sum() / totalLosses\n", "\n", "    giniSum -= (len(actual) + 1) / 2.\n", "    return giniSum / len(actual)\n", "\n", "\n", "def gini_normalized(actual, pred):\n", "    return gini(actual, pred) / gini(actual, actual)\n", "\n", "def gini_xgb(preds, dtrain):\n", "    labels = dtrain.get_label()\n", "    gini_score = gini_normalized(labels, preds)\n", "    return 'gini', gini_score"], "cell_type": "code"}, {"metadata": {"_cell_guid": "15a982b1-c87c-465f-968b-573ca0288f9e", "_uuid": "4db81867a9ada907e123fb9b3d6fb495993af3fb"}, "source": ["# 2. Feature Selection"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "361bc350-4045-422a-99ac-6c032ef52235", "_uuid": "f2c5899b0edc9cfc5bc071ecf34bc654812e006e"}, "source": ["## 2.A. Data Analysis\n", "A summary of the data analysis discoveries shows us that the dataset is highly unbalanced, there are many missing value and some columns have no correlation with target and should be dropped."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "db38b047-6d01-4087-a97f-9fadd28906cb", "_uuid": "8c29036523f31daf3f58f49bdef37425d4586b73"}, "source": ["### Importing Data"], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "4e1d6d5b-0310-495b-9b12-19917801b1be", "_uuid": "04873de5ab3c260a3a2a351273f2411bfed05a35"}, "execution_count": null, "outputs": [], "source": ["df = pd.read_csv('../input/train.csv', na_values='-1')\n", "test_df = pd.read_csv('../input/test.csv', na_values='-1')\n", "df.head()"], "cell_type": "code"}, {"metadata": {"_cell_guid": "5d5f1554-72e2-407e-9c69-eec72e1d91f4", "_uuid": "08a24b21bdf30c4ed370be866ee458480d036d0d"}, "source": ["### Class\n", "The data is splited in two classes. Unluckily, the huge majority of the samples belongs to the same class. Actually, only 3.64% belong to the other, characterizing the dataset as highly unbalanced. The bias is expected to predict 0 all times. Techniques to deal with unbalanced training set should be used.\n"], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "4993549c-349b-44d2-80ff-9f385404b29b", "_uuid": "9ba5d5d94104f981974cf665249a4b338a8f77b0", "scrolled": false}, "execution_count": null, "outputs": [], "source": ["entries = df.shape[0]\n", "plot = sns.countplot(x='target', data=df)\n", "for p in plot.patches:\n", "    plot.annotate('{:.2f}%'.format(100*p.get_height()/entries), (p.get_x()+ 0.3, p.get_height()+10000))"], "cell_type": "code"}, {"metadata": {"_cell_guid": "a35af9f3-9a7e-4000-b5cd-d728d839fb29", "_uuid": "9b8b53a44ba03a8b9b8a7017ddc4e6f085f16f6b"}, "source": ["### Null values\n", "We then search the dataset for missing entries in the samples. A quick analysis shows that many columns have multiple missing values, requiring our attention. We should proceed then either filling this values with reasonably values, or deleting the feature from our dataset. Feature analysis is then required."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "a5d0174c-3e61-4661-b4c2-7a2134b12aac", "_uuid": "d6f98f835570513673c7cf0b8509de7f95759ec5"}, "execution_count": null, "outputs": [], "source": ["msno.matrix(df=df.iloc[:, :], figsize=(20, 14), color=(0.8, 0.5, 0.2))   "], "cell_type": "code"}, {"metadata": {"collapsed": true, "_cell_guid": "3a95fbfe-d20e-4c2e-812b-1f78cebd2cba", "_uuid": "c6346cb683520b680441e9a597e44dcf229c7842"}, "execution_count": null, "outputs": [], "source": ["print('Column \\t\\t Number of Null')\n", "for column in df.columns:\n", "    print('{}:\\t {} ({:.2f}%)'.format(column,len(df[column][np.isnan(df[column])]), 100*len(df[column][np.isnan(df[column])])/entries))"], "cell_type": "code"}, {"metadata": {"_cell_guid": "3108fc0e-48bc-475c-b63c-3212c9a107bc", "_uuid": "fb9df497cc092dfcd04c2ef9740f4e2ff3dd4fc7"}, "source": ["### Correlation Matrix\n", "\n", "The correlation between pairs of features shows that there is no correlation at all between *ps_calc_etc* features and the *target* or any other features. So dropping them would prevent the curse of dimensionality."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "05967c4b-7b84-4348-bbb8-7644e73167b2", "_uuid": "e2538bf82816a196eafe587f21f0a3edc72ac297"}, "execution_count": null, "outputs": [], "source": ["corr = df.corr()\n", "f, ax = plt.subplots(figsize=(11, 9))\n", "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n", "sns.heatmap(corr, cmap=cmap, vmax=.3, center=0,\n", "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n", "\n", "plt.show()"], "cell_type": "code"}, {"metadata": {"_cell_guid": "14c25fc5-21e4-42f0-82e7-e291b6975a5a", "_uuid": "7c4561823207f5a80fcdc55ddd93f3cde1fedcd7"}, "source": ["## 2.B. Data Manipulation\n", "Based on the data analysis step, we are going to remove the *ps_calc_etc* features, and convert categorial features to dummy columns."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "9e1a4340-73bb-4733-a223-0fa4ed55e062", "_uuid": "bba8e27588e7f20df3762fffd0931d95be1aa9af"}, "source": ["### Removing Features\n", "Since *ps_calc_etc* features aren't related to *target*, removing them can prevent random junk to affect our model, and improving training and classifications times."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "18a9a1b5-fc5a-49bb-bec3-7b9e4b87d0c4", "_uuid": "666675e522ffda0b03aab6e3287ba633a9475a72", "_kg_hide-output": true}, "execution_count": null, "outputs": [], "source": ["unwanted = df.columns[df.columns.str.startswith('ps_calc_')]\n", "df = df.drop(unwanted, axis=1)\n", "test_df = test_df.drop(unwanted, axis=1)\n", "df.head()"], "cell_type": "code"}, {"metadata": {"_cell_guid": "d207fb45-5093-432b-9300-5d0657fbebb5", "_uuid": "a99032c10be6c3b5f8e681856b108562dc37f827"}, "source": ["### Changing Categorical Features to Dummy Values\n", "Why do we need to convert categorical features to dummy values? Let's call your variable X and assume it takes on values \"1\", \"2\", \"3\", \"4\" or \"5\". If you feed X into the model as numbers, the model will estimate only a single parameter, which is the effect on the target variable of increasing X by 1 unit. So if you hold everything else constant and increase X from 1 to 2, that affects the target variable the same way as increasing it from 2 to 3 or from 4 to 5.\n", "\n", "If instead you model X as categorical, you will estimate 4 parameters: the effect of increasing X from 1 to 2, from 2 to 3, and so on. These values could all be different. And that's what we really want to extract from categorical variables from the very beggining: the weight of each category."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "9c109eba-e7a8-4a15-8516-32e6fa9952f3", "_uuid": "2ae6fe4c8d83993500c203252835b1af48a714e5"}, "execution_count": null, "outputs": [], "source": ["cat_columns = [a for a in df.columns if a.endswith('cat')]\n", "\n", "for col in cat_columns:\n", "\tdummy = pd.get_dummies(pd.Series(df[col]))\n", "\tdf = pd.concat([df,dummy],axis=1)\n", "\tdf = df.drop([col],axis=1)\n", "    \n", "for col in cat_columns:\n", "\tdummy = pd.get_dummies(pd.Series(test_df[col]))\n", "\ttest_df = pd.concat([test_df,dummy],axis=1)\n", "\ttest_df = test_df.drop([col],axis=1)\n", "    \n", "df.head()\n"], "cell_type": "code"}, {"metadata": {"_cell_guid": "7884c731-5bf2-40fd-9580-5ac8ec12b5ac", "_uuid": "43a7aad47bc22e668c921d0e03486c1f03fd5f59"}, "source": ["# 3. Classification\n", "Since we have a unbalanced training set, we are going to use Classifier Ensemble methods to predict a better output, united with a StratifieldKFold strategy to train each base model with multiple balanced training sets."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "0ad34feb-e7e8-4793-8007-ddaa455644ca", "_uuid": "8af9cccd2d6b5c436c6dca0bb3b47278b4d9f06b"}, "source": ["### Ensemble Class Creation"], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "2c568091-13ce-45f2-a8c7-0f477ee4685c", "_uuid": "906948d6e1012e64eacb69f4782cc9af203540ba"}, "execution_count": null, "outputs": [], "source": ["class Ensemble(object):\n", "    def __init__(self, kfold, stacker, models):\n", "        self.kfold = kfold\n", "        self.stacker = stacker\n", "        self.models = models\n", "\n", "    def fit_predict(self, x, y, test):\n", "        x = np.array(x)\n", "        y = np.array(y)\n", "        t = np.array(test)\n", "        \n", "        train = np.zeros((x.shape[0], len(self.models)))\n", "        test = np.zeros((t.shape[0], len(self.models)))\n", "        \n", "        skf = list(StratifiedKFold(n_splits=self.kfold, shuffle=True, random_state=2016).split(x, y))\n", "        \n", "        for i, model in enumerate(self.models):\n", "\n", "            test_i = np.zeros((t.shape[0], self.kfold))\n", "\n", "            for j, (train_idx, test_idx) in enumerate(skf):\n", "                x_train = x[train_idx]\n", "                y_train = y[train_idx]\n", "                x_valid = x[test_idx]\n", "                y_valid = y[test_idx]\n", "\n", "                print (\"Fit %s fold %d\" % (str(model).split('(')[0], j+1))\n", "                \n", "                model.fit(x_train, y_train)\n", "                y_train_pred = model.predict_proba(x_train)[:,1]\n", "                y_pred = model.predict_proba(x_valid)[:,1]   \n", "                \n", "                print(\"[Train] Gini score: %.6lf\" % gini_normalized(y_train, y_train_pred))\n", "                print(\"[Test] Gini score: %.6lf\\n\" % gini_normalized(y_valid, y_pred))\n", "\n", "                train[test_idx, i] = y_pred\n", "                test_i[:, j] = model.predict_proba(t)[:,1]\n", "            test[:, i] = test_i.mean(axis=1)\n", "\n", "        self.stacker.fit(train, y)\n", "        valid = self.stacker.predict_proba(train)[:,1]\n", "        res = self.stacker.predict_proba(test)[:,1]\n", "        print(\"Staker Gini Score: %.6lf\" % gini_normalized(valid, y))\n", "        return res"], "cell_type": "code"}, {"metadata": {"_cell_guid": "f0f906a8-1bdc-452f-b076-7412dc60170a", "_uuid": "16804b0c66d4d2d16e61e21f370461678c1273d6"}, "source": ["### Preparing Data for Training/Predict"], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "972568ac-b06c-4372-9e24-cf920d48f955", "_uuid": "aaef7b52679c52837e5b829ffe4162bce05002e0"}, "execution_count": null, "outputs": [], "source": ["x = df.drop(['id', 'target'], axis=1)\n", "y = df['target'].values\n", "test_id = test_df['id']\n", "test_df = test_df.drop('id', axis=1)"], "cell_type": "code"}, {"metadata": {"_cell_guid": "4ea1f9ef-29d8-4a25-b7ff-659a564bd650", "_uuid": "f778025e8896192dc866005177fdfae1e2154397"}, "source": ["### Defining Base Models for Ensemble\n", "Those are some dummy parameters for creating models. Real parameters are in grey. In order to run with the real parameters, you need to run the code locally on your machine, because Kaggle Kernels timeout after 1 hour training."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "02a0ea8d-ca03-48b4-b5cd-bc2feb7de554", "_uuid": "5a98be4822e54da61de9c2724d3f823d667d31be"}, "execution_count": null, "outputs": [], "source": ["lgb_params = {\n", "    'learning_rate': 0.02,\n", "    'n_estimators': 1, # use 650 for real model\n", "    'max_bin': 10,\n", "    'subsample': 0.8,\n", "    'subsample_freq': 10,\n", "    'colsample_bytree': 0.8,\n", "    'min_child_samples': 500,\n", "    'random_state': 99\n", "}\n", "\n", "lgb_model = LGBMClassifier(**lgb_params)\n", "\n", "lgb2_params = {\n", "    'learning_rate': 0.02,\n", "    'n_estimators': 1, #use 1090 for real model\n", "    'colsample_bytree': 0.3,\n", "    'subsample': 0.7,\n", "    'subsample_freq': 2,\n", "    'num_leaves': 16,\n", "    'random_state': 99\n", "}\n", "\n", "lgb_model2 = LGBMClassifier(**lgb2_params)\n", "\n", "lgb3_params = {\n", "    'n_estimators': 1, #use 1100 for real model\n", "    'max_depth': 4,\n", "    'learning_rate': 0.02,\n", "    'random_state': 99\n", "}\n", "\n", "lgb_model3 = LGBMClassifier(**lgb3_params)\n", "\n", "log_model = LogisticRegression()"], "cell_type": "code"}, {"metadata": {"_cell_guid": "64857a61-048c-44c7-94ca-38ff9d887525", "_uuid": "2452b47821fe80e90b92f6638a0b3e0f37752453"}, "source": ["### Fit/Prediction\n", "Gini score is calculated for each model of the Ensemble, as well as for the final combined classifier."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "b227d20f-1f59-4819-8317-73ca37df7219", "_uuid": "1dfac60f16cb0460ec58fbf731074cc9eab63c27"}, "execution_count": null, "outputs": [], "source": ["stack = Ensemble(kfold=3,\n", "        stacker = log_model,\n", "        models = (lgb_model, lgb_model2, lgb_model3))        \n", "        \n", "y_pred = stack.fit_predict(x, y, test_df)"], "cell_type": "code"}, {"metadata": {"_cell_guid": "4ec9dfc7-9e9e-4490-baf5-2d2531458052", "_uuid": "63af425b4d888af38ce0f8954d72837efa05ce0a"}, "source": ["# 4. Submission\n", "This output is just a dummy. In orther to get the real output, you must use the right parameters for the models and run the code locally on your machine."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "392c7fe1-2f74-4502-9a7c-2a84b3fe0739", "_uuid": "f070d17bb04b8e29bb6245bddce99fc9f939e081"}, "execution_count": null, "outputs": [], "source": ["sub = pd.DataFrame()\n", "sub['id'] = test_id\n", "sub['target'] = y_pred\n", "sub.to_csv('output.csv', index=False)"], "cell_type": "code"}, {"metadata": {}, "source": ["# 5. Results\n", "\n", "For this approach, we managed to score 0.28960 at the leaderboards. The top submission scored 0.29698. That's pretty close, but, still, we are at the 1260/5169 position on the leaderboard. That's because in this competition the tiniest improvement would make you jump hundreds of positions up. Those positions were last updated at December 5th, 2017."], "cell_type": "markdown"}, {"metadata": {}, "source": ["# The Team\n", "\n", "Our team's name on the leaderboard is \"Disc\u00edpulos de Cleber\". We are three students of the Federal University of Pernambuco:\n", "* Higor Cavalcanti\n", "* Lav\u00ednia Francesca\n", "* Jo\u00e3o Vasconcelos"], "cell_type": "markdown"}], "metadata": {"language_info": {"mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "version": "3.6.3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat_minor": 1, "nbformat": 4}