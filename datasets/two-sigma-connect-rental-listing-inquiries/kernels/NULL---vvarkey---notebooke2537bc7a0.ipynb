{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6137345b-0759-7fc3-9295-a52c12d14ed6"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import scipy\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "df=pd.read_json(\"../input/train.json\")\n",
        "df['priceperbed']=(df['price'].clip(upper=7000)/df['bedrooms'].clip(lower=1))\n",
        "df['created']=df['created'].astype(np.datetime64)\n",
        "df['created_day']=np.array(df.created.values, dtype='datetime64[D]').astype(np.float32)%7\n",
        "df['created_week']=np.array(df.created.values, dtype='datetime64[W]').astype(np.float32)\n",
        "df['created_hour']=np.array(df.created.values, dtype='datetime64[h]').astype(np.float32)%24\n",
        "df['desc_count']=df.description.apply(lambda x: len(x.split())).clip(upper=150)\n",
        "df['features_count']=df.features.apply(lambda x: len(x))\n",
        "df['photos_count']=df.photos.apply(lambda x: len(x))\n",
        "\n",
        "categorical = [\"display_address\", \"building_id\", \"street_address\"]\n",
        "for f in categorical:\n",
        "        if df[f].dtype=='object':\n",
        "            lbl = preprocessing.LabelEncoder()\n",
        "            lbl.fit(list(df[f].values) + list(df[f].values))\n",
        "            df[f] = lbl.transform(list(df[f].values))\n",
        "            \n",
        "lbl = preprocessing.LabelEncoder()\n",
        "lbl.fit(list(df['manager_id'].values))\n",
        "df['manager_id'] = lbl.transform(list(df['manager_id'].values))\n",
        "\n",
        "feature_list=['no fee', 'hardwood floors', 'laundry in building']\n",
        "df['features']=df['features'].apply(lambda x: list(map(str.lower, x)))\n",
        "for feature in feature_list:\n",
        "        df[feature]=df['features'].apply(lambda x: feature in x)\n",
        "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
        "                                 stop_words='english')\n",
        "vectorizer.fit(df.description.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dbffc094-d676-a861-0999-a9279875a7dd"
      },
      "outputs": [],
      "source": [
        "df_tv, df_test = train_test_split(df, random_state=0)\n",
        "df_train, df_val = train_test_split(df_tv, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a00b3cf5-34c1-3a32-0b39-697c52f62a15"
      },
      "outputs": [],
      "source": [
        "temp = pd.concat([df_train.manager_id,pd.get_dummies(df_train.interest_level)], axis = 1\n",
        "                ).groupby('manager_id').mean()\n",
        "temp.columns = ['high_frac','low_frac', 'medium_frac']\n",
        "temp['count'] = df_train.groupby('manager_id').count().iloc[:,1]\n",
        "\n",
        "temp['manager_skill'] = temp['high_frac']*2 + temp['medium_frac']\n",
        "unranked_managers_ixes = temp['count']<20\n",
        "ranked_managers_ixes = ~unranked_managers_ixes\n",
        "mean_values = temp.loc[ranked_managers_ixes, [\n",
        "    'high_frac','low_frac', 'medium_frac','manager_skill']].mean()\n",
        "temp.loc[unranked_managers_ixes,['high_frac','low_frac', 'medium_frac','manager_skill']] = mean_values.values\n",
        "\n",
        "df_train = df_train.merge(temp.reset_index(),how='left', on='manager_id')\n",
        "df_val = df_val.merge(temp.reset_index(),how='left', on='manager_id')\n",
        "new_manager_ixes = df_val['high_frac'].isnull()\n",
        "df_val.loc[new_manager_ixes,['high_frac','low_frac', 'medium_frac','manager_skill'\n",
        "                            ]] = mean_values.values\n",
        "df_test = df_test.merge(temp.reset_index(),how='left', on='manager_id')\n",
        "new_manager_ixes = df_test['high_frac'].isnull()\n",
        "df_test.loc[new_manager_ixes,['high_frac','low_frac', 'medium_frac','manager_skill'\n",
        "                            ]] = mean_values.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "311b3c0a-300d-3d92-70e8-3bcd58081a59"
      },
      "outputs": [],
      "source": [
        "derived_cols = ['derived_'+str(i) for i in range(5)]\n",
        "cols=['price', 'bathrooms', 'bedrooms', 'latitude', 'longitude', 'priceperbed','created_hour', \n",
        "      'desc_count', 'photos_count', 'features_count', 'no fee', 'hardwood floors', \n",
        "      'laundry in building', 'manager_skill', 'listing_id']+categorical\n",
        "\n",
        "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
        "X_train = svd.fit_transform(vectorizer.transform(df_train.description))\n",
        "X_train=np.hstack([X_train, df_train[cols].values])\n",
        "X_val = svd.transform(vectorizer.transform(df_val.description))\n",
        "X_val=np.hstack([X_val, df_val[cols].values])\n",
        "X_test = svd.transform(vectorizer.transform(df_test.description))\n",
        "X_test=np.hstack([X_test, df_test[cols].values])\n",
        "target_num_map = {'high':0, 'low':1, 'medium':2}\n",
        "y_train = np.array(df_train['interest_level'].apply(lambda x: target_num_map[x]))\n",
        "y_test = np.array(df_test['interest_level'].apply(lambda x: target_num_map[x]))\n",
        "y_val = np.array(df_val['interest_level'].apply(lambda x: target_num_map[x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "72c46273-7910-ce7e-f3c5-1dda605b84ae"
      },
      "outputs": [],
      "source": [
        "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
        "xgval = xgb.DMatrix(X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f8625ec2-c4ea-6d3b-20d7-76285c2cb1f7"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "SEED = 0\n",
        "\n",
        "params = {\n",
        "    'eta':.15,\n",
        "    'max_depth':6,\n",
        "    'min_child_weight':3,\n",
        "    'colsample_bytree':.8,\n",
        "    'subsample':.8,\n",
        "    'seed':0,\n",
        "    'nthread':16,\n",
        "    'objective':'multi:softprob',\n",
        "    'eval_metric':'mlogloss',\n",
        "    'num_class':3,\n",
        "    'silent':1\n",
        "}\n",
        "\n",
        "bst = xgb.train(params, dtrain, 130, verbose_eval=25)\n",
        "y_pred = bst.predict(dtrain)\n",
        "score=log_loss(df_train['interest_level'].values, y_pred)\n",
        "print(score)\n",
        "y_pred = bst.predict(xgval)\n",
        "score=log_loss(df_val['interest_level'].values, y_pred)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1c12dd77-142b-d5c0-2d98-81af92b4c9e9"
      },
      "outputs": [],
      "source": [
        "#pd.Series(index = derived_cols + cols, data = clf.feature_importances_).sort_values().plot(\n",
        "#    kind = 'bar')"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}