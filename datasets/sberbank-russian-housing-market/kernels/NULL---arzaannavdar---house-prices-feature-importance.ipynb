{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3fc29d38-ee48-fee4-73a7-4b7b59a907ab"
      },
      "source": [
        "Trying to identify the top features to utilize in the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "59a554a6-70f9-80d6-f6b3-ba42bcfaa3fb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn.preprocessing as pre\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8165076e-a8fa-8332-9641-e2a17fc15448"
      },
      "outputs": [],
      "source": [
        "#Read data into the training set\n",
        "train_data = pd.read_csv(\"../input/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1a17aae0-fead-8417-899b-7c1e1dd498d1"
      },
      "outputs": [],
      "source": [
        "#Trying to identify NaN values in the variables\n",
        "total = train_data.isnull().sum().sort_values(ascending = False)\n",
        "percent = (train_data.isnull().sum()/train_data.isnull().count()).sort_values(ascending = False)\n",
        "missing_data = pd.concat([total,percent],axis=1,keys = [\"Total\",\"Percentage\"])\n",
        "print(missing_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "399f643c-bf52-8967-0975-4e290a6c3dcb"
      },
      "outputs": [],
      "source": [
        "#Delete all NaN values for now\n",
        "train_data = train_data.drop(missing_data[missing_data[\"Total\"]>0].index,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "529d74b7-7fb6-e994-6a09-943c8317c1c7"
      },
      "outputs": [],
      "source": [
        "#Identify top features using a basic XGBoost\n",
        "# I'd like to thank this from \n",
        "#https://www.kaggle.com/sudalairajkumar/sberbank-russian-housing-market/simple-exploration-notebook-sberbank\n",
        "#It helped me to understand a simple way to build my feature importance\n",
        "for f in train_data:\n",
        "    if train_data[f].dtype == \"object\":\n",
        "        lbl=pre.LabelEncoder()\n",
        "        lbl.fit(list(train_data[f].values))\n",
        "        train_data[f]=lbl.transform(list(train_data[f].values))\n",
        "\n",
        "xgb_params = {\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 8,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'objective': 'reg:linear',\n",
        "    'eval_metric': 'rmse',\n",
        "    'silent': 1\n",
        "}\n",
        "\n",
        "y_train = train_data[\"price_doc\"]\n",
        "x_train = train_data.drop([\"id\",\"timestamp\",\"price_doc\"],axis = 1)\n",
        "dtrain = xgb.DMatrix(x_train,y_train,feature_names = x_train.columns.values)\n",
        "model = xgb.train(dict(xgb_params,silent=0),dtrain,num_boost_round=100)\n",
        "\n",
        "fig,ax=plt.subplots(figsize = (12,18))\n",
        "xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "eb95448d-5f64-3648-46d6-dbd3f12beefd"
      },
      "source": [
        "The top 10 variables impacting the target are as follows:\n",
        "\n",
        " 1. full_sq(2023)\n",
        " 2. metro_min_avto(344)\n",
        " 3. sub_area(332)\n",
        " 4. kindergarten_km(294)\n",
        " 5. green_zone_km(224)\n",
        " 6. school_km(221)\n",
        " 7. metro_km_avto(213)\n",
        " 8. park_km(206)\n",
        " 9. industrial_km(197)\n",
        " 10. area_m(195)\n",
        "\n",
        "Out of these, area_m seems similar to full_sq and metro_min_avto seems similar to metro_km_avto. So I am removing these from my analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bb1c15ce-a996-3907-8595-5e1640f3cf6f"
      },
      "outputs": [],
      "source": [
        "#Change the Price values to log functions\n",
        "cols = [\"price_doc\",\"full_sq\",\"metro_min_avto\",\"sub_area\",\"kindergarten_km\",\"green_zone_km\",\"school_km\",\"park_km\",\"industrial_km\"]\n",
        "train_data[\"price_doc\"]= np.log(train_data[\"price_doc\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a768970e-28dd-57ef-eb4b-dc1a9eae2e5d"
      },
      "outputs": [],
      "source": [
        "#Check the plots with each of the variables\n",
        "corrmat = train_data.corr()\n",
        "sns.pairplot(train_data[cols],size = 2.5)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}