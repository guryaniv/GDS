{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"### An example using both an attention layer and a capsule layer in a GRU network for insincere text classification\n\n##### **Acknowledgements**:\n* [ Shujian Liu](https://www.kaggle.com/shujian)\n* [SRK](https://www.kaggle.com/sudalairajkumar/),\n* [Dieter](https://www.kaggle.com/christofhenkel) \n* [Khoi Nguyen ](https://www.kaggle.com/suicaokhoailang)\n* [Shujian Liu](https://www.kaggle.com/shujian/single-rnn-with-4-folds-clr)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport os\nimport time\nimport numpy as np \nimport pandas as pd\nimport gc\nimport tensorflow as tf\nimport pickle\nimport glob\nimport itertools\n\nnp.random.seed(7418880)\ntf.set_random_seed(7418880)\nfrom collections import defaultdict\n\nfrom sklearn import metrics\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import  StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.engine.topology import Layer\nfrom keras.callbacks import *\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.initializers import *\nfrom keras.optimizers import *\nimport keras.backend as K\nimport tensorflow as tf\nimport os\nimport time\nimport gc\nimport re\nfrom unidecode import unidecode\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3717771058b8623e78f0ee17b0ee6ac213a91d4"},"cell_type":"code","source":"embedding_path_dict= {'googlenews':{\n                            'path':'../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin',\n                            'format':'word2vec',\n                            'binary': True\n                      },\n                      'glove':{\n                            'path':'../input/embeddings/glove.840B.300d/glove.840B.300d.txt',\n                            'format': 'glove',\n                            'binary': ''\n                      },\n                      'glove_word2vec':{\n                            'path':'../input/glove.840B.300d.txt.word2vec',\n                            'format': 'word2vec',\n                            'binary': False\n                      },\n                      'wiki':{\n                            'path': '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec',\n                            'format': 'word2vec',\n                            'binary': False\n                      },\n                      'paragram':{\n                            'path': '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt',\n                            'format': '',\n                            'binary': False\n                      }\n                    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6124ebcb1afa95b00cb704f8123b8996cea9159"},"cell_type":"code","source":"#https://www.kaggle.com/danbrice/keras-plot-history-full-report-and-grid-search\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        title='Normalized confusion matrix'\n    else:\n        title='Confusion matrix'\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n    \n## multiclass or binary report\n## If binary (sigmoid output), set binary parameter to True\ndef full_multiclass_report(model,\n                           x,\n                           y_true,\n                           classes,\n                           batch_size=32,\n                           binary=False):\n\n    # 1. Transform one-hot encoded y_true into their class number\n    if not binary:\n        y_true = np.argmax(y_true,axis=1)\n    \n    # 2. Predict classes and stores in y_pred\n    y_pred = model.predict_classes(x, batch_size=batch_size)\n    \n    # 3. Print accuracy score\n    print(\"Accuracy : \"+ str(accuracy_score(y_true,y_pred)))\n    \n    print(\"\")\n    \n    # 4. Print classification report\n    print(\"Classification Report\")\n    print(classification_report(y_true,y_pred,digits=5))    \n    \n    # 5. Plot confusion matrix\n    cnf_matrix = confusion_matrix(y_true,y_pred)\n    print(cnf_matrix)\n    plot_confusion_matrix(cnf_matrix,classes=classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79d3cd283869e6b609f0bc385d2127755d27b576"},"cell_type":"code","source":"# Get word embeddings\ndef get_embeddings(embedding_path_dict, emb_name):\n    \"\"\"\n    :params embedding_path_dict: a dictionary containing the path, binary flag, and format of the desired embedding,\n            emb_name: the name of the embedding to retrieve\n    :return embedding index: a dictionary containing the embeddings\"\"\"\n    \n    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n    \n    if (emb_name == 'googlenews'):\n        emb_path = embedding_path_dict[emb_name]['path']\n        bin_flag = embedding_path_dict[emb_name]['binary']\n        embeddings_index = kv.load_word2vec_format(emb_path, binary=bin_flag).vectors\n    elif (emb_name in ['glove', 'wiki']):\n        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path_dict[emb_name]['path']) if len(o)>100)    \n    elif (emb_name == 'paragram'):\n        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path_dict[emb_name]['path'], encoding=\"utf8\", errors='ignore'))\n    return embeddings_index\n\n#Convert GLoVe format into word2vec format\ndef glove_to_word2vec(embedding_path_dict, emb_name='glove', output_emb='glove_word2vec'):\n    \"\"\"\n    Convert the GLOVE embedding format to a word2vec format\n    :params embedding_path_dict: a dictionary containing the path, binary flag, and format of the desired embedding,\n            glove_path: the name of the GLOVE embedding\n            output_file_path: the name of the converted embedding in embedding_path_dict. \n    :return output from the glove2word2vec script\n    \"\"\"\n    glove_input_file = embedding_path_dict[emb_name]['path']\n    word2vec_output_file = embedding_path_dict[output_emb]['path']                \n    return glove2word2vec(glove_input_file, word2vec_output_file)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1dd6cd665c9bd8a9968493f1e4499b7cf7ede4e2"},"cell_type":"markdown","source":"Let us load the train and test sets. Set max_words to be 50000 and max_len to be 70 "},{"metadata":{"trusted":true,"_uuid":"8b9a0c9a08f4e0d9c7bb5526480ad9356fbef643"},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\nprint(\"Train shape : \", train_df.shape)\nprint(\"Test_shape : \", test_df.shape)\n\ntrain_X = train_df[\"question_text\"].fillna(\"_na_\").values\ntrain_y = train_df['target'].values\ntest_X = test_df[\"question_text\"].fillna(\"_na_\").values\n\ndel train_df\nimport gc\ngc.collect()\n\nembed_size = 300\nmax_words = 60000 # number of unique words\nmax_len = 70\nneg_perc = 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"533dee01d10b09322ec8ba5b76a4ee348893016b"},"cell_type":"code","source":"train_X[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ab2cfa1c59acdc117881bb3e17d9e48c3883d94"},"cell_type":"markdown","source":"Tokenize the sentences"},{"metadata":{"trusted":true,"_uuid":"a9773cd344bc1945b1b0fa6db98bbeb4d4c48df1"},"cell_type":"code","source":"start_time = time.time()\n\ntokenizer = Tokenizer(num_words=max_words,lower=True)\ntokenizer.fit_on_texts(list(train_X))\ntrain_X=tokenizer.texts_to_sequences(train_X)\ntest_X=tokenizer.texts_to_sequences(test_X)\n\ntrain_X = pad_sequences(train_X, maxlen=max_len)\ntest_X = pad_sequences(test_X, maxlen=max_len)\n\nprint (train_X.shape, test_X.shape)\nprint(\"Total time for tokenizing = {:.0f} s\".format(time.time()-start_time))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67d1223852ef53a808318d6fdce6a68460b827c2"},"cell_type":"markdown","source":"Tokenizing takes about 65 s on average in my experience. Interesting to know these numbers since we have a 7200 s time limit for these competitiom"},{"metadata":{"trusted":true,"_uuid":"60c4978eed01a4f59c742176bb68cdefe3b56a8c"},"cell_type":"code","source":"def add_embed_to_matrix(embed_list, word_index, nb_words):\n    \n    #get embedding\n    embeddings_index={}\n    embedding_matrix = None\n    for embedding_name in embed_list:\n        embeddings_index[embedding_name]= get_embeddings(embedding_path_dict, embedding_name)\n        import gc; gc.collect()\n    \n        all_embs = np.stack(embeddings_index[embedding_name].values())\n        emb_mean,emb_std = all_embs.mean(), all_embs.std()\n        embed_size = all_embs.shape[1]\n        if (embedding_matrix is None):\n            embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n        else:\n            embedding_matrix += np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n\n    for word, i in word_index.items():\n        if i >= nb_words: continue\n        for embedding_name in embed_list:\n            embedding_vector = embeddings_index[embedding_name].get(word)\n            if (embedding_vector is not None):\n                embedding_matrix[i] = embedding_vector\n    \n    del embeddings_index\n    \n    return embedding_matrix\n        \nstart_time = time.time()\n\nword_index = tokenizer.word_index\nnb_words = min(max_words, len(word_index))\nembedding_matrix = None\n\nembeddings_list=['glove','wiki']\nembedding_matrix = add_embed_to_matrix(embeddings_list, word_index, nb_words)\nembedding_matrix = embedding_matrix/len(embeddings_list)\n        \nprint(\"Total time for embedding = {:.0f} s\".format(time.time()-start_time))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"006b59ed9e4208a61d47399baec3eec7707e3b76"},"cell_type":"markdown","source":"Let us define the model now. Nothing fancy. A GRU/LSTM bilayer concated with a LSTM/GRU layer (don't ask me why) with a few pooling, dense and dropout layers thrown in to the mix. Based on SRK's kernel."},{"metadata":{"trusted":true,"_uuid":"2ef45159496454764f80d077ab2964fee9bb098f"},"cell_type":"code","source":"def squash(x, axis=-1):\n    # s_squared_norm is really small\n    # s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n    # scale = K.sqrt(s_squared_norm)/ (0.5 + s_squared_norm)\n    # return scale * x\n    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n    scale = K.sqrt(s_squared_norm + K.epsilon())\n    return x / scale\n\n# A Capsule Implement with Pure Keras\nclass Capsule(Layer):\n    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n                 activation='default', **kwargs):\n        super(Capsule, self).__init__(**kwargs)\n        self.num_capsule = num_capsule\n        self.dim_capsule = dim_capsule\n        self.routings = routings\n        self.kernel_size = kernel_size\n        self.share_weights = share_weights\n        if activation == 'default':\n            self.activation = squash\n        else:\n            self.activation = Activation(activation)\n\n    def build(self, input_shape):\n        super(Capsule, self).build(input_shape)\n        input_dim_capsule = input_shape[-1]\n        if self.share_weights:\n            self.W = self.add_weight(name='capsule_kernel',\n                                     shape=(1, input_dim_capsule,\n                                            self.num_capsule * self.dim_capsule),\n                                     # shape=self.kernel_size,\n                                     initializer='glorot_uniform',\n                                     trainable=True)\n        else:\n            input_num_capsule = input_shape[-2]\n            self.W = self.add_weight(name='capsule_kernel',\n                                     shape=(input_num_capsule,\n                                            input_dim_capsule,\n                                            self.num_capsule * self.dim_capsule),\n                                     initializer='glorot_uniform',\n                                     trainable=True)\n\n    def call(self, u_vecs):\n        if self.share_weights:\n            u_hat_vecs = K.conv1d(u_vecs, self.W)\n        else:\n            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n\n        batch_size = K.shape(u_vecs)[0]\n        input_num_capsule = K.shape(u_vecs)[1]\n        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n                                            self.num_capsule, self.dim_capsule))\n        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n\n        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n        for i in range(self.routings):\n            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n            c = K.softmax(b)\n            c = K.permute_dimensions(c, (0, 2, 1))\n            b = K.permute_dimensions(b, (0, 2, 1))\n            outputs = self.activation(tf.keras.backend.batch_dot(c, u_hat_vecs, [2, 2]))\n            if i < self.routings - 1:\n                b = tf.keras.backend.batch_dot(outputs, u_hat_vecs, [2, 3])\n\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        return (None, self.num_capsule, self.dim_capsule)\n    \n\ndef f1_smart(y_true, y_pred):\n    args = np.argsort(y_pred)\n    tp = y_true.sum()\n    fs = (tp - np.cumsum(y_true[args[:-1]])) / np.arange(y_true.shape[0] + tp - 1, tp, -1)\n    res_idx = np.argmax(fs)\n    return 2 * fs[res_idx], (y_pred[args[res_idx]] + y_pred[args[res_idx + 1]]) / 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13e203d83752fc2701385559f7173e81764edc93"},"cell_type":"code","source":"# https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb\n\nclass Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ecd3924dc053627c258b6b9dc93de54c303f097"},"cell_type":"code","source":"# https://www.kaggle.com/hireme/fun-api-keras-f1-metric-cyclical-learning-rate/code\n\nclass CyclicLR(Callback):\n    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n    The method cycles the learning rate between two boundaries with\n    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n    The amplitude of the cycle can be scaled on a per-iteration or \n    per-cycle basis.\n    This class has three built-in policies, as put forth in the paper.\n    \"triangular\":\n        A basic triangular cycle w/ no amplitude scaling.\n    \"triangular2\":\n        A basic triangular cycle that scales initial amplitude by half each cycle.\n    \"exp_range\":\n        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n        cycle iteration.\n    For more detail, please see paper.\n    \n    # Example\n        ```python\n            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n                                step_size=2000., mode='triangular')\n            model.fit(X_train, Y_train, callbacks=[clr])\n        ```\n    \n    Class also supports custom scaling functions:\n        ```python\n            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n                                step_size=2000., scale_fn=clr_fn,\n                                scale_mode='cycle')\n            model.fit(X_train, Y_train, callbacks=[clr])\n        ```    \n    # Arguments\n        base_lr: initial learning rate which is the\n            lower boundary in the cycle.\n        max_lr: upper boundary in the cycle. Functionally,\n            it defines the cycle amplitude (max_lr - base_lr).\n            The lr at any cycle is the sum of base_lr\n            and some scaling of the amplitude; therefore \n            max_lr may not actually be reached depending on\n            scaling function.\n        step_size: number of training iterations per\n            half cycle. Authors suggest setting step_size\n            2-8 x training iterations in epoch.\n        mode: one of {triangular, triangular2, exp_range}.\n            Default 'triangular'.\n            Values correspond to policies detailed above.\n            If scale_fn is not None, this argument is ignored.\n        gamma: constant in 'exp_range' scaling function:\n            gamma**(cycle iterations)\n        scale_fn: Custom scaling policy defined by a single\n            argument lambda function, where \n            0 <= scale_fn(x) <= 1 for all x >= 0.\n            mode paramater is ignored \n        scale_mode: {'cycle', 'iterations'}.\n            Defines whether scale_fn is evaluated on \n            cycle number or cycle iterations (training\n            iterations since start of cycle). Default is 'cycle'.\n    \"\"\"\n\n    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n                 gamma=1., scale_fn=None, scale_mode='cycle'):\n        super(CyclicLR, self).__init__()\n\n        self.base_lr = base_lr\n        self.max_lr = max_lr\n        self.step_size = step_size\n        self.mode = mode\n        self.gamma = gamma\n        if scale_fn == None:\n            if self.mode == 'triangular':\n                self.scale_fn = lambda x: 1.\n                self.scale_mode = 'cycle'\n            elif self.mode == 'triangular2':\n                self.scale_fn = lambda x: 1/(2.**(x-1))\n                self.scale_mode = 'cycle'\n            elif self.mode == 'exp_range':\n                self.scale_fn = lambda x: gamma**(x)\n                self.scale_mode = 'iterations'\n        else:\n            self.scale_fn = scale_fn\n            self.scale_mode = scale_mode\n        self.clr_iterations = 0.\n        self.trn_iterations = 0.\n        self.history = {}\n\n        self._reset()\n\n    def _reset(self, new_base_lr=None, new_max_lr=None,\n               new_step_size=None):\n        \"\"\"Resets cycle iterations.\n        Optional boundary/step size adjustment.\n        \"\"\"\n        if new_base_lr != None:\n            self.base_lr = new_base_lr\n        if new_max_lr != None:\n            self.max_lr = new_max_lr\n        if new_step_size != None:\n            self.step_size = new_step_size\n        self.clr_iterations = 0.\n        \n    def clr(self):\n        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n        if self.scale_mode == 'cycle':\n            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n        else:\n            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n        \n    def on_train_begin(self, logs={}):\n        logs = logs or {}\n\n        if self.clr_iterations == 0:\n            K.set_value(self.model.optimizer.lr, self.base_lr)\n        else:\n            K.set_value(self.model.optimizer.lr, self.clr())        \n            \n    def on_batch_end(self, epoch, logs=None):\n        \n        logs = logs or {}\n        self.trn_iterations += 1\n        self.clr_iterations += 1\n\n        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n        self.history.setdefault('iterations', []).append(self.trn_iterations)\n\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        \n        K.set_value(self.model.optimizer.lr, self.clr())\n    \n\ndef f1(y_true, y_pred):\n    '''\n    metric from here \n    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n    '''\n    def recall(y_true, y_pred):\n        \"\"\"Recall metric.\n\n        Only computes a batch-wise average of recall.\n\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\n    def precision(y_true, y_pred):\n        \"\"\"Precision metric.\n\n        Only computes a batch-wise average of precision.\n\n        Computes the precision, a metric for multi-label classification of\n        how many selected items are relevant.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf9cd9fac5cec75d98c338010ba329d689e4f481"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8e1d1e242d8248fa2b0118947fe31c5d91509b9"},"cell_type":"code","source":"def capsule(embedding_matrix, nb_words):\n    K.clear_session()       \n    inp = Input(shape=(max_len,))\n    x = Embedding(nb_words, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n    x = SpatialDropout1D(rate=0.2)(x)\n    x = Bidirectional(CuDNNGRU(100, return_sequences=True, \n                                kernel_initializer=glorot_normal(seed=12300), recurrent_initializer=orthogonal(gain=1.0, seed=10000)))(x)\n\n    x = Capsule(num_capsule=10, dim_capsule=10, routings=4, share_weights=True)(x)\n    x = Flatten()(x)\n\n    x = Dense(100, activation=\"relu\", kernel_initializer=glorot_normal(seed=12300))(x)\n    x = Dropout(0.12)(x)\n    x = BatchNormalization()(x)\n\n    x = Dense(1, activation=\"sigmoid\")(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy', optimizer=Adam(),)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b7e99e0f7c77008f464d633ebab4909daf259d5"},"cell_type":"code","source":"def model_lstm_atten_capsule(embedding_matrix, nb_words):\n    \n    inp = Input(shape=(max_len,))\n    x = Embedding(nb_words, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n    #x = SpatialDropout1D(0.1)(x)\n    x = Bidirectional(CuDNNLSTM(40, return_sequences=True))(x)\n    y = Bidirectional(CuDNNGRU(40, return_sequences=True))(x)\n    \n    #atten_1 = Attention(max_len)(x) # skip connect\n    atten_2 = Attention(max_len)(y)\n    \n    cap_1 = Capsule(num_capsule=10, dim_capsule=10, routings=4, share_weights=True)(x)\n    x = Flatten()(cap_1)\n    \n    avg_pool = GlobalAveragePooling1D()(y)\n    max_pool = GlobalMaxPooling1D()(y)\n    \n    conc = concatenate([x, atten_2, avg_pool, max_pool])\n    conc = Dense(16, activation=\"relu\")(conc)\n    conc = Dropout(0.3)(conc)\n    outp = Dense(1, activation=\"sigmoid\")(conc)    \n\n    model = Model(inputs=inp, outputs=outp)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[f1])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da5891a89af13bd57c4749409e8b386fed535913"},"cell_type":"markdown","source":"Let us train this model using 5-fold stratified validation. Through trial and error,  running 2 epochs  seemed like a reasonable choice for this model, to prevent overfitting."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"0e55a607f399f193fbd4e578aba398f2d22a0899"},"cell_type":"code","source":"start_time = time.time()\n\nuid = 1\nversion =1 \nn_splits = 5\nn_epochs = 5\nbatch_size =1024\n\nclr = CyclicLR(base_lr=0.001, max_lr=0.006,\n               step_size=2000., mode='triangular2')\n\nskf = StratifiedKFold(n_splits=n_splits, random_state = 7418880, shuffle=True)\nval_preds = defaultdict(list)\ntest_preds = {}\nhistoryD={}\nfor ii, (train_index, val_index)  in enumerate(skf.split(train_X, train_y)):\n    \n    split_start_time = time.time()\n\n    X_train, X_val = train_X[train_index], train_X[val_index]\n    y_train, y_val = train_y[train_index], train_y[val_index]\n    \n    #model = capsule(embedding_matrix, nb_words)\n    model = model_lstm_atten_capsule(embedding_matrix, nb_words)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, \n              validation_data=(X_val, y_val), callbacks = [clr,], verbose= True)\n    \n    historyD[\"fold{}\".format(ii+1)] = hist.history\n    \n    pred_val_y = model.predict([X_val], batch_size=batch_size, verbose=1)\n    val_preds['fold{}'.format(ii+1)] = [pred_val_y.ravel(),y_val]\n    \n    pred_test_y = model.predict([test_X], batch_size=batch_size, verbose=1)\n    test_preds['fold{}'.format(ii+1)] =  pred_test_y.ravel()\n    \n    # summarize history for accuracy\n    plt.plot(hist.history['acc'])\n    plt.plot(hist.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    \n    # summarize history for loss\n    plt.plot(hist.history['loss'])\n    plt.plot(hist.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    \n    \n    # Print classification report\n    print(\"Classification Report- threshold 0.25\")\n    print(classification_report(y_val,(pred_val_y>0.25).astype(int),digits=5))    \n    \n    # 5. Plot confusion matrix\n    cnf_matrix = confusion_matrix(y_val,(pred_val_y>0.25))\n    print(cnf_matrix)\n    plot_confusion_matrix(cnf_matrix,classes=[0,1])\n    \n     # Print classification report\n    print(\"Classification Report- threshold 0.5\")\n    print(classification_report(y_val,(pred_val_y>=0.5).astype(int),digits=5))    \n    \n    # 5. Plot confusion matrix\n    cnf_matrix = confusion_matrix(y_val,(pred_val_y>=0.5))\n    print(cnf_matrix)\n    #plot_confusion_matrix(cnf_matrix,classes=[0,1])\n    \n    del model\n    gc.collect()\n    \n    print(\"split: {} Time for training one model = {:.0f} s\".format(ii, time.time()-split_start_time))\n    print(\"Total time for training so far = {:.0f} s\".format(time.time()-start_time))    \n# with open('train_history_uid{}_v{}.pkl'.format(uid, version),'wb') as pklfile:\n#     pickle.dump(historyD,pklfile)\n# with open('val_preds_uid{}_v{}.pkl'.format(uid, version),'wb') as pklfile:\n#     pickle.dump(val_preds,pklfile)\n# with open('test_preds_uid{}_v{}.pkl'.format(uid, version),'wb') as pklfile:\n#     pickle.dump(test_preds,pklfile)\n\nprint(\"Total time for training = {:.0f} s\".format(time.time()-start_time))    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbe818a12907f5b7d53b6188a9f9d9530bb0c9fe"},"cell_type":"markdown","source":"So total training time is ~ 65 minutes.\n\nFor each fold, a validation prediction and a test prediction are made. The threshold value to use for each of these test predictions is  obtained by a threshold scan  that yields the maximum  F1 score on the validation set. Basically what others have been using. Ad-hoc, but works.\n\nIn separate kernels, I submitted the test prediction from each of the 5 folds. The public LB scores I got were \n0.662, 0.663, 0.664, 0.665, 0.665. An average of ~0.664. Now, how does the average prediction from these five folds perform?"},{"metadata":{"trusted":true,"_uuid":"7c1822c885d1bcb5ba54c361951a85bcf66a0229"},"cell_type":"code","source":"test01_df = pd.DataFrame()\n#print(val_preds['fold6'])\nfor ii in range(len(val_preds)):\n    threshL = []\n    y_preds, y_actual = (val_preds['fold{}'.format(ii+1)])\n    for idx, thresh in enumerate(np.arange(0.1, 0.51, 0.01)):\n        thresh = np.round(thresh,2)\n        y_01 = [ 0 if x <thresh else 1 for x in y_preds]\n        threshL.append((metrics.f1_score(y_actual,y_01), thresh))\n    threshL=sorted(threshL)\n    best_F1, opt_thresh = threshL[-1]\n    print (\"For fold {0}, best validation F1 of {1:.5f} at threshold {2:.2f}\".format(ii+1, best_F1,opt_thresh))\n    test01_df['fold{}'.format(ii)] = [ 0 if x<opt_thresh else 1 for x in test_preds['fold{}'.format(ii+1)]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d0e85b1a605f0fc34d4f3fec9577a4831d985db"},"cell_type":"code","source":"print(test01_df.sum(axis=1).value_counts())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d697500f4d7c646b3f25b2c6630cc6fb1a6ffb82"},"cell_type":"markdown","source":"So,  the models disagree on (594+470+354+354) = 1772 samples . \n\nA pearson corelation coefficient between the predictions is also an useful number to know to see how correlated the differnt folds are. "},{"metadata":{"trusted":true,"_uuid":"080ba13fa75940186813d9d059efa5ca46920bd6"},"cell_type":"code","source":" test01_df.corr(method='pearson')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aebfead9db4ac9137cbf64fbad6b18ead61331a8"},"cell_type":"markdown","source":"We get a correlation coefficient of ~ 0.88 between prediction from the various folds. Heavily correlated, but still some variance.  So averaging these slightly different predictions should give us a better score than each of the  individual predictions.\n\n Let us create the submission file:"},{"metadata":{"trusted":true,"_uuid":"72c1266605e03cf22a31bf38d9f78005dd13c483"},"cell_type":"code","source":"out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\nout_df['prediction'] = [ 0 if x<2.5 else 1 for x in test01_df.sum(axis=1)]\nout_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9ab103b20e5f6832820f37248eade14bd562b2c"},"cell_type":"markdown","source":"On submission, this should yields an LB score of 0.671or thereabouts, which is a reasonable improvement of 0.007 or so. One should expect a similar improvement on other \"single models\" while using K-fold validation. Hope this kernel was useful and gives an idea of how to balance K-fold validation of a single model  vs. adding additional models to the soup."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}