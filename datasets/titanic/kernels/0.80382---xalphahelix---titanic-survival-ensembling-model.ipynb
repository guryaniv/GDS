{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"trusted":true},"cell_type":"code","source":"# Credit must be given to Anisotropic's \"Introduction to Ensembling/Stacking in Python\" \n# and Yassine Ghouzam's \"Titanic Top 4% ensembling model\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nsns.set(style='white', context='notebook', palette='deep')","execution_count":147,"outputs":[]},{"metadata":{"_cell_guid":"2c91bc57-03fb-48d9-856b-13997a28adb9","_uuid":"725a6a0800457b9dd548426eab01e1666f648780","trusted":true},"cell_type":"code","source":"# Load the training and testing data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n# We need to save the Passenger Id's for submission because it will be dropped for training\nIDtest = test['PassengerId'] \ntrain.head() # Preview the data","execution_count":148,"outputs":[]},{"metadata":{"_cell_guid":"a93a7efc-7bc1-46be-a3bf-070869a0f6c1","_uuid":"e205db6d3d6d48068ac59cf7d7bd39a01f0f4211","trusted":true},"cell_type":"code","source":"# Check for null values\nprint(train.isnull().sum())\nprint()\nprint(test.isnull().sum())","execution_count":149,"outputs":[]},{"metadata":{"_cell_guid":"06b27e56-2c0a-4d1f-9c40-37e81ce93d5c","_uuid":"778269d7152744b817a029bbdcb503b6ede81aec","trusted":true},"cell_type":"code","source":"# Outlier detection using the Tukey method\n# For each feature, we determine the interquartile range (Q3 - Q1) and define outliers as being\n# outside (iqr-outlier_step, iqr+outlier_step)\ndef detect_outlier_indices(df, n, features):\n    indices = []\n    for f in features:\n        Q1 = np.percentile(df[f], 25) # First quartile\n        Q3 = np.percentile(df[f], 75) # Third quartile\n        IQR = Q3 - Q1 # Interquartile range\n        outlier_step = 1.5 * IQR\n        # Determine outlier indices for feature\n        outliers_for_feature = df[(df[f] < (Q1 - outlier_step)) | \n                                  (df[f] > (Q3 + outlier_step))].index\n        indices.extend(outliers_for_feature)\n    outlier_count = Counter(indices) # Dict: {item: count}\n    return [index for index in outlier_count if outlier_count[index] > n]\n\noutlier_indices = detect_outlier_indices(train, 2, ['Age', 'SibSp', 'Parch', 'Fare'])\ntrain.iloc[outlier_indices] # View outliers to drop","execution_count":150,"outputs":[]},{"metadata":{"_cell_guid":"2c219e38-f6c4-4738-9138-372724985054","_uuid":"2e79dcb466f926eec373e99ff0b2559e24d0fab8","trusted":true},"cell_type":"code","source":"# reset_index(drop=True) adds new index column without creating a new column from old indices\ntrain = train.drop(outlier_indices).reset_index(drop=True)\ntrain.size # 10 less samples","execution_count":151,"outputs":[]},{"metadata":{"_cell_guid":"be342ae0-f988-438d-9baf-9d99c3e42d1d","_uuid":"34d2d663f5161aba6b9bba0efc4296745bbdfdb6","trusted":true},"cell_type":"code","source":"# Sex vs. Survived\ngraph = sns.factorplot(x='Sex', y='Survived', data=train, kind='bar')\ngraph = graph.set_ylabels('Survival Probability')\n# Pclass vs. Survived\ngraph = sns.factorplot(x='Pclass', y='Survived', data=train, kind='bar')\ngraph = graph.set_ylabels('Survival Probability')\n# SibSp vs. Survived\ngraph = sns.factorplot(x='SibSp', y='Survived', data=train, kind='bar')\ngraph = graph.set_ylabels('Survival Probability')\n# Parch vs. Survived\ngraph = sns.factorplot(x='Parch', y='Survived', data=train, kind='bar')\ngraph = graph.set_ylabels('Survival Probability')","execution_count":152,"outputs":[]},{"metadata":{"_cell_guid":"92105a5c-71a2-4410-b1f1-a6574afa1ddc","_uuid":"0c491611475fa1ecac89c9414ef57b24b88ed368","trusted":true},"cell_type":"code","source":"# Feature engineering\ntest['Fare'] = test['Fare'].fillna(test['Fare'].median()) # Removes 1 null value \ntrain['Embarked'] = train['Embarked'].fillna('S') # Removes 2 null values from embarked\n# Combine train and test data into one dataset \nfull_data = [train, test]\n\nfor dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    # Create new feature isAlone from family size\n    dataset['isAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'isAlone'] = 1\n    # Filling missing age values\n    #age_mean = dataset['Age'].mean()\n    #age_std = dataset['Age'].std()\n    #age_null_count = dataset['Age'].isnull().sum()\n    #age_null_random_list = np.random.randint(age_mean-age_std, age_mean+age_std, \n                                            #size=age_null_count)\n    #dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n\n    # Change the Age and Fare values from floats to int\n    #dataset['Age'] = dataset['Age'].astype(int)\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    # Mapping sex and embarked\n    dataset['Sex'] = dataset['Sex'].map({'female': 0, 'male': 1}).astype(int)\n    dataset['Embarked'] = dataset['Embarked'].map({'C': 0, 'Q': 1, 'S': 2}).astype(int)\n\ntrain.head()","execution_count":153,"outputs":[]},{"metadata":{"_cell_guid":"55b2c140-cc6d-4ca3-bc2a-299947d20df7","_uuid":"cf7ebc000da7675b62c7556471d3725c9f0cfefb","trusted":true},"cell_type":"code","source":"# Plot a heatmap of feature correlations\nplt.figure(figsize=(14, 12))\nplt.title('Correlation of Features')\ngraph = sns.heatmap(train.corr(), cmap=plt.cm.bwr, annot=True,\n                   fmt='.2f', square=True)","execution_count":154,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bdd8a3598599d103a4e4835455837e1684685d5"},"cell_type":"code","source":"# Must fill missing age values \n# Age distribution\n# Superimposing age densities\n# Distribution shows peak between 0 and 5 corresponding to babies and young children\n\ngraph = sns.kdeplot(train['Age'][(train['Survived'] == 0) & (train['Age'].notnull())],\n                    color='Red', shade=True)\ngraph = sns.kdeplot(train['Age'][(train['Survived'] == 1) & (train['Age'].notnull())],\n                    color='Blue', shade=True)\ngraph.set_xlabel('Age')\ngraph.set_ylabel('Frequency')\ngraph = graph.legend(['Not Survived', 'Survived'])","execution_count":155,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1abbcee23fe78f7a3e496a8f44449a8b07c001f"},"cell_type":"code","source":"# kde plot shows peak in survival rate corresponding to young age\n# Furthermore, heatmap shows that age is negatively correlated with Pclass and FamilySize, so I will use these\n# features to fill in missing values\n\nage_nan_indices = list(dataset['Age'][np.isnan(dataset['Age'])].index)\nfor dataset in full_data:\n    age_nan_indices = list(dataset['Age'][np.isnan(dataset['Age'])].index)\n    for i in age_nan_indices:\n        # Fill age with mean age of samples with similar Pclass and FamilySize\n        age_pred = dataset['Age'][(dataset['Pclass'] == dataset.iloc[i]['Pclass']) & \n                                  (dataset['FamilySize'] == dataset.iloc[i]['FamilySize'])].mean()\n        if np.isnan(age_pred):\n            dataset['Age'].iloc[i] = dataset['Age'].mean()\n        else:\n            dataset['Age'].iloc[i] = age_pred","execution_count":156,"outputs":[]},{"metadata":{"_cell_guid":"31b27ec4-4363-4cd0-ba5f-a4dda0bf7b67","_uuid":"294af1b3ae1a392287a4bd010bc688657ab13d60","trusted":true},"cell_type":"code","source":"train['Name'].head()","execution_count":157,"outputs":[]},{"metadata":{"_cell_guid":"b43395f9-ff7d-4c7f-acb2-45b2c5bea5fa","_uuid":"4b5f8eecbb6b0e5f8d10be587064be614c708aba","trusted":true},"cell_type":"code","source":"# Extract title from name and create separate feature\ndef get_title(name):\n    return name.split(',')[1].split('.')[0].strip()\n# Create Title feature \nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n# Search for rare titles\nplt.title('Title Counts')\ngraph = sns.countplot(x='Title', data=pd.concat([train, test]))\ngraph = plt.setp(graph.get_xticklabels(), rotation=45)","execution_count":158,"outputs":[]},{"metadata":{"_cell_guid":"07d1ca31-2520-4a31-814f-0d425d2a9aa6","_uuid":"de9f85ba39af5b8bc81bf40a7ef1173f0145e370","trusted":true},"cell_type":"code","source":"# Put all rare titles into a single grouping \"Rare\"\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Don', 'Rev', 'Dr', 'Major', 'Lady', 'Sir',\n                                                'Col', 'Capt', 'the Countess', 'Jonkheer',\n                                                 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace(['Mlle', 'Ms'], 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    # Title mapping\n    dataset['Title'] = dataset['Title'].map({'Mr': 0, 'Mrs': 1, 'Miss': 2, 'Master': 3, \n                                             'Rare': 4}).astype(int)\n# Men have low survival rate\ngraph = sns.factorplot(x='Title', y='Survived', data=train, kind='bar')\ngraph = graph.set_xticklabels(['Mr', 'Mrs', 'Miss', 'Master', 'Rare'])","execution_count":159,"outputs":[]},{"metadata":{"_cell_guid":"4248b5ae-3c27-4e6f-96bc-382d81787004","_uuid":"05f829c113ca42a5d985157614257bcef75f7482","scrolled":true,"trusted":true},"cell_type":"code","source":"# Replace cabin number by type 'X' if there is none\nfor dataset in full_data:\n    # First letter of cabin indicates Desk which may be important\n    dataset['Cabin'] = dataset['Cabin'].apply(lambda x: 'X' if pd.isnull(x) else x[0])\n    \norder = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'X']\ngraph = sns.countplot(pd.concat([train, test])['Cabin'], order=order)\ngraph = sns.factorplot(x='Cabin', y='Survived', data=train, kind='bar', order=order)\ngraph = graph.set_ylabels('Survival Probability')","execution_count":160,"outputs":[]},{"metadata":{"_cell_guid":"3640e0d2-0ccb-475a-ab97-ab864753d196","_uuid":"164d157336216c5208a4ebdf3975cd97f2b95ce2","collapsed":true,"trusted":true},"cell_type":"code","source":"# Focus on whether or not passenger has a cabin\nfor dataset in full_data:\n    dataset['HasCabin'] = dataset['Cabin'].apply(lambda x: 1 if x == 'X' else 0)","execution_count":161,"outputs":[]},{"metadata":{"_cell_guid":"e5c5ddf9-ad53-408d-a17e-ba1f4a8eb1f5","_uuid":"acf579d94e0739a557dcfddf1f524e8b0cf69a23","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"# Feature selection\nfeatures_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']\ntrain = train.drop(features_to_drop, axis=1)\ntest = test.drop(features_to_drop, axis=1)","execution_count":162,"outputs":[]},{"metadata":{"_cell_guid":"b01b6366-3c82-4c22-85b4-421b2e434240","_uuid":"cac31265d5a021d29e6f27344b327d8f7163eed8","collapsed":true,"trusted":true},"cell_type":"code","source":"# Separate train and label features\nY_train = train['Survived']\nX_train = train.drop('Survived', axis=1)","execution_count":163,"outputs":[]},{"metadata":{"_cell_guid":"5307b09a-f617-491e-b2b9-8a197f08646c","_uuid":"d9e0edae018a0be2bd2596e0faae684233d3c8d6","scrolled":false,"trusted":true},"cell_type":"code","source":"seed = 42 # Reproducibility\n# Stratification ensures that each fold is representative of all strata of the data\n# Proportion of each class is approximately equal\n# Generally better in terms of mean and variance compared to cross-validation\nkfold = StratifiedKFold(n_splits=10)\nclassifier_names = ['RandomForest', 'AdaBoost', 'ExtraTrees', 'GradientBoosting', \n                    'LogisticRegression', 'KNeighbors', 'MLP', 'SVC', 'DecisionTree']\n# Test different classifiers\nclassifiers = []\nclassifiers.append(RandomForestClassifier(random_state=seed))\nclassifiers.append(AdaBoostClassifier(random_state=seed))\nclassifiers.append(ExtraTreesClassifier(random_state=seed))\nclassifiers.append(GradientBoostingClassifier(random_state=seed))\nclassifiers.append(LogisticRegression(random_state=seed))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(MLPClassifier(random_state=seed))\nclassifiers.append(SVC(random_state=seed))\nclassifiers.append(DecisionTreeClassifier(random_state=seed))\n\ncv_results = []\nfor classifier in classifiers:\n    cv_results.append(cross_val_score(classifier, X_train, y=Y_train, scoring='accuracy',\n                                     cv=kfold))\n# Display cross-validation results\nfor i, result in enumerate(cv_results):\n    print('{}: {}%'.format(classifier_names[i], result.mean()*100))","execution_count":164,"outputs":[]},{"metadata":{"_cell_guid":"0f9fb323-604e-4433-a689-7490b1b15173","_uuid":"22854591121061c0780dd72754ab0b79a56cae37","trusted":true},"cell_type":"code","source":"# Hyperparameter tuning\n# Choosing RandomForest AdaBoost, GradientBoosting, LinearDiscriminantAnalysis,\n# and LogisticRegression classifiers for fine-tuning\n\n# Random Forest Classifier\nrf_clf = RandomForestClassifier()\n\nrfc_param_grid = {'n_estimators': [100, 200, 500],\n                'max_features': ['sqrt', 'log2', None],\n                'min_samples_split': [2, 3, 5, 8],\n                'min_samples_leaf': [2, 3, 5],\n                'bootstrap': [True, False]}\n\ngs_rfc = GridSearchCV(rf_clf, param_grid=rfc_param_grid, cv=kfold, scoring='accuracy', \n                      n_jobs=-1)\ngs_rfc.fit(X_train, Y_train)\n\nbest_rf_clf = gs_rfc.best_estimator_\n\nprint(best_rf_clf)\nprint(gs_rfc.best_score_)","execution_count":165,"outputs":[]},{"metadata":{"_cell_guid":"6d72adc5-daeb-43f3-8382-5f9b332732d0","_uuid":"8669c410dbb4b5b5dfd6e128dbb83a15879e742a","trusted":true},"cell_type":"code","source":"# AdaBoost Classifier\nada_clf = AdaBoostClassifier()\n\nada_param_grid = {'n_estimators': [100, 200, 500],\n                'learning_rate': [0.1, 0.02, 0.5, 1],\n                'algorithm': ['SAMME', 'SAMME.R']}\n\ngs_ada = GridSearchCV(ada_clf, param_grid=ada_param_grid, cv=kfold, scoring='accuracy', n_jobs=-1)\ngs_ada.fit(X_train, Y_train)\n\nbest_ada_clf = gs_ada.best_estimator_\n\nprint(best_ada_clf)\nprint(gs_ada.best_score_)","execution_count":166,"outputs":[]},{"metadata":{"_cell_guid":"ee31805a-1b6e-4615-ad58-eaccf3d116ee","_uuid":"23995e5f18cd46cccf4697212c819e51792a91ca","trusted":true},"cell_type":"code","source":"# ExtraTrees Classifier\nextra_clf = ExtraTreesClassifier()\n\nextra_param_grid = {'n_estimators': [100, 200, 500],\n                   'max_features': ['sqrt', 'log2', None],\n                   'min_samples_split': [2, 3, 5],\n                   'min_samples_leaf': [2, 3, 5],\n                   'bootstrap': [True, False]}\n\ngs_extra = GridSearchCV(extra_clf, param_grid=extra_param_grid, cv=kfold, scoring='accuracy',\n                       n_jobs=-1)\ngs_extra.fit(X_train, Y_train)\n\nbest_extra_clf = gs_extra.best_estimator_\n\nprint(best_extra_clf)\nprint(gs_extra.best_score_)","execution_count":167,"outputs":[]},{"metadata":{"_cell_guid":"f80e486e-ba7f-4bd7-927f-8e2bfca8b5bb","_uuid":"632330a0cf2e230be569e1d955f476704af9dec8","trusted":true},"cell_type":"code","source":"# Gradient Boosting Classifier\ngb_clf = GradientBoostingClassifier()\n\ngb_param_grid = {'loss': ['deviance'],\n                'learning_rate': [0.001, 0.01, 0.02],\n                'n_estimators': [200, 500, 800],\n                'max_depth': [1, 3, 5, 8],\n                'max_features': ['sqrt', 'log2', None]}\n\ngs_gb = GridSearchCV(gb_clf, param_grid=gb_param_grid, cv=kfold, scoring='accuracy', n_jobs=-1)\ngs_gb.fit(X_train, Y_train)\n\nbest_gb_clf = gs_gb.best_estimator_\n\nprint(best_gb_clf)\nprint(gs_gb.best_score_)","execution_count":168,"outputs":[]},{"metadata":{"_cell_guid":"af219ff5-3c15-42e8-be25-12596e5b0963","_uuid":"d6bc238128bf5612b21ee12b90c484e1d484e5db","trusted":true},"cell_type":"code","source":"# Logistic Regression\nlogreg = LogisticRegression()\n\nlog_param_grid = {'C': [1.0],\n                 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n                 'max_iter': [10, 30, 50, 100]}\n\ngs_log = GridSearchCV(logreg, param_grid=log_param_grid, cv=kfold, scoring='accuracy')\ngs_log.fit(X_train, Y_train)\n\nbest_logreg = gs_log.best_estimator_\n\nprint(best_logreg)\nprint(gs_log.best_score_)","execution_count":169,"outputs":[]},{"metadata":{"_cell_guid":"60e0b652-80f8-4dfe-b0e9-92e7bb4fed67","_uuid":"93182d432a8ee4ed8d420636f77201f845e72edc","trusted":true},"cell_type":"code","source":"# Feature importances of tree based classifiers\nnames_classifiers = [('RandomForest', best_rf_clf), ('AdaBoost', best_ada_clf), \n                     ('GradientBoosting', best_gb_clf), ('ExtraTrees', best_extra_clf), \n                     ('LogisticRegression', best_logreg)]\n\nfig, ax = plt.subplots(2, 2, figsize=(15, 15))\n\nindex = 0\nfor row in range(2):\n    for col in range(2):\n        name = names_classifiers[index][0]\n        clf = names_classifiers[index][1]\n        feature_importances = clf.feature_importances_\n        indices = np.argsort(feature_importances)[::-1] # Least to most important features\n        graph = sns.barplot(y=X_train.columns[indices], x=feature_importances[indices],\n                           ax=ax[row][col])\n        graph.set_xlabel('Relative Importance')\n        graph.set_ylabel('Features')\n        graph.set_title(name + ' feature importances')\n        index += 1\n# Title, sex, age, fare, and family size are most important features\n# Might remove series of cabin features and create a 'HasCabin' feature","execution_count":170,"outputs":[]},{"metadata":{"_cell_guid":"5f1d76e0-feea-42e4-a5ee-78b7c3f05520","_uuid":"a5a361fb1385f6b82ecd33f7e155dede94b1189d","trusted":true},"cell_type":"code","source":"test_survived_rf_clf = pd.Series(best_rf_clf.predict(test), name='Rf')\ntest_survived_ada_clf = pd.Series(best_ada_clf.predict(test), name='Ada')\ntest_survived_gb_clf = pd.Series(best_gb_clf.predict(test), name='Gb')\ntest_survived_extra_clf = pd.Series(best_extra_clf.predict(test), name='Extra')\ntest_survived_logreg = pd.Series(best_logreg.predict(test), name='Logreg')\n\nensemble_results = pd.concat([test_survived_rf_clf, test_survived_ada_clf, test_survived_gb_clf,\n                             test_survived_extra_clf, test_survived_logreg], axis=1)\n# Compare the 5 classifiers with each other\n# If the differences in predictions are small, then we can consider ensembling voting\nplt.figure(figsize=(10, 10))\ngraph = sns.heatmap(ensemble_results.corr(), cmap=plt.cm.viridis, annot=True, square=True)\ngraph.set_title('Ensemble Results')","execution_count":171,"outputs":[]},{"metadata":{"_cell_guid":"febc3b68-6d77-4968-bf37-eda28e5aa04c","_uuid":"269fa12474284d3f1c1d19a32f6497143108c380","scrolled":true,"trusted":true},"cell_type":"code","source":"# Ensemble voting is useful because predictions are similar between classifiers\n# Combines preditions from 5 classifiers\n# 'soft' takes probability of each prediction into account\nvoting_clf = VotingClassifier(estimators=[('RandomForest', best_rf_clf), ('AdaBoost', best_ada_clf), \n                                          ('GradientBoosting', best_gb_clf), ('ExtraTrees', best_extra_clf), \n                                          ('LogisticRegression', best_logreg)], voting='soft')\n\nvoting_clf = voting_clf.fit(X_train, Y_train)\nresults = cross_val_score(voting_clf, X_train, y=Y_train, scoring='accuracy', cv=kfold)\nprint('Voting classifier: {}%'.format(results.mean()*100))","execution_count":172,"outputs":[]},{"metadata":{"_cell_guid":"061348eb-ac6c-4ccf-baf6-48855334a9b6","_uuid":"5910e80c3e9860bdbc153fa62ffb6fd90111a08a","trusted":true},"cell_type":"code","source":"test_survived = voting_clf.predict(test)\nsubmission = pd.DataFrame({'PassengerId': IDtest, 'Survived': test_survived})\nsubmission.to_csv('titanic_ensemble_model.csv', index=False)","execution_count":173,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}