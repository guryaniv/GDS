{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"# Here we come toxic commentators!"},{"metadata":{"_cell_guid":"3434c19d-9bbd-458f-ae30-6c60909983ad","_uuid":"d1a49cd92cc4bf5bbf1d8c58b1c5ee158dd98082"},"cell_type":"markdown","source":"# We start with importing all the necessary packages before we dive into it any further."},{"metadata":{"_cell_guid":"845f6f6a-49fe-450d-91bd-10e7258129b5","_uuid":"9885f03b1502b51aa5331656e19e16cc966d92a6","collapsed":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport string\nimport nltk\nimport sklearn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.neural_network import MLPClassifier","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"349790d6-3955-42fb-bf9b-e5475e10a748","_uuid":"5453f88ef533d49445f099ae83436fb25ad1003b","collapsed":true},"cell_type":"markdown","source":"# Let us fetch the data and call it as 'raw_data' and the test data as 'test_data'. While we are doing that, why don't we fill the NAs with 'no comment'."},{"metadata":{"_cell_guid":"f0281548-55bb-47cc-a9f2-3caa7945b6d7","_uuid":"5fc9ce94684e06f07f634ee0296d64f61de19c5a","collapsed":true,"trusted":true},"cell_type":"code","source":"raw_data = pd.read_csv('../input/train.csv').fillna('no comment')\n\ntest_data = pd.read_csv('../input/test.csv').fillna('no comment')","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"c7cf9484-9a53-4014-8ecc-4ff08ed40aa2","_uuid":"3dc12d4ca0ef93fa5c34c27a5b2fd913a67d4c88","trusted":true},"cell_type":"code","source":"raw_data.info()","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"17beed6e-442d-4e91-8b2b-0046462b14d3","_uuid":"071fc9fcb5f921faa93b65a3a71cefa99eaee2e3"},"cell_type":"markdown","source":"# We see there are 159571 number of comments, each of them belonging to one or more of the 6 categories of toxicity."},{"metadata":{"_cell_guid":"d005de70-5171-4ffb-ae27-790547dc1323","_uuid":"29801599783f4ad6d02ce02a48061ff618ab8bb0"},"cell_type":"markdown","source":"# Now, let us combine all the comments together to do some digging."},{"metadata":{"_cell_guid":"357f53b1-8e48-48c8-b5b5-89fb4806cdd8","_uuid":"7d60f73f352533a2a850a1bd43bbe48dc7444dc8","collapsed":true,"trusted":true},"cell_type":"code","source":"all_comments = pd.concat([raw_data.comment_text, test_data.comment_text])","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"2c6656af-e8e3-4a39-b1af-6cdbe49e4ce0","_uuid":"af4baa47173e4627075e6db57ca4663e40d0069c"},"cell_type":"markdown","source":"# Let's take a look at the top 5 comments which I have put in the list 'words'."},{"metadata":{"_cell_guid":"c153adcb-19e2-4dd1-a290-7b8e98ce85d7","_uuid":"00c7ae0487256e7dc2d8832f5e1ed938ec318e56","trusted":true},"cell_type":"code","source":"sentences = [''.join(c for c in s if c not in string.punctuation) for s in all_comments]\nsentences[:5]","execution_count":24,"outputs":[]},{"metadata":{"_cell_guid":"22aba8eb-c46a-4cda-a51e-77b9cc219018","_uuid":"a1ef56c932e1a794869cbcb0bc69e2e31e9b0a15"},"cell_type":"markdown","source":"# DO NOT BE ALARMED BY THE BUNCH OF WORDS THAT FOLLOW.\n# Some really nice people out there have done us a favor and noted down some words that come in really handy to be used as stopwords.\n# I added some more to help the algorithm further. If you want to take a look, this is the link http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words\n# You can also go ahead and use the stopwords in the Natural Language Toolkit(nltk)."},{"metadata":{"_cell_guid":"66273b08-8c0f-4620-b7e8-a3ec1b6afe1e","_uuid":"34e5df0baadf8679558be7a97d91363dd854c694","collapsed":true,"trusted":true},"cell_type":"code","source":"stopwords = ['a', 'about', 'above', 'across', 'after', 'afterwards','again', 'against', 'all', 'almost', 'alone', 'along','already', 'also', 'although', 'always', 'am', 'among']\nstopwords += ['amongst', 'amoungst', 'amount', 'an', 'and', 'another','any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere']\nstopwords += ['are', 'around', 'as', 'at', 'back', 'be', 'became','because', 'become', 'becomes', 'becoming', 'been']\nstopwords += ['before', 'beforehand', 'behind', 'being', 'below','beside', 'besides', 'between', 'beyond', 'bill', 'both']\nstopwords += ['bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant','co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de']\nstopwords += ['describe', 'detail', 'did', 'do', 'done', 'down', 'due','during', 'each', 'eg', 'eight', 'either', 'eleven', 'else']\nstopwords += ['elsewhere', 'empty', 'enough', 'etc', 'even', 'ever','every', 'everyone', 'everything', 'everywhere', 'except']\nstopwords += ['few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first','five', 'for', 'former', 'formerly', 'forty', 'found']\nstopwords += ['four', 'from', 'front', 'full', 'further', 'get', 'give','go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her']\nstopwords += ['here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers','herself', 'him', 'himself', 'his', 'how', 'however']\nstopwords += ['hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed','interest', 'into', 'is', 'it', 'its', 'itself', 'keep']\nstopwords += ['last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made','many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine']\nstopwords += ['more', 'moreover', 'most', 'mostly', 'move', 'much','must', 'my', 'myself', 'name', 'namely', 'neither', 'never']\nstopwords += ['nevertheless', 'next', 'nine', 'no', 'nobody', 'none','noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of']\nstopwords += ['off', 'often', 'on','once', 'one', 'only', 'onto', 'or','other', 'others', 'otherwise', 'our', 'ours', 'ourselves']\nstopwords += ['out', 'over', 'own', 'part', 'per', 'perhaps', 'please','put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed']\nstopwords += ['seeming', 'seems', 'serious', 'several', 'she', 'should','show', 'side', 'since', 'sincere', 'six', 'sixty', 'so']\nstopwords += ['some', 'somehow', 'someone', 'something', 'sometime','sometimes', 'somewhere', 'still', 'such', 'system', 'take']\nstopwords += ['ten', 'than', 'that', 'the', 'their', 'them', 'themselves','then', 'thence', 'there', 'thereafter', 'thereby']\nstopwords += ['therefore', 'therein', 'thereupon', 'these', 'they','thick', 'thin', 'third', 'this', 'those', 'though', 'three']\nstopwords += ['three', 'through', 'throughout', 'thru', 'thus', 'to','together', 'too', 'top', 'toward', 'towards', 'twelve']\nstopwords += ['twenty', 'two', 'un', 'under', 'until', 'up', 'upon','us', 'very', 'via', 'was', 'we', 'well', 'were', 'what']\nstopwords += ['whatever', 'when', 'whence', 'whenever', 'where','whereafter', 'whereas', 'whereby', 'wherein', 'whereupon']\nstopwords += ['wherever', 'whether', 'which', 'while', 'whither', 'who','whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with']\nstopwords += ['within', 'without', 'would', 'yet', 'you', 'your','yours', 'yourself', 'yourselves']\nstopwords += ['A', 'About', 'Above', 'Across', 'After', 'Afterwards','Again', 'Against', 'All', 'Almost', 'Alone', 'Along']\nstopwords += ['Already', 'Also', 'Although', 'Always', 'Am', 'Among','Amongst', 'Amoungst', 'Amount', 'An', 'And', 'Another']\nstopwords += ['Any', 'Anyhow', 'Anyone', 'Anything', 'Anyway', 'Anywhere','Are', 'Around', 'As', 'At', 'Back', 'Be', 'Became']\nstopwords += ['Because', 'Become', 'Becomes', 'Becoming', 'Been','Before', 'Beforehand', 'Behind', 'Being', 'Below']\nstopwords += ['Beside', 'Besides', 'Between', 'Beyond', 'Bill', 'Both','Bottom', 'But', 'By', 'Call', 'Can', 'Cannot', 'Cant']\nstopwords += ['Co', 'Computer', 'Con', 'Could', 'Couldnt', 'Cry', 'De','Describe', 'Detail', 'Did', 'Do', 'Done', 'Down', 'Due']\nstopwords += ['During', 'Each', 'Eg', 'Eight', 'Either', 'Eleven', 'Else','Elsewhere', 'Empty', 'Enough', 'Etc', 'Even', 'Ever']\nstopwords += ['Every', 'Everyone', 'Everything', 'Everywhere', 'Except','Few', 'Fifteen', 'Fifty', 'Fill', 'Find', 'Fire', 'First']\nstopwords += ['Five', 'For', 'Former', 'Formerly', 'Forty', 'Found','Four', 'From', 'Front', 'Full', 'Further', 'Get', 'Give']\nstopwords += ['Go', 'Had', 'Has', 'Hasnt', 'Have', 'He', 'Hence', 'Her','Here', 'Hereafter', 'Hereby', 'Herein', 'Hereupon', 'Hers']\nstopwords += ['Herself', 'Him', 'Himself', 'His', 'How', 'However','Hundred', 'I', 'Ie', 'If', 'In', 'Inc', 'Indeed']\nstopwords += ['Interest', 'Into', 'Is', 'It', 'Its', 'Itself', 'Ieep','Last', 'Latter', 'Latterly', 'Least', 'Less', 'Ltd', 'Made']\nstopwords += ['Many', 'May', 'Me', 'Meanwhile', 'Might', 'Mill', 'Mine','More', 'Moreover', 'Most', 'Mostly', 'Move', 'Much']\nstopwords += ['Must', 'My', 'Myself', 'Name', 'Namely', 'Neither', 'Never','Nevertheless', 'Next', 'Nine', 'No', 'Nobody', 'None']\nstopwords += ['Noone', 'Nor', 'Not', 'Nothing', 'Now', 'Nowhere', 'Of','Off', 'Often', 'On','Once', 'One', 'Only', 'Onto', 'Or']\nstopwords += ['Other', 'Others', 'Otherwise', 'Our', 'Ours', 'Ourselves','Out', 'Over', 'Own', 'Part', 'Per', 'Perhaps', 'Please']\nstopwords += ['Put', 'Rather', 'Re', 'S', 'Same', 'See', 'Seem', 'Seemed','Seeming', 'Seems', 'Serious', 'Several', 'She', 'Should']\nstopwords += ['Show', 'Side', 'Since', 'Sincere', 'Six', 'Sixty', 'So','Some', 'Somehow', 'Someone', 'Something', 'Sometime']\nstopwords += ['Sometimes', 'Somewhere', 'Still', 'Such', 'System', 'Take','Ten', 'Than', 'That', 'The', 'Their', 'Them', 'Themselves']\nstopwords += ['Then', 'Thence', 'There', 'Thereafter', 'Thereby','Therefore', 'Therein', 'Thereupon', 'These', 'They']\nstopwords += ['Thick', 'Thin', 'Third', 'This', 'Those', 'Though', 'Three','Three', 'Through', 'Throughout', 'Thru', 'Thus', 'To']\nstopwords += ['Together', 'Too', 'Top', 'Toward', 'Towards', 'Twelve','Twenty', 'Two', 'Un', 'Under', 'Until', 'Up', 'Upon']\nstopwords += ['Us', 'Very', 'Via', 'Was', 'We', 'Well', 'Were', 'What','Whatever', 'When', 'Whence', 'Whenever', 'Where']\nstopwords += ['Whereafter', 'Whereas', 'Whereby', 'Wherein', 'Whereupon','Wherever', 'Whether', 'Which', 'While', 'Whither', 'Who']\nstopwords += ['Whoever', 'Whole', 'Whom', 'Whose', 'Why', 'Will', 'With','Within', 'Without', 'Would', 'Yet', 'You', 'Your']\nstopwords += ['Yours', 'Yourself', 'Yourselves']","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"fcdffd02-dd3a-4a43-98d6-ef06fdf7fa62","_uuid":"f370d2fdb4d8109f05e0e1d57463c76c7b537ff9","trusted":true},"cell_type":"code","source":"frequency = nltk.FreqDist(sentences)\nfrequency.plot(25, cumulative = False)","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"3d5e7720-3297-43b4-8541-b1d73758bee3","_uuid":"0fc747b1ba0f71bdd8159f93cdb3e8d71ad8115a","trusted":true},"cell_type":"code","source":"frequency.most_common(5)","execution_count":27,"outputs":[]},{"metadata":{"_cell_guid":"95bfed9f-fbb3-48a2-b2c1-eeb2d8bcc3ab","_uuid":"971c74d8e20ecc721548bf54705ad0b714eb22a0"},"cell_type":"markdown","source":"# Next, I'd like to calculate the number of comments per toxicity level. We need to remember that each comment can be associated with more that one labels, we are interested in finding out which labels have more comments."},{"metadata":{"_cell_guid":"5e57761d-995e-419c-ad06-573625de973e","_uuid":"92253060101c20392269202feb8517471d4cc77b","trusted":true},"cell_type":"code","source":"new_data_labels = raw_data.drop(['id', 'comment_text'], axis=1)\ncount = []\nlabels = list(new_data_labels.columns.values)\nfor i in labels:\n    count.append((i, new_data_labels[i].sum()))\nnew_data_count = pd.DataFrame(count, columns=['label','comments'])\nnew_data_count\nnew_data_count.plot(x = 'label', y= 'comments', kind= 'bar', legend= False, grid= True)","execution_count":28,"outputs":[]},{"metadata":{"_cell_guid":"48921f02-676d-40d1-a9ac-c2b5eddd327f","_uuid":"4c1c4a2db8ab14b352889129521c7de7c5e6cad9"},"cell_type":"markdown","source":"# Our good friend Term Frequency-Inverse Document Frequency is called upon!"},{"metadata":{"_cell_guid":"da028275-f2a7-4147-8932-76f1b6bbc1a5","_uuid":"8e56b7eb1fd5d43718854de32776bc86505ae511","collapsed":true,"trusted":true},"cell_type":"code","source":"vect = TfidfVectorizer(analyzer='word', stop_words=stopwords, use_idf=True,max_df=0.8,  min_df=1, ngram_range=(1,2))\nvect_word = vect.fit(sentences)\ntrain_vect = vect_word.transform(raw_data.comment_text)\ntest_vect = vect_word.transform(test_data.comment_text)","execution_count":29,"outputs":[]},{"metadata":{"_cell_guid":"170cf678-6d9c-46ba-bec3-f8f3e2c2133a","_uuid":"e9d7d532e69b8454afae4e4b47ade7d4fa8e5848"},"cell_type":"markdown","source":"# Let us split the data into training and development sets before we use it on our test data."},{"metadata":{"_cell_guid":"a0b0faa5-1b50-4e69-8ce8-2b024a55aeea","_uuid":"b5e769d495a0034e5b2ef83c111b7bdd599bb21d","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_data, dev_data, train_label, dev_label = train_test_split(train_vect,new_data_labels)","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"86acec6b-db05-481f-80d7-be27d28379eb","_uuid":"070dcee908c80b493c1701f698545211a6932db3"},"cell_type":"markdown","source":"# This is the first time I am working on a multilabel classification dataset. So, I'm going to keep my fingers crossed and go for Multi-Layer Perceptron with the following specifications. Needless to say, I have done a lot of trial and error to get this."},{"metadata":{"_cell_guid":"7e248833-0187-43e6-ba01-dd922554be4f","_uuid":"e52ef9f73f9491c1271340713164c29c5200f62a","trusted":true},"cell_type":"code","source":"mlpclass =MLPClassifier(solver='lbfgs', alpha=1e-5, validation_fraction=0.3, hidden_layer_sizes=(4,4), verbose= True, activation= 'logistic', max_iter= 200 , learning_rate_init= 0.0001)\nmlpclass.fit(train_data, train_label)","execution_count":31,"outputs":[]},{"metadata":{"_cell_guid":"21e2f972-a935-4986-9426-90e5a1955d15","_uuid":"705db8cf15b0f59789d4ae53084b7d738bb3af44"},"cell_type":"markdown","source":"# Time to try it on our development set!"},{"metadata":{"_cell_guid":"7776f38e-5001-4ba8-867a-eed614b267cd","_uuid":"904c8905ea0f9e4a34888d722b92453cfb14a8d3","collapsed":true,"trusted":true},"cell_type":"code","source":"pred = mlpclass.predict(dev_data)","execution_count":32,"outputs":[]},{"metadata":{"_cell_guid":"532f19b6-afbe-42ac-b5fc-47b3d82ba7a0","_uuid":"c6968c5dc8fb9a7dd7b870c466011fcb5775a534"},"cell_type":"markdown","source":"# Let's see how our model performed on it."},{"metadata":{"_cell_guid":"6bcc69b9-b92b-4df0-8d5b-0866b0a53f4a","_uuid":"66db6ca28d37ca2066e8b16b91adff7ec8950258","trusted":true},"cell_type":"code","source":"mlpclass.score(dev_data, dev_label)","execution_count":33,"outputs":[]},{"metadata":{"_cell_guid":"0f2ad86f-087d-4ee4-bf04-d93382aac4d7","_uuid":"17352389aea79aa1b4ea73db4f51c36ef98e6741"},"cell_type":"markdown","source":"# Get ready everybody. It is the moment of truth!!!"},{"metadata":{"_cell_guid":"af91818b-496f-4cb4-aeb7-c7dd277e2ad7","_uuid":"21b1c388ca048e507a1f4826a3fc9c454f732c28","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"test_pred = mlpclass.predict_proba(test_vect)","execution_count":34,"outputs":[]},{"metadata":{"_cell_guid":"0fad0e83-8826-4871-be92-00e6a40422f1","_uuid":"856a7234841d3519caa23b550c079694f0630cb9"},"cell_type":"markdown","source":"# Great! We are almost done and ready to submit."},{"metadata":{"_cell_guid":"5e15a2b2-7131-4322-8af3-126b70c9574d","_uuid":"35996138a0a6ee9821cbce8d005c8e4ad6cb0e9e","collapsed":true,"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv')","execution_count":35,"outputs":[]},{"metadata":{"_cell_guid":"64109e1e-356b-4faa-ad10-e5258d57d3ec","_uuid":"40e8e58d79821217d3e8c276277e905ee94a6f85","collapsed":true,"trusted":true},"cell_type":"code","source":"submission[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]]=test_pred\nsubmission.to_csv('submission.csv', index= False)","execution_count":36,"outputs":[]},{"metadata":{"_cell_guid":"a4933b9f-3d8e-48e0-b33d-dea453156414","_uuid":"a1f5b49c4d9bd56af75aa452e912c0600e422046","collapsed":true},"cell_type":"markdown","source":"# And we are done!"},{"metadata":{"_cell_guid":"10304953-ec45-45c2-aec0-3ae965d77313","_uuid":"7ca2363e7ee5d60ca58d7adda59233145a93d743","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"523d0116-583e-426d-87f5-6b0880457d70","_uuid":"2b012bf5e59816849acb04f9d07ba5b67b17af3a","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}