{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport cv2 # pic reading\nimport os\n#print(os.listdir(\"../input\"))\n","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"TRAIN_DIR = '../input/dogs-vs-cats-redux-kernels-edition/train/'\nTEST_DIR = '../input/dogs-vs-cats-redux-kernels-edition/test/'\ntrain_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"3b3fb2f7-dc2b-4de9-9999-3de0d0c03be5","_uuid":"4f37cc801f6955705a0b23e3a39fa6b51049d13a","collapsed":true,"trusted":true},"cell_type":"code","source":"def read_image(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_COLOR) # read img into color mode\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n    img = img-np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((1,1,3))\n    return img \ndef prep_data(images):\n    count = len(images)\n    data = np.ndarray((count, 224, 224,3), dtype=np.float32)\n    for i, image_file in enumerate(images):\n        image = read_image(image_file)\n        data[i] = image   \n    return data","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"eb561451-ec75-47c8-9bb4-c133b6f87e70","_uuid":"6e4526e5fb3655efcc9481fb093cbe8f217e8d45","collapsed":true,"trusted":true},"cell_type":"code","source":"trainset = train_images[:5000]\nvalidationset = train_images[-1000:]\ntrain = prep_data(trainset)\nvalidation = prep_data(validationset)","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"3535a662-beaf-4925-abe3-b890b539a4f7","_uuid":"ad08da914c03b94171434b455c70522e23999cfa","collapsed":true,"trusted":true},"cell_type":"code","source":"train_labels = []\nfor i in trainset:\n    if i[i.find('train/')+6:i.find('train/')+9] =='dog':\n        train_labels.append(1)\n    else:\n        train_labels.append(0)\nval_labels = []\nfor i in validationset:\n    if i[i.find('train/')+6:i.find('train/')+9] =='dog':\n        val_labels.append(1)\n    else:\n        val_labels.append(0)    ","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"942949bc-c354-4e99-b7ec-5f567bd3854b","_uuid":"4930798cef517f065a8da1e56ad4c97548ae321c","trusted":true},"cell_type":"code","source":"import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation, Convolution2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.layers import Flatten, Dense, Input\nfrom keras.preprocessing import image\nfrom keras.utils.layer_utils import convert_all_kernels_in_model\nfrom keras.utils.data_utils import get_file\nfrom keras import backend as K","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"0c53ff4c-a5ac-444c-82c4-eebf0e9edf48","_uuid":"98abb703858395835321dd965e244150ead39fc4","collapsed":true,"trusted":true},"cell_type":"code","source":"TF_WEIGHTS_PATH = '../input/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5'\nTF_WEIGHTS_PATH_NO_TOP = '../input/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"4be479ff-ea23-4444-8016-0be9f1703f20","_uuid":"11d82c9fcc74b51c9728ec219c42d01e378232e1","collapsed":true,"trusted":true},"cell_type":"code","source":"def VGG_19(include_top=True, weights='imagenet',input_tensor=None):\n    input_shape = (None, None, 3)\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor)\n        else:\n            img_input = input_tensor\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n\n    if include_top:\n        x = Flatten(name='flatten')(x)\n        x = Dense(4096, activation='relu', name='fc1')(x)\n        x = Dense(4096, activation='relu', name='fc2')(x)\n        x = Dense(1000, activation='softmax', name='predictions')(x)\n\n    model = Model(img_input, x)\n    if include_top:\n        weights_path = TF_WEIGHTS_PATH\n    else:\n        weights_path = TF_WEIGHTS_PATH_NO_TOP\n    model.load_weights(weights_path)\n    return model","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"4ecbe736-6687-49c6-bdee-18042547ea09","_uuid":"f7d5f1f252aeab07bfebd9b012c0653dd63f2a61","collapsed":true,"trusted":true},"cell_type":"code","source":"def save_bottlebeck_features():\n    datagen = ImageDataGenerator()\n    model = VGG_19(include_top=False, weights='imagenet')\n    generator = datagen.flow(train,train_labels, batch_size=8,shuffle=False)\n    bottleneck_features_train = model.predict_generator(generator, 625)\n    np.save(open('bottleneck_features_train2.npy', 'wb'), bottleneck_features_train)\n    print(\"bottleneck_train.npy is created..\")\n    \n    generator = datagen.flow(validation,val_labels, batch_size=8,shuffle=False)\n    bottleneck_features_validation = model.predict_generator(generator,125)\n    np.save(open('bottleneck_features_validation2.npy', 'wb'), bottleneck_features_validation)\n    print(\"bottleneck_validation.npy is created..\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2ced6e5c-1cde-4cac-8fef-9ddafc208dfb","_uuid":"d63f319df2c09b683771ae343556f7dcfc7487ec","trusted":true},"cell_type":"code","source":"save_bottlebeck_features()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}