{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1b7e2c0a-37ae-0ea8-680a-266b22f4a292"
      },
      "source": [
        "##Part 1:  Macro Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4f325526-9a69-d250-1a4a-bd5080bb7f28"
      },
      "source": [
        "Empirical studies indicate that changes in real estate sector mirrors the wider changes taking place in the economy at any point in time. Most of these studies put emphasis in explaining how macroeconomic variables are responsible for short and long run variations in residential property prices. According to Schmitz and Brett (2001) the economic strength of a place can be demonstrated by its macroeconomic conditions, which includes interest rates, inflation, job security, industrial productivity and stock market stability. In another study in Hong Kong, Ervi (2002), found out that the rate of return in property markets is linked to economic activities while demand for retail space is sensitive to changes in employment and local output. The author also recognizes that macroeconomic variables include unemployment, inflation rates, GDP, interest rates, balances of payments and foreign exchange rates. American economistSimon Kuznets believes real estate development has a close relationship with economicgrowth after analyzing a large amount of data of different countries. \u0412 \u044d\u043a\u043e\u043d\u043e\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u043b\u0438\u0442\u0435\u0440\u0430\u0442\u0443\u0440\u0435 \u043f\u0440\u0438\u0432\u043e\u0434\u044f\u0442 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0435 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0444\u0430\u043a\u0442\u043e\u0440\u043e\u0432, \u0432\u043b\u0438\u044f\u044e\u0449\u0438\u0445 \u043d\u0430 \u0440\u0430\u0437\u0432\u0438\u0442\u0438\u0435 \u0440\u044b\u043d\u043a\u0430 \u043d\u0435\u0434\u0432\u0438\u0436\u0438\u043c\u043e\u0441\u0442\u0438: \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0438\u0435 \u0438 \u0432\u043d\u0435\u0448\u043d\u0438\u0435, \u043c\u0430\u043a\u0440\u043e\u044d\u043a\u043e\u043d\u043e\u043c\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u0438 \u043c\u0438\u043a\u0440\u043e\u044d\u043a\u043e\u043d\u043e\u043c\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u0438 \u0442. \u0434. \u0412 \u0438\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u043d\u0438\u0438 \u0431\u044b\u043b\u0438 \u043e\u0442\u043e\u0431\u0440\u0430\u043d\u044b \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438, \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0437\u0443\u044e\u0449\u0438\u0435 \u0444\u0430\u043a\u0442\u043e\u0440\u044b \u0441\u043f\u0440\u043e\u0441\u0430 \u0438 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u044f \u0438, \u043f\u043e \u043c\u043d\u0435\u043d\u0438\u044e \u0430\u0432\u0442\u043e\u0440\u043e\u0432, \u043f\u043e\u0442\u0435\u043d\u0446\u0438\u0430\u043b\u044c\u043d\u043e \u0432\u043b\u0438\u044f\u044e\u0449\u0438\u0435 \u043d\u0430 \u0443\u0434\u043e\u0440\u043e\u0436\u0430\u043d\u0438\u0435 \u0436\u0438\u043b\u043e\u0439 \u043d\u0435\u0434\u0432\u0438\u0436\u0438\u043c\u043e\u0441\u0442\u0438: 1) \u0446\u0435\u043d\u0430 \u043d\u0430 \u043d\u0435\u0444\u0442\u044c \u043c\u0430\u0440\u043a\u0438 Urals; 2) \u0432\u0430\u043b\u043e\u0432\u043e\u0439 \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0438\u0439 \u043f\u0440\u043e\u0434\u0443\u043a\u0442 (\u0412\u0412\u041f); 3) \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u0434\u043e\u0445\u043e\u0434\u043e\u0432 \u043d\u0430\u0441\u0435\u043b\u0435\u043d\u0438\u044f; 4) \u0438\u043d\u0444\u043b\u044f\u0446\u0438\u044f; 5) \u0441\u0435\u0431\u0435\u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0441\u0442\u0440\u043e\u0438\u0442\u0435\u043b\u044c\u0441\u0442\u0432\u0430; 6) \u0434\u0435\u043d\u0435\u0436\u043d\u0430\u044f \u043c\u0430\u0441\u0441\u0430; 7) \u043f\u0440\u043e\u0446\u0435\u043d\u0442\u043d\u0430\u044f \u0441\u0442\u0430\u0432\u043a\u0430 \u043f\u043e \u0438\u043f\u043e\u0442\u0435\u0447\u043d\u044b\u043c \u043a\u0440\u0435\u0434\u0438\u0442\u0430\u043c; 8) \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0438\u043f\u043e\u0442\u0435\u0447\u043d\u044b\u0445 \u0441\u0434\u0435\u043b\u043e\u043a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1b041ef9-0e89-fd10-0e56-60f2860ca523"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from numpy.polynomial.chebyshev import *\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "pd.options.mode.chained_assignment = None  \n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "891afb69-180f-44f9-d76c-cb2e2964deb5"
      },
      "source": [
        "##Initialize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "771672a2-154c-c359-e027-364dfdf2b0e6"
      },
      "outputs": [],
      "source": [
        "read_columns= ['timestamp', 'oil_urals', 'gdp_quart_growth', 'cpi', 'usdrub', \\\n",
        "                'salary_growth', 'unemployment', 'average_provision_of_build_contract_moscow', 'mortgage_rate', \\\n",
        "                 'deposits_rate','deposits_growth','rent_price_3room_eco',\\\n",
        "                 'rent_price_3room_bus']\n",
        "train_df = pd.read_csv(\"../input/train.csv\",usecols=['timestamp','price_doc','full_sq'])\n",
        "macro_df = pd.read_csv(\"../input/macro.csv\",usecols=read_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d2c33a6c-5e76-c288-4822-8cbdd2df28e6"
      },
      "outputs": [],
      "source": [
        "###### Service Read routines ###\n",
        "def condition_train(value, col):\n",
        "    vals = (macro_df[macro_df['mo_ye'] == value])\n",
        "    \n",
        "    ret = vals[col].asobject\n",
        "  \n",
        "    ret = ret[0]\n",
        "\n",
        "    return ret\n",
        "\n",
        "def condition_test(value, col):\n",
        "    vals = (macro[macro['mo_ye'] == value])\n",
        "\n",
        "    ret = vals[col].asobject\n",
        "\n",
        "    ret = ret[0]\n",
        "\n",
        "    return ret\n",
        "\n",
        "def condition(value,col):\n",
        "    vals = (macro_df[macro_df['timestamp'] == value])\n",
        "    ret=vals[col].asobject\n",
        "    ret=ret[0]\n",
        "\n",
        "    return ret\n",
        "\n",
        "def init_anlz_file():\n",
        "\n",
        "    anlz_df = train_df\n",
        "    for clmn in read_columns:\n",
        "        if clmn == 'timestamp':\n",
        "            continue\n",
        "        anlz_df[clmn] = np.nan\n",
        "        anlz_df[clmn] = anlz_df['timestamp'].apply(condition, col=clmn)\n",
        "        print(clmn)\n",
        "    return anlz_df\n",
        "\n",
        "### Read Data for macro analysis\n",
        "anlz_df=init_anlz_file()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "407ba27d-01c7-b986-ffb4-0163fcb2ed3f"
      },
      "source": [
        "##Start Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ffb6971d-c0f8-5f57-3001-8b66cc88907d"
      },
      "outputs": [],
      "source": [
        "##------------------------ SERVICE ROUTINES ----------------------------------- ###\n",
        "methods=['pearson', 'kendall', 'spearman']\n",
        "def plot_grouped_trends(df,feat1,feat2,corr_df):\n",
        "   \n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    x=df.index.values\n",
        "    ch=chebfit(x,df[feat1].values,7)\n",
        "    trendf1=chebval(x,ch)\n",
        "    ax[0].plot(x,df[feat1].values,x,trendf1)\n",
        "    ax[0].set_ylabel(feat1)\n",
        "    ax[0].set_title('Chart '+feat1+' vs trend' )\n",
        "    ax[0].set_xlabel('months count')\n",
        "    ch2=chebfit(x,df[feat2].values,7)\n",
        "    trendf2=chebval(x,ch2)\n",
        "    ax[1].plot(x,df[feat2].values,x,trendf2)\n",
        "    ax[1].set_ylabel(feat2)\n",
        "    ax[1].set_title('Chart '+feat2+' vs trend' )\n",
        "    ax[1].set_xlabel('months count')\n",
        "    ##### do here two charts density distribition\n",
        "    \n",
        "    ls=[feat2]\n",
        "    for method in methods:\n",
        "        corr=df[[feat1,feat2]].corr(method=method)\n",
        "        ls.append(corr[feat1][1])\n",
        "    corr_df.loc[len(corr_df)]=ls\n",
        "### ------------------------END SERVICE ROUTINES --------------------------------###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b8152ae4-1979-c2d1-93df-7fb8ca87eec5"
      },
      "source": [
        "##Macro-economic factors influence on House pricing in Moscow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e9927810-64e9-6f08-78e2-26f5fe3f14a1"
      },
      "outputs": [],
      "source": [
        "anlz_df['timestamp']=pd.to_datetime(anlz_df['timestamp'])\n",
        "anlz_df['mo_ye']=anlz_df['timestamp'].apply(lambda x: x.strftime('%m-%Y'))\n",
        "anlz_df['price_per_sqm']=anlz_df['price_doc']/anlz_df['full_sq']\n",
        "\n",
        "\n",
        "macro_columns = ['price_doc','price_per_sqm','full_sq','oil_urals', 'gdp_quart_growth', 'cpi', 'usdrub', \\\n",
        "                'salary_growth', 'unemployment', 'average_provision_of_build_contract_moscow', 'mortgage_rate', \\\n",
        "                 'deposits_rate','deposits_growth','rent_price_3room_eco',\\\n",
        "                 'rent_price_3room_bus']\n",
        "macro_df=pd.DataFrame(anlz_df.groupby('mo_ye')[macro_columns].mean())\n",
        "macro_df.reset_index(inplace=True)\n",
        "\n",
        "\n",
        "macro_df['mo_ye']=pd.to_datetime(macro_df['mo_ye'])\n",
        "macro_df=macro_df.sort_values(by='mo_ye')\n",
        "\n",
        "\n",
        "macro_df.reset_index(inplace=True)\n",
        "macro_df.drop(['index'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "45915c08-85e1-1c3c-c882-8ad69664bb8b"
      },
      "source": [
        "###Show influence of economical factors on housing prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cfb8cad5-d2be-d898-b130-01c1d094bd14"
      },
      "outputs": [],
      "source": [
        "corr_df=pd.DataFrame(columns=['feature','pearson', 'kendall', 'spearman'])\n",
        "corr=macro_df[macro_columns].corr(method='spearman')\n",
        "fig, ax = plt.subplots(figsize=(10,10))         # Sample figsize in inches\n",
        "sns.heatmap(corr, annot=True, linewidths=.5, ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dbfe30c2-4e77-90b0-c936-d776cb1536f1"
      },
      "outputs": [],
      "source": [
        "for feat in macro_columns:\n",
        "    if (feat=='price_doc'):\n",
        "        continue\n",
        "    plot_grouped_trends(macro_df,'price_doc',feat,corr_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9e23c20a-e119-64bc-5c50-16fdad0e483c"
      },
      "source": [
        "##Correlation Table of price_doc t by methods :'pearson', 'kendall', 'spearman'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f70b8812-30ee-0919-d673-81fadce66c6d"
      },
      "outputs": [],
      "source": [
        "print(corr_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "98853e52-14cb-cd51-58d2-db060b285115"
      },
      "outputs": [],
      "source": [
        "### Choose significant macroeconomical features by their correlation\n",
        "sig_macro_columns=['oil_urals', 'gdp_quart_growth', 'cpi', 'usdrub', \\\n",
        "                'salary_growth', 'unemployment', 'mortgage_rate', \\\n",
        "                 'deposits_rate','rent_price_3room_bus']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4cf4ee0a-49a0-6833-b84f-c0e70847eff8"
      },
      "source": [
        "#Part II-Data Engineenring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eb702804-757d-e81b-dff0-7c5ccd2b3d1f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# insert in the train data and test the significant macroeconomical features by month-year data\n",
        "\n",
        "\n",
        "train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
        "train['mo_ye']=train['timestamp'].apply(lambda x: x.strftime('%m-%Y'))\n",
        "#macro_df['mo_ye']=macro_df['mo_ye'].apply(lambda x: x.strftime('%m-%Y'))\n",
        "test_df = pd.read_csv(\"../input/test.csv\",parse_dates=['timestamp'])\n",
        "test_df['mo_ye']=test_df['timestamp'].apply(lambda x: x.strftime('%m-%Y'))\n",
        "macro=pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n",
        "macro['mo_ye'] = macro['timestamp'].apply(lambda x: x.strftime('%m-%Y'))\n",
        "\n",
        "for clmn in sig_macro_columns:\n",
        "    train[clmn] = train['mo_ye'].apply(condition_train, col=clmn)\n",
        "    test_df[clmn] = test_df['mo_ye'].apply(condition_test, col=clmn)\n",
        "  \n",
        "train=train.drop(['timestamp'],1) \n",
        "\n",
        "  \n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8286c012-7126-93b5-cc19-4e5dadd61415"
      },
      "outputs": [],
      "source": [
        "#free memory\n",
        "del(train_df)\n",
        "del(macro_df)\n",
        "del(anlz_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "149b903a-b484-b96e-6464-553cec00e79b"
      },
      "outputs": [],
      "source": [
        "## Initial clean train data\n",
        "from sklearn import model_selection, preprocessing\n",
        "\n",
        "x_train = train\n",
        "\n",
        "\n",
        "##  Encode categirical varaibles exclude 'mo_ye'\n",
        "for c in x_train.columns:\n",
        "    if c=='mo_ye':\n",
        "        continue\n",
        "    if x_train[c].dtype == 'object':\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(x_train[c].values))\n",
        "        x_train[c] = lbl.transform(list(train[c].values))\n",
        "x_train['mo_ye']=x_train['mo_ye'].apply(lambda x:  100*pd.to_datetime(x).year+pd.to_datetime(x).month)\n",
        "x_train['price_doc']=np.log1p(x_train['price_doc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0e5cd72b-3f1a-f35d-0840-79c9e06c2eb2"
      },
      "source": [
        "## Dealing with missed variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "519605cb-bbec-d287-9160-f91c2be47e11"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import TransformerMixin\n",
        "class DataFrameImputer(TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
        "        if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
        "        index=X.columns)\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        return X.fillna(self.fill)\n",
        "x_train = DataFrameImputer().fit_transform(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a9ad8b67-781e-defe-8b8c-bf5593d66db8"
      },
      "source": [
        "##Starting importance variables evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3b0d962a-6b81-117c-da52-8d442ed1cca8"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "import xgboost as xgb\n",
        "target = 'price_doc'\n",
        "IDcol = 'id'\n",
        "\n",
        "predictors = [x for x in x_train.columns if x not in [target, IDcol]]\n",
        "xgb_params = {\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 8,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'objective': 'reg:linear',\n",
        "    'eval_metric': 'rmse',\n",
        "    'silent': 1\n",
        "}\n",
        "train_matrix= xgb.DMatrix(x_train[predictors], x_train[target].values, feature_names=x_train[predictors].columns.values)\n",
        "model = xgb.train(dict(xgb_params, silent=1), train_matrix, num_boost_round=100)\n",
        "# plot the important features #\n",
        "importance = model.get_fscore()\n",
        "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
        "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
        "df['fscore'] =100* df['fscore'] / df['fscore'].max()\n",
        "df=df.sort_values(by=\"fscore\",ascending=False)\n",
        "df.head(50).plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(10, 10))\n",
        "\n",
        "plt.title('XGBoost Feature Importance( 50 significant)')\n",
        "\n",
        "#plt.annotate()\n",
        "plt.xlabel('relative importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ccc7ec1c-0ae9-f2c5-1a35-4c64ea38b59e"
      },
      "source": [
        "## Check model accuracy according to best parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d1321f82-816a-5e34-b899-506ec08c392e"
      },
      "source": [
        "Best parameters are searched by GridSearchCV on my Laptop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "311bb2ba-586c-99c2-7dff-197595b8a860"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "params = {\n",
        "\n",
        "          'n_estimators': 200,\n",
        "          'max_depth': 5,\n",
        "          'min_child_weight': 100,\n",
        "          'subsample': .9,\n",
        "          'gamma': 1,\n",
        "          'objective': 'reg:linear',\n",
        "          'colsample_bytree': .8,\n",
        "\n",
        "          'nthread':3,\n",
        "          'silent':1,\n",
        "          'seed':27\n",
        "         }\n",
        "\n",
        "train, test = train_test_split(x_train, test_size = 0.2)\n",
        "predictors=df['feature'][df['fscore']>0.5].tolist() ## take predictors which score values more as 1%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d0c88390-f690-8434-0657-af347ed0674b"
      },
      "outputs": [],
      "source": [
        "dtrain = xgb.DMatrix(train[predictors].values,train[target].values)\n",
        "dtest = xgb.DMatrix(test[predictors].values,test[target].values)\n",
        "alg=xgb.XGBClassifier(**params)\n",
        "xgb_param = alg.get_xgb_params()\n",
        "cvresult = xgb.cv(xgb_param, dtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=5,  \n",
        "                          metrics='rmse', early_stopping_rounds=50, verbose_eval=50)\n",
        "\n",
        "cvresult[['train-rmse-mean', 'test-rmse-mean']].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b7fc9897-4122-b8c1-89e7-788295100333"
      },
      "source": [
        "#Set Model for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7b2aa9bd-ffed-9687-67e9-e7067cc14158"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import  mean_squared_error\n",
        "watchlist=[(dtrain,'train')]\n",
        "num_round=600\n",
        "\n",
        "#bst = xgb.train(params, dtrain, num_round,verbose_eval=False)\n",
        "bst=xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_round)\n",
        "preds = bst.predict(dtest)\n",
        "\n",
        "err=(mean_squared_error(test[target].values, preds))\n",
        "print('MSE ={}'.format(err)) # No bad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d7f4a6aa-278b-a1d7-fc25-7078d1aad0af"
      },
      "source": [
        "#Part III Data Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6c2a49ec-f9a7-a268-8e08-c3b39383442c"
      },
      "source": [
        "### Test data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f35242ff-156f-21f1-7cf6-c8c1595b128c"
      },
      "outputs": [],
      "source": [
        "\n",
        "##  Encode categirical varaibles exclude 'mo_ye'\n",
        "for c in test_df.columns:\n",
        "    if c=='mo_ye':\n",
        "        continue\n",
        "    if test_df[c].dtype == 'object':\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(test_df[c].values))\n",
        "        test_df[c] = lbl.transform(list(test_df[c].values))\n",
        "test_df['mo_ye']=test_df['mo_ye'].apply(lambda x:  100*pd.to_datetime(x).year+pd.to_datetime(x).month)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2e7e7a62-d1bb-6118-96c6-c077c9fd2cb8"
      },
      "outputs": [],
      "source": [
        "#dealing with missed varaibles\n",
        "test_df=test_df.drop(['timestamp'],1) \n",
        "IdClm=test_df['id']\n",
        "#test_df = DataFrameImputer().fit_transform(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f2f4ed1-b428-75af-f095-2cdee63bd1e5"
      },
      "outputs": [],
      "source": [
        "test_df = DataFrameImputer().fit_transform(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7f344a07-1d7c-58af-f3c3-4eb856fc57d9"
      },
      "outputs": [],
      "source": [
        "dtrain = xgb.DMatrix(x_train[predictors].values,x_train[target].values)\n",
        "bst=xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_round)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4760ce6d-5440-78e0-c0da-d1ffa4d7c878"
      },
      "outputs": [],
      "source": [
        "\n",
        "dtest = xgb.DMatrix(test_df[predictors].values)\n",
        "predsr = bst.predict(dtest)\n",
        "predsr=np.expm1(predsr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "63c654b9-4d7f-3862-8dde-7a0a05237d99"
      },
      "outputs": [],
      "source": [
        "### Submiss output\n",
        "\n",
        "output=pd.DataFrame(data={'price_doc':predsr},index=test_df['id'].values)\n",
        "output.head(10)\n",
        "output.to_csv('my_submission6.csv',header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "720e4cd3-545d-2ad1-80a6-0a5e6af7cf3d"
      },
      "outputs": [],
      "source": [
        "print(output.head())"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}