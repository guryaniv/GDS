{"cells":[{"metadata":{"_uuid":"c58e637863e60ae2a9ae7e72eed105363da83d70"},"cell_type":"markdown","source":"<h1><center><font size=\"6\">Google Landmark Recogn. Challenge Data Exploration</font></center></h1>\n\n\n<img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/7456/logos/thumb76_76.png\" width=\"600\"></img>\n\n<a id='0'>Content</a>\n- <a href='#1'>Introduction</a>\n- <a href='#2'>Load packages</a>\n- <a href='#3'>Read the data</a>\n- <a href='#4'>Inspect the data</a>\n- <a href='#5'>Image paths</a>\n- <a href='#6'>Image thumbnails</a>\n- <a href='#7'>Extracting Exif data and GPS data</a>\n- <a href='#8'>Baseline submission</a>\n- <a href='#9'>References</a>"},{"metadata":{"_uuid":"8857e9557cc6e52e767511c2f9ccee9ade6e5e0d","_cell_guid":"31788f31-3312-4c35-b078-9fa93a1784e3"},"cell_type":"markdown","source":"# <a id=\"1\">Introduction</a>\n\nThis Kernel explore the **train** and **test** datasets from [Google Landmark Recognition Challenge](https://www.kaggle.com/c/landmark-recognition-challenge). References [1-2] were used as a starting point for this Kernel. As the images in the datasets will have to be downloaded in order to conduct an analysis on the images itselfs, the Kernel is not covering the image analysis part. We include code (from Reference [3]) that will allow one competitor to retrieve tags informations from the url images.   \n\nPlease feel free to **fork and further develop** this Kernel.   \n\n<img src=\"http://lh4.ggpht.com/-Szw4nwa8izg/StLpb6miB4I/AAAAAAAAAJk/cDTWbVgI4Lg/s1600/\" width=800></img>\n"},{"metadata":{"_uuid":"f1fcbd6d683ef259d4d9c25b1d71ce5a935bec34"},"cell_type":"markdown","source":"# <a id=\"2\">Load packages</a>"},{"metadata":{"_uuid":"223ec637d6df436cd5830e84d67a9b918a5fffb3","collapsed":true,"_cell_guid":"2ff8c3bc-0ffc-4ac2-b7f0-23c595217d7a","trusted":false},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import Image\nfrom IPython.core.display import HTML \nfrom PIL import Image\nfrom PIL.ExifTags import TAGS, GPSTAGS\nfrom urllib import request\nfrom io import BytesIO\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15246e0c92749a8f112db0b79aff7bee9d399706","_cell_guid":"09d77246-ddf9-462a-874b-60db0ae7c971"},"cell_type":"markdown","source":"# <a id=\"3\">Read the data </a>"},{"metadata":{"_uuid":"b8531a3f85639fd94c5aab2622078f9097009639","collapsed":true,"_cell_guid":"4394e47b-dc6e-4326-8736-9dbae4dfb48d","trusted":false},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\nsubmission = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"801506523f0c03a8d0a68df17b1830f743f4232b","_cell_guid":"e5cbb64b-c913-4ddf-8504-59172f777f44"},"cell_type":"markdown","source":"# <a id=\"4\">Inspect the data</a>"},{"metadata":{"_uuid":"8b1bc86f31892a410be23bce071210f6fa68db99","_cell_guid":"21991a15-a82d-4018-aae9-a50f2382c176"},"cell_type":"markdown","source":"## Data shape"},{"metadata":{"_uuid":"962c8a8ddf19734eb38dc8e8c53f962390d8fd3b","collapsed":true,"_cell_guid":"1a27f02c-6efc-40a7-88b7-6c48f744cc37","trusted":false},"cell_type":"code","source":"print(\"Train data shape -  rows:\",train_df.shape[0],\" columns:\", train_df.shape[1])\nprint(\"Test data size -  rows:\",test_df.shape[0],\" columns:\", test_df.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74a230e47e20871a309f3bccbba0b82e7b9c29ad","_cell_guid":"61c993fc-958a-470c-84c3-8830b435609d"},"cell_type":"markdown","source":"## Glimpse the data\n\nLet's inspect the train and test sets"},{"metadata":{"_uuid":"24b95f36a291b11bf4e9abab8c7364a953fc9107","collapsed":true,"_cell_guid":"ff4c5d7d-5564-4771-80d6-b7bbfa373a76","trusted":false},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b506b015958edb9b5ebf0131c8ba780d2c7c4770","_cell_guid":"7b1fef52-75b4-432c-903e-01f8735d0be2"},"cell_type":"markdown","source":"Train set has three columns, first being an id for the image, the second being an url for the image and the third the id of the landmark associated with the image."},{"metadata":{"_uuid":"119115cc22238feda4bf5b8ecd23df8e2ca398a9","collapsed":true,"_cell_guid":"a7fa6e69-040e-44dd-a203-8b70e72cdb48","trusted":false},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d9a4e885c0cd53368c7814084c299599144cea6","_cell_guid":"60323c58-dbe4-4555-85f6-ed4aa0189fc7"},"cell_type":"markdown","source":"Test set has two columns, first being an id for the image, the second being an url for the image."},{"metadata":{"_uuid":"a6d55f803bb490e8111d06769893551aa8a78a2b","_cell_guid":"b521c36d-ac90-44cd-b0a3-0185d83e63d4"},"cell_type":"markdown","source":"Let's see now the expected format for the submission file"},{"metadata":{"_uuid":"bd3487e52ea99de31190f181c5b4dfa73e8dbfaa","collapsed":true,"_cell_guid":"325a6c89-c52f-4ff7-ab48-92ad35d36ae3","trusted":false},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04b28a009f957914d9b287d4b20a45d1bc662784","_cell_guid":"1af2bf82-1548-45da-a777-033917fa9712"},"cell_type":"markdown","source":"Submission has two columns, first being an id for the image, the second being the landmark. This has two elements: an landmark id that is associated with the image and its corresponding confidence score. Some query images may contain no landmarks. For these, one can submit no landmark id (and no confidence score)."},{"metadata":{"_uuid":"b89057dbc89bb1595b56c0f8f812bc28f97efcb1","_cell_guid":"ec1d6264-a856-471f-b7b0-cf6594431bc2"},"cell_type":"markdown","source":"## Data quality\n\nLet's look into more details to the data quality\n\n\n### Train data quality\n\nLet's see if we do have missing values in the training set"},{"metadata":{"_uuid":"3eb99bbf7e692baab6d8906710167515d6f6096b","collapsed":true,"_cell_guid":"5de81df3-84da-4739-8a57-21bb717226bd","trusted":false},"cell_type":"code","source":"# missing data in training data set\nmissing = train_df.isnull().sum()\nall_val = train_df.count()\n\nmissing_train_df = pd.concat([missing, all_val], axis=1, keys=['Missing', 'All'])\nmissing_train_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"668a5d00fe7111a0e60f4d2a4cf7544a0053992e","_cell_guid":"8295c9c4-6339-49a2-8097-6af7c0d701af"},"cell_type":"markdown","source":"We see that we do not have any missing values (null values) in the training data\n\n### Test data quality\n\nLet's see if we do have missing values in the test set"},{"metadata":{"_uuid":"bc96c3dfa95ca4acde0cd5a9ca1cbded1c887308","collapsed":true,"_cell_guid":"86f899df-674f-42c4-b34c-ac1137d22e26","trusted":false},"cell_type":"code","source":"# missing data in training data set\nmissing = test_df.isnull().sum()\nall_val = test_df.count()\n\nmissing_test_df = pd.concat([missing, all_val], axis=1, keys=['Missing', 'All'])\nmissing_test_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c510dbf40d8cc681be42e04c9b35ad8b1fbe3aa7","_cell_guid":"c0831e7f-d231-46f6-8269-c0ab4a12f013"},"cell_type":"markdown","source":"We can see that we do not have any missing values (null values) in the test data\n\n\n## Unique values\n\nLet's inspect the train and test data to check now many unique values are\n"},{"metadata":{"_uuid":"6cbf75d18bd9935961eec46159681785c336502f","collapsed":true,"_cell_guid":"991d60d2-8bf4-441f-80eb-c32d55522d12","trusted":false},"cell_type":"code","source":"train_df.nunique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15ff7a4b3044119ee846a1f2bc5a543b89c406b1","_cell_guid":"eeea0d58-e114-47f8-8c50-db6a47c07130"},"cell_type":"markdown","source":"In the train dataset, there are only 14951 unique landmark_id data. All id's and url's are unique. \n\nLet's see now the test data to check now many unique values are"},{"metadata":{"_uuid":"3e776188f4093aacdbecddc272258ab465df80a5","collapsed":true,"_cell_guid":"ce8dce8f-fed4-484b-9de8-cd2dade28280","trusted":false},"cell_type":"code","source":"test_df.nunique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"726602643c83b3b2f4a4cbc55c8e158897c6906a","_cell_guid":"2d6b27b6-9228-4385-b0ce-12d8aaa5baf6"},"cell_type":"markdown","source":"All id's and url's are unique in the test data as well. Let's now check if we do have any id's or url's that are in both train and test set. "},{"metadata":{"_uuid":"33cd6d3010e9f47665815926cdcc351b508574e1","collapsed":true,"_cell_guid":"a30c0227-a0e4-48d8-87ec-7a7b8aacd55c","trusted":false},"cell_type":"code","source":"# concatenate train and test datasets\nconcatenated = pd.concat([train_df, test_df])\n# print the shape of the resulted data.frame\nconcatenated.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"843d02761b07a2cc3c9540c382847d6c90df9671","collapsed":true,"_cell_guid":"2b14be0d-b30a-435f-aa97-b6f5fc1a5290","trusted":false},"cell_type":"code","source":"concatenated.nunique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf01d88f7140eb844a50ca1fe3226080c086ba3b","_cell_guid":"9675dfa0-6d02-4b9a-a147-aabbfe3391de"},"cell_type":"markdown","source":"All id's and url's are unique for the concatenated data. That means we do not have any id's or url's from train dataset leaked in the test data set as well."},{"metadata":{"_uuid":"c96c8b6e9a2f83b621a298207135e784ccc1d95e","_cell_guid":"f378c0ff-685e-4cc0-97cc-6213f322f2ef"},"cell_type":"markdown","source":"## Landmarks\n\nWe already know how many distincts landmarks there are in the train set. Let's inspect now how many occurences are for these landscapes in the train set."},{"metadata":{"_uuid":"78b07d455000bf8e5d173c267cd163ed12c3f687","collapsed":true,"_cell_guid":"28bb9fa7-6917-450c-bb9a-b696bd8fc88c","trusted":false},"cell_type":"code","source":"plt.figure(figsize = (8, 8))\nplt.title('Landmark id density plot')\nsns.kdeplot(train_df['landmark_id'], color=\"tomato\", shade=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ebd49133896a324cc783e130af85a573d2097421","_cell_guid":"d0c7d2f1-de6d-4396-852c-1bbc5edfa6b2"},"cell_type":"markdown","source":"Let's represent the same data as a density plot"},{"metadata":{"_uuid":"afb8a7b134b3b53cc5f76e3f46a88eb154fcf422","collapsed":true,"_cell_guid":"658a7aa9-924b-4f66-bd0a-0b086d00b2cc","trusted":false},"cell_type":"code","source":"plt.figure(figsize = (8, 8))\nplt.title('Landmark id distribuition and density plot')\nsns.distplot(train_df['landmark_id'],color='green', kde=True,bins=100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f83e789b27a655cf6b595c65704995104ccfb94","_cell_guid":"107d1253-8d4b-48d4-b4db-89c1f8c21c43"},"cell_type":"markdown","source":"Let's look now to the most frequent landmarks in the train set and also to the least frequent landmarks."},{"metadata":{"_uuid":"3c23fa1896cabc8787cdbf04b08836a47432bd98","collapsed":true,"_cell_guid":"0449f719-d94f-455d-b5bf-2e53594e41e1","trusted":false},"cell_type":"code","source":"th10 = pd.DataFrame(train_df.landmark_id.value_counts().head(10))\nth10.reset_index(level=0, inplace=True)\nth10.columns = ['landmark_id','count']\nth10","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"938e2f9320ef3ddb1c2d6cccb29289d470afa916","_cell_guid":"867cbdf2-567e-4db4-b1f8-c686c62fe535"},"cell_type":"markdown","source":"Most frequent landmark has 50337 apparitions in train dataset."},{"metadata":{"_uuid":"c67107214d03f661d9c898cab450f946f0f28118","collapsed":true,"_cell_guid":"a508477a-52a8-4cbe-aaba-57bae6815567","trusted":false},"cell_type":"code","source":"# Plot the most frequent landmark occurences\nplt.figure(figsize = (6, 6))\nplt.title('Most frequent landmarks')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"landmark_id\", y=\"count\", data=th10,\n            label=\"Count\", color=\"darkgreen\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77359be8ddcb3a7e715dbd93e7ed4424907a7101","collapsed":true,"_cell_guid":"5d6dcdd0-eeff-49b2-a9d7-d4b9d906f988","trusted":false},"cell_type":"code","source":"tb10 = pd.DataFrame(train_df.landmark_id.value_counts().tail(10))\ntb10.reset_index(level=0, inplace=True)\ntb10.columns = ['landmark_id','count']\ntb10","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5615656c7e625088467ce32a6ff77686a1eb027","collapsed":true,"_cell_guid":"84d83ece-0a58-420d-a1fc-05de9ded2be6","trusted":false},"cell_type":"code","source":"# Plot the least frequent landmark occurences\nplt.figure(figsize = (6,6))\nplt.title('Least frequent landmarks')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"landmark_id\", y=\"count\", data=tb10,\n            label=\"Count\", color=\"orange\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9f2911803f9cbb4bf4a37a79dc1b4d191fd8b74","_cell_guid":"3769ac8c-4db4-4a19-abcc-a7c97a6fd629"},"cell_type":"markdown","source":"Least frequent landmarks have only one occurence in the train dataset."},{"metadata":{"_uuid":"ac1f984ecd7a05cf161539815f975e597c909095","_cell_guid":"3b8b5715-2027-4860-afd2-093cf77f7161"},"cell_type":"markdown","source":"# <a id=\"5\">Image paths</a>\n\nLet's check the image paths. When we first analyzed the images, we noticed that there are just few main repositories used. Let's try now to find the names of these repositories."},{"metadata":{"_uuid":"2a9fc9d598fd7eca81c0fcb28dc7e60ceba2de2b","collapsed":true,"_cell_guid":"f8f98127-1a4a-48f2-bce5-10255547ca78","trusted":false},"cell_type":"code","source":"# Extract repositories names for train data\nll = list()\nfor path in train_df['url']:\n    ll.append((path.split('//', 1)[1]).split('/', 1)[0])\ntrain_df['site'] = ll\n# Extract repositories names for test data\nll = list()\nfor path in test_df['url']:\n    ll.append((path.split('//', 1)[1]).split('/', 1)[0])\ntest_df['site'] = ll","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61689b831af15ccc7d66c35425a01052864fa02c","_cell_guid":"88465adc-db5b-4729-ba5c-7d8dc500e4f1"},"cell_type":"markdown","source":"Let's check the shape again for train and test datasets."},{"metadata":{"_uuid":"c61348057c3b7b5adf9021310d52705dd6d9bb50","collapsed":true,"_cell_guid":"b43f4ca1-3bf3-48a4-a112-b14c9ca4ede9","trusted":false},"cell_type":"code","source":"print(\"Train data shape -  rows:\",train_df.shape[0],\" columns:\", train_df.shape[1])\nprint(\"Test data size -  rows:\",test_df.shape[0],\" columns:\", test_df.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77833fe0317a8e4b7607ee7a452dec1a722d9c40","_cell_guid":"95119025-2758-4240-a279-84173f120535"},"cell_type":"markdown","source":"We added to train and test data sets one more column, `site`, storing the name of the image repository. Let's also glimpse the train and test again, to check on the new column values."},{"metadata":{"_uuid":"c3f9ceb115964223b13b9a34919bf706eee93c2f","collapsed":true,"_cell_guid":"1fb83371-6d8b-46c8-8c3f-c7667a026a32","trusted":false},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c064eb8113e4c96fa61463421ae5f6701a860c09","collapsed":true,"_cell_guid":"4930a375-f0f4-459b-ac74-428ab10e3df1","trusted":false},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a2e74019f89581f6a87cce4760ca55f1fb5f3c3","_cell_guid":"788fd7ce-442e-4f7e-b8ca-69dc41a63279"},"cell_type":"markdown","source":"Let's group now on `site` name. We process both the train and test data."},{"metadata":{"_uuid":"db1e0a181fbe666364bf314cbd54c6f005f3e7bb","collapsed":true,"_cell_guid":"55d99edc-e361-464b-93ff-2a40ff7e7cb6","trusted":false},"cell_type":"code","source":"train_site = pd.DataFrame(train_df.site.value_counts())\ntest_site = pd.DataFrame(test_df.site.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51c62161a0a39bfe4b5e83ee786d48ad9900297c","_cell_guid":"c769d429-6596-4eeb-af18-654bfe59be5c"},"cell_type":"markdown","source":"The sites in train data are:"},{"metadata":{"_uuid":"0fb04ba2e8c2afc18d29147b9952984a78081bf7","collapsed":true,"_cell_guid":"2c9e9c31-2d67-4f3e-9c5d-11fb051fd1de","trusted":false},"cell_type":"code","source":"train_site","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"343ac2ad1729805e1ad9296ec5ae67fe30164192","collapsed":true,"_cell_guid":"ef569b3f-6b36-4959-902c-f564402bdc87","trusted":false},"cell_type":"code","source":"# Plot the site occurences in the train dataset\ntrsite = pd.DataFrame(list(train_site.index),train_site['site'])\ntrsite.reset_index(level=0, inplace=True)\ntrsite.columns = ['Count','Site']\nplt.figure(figsize = (6,6))\nplt.title('Sites storing images - train dataset')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x = 'Site', y=\"Count\", data=trsite, color=\"blue\")\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c9f5327d8b615b3b56869b8f28d0219e55a2671","_cell_guid":"cf57ff39-c9ab-4017-9a8d-da9af9237918"},"cell_type":"markdown","source":"We can observe that most of the images in the train dataset are stored on 4 sites, *lh3.googleusercontent.com*, *lh4.googleusercontent.com*, *lh5.googleusercontent.com* and *lh6.googleusercontent.com*.\n\nThe sites in test dataset are:"},{"metadata":{"_uuid":"3a1097e5baafca324045c040181c01af801fff99","collapsed":true,"_cell_guid":"ac603c36-ba83-4e13-bb0d-1f6b36c07963","trusted":false},"cell_type":"code","source":"test_site","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b386d3c10ea9267b02bda43f61d6d64827290b60","collapsed":true,"_cell_guid":"ef2b85b1-4877-4026-91e5-995e2323ddc3","trusted":false},"cell_type":"code","source":"# Plot the site occurences in the test dataset\ntesite = pd.DataFrame(list(test_site.index),test_site['site'])\ntesite.reset_index(level=0, inplace=True)\ntesite.columns = ['Count','Site']\nplt.figure(figsize = (6,6))\nplt.title('Sites storing images - test dataset')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x = 'Site', y=\"Count\", data=tesite, color=\"magenta\")\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af3b1c374517d7a1f0a5e21659874144561872c3","_cell_guid":"73b99f58-44cb-473a-bc44-58cb8387cf96"},"cell_type":"markdown","source":"We can observe that most of the images in the test dataset are stored on one site, *lh3.googleusercontent.com*, which is also the one with most content stored for train dataset.\nLet's look now to the images."},{"metadata":{"_uuid":"d9e0cd518a41d4fcf7518a2ef6bc89433178dfda","_cell_guid":"a0bbe6e7-7282-4a97-87ff-5851b8864974"},"cell_type":"markdown","source":"# <a id=\"6\">Image thumbnails</a>\n\nLet's inspect also the images. We create a function to display a certain number of images, giving a list of images urls. We show here a number of `50` images of the `Petronas Twin Towers` in Kuala Lumpur, which is the 5th ranged landmark in the selection of landmarks, based on number of occurences.\n\nWe will define two functions to display landmarks.\n"},{"metadata":{"_uuid":"573ad34b2ba6077e5220b653850997fccb3ecc3c","collapsed":true,"_cell_guid":"cebd3f76-54f0-4173-a7be-dc7c20052cba","trusted":false},"cell_type":"code","source":"def displayLandmarkImages(urls):\n    \n    imageStyle = \"height: 60px; margin: 2px; float: left; border: 1px solid blue;\"\n    imagesList = ''.join([f\"<img style='{imageStyle}' src='{u}' />\" for _, u in urls.iteritems()])\n\n    display(HTML(imagesList))\n    \n    \ndef displayLandmarkImagesLarge(urls):\n    \n    imageStyle = \"height: 100px; margin: 2px; float: left; border: 1px solid blue;\"\n    imagesList = ''.join([f\"<img style='{imageStyle}' src='{u}' />\" for _, u in urls.iteritems()])\n\n    display(HTML(imagesList))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17929d555d9d46b95370969d1fd108ccb0e3495a","collapsed":true,"_cell_guid":"a4e292fd-ca45-42e1-8cb9-9f59355a8ced","trusted":false},"cell_type":"code","source":"IMAGES_NUMBER = 50\nlandmarkId = train_df['landmark_id'].value_counts().keys()[5]\nurls = train_df[train_df['landmark_id'] == landmarkId]['url'].head(IMAGES_NUMBER)\ndisplayLandmarkImages(urls)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca2176811b18ed189f421c843f5082033065d1b8","_cell_guid":"ec56ffca-b96e-4489-9608-0524a9db595a"},"cell_type":"markdown","source":"Let's visualize now 5 images for each of the first 5 landmarks, ordered by the number of occurences."},{"metadata":{"scrolled":false,"collapsed":true,"_uuid":"95c150f3771d1d4860caf7358d19415164e0e9be","_cell_guid":"1b74222c-de53-4d4e-8325-766eee1b2622","trusted":false},"cell_type":"code","source":"LANDMARK_NUMBER = 5\nIMAGES_NUMBER = 5\nlandMarkIDs = pd.Series(train_df['landmark_id'].value_counts().keys())[1:LANDMARK_NUMBER+1]\nfor landMarkID in landMarkIDs:\n    url = train_df[train_df['landmark_id'] == landMarkID]['url'].head(IMAGES_NUMBER)\n    displayLandmarkImagesLarge(url)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74e33696f70fd2a0ec13553d3798ed1e24c0b4fb","_cell_guid":"e75bb5ed-c777-4bc6-b5a2-98e4951bb840"},"cell_type":"markdown","source":"# <a id=\"7\">Extracting Exif data and GPS data</a>\n\nWe will not be able to use the following code with this Kernel (feel free to download it) because there are some missing libraries support. It is not actually allowed to stream image data (we are allowed to display images, thought) on Kaggle so two libraries that will help us to do this are missing. The original code is from Reference [3] with a small correction for the way the image data taken from [Anokas](https://www.kaggle.com/anokas)'s Kernel (Reference [4])."},{"metadata":{"_uuid":"3152c3d1efafdb1162bd936ec41d0bf621553d7f","collapsed":true,"_cell_guid":"0e547c25-d27f-4630-90b7-988a41e863f1","trusted":false},"cell_type":"code","source":"\nclass ImageMetaData(object):\n    '''\n    Extract the exif data from any image. Data includes GPS coordinates, \n    Focal Length, Manufacture, and more.\n    '''\n    exif_data = None\n    image = None\n\n    def __init__(self, img_path):\n        \n        response = request.urlopen(url)\n        image_data = response.read()\n        self.image = Image.open(BytesIO(image_data))\n        self.get_exif_data()\n        super(ImageMetaData, self).__init__()\n\n    def get_exif_data(self):\n        \"\"\"Returns a dictionary from the exif data of an PIL Image item. Also converts the GPS Tags\"\"\"\n        exif_data = {}\n        info = self.image._getexif()\n        if info:\n            for tag, value in info.items():\n                decoded = TAGS.get(tag, tag)\n                if decoded == \"GPSInfo\":\n                    gps_data = {}\n                    for t in value:\n                        sub_decoded = GPSTAGS.get(t, t)\n                        gps_data[sub_decoded] = value[t]\n\n                    exif_data[decoded] = gps_data\n                else:\n                    exif_data[decoded] = value\n        self.exif_data = exif_data\n        return exif_data\n\n    def get_if_exist(self, data, key):\n        if key in data:\n            return data[key]\n        return None\n\n    def convert_to_degress(self, value):\n\n        \"\"\"Helper function to convert the GPS coordinates \n        stored in the EXIF to degress in float format\"\"\"\n        d0 = value[0][0]\n        d1 = value[0][1]\n        d = float(d0) / float(d1)\n\n        m0 = value[1][0]\n        m1 = value[1][1]\n        m = float(m0) / float(m1)\n\n        s0 = value[2][0]\n        s1 = value[2][1]\n        s = float(s0) / float(s1)\n\n        return d + (m / 60.0) + (s / 3600.0)\n\n    def get_lat_lng(self):\n        \"\"\"Returns the latitude and longitude, if available, from the provided exif_data (obtained through get_exif_data above)\"\"\"\n        lat = None\n        lng = None\n        exif_data = self.get_exif_data()\n        #print(exif_data)\n        if \"GPSInfo\" in exif_data:      \n            gps_info = exif_data[\"GPSInfo\"]\n            gps_latitude = self.get_if_exist(gps_info, \"GPSLatitude\")\n            gps_latitude_ref = self.get_if_exist(gps_info, 'GPSLatitudeRef')\n            gps_longitude = self.get_if_exist(gps_info, 'GPSLongitude')\n            gps_longitude_ref = self.get_if_exist(gps_info, 'GPSLongitudeRef')\n            if gps_latitude and gps_latitude_ref and gps_longitude and gps_longitude_ref:\n                lat = self.convert_to_degress(gps_latitude)\n                if gps_latitude_ref != \"N\":                     \n                    lat = 0 - lat\n                lng = self.convert_to_degress(gps_longitude)\n                if gps_longitude_ref != \"E\":\n                    lng = 0 - lng\n        return lat, lng\n    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d0ff17d57725ca65503c2d3ebdca5d7b57fdfcc","_cell_guid":"c81e3047-75de-41b4-8d21-b99582583c34"},"cell_type":"markdown","source":"## Retrieve metadata example\n\nHere is an example of usage of the ImageMetaData function.\n\n> meta_data =  ImageMetaData(urls.head(1))  \n> latlng =meta_data.get_lat_lng()  \n> print(latlng)  \n> exif_data = meta_data.get_exif_data()  \n> print(exif_data)  \n"},{"metadata":{"_uuid":"ccbc7927b811be4aa91627117cb468cac09251c1","_cell_guid":"744b30a0-5056-46d0-91cf-526584c9d56c"},"cell_type":"markdown","source":"#  <a id=\"8\">Baseline submission</a>\n\nWe are using a random guess, normalized by the frequency in the training set to prepare a submission file. The solution is picked up from Kevin Mader's Kernel, [Baseline Landmark Model](ttps://www.kaggle.com/kmader/baseline-landmark-model).\n"},{"metadata":{"_uuid":"2846a59ff0b427c2cc6736b7a953698c64b3ce1b","collapsed":true,"_cell_guid":"aa447263-0e12-4ddf-8175-bea312e26100","trusted":false},"cell_type":"code","source":"# take the most frequent label\nfreq_label = train_df['landmark_id'].value_counts()/train_df['landmark_id'].value_counts().sum()\n\n# submit the most freq label\nsubmission['landmarks'] = '%d %2.2f' % (freq_label.index[0], freq_label.values[0])\nsubmission.to_csv('submission.csv', index=False)\n\nnp.random.seed(2018)\nr_idx = lambda : np.random.choice(freq_label.index, p = freq_label.values)\n\nr_score = lambda idx: '%d %2.4f' % (freq_label.index[idx], freq_label.values[idx])\nsubmission['landmarks'] = submission.id.map(lambda _: r_score(r_idx()))\nsubmission.to_csv('rand_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae6f9f59bd82b98f6aba03827332acbc6f2d824d","_cell_guid":"754a498a-c3b4-4fd5-9017-d5a3893d10a2"},"cell_type":"markdown","source":"#  <a id=\"9\">References</a>\n\n\n[1] Max Diebold, Simple exploration of Google Recognition,  https://www.kaggle.com/mxdbld/simple-exploration-of-google-recognition  \n[2] Ashok LathwalI, Introduction and overview,   https://www.kaggle.com/codename007/introduction-and-overview   \n[3] Extract GPS & Exif Data from Images using Python, https://www.codingforentrepreneurs.com/blog/extract-gps-exif-images-python/  \n[4] Python3 Dataset Downloader with progress bar, https://www.kaggle.com/anokas/python3-dataset-downloader-with-progress-bar  \n[5] Kevin Mader, Baseline Landmark Model, https://www.kaggle.com/kmader/baseline-landmark-model  \n\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}