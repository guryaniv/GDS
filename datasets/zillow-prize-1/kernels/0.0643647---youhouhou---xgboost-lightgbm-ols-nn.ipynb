{"cells": [{"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "59359d0c-e3ed-4d26-a5bd-fe2817ba428b", "_uuid": "c7ba28f460b0218169207dbccf3d9d43ee3382f1"}, "source": ["# Parameters\n", "FUDGE_FACTOR = 1.1200  # Multiply forecasts by this\n", "\n", "XGB_WEIGHT = 0.6200\n", "BASELINE_WEIGHT = 0.0100\n", "OLS_WEIGHT = 0.0620\n", "NN_WEIGHT = 0.0800\n", "\n", "XGB1_WEIGHT = 0.8000  # Weight of first in combination of two XGB models\n", "\n", "BASELINE_PRED = 0.0115   # Baseline based on mean of training data, per Oleg"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "089dd815-a561-4638-aafc-acbfc24eab33", "_kg_hide-input": false, "_uuid": "b6e0e6cd1e125f5b42a5804af49857475be2c313", "_kg_hide-output": false}, "source": ["#Import Lib#\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import xgboost as  xgb \n", "import random \n", "import lightgbm as lgb\n", "import datetime as dt \n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import gc\n", "from sklearn.linear_model import LinearRegression\n", "from sklearn.preprocessing import LabelEncoder \n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import r2_score"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "000dc011-ac3e-4e00-bac8-a747459cad03", "_uuid": "51231327470cf646b219212a2c7c86431a164459"}, "source": ["from keras.models import Sequential\n", "from keras.layers import Dense\n", "from keras.layers import Dropout, BatchNormalization\n", "from keras.layers.advanced_activations import PReLU\n", "from keras.layers.noise import GaussianDropout\n", "from keras.optimizers import Adam\n", "from keras.wrappers.scikit_learn import KerasRegressor\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.preprocessing import Imputer"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "122fd6ec-bdd8-4cb3-8fe6-3591af1e63e0", "_uuid": "67e139fb63551317191e820c5dd11147713ceb9e"}, "source": ["#Load data#\n", "train_2017 = pd.read_csv('../input/train_2017.csv',parse_dates = [\"transactiondate\"])\n", "train_2016 = pd.read_csv('../input/train_2016_v2.csv',parse_dates = [\"transactiondate\"])\n", "frames = [train_2016,train_2017]\n", "train = pd.concat(frames)\n", "properties = pd.read_csv('../input/properties_2017.csv')\n", "test = pd.read_csv('../input/sample_submission.csv') \n", "test = test.rename(columns = {'ParcelId': 'parcelid'})"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "615f3565-2e59-48a4-a827-4e75037139e6", "_uuid": "244b955abfc8800b03221a317a6d2d8f63aaa128"}, "source": ["\n", "print(\"Training Size:\" + str(train.shape))\n", "print(\"Property Size:\" + str(properties.shape))\n", "print(\"Sample Size:\" + str(test.shape))\n"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "a92d8e71-a68f-4c28-961e-282913b9c1b1", "_uuid": "56a90c695cb156768db366e73fd420dd677510e1"}, "source": ["################\n", "################\n", "##  LightGBM  ##\n", "################\n", "################\n", "\n", "# This section is (I think) originally derived from SIDHARTH's script:\n", "#   https://www.kaggle.com/sidharthkumar/trying-lightgbm\n", "# which was forked and tuned by Yuqing Xue:\n", "#   https://www.kaggle.com/yuqingxue/lightgbm-85-97\n", "# and updated by Andy Harless:\n", "#   https://www.kaggle.com/aharless/lightgbm-with-outliers-remaining\n", "# and a lot of additional changes have happened since then"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "9bfab682-16ed-45ce-9740-3b3a7fdd5853", "_uuid": "15e5c227e2b5445e6f0cd4a48a99e237ad7ebae7"}, "source": ["##### PROCESS DATA FOR LIGHTGBM\n", "print( \"\\nProcessing data for LightGBM ...\" )\n", "for c, dtype in zip(properties.columns, properties.dtypes):\n", "    if dtype == np.float64:\n", "        properties[c] = properties[c].astype(np.float32)\n", "        \n", "df_train = train.merge(properties, how='left', on='parcelid')\n", "df_train.fillna(df_train.median(),inplace = True)\n", "\n", "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', \n", "                         'propertycountylandusecode', 'fireplacecnt', 'fireplaceflag'], axis=1)\n", "y_train = df_train['logerror'].values\n", "print(x_train.shape, y_train.shape)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "3b338de8-26f6-4f85-997f-fb1586ee85bb", "_uuid": "ace81299ffd375170aa55e9a2baf604a5c802b9d"}, "source": ["train_columns = x_train.columns\n", "\n", "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n", "    x_train[c] = (x_train[c] == True)\n", "\n", "del df_train; gc.collect()\n", "\n", "x_train = x_train.values.astype(np.float32, copy=False)\n", "d_train = lgb.Dataset(x_train, label=y_train)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "dbb7fa3e-9a18-4fb5-95bd-0450cb349546", "_uuid": "28b136e8e2bbdfdb11e46e46c8c70e9cbadbd2a7"}, "source": ["##### RUN LIGHTGBM\n", "\n", "params = {}\n", "params['max_bin'] = 10\n", "params['learning_rate'] = 0.0021 # shrinkage_rate\n", "params['boosting_type'] = 'gbdt'\n", "params['objective'] = 'regression'\n", "params['metric'] = 'l1'          # or 'mae'\n", "params['sub_feature'] = 0.345    # feature_fraction (small values => use very different submodels)\n", "params['bagging_fraction'] = 0.85 # sub_row\n", "params['bagging_freq'] = 40\n", "params['num_leaves'] = 512        # num_leaf\n", "params['min_data'] = 500         # min_data_in_leaf\n", "params['min_hessian'] = 0.05     # min_sum_hessian_in_leaf\n", "params['verbose'] = 0\n", "params['feature_fraction_seed'] = 2\n", "params['bagging_seed'] = 3\n", "\n", "np.random.seed(0)\n", "random.seed(0)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "ab87ad3e-2f16-48a4-8ffb-15987d057299", "_uuid": "19de39c267a3f9750e5e797a27f8c6570912c8e9"}, "source": ["print(\"\\nFitting LightGBM model ...\")\n", "clf = lgb.train(params, d_train, 430)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "b0ba347a-57ea-4846-935a-16e7b264454a", "_uuid": "87b255f4ed0782ea79c3919a3524a2302f4cbcaf"}, "source": ["del d_train; gc.collect()\n", "del x_train; gc.collect()"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "8cbbefed-81a0-44d7-b8e3-f3b1b8b32f24", "_uuid": "314cb3cdd7cefe40d1808adc0cedee41066f029c"}, "source": ["print(\"\\nPrepare for LightGBM prediction ...\")\n", "print(\"   Read sample file ...\")\n", "sample = pd.read_csv('../input/sample_submission.csv')\n", "print(\"   ...\")\n", "sample['parcelid'] = sample['ParcelId']\n", "print(\"   Merge with property data ...\")\n", "df_test = sample.merge(properties, on='parcelid', how='left')\n", "print(\"   ...\")\n", "del sample, properties; gc.collect()\n", "print(\"   ...\")\n", "#df_test['Ratio_1'] = df_test['taxvaluedollarcnt']/df_test['taxamount']\n", "x_test = df_test[train_columns]\n", "print(\"   ...\")\n", "del df_test; gc.collect()\n", "print(\"   Preparing x_test...\")\n", "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n", "    x_test[c] = (x_test[c] == True)\n", "print(\"   ...\")\n", "x_test = x_test.values.astype(np.float32, copy=False)\n", "\n", "print(\"\\nStart LightGBM prediction ...\")\n", "p_test = clf.predict(x_test)\n", "\n", "del x_test; gc.collect()\n", "\n", "print( \"\\nUnadjusted LightGBM predictions:\" )\n", "print( pd.DataFrame(p_test).head() )\n"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "5d6c0c7e-fd83-4db7-930f-92ed73e73175", "_uuid": "00dadb3fdb3ccca036e203d124c238964e88c97b"}, "source": ["################\n", "################\n", "##  XGBoost   ##\n", "################\n", "################\n", "\n", "# This section is (I think) originally derived from Infinite Wing's script:\n", "#   https://www.kaggle.com/infinitewing/xgboost-without-outliers-lb-0-06463\n", "# inspired by this thread:\n", "#   https://www.kaggle.com/c/zillow-prize-1/discussion/33710\n", "# but the code has gone through a lot of changes since then"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "69b8be8a-0eb6-4f72-8821-e7f0804d0d75", "_uuid": "37393d526e1960165deacdce966a0e4b1307b4ed"}, "source": ["print( \"\\nRe-reading properties file ...\")\n", "properties = pd.read_csv('../input/properties_2017.csv')"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "a4691c8e-2504-4c8e-9d6d-ce136135c698", "_uuid": "5eacc94634fd94749267c2cf610fbe6baaa271d5"}, "source": ["##### PROCESS DATA FOR XGBOOST\n", "\n", "print( \"\\nProcessing data for XGBoost ...\")\n", "for c in properties.columns:\n", "    properties[c]=properties[c].fillna(-1)\n", "    if properties[c].dtype == 'object':\n", "        lbl = LabelEncoder()\n", "        lbl.fit(list(properties[c].values))\n", "        properties[c] = lbl.transform(list(properties[c].values))\n", "\n", "train_df = train.merge(properties, how='left', on='parcelid')\n", "x_train = train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\n", "x_test = properties.drop(['parcelid'], axis=1)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "e51653bd-6a34-40da-bf0d-57285ef3bd4c", "_uuid": "d99966f9fa7b583c097701fc2d3e2997a33abad8"}, "source": ["print('Shape train: {}\\nShape test: {}'.format(x_train.shape, x_test.shape))"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "75f291f6-4aec-4b15-9580-5d094a65c4cf", "_uuid": "7ec10d397fba70b0abca77439e0bf96c5d536c3f"}, "source": ["# drop out ouliers\n", "train_df=train_df[ train_df.logerror > -0.4 ]\n", "train_df=train_df[ train_df.logerror < 0.419 ]\n", "x_train=train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\n", "y_train = train_df[\"logerror\"].values.astype(np.float32)\n", "y_mean = np.mean(y_train)\n", "\n", "print('After removing outliers:')     \n", "print('Shape train: {}\\nShape test: {}'.format(x_train.shape, x_test.shape))"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "7b4c743d-2ad8-4e15-aed4-2e97d1a7fff0", "_uuid": "bf03461e5720946c0923279c214d0917a9721abf"}, "source": ["##### RUN XGBOOST\n", "\n", "print(\"\\nSetting up data for XGBoost ...\")\n", "# xgboost params\n", "xgb_params = {\n", "    'eta': 0.037,\n", "    'max_depth': 5,\n", "    'subsample': 0.80,\n", "    'objective': 'reg:linear',\n", "    'eval_metric': 'mae',\n", "    'lambda': 0.8,   \n", "    'alpha': 0.4, \n", "    'base_score': y_mean,\n", "    'silent': 1\n", "}"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "420e4927-80a6-4404-b523-b644508e4ce9", "_uuid": "fa86ec195132779df44b228ca63a3f8f051d1910"}, "source": ["dtrain = xgb.DMatrix(x_train, y_train)\n", "dtest = xgb.DMatrix(x_test)\n", "\n", "num_boost_rounds = 250\n", "print(\"num_boost_rounds=\"+str(num_boost_rounds))\n", "\n", "# train model\n", "print( \"\\nTraining XGBoost ...\")\n", "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n", "\n", "print( \"\\nPredicting with XGBoost ...\")\n", "xgb_pred1 = model.predict(dtest)\n", "\n", "print( \"\\nFirst XGBoost predictions:\" )\n", "print( pd.DataFrame(xgb_pred1).head() )"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "f855ddf1-47ae-4469-bc76-e756f2f50b65", "_uuid": "563840510539bf1118d65537f7b5edad64fcbb90"}, "source": ["print(\"\\nSetting up data for XGBoost ...\")\n", "# xgboost params\n", "xgb_params = {\n", "    'eta': 0.033,\n", "    'max_depth': 6,\n", "    'subsample': 0.80,\n", "    'objective': 'reg:linear',\n", "    'eval_metric': 'mae',\n", "    'base_score': y_mean,\n", "    'silent': 1\n", "}\n", "\n", "\n", "num_boost_rounds = 150\n", "print(\"num_boost_rounds=\"+str(num_boost_rounds))\n", "\n", "print( \"\\nTraining XGBoost again ...\")\n", "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n", "\n", "print( \"\\nPredicting with XGBoost again ...\")\n", "xgb_pred2 = model.predict(dtest)\n", "\n", "print( \"\\nSecond XGBoost predictions:\" )\n", "print( pd.DataFrame(xgb_pred2).head() )"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "72ee3a29-bfa9-4b82-91f6-cc312974f256", "_uuid": "951e7cefc58a4d0d3cd90c5cd831c942bc68a784"}, "source": ["##### COMBINE XGBOOST RESULTS\n", "xgb_pred = XGB1_WEIGHT*xgb_pred1 + (1-XGB1_WEIGHT)*xgb_pred2\n", "#xgb_pred = xgb_pred1\n", "\n", "print( \"\\nCombined XGBoost predictions:\" )\n", "print( pd.DataFrame(xgb_pred).head() )\n", "\n", "del train_df\n", "del x_train\n", "del x_test\n", "del properties\n", "del dtest\n", "del dtrain\n", "del xgb_pred1\n", "del xgb_pred2 \n", "gc.collect()"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "4235c674-f321-489d-9272-655e63e1b387", "_uuid": "cf49da3a167923796bb34ca0e4b5f46b1e8815c3"}, "source": ["######################\n", "######################\n", "##  Neural Network  ##\n", "######################\n", "######################\n", "\n", "# Neural network copied from this script:\n", "#   https://www.kaggle.com/aharless/keras-neural-network-lb-06492 (version 20)\n", "# which was built on the skeleton in this notebook:\n", "#   https://www.kaggle.com/prasunmishra/ann-using-keras"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "d9190be8-66fb-4399-b5c1-52075b7a8f82", "_uuid": "f4aa155f4370419dfbaf51e551ccd387f1f825b6"}, "source": ["# Read in data for neural network\n", "print( \"\\n\\nProcessing data for Neural Network ...\")\n", "print('\\nLoading train, prop and sample data...')\n", "train_2017 = pd.read_csv('../input/train_2017.csv',parse_dates = [\"transactiondate\"])\n", "train_2016 = pd.read_csv('../input/train_2016_v2.csv',parse_dates = [\"transactiondate\"])\n", "frames = [train_2016,train_2017]\n", "train = pd.concat(frames)\n", "prop = pd.read_csv('../input/properties_2017.csv')\n", "sample = pd.read_csv('../input/sample_submission.csv')"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "cc6894a2-3f7f-42fa-afd1-380e54806138", "_uuid": "8a872ef02a159d31f5749f0c6ed8691666895c9b"}, "source": ["print('Fitting Label Encoder on properties...')\n", "for c in prop.columns:\n", "    prop[c]=prop[c].fillna(-1)\n", "    if prop[c].dtype == 'object':\n", "        lbl = LabelEncoder()\n", "        lbl.fit(list(prop[c].values))\n", "        prop[c] = lbl.transform(list(prop[c].values))"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "fc5753e9-ecb9-4a31-b1ed-75ce26888c50", "_uuid": "0e5eec62940c8a2f204d8f955f928466ae041156"}, "source": ["print('Creating training set...')\n", "df_train = train.merge(prop, how='left', on='parcelid')\n", "\n", "df_train[\"transactiondate\"] = pd.to_datetime(df_train[\"transactiondate\"])\n", "df_train[\"transactiondate_year\"] = df_train[\"transactiondate\"].dt.year\n", "df_train[\"transactiondate_month\"] = df_train[\"transactiondate\"].dt.month\n", "df_train['transactiondate_quarter'] = df_train['transactiondate'].dt.quarter\n", "df_train[\"transactiondate\"] = df_train[\"transactiondate\"].dt.day"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "704a6ca7-d588-46e3-a811-821a78f61506", "_uuid": "8347b3f8fbf17f770377376478475ad389ab696c"}, "source": ["print('Filling NA/NaN values...' )\n", "df_train.fillna(-1.0)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "d7dec468-bdd2-45d8-88c2-c5f1c1887f24", "_uuid": "9332ff5fe65007982ab753e4daa79494814833e6"}, "source": ["print('Creating x_train and y_train from df_train...' )\n", "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode','fireplacecnt', 'fireplaceflag'], axis=1)\n", "y_train = df_train[\"logerror\"]"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "1c43e8c3-a1ff-4d4d-9b54-d69b20e060ba", "_uuid": "c60456919dc9b6eaf6a61405c118bdc68062bd95"}, "source": ["y_mean = np.mean(y_train)\n", "print(x_train.shape, y_train.shape)\n", "train_columns = x_train.columns\n", "\n", "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n", "    x_train[c] = (x_train[c] == True)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "c38d7149-a340-41ca-ab37-86b767fa8b42", "_uuid": "abc640f85773db8dc72fd5b2a974edaa23e0c3a6"}, "source": ["print('Creating df_test...')\n", "sample['parcelid'] = sample['ParcelId']\n", "\n", "print(\"Merging Sample with property data...\")\n", "df_test = sample.merge(prop, on='parcelid', how='left')\n", "\n", "df_test[\"transactiondate\"] = pd.to_datetime('2016-11-15')  # placeholder value for preliminary version\n", "df_test[\"transactiondate_year\"] = df_test[\"transactiondate\"].dt.year\n", "df_test[\"transactiondate_month\"] = df_test[\"transactiondate\"].dt.month\n", "df_test['transactiondate_quarter'] = df_test['transactiondate'].dt.quarter\n", "df_test[\"transactiondate\"] = df_test[\"transactiondate\"].dt.day     \n", "x_test = df_test[train_columns]"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "948ca1df-0124-4da3-8214-aeb5e9469955", "_uuid": "60d9d58a1e733a2b0b55702236deb1efe2ba4bab"}, "source": ["print('Shape of x_test:', x_test.shape)\n", "print(\"Preparing x_test...\")\n", "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n", "    x_test[c] = (x_test[c] == True)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "168971f7-8743-488b-a401-f21b8b8f00aa", "_uuid": "3b10a13f8af48edb7fb1ee05c7418f1ac85bb6ed"}, "source": ["## Preprocessing\n", "print(\"\\nPreprocessing neural network data...\")\n", "imputer= Imputer()\n", "imputer.fit(x_train.iloc[:, :])\n", "x_train = imputer.transform(x_train.iloc[:, :])\n", "imputer.fit(x_test.iloc[:, :])\n", "x_test = imputer.transform(x_test.iloc[:, :])\n", "\n", "sc = StandardScaler()\n", "x_train = sc.fit_transform(x_train)\n", "x_test = sc.transform(x_test)\n", "\n", "len_x=int(x_train.shape[1])\n", "print(\"len_x is:\",len_x)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "d642fa8c-d96d-4190-83ea-cb11b8054f36", "_uuid": "56a6b773a1d7268427dc2580967e63317954f5a1"}, "source": ["print(\"\\nSetting up neural network model...\")\n", "nn = Sequential()\n", "nn.add(Dense(units = 400 , kernel_initializer = 'normal', input_dim = len_x))\n", "nn.add(PReLU())\n", "nn.add(Dropout(.4))\n", "nn.add(Dense(units = 160 , kernel_initializer = 'normal'))\n", "nn.add(PReLU())\n", "nn.add(BatchNormalization())\n", "nn.add(Dropout(.6))\n", "nn.add(Dense(units = 64 , kernel_initializer = 'normal'))\n", "nn.add(PReLU())\n", "nn.add(BatchNormalization())\n", "nn.add(Dropout(.5))\n", "nn.add(Dense(units = 26, kernel_initializer = 'normal'))\n", "nn.add(PReLU())\n", "nn.add(BatchNormalization())\n", "nn.add(Dropout(.6))\n", "nn.add(Dense(1, kernel_initializer='normal'))\n", "nn.compile(loss='mae', optimizer=Adam(lr=4e-3, decay=1e-4))"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "7b85de4f-dcbf-4307-b62e-8f442eb6c957", "_uuid": "9b372280c49a20e7a893de7f73571a999551fc3d"}, "source": ["print(\"\\nFitting neural network model...\")\n", "nn.fit(np.array(x_train), np.array(y_train), batch_size = 32, epochs = 70, verbose=2)\n", "\n", "print(\"\\nPredicting with neural network model...\")\n", "#print(\"x_test.shape:\",x_test.shape)\n", "y_pred_ann = nn.predict(x_test)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "a2d55401-f178-435f-96d8-168d15ede8c2", "_uuid": "2bf3a3eef0732f0dcf9aaa803aa1ffbe32e5bf9d"}, "source": ["#transaction dateprint( \"\\nPreparing results for write...\" )\n", "nn_pred = y_pred_ann.flatten()\n", "print( \"Type of nn_pred is \", type(nn_pred) )\n", "print( \"Shape of nn_pred is \", nn_pred.shape )"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "97a00bb8-b336-4297-b3ba-0d7fee36a004", "_uuid": "65a03f030ec4e9bf410d69cb22313ba6a40af316"}, "source": ["# Cleanup\n", "del train\n", "del prop\n", "del sample\n", "del x_train\n", "del x_test\n", "del df_train\n", "del df_test\n", "del y_pred_ann\n", "gc.collect()"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "78678ebb-8cdf-4446-8532-04fb2080c59e", "_uuid": "7fa6b148277b981ddeb6e5b1e5036d4fc065460b"}, "source": ["################\n", "################\n", "##    OLS     ##\n", "################\n", "################\n", "\n", "# This section is derived from the1owl's notebook:\n", "#    https://www.kaggle.com/the1owl/primer-for-the-zillow-pred-approach\n", "# which I (Andy Harless) updated and made into a script:\n", "#    https://www.kaggle.com/aharless/updated-script-version-of-the1owl-s-basic-ols"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "bf58223c-cd65-4a59-a9a7-b190e93b6c60", "_uuid": "2f28ac1a7228c79d4c9db47e81036040ecc46f88"}, "source": ["np.random.seed(17)\n", "random.seed(17)\n", "\n", "print( \"\\n\\nProcessing data for OLS ...\")\n", "\n", "train_2017 = pd.read_csv('../input/train_2017.csv',parse_dates = [\"transactiondate\"])\n", "train_2016 = pd.read_csv('../input/train_2016_v2.csv',parse_dates = [\"transactiondate\"])\n", "frames = [train_2016,train_2017]\n", "train = pd.concat(frames)\n", "properties = pd.read_csv(\"../input/properties_2017.csv\")\n", "submission = pd.read_csv(\"../input/sample_submission.csv\")\n", "print(len(train),len(properties),len(submission))\n", "\n", "def get_features(df):\n", "    df[\"transactiondate\"] = pd.to_datetime(df[\"transactiondate\"])\n", "    df[\"transactiondate_year\"] = df[\"transactiondate\"].dt.year\n", "    df[\"transactiondate_month\"] = df[\"transactiondate\"].dt.month\n", "    df['transactiondate'] = df['transactiondate'].dt.quarter\n", "    df = df.fillna(-1.0)\n", "    return df"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "31eeaa32-8df8-47e4-9ad2-f1688fef4e32", "_uuid": "95a1cfe6f309baee38e3958d39ec44b8e78d98ec"}, "source": ["def MAE(y, ypred):\n", "    #logerror=log(Zestimate)\u2212log(SalePrice)\n", "    return np.sum([abs(y[i]-ypred[i]) for i in range(len(y))]) / len(y)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "5315a8cf-62b1-40d6-9ffa-2fc02dbad6fa", "_uuid": "d30170e249cbb5dba5aa7180fc9b69fa3c60b079"}, "source": ["train = pd.merge(train, properties, how='left', on='parcelid')\n", "y = train['logerror'].values\n", "test = pd.merge(submission, properties, how='left', left_on='ParcelId', right_on='parcelid')\n", "properties = [] #memory\n", "\n", "exc = [train.columns[c] for c in range(len(train.columns)) if train.dtypes[c] == 'O'] + ['logerror','parcelid']\n", "col = [c for c in train.columns if c not in exc]"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "3cc5d446-7abd-4f30-a5f2-d6bb65b97085", "_uuid": "0f7e1130bb5d10a4f87e5df6f3af0117096c538e"}, "source": ["train = get_features(train[col])\n", "test['transactiondate'] = '2016-01-01' #should use the most common training date\n", "test = get_features(test[col])"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "cd6ef9d1-8ad6-4b8a-959f-6944d85ccaba", "_uuid": "4c45d62200d79fafefa3a8e1a984e92ca93384b1"}, "source": ["print(\"\\nFitting OLS...\")\n", "reg = LinearRegression(n_jobs=-1)\n", "reg.fit(train, y); print('fit...')\n", "print(MAE(y, reg.predict(train)))\n", "train = [];  y = [] #memory\n", "\n", "test_dates = ['2016-10-01','2016-11-01','2016-12-01','2017-10-01','2017-11-01','2017-12-01']\n", "test_columns = ['201610','201611','201612','201710','201711','201712']"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "594423fe-364b-42eb-9901-0b5bf20cb65e", "_uuid": "be59f52eda04e92a8a1d112d75e586cf6210f89e"}, "source": ["########################\n", "########################\n", "##  Combine and Save  ##\n", "########################\n", "########################\n", "\n", "\n", "##### COMBINE PREDICTIONS\n", "\n", "print( \"\\nCombining XGBoost, LightGBM, NN, and baseline predicitons ...\" )\n", "lgb_weight = 1 - XGB_WEIGHT - BASELINE_WEIGHT - NN_WEIGHT - OLS_WEIGHT \n", "lgb_weight0 = lgb_weight / (1 - OLS_WEIGHT)\n", "xgb_weight0 = XGB_WEIGHT / (1 - OLS_WEIGHT)\n", "baseline_weight0 =  BASELINE_WEIGHT / (1 - OLS_WEIGHT)\n", "nn_weight0 = NN_WEIGHT / (1 - OLS_WEIGHT)\n", "pred0 = 0\n", "pred0 += xgb_weight0*xgb_pred\n", "pred0 += baseline_weight0*BASELINE_PRED\n", "pred0 += lgb_weight0*p_test\n", "pred0 += nn_weight0*nn_pred"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "922cd2ae-d183-4c67-99ae-f2a953bc0a73", "_uuid": "191e7225e95be0d4821eb44203d95c110a76353c"}, "source": ["print( \"\\nPredicting with OLS and combining with XGB/LGB/NN/baseline predicitons: ...\" )\n", "for i in range(len(test_dates)):\n", "    test['transactiondate'] = test_dates[i]\n", "    pred = FUDGE_FACTOR * ( OLS_WEIGHT*reg.predict(get_features(test)) + (1-OLS_WEIGHT)*pred0 )\n", "    submission[test_columns[i]] = [float(format(x, '.4f')) for x in pred]\n", "    print('predict...', i)\n", "    \n", "print( \"\\nWriting results to disk ...\" )\n", "submission.to_csv('1003_try.csv', index=False , float_format='%.4f')\n", "print( \"\\nFinished ...\")"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "9549843d-71db-43b2-ba42-26f0b49adeaa", "_uuid": "cc4bd29919e6abbee25b8e1393b06c0674c96553"}, "source": ["train_c = train.copy()\n", "train_c['trans_month'] = train_c['transactiondate'].dt.month\n", "cnt_srs = train_c['trans_month'].value_counts()\n", "plt.figure(figsize=(12,6))\n", "sns.barplot(cnt_srs.index, cnt_srs.values,alpha = 0.8)\n", "plt.xticks(rotation='vertical')\n", "plt.xlabel('Month of transaction', fontsize=12)\n", "plt.ylabel('Number of Occurrences', fontsize=12)\n", "plt.show()"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "c541f93b-31bd-48c1-8ef0-3a1427e38655", "_uuid": "097d7ce2dc29636a6523fb4e4f758a02f1581ff4"}, "source": ["#check number of Nulls in property dataset\n", "missing_df = properties.isnull().sum(axis=0).reset_index()\n", "missing_df.columns = ['column_name','missing_count']\n", "missing_df['missing_ratio'] = missing_df['missing_count'] / properties.shape[0]\n", "missing_filtered = missing_df.loc[missing_df['missing_ratio']>0.99]\n", "#eliminate columns that has too many null\n", "eliminate_list = missing_filtered['column_name'].values\n", "properties = properties.drop(eliminate_list,axis=1)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "adec7fbd-5c83-4b26-8d4d-da0620134146", "_uuid": "a8d758440ba11cfee982dca1b54c6a7946e9a8cc"}, "source": ["# for c in properties.columns.values:\n", "#     plt.figure(figsize=(12,6))\n", "#     sns.countplot(x=c, data=properties)\n", "#     plt.ylabel('Count', fontsize=12)\n", "#     plt.xlabel(c, fontsize=12)\n", "#     plt.xticks(rotation='vertical')\n", "#     plt.show()\n", "plt.figure(figsize=(12,6))\n", "sns.countplot(x='finishedsquarefeet12', data=properties)\n", "plt.ylabel('Count', fontsize=12)\n", "plt.xlabel(\"finishedsquarefeet12\", fontsize=12)\n", "plt.xticks(rotation='vertical')\n", "plt.show()"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "430f81c5-97b4-470b-ae16-822c92b80a6c", "_uuid": "676adb9b7235f4070a0c04bed2d455a345ba447c"}, "source": ["print('t')"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "845c41db-b3dc-4ed5-8387-ab93317af0c0", "_uuid": "660dd272479132bb395cb9edb7abaf143291ce26"}, "source": ["#convert datatype\n", "def convert_datatype(dataframe):\n", "    for c, dtype in zip(dataframe.columns, dataframe.dtypes):\n", "        if dtype == np.float64:\n", "            dataframe[c] = dataframe[c].astype(np.float32)\n", "        if dtype == np.int64:\n", "            dataframe[c] = dataframe[c].astype(np.int32)\n", "            \n", "convert_datatype(properties)\n", "convert_datatype(test)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "ed303344-6616-462e-aaba-d05113f51091", "_uuid": "0d05968943886e43d46dff16e4630a073db3a521"}, "source": ["#living area proportions \n", "properties['living_area_prop'] = properties['calculatedfinishedsquarefeet'] / \\\n", "properties['lotsizesquarefeet']\n", "#tax value ratio\n", "properties['value_ratio'] = properties['taxvaluedollarcnt'] / properties['taxamount']\n", "#tax value proportions\n", "properties['value_prop'] = properties['structuretaxvaluedollarcnt'] /\\\n", "properties['landtaxvaluedollarcnt']"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "10ae842e-8edf-4710-b1c7-10eab0b0e8b8", "_uuid": "c64b9bec5ec0c274ddccc0232ab7cb7a4578d9f7"}, "source": ["#mergeing datasets\n", "df_train = train.merge(properties, how='left', on='parcelid')\n", "df_test = test.merge(properties, how='left', on='parcelid')"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "86c0e104-1f60-4cdd-bff1-db0c3b4c92a9", "_uuid": "3447824bed10701c5d6b78bb4c5807eb911224c2"}, "source": ["print(df_train.shape,train.shape,properties.shape)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "3c8c8fdb-98d5-4828-bfdb-c0cf22882de4", "_uuid": "07e3cfd2517060eac60b6c5d04f308fb5a2265ca"}, "source": ["#change missing values into 0\n", "#change categorical into to numerical\n", "\n", "def convert_label(dataframe):\n", "    lbI = LabelEncoder()\n", "    for c in dataframe.columns:\n", "        dataframe[c] = dataframe[c].fillna(0)\n", "        if dataframe[c].dtype == 'object':\n", "            lbI.fit(list(dataframe[c].values))\n", "            dataframe[c] = lbI.transform(list(dataframe[c].values))\n", "\n", "convert_label(df_train)\n", "convert_label(df_test)\n", "\n"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "679fb70b-88f5-4e24-a0a8-27f4fc1a99cb", "_uuid": "c6a75c526a242cd341267a7e8d5f59dc50b8c801"}, "source": ["#re-arranging \n", "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', \n", "                         'propertycountylandusecode', ], axis=1)\n", "x_test = df_test.drop(['parcelid', 'propertyzoningdesc',\n", "                       'propertycountylandusecode', '201610', '201611', \n", "                       '201612', '201710', '201711', '201712'], axis = 1) \n", "x_train = x_train.values\n", "y_train = df_train['logerror'].values"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "745f394a-1643-41c3-85d5-57d631b273cc", "_uuid": "40b057a28ac06d339c44e47a5b93df11ab330826"}, "source": ["from datetime import datetime\n", "\n"], "outputs": []}], "metadata": {"language_info": {"nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.1", "pygments_lexer": "ipython3", "file_extension": ".py", "name": "python", "mimetype": "text/x-python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat_minor": 1, "nbformat": 4}