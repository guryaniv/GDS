{"nbformat": 4, "cells": [{"source": ["This notebook provides additional information about stage1_train dataset that should help to balance into train/valid for cross-validation. \n", "\n", "It starts from this interesting [thread](https://www.kaggle.com/c/data-science-bowl-2018/discussion/47640) about image types. Group A are histological slides, group B are fluorescent images, and group C are bright-field images. It can complete this other [kernel](https://www.kaggle.com/nhargan/defining-microscopy-type).\n", "\n", "It looks we have the following breakdown:\n", "* fluorescent: 81.5%\n", "* histological: 16.1%\n", "* bright-field: 2.4%"], "cell_type": "markdown", "metadata": {"_cell_guid": "3d54c5e7-943f-4f3a-8439-5adaec34c3ad", "_uuid": "41e8768a852e7119e8f443b7e36da2d737f603dc"}}, {"metadata": {"_cell_guid": "1a7d1b6f-caf0-4f08-91e1-1033a03faa37", "collapsed": true, "_uuid": "e956727b1c0d4773f5d5b0d15c39e7504c55236a"}, "outputs": [], "source": ["import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import skimage.io\n", "import os\n", "import shutil\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.cluster import KMeans\n", "from textwrap import wrap\n", "np.random.seed(1234)\n", "%matplotlib inline"], "cell_type": "code", "execution_count": 11}, {"source": ["Initial variables."], "cell_type": "markdown", "metadata": {"_cell_guid": "be1dadef-d349-4f5f-a97e-5520ad71364f", "_uuid": "14a44751e8f2e1dfd3bf5750155e8fe378b8303c"}}, {"metadata": {"_cell_guid": "d60e3327-2d7f-4103-b6ba-1835a16e3aa7", "collapsed": true, "_uuid": "ad6bb080218a350877fdcc9e02ed2128c6dd4e3b"}, "outputs": [], "source": ["STAGE1_TRAIN = \"../input/stage1_train\"\n", "STAGE1_TRAIN_IMAGE_PATTERN = \"%s/{}/images/{}.png\" % STAGE1_TRAIN\n", "STAGE1_TRAIN_MASK_PATTERN = \"%s/{}/masks/*.png\" % STAGE1_TRAIN\n", "IMAGE_ID = \"image_id\"\n", "IMAGE_WIDTH = \"width\"\n", "IMAGE_WEIGHT = \"height\"\n", "HSV_CLUSTER = \"hsv_cluster\"\n", "HSV_DOMINANT = \"hsv_dominant\"\n", "TOTAL_MASK = \"total_masks\""], "cell_type": "code", "execution_count": 12}, {"source": ["Functions to load images. We keep only RGB channels as Alpha channel is always empty. "], "cell_type": "markdown", "metadata": {"_cell_guid": "5c7cb57e-2730-4c17-b221-e0b26019e113", "_uuid": "2e5853f177298d5a9a2538f514c03848ae1a7556"}}, {"metadata": {"_cell_guid": "ef7ac493-ac70-4f79-9c95-2111e91d0122", "collapsed": true, "_uuid": "446f686631a0f3dfe7ff12724caf6dd888872767"}, "outputs": [], "source": ["def image_ids_in(root_dir, ignore=[]):\n", "    ids = []\n", "    for id in os.listdir(root_dir):\n", "        if id in ignore:\n", "            print('Skipping ID:', id)\n", "        else:\n", "            ids.append(id)\n", "    return ids"], "cell_type": "code", "execution_count": 13}, {"metadata": {"_cell_guid": "f048dcb8-a660-4e48-9c4f-c571467cc77d", "collapsed": true, "_uuid": "7a5b01078bdf9388692ab9b39403db613dc80f57"}, "outputs": [], "source": ["def read_image(image_id, space=\"rgb\"):\n", "    image_file = STAGE1_TRAIN_IMAGE_PATTERN.format(image_id, image_id)\n", "    image = skimage.io.imread(image_file)\n", "    # Drop alpha which is not used\n", "    image = image[:, :, :3]\n", "    if space == \"hsv\":\n", "        image = skimage.color.rgb2hsv(image)\n", "    return image"], "cell_type": "code", "execution_count": 14}, {"metadata": {"_cell_guid": "e708a584-4148-47dc-a808-0c25c270a6fa", "collapsed": true, "_uuid": "de172cc7bb74e907a4008dd96a6893564fa2ed83"}, "outputs": [], "source": ["# Get image width, height and count masks available.\n", "def read_image_labels(image_id, space=\"rgb\"):\n", "    image = read_image(image_id, space = space)\n", "    mask_file = STAGE1_TRAIN_MASK_PATTERN.format(image_id)\n", "    masks = skimage.io.imread_collection(mask_file).concatenate()    \n", "    height, width, _ = image.shape\n", "    num_masks = masks.shape[0]\n", "    labels = np.zeros((height, width), np.uint16)\n", "    for index in range(0, num_masks):\n", "        labels[masks[index] > 0] = 255 #index + 1\n", "    return image, labels, num_masks"], "cell_type": "code", "execution_count": 15}, {"metadata": {"_cell_guid": "3ad318a0-df14-453b-a3ea-98fd3e5a560c", "collapsed": true, "_uuid": "5cafd4671fd072f2ed77be4b9b0cb6fe44b55d71"}, "outputs": [], "source": ["# Load stage 1 image identifiers.\n", "train_image_ids = image_ids_in(STAGE1_TRAIN)"], "cell_type": "code", "execution_count": 16}, {"source": ["Run KMeans on each image. Centroids provide dominant colors (based on provided colorspace). More details [here](https://www.pyimagesearch.com/2014/05/26/opencv-python-k-means-color-clustering/)."], "cell_type": "markdown", "metadata": {"_cell_guid": "212f2e72-1319-4007-b94f-2f2099916c33", "_uuid": "e9fe244236aa525307fe7cff156b5b03cd6608b4"}}, {"metadata": {"_cell_guid": "c7e8881a-26de-40e9-baf3-dfbff94a2020", "collapsed": true, "_uuid": "62ba0f22a5bfe4d858e038dcffe64e80434f88ac"}, "outputs": [], "source": ["def get_domimant_colors(img, top_colors=2):\n", "    img_l = img.reshape((img.shape[0] * img.shape[1], img.shape[2]))\n", "    clt = KMeans(n_clusters = top_colors)\n", "    clt.fit(img_l)\n", "    # grab the number of different clusters and create a histogram\n", "    # based on the number of pixels assigned to each cluster\n", "    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n", "    (hist, _) = np.histogram(clt.labels_, bins = numLabels)\n", "    # normalize the histogram, such that it sums to one\n", "    hist = hist.astype(\"float\")\n", "    hist /= hist.sum()\n", "    return clt.cluster_centers_, hist"], "cell_type": "code", "execution_count": 17}, {"metadata": {"_cell_guid": "2ab3394a-c48e-414e-bff4-4c64e5ba34ad", "collapsed": true, "_uuid": "6ce9724fff3df5c79d8c96b7a2777a6c2f88b29c"}, "outputs": [], "source": ["def get_images_details(image_ids):\n", "    details = []\n", "    for image_id in image_ids:\n", "        image_hsv, labels, num_masks = read_image_labels(image_id, space=\"hsv\")\n", "        height, width, l = image_hsv.shape\n", "        dominant_colors_hsv, dominant_rates_hsv = get_domimant_colors(image_hsv, top_colors=1)\n", "        dominant_colors_hsv = dominant_colors_hsv.reshape(1, dominant_colors_hsv.shape[0] * dominant_colors_hsv.shape[1])\n", "        info = (image_id, width, height, num_masks, dominant_colors_hsv.squeeze())\n", "        details.append(info)\n", "    return details"], "cell_type": "code", "execution_count": 18}, {"metadata": {"_cell_guid": "1bf93ca6-9290-4cd9-b83b-0fcb060b0aa1", "collapsed": true, "_uuid": "fdd651473bc88a54e83461d43700f8b1ed4df4d2"}, "outputs": [], "source": ["META_COLS = [IMAGE_ID, IMAGE_WIDTH, IMAGE_WEIGHT, TOTAL_MASK]\n", "COLS = META_COLS + [HSV_DOMINANT]"], "cell_type": "code", "execution_count": 19}, {"metadata": {"_cell_guid": "2efae9d3-6982-4a90-bcc5-8d49459f55f0", "_uuid": "9f9d246d5526956d52860a1473d38b235e8d20ea"}, "outputs": [], "source": ["details = get_images_details(train_image_ids)"], "cell_type": "code", "execution_count": 20}, {"source": ["KMeans to split images by 3 types (based on dominant HSV colors distributions)"], "cell_type": "markdown", "metadata": {"_cell_guid": "67b2d543-4870-46a3-a730-a96160c0670e", "_uuid": "df4259174bc35696907360463b447acd69e57b4d"}}, {"metadata": {"_cell_guid": "c9d4521b-1465-498d-a8c8-28fead37bc83", "collapsed": true, "_uuid": "5023956cc6f71995c026904edaab5e488235abbc"}, "outputs": [], "source": ["trainPD = pd.DataFrame(details, columns=COLS)\n", "X = (pd.DataFrame(trainPD[HSV_DOMINANT].values.tolist())).as_matrix()\n", "kmeans = KMeans(n_clusters=3).fit(X)\n", "clusters = kmeans.predict(X)\n", "trainPD[HSV_CLUSTER] = clusters"], "cell_type": "code", "execution_count": 21}, {"metadata": {"_cell_guid": "5a0c10c7-276f-45c1-9b85-6d19394eeebb", "_uuid": "634a4a0e5b4d501125db53db2d038f581e227fc2"}, "outputs": [], "source": ["trainPD.head()"], "cell_type": "code", "execution_count": 22}, {"source": ["Plot some examples for each cluster."], "cell_type": "markdown", "metadata": {"_cell_guid": "417a250a-6335-4187-bcb5-0cbe9a86e7bf", "_uuid": "78389296675293d4ca4e90a5322257e6d697c0c6"}}, {"metadata": {"_cell_guid": "e36ed873-2fe3-4b10-a028-e0346e986a5a", "collapsed": true, "_uuid": "f31915126cb946367a09dff4af610daddb28289f"}, "outputs": [], "source": ["def plot_images(images, images_rows, images_cols):\n", "    f, axarr = plt.subplots(images_rows,images_cols,figsize=(16,images_rows*2))\n", "    for row in range(images_rows):\n", "        for col in range(images_cols):\n", "            image_id = images[row*images_cols + col]\n", "            image = read_image(image_id)\n", "            height, width, l = image.shape\n", "            ax = axarr[row,col]\n", "            ax.axis('off')\n", "            ax.set_title(\"%dx%d\"%(width, height))\n", "            ax.imshow(image)"], "cell_type": "code", "execution_count": 23}, {"source": ["Some examples of cluster 0 (fluorescent images):"], "cell_type": "markdown", "metadata": {"_cell_guid": "d6330c36-9405-4a03-8c3e-df4df3dc4b67", "_uuid": "6d1e4caa3ce0b2e996fce782357bcbeadffe59c4"}}, {"metadata": {"_cell_guid": "ba75d4ff-fad1-4d63-b69e-0f026dc6c2a4", "_uuid": "a86a4784016e547a617772c1b16873a13a42201c"}, "outputs": [], "source": ["plot_images(trainPD[trainPD[HSV_CLUSTER] == 0][IMAGE_ID].values, 6, 8)"], "cell_type": "code", "execution_count": 24}, {"source": ["Some examples of cluster 1 (histological slides):"], "cell_type": "markdown", "metadata": {"_cell_guid": "c32e0c25-59d6-410f-8a61-2d8f39a14e68", "_uuid": "e8a545f4ec8e614e3db9933d40508d4cb5e6113e"}}, {"metadata": {"_cell_guid": "cb25eec6-b06c-4d54-8d38-5407a5d80fcc", "_uuid": "eae8b54e3581da38cc781aa5fb5e5e9baa6e565f"}, "outputs": [], "source": ["plot_images(trainPD[trainPD[HSV_CLUSTER] == 1][IMAGE_ID].values, 6, 8)"], "cell_type": "code", "execution_count": 25}, {"source": ["Some examples of cluster 2 (bright-field images):"], "cell_type": "markdown", "metadata": {"_cell_guid": "f9068df6-cf2f-445e-a094-95992b39de94", "_uuid": "abd7bcdf2d7007a8c6170f95384779354e06544e"}}, {"metadata": {"_cell_guid": "4062d8ce-fbdb-40f0-b908-fc401f3d8d6a", "_uuid": "18d550d159db567f6e2fc73779c0a243e1ab4b1b"}, "outputs": [], "source": ["plot_images(trainPD[trainPD[HSV_CLUSTER] == 2][IMAGE_ID].values, 2, 8)"], "cell_type": "code", "execution_count": 26}, {"metadata": {"_cell_guid": "8739279e-5467-47da-b5e0-42c71bcb06db", "_uuid": "d67a27a2c705a1d69b4fd451b7804e404843a5b1"}, "outputs": [], "source": ["P = trainPD.groupby(HSV_CLUSTER)[IMAGE_ID].count().reset_index()\n", "P['Percentage'] = 100*P[IMAGE_ID]/P[IMAGE_ID].sum()\n", "P"], "cell_type": "code", "execution_count": 27}, {"metadata": {"_cell_guid": "171a168f-fc40-41fb-85f2-5f9b6df81fc6", "_uuid": "d5d3859ffb0b8539c713bbcf4865dcf81ea7682d"}, "outputs": [], "source": ["f, ax = plt.subplots(1,1,figsize=(16,5))\n", "r = trainPD.plot(kind=\"hist\", bins=300, y = TOTAL_MASK, ax=ax, grid=True, title=\"Masks Histogram\")"], "cell_type": "code", "execution_count": 28}, {"source": ["Plot some images with masks:"], "cell_type": "markdown", "metadata": {"_cell_guid": "5b834ecc-d66c-4b38-be9e-47810f5a1e60", "_uuid": "9e8b0462235067ddfbaf9f11e6338591971e2f5d"}}, {"metadata": {"_cell_guid": "80cc8170-5b37-4081-84a3-69b10a9f3833", "collapsed": true, "_uuid": "72d8764ba687420a7915cc7cac3de347157351d4"}, "outputs": [], "source": ["def plot_image_masks(image, labels, num_masks, image_id):\n", "    f, ax = plt.subplots(1,3,figsize=(16,5))\n", "    d = ax[0].axis('off')\n", "    d = ax[0].imshow(image)\n", "    d = ax[0].set_title(\"\\n\".join(wrap(image_id, 32)))\n", "    d = ax[1].axis('off')\n", "    d = ax[1].imshow(labels)\n", "    d = ax[1].set_title(\"masks: %d\"%num_masks)\n", "    d = ax[2].axis('off')\n", "    d = ax[2].imshow(image)\n", "    d = ax[2].imshow(labels, alpha=0.5)\n", "    d = ax[2].set_title(\"both\")"], "cell_type": "code", "execution_count": 29}, {"metadata": {"_cell_guid": "59b2bacb-bfc5-484f-ba4c-823695ec2fd8", "collapsed": true, "_uuid": "dad6835537069f7c9475a937e90855ca7f4ff797"}, "outputs": [], "source": ["def display_image_masks(image_id):\n", "    image, labels, num_masks = read_image_labels(image_id)\n", "    plot_image_masks(image, labels, num_masks, image_id)"], "cell_type": "code", "execution_count": 30}, {"metadata": {"_cell_guid": "83cadcda-df35-4c0c-a3d7-7a1da2215f69", "_uuid": "d61c34dc38ee50f2c7749767afbdc7fd2e456789"}, "outputs": [], "source": ["display_image_masks(\"8f27ebc74164eddfe989a98a754dcf5a9c85ef599a1321de24bcf097df1814ca\")"], "cell_type": "code", "execution_count": 31}, {"metadata": {"_cell_guid": "c2dd2866-e73a-40e6-a8a9-ed5b64b28ede", "_uuid": "ce2d9a90cd6dbde1350932009d497a73b1b40222"}, "outputs": [], "source": ["display_image_masks(trainPD[trainPD[TOTAL_MASK] == trainPD[TOTAL_MASK].median()][IMAGE_ID].values[0])"], "cell_type": "code", "execution_count": 32}, {"metadata": {"_cell_guid": "a014d789-7347-4156-a7cd-749db288de55", "_uuid": "9c8738bbefa422fd2ce2acbb445dc7923948f953"}, "outputs": [], "source": ["display_image_masks(trainPD[trainPD[TOTAL_MASK] == trainPD[TOTAL_MASK].min()][IMAGE_ID].values[0])"], "cell_type": "code", "execution_count": 33}, {"metadata": {}, "outputs": [], "source": ["display_image_masks(trainPD[trainPD[TOTAL_MASK] == trainPD[TOTAL_MASK].max()][IMAGE_ID].values[0])"], "cell_type": "code", "execution_count": 34}], "nbformat_minor": 1, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"version": "3.6.4", "name": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python"}}}