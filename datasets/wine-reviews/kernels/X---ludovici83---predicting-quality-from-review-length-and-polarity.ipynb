{"cells": [{"metadata": {"_uuid": "98e7ca4ff73c743642eac3b283439bd39d81089c", "_cell_guid": "c902d241-600a-4fac-9cc0-58f8f7b5f8e3", "collapsed": true}, "source": ["# In this notebook, we will use the polarity and length (measured as the number of words)\n", "# of the reviews as predictor variables for the quality of a wine. We will try out several\n", "# classifiers and calculate the metrics that give us a taste of their performance\n", "from __future__ import unicode_literals\n", "from textblob import TextBlob\n", "import pandas as pd\n", "import nltk\n", "import numpy as np\n"], "cell_type": "code", "outputs": [], "execution_count": 1}, {"metadata": {"collapsed": true}, "source": ["wine = pd.read_csv(\"../input/winemag-data_first150k.csv\",sep=\",\")"], "cell_type": "code", "outputs": [], "execution_count": 2}, {"metadata": {"collapsed": true}, "source": ["wine = wine.drop_duplicates()\n", "wine= wine.dropna()"], "cell_type": "code", "outputs": [], "execution_count": 3}, {"metadata": {"collapsed": true}, "source": ["def polarity_function(review):#measures polarity of wine description\n", "    opinion_wine=TextBlob(review)\n", "    return opinion_wine.sentiment.polarity\n", "\n", "def subjectivity_function(review): #measures subjectivity of wine description\n", "    opinion_wine=TextBlob(review)\n", "    return opinion_wine.sentiment.subjectivity\n", "\n", "def words_function(review): #\u00a0measures the length of the wine description by number of words\n", "    t=TextBlob(review)\n", "    return len(t.words)"], "cell_type": "code", "outputs": [], "execution_count": 4}, {"metadata": {"collapsed": true}, "source": ["wine['polarity']= wine.description.apply(polarity_function)"], "cell_type": "code", "outputs": [], "execution_count": 5}, {"metadata": {"collapsed": true}, "source": ["wine['subjectivity']= wine.description.apply(subjectivity_function)"], "cell_type": "code", "outputs": [], "execution_count": 6}, {"metadata": {"collapsed": true}, "source": ["wine['num_words'] = wine.description.apply(words_function)"], "cell_type": "code", "outputs": [], "execution_count": 7}, {"metadata": {"collapsed": true}, "source": ["def rating_type(score):\n", "    if score > 88:\n", "        return 1\n", "    if score <= 88:\n", "        return 0\n", "#creating a binary variable named \"quality\" based on wine rating\n", "wine['quality'] = wine.points.apply(rating_type)"], "cell_type": "code", "outputs": [], "execution_count": 8}, {"metadata": {"collapsed": true}, "source": ["wine_f = wine[['num_words','polarity','quality']]"], "cell_type": "code", "outputs": [], "execution_count": 9}, {"metadata": {}, "source": ["wine_f.head()"], "cell_type": "code", "outputs": [], "execution_count": 10}, {"metadata": {}, "source": ["wine_f.corr()"], "cell_type": "code", "outputs": [], "execution_count": 11}, {"metadata": {}, "source": ["# let\u00b4s plot the data in the plane (number of words,polarity). \n", "#The color represents the quality label\n", "import matplotlib.pyplot as plt\n", "plt.figure(figsize=(6,6))\n", "plt.scatter(wine[\"num_words\"],wine[\"polarity\"],c=wine[\"quality\"],s=6)\n", "plt.xlabel('number of words in description',fontsize=14)\n", "plt.ylabel('description polarity',fontsize=14)\n", "plt.show()"], "cell_type": "code", "outputs": [], "execution_count": 13}, {"metadata": {"collapsed": true}, "source": ["# the number of words in the description is highly correlated with the wine`s quality\n", "X = wine[['polarity','subjectivity','num_words']]\n", "X=X.values"], "cell_type": "code", "outputs": [], "execution_count": 14}, {"metadata": {"collapsed": true}, "source": ["y = wine['quality']"], "cell_type": "code", "outputs": [], "execution_count": 15}, {"metadata": {"collapsed": true}, "source": ["# logistic regression"], "cell_type": "code", "outputs": [], "execution_count": 16}, {"metadata": {"collapsed": true}, "source": ["from sklearn.linear_model import LogisticRegression"], "cell_type": "code", "outputs": [], "execution_count": 17}, {"metadata": {"collapsed": true}, "source": ["clf_lr = LogisticRegression()"], "cell_type": "code", "outputs": [], "execution_count": 18}, {"metadata": {"collapsed": true}, "source": ["from sklearn.model_selection import train_test_split"], "cell_type": "code", "outputs": [], "execution_count": 19}, {"metadata": {"collapsed": true}, "source": ["X_train, X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)"], "cell_type": "code", "outputs": [], "execution_count": 20}, {"metadata": {}, "source": ["clf_lr.fit(X_train,y_train)"], "cell_type": "code", "outputs": [], "execution_count": 21}, {"metadata": {"collapsed": true}, "source": ["from sklearn.metrics import accuracy_score, precision_score, recall_score\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.metrics import confusion_matrix"], "cell_type": "code", "outputs": [], "execution_count": 22}, {"metadata": {}, "source": ["np.mean(cross_val_score(clf_lr,X,y,cv=50))*100"], "cell_type": "code", "outputs": [], "execution_count": 23}, {"metadata": {}, "source": ["np.std(cross_val_score(clf_lr,X,y,cv=50))*100"], "cell_type": "code", "outputs": [], "execution_count": 24}, {"metadata": {"collapsed": true}, "source": ["import matplotlib.pyplot as plt\n", "%matplotlib inline"], "cell_type": "code", "outputs": [], "execution_count": 25}, {"metadata": {}, "source": ["plt.hist(cross_val_score(clf_lr,X_test,y_test,cv=50))"], "cell_type": "code", "outputs": [], "execution_count": 26}, {"metadata": {}, "source": ["precision_score(clf_lr.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 27}, {"metadata": {}, "source": ["recall_score(clf_lr.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 28}, {"metadata": {}, "source": ["confusion_matrix(clf_lr.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 29}, {"metadata": {}, "source": ["from sklearn.metrics import roc_curve, auc\n", "from sklearn.cross_validation import train_test_split\n", " \n", "# shuffle and split training and test sets\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n", "clf_lr.fit(X_train, y_train)\n", " \n", "# Determine the false positive and true positive rates\n", "fpr, tpr, _ = roc_curve(y_test, clf_lr.predict_proba(X_test)[:,1])\n", " \n", "# Calculate the AUC\n", "roc_auc = auc(fpr, tpr)\n", "print(roc_auc)\n", " \n", "# Plot of a ROC curve for a specific class\n", "plt.figure()\n", "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n", "plt.plot([0, 1], [0, 1], 'k--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('ROC Curve for Logistic Regression')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"], "cell_type": "code", "outputs": [], "execution_count": 30}, {"metadata": {"collapsed": true}, "source": ["from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.svm import LinearSVC"], "cell_type": "code", "outputs": [], "execution_count": 31}, {"metadata": {"collapsed": true}, "source": ["clf_knn = KNeighborsClassifier(n_neighbors=19)"], "cell_type": "code", "outputs": [], "execution_count": 32}, {"metadata": {"collapsed": true}, "source": ["X_train, X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1,random_state = 42)"], "cell_type": "code", "outputs": [], "execution_count": 33}, {"metadata": {}, "source": ["clf_knn.fit(X_train,y_train)"], "cell_type": "code", "outputs": [], "execution_count": 34}, {"metadata": {}, "source": ["np.mean(cross_val_score(clf_knn,X_test,y_test,cv=50))*100"], "cell_type": "code", "outputs": [], "execution_count": 35}, {"metadata": {}, "source": ["np.std(cross_val_score(clf_knn,X_test,y_test,cv=50))*100"], "cell_type": "code", "outputs": [], "execution_count": 36}, {"metadata": {"collapsed": true}, "source": ["#finding the most appropriate number of neighbors\n", "acc_list=[]\n", "for n in range(1,50):\n", "    clf_knn = KNeighborsClassifier(n_neighbors=n)\n", "    clf_knn.fit(X_train,y_train)\n", "    mean_acc = np.mean(cross_val_score(clf_knn,X_test,y_test,cv=50))*100\n", "    acc_list.append(mean_acc)"], "cell_type": "code", "outputs": [], "execution_count": 37}, {"metadata": {}, "source": ["plt.figure(figsize=(10,10))\n", "plt.plot(range(1,50),acc_list)\n", "plt.show()"], "cell_type": "code", "outputs": [], "execution_count": 38}, {"metadata": {}, "source": ["precision_score(clf_knn.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 39}, {"metadata": {}, "source": ["recall_score(clf_knn.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 40}, {"metadata": {}, "source": ["confusion_matrix(clf_lr.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 41}, {"metadata": {}, "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n", "clf_knn.fit(X_train, y_train)\n", " \n", "# Determine the false positive and true positive rates\n", "fpr, tpr, _ = roc_curve(y_test, clf_knn.predict_proba(X_test)[:,1])\n", " \n", "# Calculate the AUC\n", "roc_auc = auc(fpr, tpr)\n", "print(roc_auc)\n", " \n", "# Plot of a ROC curve for a specific class\n", "plt.figure()\n", "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n", "plt.plot([0, 1], [0, 1], 'k--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('ROC Curve for K-nearest neighbors')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"], "cell_type": "code", "outputs": [], "execution_count": 42}, {"metadata": {"collapsed": true}, "source": ["from sklearn.ensemble import RandomForestClassifier"], "cell_type": "code", "outputs": [], "execution_count": 43}, {"metadata": {"collapsed": true}, "source": ["clf_rf = RandomForestClassifier(n_estimators=2,oob_score=True,random_state=42)"], "cell_type": "code", "outputs": [], "execution_count": 44}, {"metadata": {}, "source": ["clf_rf.fit(X_train,y_train)"], "cell_type": "code", "outputs": [], "execution_count": 45}, {"metadata": {}, "source": ["# shuffle and split training and test sets\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n", "clf_rf.fit(X_train, y_train)\n", " \n", "# Determine the false positive and true positive rates\n", "fpr, tpr, _ = roc_curve(y_test, clf_knn.predict_proba(X_test)[:,1])\n", " \n", "# Calculate the AUC\n", "roc_auc = auc(fpr, tpr)\n", "print(roc_auc)\n", " \n", "# Plot of a ROC curve for a specific class\n", "plt.figure()\n", "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n", "plt.plot([0, 1], [0, 1], 'k--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('ROC Curve for Random Forest')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"], "cell_type": "code", "outputs": [], "execution_count": 46}, {"metadata": {}, "source": ["precision_score(clf_rf.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 47}, {"metadata": {}, "source": ["recall_score(clf_rf.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 48}, {"metadata": {}, "source": ["confusion_matrix(clf_rf.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 49}, {"metadata": {}, "source": ["confusion_matrix(clf_lr.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 50}, {"metadata": {}, "source": ["confusion_matrix(clf_knn.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 51}, {"metadata": {"collapsed": true}, "source": ["clf_svm = LinearSVC(C=.1)\n", "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)"], "cell_type": "code", "outputs": [], "execution_count": 52}, {"metadata": {}, "source": ["clf_svm.fit(X_train,y_train)"], "cell_type": "code", "outputs": [], "execution_count": 53}, {"metadata": {}, "source": ["clf_svm.fit(X_train, y_train)\n", " \n", "# Determine the false positive and true positive rates\n", "fpr, tpr, _ = roc_curve(y_test, clf_knn.predict_proba(X_test)[:,1])\n", " \n", "# Calculate the AUC\n", "roc_auc = auc(fpr, tpr)\n", "print(roc_auc)\n", " \n", "# Plot of a ROC curve for a specific class\n", "plt.figure()\n", "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n", "plt.plot([0, 1], [0, 1], 'k--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('ROC Curve for Support Vector Machine')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"], "cell_type": "code", "outputs": [], "execution_count": 54}, {"metadata": {}, "source": ["confusion_matrix(clf_svm.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 55}, {"metadata": {}, "source": ["accuracy_score(clf_svm.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 56}, {"metadata": {}, "source": ["precision_score(clf_svm.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 57}, {"metadata": {}, "source": ["recall_score(clf_svm.predict(X_test),y_test)"], "cell_type": "code", "outputs": [], "execution_count": 58}, {"metadata": {}, "source": ["plt.hist(cross_val_score(clf_svm,X_test,y_test,cv=50))"], "cell_type": "code", "outputs": [], "execution_count": 59}, {"metadata": {"collapsed": true}, "source": [], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"collapsed": true}, "source": [], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"collapsed": true}, "source": [], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"collapsed": true}, "source": [], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"collapsed": true}, "source": [], "cell_type": "code", "outputs": [], "execution_count": null}], "metadata": {"language_info": {"version": "3.6.1", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "nbconvert_exporter": "python", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 1, "nbformat": 4}