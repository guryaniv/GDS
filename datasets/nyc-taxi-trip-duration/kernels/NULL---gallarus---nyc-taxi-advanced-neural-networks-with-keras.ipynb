{"cells":[{"metadata":{"_uuid":"ee3ed1e89f0dcbfc9ae35d8f9c97f556bf901fd8"},"cell_type":"markdown","source":"# NYC Taxi - Advanced Neural Networks with Keras\n\n## Introduction\n\n### Foreword\n\nThis kernel is a study of mainly two Neural Network techniques using the data from the [New York City Taxi Trip Duration competition](https://www.kaggle.com/c/nyc-taxi-trip-duration).\n\nMy aim here is not to present the data exploration and data preparation. Kernels like [NYC Taxi EDA - Update: The fast & the curious](https://www.kaggle.com/headsortails/nyc-taxi-eda-update-the-fast-the-curious) and [From EDA to the Top (LB 0.367)\n](https://www.kaggle.com/gaborfodor/from-eda-to-the-top-lb-0-367) do an amazing job at that and my small data management is directly inspired from them.\n\nMoreover the goal is not to have a perfect model at the end but to showcase some ideas. At the end of the day the model shown here scores a RMSLE around 0.40 in the public leaderboard\n\nFinally, this is my first real kernel (appart from a test one on the Titanic Competition). Feel free to comment and point out my mistakes. I am here to learn.\n\n### The techniques of interest\n\nWhat I want to explain today is the creation of a Neural Network with share weights on the one hand, using Keras [functional API](https://keras.io/getting-started/functional-api-guide/) and the usage of multiple train metrics to improve the learning speed and accuracy.\n"},{"metadata":{"_uuid":"8bc3b1a6634949a2ea0fd403731e47f96a45f7fe"},"cell_type":"markdown","source":"## Quick data management\n\nTo make the predictions relevant a minimum of data management is in order. I kept it simple and only took ideas from other kernels.\n\n### Importing libraries"},{"metadata":{"trusted":true,"_uuid":"2802a83d29d1dc3b9f03f7cdb55ed04f488b2cc3","collapsed":true},"cell_type":"code","source":"# No need for presentations I guess\nimport numpy as np\nimport pandas as pd\n\n# I import keras from the tensorflow library\nimport tensorflow as tf\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras.models import Sequential, Model\nfrom tensorflow.python.keras.layers import Dense, Input\n\n# Preprocessing and evaluation metric\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_log_error","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"3dbfe127e46860eef9a2693f5847de6ebd201ccc"},"cell_type":"markdown","source":"### Data processessing\n\nThe haversine function you may recognise. It comes directly from the [From EDA to the Top (LB 0.367)\n](https://www.kaggle.com/gaborfodor/from-eda-to-the-top-lb-0-367) kernel. It allows to get an \"as the crow flies\" distance between pickup and dropout."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a34433bf25efa660f9593e8eb9d12cae940c685c"},"cell_type":"code","source":"def haversine(lat1, lng1, lat2, lng2):\n        lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n        R = 6371\n\n        lat = lat2 - lat1\n        lng = lng2 - lng1\n\n        d = np.sin(lat * 0.5)**2 \\\n            + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5)**2\n        h = 2 * R * np.arcsin(np.sqrt(d))\n\n        return h","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"2b17163bcc50e89480b65a68c106aef040422e3f"},"cell_type":"markdown","source":"What the next function does is :\n* Remove the `id` column\n* Calculate the haversine distance of each trip\n* Split the `pickup_datetime` column into sub elements\n* One Hot encode categorical variables\n* Drop the `dropoff_datetime` column if processing the train set\n* Removes some outliers on the train set based on duration and speed\n\nIt also put the GPS coordinates to be the first four columns of the set. We will soon see why."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"283ccdeb32911d3d57ef44b3d598cb4b220cf1f1"},"cell_type":"code","source":"def data_prep(raw, pred_data=False):\n    out = raw.copy()\n    # drop the 'id' column\n    out.drop('id', axis=1, inplace=True)\n    \n    # add the haversine distance\n    out.loc[:, 'distance'] = haversine(out.loc[:, 'pickup_latitude'],  \\\n                                       out.loc[:, 'pickup_longitude'], \\\n                                       out.loc[:, 'dropoff_latitude'], \\\n                                       out.loc[:, 'dropoff_longitude'])\n    \n    # split date_times\n    elts = ['month', 'day', 'hour', 'minute', 'second']\n    \n    col = 'pickup_datetime'\n    out[col] = pd.to_datetime(out[col])\n\n    for el in elts:\n        out[col + '_' + el] = out[col].map(lambda x: getattr(x, el))\n\n    out[col + '_day_of_week'] = out[col].map(lambda x: x.isoweekday())\n    \n    # remove the original datetime column    \n    out.drop('pickup_datetime', axis=1, inplace=True)\n    \n    # one hot encode categoricals :\n    out = pd.get_dummies(out, columns=['vendor_id', \n                                       'store_and_fwd_flag', \n                                       'pickup_datetime_day_of_week'])\n    \n    # remove some outliers : trip longer than 22 hours and avg speed > 100km/h\n    if not pred_data:\n        out = out[out['trip_duration'] < 22 * 3600]\n        out = out[out['distance'] / out['trip_duration'] * 3600 < 100 ]\n        out.drop('dropoff_datetime', axis=1, inplace=True)\n        \n    # split the gps locations out of `out` \n    coords = ['pickup_latitude', 'pickup_longitude', \n              'dropoff_latitude' ,'dropoff_longitude']\n    \n    out_gps = out.loc[:, coords]\n    out.drop(coords, axis=1, inplace=True)\n\n    return pd.concat([out_gps, out], axis=1)","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"91364d37183e137dccd9f9463938e0b77f125227"},"cell_type":"markdown","source":"### Data preparation\n\nI apply the processing on the train set."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f423f3773f67abfd3cef3574d70abfed3c7319bd"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntrain = data_prep(train)  \n\nX = train.drop('trip_duration', axis=1)\ny = train['trip_duration']\n\ntrain = None","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"61d2fc570c15f1663d5ef57b60d287c1eabf7dec"},"cell_type":"markdown","source":"Now that I have a `X` and `Y` I use the `StandardScaler` from scikit learn to scale the inputs.\n\nI also split `X` into `X_flat`, and `X_coords` 0 and 1. These last two are respectively the pickup and dropoff GPS coordinates. `X_flat` contains the rest of the training data."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5c350e779457cfd25a0ec03b027e55c5765d1b96"},"cell_type":"code","source":"scaler = StandardScaler()\nX = scaler.fit_transform(X)\n\nX_flat = X[:, 4:]\nX_coords0 = X[:, :2]\nX_coords1 = X[:, 2:4]","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"af1a8c56f767f4339cd025e2e2c5e64e066a1e43"},"cell_type":"markdown","source":"## Let's build a Neural Network\n\nFirst I set the seed for reproductibility and define `tb_path` as the folder where my TensorBoard's log will go"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5c52e9d06e1351aff58b807b8bb452e0ebcc7c68"},"cell_type":"code","source":"tb_path = 'tbGraphs/taxi/mult_shared/'\nnp.random.seed(1)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"84b32526d54810cc33e2c9839ce650e906774aeb"},"cell_type":"markdown","source":"### Multiple input network with shared weights\n\nThe first technique I want to present is \"Multiple input network with shared weights\". \n\nIn this data set we have two pieces of really similar information, the GPS coordinates. The neighborhood these coordinates describe are the same for 'pickup' and 'dropoff'.\n\nMy network will feature a sub-network shared both set of GPS coordinates. This means that the weights are the same for 'pickup' and 'dropoff' coordinates. It is in a way similar to convolutional networks.\n\nBelow is a representation of that idea."},{"metadata":{"_uuid":"859b0919c288ded4690315e6e6069eed99493f22"},"cell_type":"markdown","source":"![model](http://interactive.blockdiag.com/image?compression=deflate&encoding=base64&src=eJx1jDEKgDAQBHtfcR8QtBb8ypGYi4oxJ8kFC_HvJoWNRNhqZ3a142kzq5rhagAm5mA6aEeIiwpkMCa9syE3vLCvwkw_XdECRUG2KAuhJzk5bOUnxzoluPojya-XrUpfdE6Sh0NzP63MQQs)"},{"metadata":{"_uuid":"f0e551b9e4df1a0f8a95ff5e135cb97a1d9d282c"},"cell_type":"markdown","source":"### Creating the network\n\nThe problem we have is that we can't define our network only with the \"Sequential()\" API. What we need is the [functional API](https://keras.io/getting-started/functional-api-guide/) and the `concatenate` layer.\n\nI first set some parameters for the dimensions of the network"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1284ee3276935fdc56d969ffebf85c97e1c51992"},"cell_type":"code","source":"sub_n = 3 # number of layers in the shared subnet\nlvl_n = 4 # number of layers for the second part of the network\nn_node = 200 # number of neuron for each layer","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"4773d8339b1195a390306b0d609b34190c3a1ccc"},"cell_type":"markdown","source":"#### Coordinates subnet\n\nI will first create a Sequential model and add to it `sub_n - 1` dense layers"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b01c904d1207bc530ba19e85e757ca85e4224630"},"cell_type":"code","source":"coord_mod = Sequential()\n\ncoord_mod.add(Dense(n_node, activation='relu', input_dim=2))\nfor _ in range(sub_n - 1):\n    coord_mod.add(Dense(n_node, activation='relu'))","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"9466a42b31553a34a840af6f4408ca4e03ae7a12"},"cell_type":"markdown","source":"Then using I create two `Input` layers accepting two parameters each (the latitude and longitude)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5e2250b8d6d8e0fe4244016fbbd9b0c5f32cbfc2"},"cell_type":"code","source":"coord_inputs0 = Input(shape=(2, ))\ncoord_inputs1 = Input(shape=(2, ))","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ead85812b4b599fee3cea7a347e4621901abb99e"},"cell_type":"markdown","source":"![model](http://interactive.blockdiag.com/image?compression=deflate&encoding=base64&src=eJyVkMEKwjAMhu97ioBXBT0XfRGR0rVZW1YXaVOmiO_uQMWh3aHX5P8S_q8NpHvjlYV7A6CJotmCWB01BYqwh-CtYxvxtgbGK_-NT-KD7aqx5FREI1Nuz2QwQB3dBcXSD5fMlWDExJI6yQ7lgDxS7CsvUOb6t1-9m8Nv9ZnE0rLgaooVerz_zNQs5RY8TPFXOdE8nv6YvUs) "},{"metadata":{"_uuid":"ae401c56cfe73b5e1811b3df30af98ea144a90ec"},"cell_type":"markdown","source":"After that I apply my previously designed model to both of these inputs. Because it is the same model everything is shared : architecture of the model but more importantly weights."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"13d3d744c3f8252bfd1be621dd5d75f04f41b57f"},"cell_type":"code","source":"shared_coord0 = coord_mod(coord_inputs0)\nshared_coord1 = coord_mod(coord_inputs1)","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"e758832b4b9b8a9d257a4de144179a7321d33cbd"},"cell_type":"markdown","source":"Finally I concatenate these two into one layer using the `concatenate` layer."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e0e16d01cb66382f928a813c6b1a6aaa6083f1e8"},"cell_type":"code","source":"merged_coord = keras.layers.concatenate([shared_coord0, shared_coord1])","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"a036050e2f7ce582ec60cc4de7289a1162792d4d"},"cell_type":"markdown","source":"![model](http://interactive.blockdiag.com/image?compression=deflate&encoding=base64&src=eJyVkMEKwjAMhu97ioBXBT0XfRGR0rVZW1YXaVOmiO_uQMWh3aHX5P8S_q8NpHvjlYV7A6CJotmCWB01BYqwh-CtYxvxtgbGK_-NT-KD7aqx5FREI1Nuz2QwVPNdUCz9cMkMdWDExJI6yQ7lgDxS7CsvUOb6t1_Bm8Nv-ZnG0rJga4oVerz_zNQs5RY8TPFXOdE8nvMWvak)"},{"metadata":{"_uuid":"50beb7c8f511ed6059f367d75377292695857df9"},"cell_type":"markdown","source":"#### The rest of the net\n\nSimilarly I create a `Input` layer for the flat part of my data"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b4220ac6b8a19e3c7bb4f09225ed472bf881038e"},"cell_type":"code","source":"flat_inputs = Input(shape=(X_flat.shape[1], ))","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"84dacdb359ca51e9b63e15be4e1dd3664c25847e"},"cell_type":"markdown","source":"Again I concatenate it with my last part"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"663cc50f226335f05943fd796d6eeafbc6def723"},"cell_type":"code","source":"l = keras.layers.concatenate([merged_coord, flat_inputs])","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c6a51520719061ab6d577b445f7aa9709a359ae2"},"cell_type":"markdown","source":"![model](http://interactive.blockdiag.com/image?compression=deflate&encoding=base64&src=eJyVkMEKwjAMhu97ioBXBT0XfRGR0rVZW1YXaVNUxHd3ouLQ7tBr8n8J_9cG0r3xysKtAdBE0axBLPaaAkXYQvDWsY14XQLjhf_GB_HBNtVYciqikSm3RzIYqvkuKJZ-OGWuRiMmltRJdigH5DPFHuouUObn4zroq3i1-60_EVlaFnyNsUKP95-JnLncjIcx_ionmvsD_Fa-Bw)"},{"metadata":{"_uuid":"e443091f206520733267f831130c57a059428a8d"},"cell_type":"markdown","source":"Now I add`lvl_n` dense layers on top of this concatenated layer"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0c70a620cc6d38466afa69c4099fdca8c80eb0b8"},"cell_type":"code","source":"for lnl in range(lvl_n):\n    l = Dense(n_node, activation='relu')(l)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"db1c6e93d13aa553cf5166dbf681186ff7d316c5"},"cell_type":"markdown","source":"![model](http://interactive.blockdiag.com/image?compression=deflate&encoding=base64&src=eJyVkMEKwjAMhu97ioBXBT0XfRGR0rVZW1YXaVNUxHd3ouLQ7tBr8n_5ydcG0r3xysKtAdBE0axBLPaaAkXYQvDWsY14XQLjhf_GB_HBNtVYciqikSm3RzIYqvkuKJZ-OGWuRiMmltRJdigH5DPFvvoGZX5W10Ffyavdr4CJytKyYGyMFT5590z0zOVmTIzx13OiuT8AHqO-ZQ)"},{"metadata":{"_uuid":"14aeed096e4ad89940a42b83503a045c3e70701b"},"cell_type":"markdown","source":"And finally I add the output layer. Because the duration is a positive number of seconds I find the `relu` activation relevant."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"76162dbfa60dee71c0af93245735172a2b3c3b9c"},"cell_type":"code","source":"main_output = Dense(1, activation='relu', name='main_output')(l) ","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d8dec5596c778091ff7107d37dfa2f9573203df8"},"cell_type":"markdown","source":"![model](http://interactive.blockdiag.com/image?compression=deflate&encoding=base64&src=eJydkMEKwjAMhu97ioBXBT0XfRGR0rVZW1YXaVNUxHd3oOLQ7lCvyf_lJ18bSPfGKwu3BkATRbMGsdhrChRhC8FbxzbidQmMF_4ZH8Qb21RjyamIRqbcHslgqOa7oFj64ZS5Go2YWFIn2aEckM8U--oblPmf6o_m1e5bwURmaVlwNsYKv7x6JoLmcjMuxvjzPdHcH1QRvsM)"},{"metadata":{"_uuid":"698f84b09bb75fa192cc8e6b84ef6d21535a0535"},"cell_type":"markdown","source":"The last part is to use `Model()` to turn that beautiful architecture into a reality.\n\nWhat we need to do is list all the input layers and all the output layers in it."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"eb3f6c9db9c06612ffef99d5ce080636b777e855"},"cell_type":"code","source":"model = Model(inputs=[coord_inputs0, coord_inputs1, flat_inputs], \n              outputs=main_output)","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"c0aba95cef2a59f5b13751e88ee63037f0cbd917"},"cell_type":"markdown","source":"That's it our network is built !!"},{"metadata":{"_uuid":"50168bc912e47b45f4091edb31d0418251ebfd3c"},"cell_type":"markdown","source":"### Compiling and training the network\n\nNow that we have a model we need to train it. In order to do so I will use the `adam` optimizer.\n\nThe second thing that I want adress here is the choice of loss function. \n\nNaively using MSLE seems the best option because it is the metric of evaluation. However doing so result in an slow training . \n\nWhen using the MSE the learning is way faster but the RMSE calculated in the end is not as good.\n\nWhat I decided to do was to train a first time for 30 epochs using MSE then to load the best weights (on the validation set MSLE) and train again for 30 epochs usings MSLE.\n"},{"metadata":{"_uuid":"45f250169828ee1876bc422efaa69a6b9b6abcfe"},"cell_type":"markdown","source":"#### Using MSE\n\nSo first I compile the model using MSE as my loss function"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"59029e9b982df720e66f0abb1f16f2f351f8f65d"},"cell_type":"code","source":"model.compile(loss='mean_squared_error',\n              optimizer='adam',\n              metrics=['msle', 'mse'])","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"482192ce6bf1f8d33df72c59c273118738519d2d"},"cell_type":"markdown","source":"Then I define my batch size and setup two callbacks\n* `tbCallBack` to be able to view the learning process in TensorBoard\n* `ckCallBack` that will save the best model at each epoch"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b456e113b8e78e3ce3b26d3480d2f11a5f284f8c"},"cell_type":"code","source":"batches = 512\n\npath_grph = tb_path + 'shared/test' + str(sub_n) + '_' + str(lvl_n) + '_' + str(n_node)\ntbCallBack = keras.callbacks.TensorBoard(log_dir=path_grph,\n                                         histogram_freq=0, \n                                         write_graph=True, \n                                         write_images=False)\n\n\npath_mdl = 'shared_model' + str(sub_n) + '_' + str(lvl_n) + '_' + str(n_node) + '.hdf5'\nckCallBack = keras.callbacks.ModelCheckpoint(path_mdl, \n                                             monitor='val_mean_squared_logarithmic_error',\n                                             save_best_only=True,\n                                             mode='min')","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"8b6aad2f127ccf576d96fe18addb6024b531a394"},"cell_type":"markdown","source":"Then I start the fitting"},{"metadata":{"trusted":true,"_uuid":"0f55aae516409ee6127373708424cb7f871bdd3f","collapsed":true},"cell_type":"code","source":"model.fit([X_coords0, X_coords1, X_flat], y, \n          batch_size=batches,\n          epochs=30,\n          validation_split=0.2,\n          verbose=1,\n          callbacks=[tbCallBack, ckCallBack])","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"f2c26a67f5a2a4c840526ba844ec4ee1a21f09d5"},"cell_type":"markdown","source":"#### Using MSLE\n\nFor this second part of the training I load the best weights saved by the CheckPoint callback and relaunch the training from there.\n\nTo change the loss function all that needs to be done is recompiling the model. That does not reset the weights"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"738966ba9eb688345c9655ed871f3ae1548c15d5"},"cell_type":"code","source":"model.load_weights(path_mdl)\nmodel.compile(loss='mean_squared_logarithmic_error',\n              optimizer='adam',\n              metrics=['msle', 'mse'])","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"6dc29f53e5c8dcdf4ff193e56b14b92145b5510c"},"cell_type":"markdown","source":"I remake the TensorBoard callback to be able to see both trainings separately"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b7d6faf565156648fd75bb279bf30599311fb18f"},"cell_type":"code","source":"path_grph = tb_path + 'shared/test_msle' + str(sub_n) + '_' + str(lvl_n) + '_' + str(n_node)\ntbCallBack = keras.callbacks.TensorBoard(log_dir=path_grph,\n                                         histogram_freq=0, \n                                         write_graph=True, \n                                         write_images=False)","execution_count":30,"outputs":[]},{"metadata":{"_uuid":"6dfef51f75d041476ddbfb6e5408ce81edce974a"},"cell_type":"markdown","source":"And the fitting itself"},{"metadata":{"trusted":true,"_uuid":"52ea204f34cfb8e4820c73c33660513743f4d8a2","collapsed":true},"cell_type":"code","source":"model.fit([X_coords0, X_coords1, X_flat], y, \n          batch_size=batches,\n          epochs=30,\n          validation_split=0.2,\n          verbose=1,\n          callbacks=[tbCallBack, ckCallBack])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"761552aa7387d2897998def392075a947dbc2f18"},"cell_type":"markdown","source":"After that step I have a file named `'shared_model' + str(sub_n) + '_' + str(lvl_n) + '_' + str(n_node) + '.hdf5'` that contains the best weights after the second training"},{"metadata":{"_uuid":"754856db49e782cbccbe42eacd0775caa87a95e6"},"cell_type":"markdown","source":"## Predict\n\nWith all that done I can make a submission.\n\nBefore that I prepare the test set."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"44c660773c1382006a97d7e774a7e1a1b78ad46c"},"cell_type":"code","source":"validation = pd.read_csv('../input/test.csv')\nvalidation = data_prep(validation, pred_data=True)  \nvalidation = scaler.transform(validation)\n\nX_flat_val = validation[:, 4:]\nX_coords_val0 = validation[:, :2]\nX_coords_val1 = validation[:, 2:4]","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"79ba1d10f15349e0d55427d4f31d586854a9d88f"},"cell_type":"markdown","source":"I import the submission template"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"319df5d3c1a26b9790c3cefa11b0d54876beea9d"},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv')","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"6b8d0837a2192490de23c7dee76d27aa9107f0fc"},"cell_type":"markdown","source":"I load my best weights and make my prediction"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a8e5e5568f41b955bc2f05e8c76443790748ddd6"},"cell_type":"code","source":"model.load_weights(path_mdl)\nkeras_preds = model.predict([X_coords_val0, X_coords_val1, X_flat_val])","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"a79469e9d0f73524a56164cc27562353a4550d1f"},"cell_type":"markdown","source":"Finally I create my 'keras_submission.csv'"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"0318677a0f297cee45a3fb63f9855ac39ed6dbd3"},"cell_type":"code","source":"keras_submission = submission.copy()\nkeras_submission.trip_duration = keras_preds\n\nkeras_submission.to_csv('keras_submission.csv', index=False)","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"76dd23a8ae118d5b64899bdf255e56ab40300d6d"},"cell_type":"markdown","source":"The file submitted got a score of 0.40266 on kaggle that would place it around rank 496\n\n## Conclusion\n\nI hope you enjoyed that kernel as much as I enjoyed making it and learning about all the things in it. \n\nI am far from being an expert on the subject so don't hesitate to make comment and to suggest modification.\n\nThe final network presented is not by far perfect and I voluntarily chose to not tweak every aspect of it to avoid cluttering the kernel"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}