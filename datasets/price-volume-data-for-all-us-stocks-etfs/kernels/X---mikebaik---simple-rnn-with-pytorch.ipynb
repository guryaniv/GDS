{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"1476292f2d1a6d5ed2998f7ab3ca9a513c06c2f6"},"cell_type":"markdown","source":"# Test driving the RNN model with Pytorch\n\nUsing a very simple RNN model to predict an index of S&P 500. This is similar to the way regressions would do this kind of jobs.\n\nSetting things up so that RNN model be utilized, familiarize oneself with Pytorch. \n\nYes, the model is naive, but it is also easy to tweak things so that it actually produces something more meaningful."},{"metadata":{"_uuid":"a6c4378f17c314d55b61447a628c5dbdfa8af077"},"cell_type":"markdown","source":"# Not trying to split into training set and test set\n\nThis is purely for the purpose of setting things up to get to know Pytorch."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\n\n\nclass StockDataset(Dataset):\n\n    def __init__(self, x_data_to_process, y_data_to_process):\n        \"\"\" inputs for x and y values are given as pandas obj \"\"\"\n        self.data = pd.merge(x_data_to_process, y_data_to_process, on='Date')\n        self.data = self.data.values    # from pd to np\n\n        print('The shape of the data is {}'.format(self.data.shape))\n\n        self.x_data = self.data[:, 1:x_data_to_process.shape[1]].astype(np.float32)\n        self.y_data = self.data[:, x_data_to_process.shape[1]:].astype(np.float32)\n\n        \"\"\" Normalize x_data, putting it off for now \"\"\"\n        self.rebase_to_one()\n\n        \"\"\" convert to torch \"\"\"\n        self.x_data = torch.from_numpy(self.x_data)\n        self.y_data = torch.from_numpy(self.y_data)\n\n        self.len = self.data.shape[0]\n\n    def __getitem__(self, index):\n        return self.x_data[index], self.y_data[index]\n\n    def __len__(self):\n        return self.len\n\n    def rebase_to_one(self):\n        \"\"\" self.x_data rebased to one on the firsts element \"\"\"\n        self.x_data = self.x_data.T\n        list_of_first_elem_price = [i[0] for i in self.x_data]\n        shape_row, shape_column = self.x_data.shape[0], self.x_data.shape[1]\n\n        for i in range(shape_row):\n            for j in range(shape_column):\n                self.x_data[i][j] /= list_of_first_elem_price[i]\n        self.x_data = self.x_data.T\n\n\n\ndef get_dictionary_of_data():\n    def get_dictionary_of_data_helper(list_of_stocks):\n        dict_of_stocks = {}\n        for i in range(len(list_of_stocks)):\n            key = str(list_of_stocks[i]).lower()\n            path ='../input/Data/Stocks/{}.us.txt'.format(key)\n            try:\n                dict_of_stocks[key] = pd.read_csv(path)\n            except FileNotFoundError:\n                print(\"File of {} not found\".format(key))\n\n        return dict_of_stocks\n\n    # Use these tickers if possible to predict S&P's value\n    spx_partial_list = np.array(['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO',\n                                     'KO', 'DWDP', 'XOM', 'GE', 'GS', 'HD', 'IBM', 'INTC',\n                                     'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', 'PFE', 'PG',\n                                     'TRV', 'UNH', 'UTX', 'VZ', 'V', 'WMT', 'DIS'])\n\n    return get_dictionary_of_data_helper(spx_partial_list)\n\n\ndef closing_prices_in_pd(dict_of_stocks):\n    \"\"\" merge stock data on Dates \"\"\"\n    temp_dict = {}\n    for i in dict_of_stocks.keys():\n        temp_dict[i] = (dict_of_stocks[i])[['Date', 'Close', 'Volume']]\n\n    merged = None\n    for i in temp_dict.keys():\n        if merged is None:\n            merged = temp_dict[i]\n        elif temp_dict[i].shape[0] > 3000: # Arbitrary selection, longer than 3000\n            merged = pd.merge(merged, temp_dict[i], on='Date')\n\n    return merged\n","execution_count":15,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"095abfb548edcef9d7b6ec3d0a07d7e05315ca7d"},"cell_type":"code","source":"from torch.autograd import Variable\n\n\nclass Model(torch.nn.Module):\n\n    def __init__(self, input_size, rnn_hidden_size, output_size):\n\n        super(Model, self).__init__()\n\n        self.rnn = torch.nn.RNN(input_size, rnn_hidden_size,\n                                num_layers=2, nonlinearity='relu',\n                                batch_first=True)\n        self.h_0 = self.initialize_hidden(rnn_hidden_size)\n\n        self.linear = torch.nn.Linear(rnn_hidden_size, output_size)\n\n    def forward(self, x):\n\n        x = x.unsqueeze(0)\n        self.rnn.flatten_parameters()\n        out, self.h_0 = self.rnn(x, self.h_0)\n\n        out = self.linear(out)\n\n        # third_output = self.relu(self.linear3(second_output))\n        # fourth_output = self.relu(self.linear4(third_output))\n        # output = self.rnn(lineared_output)\n        # output = self.dropout(output)\n        return out\n\n    def initialize_hidden(self, rnn_hidden_size):\n        # n_layers * n_directions, batch_size, rnn_hidden_size\n        return Variable(torch.randn(2, 1, rnn_hidden_size),\n                        requires_grad=True)","execution_count":16,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"aa20adb78add5f4622164405c6e859ab802d3179"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import DataLoader\n\nRNN_HIDDEN_SIZE = 32\n\n\ndef train(input_size, hidden_size, output_size, train_loader):\n    plt.figure(1, figsize=(12, 5))\n\n    file_path = 'my_model.model'\n\n    try:\n        model = torch.load(file_path)\n    except:\n        model = Model(input_size, hidden_size, output_size)\n\n    criterion = torch.nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n    epochs = 1\n\n    for epoch in range(epochs):\n        predictions = []\n        correct_values = []\n\n        for i, data in enumerate(train_loader):\n            xs, ys = data\n            xs, ys = Variable(xs), Variable(ys)\n\n            y_pred = model(xs)\n            loss = criterion(y_pred, ys)\n            optimizer.zero_grad()\n            loss.backward(retain_graph=True)\n            torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n            optimizer.step()\n\n            predictions.append(y_pred.cpu().data.numpy().ravel())\n            correct_values.append(ys.cpu().data.numpy().ravel())\n\n        def stacking_for_charting(given_list):\n            ret = np.array([0])\n            for i in given_list:\n                ret = np.hstack((ret, i.ravel()))\n            return ret[1:]\n\n        predictions_for_chart = stacking_for_charting(predictions)\n        correct_values_for_chart = stacking_for_charting(correct_values)\n\n        print(predictions_for_chart)\n\n        steps = np.linspace(epoch*predictions_for_chart.shape[0],\n                            (epoch+1)*predictions_for_chart.shape[0],\n                            predictions_for_chart.shape[0])\n        plt.plot(steps, predictions_for_chart, 'r-')\n        plt.plot(steps, correct_values_for_chart, 'b-')\n        plt.draw()\n        plt.pause(0.05)\n\n    torch.save(model, file_path)\n    plt.show()","execution_count":17,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"cfb039020708b43bbf45e183dc2c4a6634764776"},"cell_type":"code","source":"def main():\n\n    \"\"\" GETTING THE DICTIONARY OF STOCK DATA \"\"\"\n    X_data_source = get_dictionary_of_data()\n\n    \"\"\" THE ETF DATA TO BE USED AS Y \"\"\"\n    Y_data_source = {'spy': pd.read_csv('../input/Data/ETFs/spy.us.txt')}\n\n    X_data = closing_prices_in_pd(X_data_source)\n    Y_data = closing_prices_in_pd(Y_data_source)\n\n    Y_data = Y_data.drop(['Volume'], axis=1)\n\n    dataset = StockDataset(X_data, Y_data)\n    train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=False, num_workers=1)\n\n    input_size = X_data.shape[1]-1\n    hidden_size = RNN_HIDDEN_SIZE\n    output_size = Y_data.shape[1]-1\n\n    train(input_size, hidden_size, output_size, train_loader)","execution_count":18,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"d2b4113ddde329c89edee7686f330cdc5133c36b"},"cell_type":"code","source":"main()","execution_count":19,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}