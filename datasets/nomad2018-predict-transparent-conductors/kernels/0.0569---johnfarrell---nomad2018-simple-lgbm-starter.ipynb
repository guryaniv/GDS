{"metadata": {"language_info": {"pygments_lexer": "ipython3", "file_extension": ".py", "name": "python", "version": "3.6.3", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "cells": [{"execution_count": null, "cell_type": "code", "outputs": [], "source": ["import os\n", "import gc\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')\n", "print(train.shape)\n", "train.head(10)"], "metadata": {"_cell_guid": "e7bac91a-e9ef-4ecb-898c-4c54e171c0b9", "_uuid": "fe7e1b8d6bfb4c0036409d1a5c81b913f575f78a"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["print(test.shape)\n", "test.head(10)"], "metadata": {"_cell_guid": "365ba4a8-da01-4f2a-9e44-ec409d6fe4a0", "_uuid": "a16cb07eee2ecbed439d255201526f4f36558823"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["target_fe = np.log1p(train.formation_energy_ev_natom)\n", "target_be = np.log1p(train.bandgap_energy_ev)\n", "del train['formation_energy_ev_natom'], train['bandgap_energy_ev'], train['id'], test['id']"], "metadata": {"_cell_guid": "b30a8469-2f91-4347-85db-2c6ba92aee6d", "collapsed": true, "_uuid": "ff945bd7d76902046d18587892675b2c8b7c31e9"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["sorted(train['spacegroup'].unique())"], "metadata": {"_cell_guid": "bd2e7bde-5e72-4c5e-b3ab-e072816e8497", "_uuid": "bd3238a3b5d5ced3f5a5aae10159dbc0f33af2fc"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["sorted(test['spacegroup'].unique())"], "metadata": {"_cell_guid": "2473a1f6-8691-4aae-bc93-503c537fec62", "_uuid": "a274c6fa14e9ba2d7886fd2c3a829987b3b73aad"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["train = pd.concat([train.drop(['spacegroup'], axis=1), \n", "                   pd.get_dummies(train['spacegroup'], prefix='SG')], axis=1)\n", "test = pd.concat([test.drop(['spacegroup'], axis=1), \n", "                   pd.get_dummies(test['spacegroup'], prefix='SG')], axis=1)"], "metadata": {"_cell_guid": "642f90a4-a646-463b-a852-5b6f80e62f29", "collapsed": true, "_uuid": "b630a91694589af7c989d776c8e56ae9e6132c27"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["import lightgbm as lgb\n", "import multiprocessing\n", "\n", "def cv_train_model(X, y, \n", "                   verbose_eval=None, \n", "                   early_stopping_rounds=None,\n", "                   params=None):\n", "    if type(y) is pd.core.frame.DataFrame:\n", "        y = y.values.ravel()\n", "    dstrain = lgb.Dataset(X, label=y)\n", "    max_boost_round = 4000\n", "    if params is None:\n", "        lgb_params = {\n", "            'objective': 'regression_l2',\n", "            'learning_rate': 0.008,\n", "            'num_threads': 4,#multiprocessing.cpu_count(),\n", "            'max_depth': 4,\n", "            'min_data_in_leaf': 23,\n", "            'feature_fraction': 0.93,\n", "            'bagging_fraction': 0.93,\n", "            'bagging_freq': 1,\n", "            'lambda_l2': 1e2,\n", "            'metric': ['mse']\n", "        }\n", "    print('lgb cv and training...')\n", "    if verbose_eval is None:\n", "        verbose_eval = int(max_boost_round/30)\n", "    if early_stopping_rounds is None:\n", "        early_stopping_rounds = int(max_boost_round/10)\n", "    cv_lgb = lgb.cv(lgb_params, dstrain,\n", "                    num_boost_round=max_boost_round,\n", "                    nfold=10,\n", "                    stratified=False,\n", "                    verbose_eval=verbose_eval,\n", "                    early_stopping_rounds=early_stopping_rounds,\n", "                    show_stdv=False)\n", "    best_round = np.argmin(cv_lgb['l2-mean'])\n", "    best_cv_mean = np.min(cv_lgb['l2-mean'])\n", "    print('best round', best_round)\n", "    print('best mse-mean', best_cv_mean)\n", "    model_lgb = lgb.train(lgb_params, dstrain, \n", "                          num_boost_round=best_round,\n", "                          valid_sets=dstrain,\n", "                          verbose_eval=verbose_eval)\n", "    print('lgb cv and training finished...')\n", "    return model_lgb, best_cv_mean\n", "def get_feat_weight(model_lgb, feat_names, plot=True):\n", "    feat_weight = pd.DataFrame(model_lgb.feature_importance(),\n", "                               columns=['feature_importance'],\n", "                               index=feat_names)\n", "    if plot:\n", "        indices = np.argsort(feat_weight['feature_importance'])[::-1]\n", "        plt.figure(figsize=(12, 6))\n", "        plt.title('feature importance (lightgbm)')\n", "        plt.bar(range(len(feat_weight)), list(feat_weight.iloc[indices, 0]))\n", "        plt.xticks(range(len(feat_weight)), feat_weight.iloc[indices].index, \n", "                   rotation='vertical')\n", "        plt.xlim([-1, len(feat_weight)])\n", "        plt.show()\n", "    return feat_weight\n", "def get_model_cv(df, y, plot=True, verbose_eval=False):\n", "    model_lgb, best_cv_mean = cv_train_model(df, y, verbose_eval=verbose_eval)\n", "    feat_weight = get_feat_weight(model_lgb, feat_names=df.columns, plot=plot)\n", "    print('best cv mean', best_cv_mean)\n", "    return best_cv_mean, feat_weight, model_lgb"], "metadata": {"_cell_guid": "a12034e6-3c2a-473f-bef3-2f5ca6e1c8c9", "collapsed": true, "_uuid": "3908ab23833bf8b86b695b899537ac55f3026871"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["best_cv_mean_fe, feat_weight_fe, model_lgb_fe = get_model_cv(train, target_fe)\n", "pred_fe = np.expm1(model_lgb_fe.predict(test))\n", "best_cv_mean_be, feat_weight_be, model_lgb_be = get_model_cv(train, target_be)\n", "pred_be = np.expm1(model_lgb_be.predict(test))\n", "scr_total = np.mean([np.sqrt(best_cv_mean_fe), np.sqrt(best_cv_mean_be)])\n", "print(f'total cv score: {scr_total}')\n", "sub = pd.read_csv('../input/sample_submission.csv')\n", "sub['formation_energy_ev_natom'] = pred_fe\n", "sub['bandgap_energy_ev'] = pred_be\n", "sub.to_csv(f'sb_{scr_total}.csv', index=False) ### LB ~0.0570"], "metadata": {"_cell_guid": "f61bf3f7-bb08-413a-989e-4903d1f3f66c", "_uuid": "bd99262964c190c7909baedc2a4145023e644a46"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["### uncomment to get cv pred\n", "from sklearn.linear_model import RidgeCV\n", "from sklearn.model_selection import KFold\n", "from sklearn.metrics import mean_squared_error\n", "from sklearn.preprocessing import StandardScaler\n", "rg = RidgeCV(alphas=[0.003, 0.01, 0.3, 3, 10], cv=5)\n", "\n", "def kfold_cv(X, y, test, n_splits=10, \n", "             train_lgb=True, \n", "             lgb_ratio=0.8,\n", "             cv_pred_test=False):\n", "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=233)\n", "    cv_pred = np.zeros((len(test)))\n", "    scr_total = 0\n", "    for fold_id, (tr_idx, te_idx) in enumerate(kf.split(y)):\n", "        print(f'Starting No.{fold_id} fold CV out of {n_splits} ...')\n", "        X_tr, y_tr = X.iloc[tr_idx], y.iloc[tr_idx]\n", "        X_te, y_te = X.iloc[te_idx], y.iloc[te_idx]\n", "        rg.fit(StandardScaler().fit_transform(X_tr), y_tr)\n", "        pred_rg = rg.predict(StandardScaler().fit_transform(X_te))\n", "        mse = mean_squared_error(y_te, pred_rg)\n", "        print('=======rg mse:', mse)\n", "        if train_lgb==True:\n", "            _, _, model_lgb = get_model_cv(X_tr, y_tr, False, 0)\n", "            print('=======lgb mse:',mean_squared_error(y_te, model_lgb.predict(X_te)))\n", "            avg_mse = mean_squared_error(y_te, \n", "                                         pred_rg*(1-lgb_ratio)+\\\n", "                                         model_lgb.predict(X_te)*lgb_ratio)\n", "            print(f'=======avg mse: {avg_mse}')\n", "            scr_total += avg_mse / n_splits\n", "        else:\n", "            scr_total += mse / n_splits\n", "        if cv_pred_test == True:\n", "            if train_lgb == True: \n", "                cv_pred += (rg.predict(StandardScaler().fit_transform(\n", "                        test))*(1-lgb_ratio) + \\\n", "                            model_lgb.predict(test)*lgb_ratio)/n_splits\n", "            else:\n", "                cv_pred += rg.predict(StandardScaler().fit_transform(\n", "                        test))/n_splits\n", "    print(f'score total: {scr_total}')\n", "    if not cv_pred_test:\n", "        return scr_total\n", "    else:\n", "        return scr_total, np.expm1(cv_pred)\n", "#lgb_ratio = 0.95\n", "#cv_fe, cv_pred_fe = kfold_cv(train, target_fe, test, n_splits=10, \n", "#                             train_lgb=True, lgb_ratio=lgb_ratio, cv_pred_test=True)\n", "#cv_be, cv_pred_be = kfold_cv(train, target_be, test, n_splits=10, \n", "#                             train_lgb=True, lgb_ratio=lgb_ratio, cv_pred_test=True)\n", "#cv_total = np.mean([np.sqrt(cv_fe), np.sqrt(cv_be)])\n", "#print(f'fe: {cv_fe}; be: {cv_be}')\n", "#print(f'cv total rmsle:{cv_total}')\n", "#sub['formation_energy_ev_natom'] = cv_pred_fe\n", "#sub['bandgap_energy_ev'] = cv_pred_be\n", "#sub.to_csv(f'sb_lgb{lgb_ratio}_rg_{cv_total}.csv', index=False) ### LB ~0.0573"], "metadata": {"_cell_guid": "3bf249cf-ef29-485b-9624-9451486c8108", "collapsed": true, "_uuid": "e6e6ff0e78d1a8a1b7897616dfb29768f2efc9e8"}}], "nbformat": 4, "nbformat_minor": 1}