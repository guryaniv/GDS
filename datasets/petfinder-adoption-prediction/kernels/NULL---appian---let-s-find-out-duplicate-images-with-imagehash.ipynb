{"cells":[{"metadata":{"_uuid":"71e0e8af66713faf9ef036aa8d0c8354c2288307"},"cell_type":"markdown","source":"- Version6: Fixed order of RGB when plotting. Added json output.\n- Version2: Description added."},{"metadata":{"trusted":true,"_uuid":"4a78d0be9bc398c6f69dffdb9709c7e32361f47d"},"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport glob\nimport itertools\nimport collections\n\nfrom PIL import Image\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm\nimport pandas as pd\nimport numpy as np\nimport torch\nimport imagehash\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"300d1d24d8d0e5f99debd1bb2a2e3925ab92bcca"},"cell_type":"markdown","source":"## Calc similalities between all image pairs\nI use imagehash library to calculate hash value of image. \nhttps://github.com/JohannesBuchner/imagehash\n\nThere are several hash functions provided and I used 4 of them and combined the calculated hash values.\n\n  - average hashing (aHash)\n  - perception hashing (pHash)\n  - difference hashing (dHash)\n  - wavelet hashing (wHash)\n  \nI used profile image(1st image) of pet images to calculate hash values. "},{"metadata":{"trusted":true,"_uuid":"3a94ec9c45f58e7bc62bfeee6c2cdf06d7d92d92"},"cell_type":"code","source":"def run():\n\n    funcs = [\n        imagehash.average_hash,\n        imagehash.phash,\n        imagehash.dhash,\n        imagehash.whash,\n        #lambda x: imagehash.whash(x, mode='db4'),\n    ]\n\n    petids = []\n    hashes = []\n    for path in tqdm(glob.glob('../input/*_images/*-1.jpg')):\n\n        image = Image.open(path)\n        imageid = path.split('/')[-1].split('.')[0][:-2]\n\n        petids.append(imageid)\n        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))\n\n    return petids, np.array(hashes)\n\n%time petids, hashes_all = run()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6003bbf5ff9c947902b1839caa605b1b52484ff3"},"cell_type":"markdown","source":"Convert numpy array into torch tensor to speed up similarity calculation."},{"metadata":{"trusted":true,"_uuid":"c49b7d3fe7757d3d10e3fa145eae28f1ecc44b91"},"cell_type":"code","source":"hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21b0c202ad7cbedc24cdabc5e8eed562857ddbb5"},"cell_type":"markdown","source":"Calculate similarities among all image pairs. Divide the value by 256 to normalize (0-1)."},{"metadata":{"trusted":true,"_uuid":"c3245ecda55917aa2c24224fe242db66b3c5818a"},"cell_type":"code","source":"%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45d9808d423b0cc16285cf9fbc3e5366c26ca81d"},"cell_type":"markdown","source":"## Thresholding"},{"metadata":{"trusted":true,"_uuid":"69fd02377ac353670c29f295d38a79e5b5708887"},"cell_type":"code","source":"indices1 = np.where(sims > 0.9)\nindices2 = np.where(indices1[0] != indices1[1])\npetids1 = [petids[i] for i in indices1[0][indices2]]\npetids2 = [petids[i] for i in indices1[1][indices2]]\ndups = {tuple(sorted([petid1,petid2])):True for petid1, petid2 in zip(petids1, petids2)}\nprint('found %d duplicates' % len(dups))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c759296ca500c0a774332379f8fe9fe524f7269"},"cell_type":"markdown","source":"## Associate petid with csv info"},{"metadata":{"trusted":true,"_uuid":"209d86c56e9b5d1bbb167aaa32f3f3b130928b95"},"cell_type":"code","source":"train = pd.read_csv('../input/train/train.csv')\ntest = pd.read_csv('../input/test/test.csv')\n\ntrain.loc[:,'Category'] = 'train'\ntest.loc[:,'Category'] = 'test'\ntest.loc[:,'AdoptionSpeed'] = np.nan\n\ndf = pd.concat([train, test], sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"449984e5ed64df865902261828add5a322567cf4"},"cell_type":"code","source":"detail = {petid:df[df.PetID == petid].iloc[0] for petid in itertools.chain.from_iterable(list(dups))}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69264070e02b7aa8c834560a62ce20ea6b44df5a"},"cell_type":"code","source":"def show(row1, row2):\n\n    print('PetID: %s / %s' % (row1.PetID, row2.PetID))\n    print('Name: %s / %s' % (row1.Name, row2.Name))\n    print('Category: %s / %s' % (row1.Category, row2.Category))\n    print('AdoptionSpeed: %s / %s' % (row1.AdoptionSpeed, row2.AdoptionSpeed))\n    print('Breed1: %d / %d' % (row1.Breed1, row2.Breed1))\n    print('Age: %d / %d' % (row1.Age, row2.Age))\n    print('RescuerID:\\n%s\\n%s' % (row1.RescuerID, row2.RescuerID))\n    \n    image1 = cv2.imread('../input/%s_images/%s-1.jpg' % (row1.Category, row1.PetID))\n    image2 = cv2.imread('../input/%s_images/%s-1.jpg' % (row2.Category, row2.PetID))\n    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n    image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n    \n    fig = plt.figure(figsize=(10, 20))\n    fig.add_subplot(1,2,1)\n    plt.imshow(image1)\n    fig.add_subplot(1,2, 2)\n    plt.imshow(image2)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a44ceb5955e937edb3e1a1190321479eb4c212f8"},"cell_type":"markdown","source":"## Example of duplicates"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"7d57aa3e8e7f87e0c22fb7793834c68dba158c01"},"cell_type":"code","source":"for petid1, petid2 in sorted(list(dups)):\n    row1 = detail[petid1]\n    row2 = detail[petid2]\n    if row1.Category != row2.Category:\n        show(row1, row2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b510e41f15a690f71da65c647b26ccbfa922722b"},"cell_type":"markdown","source":"- Some pets change their info (such as Name, Breed, Age).\n- Some pets are adopted more than once even twice."},{"metadata":{"_uuid":"b8da4f5e8a1f892e005c36e3bd76532a9f3f6b68"},"cell_type":"markdown","source":"## Which column info is inconsistent on duplicate pairs?"},{"metadata":{"trusted":true,"_uuid":"11a6cdde9727a5e409c05a265fb92755b5855c97"},"cell_type":"code","source":"counter = collections.Counter()\nfor petid1, petid2 in list(dups):\n    row1 = detail[petid1]\n    row2 = detail[petid2]\n    \n    for attr in train.columns:\n        if getattr(row1, attr) != getattr(row2, attr):\n            counter[attr] += 1\n            \ncounter","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e709b1b022b68464f2ad75dd61f27d4d917f32fd"},"cell_type":"markdown","source":"- Duplicate pets change their name often.\n- 1/3 of duplicate pets with different RescuerID"},{"metadata":{"_uuid":"d4f701e4b8dfcbaf999f453fe932281cc5587570"},"cell_type":"markdown","source":"## Let's see how their description changes"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"3670fb5b0f4b0c32e1dcd7b40069dfe135b5e5b2"},"cell_type":"code","source":"for petid1, petid2 in list(dups)[:20]:\n    row1 = detail[petid1]\n    row2 = detail[petid2]\n    if row1.Description != row2.Description:\n        print(row1.Description)\n        print('-'*5)\n        print(row2.Description)\n        print('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e62d5a511d292c341ffd21ab8269a8bea907fd2"},"cell_type":"code","source":"import json\nout = [[petid1,petid2] for petid1,petid2 in dups.keys()]\nwith open('dups.json', 'w') as fp:\n    fp.write(json.dumps(out))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}