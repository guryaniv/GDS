{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"### Starter code for PyTorch\nThis is a starter code for people who want to start experimenting with PyTorch. The model is very basic and only uses continous variables of the application_train.csv file.\nThere are lot of improvements possible like \n1. Using embeddings for categorical variables\n2. Using other input files to improve features\n"},{"metadata":{"_uuid":"b3f220f228e9057ff1c81e1fcef0b1bd6512c084"},"cell_type":"markdown","source":"#### Import all necessary libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport torch\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn import preprocessing","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"8e48f9d08e213a863ed112d4f8ee8eef547501f2"},"cell_type":"markdown","source":"#### Read training file"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"44de7f23032703bde9ff617dd6e4024c1650aae5"},"cell_type":"code","source":"raw_train = pd.read_csv('../input/application_train.csv')\nraw_train.head()","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"095999346e3084fbed85a3aba2b13634e80ad4c8","collapsed":true},"cell_type":"code","source":"target = 'TARGET'\nid_col = 'SK_ID_CURR'\n\n#Delete target column as it is not useful for prediction\ndel raw_train[id_col]\n\n#Distribution of target variable\nraw_train[target].value_counts()\n\n#Store target variable to be used later\ntarget_val = raw_train[target]\n\n#Delete target column from features\ndel raw_train[target]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"248aa97a313fc023256b699a06224f7c85c91fa3"},"cell_type":"code","source":"#### Fetch all continous variables","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"31a1c5d6fecb3103287a08b55d1a76ab1db24b9a"},"cell_type":"code","source":"cont_vars = []\nfor col in raw_train.columns:\n    if raw_train[col].dtype == 'int64' or raw_train[col].dtype == 'float64':\n        cont_vars.append(col)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8ce61f3336e230fdcd027f18fb501704cbc01859"},"cell_type":"code","source":"#Store number of continous variable. This will be equivalent to number of neurons in input layer\ncont_train = raw_train.loc[:, cont_vars]\ncurr_dim = cont_train.shape[1]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c08e56a5f556f7b44f1c59e7499ba2fc6e4aaf28"},"cell_type":"code","source":"#Fill NAs with mean value of column. Lot of scope of improvement here :)\ncont_train = cont_train.fillna(cont_train.mean())\n\n#Normalize features using standard scaler. We will use same standard scaler object to normalize test data\nstd_scale = preprocessing.StandardScaler().fit(cont_train[cont_vars])\ncont_train[cont_vars] = std_scale.transform(cont_train[cont_vars])\n","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"2d8bca9ac3514e2e5920ecc43da08e2a00d77403"},"cell_type":"markdown","source":"### Basic Nueral net model using Pytorch\nInput layer has as many neurons as continous variables\nThen there are 2 hidden layers with 40 and 20 neurons.  These are random numbers that I used. Feel free to experiment and give better architecture. Also, I have used ReLU on first hidden layer.  Feel free to put another ReLU in second hidden layer.\nOutput layer has 1 neuron which is followed by sigmoid activation to get the output between 0 and 1. (Probability score)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2cc9bd9aa48aff8e517df6432ee95d3099a3070e"},"cell_type":"code","source":"class basic_model(torch.nn.Module):\n    def __init__(self, i_dim):\n        super(basic_model, self).__init__()\n        self.linear1 = torch.nn.Linear(i_dim, 40)\n        self.linear2 = torch.nn.Linear(40, 20)\n        self.linear3 = torch.nn.Linear(20, 1)\n        self.out_act = torch.nn.Sigmoid()\n    \n    def forward(self, x):\n        h_relu = self.linear2(self.linear1(x).clamp(min=0))\n        y_pred = self.out_act(self.linear3(h_relu))\n        return y_pred","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"bd24558ec5ae0c1c0adc8dd35cf9733f102da8c1"},"cell_type":"markdown","source":"Set other necessary variables like batch_size, type of optimizer to use and the loss function."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8d493836427f091069dd1ec5a2e9026a90b279ae"},"cell_type":"code","source":"batch_size = 256\nin_dim = curr_dim\nmodel = basic_model(in_dim)\ncriterion = torch.nn.BCELoss()\nlearning_rate = .001\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,  betas=(0.9, 0.999))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1561b4124502fd6ee1e2a0a7c4d37506d02e8a3c"},"cell_type":"markdown","source":"### Train the model"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1c7c3730126c5d08b4ee6db405c618b2f266ea88"},"cell_type":"code","source":"def train_epoch(model, criterion, optimizer, batch_size=batch_size):\n    #model.train()\n    losses = []\n    \n    for beg_i in range(0, cont_train.shape[0], batch_size):\n        x_batch = cont_train.loc[beg_i:beg_i + batch_size, :]\n        y_batch = target_val.loc[beg_i:beg_i + batch_size]\n        input_data = torch.from_numpy(np.array(x_batch, dtype=np.float32))\n        target_data = torch.from_numpy(np.array(y_batch, dtype=np.float32))\n        y_pred = model(input_data)\n        loss = criterion(y_pred, target_data)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        losses.append(loss.data.numpy())\n        \n\n    return losses\n\ne_losses = []\nnum_epochs = 2\nfor e in range(num_epochs):\n    #losses = train_epoch(model, criterion, optimizer)\n    e_losses += train_epoch(model, criterion, optimizer)\nplt.plot(e_losses)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"086a5307ea186f2f1e41606202984f39c95071e7"},"cell_type":"markdown","source":"### Predict"},{"metadata":{"trusted":true,"_uuid":"9a4edf819edf7246038bedd643d86cc7ea45f07a"},"cell_type":"code","source":"test_data = pd.read_csv('../input/application_test.csv')\n\n#Store ids\ntest_id = test_data.SK_ID_CURR\n\n#Use only continous features\ntest_data = test_data.loc[:, cont_vars]\n\n#Fill NA values\ntest_data[cont_vars] = test_data[cont_vars].fillna(raw_train[cont_vars].mean())\n\n#Normalize data\ntest_data[cont_vars] = std_scale.transform(test_data[cont_vars])\n\n#Convert to tensor\ntorch_test_data = torch.from_numpy(np.array(test_data, dtype=np.float32))\n\n#Make predictions\nprobs = model(torch_test_data)\n\n#Convert to numpy\nprobs = probs.detach().numpy()\n\n#Prepare results\nresult = test_id.to_frame()\nresult[target] = probs\nresult.to_csv('pytorch_first.csv', index=False)","execution_count":1,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"48b50ffb87c2930e51d71cd39cd1e3fbe15cbc50"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}