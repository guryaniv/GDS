{"metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "version": "3.6.3", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "mimetype": "text/x-python"}}, "cells": [{"cell_type": "markdown", "metadata": {"_uuid": "c5c8e70fc7c9cd5667759bb5224fbe3b1aabd692", "_cell_guid": "55fd0f2e-cdca-47d3-972a-3b75d153a7ff"}, "source": ["**Training your own CNN model**\n", "The steps involved are:-\n", "1.\n", "2.\n", "3.\n"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "30eb0745f0ddcdc29928590b73a0728dd73746b2", "_cell_guid": "b976d500-1e50-44e0-97ee-bb08367520fd"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "import os\n", "import cv2\n", "import skimage\n", "import matplotlib.pyplot as plt\n", "from glob import glob\n", "from PIL import Image, ImageOps\n", "from scipy.misc import imresize\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import LabelBinarizer\n", "\n", "Base_Data_Folder = \"../input\"\n", "Train_Data_Folder = os.path.join(Base_Data_Folder, \"train\")"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_kg_hide-input": false, "_uuid": "4246bb380e5fd0aa6109a967cd412cc6d683290e", "_cell_guid": "d8746905-dc5b-4997-ac86-bff54dd876ba"}, "source": ["Read in the images and convert it from RGB to BGR (because OpenCV uses BGR)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "840884072cc2330613e27c0d613cea422a59ca92", "_cell_guid": "845f965d-b568-4e86-a7aa-89a3e37e9ef4"}, "source": ["images = glob('../input/train/*/*.png')\n", "images_per_class = {}\n", "for class_folder_name in os.listdir(Train_Data_Folder):\n", "    class_folder_path = os.path.join(Train_Data_Folder, class_folder_name)\n", "    class_label = class_folder_name\n", "    images_per_class[class_label] = []\n", "    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n", "        image_rgb = cv2.imread(image_path, cv2.IMREAD_COLOR)\n", "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n", "        images_per_class[class_label].append(image_bgr)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "40d9543a4e428c11bd6a22681582178579cbd2e0", "_cell_guid": "ac9426c8-7257-40f3-a4f5-af82886020f6"}, "source": ["**Number of images per class**"]}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "f0c185735938ec3f145f3a60edafc08ae89f41a5", "_cell_guid": "5e65d7a9-8b25-4c7d-b293-3f519c5757e6"}, "source": ["for key,value in images_per_class.items():\n", "    print(\"{0} -> {1}\".format(key, len(value)))"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "cc4a7071f8a3061ba988ff4dc7b1d2125a09b309", "_cell_guid": "97325388-8930-4bd2-b6d0-cabe7daf60f5"}, "source": ["*Preprocessing for the Images*"]}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "ec295c62b9bcfd0ea0862ab66e0eeec747bfa1db", "_cell_guid": "dacbf115-26e8-41bc-8728-5c0d4c830177"}, "source": ["# Test image to see the changes\n", "test_1 = images_per_class[\"Black-grass\"][97]\n", "test_2 = images_per_class[\"Common wheat\"][97]\n", "test_3 = images_per_class[\"Loose Silky-bent\"][97]\n", "\n", "test_1hsv = cv2.cvtColor(test_1, cv2.COLOR_BGR2HSV)\n", "test_2hsv = cv2.cvtColor(test_2, cv2.COLOR_BGR2HSV)\n", "test_3hsv = cv2.cvtColor(test_3, cv2.COLOR_BGR2HSV)\n", "\n", "sensitivity = 35\n", "lower_hsv = np.array([60 - sensitivity, 100, 50])\n", "upper_hsv = np.array([60 + sensitivity, 255, 255])\n", "\n", "mask1 = cv2.inRange(test_1hsv, lower_hsv, upper_hsv)\n", "mask2 = cv2.inRange(test_2hsv, lower_hsv, upper_hsv)\n", "mask3 = cv2.inRange(test_3hsv, lower_hsv, upper_hsv)\n", "\n", "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n", "mask1 = cv2.morphologyEx(mask1, cv2.MORPH_CLOSE, kernel)\n", "mask2 = cv2.morphologyEx(mask2, cv2.MORPH_CLOSE, kernel)\n", "mask3 = cv2.morphologyEx(mask3, cv2.MORPH_CLOSE, kernel)\n", "\n", "output1 = cv2.bitwise_and(test_1, test_1, mask = mask1)\n", "output2 = cv2.bitwise_and(test_2, test_2, mask = mask2)\n", "output3 = cv2.bitwise_and(test_3, test_3, mask = mask3)\n", "\n", "output_blurred1 = cv2.GaussianBlur(output1, (0, 0), 3)\n", "output_blurred2 = cv2.GaussianBlur(output2, (0, 0), 3)\n", "output_blurred3 = cv2.GaussianBlur(output3, (0, 0), 3)\n", "\n", "output_sharp1 = cv2.addWeighted(output1, 1.5, output_blurred1, -0.5, 0)\n", "output_sharp2 = cv2.addWeighted(output2, 1.5, output_blurred2, -0.5, 0)\n", "output_sharp3 = cv2.addWeighted(output3, 1.5, output_blurred3, -0.5, 0)\n", "\n", "fig, axs = plt.subplots(1, 4, figsize=(20, 20))\n", "axs[0].imshow(test_1)\n", "axs[1].imshow(mask1)\n", "axs[2].imshow(output1)\n", "axs[3].imshow(output_sharp1)\n", "\n", "fig, axs = plt.subplots(1, 4, figsize=(20, 20))\n", "axs[0].imshow(test_2)\n", "axs[1].imshow(mask2)\n", "axs[2].imshow(output2)\n", "axs[3].imshow(output_sharp2)\n", "\n", "fig, axs = plt.subplots(1, 4, figsize=(20, 20))\n", "axs[0].imshow(test_3)\n", "axs[1].imshow(mask3)\n", "axs[2].imshow(output3)\n", "axs[3].imshow(output_sharp3)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"collapsed": true, "_uuid": "bdeab42f8c09c69370608d2b5eacde0f86279369", "_cell_guid": "4f9bbd86-a0d3-497e-a14f-6e1f9e031a07"}, "source": ["Change all the images To Green and Black and save them"]}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "de4a024f2f1ec9e78c502c6b153d405b7c49fb10", "_cell_guid": "6c72cfc1-ef46-4c5c-99af-7c02a3b8f89f"}, "source": ["sensitivity = 35\n", "lower_hsv = np.array([60 - sensitivity, 100, 50])\n", "upper_hsv = np.array([60 + sensitivity, 255, 255])\n", "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n", "\n", "images_per_class_processed = {}\n", "for class_folder_name in os.listdir(Train_Data_Folder):\n", "    class_folder_path = os.path.join(Train_Data_Folder, class_folder_name)\n", "    class_label = class_folder_name\n", "    images_per_class_processed[class_label] = []\n", "    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n", "        image_rgb = cv2.imread(image_path, cv2.IMREAD_COLOR)\n", "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n", "        image_resized = cv2.resize(image_bgr, (128, 128)) \n", "        image_hsv = cv2.cvtColor(image_resized, cv2.COLOR_BGR2HSV)\n", "        \n", "        mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n", "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n", "\n", "        output = cv2.bitwise_and(image_resized, image_resized, mask = mask)\n", "\n", "        output_blurred = cv2.GaussianBlur(output, (0, 0), 3)\n", "        output_sharp = cv2.addWeighted(output, 1.5, output_blurred, -0.5, 0)\n", "        \n", "        images_per_class_processed[class_label].append(output_sharp)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "98c89909aa2903d29f7c9b08aed9609cac4c32fa", "_cell_guid": "3eb26d17-a4dd-4418-a3d4-b2fc12c8d3bb"}, "source": ["sensitivity = 35\n", "lower_hsv = np.array([60 - sensitivity, 100, 50])\n", "upper_hsv = np.array([60 + sensitivity, 255, 255])\n", "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n", "\n", "imagez = glob('../input/train/*/*.png')\n", "labels = []\n", "images_processed = []\n", "for image in imagez:\n", "    if image[-3:] != 'png':\n", "        continue\n", "    labels.append(image.split('/')[-2])\n", "    new_img = Image.open(image)\n", "    images_processed.append(ImageOps.fit(new_img, (128, 128), Image.ANTIALIAS).convert('RGB'))"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "1f705b230d03a90c353739b84e62191e578545af", "_cell_guid": "e8377036-4662-4053-927a-f774d2d43274"}, "source": ["sensitivity = 35\n", "lower_hsv = np.array([60 - sensitivity, 100, 50])\n", "upper_hsv = np.array([60 + sensitivity, 255, 255])\n", "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1,1))\n", "\n", "image = np.array(images_processed[213])\n", "image_x = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n", "image_hsv = cv2.cvtColor(image_x, cv2.COLOR_BGR2HSV)\n", "mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n", "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n", "output = cv2.bitwise_and(image, image, mask = mask)\n", "output_blurred = cv2.GaussianBlur(output, (0, 0), 3)\n", "output_sharp = cv2.addWeighted(output, 1.5, output_blurred, -0.5, 0)\n", "Image.fromarray(output_sharp)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "30b8f7de297bda3e3d934b6a8e42cee6ca96cdc9", "_cell_guid": "4dc67498-fd72-4aa1-b443-d6e4546e2ac6"}, "source": [], "outputs": []}], "nbformat": 4, "nbformat_minor": 1}