{"cells":[{"metadata":{"trusted":true,"_uuid":"57432882dee312f49a8635e5ca10dd424af3ebcb"},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\n\n# DRAGONS\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cat\n\n\n# plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\nimport ast\nfrom tqdm import tqdm\nfrom datetime import datetime\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\nrandom_seed = 2019","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85e47d6d91209014e7a3e897e4290793054bf2fb"},"cell_type":"code","source":"def prepare(df):\n    global json_cols\n    global train_dict\n    \n    #df['rating'] = df['rating'].fillna(1.5)\n    #df['totalVotes'] = df['totalVotes'].fillna(6)\n    #df['weightedRating'] = ( df['rating']*df['totalVotes'] + 6.367 * 1000 ) / ( df['totalVotes'] + 1000 )\n\n    df[['release_month','release_day','release_year']]=df['release_date'].str.split('/',expand=True).replace(np.nan, 0).astype(int)\n    df['release_year'] = df['release_year']\n    df.loc[ (df['release_year'] <= 18) & (df['release_year'] < 100), \"release_year\"] += 2000\n    df.loc[ (df['release_year'] > 18)  & (df['release_year'] < 100), \"release_year\"] += 1900\n    \n    releaseDate = pd.to_datetime(df['release_date']) \n    df['release_dayofweek'] = releaseDate.dt.dayofweek \n    df['release_quarter'] = releaseDate.dt.quarter     \n\n    df['_budget_runtime_ratio'] = df['budget']/df['runtime'] \n    df['_budget_popularity_ratio'] = df['budget']/df['popularity']\n    df['_budget_year_ratio'] = df['budget']/(df['release_year']*df['release_year'])\n    df['_releaseYear_popularity_ratio'] = df['release_year']/df['popularity']\n    df['_releaseYear_popularity_ratio2'] = df['popularity']/df['release_year']\n    #df['budget_genre_mean'] = df.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\n\n    #df['_popularity_totalVotes_ratio'] = df['totalVotes']/df['popularity']\n    #df['_rating_popularity_ratio'] = df['rating']/df['popularity']\n    #df['_rating_totalVotes_ratio'] = df['totalVotes']/df['rating']\n    #df['_totalVotes_releaseYear_ratio'] = df['totalVotes']/df['release_year']\n    #df['_budget_rating_ratio'] = df['budget']/df['rating']\n    #df['_runtime_rating_ratio'] = df['runtime']/df['rating']\n    #df['_budget_totalVotes_ratio'] = df['budget']/df['totalVotes']\n    \n    df['has_homepage'] = 0\n    df.loc[pd.isnull(df['homepage']) ,\"has_homepage\"] = 1\n    \n    df['isbelongs_to_collectionNA'] = 0\n    df.loc[pd.isnull(df['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 1\n    \n    df['isTaglineNA'] = 0\n    df.loc[df['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n\n    df['isOriginalLanguageEng'] = 0 \n    df.loc[ df['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\n    \n    df['isTitleDifferent'] = 1\n    df.loc[ df['original_title'] == df['title'] ,\"isTitleDifferent\"] = 0 \n\n    df['isMovieReleased'] = 1\n    df.loc[ df['status'] != \"Released\" ,\"isMovieReleased\"] = 0 \n\n    # get collection id\n    df['collection_id'] = df['belongs_to_collection'].apply(lambda x : np.nan if len(x)==0 else x[0]['id'])\n    \n    df['original_title_letter_count'] = df['original_title'].str.len() \n    df['original_title_word_count'] = df['original_title'].str.split().str.len() \n\n\n    df['title_word_count'] = df['title'].str.split().str.len()\n    df['overview_word_count'] = df['overview'].str.split().str.len()\n    df['tagline_word_count'] = df['tagline'].str.split().str.len()\n    \n    df['production_countries_count'] = df['production_countries'].apply(lambda x : len(x))\n    df['production_companies_count'] = df['production_companies'].apply(lambda x : len(x))\n    df['cast_count'] = df['cast'].apply(lambda x : len(x))\n    df['crew_count'] = df['cast'].apply(lambda x : len(x))\n\n    df['meanruntimeByYear'] = df.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\n    df['meanPopularityByYear'] = df.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\n    df['meanBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('mean')\n    #df['meantotalVotesByYear'] = df.groupby(\"release_year\")[\"totalVotes\"].aggregate('mean')\n    #df['meanTotalVotesByRating'] = df.groupby(\"rating\")[\"totalVotes\"].aggregate('mean')\n\n    for col in ['genres', 'production_countries', 'spoken_languages', 'production_companies'] :\n        df[col] = df[col].map(lambda x: sorted(list(set([n if n in train_dict[col] else col+'_etc' for n in [d['name'] for d in x]])))).map(lambda x: ','.join(map(str, x)))\n        temp = df[col].str.get_dummies(sep=',')\n        df = pd.concat([df, temp], axis=1, sort=False)\n    df.drop(['genres_etc'], axis = 1, inplace = True)\n    \n    df = df.drop(['belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline', 'collection_id'\n    ],axis=1)\n    \n    df.fillna(value=0.0, inplace = True) \n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f23a999bfee2a3f821873380d35225a87d0d032e"},"cell_type":"code","source":"train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\ntest = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')\ntrain_na = pd.read_csv(\"../input/cleandata/clean_train.csv\")\ntest_na  = pd.read_csv(\"../input/cleandata/clean_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1b2d5b223f9821f42b654a1d336d7248fde507d"},"cell_type":"code","source":"### The explanation will be available soon ###\n\ntrain_release = pd.read_csv('../input/releasedata/train_release.csv')\ntest_release = pd.read_csv('../input/releasedata/test_release.csv')\ntrain['X'] = train_release['5']\ntest['X'] = test_release['6']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a5584dbb3be56001b35e61d8e51568d7e850700"},"cell_type":"code","source":"train['X'] = train['X'].shift(periods=1)\ntest['X'] = test['X'].shift(periods=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e37af57b184a2240ccf70a2850c97944e6e5ac9f"},"cell_type":"code","source":"### CLEAN\n\nfor ID in train_na['id'] : \n    train.loc[train['id'] == ID,'budget'] = train_na.loc[train_na['id'] == ID,'budget']\n\n\nfor ID in test_na['id'] : \n    test.loc[test['id'] == ID,'budget'] = test_na.loc[test_na['id'] == ID,'budget']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e431d3aaad9a4a06af3a853e9034883893db747"},"cell_type":"code","source":"train.index = train['id']\ntrain_na.index = train_na['id']\ntest.index = test['id']\ntest_na.index = test_na['id']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52ff5115feeda6cf7d834fc0a50bf822d1c68531"},"cell_type":"markdown","source":"## Clean budget and revenue"},{"metadata":{"trusted":true,"_uuid":"4f31cf8c772aaab7c8fa2e1eb993ece9d73f06e1"},"cell_type":"code","source":"for ID in train_na['id'] : \n    train.loc[train['id'] == ID,'budget'] = train_na.loc[train_na['id'] == ID,'budget']\n\n\nfor ID in test_na['id'] : \n    test.loc[test['id'] == ID,'budget'] = test_na.loc[test_na['id'] == ID,'budget']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcc3263cbba81b86c07776c30c8498d78334a7c5"},"cell_type":"code","source":"train.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\ntrain.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \ntrain.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\ntrain.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\ntrain.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \ntrain.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\ntrain.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\ntrain.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\ntrain.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\ntrain.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\ntrain.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\ntrain.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\ntrain.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\ntrain.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \ntrain.loc[train['id'] == 1542,'budget'] = 1              # All at Once\ntrain.loc[train['id'] == 1542,'budget'] = 15800000       # Crocodile Dundee II\ntrain.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\ntrain.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\ntrain.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\ntrain.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\ntrain.loc[train['id'] == 2491,'revenue'] = 6800000       # Never Talk to Strangers\ntrain.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\ntrain.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\ntrain.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\ntrain.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2c4e93105fac0ca2c48d0b1d4ac7cac1dce74dbd"},"cell_type":"code","source":"test['revenue'] = np.nan\n\n# features from https://www.kaggle.com/kamalchhirang/eda-simple-feature-engineering-external-data\n# train = pd.merge(train, pd.read_csv('../input/tmdb-box-office-movies-rating-total-votes/trainRatingTotalVotes.csv'), how='left', on=['imdb_id'])\n# test = pd.merge(test, pd.read_csv('../input/tmdb-box-office-movies-rating-total-votes/testRatingTotalVotes.csv'), how='left', on=['imdb_id'])\n\njson_cols = ['genres', 'production_companies', 'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\ndef get_dictionary(s):\n    try:\n        d = eval(s)\n    except:\n        d = {}\n    return d\n\nfor col in tqdm(json_cols + ['belongs_to_collection']) :\n    train[col] = train[col].apply(lambda x : get_dictionary(x))\n    test[col] = test[col].apply(lambda x : get_dictionary(x))\n\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21df291d86126c44981d46f9088fcfcbe2ed6306"},"cell_type":"code","source":"# parse json data and build category dictionary\ndef get_json_dict(df) :\n    global json_cols\n    result = dict()\n    for e_col in json_cols :\n        d = dict()\n        rows = df[e_col].values\n        for row in rows :\n            if row is None : continue\n            for i in row :\n                if i['name'] not in d :\n                    d[i['name']] = 0\n                d[i['name']] += 1\n        result[e_col] = d\n    return result\n\ntrain_dict = get_json_dict(train)\ntest_dict = get_json_dict(test)\n\n# remove cateogry with bias and low frequency\nfor col in json_cols :\n    \n    remove = []\n    train_id = set(list(train_dict[col].keys()))\n    test_id = set(list(test_dict[col].keys()))   \n    \n    remove += list(train_id - test_id) + list(test_id - train_id)\n    for i in train_id.union(test_id) - set(remove) :\n        if train_dict[col][i] < 10 or i == '' :\n            remove += [i]\n            \n    for i in remove :\n        if i in train_dict[col] :\n            del train_dict[col][i]\n        if i in test_dict[col] :\n            del test_dict[col][i]\n            \n    print(col, 'size :', len(train_id.union(test_id)), '->', len(train_dict[col]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cabb91e598386382277dde70e3c0fc048020fc2"},"cell_type":"markdown","source":"[Exemple](https://www.themoviedb.org/movie/41393-zyzzyx-road?language=en-US) of a film where his revenu must be multiplied by one million"},{"metadata":{"trusted":true,"_uuid":"3f1e9c4fe77645bd3141d4e4fba1ac1768854b59"},"cell_type":"code","source":"from IPython.display import Image\ndisplay(Image('../input/example/example.PNG', width= 800, unconfined=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbf6f9be26090b15cd5afd9273f19c3345e5ff67"},"cell_type":"code","source":"power_six = train.id[train.budget > 1000][train.revenue < 100]\n\nfor k in power_six :\n    train.loc[train['id'] == k,'revenue'] =  train.loc[train['id'] == k,'revenue'] * 1000000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"632541eeb1c317a45f78885ba8134e7c0e30a3af"},"cell_type":"code","source":"# prepare data\nall_data = prepare(pd.concat([train, test]).reset_index(drop = True))\ntrain = all_data.loc[:train.shape[0] - 1,:]\ntest = all_data.loc[train.shape[0]:,:]                           \nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ea77c5abf24c0b3eff6b3ac8deb50a29545fc60"},"cell_type":"code","source":"sns.distplot(np.log1p(train['budget']), hist=False) # blue\ntrain['budget'] = np.log1p(train['budget'])\ntest['budget'] = np.log1p(test['budget'])\ntrain['popularity'] = np.log1p(train['popularity'])\ntest['popularity'] = np.log1p(test['popularity'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92091377a63d880f0f627a8c596907c99f6a83b0"},"cell_type":"code","source":"features = list(train.columns)\nfeatures =  [i for i in features if i != 'id' and i != 'revenue']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5c5ffd364345402c156a1cfc562fb700e111d9f"},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\ndef score(data, y):\n    validation_res = pd.DataFrame(\n    {\"id\": data[\"id\"].values,\n     \"transactionrevenue\": data[\"revenue\"].values,\n     \"predictedrevenue\": np.expm1(y)})\n\n    validation_res = validation_res.groupby(\"id\")[\"transactionrevenue\", \"predictedrevenue\"].sum().reset_index()\n    return np.sqrt(mean_squared_error(np.log1p(validation_res[\"transactionrevenue\"].values), \n                                     np.log1p(validation_res[\"predictedrevenue\"].values)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b6fd7e2f4162068c25358ee62a9de2e81708084"},"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\n\nclass KFoldValidation():\n    def __init__(self, data, n_splits=5):\n        unique_vis = np.array(sorted(data['id'].astype(str).unique()))\n        folds = GroupKFold(n_splits)\n        ids = np.arange(data.shape[0])\n        \n        self.fold_ids = []\n        for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n            self.fold_ids.append([\n                    ids[data['id'].astype(str).isin(unique_vis[trn_vis])],\n                    ids[data['id'].astype(str).isin(unique_vis[val_vis])]\n                ])\n            \n    def validate(self, train, test, features, model, name=\"\", prepare_stacking=False, \n                 fit_params={\"early_stopping_rounds\": 500, \"verbose\": 100, \"eval_metric\": \"rmse\"}):\n        model.FI = pd.DataFrame(index=features)\n        full_score = 0\n        \n        if prepare_stacking:\n            test[name] = 0\n            train[name] = np.NaN\n        \n        for fold_id, (trn, val) in enumerate(self.fold_ids):\n            devel = train[features].iloc[trn]\n            y_devel = np.log1p(train[\"revenue\"].iloc[trn])\n            valid = train[features].iloc[val]\n            y_valid = np.log1p(train[\"revenue\"].iloc[val])\n                       \n            print(\"Fold \", fold_id, \":\")\n            model.fit(devel, y_devel, eval_set=[(valid, y_valid)], **fit_params)\n            \n            if len(model.feature_importances_) == len(features):  # some bugs in catboost?\n                model.FI['fold' + str(fold_id)] = model.feature_importances_ / model.feature_importances_.sum()\n\n            predictions = model.predict(valid)\n            predictions[predictions < 0] = 0\n            print(\"Fold \", fold_id, \" error: \", mean_squared_error(y_valid, predictions)**0.5)\n            \n            fold_score = score(train.iloc[val], predictions)\n            full_score += fold_score / len(self.fold_ids)\n            print(\"Fold \", fold_id, \" score: \", fold_score)\n            \n            if prepare_stacking:\n                train[name].iloc[val] = predictions\n                \n                test_predictions = model.predict(test[features])\n                test_predictions[test_predictions < 0] = 0\n                test[name] += test_predictions / len(self.fold_ids)\n                \n        print(\"Final score: \", full_score)\n        return full_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83209ee9a2370b8e9c2ab6245368f7a5c4a737a6"},"cell_type":"code","source":"Kfolder = KFoldValidation(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a64da194e395bf795fe5204a41d9824fbfff0a8a"},"cell_type":"code","source":"lgbmodel = lgb.LGBMRegressor(n_estimators=10000, \n                             objective=\"regression\", \n                             metric=\"rmse\", \n                             num_leaves=20, \n                             min_child_samples=100,\n                             learning_rate=0.01, \n                             bagging_fraction=0.8, \n                             feature_fraction=0.8, \n                             bagging_frequency=1, \n                             bagging_seed=random_seed, \n                             subsample=.9, \n                             colsample_bytree=.9,\n                             use_best_model=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07d33f2c3c851799a0e0522d28622d5ce2c79645","scrolled":true},"cell_type":"code","source":"Kfolder.validate(train, test, features , lgbmodel, name=\"lgbfinal\", prepare_stacking=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c2ca2e14e7c48515f366cbebf47d6c0ff8a5070"},"cell_type":"code","source":"lgbmodel.FI.mean(axis=1).sort_values()[150:195].plot(kind=\"barh\",title = \"Features Importance\", figsize = (10,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b72f71849cbf0704ee9de95d8af4104f597d8ea"},"cell_type":"code","source":"xgbmodel = xgb.XGBRegressor(max_depth=6, \n                            learning_rate=0.01, \n                            n_estimators=10000, \n                            objective='reg:linear', \n                            gamma=1.45, \n                            seed=random_seed, \n                            silent=True,\n                            subsample=0.7, \n                            colsample_bytree=0.8, \n                            colsample_bylevel=0.50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5434dfe8ef4c3f931e99fbc39c1a7436bb9ff167"},"cell_type":"code","source":"Kfolder.validate(train, test, features, xgbmodel, name=\"xgbfinal\", prepare_stacking=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29871c5339183800fe9af1d71dd4deb3b1792661"},"cell_type":"code","source":"catmodel = cat.CatBoostRegressor(iterations=10000, \n                                 learning_rate=0.01, \n                                 depth=5, \n                                 eval_metric='RMSE',\n                                 colsample_bylevel=0.7,\n                                 bagging_temperature = 0.2,\n                                 metric_period = None,\n                                 early_stopping_rounds=200,\n                                 random_seed=random_seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9360d3d3b8762bb219ce6ddf31305146a21039c3"},"cell_type":"code","source":"Kfolder.validate(train, test, features , catmodel, name=\"catfinal\", prepare_stacking=True,\n               fit_params={\"use_best_model\": True, \"verbose\": 100})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bab0b764b89acfa54dfd981564721290aec8677"},"cell_type":"code","source":"train['PredictedLogRevenue'] = 0.4 * train[\"lgbfinal\"] + \\\n                               0.2 * train[\"xgbfinal\"] + \\\n                               0.4 * train[\"catfinal\"]\n\nscore(train, train.PredictedLogRevenue)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc0d5a6b02b76383251a5e47784dee6f822a8544"},"cell_type":"code","source":"test['revenue'] =  np.expm1(0.4 *test[\"lgbfinal\"]+  0.4 * test[\"catfinal\"] + 0.2 * test[\"xgbfinal\"])\ntest[['id','revenue']].to_csv('submission.csv', index=False)\nplt.show()\ntest[['id','revenue']].head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}