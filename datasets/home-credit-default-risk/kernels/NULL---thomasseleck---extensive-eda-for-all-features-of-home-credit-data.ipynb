{"cells":[{"metadata":{"_uuid":"c43684b4acaa52588921dc42376deae3b1b71ccf"},"cell_type":"markdown","source":"# Home Credit Default Risk - Exploratory Data Analysis\n\n### Author: Thomas SELECK\n### Date: 2018-05-20\n\nThe purpose of this competition is to detect which clients of Home Credit won't be able to repay their loans.\n\nThe main goal of this notebook is to explore the data provided by Home Credit to see how it looks like and what we can do with it."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"df5a6923856b563fb8021f3e0bed9e2995719c8b"},"cell_type":"code","source":"import time\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', 100)\nimport matplotlib.pylab as plt\n%matplotlib inline\nfrom matplotlib.pylab import rcParams\nimport warnings\nimport seaborn as sns\ncolor = sns.color_palette()\nimport pickle\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\nwarnings.filterwarnings(\"ignore\")\nrcParams['figure.figsize'] = 12, 8\nnp.random.seed(23)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"717e6ac6c74813f385a28a0037e138025e3ac384"},"cell_type":"markdown","source":"## 1. About Kaggle evaluation\n\nSubmissions are evaluated on the AUC metric."},{"metadata":{"_uuid":"45734b1d37ba6b91b4f5d873f8ea3307c16abf57"},"cell_type":"markdown","source":"## 2. About Kaggle submissions\n \nFor each *SK_ID_CURR* in the test set, we must predict a probability for the *TARGET* variable."},{"metadata":{"_uuid":"ac155f5183fd1f6b3d5ae75aeb72427530c1ec92"},"cell_type":"markdown","source":"## 3. Loading the data and first exploration\n\nThe data provided by Home Credit is split in several files.\n\n - <b>application_{train|test}.csv</b><br>\n    This is the main table, broken into two files for Train (with TARGET) and Test (without TARGET).\n    Static data for all applications. One row represents one loan in our data sample.\n    \n    \n - <b>bureau.csv</b><br>\n    All client's previous credits provided by other financial institutions that were reported to Credit Bureau (for clients who\n    have a loan in our sample). For every loan in our sample, there are as many rows as number of credits the client had in\n    Credit Bureau before the application date.\n\n\n - <b>bureau_balance.csv</b><br>\n    Monthly balances of previous credits in Credit Bureau.\n    This table has one row for each month of history of every previous credit reported to Credit Bureau – i.e the table has\n    (#loans in sample * # of relative previous credits * # of months where we have some history observable for the previous\n    credits) rows.\n\n\n - <b>POS_CASH_balance.csv</b><br>\n    Monthly balance snapshots of previous POS (point of sales) and cash loans that the applicant had with Home Credit.\n    This table has one row for each month of history of every previous credit in Home Credit (consumer credit and cash loans)\n    related to loans in our sample – i.e. the table has (#loans in sample * # of relative previous credits * # of months in\n    which we have some history observable for the previous credits) rows.\n\n\n - <b>credit_card_balance.csv</b><br>\n    Monthly balance snapshots of previous credit cards that the applicant has with Home Credit.\n    This table has one row for each month of history of every previous credit in Home Credit (consumer credit and cash loans)\n    related to loans in our sample – i.e. the table has (#loans in sample * # of relative previous credit cards * # of months\n    where we have some history observable for the previous credit card) rows.\n\n\n - <b>previous_application.csv</b><br>\n    All previous applications for Home Credit loans of clients who have loans in our sample.\n    There is one row for each previous application related to loans in our data sample.\n\n\n - <b>installments_payments.csv</b><br>\n    Repayment history for the previously disbursed credits in Home Credit related to the loans in our sample.\n    There is a) one row for every payment that was made plus b) one row each for missed payment.\n    One row is equivalent to one payment of one installment OR one installment corresponding to one payment of one previous\n    Home Credit credit related to loans in our sample.\n\n\n - <b>HomeCredit_columns_description.csv</b><br>\n    This file contains descriptions for the columns in the various data files."},{"metadata":{"trusted":false,"_uuid":"5ba4113a0cac8a3ebff5c994ee16355a21be6f7c"},"cell_type":"code","source":"# Create a dictionary with features types to reduce memory consumption; this roughly halves the needed memory\nmain_features_dtypes_dict = {}\n\n# Add np.int8 cols\nfor col in [\"CNT_CHILDREN\", \"FLAG_MOBIL\", \"FLAG_EMP_PHONE\", \"FLAG_WORK_PHONE\", \"FLAG_CONT_MOBILE\", \"FLAG_PHONE\", \"FLAG_EMAIL\", \n            \"REGION_RATING_CLIENT\", \"REGION_RATING_CLIENT_W_CITY\", \"HOUR_APPR_PROCESS_START\", \"REG_REGION_NOT_LIVE_REGION\", \n            \"REG_REGION_NOT_WORK_REGION\", \"LIVE_REGION_NOT_WORK_REGION\", \"REG_CITY_NOT_LIVE_CITY\", \"REG_CITY_NOT_WORK_CITY\", \n            \"LIVE_CITY_NOT_WORK_CITY\", \"OWN_CAR_AGE\", \"CNT_CREDIT_PROLONG\", \"MONTHS_BALANCE\", \"CNT_DRAWINGS_CURRENT\",\n            \"HOUR_APPR_PROCESS_START\", \"NFLAG_LAST_APPL_IN_DAY\"]:\n    main_features_dtypes_dict[col] = np.int8\n\n# Add np.int16 cols\nfor col in [\"DAYS_BIRTH\", \"DAYS_ID_PUBLISH\", \"DAYS_CREDIT\", \"CREDIT_DAY_OVERDUE\", \"SK_DPD\", \"SK_DPD_DEF\", \"DAYS_DECISION\",\n            \"NUM_INSTALMENT_NUMBER\"]:\n    main_features_dtypes_dict[col] = np.int16\n\n# Add np.int32 cols\nfor col in [\"SK_ID_CURR\", \"DAYS_EMPLOYED\", \"SK_ID_BUREAU\", \"DAYS_CREDIT_UPDATE\", \"SK_ID_BUREAU\", \"SK_ID_PREV\", \n            \"AMT_CREDIT_LIMIT_ACTUAL\", \"SELLERPLACE_AREA\"]:\n    main_features_dtypes_dict[col] = np.int32\n\n# Add np.float16 cols ; these features are integers, but as they contains NAs, they only can be casted to float\nfor col in [\"OWN_CAR_AGE\", \"CNT_FAM_MEMBERS\", \"OBS_30_CNT_SOCIAL_CIRCLE\", \"DEF_30_CNT_SOCIAL_CIRCLE\", \"OBS_60_CNT_SOCIAL_CIRCLE\",\n            \"DEF_60_CNT_SOCIAL_CIRCLE\", \"DAYS_LAST_PHONE_CHANGE\", \"AMT_REQ_CREDIT_BUREAU_HOUR\", \"AMT_REQ_CREDIT_BUREAU_DAY\", \n            \"AMT_REQ_CREDIT_BUREAU_WEEK\", \"AMT_REQ_CREDIT_BUREAU_MON\", \"AMT_REQ_CREDIT_BUREAU_QRT\", \"AMT_REQ_CREDIT_BUREAU_YEAR\",\n            \"CNT_INSTALMENT\", \"CNT_INSTALMENT_FUTURE\", \"CNT_DRAWINGS_ATM_CURRENT\", \"CNT_DRAWINGS_OTHER_CURRENT\", \n            \"CNT_DRAWINGS_POS_CURRENT\", \"CNT_INSTALMENT_MATURE_CUM\", \"CNT_PAYMENT\", \"NFLAG_INSURED_ON_APPROVAL\",\n            \"NUM_INSTALMENT_VERSION\", \"DAYS_INSTALMENT\", \"DAYS_ENTRY_PAYMENT\"]:\n    main_features_dtypes_dict[col] = np.float16\n\n# Add np.float32 cols\nfor col in [\"AMT_INCOME_TOTAL\", \"AMT_CREDIT\", \"AMT_ANNUITY\", \"AMT_GOODS_PRICE\", \"REGION_POPULATION_RELATIVE\", \"DAYS_REGISTRATION\",\n            \"APARTMENTS_AVG\", \"BASEMENTAREA_AVG\", \"YEARS_BEGINEXPLUATATION_AVG\", \"YEARS_BUILD_AVG\", \"COMMONAREA_AVG\", \n            \"ELEVATORS_AVG\", \"ENTRANCES_AVG\", \"FLOORSMAX_AVG\", \"FLOORSMIN_AVG\", \"LANDAREA_AVG\", \"LIVINGAPARTMENTS_AVG\", \n            \"LIVINGAREA_AVG\", \"NONLIVINGAPARTMENTS_AVG\", \"NONLIVINGAREA_AVG\", \"APARTMENTS_MODE\", \"BASEMENTAREA_MODE\", \n            \"YEARS_BEGINEXPLUATATION_MODE\", \"YEARS_BUILD_MODE\", \"COMMONAREA_MODE\", \"ELEVATORS_MODE\", \"ENTRANCES_MODE\", \n            \"FLOORSMAX_MODE\", \"FLOORSMIN_MODE\", \"LANDAREA_MODE\", \"LIVINGAPARTMENTS_MODE\", \"LIVINGAREA_MODE\", \n            \"NONLIVINGAPARTMENTS_MODE\", \"NONLIVINGAREA_MODE\", \"APARTMENTS_MEDI\", \"BASEMENTAREA_MEDI\", \n            \"YEARS_BEGINEXPLUATATION_MEDI\", \"YEARS_BUILD_MEDI\", \"COMMONAREA_MEDI\", \"ELEVATORS_MEDI\", \"ENTRANCES_MEDI\", \n            \"FLOORSMAX_MEDI\", \"FLOORSMIN_MEDI\", \"LANDAREA_MEDI\", \"LIVINGAPARTMENTS_MEDI\", \"LIVINGAREA_MEDI\", \n            \"NONLIVINGAPARTMENTS_MEDI\", \"NONLIVINGAREA_MEDI\", \"TOTALAREA_MODE\", \"DAYS_CREDIT_ENDDATE\", \"DAYS_ENDDATE_FACT\", \n            \"AMT_CREDIT_MAX_OVERDUE\", \"AMT_CREDIT_SUM\", \"AMT_CREDIT_SUM_DEBT\", \"AMT_CREDIT_SUM_LIMIT\", \"AMT_CREDIT_SUM_OVERDUE\", \n            \"AMT_ANNUITY\", \"AMT_BALANCE\", \"AMT_DRAWINGS_ATM_CURRENT\", \"AMT_DRAWINGS_CURRENT\", \"AMT_DRAWINGS_OTHER_CURRENT\", \n            \"AMT_DRAWINGS_POS_CURRENT\", \"AMT_INST_MIN_REGULARITY\", \"AMT_PAYMENT_CURRENT\", \"AMT_PAYMENT_TOTAL_CURRENT\", \n            \"AMT_RECEIVABLE_PRINCIPAL\", \"AMT_RECIVABLE\", \"AMT_TOTAL_RECEIVABLE\", \"AMT_APPLICATION\", \"AMT_CREDIT\", \n            \"AMT_DOWN_PAYMENT\", \"AMT_GOODS_PRICE\", \"DAYS_FIRST_DRAWING\", \"DAYS_FIRST_DUE\", \"DAYS_LAST_DUE_1ST_VERSION\", \n            \"DAYS_LAST_DUE\", \"DAYS_TERMINATION\", \"AMT_INSTALMENT\", \"AMT_PAYMENT\"]:\n    main_features_dtypes_dict[col] = np.float32\n\nfor i in range(2, 22):\n    main_features_dtypes_dict[\"FLAG_DOCUMENT_\" + str(i)] = np.int8\n\nprint(\"    Loading: ../input/application_train.csv ...\")\ntraining_set_df = pd.read_csv(\"../input/application_train.csv\", dtype = main_features_dtypes_dict)\nprint(\"    Loading: ../input/application_test.csv ...\")\ntesting_set_df = pd.read_csv(\"../input/application_test.csv\", dtype = main_features_dtypes_dict)\nprint(\"    Loading: ../input/bureau.csv ...\")\nbureau_data_df = pd.read_csv(\"../input/bureau.csv\", dtype = main_features_dtypes_dict)\nprint(\"    Loading: ../input/bureau_balance.csv ...\")\nbureau_balance_data_df = pd.read_csv(\"../input/bureau_balance.csv\", dtype = main_features_dtypes_dict)\nprint(\"    Loading: ../input/credit_card_balance.csv ...\")\ncredit_card_balance_data_df = pd.read_csv(\"../input/credit_card_balance.csv\", dtype = main_features_dtypes_dict)\nprint(\"    Loading: ../input/installments_payments.csv ...\")\ninstallments_payments_data_df = pd.read_csv(\"../input/installments_payments.csv\", dtype = main_features_dtypes_dict)\nprint(\"    Loading: ../input/POS_CASH_balance.csv ...\")\npos_cash_balance_data_df = pd.read_csv(\"../input/POS_CASH_balance.csv\", dtype = main_features_dtypes_dict)\nprint(\"    Loading: ../input/previous_application.csv ...\")\nprevious_application_data_df = pd.read_csv(\"../input/previous_application.csv\", dtype = main_features_dtypes_dict)\n\n# Put ID as index\nprint(\"    Put 'SK_ID_CURR' as index...\")\ntraining_set_df.index = training_set_df[\"SK_ID_CURR\"]\ntraining_set_df.drop(\"SK_ID_CURR\", axis = 1, inplace = True)\ntesting_set_df.index = testing_set_df[\"SK_ID_CURR\"]\ntesting_set_df.drop(\"SK_ID_CURR\", axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5df00d6e962209a5583dfa144670b3f380648fbc"},"cell_type":"markdown","source":"### 3.1. Looking at the target\n\nHere we want to solve a binary classification problem: either the client can repay its loan or not. What we want to know is the proportion of loan default: is the target unbalanced?"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"d2fddd578ee4ee9f6938e489a3d4df700e30b9f1"},"cell_type":"code","source":"sns.countplot(x = training_set_df[\"TARGET\"])\nplt.title(\"Count plot of each level of the target\")\nprint(\"Percentage of positive target:\", round((training_set_df[\"TARGET\"].loc[training_set_df[\"TARGET\"] == 1].shape[0] / training_set_df[\"TARGET\"].shape[0]) * 100, 4), \"%\")\nprint(\"Percentage of negative target:\", round((training_set_df[\"TARGET\"].loc[training_set_df[\"TARGET\"] == 0].shape[0] / training_set_df[\"TARGET\"].shape[0]) * 100, 4), \"%\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aaf95a7479326516964d6bb627e8eb1d1de4d636"},"cell_type":"markdown","source":"Only 8% of the samples have a positive target. The data is highly unbalanced.\nNow let's look at features from the main dataset: application_train.csv.\n\n### 3.2. Looking at main data: application_train.csv\n\nWe'll begin by diving in the data using univariate analysis. Firstly, we split our dataset into three parts: categorical features, binary features (dummies) and numerical ones."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"044f957f50bd6ff24da515623f1001082a1742ed"},"cell_type":"code","source":"nb_levels_sr = training_set_df.nunique()\nbinary_features_lst = nb_levels_sr.loc[nb_levels_sr == 2].index.tolist()\ncategorical_features_lst = list(set(training_set_df.select_dtypes([\"object\"]).columns.tolist()) - set(binary_features_lst))\nnumerical_features_lst = list(set(training_set_df.columns.tolist()) - set(categorical_features_lst) - set(binary_features_lst))\nbinary_features_lst = list(set(binary_features_lst) - {\"TARGET\"})\n\nprint(\"Binary features:\", binary_features_lst)\nprint(\"\\n\")\nprint(\"Categorical features:\", categorical_features_lst)\nprint(\"\\n\")\nprint(\"Numerical features:\", numerical_features_lst)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed6be191932242e4ebf87c3cf5cb9e755c143104"},"cell_type":"markdown","source":"We'll begin by looking at how binary features relate with the target."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f6927eb758c74015b59e0a5454c515cdc8fb0be1"},"cell_type":"code","source":"binary_features_lst.sort()\n\nfig, ax = plt.subplots(6, 6, sharex = False, sharey = False, figsize = (20, 20))\ni = 0\nj = 0\nfor idx in range(len(binary_features_lst)):\n    if idx % 6 == 0 and idx != 0:\n        j += 1\n        \n    i = idx % 6\n    feature = binary_features_lst[idx]\n    table_df = pd.crosstab(training_set_df[\"TARGET\"], training_set_df[feature], normalize = True)\n    # Normalize statistics to remove target unbalance\n    table_df = table_df.div(table_df.sum(axis = 1), axis = 0)\n    table_df = table_df.div(table_df.sum(axis = 0), axis = 1)\n    sns.heatmap(table_df, annot = True, square = True, ax = ax[j, i], cbar = False, fmt = '.2%')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a4ebc5678a84459bb5b4f34c9e8c1cd80b240c2"},"cell_type":"markdown","source":"Here, we can see that some binary features, when they equal to 1, gives the right target. These features are the following:\n - *FLAG_DOCUMENT_10*\n - *FLAG_DOCUMENT_12*\n - *FLAG_DOCUMENT_4*\n\nFor the feature *FLAG_MOBIL*, when it equals to 0, the target is always 0.\nAnother interesting fact is that for those four features, when they are the other level (0 for the first three, and 1 for the last one), probability of target equal to 1 is 50%. So in this case these features are totally useless.\n\nNow, let's look at categorical features."},{"metadata":{"scrolled":false,"trusted":false,"collapsed":true,"_uuid":"359cb8077caf50467a051d631ff2c211662da4c1"},"cell_type":"code","source":"for feature in categorical_features_lst:\n    fig, ax = plt.subplots(1, 2, sharex = False, sharey = False, figsize = (20, 10))\n    # Plot levels distribution\n    if training_set_df[feature].nunique() < 10:\n        sns.countplot(x = training_set_df[feature], ax = ax[0], order = training_set_df[feature].value_counts().index.tolist())\n    else:\n        sns.countplot(y = training_set_df[feature], ax = ax[0], order = training_set_df[feature].value_counts().index.tolist())\n    ax[0].set_title(\"Count plot of each level of the feature: \" + feature)\n\n    # Plot target distribution among levels\n    table_df = pd.crosstab(training_set_df[\"TARGET\"], training_set_df[feature], normalize = True)\n    table_df = table_df.div(table_df.sum(axis = 0), axis = 1)\n    table_df = pd.crosstab(training_set_df[\"TARGET\"], training_set_df[feature], normalize = True)\n    table_df = table_df.div(table_df.sum(axis = 0), axis = 1)\n    table_df = table_df.transpose().reset_index()\n    order_lst = table_df.sort_values(by = 1)[feature].tolist()\n    table_df = table_df.melt(id_vars = [feature])\n    if training_set_df[feature].nunique() < 10:\n        ax2 = sns.barplot(x = table_df[feature], y = table_df[\"value\"] * 100, hue = table_df[\"TARGET\"], ax = ax[1], order = order_lst)\n        for p in ax2.patches:\n            height = p.get_height()\n            ax2.text(p.get_x() + p.get_width() / 2., height + 1, \"{:1.2f}\".format(height), ha = \"center\")\n    else:\n        ax2 = sns.barplot(x = table_df[\"value\"] * 100, y = table_df[feature], hue = table_df[\"TARGET\"], ax = ax[1], order = order_lst)\n        for p in ax2.patches:\n            width = p.get_width()\n            ax2.text(width + 3.1, p.get_y() + p.get_height() / 2. + 0.35, \"{:1.2f}\".format(width), ha = \"center\")\n\n    ax[1].set_title(\"Target distribution among \" +  feature + \" levels\")\n    ax[1].set_ylabel(\"Percentage\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83ea1c42aed6fedb8d052799375f6d48cf649b96"},"cell_type":"markdown","source":"Here, we can see some interesting insights from this data:\n - Materials composing the walls do have an influence on the default risk of the client: clients living in Wooden houses have twice the risk of default than clients living in Monolithic houses\n - The distribution of the type of organization where the client works is highly skewed, but we can see that some sectors are more prone to have defaulting clients. It will be interesting to link them with client's wages.\n - The vast majority of clients come to the bank to get a loan unaccompanied. But this feature doesn't have a great influence on the default risk.\n - Client's education have a great impact on his default risk: having an academic degree reduces the default risk 5 times compared to lower secondary education. There is probably a link between education, salary and ease of finding and keeping a job.\n - Majority of clients are laborers or sales staff. Here being an accountant reduces the default risk by a factor of 3.55 compared to a low-skilled laborer. This goes in the same way than education.\n - Most of the clients are married, but family status have a low impact on default risk unless you are a widow. In this case, your risk decrease.\n - The studied population is composed of 1/3 men and 2/3 women. Men have a higher risk of default than women.\n - Majority of people live in a flat or house they own. People that live with their parents or in a rented appartment have twice the risk than people that own their home.\n - Income type has a great impact on the default risk. Unemployed people or people in maternity leave have a huge default risk.\n - Majority of people live in a block of flats.\n \nHere, we can see that population is split on two axis that are correlated: the people's wealth (poorest people have greater default risk than richest ones) and the people's education (higher education means lower default risk).\n\nNow, let's look at numerical features."},{"metadata":{"scrolled":false,"trusted":false,"collapsed":true,"_uuid":"c90a0173e395a16c114f831a3f2582a04f1f754b"},"cell_type":"code","source":"# generate the linkage matrix\nnumerical_features_df = training_set_df[numerical_features_lst + [\"TARGET\"]]\nnumerical_features_df.fillna(-1, inplace = True) # We need to impute missing values before creating the dendrogram\nnumerical_features_df = numerical_features_df.transpose()\nZ = linkage(numerical_features_df, \"ward\")\nplt.figure(figsize = (20, 15))\nplt.title(\"Hierarchical Clustering Dendrogram\")\nplt.xlabel(\"feature\")\nplt.ylabel(\"distance\")\ndend = dendrogram(\n    Z,\n    leaf_rotation = 90.,  # rotates the x axis labels\n    leaf_font_size = 8.,  # font size for the x axis labels\n    labels = numerical_features_df.index.tolist()\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f03957844e426aa43f15851161306870c8a4f0ec"},"cell_type":"markdown","source":"From the dendrogram above, we can distinguish several groups of features that similar.\n - *AMT_CREDIT* and *AMT_GOODS_PRICE* are in the same cluster. One feature gives the amount of the loan, the other gives the price of the good we want to buy with the loan. As in the majority of cases the amount of the loan equals the price of the good, both features will be highly similar and correlated.\n - *DAYS_ID_PUBLISH* and *DAYS_REGISTRATION*: these features indicate the number of days between the loan application and the change of the identity document with which he applied for the loan for the first and days between the loan application and the change of registration for the second. As these features are similar, we can think that when the client changes his registration, he also changes his identity document.\n - *AMT_INCOME_TOTAL*, *DAYS_EMPLOYED*, *AMT_ANNUITY*, *DAYS_BIRTH* are put apart from other features by hierarchical clustering.\n - Other features are highly similar and are related to the home of the client.\n - \"Black box\" features *EXT_SOURCE_1*, *EXT_SOURCE_2*, *EXT_SOURCE_3* are in the same group than home-related features. Maybe they also are related to client's home.\n \nNow, let's plot correlation matrix between the numerical features and the target."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f31f62f8a186e36dd708527a777b86ab04301204"},"cell_type":"code","source":"plt.figure(figsize = (20, 20))\nsns.heatmap(training_set_df[dend[\"ivl\"]].corr(), annot = False, square = True)\nplt.title(\"Correlation plot between numerical features and target\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e5ffc221679b2e49e04b9cfd8d3c7fb2556d285"},"cell_type":"markdown","source":"Here, we can see that numerical features have a low correlation with the target we want to predict. Only the features *EXT_SOURCE_1*, *EXT_SOURCE_2* and *EXT_SOURCE_3* have a correlation greater than 15%.\n\nWe can also distinguish clusters of features in white / yellow on the correlation plot above that are highly correlated. These features are majoritely related to the client's home.\n\nHere, client's home have a low correlation with target: the home where the client lives have little impact on the default risk. It's probably because near all clients live in a block of flats and their homes are similar.\n\nNow let's plot each numerical feature to look at its distribution."},{"metadata":{"scrolled":false,"trusted":false,"collapsed":true,"_uuid":"39afb51b89d0fc9c89686e247b497cf0f4b21208"},"cell_type":"code","source":"for feature in numerical_features_lst:\n    fig, ax = plt.subplots(1, 2, sharex = False, sharey = False, figsize = (20, 7))\n    \n    # Plot feature distribution\n    plot_df = training_set_df[[feature, \"TARGET\"]].dropna()\n    sns.distplot(plot_df[feature], kde = False, bins = 100, ax = ax[0])\n    ax[0].set_title(\"Histogram of the feature: \" + feature)\n\n    # Plot feature against target\n    sns.boxplot(x = training_set_df[\"TARGET\"], y = training_set_df[feature], ax = ax[1])\n    ax[1].set_title(\"Boxplot of the feature: \" + feature + \" wrt TARGET\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f3e695ae95e8c61ab9a90e2fde4aa4a544efedc"},"cell_type":"markdown","source":"From the plots above, we can see the following:\n - There are outliers in the data: some clients are employed since a negative number of days. Some clients can have an income greater than \\$100M\n - Some numerical are actually categorical features. For instance, it's the case for *FLOORSMAX_AVG*. Denormalizing those features maybe can add some value to the data.\n - Lots of features have an important skewness. Dealing with this can improve performances.\n \n### 3.3. Looking at missing values from application_train.csv\n\nNow, let's look at missing values distribution in the data."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"c42788d9485abf91ff9e9921d03c1b19cf1932b5"},"cell_type":"code","source":"missing_values_sr = training_set_df.isnull().sum()\nmissing_values_df = missing_values_sr.loc[missing_values_sr > 0].sort_values(ascending = False).reset_index()\nmissing_values_df.columns = [\"Feature\", \"Number of missing values\"]\nmissing_values_df[\"Percentage of missing values\"] = (missing_values_df[\"Number of missing values\"] / training_set_df.shape[0]) * 100\n\nsns.barplot(x = missing_values_df[\"Feature\"], y = missing_values_df[\"Percentage of missing values\"])\nplt.xticks(rotation = 90)\nplt.title(\"Percentage of missing values in the application data\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2eec7149f13ce29b6227964e8898b41d3637e2fc"},"cell_type":"markdown","source":"Here, we can see that some features have a lot of missing values (near 70%). It will be interesting to know if number of missing value for each client have an impact on the performances of the predictive model."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"eeb71dda32c3bc48e902eb52173fb7bb71ee87e2"},"cell_type":"code","source":"is_missing_df = training_set_df.isnull().astype(np.int8)\nis_missing_df = is_missing_df[missing_values_df[\"Feature\"]]\n\nfig, ax = plt.subplots(9, 8, sharex = False, sharey = False, figsize = (26, 30))\ni = 0\nj = 0\nfor idx in range(len(missing_values_df[\"Feature\"])):\n    if idx % 8 == 0 and idx != 0:\n        j += 1\n        \n    i = idx % 8\n    feature = is_missing_df.columns.tolist()[idx]\n    table_df = pd.crosstab(training_set_df[\"TARGET\"], is_missing_df[feature], normalize = True)\n    # Normalize statistics to remove target unbalance\n    table_df = table_df.div(table_df.sum(axis = 1), axis = 0)\n    table_df = table_df.div(table_df.sum(axis = 0), axis = 1)\n    sns.heatmap(table_df, annot = True, square = True, ax = ax[j, i], cbar = False, fmt = '.2%')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c29bc24ec9c088d8ecc6e7bc33c62e6df157cd6"},"cell_type":"markdown","source":"Interesting: we can see that when *AMT_ANNUITY*, *CNT_FAM_MEMBERS* and *DAYS_LAST_PHONE_CHANGE* are missing, then the target is always 0. They can be interesting features to add to our model.\n\n### 3.4. Looking at bureau.csv and bureau_balance.csv\n\nNow, let's explore those two additional files. Let's begin by merging them into a single data frame."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"b8a0a29adabb0cf05334744b5571d9bcc448ddb9"},"cell_type":"code","source":"merged_df = bureau_data_df.merge(bureau_balance_data_df, how = \"left\", on = \"SK_ID_BUREAU\")\nmerged_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"adf9641c26a6bc36a0ed7f1e8696b0d5ac706ed2"},"cell_type":"markdown","source":"Now, we'll look at categorical features inside this dataset."},{"metadata":{"scrolled":false,"trusted":false,"collapsed":true,"_uuid":"2f3435430e17e6049d667a4d004026c425091d8f"},"cell_type":"code","source":"categorical_features_lst = merged_df.select_dtypes([\"object\"]).columns.tolist()\n\nfor feature in categorical_features_lst:\n    fig, ax = plt.subplots(1, 1, sharex = False, sharey = False, figsize = (20, 10))\n    # Plot levels distribution\n    if merged_df[feature].nunique() < 10:\n        sns.countplot(x = merged_df[feature], ax = ax, order = merged_df[feature].value_counts().index.tolist())\n    else:\n        sns.countplot(y = merged_df[feature], ax = ax, order = merged_df[feature].value_counts().index.tolist())\n    ax.set_title(\"Count plot of each level of the feature: \" + feature)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6db395c4edca7114a7d485517314b060bba6c81d"},"cell_type":"markdown","source":"From the plots above, we can see that the majority of credits are either closed or active.\nOne currency dominates all credits. Maybe its USD.\nThe majority of loans are consumer credits or credit card. Then car loans and mortgage loans come after.\nThe last plot shows us the status of Credit Bureau loan during the month. This feature seems similar to *CREDIT_ACTIVE*.\n\nNow, let's look at numerical features."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"00e1708798ee2083c294d25a0a971e3c9768e3b9"},"cell_type":"code","source":"numerical_features_lst = list(set(merged_df.columns.tolist()) - set(categorical_features_lst))\n\n# generate the linkage matrix\nnumerical_features_df = merged_df[numerical_features_lst]\nnumerical_features_df.fillna(-1, inplace = True) # We need to impute missing values before creating the dendrogram\nnumerical_features_df = numerical_features_df.transpose()\nZ = linkage(numerical_features_df, \"ward\")\nplt.figure(figsize = (20, 15))\nplt.title(\"Hierarchical Clustering Dendrogram\")\nplt.xlabel(\"feature\")\nplt.ylabel(\"distance\")\ndend = dendrogram(\n    Z,\n    leaf_rotation = 90.,  # rotates the x axis labels\n    leaf_font_size = 8.,  # font size for the x axis labels\n    labels = numerical_features_df.index.tolist()\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"236e6c2c0e743bc7227fd15ab63656fc091bb0d9"},"cell_type":"markdown","source":"Here, we can see that date-related features are highly similar."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f1e1532b358b0e5e392fa98a1e0ec9025c3a6337"},"cell_type":"code","source":"plt.figure(figsize = (20, 20))\nsns.heatmap(merged_df[dend[\"ivl\"]].corr(), annot = True, square = True)\nplt.title(\"Correlation plot between numerical features\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e08d7fd396e3a39b1ffd99963ab8b22c1a3158d"},"cell_type":"markdown","source":"Here we can see that some features related to how many days before current application did client apply for Credit Bureau credit are highly correlated. High correlation exists between *AMT_CREDIT_SUM* and *AMT_CREDIT_SUM_DEBT*. Other features are not correlated, as correlation is near zero.\n\nNow, let's plots histograms of these features."},{"metadata":{"scrolled":false,"trusted":false,"collapsed":true,"_uuid":"3c7361c42951a3bd54e4f2d76615de34b60870fc"},"cell_type":"code","source":"for feature in numerical_features_lst:\n    fig, ax = plt.subplots(1, 1, sharex = False, sharey = False, figsize = (20, 7))\n    \n    # Plot feature distribution\n    sns.distplot(merged_df[feature].dropna(), kde = False, bins = 100, ax = ax)\n    ax.set_title(\"Histogram of the feature: \" + feature)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"645092ba07d1218186a35670c1de90c522ab6392"},"cell_type":"markdown","source":"From the histograms above, we can get some useful insights:\n - They are a lot of outliers, especially for features: *CREDIT_DAY_OVERDUE*, *AMT_CREDIT_SUM_DEBT*, *AMT_ANNUITY*, *AMT_CREDIT_SUM*, *DAYS_CREDIT_ENDDATE*, *AMT_CREDIT_SUM_LIMIT*, *CNT_CREDIT_PROLONG*, *DAYS_ENDDATE_FACT*, *AMT_CREDIT_SUM_OVERDUE*, *AMT_CREDIT_MAX_OVERDUE*, *DAYS_CREDIT_UPDATE*\n - For *MONTHS_BALANCE*, why three bins are missing?\n \nNow, let's look at missing values."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"379f3eabe5594923dcde2be1b672e0ab42879984"},"cell_type":"code","source":"missing_values_sr = merged_df.isnull().sum()\nmissing_values_df = missing_values_sr.loc[missing_values_sr > 0].sort_values(ascending = False).reset_index()\nmissing_values_df.columns = [\"Feature\", \"Number of missing values\"]\nmissing_values_df[\"Percentage of missing values\"] = (missing_values_df[\"Number of missing values\"] / merged_df.shape[0]) * 100\n\nsns.barplot(x = missing_values_df[\"Feature\"], y = missing_values_df[\"Percentage of missing values\"])\nplt.xticks(rotation = 90)\nplt.title(\"Percentage of missing values in the bureau and bureau balance data\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fdb651b335cfc6b9569fb6183cf02e5609d3b697"},"cell_type":"markdown","source":"Here, we can see that only nine features have missing values.\n\n# 3.5. Looking at credit_card_balance.csv\n\nThis data contains monthly balance snapshots of previous credit card clients have with Home Credit."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"62965bb5f67c0e5440daedd3f808ade4383140a8"},"cell_type":"code","source":"categorical_features_lst = credit_card_balance_data_df.select_dtypes([\"object\"]).columns.tolist()\n\nfor feature in categorical_features_lst:\n    fig, ax = plt.subplots(1, 1, sharex = False, sharey = False, figsize = (20, 10))\n    # Plot levels distribution\n    if credit_card_balance_data_df[feature].nunique() < 10:\n        sns.countplot(x = credit_card_balance_data_df[feature], ax = ax, order = credit_card_balance_data_df[feature].value_counts().index.tolist())\n    else:\n        sns.countplot(y = credit_card_balance_data_df[feature], ax = ax, order = credit_card_balance_data_df[feature].value_counts().index.tolist())\n    ax.set_title(\"Count plot of each level of the feature: \" + feature)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2810e7e289c654a622e854f9845eef6a24f0fe2"},"cell_type":"markdown","source":"In this dataset, there is only one categorical feature that indicates the contract status on the previous credit. We can see that most previous credits are still active.\n\nNow, let's look at numerical features."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"dfe74a3a2b077de9496904d57f323857ad150df3"},"cell_type":"code","source":"numerical_features_lst = list(set(credit_card_balance_data_df.columns.tolist()) - set(categorical_features_lst))\n\n# generate the linkage matrix\nnumerical_features_df = credit_card_balance_data_df[numerical_features_lst]\nnumerical_features_df.fillna(-1, inplace = True) # We need to impute missing values before creating the dendrogram\nnumerical_features_df = numerical_features_df.transpose()\nZ = linkage(numerical_features_df, \"ward\")\nplt.figure(figsize = (20, 15))\nplt.title(\"Hierarchical Clustering Dendrogram\")\nplt.xlabel(\"feature\")\nplt.ylabel(\"distance\")\ndend = dendrogram(\n    Z,\n    leaf_rotation = 90.,  # rotates the x axis labels\n    leaf_font_size = 8.,  # font size for the x axis labels\n    labels = numerical_features_df.index.tolist()\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3598e9cc8f73fbfc166c383b47564cdff4ee33b"},"cell_type":"markdown","source":"Here, we can see that features can be split into two clusters: features from *AMT_PAYMENT_TOTAL_CURRENT* to *CNT_DRAWINGS_POS_CURRENT* and from *AMT_CREDIT_LIMIT_ACTUAL* to *AMT_RECIVABLE*. The first cluster groups features related to the amount and number of drawings, whereas the second one deals with balance amount and credit limit."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"6427a6ce460eb53564b771c76fa419d96697bb5f"},"cell_type":"code","source":"plt.figure(figsize = (20, 20))\nsns.heatmap(credit_card_balance_data_df[dend[\"ivl\"]].corr(), annot = True, square = True)\nplt.title(\"Correlation plot between numerical features\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc1e3369d1ad20e2221368807104288390c8fbb9"},"cell_type":"markdown","source":"Here, we can see some highly correlated features or even duplicated features (*AMT_RECEIVABLE_PRINCIPAL*, *AMT_BALANCE*, *AMT_TOTAL_RECEIVABLE* and *AMT_RECEIVABLE*).\n\nNow let's look at those features' distribution."},{"metadata":{"scrolled":false,"trusted":false,"collapsed":true,"_uuid":"23a3ae7e409364890be218a204cc82010274a307"},"cell_type":"code","source":"for feature in numerical_features_lst:\n    fig, ax = plt.subplots(1, 1, sharex = False, sharey = False, figsize = (20, 7))\n    \n    # Plot feature distribution\n    sns.distplot(credit_card_balance_data_df[feature].dropna(), kde = False, bins = 100, ax = ax)\n    ax.set_title(\"Histogram of the feature: \" + feature)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00c8133e6bd7b1ae0caa107ebc1b86be915fd8e5"},"cell_type":"markdown","source":"Here, we have a lot of outliers. We also have four bins missing in *MONTHS_BALANCE*.\n\nNow, let's look at outliers."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"87885a2a81d6b0a736e35b269d1aa7c1341e7736"},"cell_type":"code","source":"missing_values_sr = credit_card_balance_data_df.isnull().sum()\nmissing_values_df = missing_values_sr.loc[missing_values_sr > 0].sort_values(ascending = False).reset_index()\nmissing_values_df.columns = [\"Feature\", \"Number of missing values\"]\nmissing_values_df[\"Percentage of missing values\"] = (missing_values_df[\"Number of missing values\"] / credit_card_balance_data_df.shape[0]) * 100\n\nsns.barplot(x = missing_values_df[\"Feature\"], y = missing_values_df[\"Percentage of missing values\"])\nplt.xticks(rotation = 90)\nplt.title(\"Percentage of missing values in the credit card balance data\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"394fb545f158dd314c4241b4ed1afebd43facf8a"},"cell_type":"markdown","source":"Here, only nine features have missing values. Furthermore, the amount of missing value is less than 20% and seems to be the same for six features.\n\n### 3.6. Looking at installments_payments.csv\n\nThis dataset gives us data about repayment history for the loans in our data sample."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ccb4b0277b68a64a1defa1445ec9b479576a6508"},"cell_type":"code","source":"numerical_features_lst = installments_payments_data_df.columns.tolist()\n\n# generate the linkage matrix\nnumerical_features_df = installments_payments_data_df[numerical_features_lst]\nnumerical_features_df.fillna(-1, inplace = True) # We need to impute missing values before creating the dendrogram\nnumerical_features_df = numerical_features_df.transpose()\nZ = linkage(numerical_features_df, \"ward\")\nplt.figure(figsize = (20, 15))\nplt.title(\"Hierarchical Clustering Dendrogram\")\nplt.xlabel(\"feature\")\nplt.ylabel(\"distance\")\ndend = dendrogram(\n    Z,\n    leaf_rotation = 90.,  # rotates the x axis labels\n    leaf_font_size = 8.,  # font size for the x axis labels\n    labels = numerical_features_df.index.tolist()\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"168dfffd64957f1b2888cae5b340f89c99c93c50"},"cell_type":"markdown","source":"This dataset only contains numerical features. So we skipped the categorical features analysis part. We can see here that if we exclude keys needed to join data (*SK_ID_PREV* and *SK_ID_CURR*), all features seems similar."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"2362384fafbfcdb0589adabff5e6fc3782bcbb45"},"cell_type":"code","source":"plt.figure(figsize = (15, 15))\nsns.heatmap(installments_payments_data_df[dend[\"ivl\"]].corr(), annot = True, square = True)\nplt.title(\"Correlation plot between numerical features\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e0e831088665080fee6c3ef3c69ea0cc6511506"},"cell_type":"markdown","source":"Here we can see that:\n - *DAYS_INSTALMENT* and *DAYS_ENTRY_PAYMENT* seems duplicated.\n - *AMT_INSTALMENT* and *AMT_PAYMENT* are highly correlated.\n - Other features have a low correlation with each other."},{"metadata":{"scrolled":false,"trusted":false,"collapsed":true,"_uuid":"09af768e98a781454a66511e99ad88a0cbc53b9e"},"cell_type":"code","source":"for feature in numerical_features_lst:\n    fig, ax = plt.subplots(1, 1, sharex = False, sharey = False, figsize = (20, 7))\n    \n    # Plot feature distribution\n    sns.distplot(installments_payments_data_df[feature].dropna(), kde = False, bins = 100, ax = ax)\n    ax.set_title(\"Histogram of the feature: \" + feature)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"079de75eaee125ebbf542d2e55ad5dcb4e25fced"},"cell_type":"markdown","source":"Here, we can find a lot of outliers, like in the previous datasets. The data is also highly skewed."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"4b49e531da05534299d61fae2432ae48b08a38e9"},"cell_type":"code","source":"missing_values_sr = installments_payments_data_df.isnull().sum()\nmissing_values_df = missing_values_sr.loc[missing_values_sr > 0].sort_values(ascending = False).reset_index()\nmissing_values_df.columns = [\"Feature\", \"Number of missing values\"]\nmissing_values_df[\"Percentage of missing values\"] = (missing_values_df[\"Number of missing values\"] / installments_payments_data_df.shape[0]) * 100\n\nsns.barplot(x = missing_values_df[\"Feature\"], y = missing_values_df[\"Percentage of missing values\"])\nplt.xticks(rotation = 90)\nplt.title(\"Percentage of missing values in the installments payments data\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d136f68226de76ac36c4708e81d8053383b038ab"},"cell_type":"markdown","source":"Here, only two features have a missing values. The amount of missing values is very small (0.02%) and identical for both features.\n\n### 3.7. Looking at POS_cash_balance.csv\n\nThis dataset contains data about monthly balance snapshots of previous POS (point of sales) and cash loans that the applicant had with Home Credit."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"017b2a55684576852d7c8f77b9d9060ff86b2b6a"},"cell_type":"code","source":"categorical_features_lst = pos_cash_balance_data_df.select_dtypes([\"object\"]).columns.tolist()\n\nfor feature in categorical_features_lst:\n    fig, ax = plt.subplots(1, 1, sharex = False, sharey = False, figsize = (20, 10))\n    # Plot levels distribution\n    if pos_cash_balance_data_df[feature].nunique() < 10:\n        sns.countplot(x = pos_cash_balance_data_df[feature], ax = ax, order = pos_cash_balance_data_df[feature].value_counts().index.tolist())\n    else:\n        sns.countplot(y = pos_cash_balance_data_df[feature], ax = ax, order = pos_cash_balance_data_df[feature].value_counts().index.tolist())\n    ax.set_title(\"Count plot of each level of the feature: \" + feature)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f395ff9a248112a192c130dd3008901b88d9e758"},"cell_type":"markdown","source":"This feature seems similar to the one with the same name in credit_card_balance.csv dataset. Maybe there is a connection between them.\n\nNow, let's look at numerical features."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"3d88e6b6688349df60e5044d0a731670c9a55b3c"},"cell_type":"code","source":"numerical_features_lst = list(set(pos_cash_balance_data_df.columns.tolist()) - set(categorical_features_lst))\n\n# generate the linkage matrix\nnumerical_features_df = pos_cash_balance_data_df[numerical_features_lst]\nnumerical_features_df.fillna(-1, inplace = True) # We need to impute missing values before creating the dendrogram\nnumerical_features_df = numerical_features_df.transpose()\nZ = linkage(numerical_features_df, \"ward\")\nplt.figure(figsize = (20, 15))\nplt.title(\"Hierarchical Clustering Dendrogram\")\nplt.xlabel(\"feature\")\nplt.ylabel(\"distance\")\ndend = dendrogram(\n    Z,\n    leaf_rotation = 90.,  # rotates the x axis labels\n    leaf_font_size = 8.,  # font size for the x axis labels\n    labels = numerical_features_df.index.tolist()\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1c78f46c18998ba5fd7977a8815f28d88b4160f"},"cell_type":"markdown","source":"Here, we can see that is we exclude database keys, all features are highly similar."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"c2a0330fcba66246b6d50355b014cb2a239ad42b"},"cell_type":"code","source":"plt.figure(figsize = (15, 15))\nsns.heatmap(pos_cash_balance_data_df[dend[\"ivl\"]].corr(), annot = True, square = True)\nplt.title(\"Correlation plot between numerical features\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b53254619fb6ad780c23d238f96162d50b97da35"},"cell_type":"markdown","source":"Here, we can see that *CNT_INSTALMENT* and *CNT_INTSALMENT_FUTURE* are highly correlated. "},{"metadata":{"scrolled":false,"trusted":false,"collapsed":true,"_uuid":"f7118c9562b9aa95e185fa842e5e62ee188690ed"},"cell_type":"code","source":"for feature in numerical_features_lst:\n    fig, ax = plt.subplots(1, 1, sharex = False, sharey = False, figsize = (20, 7))\n    \n    # Plot feature distribution\n    sns.distplot(pos_cash_balance_data_df[feature].dropna(), kde = False, bins = 100, ax = ax)\n    ax.set_title(\"Histogram of the feature: \" + feature)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b0457d9ee380ff19a5d8a29b450635585532325"},"cell_type":"markdown","source":"Here we can see lots of outliers in the features and high skewness. There are also missing bins in *MONTHS_BALANCE*. It will be interesting to see if there is a connection between all features named *MONTHS_BALANCE*.\n\nNow, let's look at missing values."},{"metadata":{"scrolled":false,"trusted":false,"collapsed":true,"_uuid":"c257d824c8e2f08f949685fb52fbe0ad89847981"},"cell_type":"code","source":"missing_values_sr = pos_cash_balance_data_df.isnull().sum()\nmissing_values_df = missing_values_sr.loc[missing_values_sr > 0].sort_values(ascending = False).reset_index()\nmissing_values_df.columns = [\"Feature\", \"Number of missing values\"]\nmissing_values_df[\"Percentage of missing values\"] = (missing_values_df[\"Number of missing values\"] / pos_cash_balance_data_df.shape[0]) * 100\n\nsns.barplot(x = missing_values_df[\"Feature\"], y = missing_values_df[\"Percentage of missing values\"])\nplt.xticks(rotation = 90)\nplt.title(\"Percentage of missing values in the pos cash balance data\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a897869b0f944f83f9e90a17d424a5780119ae3d"},"cell_type":"markdown","source":"Here, only two features have a missing values. The amount of missing values is very small (0.25%) and identical for both features.\n\n### 3.8. Looking at previous_application.csv\n\nThis dataset contains data about all previous applications for Home Credit loans of clients who have loans in our sample."},{"metadata":{"scrolled":false,"trusted":false,"collapsed":true,"_uuid":"c4325b6154a634ec4fdbe64dd9c558099dd543a4"},"cell_type":"code","source":"categorical_features_lst = previous_application_data_df.select_dtypes([\"object\"]).columns.tolist()\n\nfor feature in categorical_features_lst:\n    fig, ax = plt.subplots(1, 1, sharex = False, sharey = False, figsize = (20, 10))\n    # Plot levels distribution\n    if previous_application_data_df[feature].nunique() < 10:\n        sns.countplot(x = previous_application_data_df[feature], ax = ax, order = previous_application_data_df[feature].value_counts().index.tolist())\n    else:\n        sns.countplot(y = previous_application_data_df[feature], ax = ax, order = previous_application_data_df[feature].value_counts().index.tolist())\n    ax.set_title(\"Count plot of each level of the feature: \" + feature)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ddd381736d3a2495216388e6fdc6bc7277d86163"},"cell_type":"markdown","source":"We can get useful insights from the plots above:\n - Most of the previous loans were cash loans or consumer loans.\n - For *NAME_CASH_LOAN_PURPOSE*, the two highest common levels are not documented in the data description. We'll need to figure out what \"XAP\" and \"XNA\" means by ourselves.\n - We can see that if we remove \"XNA\" / \"XAP\" levels from the features, goods that clients buy are mostly electronic devices like computers or smartphones. Then comes furniture and building materials.\n\nNow, let's look at numerical features."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"76e20509ae0374643d32d078e02a9e1ab50a37e6"},"cell_type":"code","source":"numerical_features_lst = list(set(previous_application_data_df.columns.tolist()) - set(categorical_features_lst))\n\n# generate the linkage matrix\nnumerical_features_df = previous_application_data_df[numerical_features_lst]\nnumerical_features_df.fillna(-1, inplace = True) # We need to impute missing values before creating the dendrogram\nnumerical_features_df = numerical_features_df.transpose()\nZ = linkage(numerical_features_df, \"ward\")\nplt.figure(figsize = (20, 15))\nplt.title(\"Hierarchical Clustering Dendrogram\")\nplt.xlabel(\"feature\")\nplt.ylabel(\"distance\")\ndend = dendrogram(\n    Z,\n    leaf_rotation = 90.,  # rotates the x axis labels\n    leaf_font_size = 8.,  # font size for the x axis labels\n    labels = numerical_features_df.index.tolist()\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa12e6a5f12225525dc2909add2b28730e456240"},"cell_type":"markdown","source":"Here, we can see that is we exclude database keys, we can see several features clusters."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f571efc18711678cdbbdc30b583b9ae7de34463a"},"cell_type":"code","source":"plt.figure(figsize = (15, 15))\nsns.heatmap(previous_application_data_df[dend[\"ivl\"]].corr(), annot = True, square = True)\nplt.title(\"Correlation plot between numerical features\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bed25731ee4916b49770f67254379af3f9b02098"},"cell_type":"markdown","source":"Here, we can see several interesting things:\n - Some features are duplicated: *AMT_GOODS_PRICE* and *AMT_APPLICATION*. Those two features are highly correlated with *AMT_CREDIT*.\n - We can see two white rectangles. We'll need to dig into them later to figure out what they mean.\n - Some features are highly correlated, either positively or negatively."},{"metadata":{"scrolled":false,"trusted":false,"collapsed":true,"_uuid":"c6b8ee62cd2b90fb707efcde4dfc4373c07e642e"},"cell_type":"code","source":"for feature in numerical_features_lst:\n    fig, ax = plt.subplots(1, 1, sharex = False, sharey = False, figsize = (20, 7))\n    \n    # Plot feature distribution\n    sns.distplot(previous_application_data_df[feature].dropna(), kde = False, bins = 100, ax = ax)\n    ax.set_title(\"Histogram of the feature: \" + feature)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"051b6fdbf6d7cea5723faaafa3432ebc4c05c45d"},"cell_type":"markdown","source":"Here we can see lots of outliers in the features and high skewness. There is something strange in the data for the following features: *DAYS_TERMINATION*, *DAYS_FIRST_DRAWING*, *DAYS_FIRST_DUE*, *DAYS_LAST_DUE_1ST_VERSION* and *DAYS_LAST_DUE*: all those features have an important amount of values greater than 350000 days. This is roughly equal to 1000 years. How can this be possible? Are those values a placeholder/default value?\n\nNow, let's look at missing values."},{"metadata":{"scrolled":false,"trusted":false,"collapsed":true,"_uuid":"6f6180f6d8f11714364dfed2a5c69c358da8a541"},"cell_type":"code","source":"missing_values_sr = previous_application_data_df.isnull().sum()\nmissing_values_df = missing_values_sr.loc[missing_values_sr > 0].sort_values(ascending = False).reset_index()\nmissing_values_df.columns = [\"Feature\", \"Number of missing values\"]\nmissing_values_df[\"Percentage of missing values\"] = (missing_values_df[\"Number of missing values\"] / previous_application_data_df.shape[0]) * 100\n\nsns.barplot(x = missing_values_df[\"Feature\"], y = missing_values_df[\"Percentage of missing values\"])\nplt.xticks(rotation = 90)\nplt.title(\"Percentage of missing values in the previous applications data\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea52f9d821a9adc00924cb6ce664e6d5d86467eb"},"cell_type":"markdown","source":"Here we can see that two features have nearly 100% of missing values. For other features that have missing values, we can see that some features have the same number of missing values. It's possible that there is correlation between missing values for them."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ed11e7db30bc0747f4cf652a4382d37558a0c2e0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"nbformat":4,"nbformat_minor":1}