{"cells":[{"metadata":{"_cell_guid":"e84522e5-bafd-45e6-ad22-f5de84128e98","_uuid":"3ca061cd70cc6145bba5a703e70b718f6d3cdc76"},"cell_type":"markdown","source":"# This notebook is a duplicate of Kjetil Åmdal-Sævik's \"Keras U-Net starter - LB 0.277\" to which I added Data Augmentation using keras ImageDataGenerator.\n"},{"metadata":{"_cell_guid":"88c8f888-4eb5-438e-8428-0d6f9280aa70","_uuid":"3cf23599bb2587214d3f8b50d3b512bb025159f1"},"cell_type":"markdown","source":"### Importing the needed libraries"},{"metadata":{"_cell_guid":"6b324c96-b92c-4c71-835a-cc6adb1c7a0c","_uuid":"9d65868c23446ed123810c4187c0e598ce01c652","collapsed":true,"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport random\nimport warnings\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom itertools import chain\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\n\nimport tensorflow as tf\n\n# Set some parameters\nBATCH_SIZE = 10 # the higher the better\nIMG_WIDTH = 128 # for faster computing on kaggle\nIMG_HEIGHT = 128 # for faster computing on kaggle\nIMG_CHANNELS = 3\nTRAIN_PATH = '../input/stage1_train/'\nTEST_PATH = '../input/stage1_test/'\n\nwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')\nseed = 42","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b2464b8e-77ba-44b1-8c78-06b1e690910d","_uuid":"a3c37b92fa214f1be75ac3630927555ff40674b2"},"cell_type":"markdown","source":"###  1. Preparing the data"},{"metadata":{"_cell_guid":"bb7da2b8-5921-4769-9bee-afab2135472d","_uuid":"2ff390c2a99e276c65e34d9ed61208347cacafe2","collapsed":true,"trusted":true},"cell_type":"code","source":"# Get train and test IDs\ntrain_ids = next(os.walk(TRAIN_PATH))[1]\ntest_ids = next(os.walk(TEST_PATH))[1]\nnp.random.seed(10)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c6db52ac-98df-4e0f-bab2-b83565c0fde2","_uuid":"ef50f72d80920e9b53c73919994199c0c9a8c955","collapsed":true,"trusted":true},"cell_type":"code","source":"# Get and resize train images and masks\nX_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    path = TRAIN_PATH + id_\n    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_train[n] = img\n    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n    for mask_file in next(os.walk(path + '/masks/'))[2]:\n        mask_ = imread(path + '/masks/' + mask_file)\n        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n                                      preserve_range=True), axis=-1)\n        mask = np.maximum(mask, mask_)\n    Y_train[n] = mask\n\n# Get and resize test images\nX_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    path = TEST_PATH + id_\n    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    sizes_test.append([img.shape[0], img.shape[1]])\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_test[n] = img\n\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5f70481c-7b7b-4f60-8d11-e0e36030697c","_uuid":"1593b0eb0503758424ce1ec5ded8d59557d4d1df"},"cell_type":"markdown","source":"###  2. Data Augmentation"},{"metadata":{"_cell_guid":"0e78cfea-5120-4c18-80a0-fd09964e024d","_uuid":"7448169cf1949461f30735a89f96b4c4003dccea","collapsed":true,"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\n\n# Creating the training Image and Mask generator\nimage_datagen = image.ImageDataGenerator(shear_range=0.5, rotation_range=50, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, fill_mode='reflect')\nmask_datagen = image.ImageDataGenerator(shear_range=0.5, rotation_range=50, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, fill_mode='reflect')\n\n# Keep the same seed for image and mask generators so they fit together\n\nimage_datagen.fit(X_train[:int(X_train.shape[0]*0.9)], augment=True, seed=seed)\nmask_datagen.fit(Y_train[:int(Y_train.shape[0]*0.9)], augment=True, seed=seed)\n\nx=image_datagen.flow(X_train[:int(X_train.shape[0]*0.9)],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\ny=mask_datagen.flow(Y_train[:int(Y_train.shape[0]*0.9)],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n\n\n\n# Creating the validation Image and Mask generator\nimage_datagen_val = image.ImageDataGenerator()\nmask_datagen_val = image.ImageDataGenerator()\n\nimage_datagen_val.fit(X_train[int(X_train.shape[0]*0.9):], augment=True, seed=seed)\nmask_datagen_val.fit(Y_train[int(Y_train.shape[0]*0.9):], augment=True, seed=seed)\n\nx_val=image_datagen_val.flow(X_train[int(X_train.shape[0]*0.9):],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\ny_val=mask_datagen_val.flow(Y_train[int(Y_train.shape[0]*0.9):],batch_size=BATCH_SIZE,shuffle=True, seed=seed)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a6a85b26-695e-4975-b22f-80a79209c370","_uuid":"22785cbdcdf3e7712ba2423a90869e44bd74e28c","collapsed":true,"trusted":true},"cell_type":"code","source":"# Checking if the images fit\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nimshow(x.next()[0].astype(np.uint8))\nplt.show()\nimshow(np.squeeze(y.next()[0].astype(np.uint8)))\nplt.show()\nimshow(x_val.next()[0].astype(np.uint8))\nplt.show()\nimshow(np.squeeze(y_val.next()[0].astype(np.uint8)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"54ec711a-1380-426f-8223-b03a62c659a2","_uuid":"a23269d50bba3f2521202ff835fd5a4d34c785e9","collapsed":true,"trusted":true},"cell_type":"code","source":"#creating a training and validation generator that generate masks and images\ntrain_generator = zip(x, y)\nval_generator = zip(x_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ae011253-08b8-44db-8be9-c1092e171553","_uuid":"17f9af12f2fc93a2e57c3cfdc3c122f97f1fa7e4"},"cell_type":"markdown","source":"###  3. Creating the U-net model"},{"metadata":{"_cell_guid":"1b9b4831-27b2-4a9d-a371-b31ef3a423e1","_uuid":"1f14f1661097ea33049514f442492e0d4d44480c","collapsed":true,"trusted":true},"cell_type":"code","source":"# Define IoU metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0f97a2d9-a9a0-4399-bbca-198cdda087b6","_uuid":"ab499cefbbe8dc514c6347fe203d87eb7974adf0","collapsed":true,"trusted":true},"cell_type":"code","source":"# Build U-Net model\ninputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\ns = Lambda(lambda x: x / 255) (inputs)\n\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\nc1 = Dropout(0.1) (c1)\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\nc2 = Dropout(0.1) (c2)\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\nc3 = Dropout(0.2) (c3)\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\nc5 = Dropout(0.3) (c5)\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(0.2) (c7)\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(0.1) (c8)\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(0.1) (c9)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5d17d35a-753d-47c5-b1d7-7effa1af04a7","_uuid":"a9378262b0194c0aa54df3e2ea5696b447f8ef83"},"cell_type":"markdown","source":"###  4. Training"},{"metadata":{"_cell_guid":"2cc45263-7607-4d9d-b0e0-88b3135ba60b","_uuid":"440055f1d1feb25fe08f942d15257e2454d2022b","collapsed":true,"trusted":true},"cell_type":"code","source":"# Fit model\nearlystopper = EarlyStopping(patience=3, verbose=1)\ncheckpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\nresults = model.fit_generator(train_generator, validation_data=val_generator, validation_steps=10, steps_per_epoch=250,\n                              epochs=3, callbacks=[earlystopper, checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6e12a9f1-279f-4031-b8c5-4f825f84cc13","_uuid":"168a4d55c79c92cd17a398cff13876fb0b32cdbf"},"cell_type":"markdown","source":"###  5. Prediction"},{"metadata":{"_cell_guid":"ef72a295-7187-41d6-9ecf-c5ee201f000d","_uuid":"f9b92b3ce2079288fe8a2ed75f3c8679ee93113f","collapsed":true,"trusted":true},"cell_type":"code","source":"# Predict on train, val and test\nmodel = load_model('model-dsbowl2018-1.h5', custom_objects={'mean_iou': mean_iou})\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\npreds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\npreds_test = model.predict(X_test, verbose=1)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)\n\n# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in range(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fbad21c9-d1ef-4aee-9e16-8b340e38cd69","_uuid":"b050929802713d41a75fc97a960ac6534e5cbde1","collapsed":true,"trusted":true},"cell_type":"code","source":"# Perform a sanity check on some random training samples\nix = random.randint(0, len(preds_train_t))\nimshow(X_train[ix])\nplt.show()\nimshow(np.squeeze(Y_train[ix]))\nplt.show()\nimshow(np.squeeze(preds_train_t[ix]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0c9fed3a-fa91-4957-833f-c2b8adf64743","_uuid":"bf24083f20c4e618eeee2933dc1fd1a36413f8b7","collapsed":true,"trusted":true},"cell_type":"code","source":"# Perform a sanity check on some random validation samples\nix = random.randint(0, len(preds_val_t))\nimshow(X_train[int(X_train.shape[0]*0.9):][ix])\nplt.show()\nimshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\nplt.show()\nimshow(np.squeeze(preds_val_t[ix]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e2e17c4a-e84e-4552-950d-a49e95393ed9","_uuid":"b66a4b8ebd2a804d8d102436b0953183bdb4f30b","collapsed":true,"trusted":true},"cell_type":"code","source":"# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\ndef rle_encoding(x):\n    dots = np.where(x.T.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef prob_to_rles(x, cutoff=0.5):\n    lab_img = label(x > cutoff)\n    for i in range(1, lab_img.max() + 1):\n        yield rle_encoding(lab_img == i)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"46ff9859-1d81-4a7b-be2a-f0421a67ad79","_uuid":"b27241fd5a881fa0b17711ed71b7a99b7a9b4859","collapsed":true,"trusted":true},"cell_type":"code","source":"new_test_ids = []\nrles = []\nfor n, id_ in enumerate(test_ids):\n    rle = list(prob_to_rles(preds_test_upsampled[n]))\n    rles.extend(rle)\n    new_test_ids.extend([id_] * len(rle))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f3d93130-6408-49c1-acf5-ebfdd9eb6130","_uuid":"3b70ba9c8bc6aca2670e95218f28bf04d2f2d521","collapsed":true,"trusted":true},"cell_type":"code","source":"# Create submission DataFrame\nsub = pd.DataFrame()\nsub['ImageId'] = new_test_ids\nsub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\nsub.to_csv('sub-dsbowl2018-1-DA2-batch10.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}