{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"# *******************************************************************************************\n# ************** IMPORT VARIOUS PACKAGES USED IN THIS NOTEBOOK  *****************************\n# *******************************************************************************************\n\nimport pandas as pd\nfrom pandas import DataFrame\nimport csv as csv\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3fe171ea7465b3f834e70a76ab52db144fad163","collapsed":true},"cell_type":"code","source":"# *******************************************************************************************\n# ************** READ IN DATA AND CONDUCT EXPLORATORY DATA ANALYSIS *************************\n# *******************************************************************************************","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07d2a109d12f423c4c5f7fbf8bcc935f8e24bfaf","collapsed":true},"cell_type":"code","source":"# read in training data \ntrain = pd.read_csv(\"../input/train.tsv\",sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2249897634fccc1dd86e226803af111ffb41c4c"},"cell_type":"code","source":"train.shape\n\n# There are 156,060 rows and 4 columns in the training data set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb95de8f64798141d926874570b2ddb54df27a50","scrolled":true},"cell_type":"code","source":"# Look at first 5 rows\n\ntrain.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7348efcb85634f9a5c08ddcc7e70e9784388ca22","collapsed":true},"cell_type":"code","source":"# read in test data file\n\ntest = pd.read_csv(\"../input/test.tsv\",sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"962cf02f24cfdae82f5c52acac3d2837396d4faa"},"cell_type":"code","source":"test.shape\n\n# There are 66,292 rows and 3 columns in the testing data set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bff53a627404fbc5577388288d11d1068803721"},"cell_type":"code","source":"# Look at first 5 rows.  This is easier to view in the tsv file directly since the volume of data is very small.\n\ntest.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d61d72b55751a55919e5f1f67402b2def5d96554","collapsed":true},"cell_type":"code","source":"# read in submission data file.  This is the file I will overwrite when I submit results\n\nsubmission = pd.read_csv(\"../input/sampleSubmission.csv\",sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f51878eea23c2d1869d3bd91af150fd8534c05e7"},"cell_type":"code","source":"# Look at the first 5 rows.  Note that they are all initially populated with scores of '2' for sentiment\n\nsubmission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"853f903f1562a22930ac1ec11b4bd0f388e83fbb"},"cell_type":"code","source":"# What's the distribution of the sentiment scores in the training data?\n\ntrain['Sentiment'].value_counts()\n\n# Not surprising. Only 7,072 are negative(0) and 9,206 are positive(4). Most fall in between. 2 (neutral) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a0bb17b49de3e25936091889a3beb3b97a41107"},"cell_type":"code","source":"# Let's plot that in a histogram to make it easier to view\n\nplt.hist(train['Sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2963ce2a63d115db2132921f9f8ab466e47b91e1","collapsed":true},"cell_type":"code","source":"# *******************************************************************************************\n# ************************** DATA PREPARATION FOR MODELING **********************************\n# *******************************************************************************************","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b8ce35cfe64a1202fc567c835e1957c153c73c1","collapsed":true},"cell_type":"code","source":"# tifidf is used to determine how important a word is in the document\n# Based on two factors.  How common it is (term frequency) and how rare it is - rarer is better (inverse document \n# frequency, which penalizes common words like 'the' and highly weighs less common words) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ada35cc2e1acdddaeffb4e69ae56212fa55e2b41","collapsed":true},"cell_type":"code","source":"# tfidf vectorizer converts words into a matrix of TF-IDF features.  It removes common words like 'a', and 'the'.\n\ntfidf = TfidfVectorizer(stop_words='english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"865591d8f8b64949d03dc9dab15e43743ce0b7f6","collapsed":true},"cell_type":"code","source":"# Let's run it on the phrases column of the training data.\n\nX_train = tfidf.fit_transform(train.Phrase)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f3ea64586f2f786b93f7a1b0fa357a03238e3ef"},"cell_type":"code","source":"# We now have a matrix of 0's and 1's.  For each of the 156,060 rows, we now have 14,955 columns.  \nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a32764f74e6428867bc4635460d924df6e46eccb"},"cell_type":"code","source":"print(X_train)\n\n# Note that the first phrase (represented as row 0 below) has 11 core words.  \n\n# \"A series of escapades demonstrating the adage that what is good for the goose is also\n# good for the gander , some of which occasionally amuses but none of which amounts to much of a story.\" -->\n\n# Possibly the 11 core words are these (note that filler words are stripped out)\n# series, escapades, demonstrating, adage, good, goose, gander, occassionally, amuses, amounts, story\n\n# .228 is the tfidf score for the relative importance of this set of words in the training set.  \n\n# Note that the next phrase (represented as row 1 below) is exactly the same other than it only has 6 of the core words.  \n\n# 'A series of escapades demonstrating the adage that what is good for the goose'\n\n# Possibly it's these...\n# series, escapades, demonstrating, adage, good, goose\n\n# Note that each of these words in the matrix (indicated by the second number) consists of the same list as above (11645, 4504, etc.).\n# tfidf score is .360, so this is considered more important than the first sentence.\n\n# The next phrase (represented as row 2 below) is 'A series'.  And so on...","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69fba5042a40a10503d8361add5bb9b9a5ba085b","collapsed":true},"cell_type":"code","source":"# Run the same vectorizer on the test data\n\nX_test = tfidf.transform(test.Phrase)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15d9d6b610dde5083ae6753d60ef8b71c22980d8"},"cell_type":"code","source":"X_test\n\n# For each of the 66,292 rows, we have 14,955 columns.  I believe the reason we're coming up with the same number\n# of columns we had in the training data is that we're using transform, and not fit_transform.  Fit_transform\n# creates the original matrix based on training data. Transform then takes the test data and fits it to that.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"690c36f3a17d66c6b3433024d4fd3700070d1fdf","collapsed":true},"cell_type":"code","source":"# Represent the sentiment scores in each row of the training data as 'y' \ny = train.Sentiment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c141354d5efc43dc4798456e5e3c9199ce693584","collapsed":true},"cell_type":"code","source":"# Split the training data into a train/validation set to iteratively improve the performance of the model.  Will do a 70/30 split\n\nxtrain, xvalid, ytrain, yvalid = train_test_split(X_train, y, \n                                                  stratify=y, \n                                                  random_state=1, \n                                                  test_size=0.3, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"91cae4a309a479e63ce8d88d6137a66cb65524b6"},"cell_type":"code","source":"# *******************************************************************************************\n# ********************************* DATA MODELING -Linear  SVC ******************************\n# *******************************************************************************************","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"15168edfc5eda303e50eb95e98ffb55ed99909f9"},"cell_type":"code","source":"# Train model on full training data, predict test values based on this model\nsvc = LinearSVC(dual=False).fit(X_train,y).predict(X_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"152848b2ca5dab95cb8e8412120c76bc4200bf23"},"cell_type":"code","source":"# Add predictions from linear SVC model to a new data frame (df) in a column named 'svc'\ndf = pd.DataFrame(svc,columns=['svc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c2f05192e32dabf991a20fbb2eaeb04a0e4ae949"},"cell_type":"code","source":"# Submit predictions from linear SVC\n\nsubmission['Sentiment'] = df['svc']\nsubmission.to_csv(\"svc.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c69a2a0e5376aaa13c6f3040b8ac10725bedeef4"},"cell_type":"code","source":"plt.hist(df['svc'])\n# Seems to be close to the training set distribution - neutral slightly overstated  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7b3c024a1b28e59512d68c5cf0a1e3af725853ea"},"cell_type":"code","source":"# *******************************************************************************************\n# ********************************* DATA MODELING -Logistic Regression **********************\n# *******************************************************************************************","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59603f4a59682031e6611ace92c65298746bfd81"},"cell_type":"code","source":"# Train model on full training data, predict test values based on this model\nlr=LogisticRegression()\nlr.fit(X_train,y)\ny_pred_lr = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d82f40eff76ab4fd8f6df51eca06e58134c8aeec"},"cell_type":"code","source":"# Add predictions from logistic regression model to data frame in a column named 'lr'\ndf['lr'] = y_pred_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61c1c9821d9bb4b8803776cc5aad1a65b474e7f7"},"cell_type":"code","source":"plt.hist(df['lr'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e4875b0ffd5630d6bf59439d7e04641b00bfe81d"},"cell_type":"code","source":"# Submit predictions from logistic regression\n\nsubmission['Sentiment'] = df['lr']\nsubmission.to_csv(\"lr.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0df429ccdd3042f22ff6ee385dbf401218014448","collapsed":true},"cell_type":"code","source":"# *******************************************************************************************\n# ********************************* DATA MODELING - XG Boost ********************************\n# *******************************************************************************************","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18f37a30aac5e5342e1ed9a653642b47dab2188e","collapsed":true},"cell_type":"code","source":"# Runs a XG Boost model using the training matrix and corresponding sentiments to predict the values of the testing data\n\nxgb = xgb.XGBClassifier(max_depth=14, n_estimators=500, colsample_bytree=0.8, \n                        subsample=0.8, nthread=10, learning_rate=0.1)\nxgb.fit(xtrain, ytrain)\npredictions = xgb.predict(xvalid)\n\nprint(\"accuracy_score\",accuracy_score(yvalid, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e08da810ca7855e2627f87a50763cb88bf9b8e48","collapsed":true},"cell_type":"code","source":"# Run the best model we can define above on the full test set to predict the sentiment.  \n\nxgb = xgb.predict(X_test)\ndf = pd.DataFrame(xgb,columns=['xgb'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"70bd3063f907c368d3e07cd7dba46a5375b69f5c"},"cell_type":"code","source":"submission['Sentiment'] = df['xgb']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e45bb3437b4843dca118e343a1ebd9b1de515d4f"},"cell_type":"code","source":"submission.to_csv(\"xgb.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"064a54836f528c272157bd4233735ffcb50fd8ec","collapsed":true},"cell_type":"code","source":"plt.hist(df['xgb'])\n\n# Not great... massively overestimates neutral sentiment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dff3f86741955271502a31eaeed798d0728afa93"},"cell_type":"code","source":"# *******************************************************************************************\n# ******************************* DATA MODELING - LIGHT GBM *********************************\n# *******************************************************************************************","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"66873c85fd7381d063fd958f47ae882decec28e2"},"cell_type":"code","source":"lgb = lgb.LGBMClassifier(boosting_type='dart',\n                         num_leaves=800,\n                        learning_rate=0.05,\n                        n_estimators=800,\n                        colsample_bytree=.8,\n                        num_boost_rounds=800)\n\n# Parameters need to be tuned... this is likely to be significantly overfitting, but scored reasonably well.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d9fc80becee48a1b369f0baf6b2b590358f6f0f","collapsed":true},"cell_type":"code","source":"lgb.fit(xtrain, ytrain,\n        eval_set=[(xvalid, yvalid)],\n        eval_metric='multi_logloss',\n        early_stopping_rounds=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95c4646848192f1a2c54f7a38d2cd1e72e7fc44b","collapsed":true},"cell_type":"code","source":"# Predict the values of the valdation set to understand how accurate the model is.\n\npredictions = lgb.predict(xvalid, num_iteration = lgb.best_iteration_)\nprint(\"accuracy_score\",accuracy_score(yvalid, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51cbb1f8fd3a9547afea650909863c9a66f2e2fd","collapsed":true},"cell_type":"code","source":"# Predict test values based on the best iteration from above \ndf['lgbm'] = lgb.predict(X_test, num_iteration=lgb.best_iteration_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"602dcc5c7d6a855c72958816728804f3c9c0cd09"},"cell_type":"code","source":"# Submit predictions from light gradient boosting model\n\nsubmission['Sentiment'] = df['lgbm']\nsubmission.to_csv(\"lgbm.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e0384246b78438889bbade6eb8538c64e6833a5","collapsed":true},"cell_type":"code","source":"plt.hist(df['lgbm'])\n\n# Eyeball- seems to overestimate neutral sentiment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d3375e989a409c4e30e823de50b04a228e80f5f","collapsed":true},"cell_type":"code","source":"# *******************************************************************************************\n# ********************************* BLEND THE MODELS ****************************************\n# *******************************************************************************************","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"636c930ee69ba7ce204a7fbe702793e82b12a601","collapsed":true},"cell_type":"code","source":"# Check that predictions have already been added to a data frame\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d4a3f704d1833b4c31f039d018c1751fea642834"},"cell_type":"code","source":"# Let's take a majority vote.  Take the most commonly occuring sentiment per row (mode).  \n# Ensure that values are integers, not floats\n\nsubmission['Sentiment'] = df.mode(axis=1)\nsubmission['Sentiment'] = submission.Sentiment.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63bf096a253bb24e46df41dd08b407804fe28766","collapsed":true},"cell_type":"code","source":"plt.hist(submission['Sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a2fae9637d12b39b1a5687fbc14042fd40bbb1a","collapsed":true},"cell_type":"code","source":"# *******************************************************************************************\n# ********************************* SUBMIT FILE *********************************************\n# *******************************************************************************************","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04fa370483c80aa4146f544ce2366b64b6002d07","collapsed":true},"cell_type":"code","source":"submission.to_csv(\"blended.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}