{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3d2c9c26-a887-c34f-9573-ef6fe058cd12"
      },
      "source": [
        "**Exploration Topics: ID - 10 of train**\n",
        "\n",
        " - correlations of y and features\n",
        " - feature dynamics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6371083d-5cdd-dfe3-eac0-76479f61afae"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import kagglegym\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9c01ede6-8541-9449-f154-bc68b8e2ebf3"
      },
      "outputs": [],
      "source": [
        "# Create environment\n",
        "env = kagglegym.make()\n",
        "\n",
        "# Get first observation\n",
        "observation = env.reset()\n",
        "\n",
        "# Get the train dataframe\n",
        "train = observation.train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b45b1b29-7a26-ef8d-4aab-68ae7b1ad6b8"
      },
      "outputs": [],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "24554ed5-1496-d3da-1309-f3b09f5d6c3c"
      },
      "outputs": [],
      "source": [
        "len(train.id.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "36787543-a5b7-b7ac-9edb-78fd25536684"
      },
      "outputs": [],
      "source": [
        "len(train.timestamp.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a41979bf-70b1-ca22-51c2-f8b10a70fc59"
      },
      "outputs": [],
      "source": [
        "def getidtraindata(instrument):\n",
        "    return train.loc[train.id==instrument,:]\n",
        "\n",
        "train10 = getidtraindata(10)\n",
        "train10.head()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5c8d8f6f-068b-880a-3e9b-99173ab7c077"
      },
      "outputs": [],
      "source": [
        "train10.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "41f59670-a8a6-2470-f797-c13d8b07c28a"
      },
      "source": [
        "Let's have a look at the features that are mostly correlated with the y-values of id 10:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e6a57570-a295-6aa1-fef6-262d2eef54ab"
      },
      "outputs": [],
      "source": [
        "x_cols = [col for col in train.columns if col not in ['id','timestamp','y']]\n",
        "labels = []\n",
        "values = []\n",
        "nan_counts = []\n",
        "for col in x_cols:\n",
        "    labels.append(col)\n",
        "    values.append(np.corrcoef(train10[col].values, train10.y.values)[0,1])\n",
        "    nan_counts.append(train10[col].isnull().sum())\n",
        "\n",
        "ind = np.arange(len(labels))\n",
        "width = 0.9\n",
        "fig, ax = plt.subplots(figsize=(6,40))\n",
        "rects = ax.barh(ind, np.array(values), color='y')\n",
        "ax.set_yticks(ind+((width)/2.))\n",
        "ax.set_yticklabels(labels, rotation='horizontal')\n",
        "ax.set_xlabel(\"Correlation coefficient\")\n",
        "ax.set_title(\"Correlation coefficient\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "852b424d-d34e-8cd9-9661-42a751a42bab"
      },
      "outputs": [],
      "source": [
        "print(nan_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bf86eea1-57e3-f01f-0adb-a023ba1fbc8b"
      },
      "source": [
        "To work with the correlation coefficients of y and features, they are stored in a dataframe. Now, let's have a closer look at three features that have coefficients above abs(0.2) and the lowest number of nan values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b079ee7f-d54a-2466-e1f6-b2504adbdb0a"
      },
      "outputs": [],
      "source": [
        "y_feature_correlations = pd.DataFrame(values, index=labels, columns=['coefficient'])\n",
        "y_feature_correlations['Nr of NaN'] = nan_counts\n",
        "y_feature_correlations.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fd52a6fe-3da8-37c2-aa8b-7709305cf239"
      },
      "outputs": [],
      "source": [
        "sorted_y_feature_correlations = y_feature_correlations.sort_values(['coefficient'], ascending=False)\n",
        "sorted_y_feature_correlations.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "698432a9-38fc-209d-1478-812e15759d16"
      },
      "source": [
        "Now, we see that for id 10, fundamental 50, 39 and 46 have zero nan-values and are highest correlated with our y-values. Let's plot the time-evolution of y and these fundamentals:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "929cbb04-1e28-f976-484f-f21f096e0dde"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(train10.timestamp, train10.fundamental_50, '.')\n",
        "plt.xlabel('timestamp')\n",
        "plt.ylabel('fundamental_50')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train10.timestamp, train10.fundamental_39, '.')\n",
        "plt.xlabel('timestamp')\n",
        "plt.ylabel('fundamental_39')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train10.timestamp, train10.fundamental_46, '.')\n",
        "plt.xlabel('timestamp')\n",
        "plt.ylabel('fundamental_39')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train10.timestamp, train10.y, '.-')\n",
        "plt.xlabel('timestamp')\n",
        "plt.ylabel('y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "40bc7999-0d0c-ae84-b63d-fc32610e7328"
      },
      "source": [
        "Uhi, there are crazy jumps at nearly the same time!!! But... in the beginning they do not behave the same way.... In contrast, let's have a look at the time evolution of the anti-correlated features: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e9a460d5-9ee8-99af-aef3-a0b746ad7c64"
      },
      "outputs": [],
      "source": [
        "sorted_y_feature_correlations = y_feature_correlations.sort_values(['coefficient'], ascending=True)\n",
        "sorted_y_feature_correlations.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8bb364ce-8bee-a203-942b-fa1082c690ff"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(train10.timestamp, train10.fundamental_50, '.')\n",
        "plt.xlabel('timestamp')\n",
        "plt.ylabel('fundamental_36')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train10.timestamp, train10.fundamental_39, '.')\n",
        "plt.xlabel('timestamp')\n",
        "plt.ylabel('fundamental_30')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train10.timestamp, train10.fundamental_46, '.')\n",
        "plt.xlabel('timestamp')\n",
        "plt.ylabel('technical_27')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5a61314b-94aa-5891-c662-a4db97b8cee0"
      },
      "source": [
        "For the next analysis part, the feature data is scaled to values between 0 and 1. This way it is much easier to visualize the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "31b3b43d-359b-464e-496f-88f230c55aad"
      },
      "outputs": [],
      "source": [
        "def scale(values):\n",
        "    new_values = []\n",
        "    for value in values:\n",
        "        new_value = (value - values.min())/(values.max()-values.min())\n",
        "        new_values.append(new_value)\n",
        "    return new_values\n",
        "\n",
        "def scale_all_features(data):\n",
        "    scaled_data = pd.DataFrame(data.timestamp)\n",
        "    for col, old_values in data.iteritems():\n",
        "        if col not in ['id','timestamp','y']:\n",
        "            scaled_data[str(col)] = scale(old_values)\n",
        "    return scaled_data\n",
        "\n",
        "scaled_train10 = scale_all_features(train10)\n",
        "scaled_train10.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e955a4b2-54c0-fccb-78f1-4c924dc13709"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "for col, values in scaled_train10.iteritems():\n",
        "    if col not in ['id','timestamp','y']:\n",
        "        plt.plot(scaled_train10.timestamp, values, '.')\n",
        "plt.xlabel('timestamp')\n",
        "plt.ylabel('scaled feature values')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5a79dfdf-45bd-6a77-ee77-49694981415d"
      },
      "source": [
        "This looks funny and and reminds me of bifurcations, feigenbaum constant etc.. I think we have entered the world of nonlinear dynamics and perhaps of chaotic systems. The features are probably highly non-linear correlated and there are some kind of phase-transitions (for example close to 20, 40 and 85 timepoints many features \"jump\"). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ecb97b88-c977-b942-89e4-90ab65fbb150"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}