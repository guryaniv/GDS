{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv1D, Dropout, Flatten\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.utils import shuffle\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport glob\n\n_INPUT_FILE_NAME = \"../input/creditcard.csv\"\n\n\ndef read_and_sanitize_data():\n    data = pd.read_csv(_INPUT_FILE_NAME, sep=',')\n    return data\n\n\ndef model(input_shape):\n    print(input_shape)\n    model = Sequential()\n    model.add(Dense(32, input_shape=input_shape, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n    return model\n\n\n\ninput_data = read_and_sanitize_data()\nprint(input_data.shape)\ntrain_x = input_data.drop(labels='Class', axis=1)\nprint(train_x.shape)\ntrain_y = input_data[['Class']]\nprint(train_y.shape)\ntrain_x.drop(train_x.head(1).index, inplace=True)\ntrain_y.drop(train_y.head(1).index, inplace=True)\nmodel = model(train_x.shape[1:])\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nprint(model.summary())\ntrain_x, train_y = shuffle(train_x, train_y, random_state=2)\nhistory = model.fit(np.asarray(train_x), np.asarray(train_y), epochs=100, batch_size=train_x.shape[0],\n                    class_weight={0: 1, 1: 100})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"58025adbca43d19a9e9985968e2dfff6385b44cc"},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e1f5c75dc6bb8c1198e7295a02f45796583e04f"},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2a58c4d994c9371583421e60598b864a38d0d74e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}