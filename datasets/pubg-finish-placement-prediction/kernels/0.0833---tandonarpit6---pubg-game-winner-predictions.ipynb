{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"Let's use a simple XGBoost model to do the predictions- remove the identifiers in the intial feature set. With the data formatted and in numbers, let's not spend much time in data pre-processing.\n\nThen spend more time in Permutation Importance, partial dependency plot and SHAP analysis to identify the key features and make qualitative sense of what impacts a good game performance in PUBG."},{"metadata":{"_uuid":"1ad256c24372aeea8252489aca4fc7896f8edc8a"},"cell_type":"markdown","source":"Reading the data files."},{"metadata":{"trusted":true,"_uuid":"6dc4b9248e575fb065901afd3cb0b37b597629a7"},"cell_type":"code","source":"train=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')\nsubmission=pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c56180d2dd6993de8aebca1d68b6e56164c34e0a"},"cell_type":"markdown","source":"Making feature and prediction set from training and test data. Have removed only the identifiers for now."},{"metadata":{"trusted":true,"_uuid":"bf0db06b8b4a23d2bc6fec1d44e58524a4873748"},"cell_type":"code","source":"x_train=train.copy()\ny_train=train['winPlacePerc']\nx_train=x_train.drop(columns=['Id','groupId','matchId','numGroups','maxPlace','winPlacePerc','damageDealt','headshotKills','roadKills','vehicleDestroys'])\nx_test=test.copy()\nx_test=x_test.drop(columns=['Id','groupId','matchId','numGroups','maxPlace','damageDealt','headshotKills','roadKills','vehicleDestroys'])\n\nx_train.sort_index(axis=1,inplace=True)\nx_test.sort_index(axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb5678e4982a202f3b189fabde1c3a97518a9d11"},"cell_type":"markdown","source":"Using the simple XGBoost model to make predictions and then will use methods to understand the model and do feature engineering."},{"metadata":{"trusted":true,"_uuid":"a9f64d71806ce1a4a3005b5fd5af7a0f9ac9995a"},"cell_type":"code","source":"import xgboost as xgb\n\nmodel=xgb.XGBRegressor()\nmodel.fit(x_train,y_train)\n\ny_pred=model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7f37021109518ed6c3d985af4d1cb59ef99ebbb"},"cell_type":"markdown","source":"Preparing the submission file."},{"metadata":{"_uuid":"8634d5a8fac79a1d0881c54e29f71b8b1a0ea42a"},"cell_type":"markdown","source":"In the simple XGBoost model, the score comes to around 0.0833. Let's try to understand the features in detail and improve the model."},{"metadata":{"trusted":true,"_uuid":"daaa1a8cb2de2878ea7e1a678c2098ab896c01c7"},"cell_type":"code","source":"from matplotlib import pyplot as plt\nfrom xgboost import plot_importance\n\nplot_importance(model)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15da4a39a6c0cc213196809f39315cbbb1c7b72f"},"cell_type":"markdown","source":"Let's remove the 4 features with 0 feature importance and then see the improvement in accuracy score. Removing the 4 features with 0 importance doesn't alter the predictions at all. However, if I remove any more features with low importance, then the predictions get slightly worse. So keeping all the features with non-zero importance.\nEither we do hyperparameter tuning or better try Deep learning. Dataset with 4.5 million rows is huge, can try with a simple feed forward neural network to compare predictions with XGBoost.\n\nBefore getting into Deep Learning, let's use SHAP values to better understand the dataset in current model."},{"metadata":{"trusted":true,"_uuid":"8da497432bfd56fd0dc049454314e10af5730674"},"cell_type":"code","source":"import shap\n\nexplainer=shap.TreeExplainer(model)\nshap_values=explainer.shap_values(x_test)\n\nshap.summary_plot(shap_values,x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cecf30c79bed3346eb782427fb8ac23dfa27562f"},"cell_type":"code","source":"shap.dependence_plot('walkDistance',shap_values,x_test,interaction_index='killPlace')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d439c5c05dc761eda6b3d4d7d92d3b472ce83388"},"cell_type":"markdown","source":"Let's use Deep Learning model to predict."},{"metadata":{"trusted":true,"_uuid":"5c5f77e12ac723a6d0a2c9c9a87dff79ac06d34f"},"cell_type":"code","source":"from keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.layers import Dropout\n\nmodel1=models.Sequential()\nmodel1.add(layers.Dense(512,activation='relu',input_shape=(x_train.shape[1],)))\nmodel1.add(Dropout(0.2))\nmodel1.add(layers.Dense(512,activation='relu'))\nmodel1.add(Dropout(0.2))\nmodel1.add(layers.Dense(1))\n\nmodel1.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])\n\nmodel1.fit(x_train,y_train,epochs=16,batch_size=512)\n\ny_pred_DL=model1.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5dd2f230152da5de28af4117a5154b94264ef1c"},"cell_type":"code","source":"submission['winPlacePerc']=y_pred_DL\nsubmission.to_csv('sample_submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}