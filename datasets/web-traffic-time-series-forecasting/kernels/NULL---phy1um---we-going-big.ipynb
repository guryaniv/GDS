{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"file_extension": ".py", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3", "nbconvert_exporter": "python"}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"metadata": {"_cell_guid": "45fc169e-afb5-49af-9624-f41c6a460af4", "_uuid": "959fc063d1cc3d0817ef7edec46995eb1a8d926a", "_kg_hide-output": false, "scrolled": true}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "#train = pd.read_csv('../input/train_1.csv').fillna('0')\n", "train = pd.read_csv(\"../input/train_1.csv\")\n", "train.head()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "0a01469d-1439-498d-a6e2-1c432c65e823", "_uuid": "db3331f17199e93decfd1bc85f91a8ccef8b6f7b"}, "source": ["# split away the page data from the time series data\n", "train_pages = pd.DataFrame({ 'Page': train[\"Page\"]})\n", "train_pages.head()\n", "        "], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "ec321f62-53eb-4884-bb00-f1c7ef3263ed", "_uuid": "c6e8bf0b83fb62682c175aab356417ea7e7d82c2", "scrolled": true}, "source": ["# from https://www.kaggle.com/muonneutrino/wikipedia-traffic-data-exploration\n", "# create properties for the important data points\n", "import re\n", "def getLang(page):\n", "    sear = re.search('[a-z][a-z].wikipedia.org',page)\n", "    if sear:\n", "        return sear[0][0:2]\n", "    return 'null'\n", "\n", "train_pages['language'] = train_pages.Page.map(getLang)\n", "\n", "def getExtra(page):\n", "    i = page.find(\".org_\")\n", "    if i > 0:\n", "        return page[i+len(\".org_\"):]\n", "    return \"NA\"\n", "\n", "train_pages['namemeta'] = train_pages.Page.map(getExtra)\n", "\n", "def getAccess(page):\n", "    spl = page.split(\"_\")\n", "    if len(spl) >= 1:\n", "        return spl[0]\n", "    return 'null'\n", "train_pages['access'] = train_pages.namemeta.map(getAccess)\n", "\n", "def getClient(page):\n", "    spl = page.split(\"_\")\n", "    if len(spl) >= 2:\n", "        return spl[1]\n", "    return 'null'\n", "train_pages['client'] = train_pages.namemeta.map(getClient)\n", "train_pages.head()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "86e330ae-0716-479b-a371-267107d0dbc7", "_uuid": "a9617d2b9699b11e5f02a6d01101043ff26d6493"}, "source": ["#train[\"mean\"] = train.drop(\"Page\", axis=1).mean(axis=0)\n", "\n", "train['mean'] = train.drop(\"Page\", axis=1).astype(float).mean(axis=1, skipna=True)\n", "train.head()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "168acf78-5f96-4886-9eb7-5a0bc4b3b982", "_uuid": "aca188f170b67af3f25e402d5fe571850448ec4b"}, "source": ["for i in train.iterrows():\n", "    print(i[1][1:])\n", "    print(max(i[1]))\n", "    raise Exception\n", "train.head()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "8965eae7-c350-4b29-9ae6-c6bd1c241cac", "collapsed": true, "_uuid": "71b438606e2d8decd6e885035a514d6f1fb0db37", "scrolled": true}, "source": ["# rename our time series data briefly - they are sequential over 500 days it seems?\n", "r = list(range(0,550))\n", "\n", "from datetime import datetime\n", "dateRoot = datetime.strptime(\"2015-07-01\", \"%Y-%m-%d\")\n", "def getDateDiff(dateString):\n", "    dateDiff = datetime.strptime(dateString, \"%Y-%m-%d\")\n", "    return (dateDiff - dateRoot).days()\n", "\n", "timef_train = train.drop(\"Page\", axis=1).drop(\"mean\", axis=1)\n", "timef_train.columns = r\n", "timef_train.head()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "783ca925-755a-426c-bfff-4338190e3da0", "collapsed": true, "_uuid": "f9ce639714abdfd658cdc4c7d4260c567d78b342"}, "source": ["import scipy.optimize\n", "import matplotlib.pyplot as plt\n", "from math import exp\n", "\n", "def gaussian(x, amp, cen, wid):\n", "    return amp * np.exp(-(x-cen)**2 / wid)\n", "\n", "\n", "#xdata = #timef_train.columns.astype(float);\n", "xdata = list(range(0,550))\n", "for row in timef_train.iterrows():\n", "    ydata = row[1]\n", "    popt, pcov = scipy.optimize.curve_fit(gaussian, xdata, ydata)\n", "    fig = plt.figure()\n", "    ax = fig.add_subplot(2,1,1)\n", "    ax.plot(xdata, ydata, 'b-', label='data')\n", "    ax.plot(xdata, gaussian(xdata, *popt), 'g--', label='fit-test')\n", "    ax.set_yscale('log')\n", "    plt.xlabel('x')\n", "    plt.ylabel('y')\n", "    ax.legend()\n", "    plt.show()\n", "    raise Exception\n"], "execution_count": null, "cell_type": "code", "outputs": []}]}