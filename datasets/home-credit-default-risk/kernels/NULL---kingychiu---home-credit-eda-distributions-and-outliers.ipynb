{"cells":[{"metadata":{"_uuid":"e793b768f8d3315e39215e7baf8d3410ea491911"},"cell_type":"markdown","source":"Hi there, this notebook aims to provide visualization about different features distribution and observing abnormal values in the dataset. \n\n# Table of Contents\n1. Target Distribution\n2. application_{train|test}.csv\n    * 2.1 NaN Count\n    * 2.2 [Feature Generation] Adding IS_NAN features for each column.\n    * 2.3 The importance of the missing values\n    * 2.4. Features' Distribution\n    * 2.5 Are the distributions making sense?\n3. bureau.csv\n4. ...pending\n\n# 1. Target Distribution\n\n\n"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"8321de93120c7e3bd2b9995bd93d09d6dd63d5e1","_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport matplotlib\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport collections\nfrom lightgbm import LGBMClassifier, plot_importance\nimport seaborn as snss\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'figure.max_open_warning': 200})\n%matplotlib inline\ntrain_application_df = pd.read_csv('../input/application_train.csv')\ntest_application_df = pd.read_csv('../input/application_test.csv')\n# print(train_application_df.shape, test_application_df.shape)\nall_application_df = pd.concat([train_application_df, test_application_df], axis=0)\n# print(all_application_df.shape)","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"b18e17538f57379ca86a9025fe2cd5f249a729a6"},"cell_type":"markdown","source":"The target distribution is imbalanced, which indicates the company has already done a great job (some direct feature, like external scoring, in the dataset might not be that helpful)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"target_distribution = train_application_df['TARGET'].value_counts()\ntarget_distribution.plot.pie(figsize=(10, 10),\n                             title='Target Distribution',\n                             fontsize=15, \n                             legend=True, \n                             autopct=lambda v: \"{:0.1f}%\".format(v))","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"0630c3863cb0824736922472dd1c717e718b6a60"},"cell_type":"markdown","source":"# 2. application_{train|test}.csv> \n##  2.1 NaN Count\nThere are lots of NaN values in the dataset (also as discussed in the forum, the organizer also filled in some missing data with magic values). Need to handle them carefully."},{"metadata":{"trusted":true,"_uuid":"4f2598170acb3b41aff638a0919ece3a366f9fc1","collapsed":true},"cell_type":"code","source":"total_nans = all_application_df.isna().sum()\nnan_precents = (all_application_df.isna().sum()/all_application_df.isna().count()*100)\nfeature_overview_df  = pd.concat([total_nans, nan_precents], axis=1, keys=['NaN Count', 'NaN Pencent'])\nfeature_overview_df['Type'] = [all_application_df[c].dtype for c in feature_overview_df.index]\npd.set_option('display.max_rows', None)\ndisplay(feature_overview_df)\npd.set_option('display.max_rows', 20)","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"971dbff697ee440c97bb72c79c656ac6264ed1c1"},"cell_type":"markdown","source":"## 2.2 [Feature Generation] Adding IS_NAN features for each column."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fe72d62d42e9b87f50c53ed990d928042e56cfbb","_kg_hide-input":false},"cell_type":"code","source":"all_application_is_nan_df = pd.DataFrame()\nfor column in all_application_df.columns:\n    if all_application_df[column].isna().sum() == 0:\n        continue\n    all_application_is_nan_df['is_nan_'+column] = all_application_df[column].isna()\n    all_application_is_nan_df['is_nan_'+column] = all_application_is_nan_df['is_nan_'+column].map(lambda v: 1 if v else 0)\nall_application_is_nan_df['target'] = all_application_df['TARGET']\nall_application_is_nan_df = all_application_is_nan_df[pd.notna(all_application_is_nan_df['target'])]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a91bc7ad96c050d08f759a0e36d694f4e3dd42d4","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"display(all_application_is_nan_df)","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"acac57c8363872cad06a027b6a3ac2e580926209"},"cell_type":"markdown","source":"## 2.3 The importance of the missing values"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"81ab122600b354efa57ac8419f46a63cf645e0e1"},"cell_type":"code","source":"Y = all_application_is_nan_df.pop('target')\nX = all_application_is_nan_df\n\ntrain_X, valid_X, train_Y, valid_Y = train_test_split(X, Y, test_size=0.2, random_state=2018)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c32fca3ab7e6f3302fe46a08c5703b8dcbc2505e","collapsed":true},"cell_type":"code","source":"clf = LGBMClassifier(n_estimators=200, learning_rate=0.01)\nclf.fit(\n        train_X,\n        train_Y,\n        eval_set=[(train_X, train_Y), (valid_X, valid_Y)],\n        eval_metric='auc',\n        early_stopping_rounds=50,\n        verbose=False\n       )\nplot_importance(clf, figsize=(10,10))","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"9f3ac6f9b31ddc98c87b8494468a6af3d5d9bbb8"},"cell_type":"markdown","source":"## 2.4 Features' Distribution"},{"metadata":{"_kg_hide-input":true,"trusted":true,"scrolled":false,"_uuid":"778637f93c3149308e297125f643700c829c09c5","collapsed":true,"_kg_hide-output":true},"cell_type":"code","source":"# add noise to y axis to avoid overlapping\ndef rand_jitter(arr):\n    nosie = .01*(max(arr)-min(arr))\n    return arr + np.random.randn(len(arr))\n\ndef draw_feature_distribution(df, column):\n    column_values = df[df[column].notna()][column]\n    # group by target\n    class_0_values = df[df[column].notna() & (df['TARGET']==0)][column]\n    class_1_values = df[df[column].notna() & (df['TARGET']==1)][column]\n    class_t_values = df[df[column].notna() & (df['TARGET'].isna())][column]        \n    print('\\n\\n', column)\n    # for features with unique values >= 10\n    if len(df[column].value_counts().keys()) >= 10:\n        fig, ax = plt.subplots(1, figsize=(15, 4))\n        if df[column].dtype == 'object':\n            label_encoder = LabelEncoder()\n            label_encoder.fit(column_values)\n            class_0_values = label_encoder.transform(class_0_values)\n            class_1_values = label_encoder.transform(class_1_values)\n            class_t_values = label_encoder.transform(class_t_values)\n            column_values = label_encoder.transform(column_values)\n            plt.xticks(range(len(label_encoder.classes_)), label_encoder.classes_, fontsize=12, rotation='vertical')\n\n        ax.scatter(class_0_values, rand_jitter([0]*class_0_values.shape[0]), label='Class0', s=10, marker='o', color='#7ac143', alpha=1)\n        ax.scatter(class_1_values, rand_jitter([10]*class_1_values.shape[0]), label='Class1', s=10, marker='o', color='#fd5c63', alpha=1)\n        ax.scatter(class_t_values, rand_jitter([20]*class_t_values.shape[0]), label='Test', s=10, marker='o', color='#037ef3', alpha=0.4)\n        ax.set_title(column +' group by target', fontsize=16)\n        ax.legend(bbox_to_anchor=(1.01, 1), loc=\"upper left\")\n        ax.set_title(column +' distribution', fontsize=16)\n    else:      \n        all_categories = list(df[df[column].notna()][column].value_counts().keys())\n        bar_width = 0.25\n        \n        fig, ax = plt.subplots(figsize=(20, 4))\n        ax.set_title(column, fontsize=16)\n        plt.xlabel('Categories', fontsize=16)\n        plt.ylabel('Counts', fontsize=16)\n\n        value_counts = class_0_values.value_counts()\n        x_0 = np.arange(len(all_categories))\n        y_0 = [value_counts.get(categroy, 0) for categroy in all_categories]\n        ax.bar(x_0, y_0, color='#7ac143', width=bar_width, label='class0')\n\n        value_counts = class_1_values.value_counts()\n        x_1 = np.arange(len(all_categories))\n        y_1 = [value_counts.get(categroy, 0) for categroy in all_categories]\n        ax.bar(x_1+bar_width, y_1, color='#fd5c63', width=bar_width, label='class1')\n        \n        value_counts = class_t_values.value_counts()\n        x_2 = np.arange(len(all_categories))\n        y_2 = [value_counts.get(categroy, 0) for categroy in all_categories]\n        ax.bar(x_2+2*bar_width, y_2, color='#037ef3', width=bar_width, label='test')\n        \n        ax.legend(bbox_to_anchor=(1.01, 1), loc=\"upper left\")\n        \n        for i, v in enumerate(y_0):\n            if y_0[i]+y_1[i] == 0:\n                ax.text(i - .08, max(y_0)//1.25,  'Missing in Train', fontsize=14, rotation='vertical')\n            else:\n                ax.text(i - .08, max(y_0)//1.25,  \"{:0.1f}%\".format(100*y_0[i]/(y_0[i]+y_1[i])), fontsize=14, rotation='vertical')\n        \n        for i, v in enumerate(y_1):\n            if y_0[i]+y_1[i] == 0:\n                ax.text(i - .08, max(y_0)//1.25,  'Missing in Train', fontsize=14, rotation='vertical')\n            else:\n                ax.text(i + bar_width - .08, max(y_0)//1.25, \"{:0.1f}%\".format(100*y_1[i]/(y_0[i]+y_1[i])), fontsize=14, rotation='vertical')\n \n        for i, v in enumerate(y_2):\n            if y_2[i] == 0:\n                ax.text(i + 2*bar_width - .08, max(y_0)//1.25, 'Missing in Test', fontsize=14, rotation='vertical')\n            else:\n                ax.text(i + 2*bar_width - .08, max(y_0)//1.25, str(y_2[i]), fontsize=14, rotation='vertical')\n        \n        plt.xticks(x_0 + 2*bar_width/3, all_categories, fontsize=16)\n        \n    plt.show()","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2a29bea4957a8c7cc13d2e54e66e436e075394b","collapsed":true},"cell_type":"code","source":"print(\"only showing the distribution for the first few columns, edit the counter to show all distribution\")\nshow_feature_count = 10\nfor column in all_application_df.columns:\n    if show_feature_count == 0:\n        break\n    show_feature_count -= 1\n    draw_feature_distribution(all_application_df, column)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"73a147feae7156dce418cfb135be49d7aff01483"},"cell_type":"markdown","source":"## 2.5 Are the distributions making sense?\n### 2.5.1 DAYS_EMPLOYED\nHow many days before the application the person started current employment\n\nDiscussed in the forum, For DAYS_xxx columns, **365243 means missing value**.\n* The original distribution:"},{"metadata":{"trusted":true,"_uuid":"1b1f8660fba4ffd9cdb78d12fb32d8a5d16e5ce5","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"draw_feature_distribution(all_application_df, 'DAYS_EMPLOYED')","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"32823010392fde47e3dcf403e4d3ef6f6c1198aa"},"cell_type":"markdown","source":"If the magic number is removed, the distribution:"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"cd8b121af317df32a44b7213d2e1940bb2b2f8cf","collapsed":true},"cell_type":"code","source":"# the organizer used 365243 to represent missing value in this column\ntemp_df = all_application_df[all_application_df['DAYS_EMPLOYED'] != 365243]\ndraw_feature_distribution(temp_df, 'DAYS_EMPLOYED')","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"faa87e116a9048d74b6aa0d8a675e70cce4a8b97"},"cell_type":"markdown","source":"### 2.5.2 AMT_INCOME_TOTAL\nIncome of the client.\n\nThere are a huge number at the right of the plot (1.170000e+08):"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"cdf325295f95acfd9021a679c50e51224f4e784f","collapsed":true},"cell_type":"code","source":"print(all_application_df['AMT_INCOME_TOTAL'].describe())\ndraw_feature_distribution(all_application_df, 'AMT_INCOME_TOTAL')","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"3a75b7452e83cb0d975e05a425cc11126a11f005"},"cell_type":"markdown","source":"The plot makes more sense if we remove that data point:"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"d7e57d029fdecf854aaf128f18bf68f3741ce7fa","collapsed":true},"cell_type":"code","source":"temp_df = all_application_df[all_application_df['AMT_INCOME_TOTAL'] != 1.170000e+08]\ndraw_feature_distribution(temp_df, 'AMT_INCOME_TOTAL')","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"e52a1cb36161a8bc222a97ab3bb6a78e4827fffd"},"cell_type":"markdown","source":"### 2.5.3 AMT_REQ_CREDIT_BUREAU_QRT\nNumber of enquiries to Credit Bureau about the client 3 month before application (excluding one month before application)\n\nWhy were there 261 enquireies about a application within 2 months? 4 calls a day?"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"cb4622a91adfc09cab2bae602fdd4601d75a8e9b","collapsed":true},"cell_type":"code","source":"print(all_application_df['AMT_REQ_CREDIT_BUREAU_QRT'].describe())\ndraw_feature_distribution(all_application_df, 'AMT_REQ_CREDIT_BUREAU_QRT')","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"a8d53d5d1229bb8b051e9c4bb4f50d420b217daa"},"cell_type":"markdown","source":"Removing that data point:"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"81d7e723315286c988e38db16df2af9711b7ac5d","collapsed":true},"cell_type":"code","source":"temp_df = all_application_df[all_application_df['AMT_REQ_CREDIT_BUREAU_QRT'] != 261]\ndraw_feature_distribution(temp_df, 'AMT_REQ_CREDIT_BUREAU_QRT')","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"9de6e07f930f5a794778102df978fc622902a545"},"cell_type":"markdown","source":"### 2.5.4 Normalized information about building where the client lives\n\nWhy those Normalized information got many 0s and 1s? such as this one:"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"7a6d1a1038c7ca5a21f281f208610ddfc554ce0e","collapsed":true},"cell_type":"code","source":"draw_feature_distribution(all_application_df, 'NONLIVINGAPARTMENTS_MODE')","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"53e8d1a3f3c6db07fbe35bd04bc1e294bdc30830"},"cell_type":"markdown","source":"### 2.5.5 OBS_30_CNT_SOCIAL_CIRCLE\nHow many observation of client's social surroundings with observable 30 DPD (days past due) default\n\nIs it normal to have over 350 social surroundings overations?"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"24b34e133003b487c4e4968e7b631e90720c124a","collapsed":true},"cell_type":"code","source":"draw_feature_distribution(all_application_df, 'OBS_30_CNT_SOCIAL_CIRCLE')","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"53fe13ee2d70eb2cc42803e36d021bcb0624c721"},"cell_type":"markdown","source":"# 3 bureau.csv\n\nPending"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dabe4e20c3a8635ed171be7b729258c2dd9f333c"},"cell_type":"markdown","source":"Thanks for reading, this is my first attempt to try making a relatively complete EDA & visualization. Please let me know if you have any suggestions, I am desired to learn new things."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d80f8fa46702c7bdce6bcf968353495a829b453b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}