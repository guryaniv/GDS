{"cells": [{"metadata": {"_uuid": "addb1b7acb4089b53d8a9c5269b58729fd7a0bf7", "_cell_guid": "37ea5119-168c-4779-a1f6-d1e2c52a2c87"}, "cell_type": "markdown", "source": ["# Import Library\n", "> \n", "* pandas\n", "* numpy\n", "* operating system\n", "* opencv 2"]}, {"outputs": [], "metadata": {"_uuid": "19cc2fad8f62132f438246642d11e4f2d9de4e1e", "_cell_guid": "2212edeb-a695-4657-80ee-2d0cd8a859bf", "collapsed": true, "_execution_state": "busy"}, "cell_type": "code", "source": ["import numpy as np\n", "import pandas as pd\n", "import os\n", "import cv2"], "execution_count": 11}, {"metadata": {"_uuid": "4f19d26f1b4ee8f20232d606fd20db001904b146", "_cell_guid": "0dcc466f-0e3e-4ae5-8b9b-d26ce25f285a"}, "cell_type": "markdown", "source": ["# Prepare data from directory\n", "> \n", "* list directory train and test\n", "* define size image to load (row, column) and channel (3 channel to RGB)\n", "* sort directory list and add directory name with name file"]}, {"outputs": [], "metadata": {"_uuid": "d5bedd62256c45acf193a82555ee2b8c182bf7a0", "_cell_guid": "f2083822-0c8e-4ced-910d-209030e61ef1", "collapsed": true, "_execution_state": "busy"}, "cell_type": "code", "source": ["TRAIN_DIR = '../input/train/'\n", "TEST_DIR = '../input/test/'\n", "\n", "ROWS = 128\n", "COLS = 128\n", "CHANNELS = 1\n", "\n", "train = os.listdir(TRAIN_DIR)\n", "train = sorted(train,key=lambda x: int(os.path.splitext(x)[0]))\n", "train = [TRAIN_DIR + x for x in train]\n", "\n", "test  = os.listdir(TEST_DIR)\n", "test  = sorted(test,key=lambda x: int(os.path.splitext(x)[0]))\n", "test  = [TEST_DIR + x for x in test]"], "execution_count": 12}, {"metadata": {}, "cell_type": "markdown", "source": ["# Preprocess data\n", "* load data with open cv\n", "* resize image with size that already define above\n", "* store pixel value to numpy array"]}, {"outputs": [], "metadata": {"_uuid": "c3124e837e1f85ac4b511a4264757579a93c6261", "_cell_guid": "083c6202-792e-431c-b01c-9aa39c7f90df", "_execution_state": "busy"}, "cell_type": "code", "source": ["def read_image(file_path):\n", "    img = cv2.imread(file_path, 0)\n", "    img = cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n", "    return img\n", "\n", "\n", "def prep_data(images):\n", "    count = len(images)\n", "    data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.uint8)\n", "\n", "    for i, image_file in enumerate(images):\n", "        image = read_image(image_file)\n", "        data[i] = image\n", "        if i%250 == 0: print('Processed {} of {}'.format(i, count))\n", "    \n", "    return data\n", "\n", "train = prep_data(train)\n", "test = prep_data(test)\n", "\n", "print(\"Train shape: {}\".format(train.shape))\n", "print(\"Test shape: {}\".format(test.shape))"], "execution_count": 13}, {"metadata": {}, "cell_type": "markdown", "source": ["## Load and get label"]}, {"outputs": [], "metadata": {"_uuid": "60d0031d578aaa7478c87fb339141d5837d869b2", "_cell_guid": "929253d6-1758-4a99-be64-1188c643368c", "_execution_state": "busy"}, "cell_type": "code", "source": ["label = pd.read_csv(\"../input/train_labels.csv\")\n", "y = label[\"invasive\"]\n", "y.shape"], "execution_count": 14}, {"metadata": {}, "cell_type": "markdown", "source": ["## Plot data training sample image"]}, {"outputs": [], "metadata": {"_uuid": "267c3ee1098323b024239e13b3df00c50d93278b", "_cell_guid": "1809b6ba-5b28-4108-b2e8-0ca1c0036647", "_execution_state": "busy"}, "cell_type": "code", "source": ["from matplotlib import pyplot as plt\n", "from matplotlib import cm\n", "for i in range(9):\n", "    plt.subplot(331+i)\n", "    plt.imshow(train.reshape(-1,1,128,128)[i][0], cmap=cm.binary)\n", "plt.show()\n", "print(label[0:9])"], "execution_count": 15}, {"metadata": {}, "cell_type": "markdown", "source": ["## Split 500 above for training and first 500 data for validation"]}, {"outputs": [], "metadata": {"_uuid": "20d840936ba3af01bf525ae1cc9674d639a3025a", "_cell_guid": "668a31fd-cc1c-4c52-80f3-5fc571c9fe43", "_execution_state": "busy"}, "cell_type": "code", "source": ["y_train = y[500:]\n", "y_valid = y[:500]\n", "\n", "X_train = train[500:]\n", "X_valid = train[:500]\n", "y_train[0:9]"], "execution_count": 16}, {"metadata": {}, "cell_type": "markdown", "source": ["## Load keras library to define model"]}, {"outputs": [], "metadata": {"_uuid": "03f1e59d76d6850c887282513432f207bea6b04a", "_cell_guid": "3c56ebff-87ed-442c-9277-3dd2e5095b5b", "_execution_state": "busy"}, "cell_type": "code", "source": ["from keras.models import Sequential\n", "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\n", "from keras.optimizers import RMSprop\n", "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n", "from keras.utils import np_utils"], "execution_count": 17}, {"outputs": [], "metadata": {"_uuid": "102d6bdb44364a36175d3ef3375fba5986abca63", "_cell_guid": "01256971-19d1-4540-a77c-43a146a5b1d2", "_execution_state": "busy"}, "cell_type": "code", "source": ["X_train = X_train.reshape(X_train.shape[0], 128, 128, 1).astype('float32')\n", "X_valid = X_valid.reshape(X_valid.shape[0], 128, 128, 1).astype('float32')\n", "\n", "# normalize inputs from 0-255 to 0-1\n", "X_train = X_train / 255\n", "X_valid = X_valid / 255\n", "\n", "# one hot encode outputs\n", "y_train = np_utils.to_categorical(y_train)\n", "y_valid = np_utils.to_categorical(y_valid)\n", "num_classes = y_valid.shape[1]\n", "num_classes"], "execution_count": 18}, {"outputs": [], "metadata": {"_uuid": "d2432d871b8719d120e5ff24600f042e7cc715a3", "_cell_guid": "321ac036-38c3-4406-a828-145ae6b8a9d6", "collapsed": true, "_execution_state": "busy"}, "cell_type": "code", "source": ["def larger_model():\n", "    # create model\n", "    model = Sequential()\n", "    model.add(Convolution2D(64, 5, 5, border_mode='valid', input_shape=(128, 128, 1), activation='relu'))\n", "    model.add(MaxPooling2D(pool_size=(2, 2)))\n", "    model.add(Convolution2D(32, 3, 3, activation='relu'))\n", "    model.add(MaxPooling2D(pool_size=(2, 2)))\n", "    model.add(Dropout(0.2))\n", "    model.add(Flatten())\n", "    model.add(Dense(128, activation='relu'))\n", "    model.add(Dense(50, activation='relu'))\n", "    model.add(Dense(num_classes, activation='softmax'))\n", "    # Compile model\n", "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n", "    return model"], "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "0b05f3822c73b95c1b62ce95231d3d765ff00766", "_cell_guid": "71eb91c6-9c98-410c-bda5-6c20a4fbdd4a", "_execution_state": "busy"}, "cell_type": "code", "source": ["# build the model\n", "model = larger_model()\n", "# Fit the model\n", "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10, batch_size=250, verbose=2)"], "execution_count": null}], "nbformat": 4, "metadata": {"language_info": {"version": "3.6.1", "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "name": "python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat_minor": 1}