{"nbformat_minor": 2, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"version": "2.7.13", "codemirror_mode": {"version": 2, "name": "ipython"}, "name": "python", "pygments_lexer": "ipython2", "file_extension": ".py", "mimetype": "text/x-python", "nbconvert_exporter": "python"}}, "cells": [{"source": ["# Credit Card Fraud Detection"], "metadata": {"_uuid": "8677a6ff06486a26379f48208d0fc43ae2b2dee5"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": "### 1. Goal\n\nTrain, evaluate and optimize models to predict fraudulent credit card transactions using (i) data on credit card transactions from Kaggle and (ii) LogisticRegression and RandomForestClassifiers\n\n### 2. Approach\n1. Start with a logistic regression classifier, and then move on to use a random forest classifier\n2. Undersample the number of non-fraudulent cases in the training set so as to reduce the skew\n3. Apply GridSearchCV or RandomizedSearchCV to find the most optimal hyperparameters for each model\n4. Increase the train_test_split ratio from the default of 25% to 40%. If the recall rate of the test set doesn't dip, we know that we're not overfitting\n\n### 3. Summary of experiments\n![image](https://image.ibb.co/hyXJ7v/Screen_Shot_2017_07_15_at_07_16_23.png)\n\n### 4. TL;DR / Key findings\n1. A **\"vanilla\" random forest model (i.e. with default hyperparameters) trained on a balanced dataset (See [Iteration 7](#iteration_7)) performs the best.** (Well, random forest models optimized with RandomizedSearchCV perform better, but not by much)\n2. This model is able to **accurately predict fraud cases with a 95% recall rate** (i.e. of the 492 fraud cases, it only misclassified 5% (47 cases) as false negatives). This is true even when the model given only 60% of the data as training data. \n3. Variables `V17`, `V12`, `V11`, `V14`, `V16` and `V10` (anonymized because banks) have the highest feature importance score in determining fraud cases (see [chart](#feature_importances))\n\n### 5. Other observations from a machine learning standpoint\n\n1. LogisticRegression models are a great starting point for building classification models, and can reach the same recall rate after some hyperparameter optimization with `GridSearchCV`\n2. RandomForestClassifier models performs better than LogisticRegression out of the box, even without any tuning/optimisation\n3. Undersampling is a useful technique for training models with highly skewed data (and `imblearn.under_sampling.RandomUnderSampler` from the `imbalanced_learn` library has a nice API that makes resampling as easy as calling a method\n", "metadata": {"_uuid": "86a05e457050da749ffceae1c537993e575966de"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"metadata": {"_execution_state": "idle", "_uuid": "be7905030836045125291a0ed0047d4f23efe452", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport imblearn\n\n%matplotlib inline\npd.options.display.max_columns = 40\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression", "metadata": {"_uuid": "d3384bd7cca9dc7db406adb58d2cd2a458564229", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["### Load data"], "metadata": {"_uuid": "73039a2b6da6961d15d964f38ac2e5021569a80b"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["df = pd.read_csv('./data/creditcard.csv')"], "metadata": {"_uuid": "4744693fd9e54f84d8a14a2b04e8bfef5edf72ee", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["df.head()"], "metadata": {"_uuid": "dae4307f991d9d5de15b3c70fe748dde58a1c245", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["df.describe()"], "metadata": {"_uuid": "44c21911f86bf607fdb398577b16f7e726880851", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["### Exploratory data analysis"], "metadata": {"_uuid": "00a3c2b27b466c329891ee786d1a10d5d1efcc19"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["pd.value_counts(df['Class'])"], "metadata": {"_uuid": "0dc559adac723a1a4fe3947ae073c3c09a4b2821", "scrolled": true, "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["non_fraud_percentage = (284315-492)/284315.0\n", "print(non_fraud_percentage)"], "metadata": {"_uuid": "24fbda4bdb5d9626b1094de75643f9019cfb656a", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["We have a highly unbalanced dataset, and this will make it hard to train our model to detect fraud.\n", "If we wrote a function to always predict 0 (y=not_fraud), we would be correct **99.8%** of the time, but would not have detected any of the fraud cases.\n", "\n", "To deal with this, we have 3 options:\n", "1. **Weighting**: Assign the under-represented class a higher weight. However, this is unlikely to be effective given the significant skew in the dataset.\n", "2. **Thresholding**: Override the model's `.predict()` method to classify something as 0 or 1 based on a probability threshold (e.g. 0.90), rather than the probability with the higher value (e.g. 0.50001)\n", "3. **Sampling**: For each training set, sample it in such a way that the instances of 0 and 1 are roughly equal\n", "\n", "[Read more](https://stackoverflow.com/questions/26221312/dealing-with-the-class-imbalance-in-binary-classification/26244744#26244744)"], "metadata": {"_uuid": "fac133092e42ce9e94f984ee65770f389b3c0b86"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["### Preparing our data for modeling"], "metadata": {"_uuid": "f95d39a75d9ea6d7778aa7054f471a75496fafe7"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["X = df.ix[:, df.columns != 'Class']\n", "y = df.ix[:, df.columns == 'Class'].values.ravel()"], "metadata": {"_uuid": "9123a13df6b666b8b98b71f23f518b40fee1d8fd", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["[`.ravel()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ravel.html) is a method that helps us convert y (which is originally a column-vector) to a 1-dimensional array, so that scikit-learn won't throw a DataConversionWarning. The code will work without transforming it with `.values.ravel()` as well, but we'll have a warning message, which is not so nice. "], "metadata": {"_uuid": "fdf884233cf15d5368e07c587a888a18066fafe7"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["### Split our data into train and test sets\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0)"], "metadata": {"_uuid": "b8c062e151b0493a53cc625f7d26137ca5e21451", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["# Defining some utility methods for printing model metrics\n", "\n", "def print_header(title):\n", "    print(\"\\n\" + title + \":\\n\")\n", "    \n", "def print_metrics(model, X, y):\n", "    expected = y\n", "    predicted = model.predict(X)\n", "    \n", "    print_header('CONFUSION MATRIX')\n", "    print(metrics.confusion_matrix(expected, predicted))\n", "    \n", "    print_header('CLASSIFICATION REPORT')\n", "    print(metrics.classification_report(expected, predicted))"], "metadata": {"_uuid": "c0573495fb7ec8fcdc134eb4e2d680d4305103dc", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["<a id='iteration_1'></a>\n", "## Iteration 1: Logistic regression model (with no sampling or thresholding)"], "metadata": {"_uuid": "b3ad89532eab21c760f2ce2d29471d82acf5fb0d"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["### Train our model"], "metadata": {"_uuid": "f6d89aca1b0b29930bff45c587bbfea3df05e135"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["model_1 = LogisticRegression()"], "metadata": {"_uuid": "c07fac2ef1cd4c3676d92a07dbd2cecf32928c3c", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["model_1.fit(X_train, y_train)"], "metadata": {"_uuid": "0b84cb1d34a6f83897fef3faf103d29cade540c3", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["### Evaluate our model"], "metadata": {"_uuid": "033746a155075036ecc8a60489d3bcd866b44dc1"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["# 1. .score()\n", "train_score_1 = model_1.score(X_train, y_train)\n", "test_score_1 = model_1.score(X_test, y_test)\n", "\n", "print(\"training set score: %f\" % train_score_1)\n", "print(\"test set score:     %f\" % test_score_1)"], "metadata": {"_uuid": "fff110d04b625cd318ca086856dbd724406568bc", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["Given the skewed of the data, even if we always predicted 'no fraud', we will get a score of 99.8%. As such, score is not a useful metric and this is the last time we will use it to evaluate our model"], "metadata": {"_uuid": "3115b79df8e44eb623c8d20918e29e41ac29795e"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["print_metrics(model_1, X, y)"], "metadata": {"_uuid": "2bf9874942817d3743a20c870ccaa0db4494c3f0", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["Looking at the 2nd nested array (`[false_positives, true_positives]`), we see that we've correctly predicted **322** fraudulent transactions, and we've misclassified **170** fraudulent transactions as non-fraudulent."], "metadata": {"_uuid": "9670218c4a444e10961517467b66d8618660b98d"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["Looking at the precision score, we can see that **74% of our predictions of y=1 (fraud) were were**.\n", "\n", "Looking at the recall score, we can see that only **65% of the fraudulent cases in reality were correctly classified**.\n", "\n", "Note: remember our helpful mnemonic:\n", "- **pre**cision: a measure of our accuracy with our **pre**dictions as the baseline\n", "- **re**call: a measure of our accuracy with the **re**ality as the baseline"], "metadata": {"_uuid": "42bbde2b14ff90e235ddcf7a4d2f918a48bf37b9"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["<a id='iteration_2'></a>\n", "## Iteration 2: Logistic regression model (with undersampled data)"], "metadata": {"_uuid": "a737edeb14faa069f52e7d665e0411e2225bc5b9"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["To improve the accuracy of the model, we can undersample the data such that the proportion of cases of y=0 and y=1 are 50-50, instead of 99.8-0.2.\n", "\n", "**`imblearn`** (imbalanced_learn) is a nice library that has methods for doing this undersampling"], "metadata": {"_uuid": "7ffaf6a08856b7750ab036893b64d3b08f58a286"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["from imblearn.under_sampling import RandomUnderSampler\n", "\n", "import collections"], "metadata": {"_uuid": "4a75e11940070fdb466e71abd2ef57b9b86765a5", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["rus = RandomUnderSampler(return_indices=True)\n", "X_undersampled, y_undersampled, idx_resampled = rus.fit_sample(X, y)\n", "print('length of X and y:', len(X_undersampled), len(y_undersampled))\n", "print('Count of y values:', collections.Counter(y_undersampled))"], "metadata": {"_uuid": "05ed661f3b2f50b1bc6942ce94f3e7dfaea53e3a", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["X_train_undersampled_25_percent_split, X_test_undersampled_25_percent_split, y_train_undersampled_25_percent_split,\\\n", "    y_test_undersampled_25_percent_split = train_test_split(X_undersampled, y_undersampled, random_state=0)"], "metadata": {"_uuid": "0cdd8dabe304076930aeea85aadaba13eee19e93", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["model_2 = LogisticRegression()\n", "model_2.fit(X_train_undersampled_25_percent_split, y_train_undersampled_25_percent_split)"], "metadata": {"_uuid": "35322b6c34a79ea87959c28424d4b616548b8ee6", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["print_metrics(model_2, X, y)"], "metadata": {"_uuid": "32962cc82b2997e44bb3d47d18d993e3b44ab363", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["<a id='iteration_3'></a>\n", "## Iteration 3: Logistic regression model (with GridSearchCV)"], "metadata": {"_uuid": "e918757c862839e7f4615cb78c5ed4f46e754286"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["from sklearn.model_selection import GridSearchCV"], "metadata": {"_uuid": "4a1e69802d6dfbf781d8df436bb045083969b5cc", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["logistic_regression_model = LogisticRegression()\n", "\n", "param_grid = {'C': [0.01, 0.1, 1, 10],\n", "              'class_weight': [{\n", "                  0: 1, \n", "                  1: 2\n", "              },\n", "              {\n", "                  0: 1, \n", "                  1: 1.2\n", "              },\n", "              {\n", "                  0: 1, \n", "                  1: 1.4\n", "              }\n", "              ]}\n", "\n", "model_3 = GridSearchCV(estimator=logistic_regression_model, param_grid=param_grid, cv=5)\n", "model_3.fit(X_train, y_train)\n", "\n", "print(\"Best estimator:\", model_3.best_estimator_)\n", "print(\"Best score:\", model_3.best_score_)"], "metadata": {"_uuid": "cc2e0cf20cadc7669d9392ccffdf1a8a0b28dfae", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["print_metrics(model_3, X, y)"], "metadata": {"_uuid": "38e79e028757ff812af200e6311d69009f4acc2b", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["<a id='iteration_4'></a>\n", "## Iteration 4: Logistic regression model (with undersampled data and GridSearchCV)"], "metadata": {"_uuid": "d1d7126bc33a4a829e090a2f0dde37f349f24910"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["logistic_regression_model = LogisticRegression()\n", "\n", "param_grid = {'C': [0.01, 0.1, 1, 10],\n", "              'class_weight': [{\n", "                  0: 1, \n", "                  1: 2\n", "              },\n", "              {\n", "                  0: 1, \n", "                  1: 1.2\n", "              },\n", "              {\n", "                  0: 1, \n", "                  1: 1.4\n", "              }]}\n", "\n", "model_4 = GridSearchCV(estimator=logistic_regression_model, param_grid=param_grid, cv=5)\n", "model_4.fit(X_train_undersampled_25_percent_split, y_train_undersampled_25_percent_split)\n", "\n", "print(\"Best estimator:\", model_4.best_estimator_)\n", "print(\"Best score:\", model_4.best_score_)"], "metadata": {"_uuid": "888ce3f9b8601e084e16491cc0dc925d216243d2", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["print_metrics(model_4, X, y)"], "metadata": {"_uuid": "93790df1ba95094d312c458ca445f0c7e83f51fb", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["<a id='iteration_5'></a>\n", "## Iteration 5: Random Forest"], "metadata": {"_uuid": "a195ff82ce91db08295d656bea8e3697097a88c1"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["from sklearn.ensemble import RandomForestClassifier"], "metadata": {"_uuid": "a774beb1c409c75e339146bf59a10c156dce07d2", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["model_5 = RandomForestClassifier(random_state=0)\n", "model_5.fit(X_train, y_train)"], "metadata": {"_uuid": "3301a16e17a3116e358c056b371c9a24998ff934", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["print_metrics(model_5, X, y)"], "metadata": {"_uuid": "52548445026ae8d0bfc42fc2332240d703d70581", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["<a id=\"feature_importances\"></a>\n", "### Bonus step: View/plot feature\\_importances\\_ in a random forest classifier"], "metadata": {"_uuid": "530fdf764f058ba0fe71674149b00c39aa3fee46"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["model_5.feature_importances_"], "metadata": {"_uuid": "207373fdc85e9b1f7df80371c9630f4390095e92", "scrolled": true, "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["plt.plot(model_5.feature_importances_, 'o')\n", "plt.xticks(range(32), df.columns.values, rotation=90);"], "metadata": {"_uuid": "46b97af74fca3e5d0c1d7c2b7c9004684b9e30a7", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["<a id='iteration_6'></a>\n", "## Iteration 6: Random Forest (with undersampling)"], "metadata": {"_uuid": "9144df6efd11537dc5e08f389558b304f686e541"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["from sklearn.ensemble import RandomForestClassifier"], "metadata": {"_uuid": "a7dcff1e49897892046a853edce69ce9fb825279", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["model_6 = RandomForestClassifier(random_state=0)\n", "model_6.fit(X_train_undersampled_25_percent_split, y_train_undersampled_25_percent_split)"], "metadata": {"_uuid": "d2168d1c432c8ec41e7a60f89b48a22db9995652", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["print_metrics(model_6, X, y)"], "metadata": {"_uuid": "cd92974eefc515771797a9a7f20af461e6d1ca78", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["<a id='iteration_7'></a>\n", "## Iteration 7: Random Forest (with undersampled data, and 40% train_test_split ratio)"], "metadata": {"_uuid": "b09e555b8ee8dc35627b51d245e25bc14c7b962c"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["To ensure that we're not overfitting, let's try it with 40% train_test_split ratio (i.e. 40% of the data will be held off for testing/validating), instead of the default ratio of 25%"], "metadata": {"_uuid": "80b20b296b0d24a896ee54ff9434f7cc3f40d343"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["X_train_undersampled_40_percent_split, X_test_undersampled_40_percent_split, y_train_undersampled_40_percent_split,\\\n", "    y_test_undersampled_40_percent_split = train_test_split(X_undersampled,\n", "                                                            y_undersampled,\n", "                                                            test_size=0.4,\n", "                                                            random_state=0)"], "metadata": {"_uuid": "3e79975e9a0a8e100cf344030b5c434ee76d3848", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["model_7 = RandomForestClassifier(random_state=0)\n", "model_7.fit(X_train_undersampled_40_percent_split, y_train_undersampled_40_percent_split)"], "metadata": {"_uuid": "cd719129d741590e73704fcdc08d53fef495582f", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["print_metrics(model_7, X, y)"], "metadata": {"_uuid": "53c04f10608cc801a145d9f02450fc367c4f8c8e", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["We see that our recall score has dropped from 0.97 to **0.91**, which confirms our suspicion that our earlier score of 0.97 was due to overfitting! \ud83d\ude22\ud83d\ude22"], "metadata": {"_uuid": "64debdeb505e2d860847a766ed78f4f22b7cea16"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["<a id='iteration_8'></a>\n", "## Iteration 8: Random Forest (with undersampling, and 40% train_test_split ratio, and optimization with GridSearchCV)"], "metadata": {"_uuid": "9f045f410e904592c61e79c3608689bd84379557"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["from sklearn.ensemble import RandomForestClassifier"], "metadata": {"_uuid": "e7e261f145c5205b06f3dfe659693922c6ada43c", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["random_forest_classifier_model = RandomForestClassifier(random_state=0)"], "metadata": {"_uuid": "c620b69cca569147ccc64978a906f280be6678f9", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["To know which params we can tune, you can use the `.get_params` property. As for what values to put in, this will require some reading and general googling :-)\n", "\n", "Generally, random forests are tuned by tweaking the following hyperparameters:\n", "- max_features\n", "- n_estimators\n", "- min_samples_leaf\n", "- class_weight"], "metadata": {"_uuid": "e2f4a4090bd183a8718d5bb02dce8d891c7976ed"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["random_forest_classifier_model.get_params"], "metadata": {"_uuid": "884e9328f74810433389e323e66e44a9812ed64e", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["random_forest_classifier_model = RandomForestClassifier(random_state=0)\n", "\n", "param_grid = {'max_features': [None, 'auto', 'sqrt', 'log2'],\n", "              'n_estimators': [1, 2, 4, 8, 10, 20, 30, 50],\n", "              'min_samples_leaf': [1,5,10,50],\n", "              'class_weight': [{\n", "                  0: 1, \n", "                  1: 1\n", "              },\n", "              {\n", "                  0: 1, \n", "                  1: 1.5\n", "              },\n", "              {\n", "                  0: 1, \n", "                  1: 2\n", "              },\n", "              {\n", "                  0: 1, \n", "                  1: 2.5\n", "              }\n", "              ]}\n", "\n", "model_8 = GridSearchCV(estimator=random_forest_classifier_model, \n", "                       param_grid=param_grid, cv=5)\n", "model_8.fit(X_train_undersampled_40_percent_split, y_train_undersampled_40_percent_split)\n", "\n", "print(\"Best estimator:\", model_8.best_estimator_)\n", "print(\"Best score:\", model_8.best_score_)"], "metadata": {"_uuid": "2bccf7f23efd19c2d9d2e7bfe814544819f1615d", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["print_metrics(model_8, X, y)"], "metadata": {"_uuid": "60dfdd6ff0d5760d904095f04916c3c2225a68cf", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["<a id='iteration_9'></a>\n", "## Iteration 9: Random Forest (with undersampling, and 40% train_test_split ratio, and optimization with RandomizedSearchCV)"], "metadata": {"_uuid": "313d5bdb2f314ed4bdde0720de4e1541a3872e61"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["from sklearn.model_selection import RandomizedSearchCV\n", "from sklearn.ensemble import RandomForestClassifier\n", "from scipy.stats import randint as sp_randint"], "metadata": {"_uuid": "567c2d16297e98c3892a80da5d77f999754a32b8", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["rfc_model = RandomForestClassifier(random_state=0)\n", "param_dist = {\"max_depth\": [3, None],\n", "              \"max_features\": list(range(1, 12)),\n", "              \"min_samples_split\": list(range(2, 12)),\n", "              \"min_samples_leaf\": list(range(1, 12)),\n", "              \"bootstrap\": [True, False],\n", "              \"criterion\": [\"gini\", \"entropy\"]}\n", "\n", "model_9 = RandomizedSearchCV(rfc_model, \n", "                             n_iter=30, \n", "                             param_distributions=param_dist, \n", "                             scoring='recall', \n", "                             cv=5,\n", "                             n_jobs=-1)\n", "\n", "model_9.fit(X_train_undersampled_40_percent_split, y_train_undersampled_40_percent_split)"], "metadata": {"_uuid": "d0c475703fbb7cb04d78250bbf4e853e36393661", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["print_metrics(model_9, X, y)"], "metadata": {"_uuid": "dd83d97c5c2956345fdb96d12353c72e5e22d10c", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["<a id='iteration_10'></a>\n", "## Iteration_10: Random Forest (without undersampling, with a 25% train_test_split ratio and optimized with RandomizedSearchCV)"], "metadata": {"_uuid": "1806aa4fde8fe942d536d4b886f2a3decdd731ca"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"source": ["rfc_model = RandomForestClassifier(random_state=0)\n", "param_dist = {\"max_depth\": [3, None],\n", "              \"max_features\": list(range(1, 12)),\n", "              \"min_samples_split\": list(range(2, 12)),\n", "              \"min_samples_leaf\": list(range(1, 12)),\n", "              \"bootstrap\": [True, False],\n", "              \"criterion\": [\"gini\", \"entropy\"]}\n", "\n", "model_10 = RandomizedSearchCV(rfc_model, \n", "                             n_iter=30, \n", "                             param_distributions=param_dist, \n", "                             scoring='recall', \n", "                             cv=5,\n", "                             n_jobs=-1)\n", "\n", "model_10.fit(X_train, y_train)"], "metadata": {"_uuid": "578c40c8bac2f04ac67d9ab0b6e3ee2fcd713746", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["print_metrics(model_10, X, y)"], "metadata": {"_uuid": "677a821895d74a4ebce5a888fe7f2d6a2c6a5ada", "collapsed": false}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["### Conclusion:\n", "1. Wahoo! model_6 gave us a 0.95 recall rate without any optimization at all! In other words, our model can **identify fraud with up to 95% accuracy**, even when only given 60% of the data as training data. We achieved this by using the following techniques:\n", "  - Resampling with `imblearn.under_sampling.RandomUnderSampler` to get a balanced training dataset with an equal number of fraud (492 cases) and non-fraud (also 492 cases).\n", "  - Randomized search cross validation\n", "  \n", "2. LogisticRegression models are a great starting point for building classification models\n", "3. RandomForestClassifier models performs better than LogisticRegression out of the box, even without any tuning/optimisation\n", "4. Undersampling is a useful technique for training models with highly skewed data\n", "5. GridSearchCV and RandomizedSearchCV allow us search the hyperparameter space to find the most optimal hyperparameters"], "metadata": {"_uuid": "4c93c5fcdd0705f0cd54cd90a581b8268a45397e"}, "outputs": [], "execution_count": null, "cell_type": "markdown"}], "nbformat": 4}