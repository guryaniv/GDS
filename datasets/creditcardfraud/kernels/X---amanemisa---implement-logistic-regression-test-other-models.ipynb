{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "59367c98-abb6-66f2-21ce-d7ee506d8baf"
      },
      "source": [
        "In this project, I'm going to do these things:\n",
        "\n",
        " 1. Implement Logistic Regression based on Machine Learning Course from\n",
        "    Stanford University\n",
        "\n",
        " 2.  Use Logistic Regression Classifier in Python scikit-learn library\n",
        "\n",
        " 3. Compare Logistic Regression with other classifiers: (1) Support Vector Classifier (2) Random\n",
        "    Forrest Classifier\n",
        "\n",
        " 4. Change the size of training set and compare\n",
        "\n",
        " 5. Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a03a61c0-15d7-9bd6-8fdb-8a66912d04d0"
      },
      "source": [
        "First, let's read in data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "96dec583-e1c1-ba74-0075-88a0311ec77f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "19de39ad-9c27-5dc8-765f-3b3084b98d72"
      },
      "outputs": [],
      "source": [
        "creditcard = pd.read_csv('../input/creditcard.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "88f8c34f-3ec1-d990-ed23-3249459b7fde"
      },
      "outputs": [],
      "source": [
        "X = creditcard[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
        "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
        "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']]\n",
        "y = creditcard['Class']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "401bf191-c09a-d29c-e717-0b81d6c465f3"
      },
      "source": [
        "#1. Implement Logistic Regression\n",
        "\n",
        "Next, let's do logistic regression. Of course we can explore and scale features, or introduce new features of higher degrees, but I'am just gonna implement a basic logistic regression here.\n",
        "\n",
        "reference: [Link] https://www.coursera.org/learn/machine-learning\n",
        "\n",
        " [Link]http://aimotion.blogspot.com/2011/11/machine-learning-with-python-logistic.html\n",
        "\n",
        "\n",
        "Cost function is defined as [Link] http://4.bp.blogspot.com/-0vWgkEmE-u4/TraaI_rd-bI/AAAAAAAAAow/Ya5rp0rQS48/s1600/Screen+shot+2011-11-06+at+11.30.37+AM.png\n",
        "\n",
        "Gradient is defined as [Link] http://2.bp.blogspot.com/-jpwtW1KQIoE/TraaRvy_8MI/AAAAAAAAAo4/9qnO3SyiqaA/s1600/Screen+shot+2011-11-06+at+11.30.41+AM.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e27b69a2-f4dd-5aa3-8e68-b0b75e99e951"
      },
      "outputs": [],
      "source": [
        "# we need train_test_split to split data into training set and test set\n",
        "# we need metrics to measure accuracy after preditions\n",
        "# we need optimize from scipy to optimize cost function\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn import metrics\n",
        "import scipy.optimize as op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aaaab757-7c45-9792-3acf-da21a239e6ed"
      },
      "outputs": [],
      "source": [
        "# in order to save time, I keep the size of training set to be less than 100000\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.65, random_state=0)\n",
        "print(Xtrain.shape);\n",
        "print(Xtest.shape);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b53b45a8-803a-e8c7-f337-2c2f513375d9"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    return 1/(1 + np.exp(-z));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "27f84838-33b9-7a60-cd42-434299511be8"
      },
      "outputs": [],
      "source": [
        "# define cost function. theta is an array containing coefficents for all feathers.\n",
        "def costFunctionReg(theta, X, y):\n",
        "    m = len(y)\n",
        "    n = len(theta)\n",
        "    h = sigmoid(X.dot(theta))\n",
        "    J = (-y.T.dot(np.log(h))-(1-y.T).dot(np.log(1-h)))/m\n",
        "    return J"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a62ba0b8-b6b9-4710-28b5-049c75abfdbf"
      },
      "outputs": [],
      "source": [
        "# define gradient\n",
        "def Gradient(theta, X, y):\n",
        "    m = len(y)\n",
        "    n = len(theta)\n",
        "    h = sigmoid(X.dot(theta))\n",
        "    grad = (1/m)*(X.T).dot(h-y);\n",
        "    return grad.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "576d8651-e085-b89c-3e61-7dfa273b7d87"
      },
      "outputs": [],
      "source": [
        "# define predict function\n",
        "def predict(theta, X):\n",
        "    m, n = X.shape\n",
        "    p = np.zeros(m)\n",
        "    h = sigmoid(X.dot(theta))\n",
        "    for i in range(0, m):\n",
        "        if h[i] > 0.5:\n",
        "            p[i] = 1\n",
        "        else:\n",
        "            p[i] = 0\n",
        "    return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "067a64c5-57a2-82ae-8cae-1825c8326ea8"
      },
      "outputs": [],
      "source": [
        "# convert data to arrays\n",
        "Xtrain = np.array(Xtrain)\n",
        "ytrain = np.array(ytrain)\n",
        "Xtest = np.array(Xtest)\n",
        "ytest = np.array(ytest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bea41ec8-99ed-b01a-15e7-943203a96502"
      },
      "outputs": [],
      "source": [
        "# add a column of ones to Xtrain\n",
        "Xtrain_ones = np.append(np.ones((Xtrain.shape[0],1)), Xtrain, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ee282783-3436-6aa5-d5fa-2e1abda12822"
      },
      "outputs": [],
      "source": [
        "# use fmin_bfgs to minimize cost function and fine theta, about 2 mins\n",
        "initial_theta = np.zeros(Xtrain_ones.shape[1])\n",
        "theta_optimal = op.fmin_bfgs(f= costFunctionReg, x0 = initial_theta, args = (Xtrain_ones,ytrain), fprime = Gradient, maxiter = 400);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "547e9fda-6846-4074-cebf-a5517f3a21ac"
      },
      "outputs": [],
      "source": [
        "# make predition and check accuracy\n",
        "Xtest_ones = np.append(np.ones((Xtest.shape[0],1)), Xtest,axis = 1);\n",
        "ypred = predict(theta_optimal,Xtest_ones);\n",
        "print(metrics.confusion_matrix(ytest,ypred));\n",
        "print(metrics.classification_report(ytest,ypred));\n",
        "print('Accuracy : %f' %(metrics.accuracy_score(ytest,ypred)));\n",
        "print('Area under the curve : %f' %(metrics.roc_auc_score(ytest,ypred)));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ae403bde-80bd-049d-0985-2c09fee723a5"
      },
      "source": [
        "Well, it works, but not perfect. Let's see what python library can do next. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "987cade9-a37a-26a0-cd13-f1fc9aaea296"
      },
      "source": [
        "#2. Use Logistic Regression Classifier in Python scikit-learn library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "12b9908d-38cc-89dc-f2ed-dda18ad49188"
      },
      "outputs": [],
      "source": [
        "# call the classifier and train the data\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf_logistic = LogisticRegression(penalty='l2');\n",
        "clf_logistic.fit(Xtrain, ytrain);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "56d41b68-0ad7-c4c4-3c5d-f5d28c32e0a9"
      },
      "outputs": [],
      "source": [
        "# make predition and check accuracy\n",
        "ypred = clf_logistic.predict(Xtest);\n",
        "print(metrics.confusion_matrix(ytest,ypred));\n",
        "print(metrics.classification_report(ytest,ypred));\n",
        "print('Accuracy : %f' %(metrics.accuracy_score(ytest,ypred)));\n",
        "print('Area under the curve : %f' %(metrics.roc_auc_score(ytest,ypred)));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ffd41582-7adc-f17b-bf35-a7989fbcf4d2"
      },
      "source": [
        "Yes, it's better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "05f6ef1d-e1d7-89e7-9e3a-fe5b0b312271"
      },
      "source": [
        "#3. Check other classifiers and compare\n",
        "I will check Support Vector Classifier and Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "965a9546-4e31-c8f3-7cb9-38142cc8a2a8"
      },
      "source": [
        "##(1) support vector classifier. \n",
        "\n",
        "We can change kernels for SVC. Here I've tested 'linear' and 'sigmoid'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "972c97b9-2bda-9d3d-5f49-2af078ae4abe"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cbc5c249-2f00-3720-cdf8-2b0286100edf"
      },
      "source": [
        "Just want to put a reminder here: the following one is very slow!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "daf54dc2-1e31-75a4-8e1d-47bd0bebf4b8"
      },
      "outputs": [],
      "source": [
        "# SVC with 'linar' kernel. It took about 10 mins.\n",
        "clf_linear = SVC(kernel='linear')\n",
        "clf_linear.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f3b615ab-43ca-f9dd-143d-20797b89ccf2"
      },
      "outputs": [],
      "source": [
        "# make prediction and check accuracy\n",
        "ypred = clf_linear.predict(Xtest)\n",
        "print(metrics.confusion_matrix(ytest,ypred))\n",
        "print(metrics.classification_report(ytest,ypred))\n",
        "print('Accuracy : %f' %(metrics.accuracy_score(ytest,ypred)))\n",
        "print('Area under the curve : %f' %(metrics.roc_auc_score(ytest,ypred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6b4a9baa-b6f9-e6cc-724e-a75b1583cd1a"
      },
      "outputs": [],
      "source": [
        "# SVC with 'sigmoid' kernel\n",
        "clf_sigmoid = SVC(kernel='sigmoid')\n",
        "clf_sigmoid.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "231c8461-dcd9-093d-861e-085b6c88685e"
      },
      "outputs": [],
      "source": [
        "ypred = clf_sigmoid.predict(Xtest)\n",
        "print(metrics.confusion_matrix(ytest,ypred));\n",
        "print(metrics.classification_report(ytest,ypred));\n",
        "print('Accuracy : %f' %(metrics.accuracy_score(ytest,ypred)));\n",
        "print('Area under the curve : %f' %(metrics.roc_auc_score(ytest,ypred)));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f4744e33-24dd-0caf-babd-5a67f2da4f19"
      },
      "source": [
        "Mmm, SVC does not work very good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7c64c119-8d44-1a5a-bb46-f9d201965517"
      },
      "source": [
        "##(2) Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6237b80d-e381-b5b6-956d-681bfb12401c"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf_rf = RandomForestClassifier()\n",
        "clf_rf.fit(Xtrain,ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c6231127-c64a-66b8-c487-5843608d7030"
      },
      "outputs": [],
      "source": [
        "ypred = clf_rf.predict(Xtest);\n",
        "print(metrics.confusion_matrix(ytest,ypred));\n",
        "print(metrics.classification_report(ytest,ypred));\n",
        "print('Accuracy : %f' %(metrics.accuracy_score(ytest,ypred)));\n",
        "print('Area under the curve : %f' %(metrics.roc_auc_score(ytest,ypred)));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4304b5d0-283b-7a57-6ea8-9751be4413fc"
      },
      "source": [
        "Random Forrest is pretty good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d528efd5-4469-6cc8-430c-27d33f0f15cb"
      },
      "source": [
        "##4. Change the size of training set and compare\n",
        "\n",
        "I am done with my codes and testing, and I am just thinking: what if the training set is even larger. The result should be better, right? Let's see."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b23b859e-dd59-edf7-bfba-5996a12c7d6a"
      },
      "outputs": [],
      "source": [
        "Xtrain2, Xtest2, ytrain2, ytest2 = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "print(Xtrain2.shape);\n",
        "print(Xtest2.shape);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f6fed230-0773-c0ba-3e83-33986c0f4157"
      },
      "source": [
        "Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "15d87d96-778b-f5c5-2487-dd5530cbfd40"
      },
      "outputs": [],
      "source": [
        "# Use logistic regression again\n",
        "clf_logistic2 = LogisticRegression(penalty='l2');\n",
        "clf_logistic2.fit(Xtrain2, ytrain2);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4dff615f-bfde-faaa-19ad-56f33aa302f7"
      },
      "outputs": [],
      "source": [
        "# make predition and check accuracy\n",
        "ypred2 = clf_logistic2.predict(Xtest2);\n",
        "print(metrics.confusion_matrix(ytest2,ypred2));\n",
        "print(metrics.classification_report(ytest2,ypred2));\n",
        "print('Accuracy : %f' %(metrics.accuracy_score(ytest2,ypred2)));\n",
        "print('Area under the curve : %f' %(metrics.roc_auc_score(ytest2,ypred2)));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f72a9e8d-4864-1b55-7b33-9fe68d9fa5c1"
      },
      "source": [
        "Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6cf6f24e-4040-2bae-1523-fbf6569dfca2"
      },
      "outputs": [],
      "source": [
        "# Use random forest classifier again\n",
        "clf_rf2 = RandomForestClassifier()\n",
        "clf_rf2.fit(Xtrain2,ytrain2);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8a57ea43-e761-a429-71c5-f4a1d508a94e"
      },
      "outputs": [],
      "source": [
        "ypred2 = clf_rf.predict(Xtest2);\n",
        "print(metrics.confusion_matrix(ytest2,ypred2));\n",
        "print(metrics.classification_report(ytest2,ypred2));\n",
        "print('Accuracy : %f' %(metrics.accuracy_score(ytest2,ypred2)));\n",
        "print('Area under the curve : %f' %(metrics.roc_auc_score(ytest2,ypred2)));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "042b834d-7ed5-0a22-9941-ebeaef264d48"
      },
      "source": [
        "## 5 Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "11381772-f267-1a6e-e749-fb25eec5b32c"
      },
      "source": [
        "1. The basic logistic regression codes I've implemented need to be improved for this problem.\n",
        "\n",
        "2. The Logistic Regression and Random Forrest Classifier in scikit-learn library are pretty good.  The areas under the ROC curve are 0.86 and 0.87 respectively.\n",
        "\n",
        "3. The Support Vector Classifiers with Kernel 'linear' and 'sigmoid' are not good. The areas under the ROC curve are 0.68 and 0.5. 'Linear' SVC is quite slow and 'Sigmoid' SVC does not recgnize any '1' in the test set at all. This also tells us the measure 'Accuracy' is not a good one for this problem.\n",
        "\n",
        "4. After I increase the size of training set (from 35% to 80% of all data), the area ROC becomes 0.78 for Logistic Regression and still 0.87 for Random Forrest Classifier. This fact is interesting for me."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}