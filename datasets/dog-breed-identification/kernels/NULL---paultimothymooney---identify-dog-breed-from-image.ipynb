{"nbformat": 4, "nbformat_minor": 1, "cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "ff23081f-fa0c-4c32-9691-22ebbbfb236f", "_uuid": "dd0fca94a18bd73c1b68f5875efa765973ffa9e6"}, "source": ["-- WORK IN PROGRESS --"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "d133385d-2b49-4920-8aa5-75716fe83978", "_uuid": "783b40e31d2aa7a546b8f53b0ec27a141976fbcf"}, "source": ["**Dog Breed Identification**\n", "\n", "Predict the breed of a dog given an input image of a dog"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "b84f37e4-2880-482e-95bc-81786622ee9d", "_uuid": "de8fa0ff676b756f2c7967f7a0b5fe22a0ecf82d"}, "source": ["*Step 1: Import Modules*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "72eec502-3e90-4ed9-8400-28588291c103", "_uuid": "bcedecab52264885cd34b2fc8eea7810352835ce", "_kg_hide-input": true}, "source": ["from tqdm import tqdm\n", "import seaborn as sns\n", "from keras.preprocessing import image\n", "import cv2\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import os\n", "import itertools\n", "from PIL import Image\n", "import sklearn as sklearn\n", "from sklearn.metrics import confusion_matrix\n", "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n", "from sklearn import model_selection\n", "from sklearn.model_selection import train_test_split, learning_curve\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.svm import SVC, LinearSVC\n", "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n", "from sklearn.neural_network import MLPClassifier as MLPC\n", "from sklearn import model_selection\n", "import tensorflow as tf\n", "import keras\n", "from keras import backend as K\n", "from keras.models import Sequential\n", "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n", "from keras import initializers, layers, models\n", "from keras.utils import to_categorical\n", "from keras.preprocessing.image import ImageDataGenerator\n", "from keras import callbacks\n", "from keras.utils.vis_utils import plot_model\n", "from mpl_toolkits.axes_grid1 import ImageGrid\n", "from os import listdir, makedirs\n", "from os.path import join, exists, expanduser\n", "from sklearn.metrics import log_loss, accuracy_score\n", "from keras.preprocessing import image\n", "from keras.applications.vgg16 import VGG16\n", "from keras.applications.resnet50 import ResNet50\n", "from keras.applications import xception\n", "from keras.applications import inception_v3\n", "from keras.applications.vgg16 import preprocess_input, decode_predictions\n", "import datetime as dt\n", "start = dt.datetime.now()\n", "%matplotlib inline"], "execution_count": 1}, {"cell_type": "markdown", "metadata": {"_cell_guid": "e7a79ad2-04e1-4ace-8e6c-e203b3b9cbcf", "_uuid": "30026ee60f85cfc58220ca6ffe64e6d04df0f61f"}, "source": ["*Step 2: Describe Data*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "f97808ce-d890-4893-9f20-a2daa6e6c96c", "_uuid": "fd64db336a22628a30cf5c3d90912686d0fd4305"}, "source": ["df_train = pd.read_csv('../input/dog-breed-identification/labels.csv')\n", "df_test = pd.read_csv('../input/dog-breed-identification/sample_submission.csv')\n", "df_train.head(10)"], "execution_count": 2}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "8522beba-b393-4905-8d58-681d5cb7bfa2", "_uuid": "a3491d2e2f595067cc35031c66f8c572ac97308e"}, "source": ["yy = pd.value_counts(df_train['breed'])\n", "\n", "fig, ax = plt.subplots()\n", "fig.set_size_inches(15, 9)\n", "sns.set_style(\"whitegrid\")\n", "\n", "ax = sns.barplot(x = yy.index, y = yy, data = df_train)\n", "ax.set_xticklabels(ax.get_xticklabels(), rotation = 90, fontsize = 8)\n", "ax.set(xlabel='Dog Breed', ylabel='Count')\n", "ax.set_title('Distribution of Dog breeds')"], "execution_count": 3}, {"cell_type": "markdown", "metadata": {"_cell_guid": "77dc3c68-5a24-4259-bf90-378eeb5739bd", "_uuid": "e42085d728e91b8172835f5c2f7e497944e2186e"}, "source": ["*Step 3: Reduce Size of Dataset if Needed*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "9f4fa08f-4aeb-4716-a9b9-7ca8596d4a9f", "_uuid": "96435a7f353bfc8619f6b9088abdbafe5db14d66"}, "source": ["labels = df_train\n", "top_breeds = sorted(list(labels['breed'].value_counts().head(16).index))\n", "labels = labels[labels['breed'].isin(top_breeds)]\n", "labels.breed.value_counts().plot(kind='bar')\n", "#df_train = labels ### remove this line to go back to 120 different breeds instead of 16"], "execution_count": 4}, {"cell_type": "markdown", "metadata": {"_cell_guid": "a9d83511-2b48-45a6-a75e-1fbfdd5438ac", "_uuid": "4f1f02628c65d66879272d85f0e4896d2e76d250"}, "source": ["*Step 4: Load the Corresponding Images*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "b18eff44-927e-49c8-8c33-a53298fde213", "_uuid": "a57ebc297b74441c84c153d6ef4d4a7b8183496d"}, "source": ["targets_series = pd.Series(df_train['breed'])\n", "one_hot = pd.get_dummies(targets_series, sparse = True)\n", "one_hot_labels = np.asarray(one_hot)\n", "\n", "im_size = 128\n", "x_train1 = []\n", "y_train1 = []\n", "x_test1 = []\n", "i = 0 \n", "\n", "for f, breed in tqdm(df_train.values):\n", "    img = cv2.imread('../input/dog-breed-identification/train/{}.jpg'.format(f))\n", "    label = one_hot_labels[i]\n", "    x_train1.append(cv2.resize(img, (im_size, im_size)))\n", "    y_train1.append(label)\n", "    i += 1\n", "\n", "for f in tqdm(df_test['id'].values):\n", "    img = cv2.imread('../input/dog-breed-identification/test/{}.jpg'.format(f))\n", "    x_test1.append(cv2.resize(img, (im_size, im_size)))\n", "\n", "y_train_raw = np.array(y_train1, np.uint8)\n", "x_train_raw = np.array(x_train1, np.float32) / 255.\n", "x_testContest  = np.array(x_test1, np.float32) / 255.\n", "\n", "num_class = y_train_raw.shape[1]\n", "\n", "print(x_train_raw.shape)\n", "print(y_train_raw.shape)\n", "# print(x_testContest.shape)    "], "execution_count": 5}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "3477d557-3087-43c0-ba27-625dd6e43310", "collapsed": true, "_uuid": "2ffe55b7562c2cd073d47bc24143220155a2ab17"}, "source": ["x_train,x_test,y_train,y_test = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=1)"], "execution_count": 6}, {"cell_type": "markdown", "metadata": {"_cell_guid": "7855bab5-9859-4012-89f6-84cd4d29d5ce", "_uuid": "45ee25e15d9a718ea443b6f1e6a357f7c0e1fb48"}, "source": ["*Step 5: Display Images*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "6700c7c5-4ffe-49c1-8caf-0fb3a88640a8", "_uuid": "3d45c329a60c58772c0d7171de8dbd73f530da35"}, "source": ["fig, ax = plt.subplots()\n", "img = image.load_img('../input/dog-breed-identification/train/fff43b07992508bc822f33d8ffd902ae.jpg')\n", "img = image.img_to_array(img)\n", "ax.imshow(img / 255.) \n", "ax.axis('off')\n", "plt.show()"], "execution_count": 7}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "95835774-c22b-4bd0-8a07-872bf96b6e28", "_uuid": "5285f40a6a50e3cd8bbd7ef0295f0bfd36ea39aa"}, "source": ["df_train2 = pd.read_csv('../input/dog-breed-identification/labels.csv')\n", "top_breeds = df_train2['breed']\n", "\n", "plt.subplot(1, 2, 1)\n", "plt.title(top_breeds[np.where(y_train[5]==1)[0][0]])\n", "plt.axis('off')\n", "plt.imshow(x_train[5])\n", "plt.subplot(1, 2, 2)\n", "plt.title(top_breeds[np.where(y_train[7]==1)[0][0]])\n", "plt.axis('off')\n", "plt.imshow(x_train[7])\n", "plt.show()"], "execution_count": 8}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "79009ac9-839a-4116-93fd-f8ca452420b2", "_uuid": "2bd3d734b60ef2610d2734856dc2d2b134a1874f"}, "source": ["import random\n", "df = df_train\n", "n = len(df)\n", "breed = set(df['breed'])\n", "n_class = len(breed)\n", "class_to_num = dict(zip(breed, range(n_class)))\n", "num_to_class = dict(zip(range(n_class), breed))\n", "%config InlineBackend.figure_format = 'retina'\n", "n=100\n", "plt.figure(figsize=(12, 6))\n", "for i in range(8):\n", "    random_index = random.randint(0, n-1)\n", "    plt.subplot(2, 4, i+1)\n", "    plt.imshow(x_train[random_index][:,:,::-1])\n", "    plt.title(num_to_class[y_train[random_index].argmax()])\n", "    plt.axis('off')\n"], "execution_count": 9}, {"cell_type": "markdown", "metadata": {"_cell_guid": "7a6d0700-821b-4de2-b477-c05a3cfea915", "_uuid": "498a2572c9d27caffb1a7436ec7cf4155e4bca12"}, "source": ["*Step 6: Define Helper Functions*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "e7f62883-d6c6-49a5-b945-6c9838c24a73", "collapsed": true, "_uuid": "6d03cb8d2849c307100253fbcb469d8c3de6c28f"}, "source": ["# Plot confusion matrix\n", "def plot_confusion_matrix(cm, classes,\n", "                          normalize=False,\n", "                          title='Confusion matrix',\n", "                          cmap=plt.cm.Blues):\n", "    \"\"\"\n", "    This function prints and plots the confusion matrix.\n", "    Normalization can be applied by setting `normalize=True`.\n", "    \"\"\"\n", "    plt.figure(figsize = (30,30))\n", "    #plt.figure(figsize = (15,15))\n", "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n", "    plt.title(title)\n", "    plt.colorbar()\n", "    tick_marks = np.arange(len(classes))\n", "    plt.xticks(tick_marks, classes, rotation=90)\n", "    plt.yticks(tick_marks, classes)\n", "    if normalize:\n", "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n", "\n", "    thresh = cm.max() / 2.\n", "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n", "        plt.text(j, i, cm[i, j],\n", "                 horizontalalignment=\"center\",\n", "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n", "    plt.tight_layout()\n", "    plt.ylabel('True label')\n", "    plt.xlabel('Predicted label')\n", "\n", "# Special callback to see learning curves\n", "class MetricsCheckpoint(Callback):\n", "    \"\"\"Callback that saves metrics after each epoch\"\"\"\n", "    def __init__(self, savepath):\n", "        super(MetricsCheckpoint, self).__init__()\n", "        self.savepath = savepath\n", "        self.history = {}\n", "    def on_epoch_end(self, epoch, logs=None):\n", "        for k, v in logs.items():\n", "            self.history.setdefault(k, []).append(v)\n", "        np.save(self.savepath, self.history)\n", "\n", "def plotKerasLearningCurve():\n", "    plt.figure(figsize=(10,5))\n", "    metrics = np.load('logs.npy')[()]\n", "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n", "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n", "        l = np.array(metrics[k])\n", "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n", "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n", "        y = l[x]\n", "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n", "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n", "    plt.legend(loc=4)\n", "    plt.axis([0, None, None, None]);\n", "    plt.grid()\n", "    plt.xlabel('Number of epochs')\n", "    \n", "map_characters = {0:'none',1:'affenpinscher',2:'afghan_hound',3:'african_hunting_dog',\n", "4:'airedale',5:'american_staffordshire_terrier',6:'appenzeller',7:'australian_terrier',\n", "8:'basenji',9:'basset',10:'beagle',11:'bedlington_terrier',12:'bernese_mountain_dog',\n", "13:'black-and-tan_coonhound',14:'blenheim_spaniel',15:'bloodhound',16:'bluetick',\n", "17:'border_collie',18:'border_terrier',19:'borzoi',20:'boston_bull',21:'bouvier_des_flandres',\n", "22:'boxer',23:'brabancon_griffon',24:'briard',25:'brittany_spaniel',26:'bull_mastiff',\n", "27:'cairn',28:'cardigan',29:'chesapeake_bay_retriever',30:'chihuahua',31:'chow',\n", "32:'clumber',33:'cocker_spaniel',34:'collie',35:'curly-coated_retriever',36:'dandie_dinmont',\n", "37:'dhole',38:'dingo',39:'doberman',40:'english_foxhound',41:'english_setter',\n", "42:'english_springer',43:'entlebucher',44:'eskimo_dog',45:'flat-coated_retriever',\n", "46:'french_bulldog',47:'german_shepherd',48:'german_short-haired_pointer',49:'giant_schnauzer',\n", "50:'golden_retriever',51:'gordon_setter',52:'great_dane',53:'great_pyrenees',\n", "54:'greater_swiss_mountain_dog',55:'groenendael',56:'ibizan_hound',57:'irish_setter',\n", "58:'irish_terrier',59:'irish_water_spaniel',60:'irish_wolfhound',61:'italian_greyhound',\n", "62:'japanese_spaniel',63:'keeshond',64:'kelpie',65:'kerry_blue_terrier',66:'komondor',\n", "67:'kuvasz',68:'labrador_retriever',69:'lakeland_terrier',70:'leonberg',71:'lhasa',72:'malamute',\n", "73:'malinois',74:'maltese_dog',75:'mexican_hairless',76:'miniature_pinscher',77:'miniature_poodle',\n", "78:'miniature_schnauzer',79:'newfoundland',80:'norfolk_terrier',81:'norwegian_elkhound',\n", "82:'norwich_terrier',83:'old_english_sheepdog',84:'otterhound',85:'papillon',86:'pekinese',\n", "87:'pembroke',88:'pomeranian',89:'pug',90:'redbone',91:'rhodesian_ridgeback',92:'rottweiler',\n", "93:'saint_bernard',94:'saluki',95:'samoyed',96:'schipperke',97:'scotch_terrier',98:'scottish_deerhound',\n", "99:'sealyham_terrier',100:'shetland_sheepdog',101:'shih-tzu',102:'siberian_husky',103:'silky_terrier',\n", "104:'soft-coated_wheaten_terrier',105:'staffordshire_bullterrier',106:'standard_poodle',\n", "107:'standard_schnauzer',108:'sussex_spaniel',109:'tibetan_mastiff',110:'tibetan_terrier',111:'toy_poodle',\n", "112:'toy_terrier',113:'vizsla',114:'walker_hound',115:'weimaraner',116:'welsh_springer_spaniel',\n", "117:'west_highland_white_terrier',118:'whippet',119:'wire-haired_fox_terrier',120:'yorkshire_terrier'}"], "execution_count": 10}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "50edba1f-da6f-4e04-b644-a4489a0edf07", "collapsed": true, "_uuid": "cbbe242bcd804d361301e8f5b3a0a6fd412bcd07"}, "source": ["#map_characters = {0:'afghan_hound', 1:'airedale', 2:'basenji', 3:'beagle', 4:'bernese_mountain_dog', 5:'cairn', 6:'entlebucher', 7:'great_pyrenees', 8:'japanese_spaniel', 9:'leonberg', 10:'maltese_dog', 11:'pomeranian', 12:'samoyed', 13:'scottish_deerhound', 14:'shih-tzu', 15:'tibetan_terrier'}"], "execution_count": 11}, {"cell_type": "markdown", "metadata": {"_cell_guid": "72884aaf-5c7d-414b-aa03-6b5751dfff88", "_uuid": "a0481bf713d7786a44b7ae3102058c6046b6fa99"}, "source": ["*Step 7: Evaluate Convolutional Network Approach*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "0b820f95-1d57-4024-93da-5dbb943a25c7", "_uuid": "ddbb974ef7f1c49865b009c600e97c2938319f9f"}, "source": ["num_classes = 120\n", "#num_classes = 16\n", "def runKerasCNNAugment(a,b,c,d):\n", "    #global model\n", "    batch_size = 128\n", "    epochs = 10\n", "    im_size = 128\n", "    #img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n", "    #input_shape = (img_rows, img_cols, 3)\n", "    input_shape = (im_size,im_size,3)\n", "    model = Sequential()\n", "    model.add(Conv2D(32, kernel_size=(3, 3),\n", "                     activation='relu',\n", "                     input_shape=input_shape))\n", "    model.add(Conv2D(64, (3, 3), activation='relu'))\n", "    model.add(MaxPooling2D(pool_size=(2, 2)))\n", "    model.add(Dropout(0.25))\n", "    model.add(Flatten())\n", "    model.add(Dense(128, activation='relu'))\n", "    model.add(Dropout(0.5))\n", "    model.add(Dense(num_classes, activation='softmax'))\n", "    model.compile(loss=keras.losses.categorical_crossentropy,\n", "                  optimizer=keras.optimizers.RMSprop(lr=0.0001),\n", "                  metrics=['accuracy'])\n", "    datagen = ImageDataGenerator(\n", "        featurewise_center=False,  # set input mean to 0 over the dataset\n", "        samplewise_center=False,  # set each sample mean to 0\n", "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n", "        samplewise_std_normalization=False,  # divide each input by its std\n", "        zca_whitening=False,  # apply ZCA whitening\n", "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n", "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n", "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n", "        horizontal_flip=True,  # randomly flip images\n", "        vertical_flip=False)  # randomly flip images\n", "    model.fit_generator(datagen.flow(a,b, batch_size=32),\n", "                        steps_per_epoch=len(a) / 32, epochs=epochs, validation_data = [c, d],callbacks = [MetricsCheckpoint('logs')])\n", "    score = model.evaluate(c,d, verbose=0)\n", "    print('\\nKeras CNN #1C - accuracy:', score[1],'\\n')\n", "    y_pred = model.predict(c)\n", "    #map_characters = {0: 'No Ship', 1: 'Ship'}\n", "    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')    \n", "    score = model.evaluate(c,d, verbose=0)\n", "    Y_pred_classes = np.argmax(y_pred,axis = 1) \n", "    Y_true = np.argmax(d,axis = 1) \n", "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n", "    plotKerasLearningCurve()\n", "    plt.show()\n", "    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values())) \n", "    plt.show()\n", "    return model\n", "runKerasCNNAugment(x_train,y_train,x_test,y_test)"], "execution_count": 12}, {"cell_type": "markdown", "metadata": {"_cell_guid": "c19d40f6-5043-4415-9b3c-197383e893cb", "_uuid": "03b1784a6028b41068c4e7394a050898450a5111"}, "source": ["With this convolutional network model both the training accuracy and the validation accuracy steadily increase with time.  Given a sufficient number of epochs I suspect that the model would indeed be sufficiently accurate.  This is not possible given the time limitations on the Kaggle Kernel, however.  Instead I will use a transfer learning approach in order to save time."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "496e4590-a3fd-4772-ae50-cdc0e3b69bec", "_uuid": "8684f43d2e71bebd9ba7ff9a8b10f83ebee4afc2"}, "source": ["*Step 8: Evaluate Transfer Learning Approach*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "4bf4ff33-71ec-4d7e-887e-16eabc8fc2c5", "_uuid": "39ddff402911d2adb0f9cc9fd15a257f6d04868a"}, "source": ["from keras.applications.vgg16 import VGG16\n", "from keras.models import Model\n", "weight_path = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n", "epochs = 10\n", "num_class = 120\n", "#num_class = 16\n", "def vgg16network(a,b,c,d):\n", "    global model\n", "    base_model = VGG16(#weights='imagenet',\n", "        weights = weight_path, include_top=False, input_shape=(im_size, im_size, 3))\n", "    # Add a new top layer\n", "    x = base_model.output\n", "    x = Flatten()(x)\n", "    predictions = Dense(num_class, activation='softmax')(x)\n", "    # This is the model we will train\n", "    model = Model(inputs=base_model.input, outputs=predictions)\n", "    # First: train only the top layers (which were randomly initialized)\n", "    for layer in base_model.layers:\n", "        layer.trainable = False\n", "    model.compile(loss='categorical_crossentropy', \n", "                  optimizer=keras.optimizers.RMSprop(lr=0.0001), \n", "                  metrics=['accuracy'])\n", "    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n", "    model.summary()\n", "    model.fit(a,b, epochs=epochs, validation_data=(c,d), verbose=1,callbacks = [MetricsCheckpoint('logs')])\n", "    score = model.evaluate(c,d, verbose=0)\n", "    print('\\nKeras CNN #2 - accuracy:', score[1], '\\n')\n", "    y_pred = model.predict(c)\n", "    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='') \n", "    Y_pred_classes = np.argmax(y_pred,axis = 1) \n", "    Y_true = np.argmax(d,axis = 1) \n", "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n", "    plotKerasLearningCurve()\n", "    plt.show()\n", "    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values()))\n", "    plt.show()\n", "    return model\n", "vgg16network(x_train,y_train,x_test,y_test)"], "execution_count": 13}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ae18fc47-ce95-4f86-ba5f-d143d5deb84f", "_uuid": "f00ad465af7b0510f556c5dddd7febff50323d3c"}, "source": ["25% accuracy is much better than random chance given 120 different breeds of dogs.  I should be able to do better than that though, so I will need to try again later, perhaps by using a different pretrained model."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "c1c885e0-b678-4792-8fb1-5aea700ec95c", "_uuid": "1cee1f46fef301aa8abe5af2166f6effe3d58348"}, "source": ["*Step 9: Submit Predictions*"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "84c5c1ac-7388-4a29-a5b4-74dd401554fd", "collapsed": true, "_uuid": "452ed7bd33a5781c627a91d7b0485132ae9600d9"}, "source": ["# preds = model.predict(x_testContest, verbose=1)\n", "# sub = pd.DataFrame(preds)\n", "# # Set column names to those generated by the one-hot encoding earlier\n", "# col_names = one_hot.columns.values\n", "# sub.columns = col_names\n", "# # Insert the column id from the sample_submission at the start of the data frame\n", "# sub.insert(0, 'id', df_test['id'])\n", "# sub.head(5)\n", "\n", "# submission = sub\n", "# submission.to_csv('new_submission.csv', index=False)"], "execution_count": 14}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "e9f79fe2-133c-4f08-83f2-332a9c1266c8", "_uuid": "8da6585319c065df144951f2e740be6ddf6e8a69"}, "source": ["end = dt.datetime.now()\n", "print('Total time {} s.'.format((end - start).seconds))"], "execution_count": 15}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "f0eb34be-b2c2-4e18-bdb7-4a859ff2b22b", "collapsed": true, "_uuid": "7109a5a1ba40f2496f31e74066ffec062d03b720"}, "source": [], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "83332c35-33c6-4d60-bd13-0c707bf41562", "collapsed": true, "_uuid": "6656d07d2ec51adb0316e1450de21c9894fcb831"}, "source": [], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "ca40f011-76dc-4348-8bb0-7947e15e3676", "collapsed": true, "_uuid": "3a42788f16351f351d4f73c34088f97d7abcbf26"}, "source": [], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "517f41e8-d310-4614-9a75-8c8261313d60", "collapsed": true, "_uuid": "c57bf26e514690b956dc7cbfed95de3dec98c18a"}, "source": [], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "3ba2df48-8a5a-48b8-bd5f-f72e82b716bc", "collapsed": true, "_uuid": "a6b3ab7f0f4ada32a5a59fbecf45d3885dcf62ee"}, "source": [], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "3fee95f5-cf75-4199-a795-710801c323d7", "collapsed": true, "_uuid": "85e3aa529040ee477d6434c0e559ad7195554eec"}, "source": [], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "e9b1274b-b525-4c2b-bb7b-ac07edcbad45", "collapsed": true, "_uuid": "0f9b7d862af45364fcdfc853e20a1f13bd65bdd8"}, "source": [], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "c3e1a344-61f5-4584-a256-5d294601d70a", "collapsed": true, "_uuid": "dbe51a7869e364fc54a1361e2d8d8d394de9f32b"}, "source": [], "execution_count": null}], "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"nbconvert_exporter": "python", "version": "3.6.4", "pygments_lexer": "ipython3", "name": "python", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py"}}}