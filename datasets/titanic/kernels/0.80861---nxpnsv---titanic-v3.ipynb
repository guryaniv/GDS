{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn import preprocessing, metrics \nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dda5df69a89224bbedc429016fb18eb370ee380c"},"cell_type":"markdown","source":"# Data wrangling and feature engineering"},{"metadata":{"trusted":true,"_uuid":"73b643e26a4255de2f20d5c486da3fab1853b105"},"cell_type":"code","source":"# Create full data set for convenient transformation\n# (drop Survived and PassengerId to reduce possible bias)\nfull = pd.concat([train.drop('Survived', axis=1), test], axis=0)\nfull.drop('PassengerId', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff5acf685e4638f68b32fcba4522cbd91410b8da"},"cell_type":"code","source":"# There are null entries!\nfull.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a622c10c7e4cabbec619ffbca2e81637a4fe601"},"cell_type":"code","source":"# Impute Embarked and Fare with the mode and mean\nfull['Embarked'].fillna(full['Embarked'].mode(), inplace=True)\nfull['Fare'].fillna(full['Fare'].mean(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49e49dae2482ea72e3e6e949aa56f1e7d91f496c"},"cell_type":"code","source":"# Number of nulls correlates to survivial\n# Instead of imputing we can use this\ndef null_count(df):\n    return df[[\"Cabin\", \"Age\"]].apply(lambda x: x.isnull().astype(int)).sum(axis=1)\ntrain[\"nnull\"] = null_count(train)\nprint(train.groupby(\"nnull\").agg(({'PassengerId':'size', 'Survived':'mean'})))\nfull[\"nnull\"] = null_count(full) # Apply to full dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"926b01cda03ca00a713748e1d14319cdabe0edf2"},"cell_type":"code","source":"# Cabin type (first letter in cabin) also correlates to survival\ndef cabin_type(df):\n    cab = df['Cabin'].astype(str).str[0] # this captures the letter\n    return cab.map(\n        {k: i for i, k in enumerate(cab.unique())})\ntrain[\"Cabin_type\"] = cabin_type(train)\n# this transforms the letters into numbers\nprint(train.groupby(\"Cabin_type\").agg(({'PassengerId':'size', 'Survived':'mean'})))\nfull[\"Cabin_type\"] = cabin_type(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91c935c9d48eae894a9fd747374be17b6c71d9e8"},"cell_type":"code","source":"# We can drop no longer used columns\nfull.drop([\"Cabin\", \"Age\"], inplace=True, axis=1) # Drop replaced column\n# Now there are no more null\nfull.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f0bc75e04ac6aeedbac721b5bb63cb8774a77a5"},"cell_type":"code","source":"# Titles are correlated to survival, but there are many types so we collapse titles to fewer categories\ndef extract_titles(df):\n    titles = {\n        \"Mr\" :         \"Mr\",\n        \"Mme\":         \"Mrs\",\n        \"Ms\":          \"Mrs\",\n        \"Mrs\" :        \"Mrs\",\n        \"Master\" :     \"Master\",\n        \"Mlle\":        \"Miss\",\n        \"Miss\" :       \"Miss\",\n        \"Capt\":        \"Officer\",\n        \"Col\":         \"Officer\",\n        \"Major\":       \"Officer\",\n        \"Dr\":          \"Officer\",\n        \"Rev\":         \"Officer\",\n        \"Jonkheer\":    \"Royalty\",\n        \"Don\":         \"Royalty\",\n        \"Sir\" :        \"Royalty\",\n        \"Countess\":    \"Royalty\",\n        \"Dona\":        \"Royalty\",\n        \"Lady\" :       \"Royalty\"\n    }\n    return df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False).map(titles)\ntrain[\"title\"] = extract_titles(train)\n# this transforms the letters into numbers\nprint(train.groupby(\"title\")[[\"Survived\"]].mean())\nfull[\"title\"] = extract_titles(full)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d49e5b72632bdbfda33b9ebe2fa0af75073252da"},"cell_type":"code","source":"# Make a famliy size from parch and sibsp\nfull[\"Family_size\"] = full[[\"Parch\", \"SibSp\"]].sum(axis=1) + 1\nfull.drop([\"Parch\", \"SibSp\", 'Name', 'Ticket'], inplace=True, axis=1) # Drop useless columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9377bb813f30f20a5a4c8e2cef7704b995cc4c8c"},"cell_type":"code","source":"# Encode sex as 0 or 1\nlable_encoder = preprocessing.LabelEncoder()\nlable_encoder.fit(full[\"Sex\"])\nfull[\"Sex\"] = lable_encoder.transform(full[\"Sex\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"792effa5176fb9125ccfa2f581f994b886f9ece6"},"cell_type":"code","source":"# Expand categoricals to dummy booleans\ndummies = pd.get_dummies(full, columns = [\"title\", 'nnull', 'Cabin_type', 'Embarked'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b998ed4ae3321c2ad863162b92f9fa0706f60fb6"},"cell_type":"code","source":"display(dummies.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"957bb92a17ff054f15f3569b890268a8b58a0894"},"cell_type":"markdown","source":"# Machine learning part"},{"metadata":{"trusted":true,"_uuid":"4e0f3e50cabe7719ec3df1a2524bf77927fe3f8a"},"cell_type":"code","source":"X = dummies[:len(train)]\nnew_X = dummies[len(train):]\ny = train.Survived\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size = .3, random_state = 1, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f6a310c49bb3912bd74ddc480ebabeb4bf36c67"},"cell_type":"code","source":"def grid_search(clf, grid, X, y, cv=10):\n    gs = GridSearchCV(\n        clf,\n        grid,\n        scoring='roc_auc',\n        iid=False,\n        verbose=1,\n        cv=cv)\n    gs.fit(X, y)\n    print(\"Params\", gs.best_params_)\n    print(\"Score\", gs.best_score_)\n    return gs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dabddc1044d903662886a5f7c9496ac3b59b56d9"},"cell_type":"code","source":"xgbclf = XGBClassifier(\n    learning_rate =0.1,\n    n_estimators=1000,\n    max_depth=5,\n    min_child_weight=1,\n    gamma=0,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    objective= 'binary:logistic',\n    scale_pos_weight=1,\n    seed=1)\n# Find max_depth and min_child_weight\ngs_1 = grid_search(\n    xgbclf,\n    {\n        'max_depth':range(3,10,1),\n        'min_child_weight':range(1,6,1)\n    },\n    X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa51eb1677fa5e9322fa3c1f20e774e411909ef7"},"cell_type":"code","source":"# Now find best gamma\ngs_2 = grid_search(\n    gs_1.best_estimator_,\n    {'gamma':[i*0.1 for i in range(0,5)]},\n    X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcd25ba4062a366b4286a5cfde3b0e28462b6ef7"},"cell_type":"code","source":"# Find subsample and colsample\ngs_3 = grid_search(\n    gs_2.best_estimator_,\n    {\n         'subsample':[i*0.1 for i in range(6,10)],\n         'colsample_bytree':[i*0.1 for i in range(6,10)]\n    },\n    X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5de38a7f86ad17dabe9b9e52b7228b4f7606a731"},"cell_type":"code","source":"# Find regularization parameter\ngs_4 = grid_search(\n    gs_3.best_estimator_,\n    {'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]},\n    X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34060922dc9f4ec612e00e0c24b4ddbc69fb99c0"},"cell_type":"code","source":"params = gs_4.best_params_\nparams[\"learning_rate\"] = 0.01\nxgbclf = XGBClassifier(**params)\nxgbclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c014ba2fba38722d47aeb9545ecd3f47f73aebf"},"cell_type":"code","source":"xgb_pred = xgbclf.predict(new_X)\nsubmission = pd.concat([test.PassengerId, pd.DataFrame(xgb_pred)], axis = 'columns')\nsubmission.columns = [\"PassengerId\", \"Survived\"]\nsubmission.to_csv('titanic_submission.csv', header = True, index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}