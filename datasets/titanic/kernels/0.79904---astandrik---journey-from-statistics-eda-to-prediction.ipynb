{"metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"version": "3.6.3", "name": "python", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3"}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"metadata": {"_cell_guid": "b05bdfc6-cfc4-434f-b29c-514ad776057b", "_uuid": "f7dc90a3a57d9c4ad19b9b4a513da18043b3f5ad", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["import numpy as np\n", "import scipy as sc\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import statistics as stat\n", "%matplotlib inline\n", "sns.set_style('whitegrid')\n", "\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "from sklearn.preprocessing import StandardScaler, LabelEncoder, Normalizer\n", "\n", "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n", "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, KFold\n", "\n", "from sklearn.svm import SVC\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.linear_model import LogisticRegression\n", "from xgboost import XGBClassifier"]}, {"metadata": {"_cell_guid": "1efdbc77-644a-43f8-8051-3b054266c07c", "_uuid": "729bf7007221eebaeec60f04dc2de35a0d064779"}, "cell_type": "markdown", "source": ["*IMPORT DATASET**\n", "\n", "1st of all, let's import the dataset"]}, {"metadata": {"_cell_guid": "8e51f607-7579-4643-beb1-7896189e2927", "_uuid": "eb121c14db2eea91aa363bf2f108aa984f3a00a5", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')"]}, {"metadata": {"_cell_guid": "53d8f301-3a44-469b-9786-72fd57d24541", "_uuid": "51a6548331759416201a571cc561d4e05f1205e6"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["train.shape, test.shape"]}, {"metadata": {"_cell_guid": "4910039b-7e65-4ceb-88e9-199babcbd816", "_uuid": "0e82c35d79983fe4b6c90e45bb0cfe0b78ebdf53"}, "cell_type": "markdown", "source": ["**A. DESCRIPTIVE STATISTICS**\n", "\n", "All right, using few lines of code, let's try to describe the data using desctiptive statistics"]}, {"metadata": {"_cell_guid": "4fdea9d1-eb71-444e-a179-130fad187887", "_uuid": "a3362f9ea0a8a3024aef97a09ead90a92d9896a8"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["train.describe()"]}, {"metadata": {"_cell_guid": "045642b8-fcbb-4fc9-a951-4168f678e3a5", "_uuid": "a57bcc6ed284dd80ec3116117b0397c8457bf0a1"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["test.describe()"]}, {"metadata": {"_cell_guid": "081f79dc-8d8f-4661-8aff-aaeef2b589df", "_uuid": "b8434571ac1f2f4fda74f4641c26ee7e10dd1fa7"}, "cell_type": "markdown", "source": ["**A.1 Numerical Attributes**\n", "\n", "From above simple code, we can see some numerical attributes described by some simple descriptive statistics. **What do we get here?**\n", "1. **Survived**: the sample mean of this training data is 0,38, which could means *only about that percentage of passengers survived from titanic accident*\n", "\n", "2. **Pclass** (Passenger Class: there are 3 class of passenger. At Q2(50%) and Q3(75%) we could see the value is 3, which could means *there are minimum 50% (or more) passengers which is 3rd class passengers*. It seems logical since lower class usually have cheaper ticket prize, and more quota for that class\n", "\n", "3. **Age**: from train and test data, the count values seems different from the others. yes, **Age attribute contains missing values**. Another usefull information, the mean/average age on training data is 29 years old, which is 1 years older than the median value of the mean (30 mean and 27 median on test dataset), so what does it mean?\n", "    \n", "    it means the distributions of age values have **right skew**, which we expect some outliers in the *higher age value* (on the right size ofthe axis. As we can see, on the training and test dataset max value is 80 and 76 respectively.\n", "    \n", "4. **SibSp and Parch**: these attributes indicate number of SIblings or spouses, and Parent or Children number aboard. From the mean value, seems *majority of the passengers is alone (neither have SibSp or Parch)*. It is interesting that we see the maximum value have 8 SibSp and 9 ParCh, *maybe the oldest person brought his/her entire family on the ship*\n", "\n", "5. **Fare**: there are huge difference between mean and median value of this attributes, which is logical. *Many passengers from 3rd class which always have lower Fare*, on the other hand, we have so high value on max of Fare here, which seems an outlier that affect the average of this attributes (**again, right skew**). **Fare attribute contain 1 missing value on test dataset**"]}, {"metadata": {"_cell_guid": "19e360b1-d740-46b9-b9f5-5b565fe08e55", "_uuid": "b306355d32d449699dbe241c6834378ebdbb6aa3"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["train.describe(include=['O'])"]}, {"metadata": {"_cell_guid": "a7f51a24-16ca-4217-b7d9-1b2b0156bee3", "_uuid": "b43edb773c70c501d860f9d8cd675f19e5aa3df9"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["test.describe(include=['O'])"]}, {"metadata": {"_cell_guid": "f6e3b090-122f-4d1a-bf12-6f53b57a19dd", "_uuid": "9e1fcb0b0a1f76277d8e9f4bc45106fd9282c450"}, "cell_type": "markdown", "source": ["**A.2 Categorical Attributes**\n", "Now, we're dealing with categorical attributes. From describe method above, we get some new information:\n", "1. **Name**: all names are unique (nothing special), *but they contains title*. maybe we can do some feature engineering later to get new attributes which could improve our prediction later.\n", "\n", "2.  **Sex**: or *gender*. consist of 2 categories, male and female, with both on training and test dataset, male have higher frequency (approximately 60 : 40)\n", "\n", "3.  **Ticket**: soooo many unique values for this attributes. Maybe I'll just drop this attribute for now and include it for future research\n", "\n", "4. **Cabin**: so many **missing values** here (*204 filled from 891 possible* on training dataset and *91 filled from 418 possible* on test dataset). *Maybe some passengers*, which we already know, 3rd class or some low Fare paid passenger, **don't have Cabin**.\n", "\n", "5. **Embarked**: There are **2 missing values** on training dataset. from train and test dataset, we know that most of Passengers embarked from S (*what's this \"S\" anyway?*)."]}, {"metadata": {"_cell_guid": "c7bc68fd-c490-415d-9365-d2a1bcc63a91", "_uuid": "42449930c0ddc0904fd1b8f1b3944283cecb39ec"}, "cell_type": "markdown", "source": ["**B. EXPLORATORY DATA ANALYSIS**"]}, {"metadata": {"_cell_guid": "0d2d163f-6a28-4d01-9c45-b3a5b5ce41b3", "_uuid": "b9a99918a77b0c9df33f295d94809834847f4744"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["train.head()"]}, {"metadata": {"_cell_guid": "10ca4606-3edd-42fd-83e9-2ac6989575e6", "_uuid": "66a4514515adb6de19c6c1fe72d809649fa0401f"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["f,ax = plt.subplots(3,4,figsize=(20,16))\n", "sns.countplot('Pclass',data=train,ax=ax[0,0])\n", "sns.countplot('Sex',data=train,ax=ax[0,1])\n", "sns.boxplot(x='Pclass',y='Age',data=train,ax=ax[0,2])\n", "sns.countplot('SibSp',hue='Survived',data=train,ax=ax[0,3],palette='husl')\n", "sns.distplot(train['Fare'].dropna(),ax=ax[2,0],kde=False,color='b')\n", "sns.countplot('Embarked',data=train,ax=ax[2,2])\n", "\n", "sns.countplot('Pclass',hue='Survived',data=train,ax=ax[1,0],palette='husl')\n", "sns.countplot('Sex',hue='Survived',data=train,ax=ax[1,1],palette='husl')\n", "sns.distplot(train[train['Survived']==0]['Age'].dropna(),ax=ax[1,2],kde=False,color='r',bins=5)\n", "sns.distplot(train[train['Survived']==1]['Age'].dropna(),ax=ax[1,2],kde=False,color='g',bins=5)\n", "sns.countplot('Parch',hue='Survived',data=train,ax=ax[1,3],palette='husl')\n", "sns.swarmplot(x='Pclass',y='Fare',hue='Survived',data=train,palette='husl',ax=ax[2,1])\n", "sns.countplot('Embarked',hue='Survived',data=train,ax=ax[2,3],palette='husl')\n", "\n", "ax[0,0].set_title('Total Passengers by Class')\n", "ax[0,1].set_title('Total Passengers by Gender')\n", "ax[0,2].set_title('Age Box Plot By Class')\n", "ax[0,3].set_title('Survival Rate by SibSp')\n", "ax[1,0].set_title('Survival Rate by Class')\n", "ax[1,1].set_title('Survival Rate by Gender')\n", "ax[1,2].set_title('Survival Rate by Age')\n", "ax[1,3].set_title('Survival Rate by Parch')\n", "ax[2,0].set_title('Fare Distribution')\n", "ax[2,1].set_title('Survival Rate by Fare and Pclass')\n", "ax[2,2].set_title('Total Passengers by Embarked')\n", "ax[2,3].set_title('Survival Rate by Embarked')"]}, {"metadata": {"_cell_guid": "c147ba3b-4a86-4b5a-b047-04946cf5b3ee", "_uuid": "f3add6ed695976ad0e0aa279c4360db8d5540056"}, "cell_type": "markdown", "source": ["> Some usefull information:\n", "* clearly, we can see most passengers are in class 3, which have least survival probability here\n", "* from Sex attribute, we can see total male Passengers is almost 2 times of female passengers, but lower survival probability *maybe male passengers tend to save their lady first?*\n", "* from above figure, we can try to input missing age by class\n", "    * Pclass 1, Age average approximately = 37\n", "    * Pclass 2, Age average approximately = 29\n", "    * Pclass 3, Age average approximately = 24\n", "* also on age attributes, we already clearly see the age distributions follow normal distribution with right skew\n", "* it seems passenger with Sibling/Spouse, or have parent/children aboard, have higher survival rate than passenger which is alone!"]}, {"metadata": {"_cell_guid": "51275aee-f06a-4c43-b2c7-ed9fa1bc1f94", "_uuid": "7a10c705bdba00b50c45661c3458ac5bd33e9bd9"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["train['Cabin'].value_counts().head()"]}, {"metadata": {"_cell_guid": "ad1db084-1e8c-4b3a-9b0e-9000e3bc5f9a", "_uuid": "66ecd5058b508b08508c90b407cb501a0bb3d318"}, "cell_type": "markdown", "source": ["Now we got new information, some passenger have multiple cabin listed.\n", "for each passenger, I'll just try to create a new feature called **'Deck'** with first letter from the Cabin as its value.\n", "if passenger have multiple deck listed, I'll just use the higher class deck (ex: A and D, I'll just use A as the value)\n", "\n", "thanks to this discussion: https://www.kaggle.com/c/titanic/discussion/4693\n", "\n", "\"first class had the top decks (A-E), second class (D-F), and third class (E-G). It also makes sense that the people towards the top (higher decks, higher pclass) more likely survived, because they were closer to the lifeboats.\""]}, {"metadata": {"_cell_guid": "95f2ae97-db82-4642-8fb7-560b82d9b911", "_uuid": "b62a4dc156ae5ee2da2250cee8a743083fc2e89e"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["g = sns.FacetGrid(col='Embarked',data=train)\n", "g.map(sns.pointplot,'Pclass','Survived','Sex',palette='viridis')\n", "g.add_legend()"]}, {"metadata": {"_cell_guid": "5491d646-5f2a-42d0-8e74-a963c6d675a9", "_uuid": "07ef5206bf3e45c034e8f9daad95ab106eb3d42d"}, "cell_type": "markdown", "source": ["We got a lot information from above visualization, such as:\n", "* Female passenger Embarked from S and Q have high survival rate\n", "* Female from class 1 and 2 Embarked from Queenstown absolutely survived!!!\n", "* Male Embarked from Queenstown with Pclass 1, have lowest survival rate!\n", "* Male Embarked from Cherbourg with Class 1 and 2 have high survival rate too."]}, {"metadata": {"_cell_guid": "4f1cfe40-7bf0-4bbd-9207-e7ece4652183", "_uuid": "869f35e6b1cc8fc65642588a3ed680e93f4f9262"}, "cell_type": "markdown", "source": ["**C. SUMMARY**\n", "\n", "Before we do this journey further, let's summarize our information and so far and what we should do with them.\n", "* **Survived:**\n", "    * The value we should predict using test dataset. It is numerical with binary value 0 (Dead) and 1 (Survived)\n", "    \n", "* **Pclass:**\n", "    * The data type is categorical, level of measurement is qualitative->ordinal, since the level seems like 1>2>3.\n", "    * Since this is a categorical, maybe we should **get dummies** of this variable.\n", "    \n", "* **Name:**\n", "    * The data type is categorical, level of measurement is qualitative->nominal.\n", "    * We should include this variable in **Feature Engineering** process to extract the title value which maybe could improve our prediction result.\n", "    \n", "* **Sex:**\n", "    * The data type is categorical, level of measurement is qualitative->nominal.\n", "    * Since this is a categorical, maybe we should change the value to binary value 0 for male and 1 for female. We'll do this on **Data Preparation** process.\n", "    \n", "* **Age:**\n", "    * The data type is numerical->continous with level of measurement is quantitative->ratio.\n", "    * we should fill the **missing values**\n", "    * in order to divide the train data so the machine learning could understand better, I prefer to change the level of measurement to quantitative->interval using the group of age (maybe child, teenagers, young adult, adult) on **Feature Engineering** process.\n", "    \n", "* **SibSp & Parch:**\n", "    * The data type is numerical, level of measurement is quantitative->ratio.\n", "    * Passenger with Sibling/Spouse, or have parent/children aboard, have higher survival rate than passenger which is alone!\n", "    * So I'll create a new feature based on this attribute called 'is_alone', I'll do this on **Feature engineering** process.\n", "    \n", "* **Ticket:**\n", "    * *I'' drop this for now.*\n", "    \n", "* **Fare:**\n", "    * The data type is numerical->continous with level of measurement is quantitative->ratio.\n", "    * There is 1 missing value in test dataset\n", "    * in order to divide the train data so the machine learning could understand better, I prefer to change the level of measurement to quantitative->interval using the group of Fares (maybe low Fare, Medium Fare, and High Fare or something like that) on **Feature Engineering** process.\n", "    \n", "* **Cabin:**\n", "    * The data type is categorical, level of measurement is qualitative->ordinal, since the level seems like A>B>C>D..\n", "    * Some passenger have multiple cabin listed.\n", "    * there are many **missing values** on this attributes, I'll fill it with 'No Cabin' string.\n", "    * for each passenger, I'll just try to create a new feature called **'Deck'** with first letter from the Cabin as its value on **Feature Engineering** process.\n", "    * if passenger have multiple deck listed, I'll just use the higher class deck (ex: A and D, I'll just use A as the value)\n", "    \n", "* **Embarked:**\n", "    * The data type is categorical, level of measurement is qualitative->nominal.\n", "    * Since this is a categorical, maybe we should **get dummies** of this variable.\n", "    * there are 2 missing values on training dataset"]}, {"metadata": {"_cell_guid": "1a33d738-d5cd-4206-8545-efd5796c68c6", "_uuid": "615f7d56b1d51a4d08da681d43d915901604c856"}, "cell_type": "markdown", "source": ["**D. DEALING WITH MISSING VALUES**\n", "\n", "from the summary above, we should fill missing values in **Age**, 1 value of **Fare** in test, and 2 values of **Embarked** in training. So, let's do this.\n", "\n", "wait, let's check the missing values using heatmap."]}, {"metadata": {"_cell_guid": "c0da17da-5466-46bc-acfe-5aa480943814", "_uuid": "0075f89b898685b798fc9cb2b9d26df4630fff8b"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["f,ax = plt.subplots(1,2,figsize=(15,3))\n", "sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis',ax=ax[0])\n", "sns.heatmap(test.isnull(),yticklabels=False,cbar=False,cmap='viridis',ax=ax[1])"]}, {"metadata": {"_cell_guid": "b7db013e-2d23-4889-aff3-15c400b26ad5", "_uuid": "a8702901640b9211342e65b19817764f59a8e26b"}, "cell_type": "markdown", "source": ["**D.1 Filling missing values in Age**\n", "\n", "I'll try to input missing Age by Pclass:\n", "* Pclass 1, Age average approximately = 37\n", "* Pclass 2, Age average approximately = 29\n", "* Pclass 3, Age average approximately = 24"]}, {"metadata": {"_cell_guid": "514cf25a-29ca-49c2-9333-a4107cb6623c", "_uuid": "60f4c6e71ef18c40314496a9aefbc7d6e52913cd", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["def fill_age(cols):\n", "    Age = cols[0]\n", "    PClass = cols[1]\n", "    \n", "    if pd.isnull(Age):\n", "        if PClass == 1:\n", "            return 37\n", "        elif PClass == 2:\n", "            return 29\n", "        else:\n", "            return 24\n", "    else:\n", "        return Age"]}, {"metadata": {"_cell_guid": "a41e2ab6-9f69-4554-80a0-d72744d07805", "_uuid": "6e16fc0a7632c5985d242a45e8dd24c1ccee2be8", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["train['Age'] = train[['Age','Pclass']].apply(fill_age,axis=1)\n", "test['Age'] = test[['Age','Pclass']].apply(fill_age,axis=1)"]}, {"metadata": {"_cell_guid": "f47d72e2-3c54-41dd-92e2-ba805cdf8153", "_uuid": "bdbd45a33ee824b5ea4211a43d8d01166f108d22", "collapsed": true}, "cell_type": "markdown", "source": ["**D.2 Filling missing values in Fare, Cabin and Embarked**"]}, {"metadata": {"_cell_guid": "2594b1a1-a218-4162-9132-a87f84fcba73", "_uuid": "42fc153c999baba95ec23545b540175bed5fd19b", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["test['Fare'].fillna(stat.mode(test['Fare']),inplace=True)\n", "train['Embarked'].fillna('S',inplace=True)\n", "train['Cabin'].fillna('No Cabin',inplace=True)\n", "test['Cabin'].fillna('No Cabin',inplace=True)"]}, {"metadata": {"_cell_guid": "f0ca0a5e-f550-45be-8fa6-600d78d5594f", "_uuid": "816e5002f0d7dc06bdce62ad0081b2af70dc2b06"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["f,ax = plt.subplots(1,2,figsize=(15,3))\n", "sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis',ax=ax[0])\n", "sns.heatmap(test.isnull(),yticklabels=False,cbar=False,cmap='viridis',ax=ax[1])"]}, {"metadata": {"_cell_guid": "334abab5-9252-4607-a134-511b57390c6a", "_uuid": "8dc7a63d9e3396d29f9e9f24e3647359ec3eef44"}, "cell_type": "markdown", "source": ["**IT'S CLEAR!!!** ready for feature engineering, but, we'll drop Ticket first"]}, {"metadata": {"_cell_guid": "953727d5-f315-42b9-ae48-17150b80739e", "_uuid": "55cc38659b186ee816dbf76a25f661fb8ff37319", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["train.drop('Ticket',axis=1,inplace=True)\n", "test.drop('Ticket',axis=1,inplace=True)"]}, {"metadata": {"_cell_guid": "9fd40c74-0e17-4add-8c56-c437be92d98e", "_uuid": "27bea12476dd1f4c90ffbde406f610536824c0b4"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["train.head()"]}, {"metadata": {"_cell_guid": "5e17a517-cc9c-4bda-a108-683020e1d94f", "_uuid": "43b779feb34e9a7949b4065bf3cc886c0413aba3"}, "cell_type": "markdown", "source": ["**E. FEATURE ENGINEERING**\n", "\n", "from summary above, we will do some work on **Name, Age, SibSP & Parch, Fare, Cabin**. Let's do this!"]}, {"metadata": {"_cell_guid": "345b840a-d7fb-46f4-b597-d26eaa8cf2c1", "_uuid": "dadc8bce5a988cdcc5fe18277760f148cd0f32ec", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["#combine dataset 1st for easier Feature Engineering\n", "train['IsTrain'] = 1\n", "test['IsTrain'] = 0\n", "df = pd.concat([train,test])"]}, {"metadata": {"_cell_guid": "961d2867-c930-45fc-88a6-527ae7ede0e2", "_uuid": "98af5a6dc186a10064bee6d62f83bc290a71bf17"}, "cell_type": "markdown", "source": ["**E.1 Feature Engineering: Name -> Title**"]}, {"metadata": {"_cell_guid": "97e300fd-c352-49ae-868f-ce6851140b40", "_uuid": "fc37abac57ccd24e386a55fc8fa539cfba533893"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df['Title'] = df['Name'].str.split(', ').str[1].str.split('.').str[0]\n", "df['Title'].value_counts()"]}, {"metadata": {"_cell_guid": "320a3e1c-a904-4250-9006-3ef2468fc422", "_uuid": "3f134dbc467878bd0c19abb1f3f10268e47937ac"}, "cell_type": "markdown", "source": ["for these rare title, we'll convert them to 'Others', except **Mme** will be converted to Mrs, **Ms and Mlle** to Miss"]}, {"metadata": {"_cell_guid": "5311fc6a-ed1e-4906-ba50-122eb6ca33c3", "_uuid": "65eed813412eaa6ed79c59c61bbe36ea897c9edc"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df['Title'].replace('Mme','Mrs',inplace=True)\n", "df['Title'].replace(['Ms','Mlle'],'Miss',inplace=True)\n", "df['Title'].replace(['Dr','Rev','Col','Major','Dona','Don','Sir','Lady','Jonkheer','Capt','the Countess'],'Others',inplace=True)\n", "df['Title'].value_counts()"]}, {"metadata": {"_cell_guid": "258d6ae5-e73d-4f34-933b-470dd419bea2", "_uuid": "042dadba279c03f62f390f818a69857c5d71e3a8"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df.drop('Name',axis=1,inplace=True)\n", "df.head()"]}, {"metadata": {"_cell_guid": "824ea705-d19f-49bc-9b9a-a665da035371", "_uuid": "3169e642208bf2009ccc54701f72a756b0963341"}, "cell_type": "markdown", "source": ["**E.2 Feature Engineering: Age -> AgeGroup**"]}, {"metadata": {"_cell_guid": "4376be05-e423-4ebd-ae3d-617641ba7c2f", "_uuid": "60b17b33ce75a2cc08b9493283aa2ca8a97499f7"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["sns.distplot(df['Age'],bins=5)"]}, {"metadata": {"_cell_guid": "eb3db2ac-07e4-4be6-b34b-9041b685d787", "_uuid": "67945a33a2ddab196b0833fc9b6111e4d09a4bd0"}, "cell_type": "markdown", "source": ["I'll divide age to 5 categories, they are, Child(<=19), Young Adult(>19,<=30), Adult(>30,<=45), Old(>45,<=63), Veteran(>63), \n", "\n", "with: **child = 0, Young Adult = 1, Adult = 2, Old = 3, Veteran = 4**"]}, {"metadata": {"_cell_guid": "84d6f567-ce28-446d-9073-04334075585d", "_uuid": "4e36f713d6b1d96c6aeb89ce9e429981b1f84ef6", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df['AgeGroup'] = df['Age']\n", "df.loc[df['AgeGroup']<=19, 'AgeGroup'] = 0\n", "df.loc[(df['AgeGroup']>19) & (df['AgeGroup']<=30), 'AgeGroup'] = 1\n", "df.loc[(df['AgeGroup']>30) & (df['AgeGroup']<=45), 'AgeGroup'] = 2\n", "df.loc[(df['AgeGroup']>45) & (df['AgeGroup']<=63), 'AgeGroup'] = 3\n", "df.loc[df['AgeGroup']>63, 'AgeGroup'] = 4"]}, {"metadata": {"_cell_guid": "3322733d-f28b-4c82-9428-b37dd0f127c4", "_uuid": "7d6f635b976d699cad3dffa4a53a384fd4d6c852"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["sns.countplot(x='AgeGroup',hue='Survived',data=df[df['IsTrain']==1],palette='husl')"]}, {"metadata": {"_cell_guid": "b6283b39-defa-4db7-813a-2e8a135e0d9e", "_uuid": "036b4c6a7ddc26e1a6bcdae42be7ff441085736f"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df.drop('Age',axis=1,inplace=True)\n", "df.head()"]}, {"metadata": {"_cell_guid": "2796c76b-7259-4955-b613-a024eaf88e43", "_uuid": "e0379782c58f4ef6b83764df0b7bff48e128fa32"}, "cell_type": "markdown", "source": ["**E.3 Feature Engineering: SibSp & Parch -> IsAlone**"]}, {"metadata": {"_cell_guid": "836c3aed-e4c9-417d-860f-c3b271a15713", "_uuid": "963acf95f3407a304169507f39e233ac9223d736", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df['FamilySize'] = df['SibSp'] + df['Parch'] + 1 #himself\n", "df['IsAlone'] = 0\n", "df.loc[df['FamilySize']==1, 'IsAlone'] = 1"]}, {"metadata": {"_cell_guid": "35123efe-a781-4594-87f8-df8d050b13f6", "_uuid": "28679ab1b39d111260a89465e092f4dcac204719"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["#checking correlation with survival rate\n", "f,ax = plt.subplots(1,2,figsize=(15,6))\n", "sns.countplot(df[df['IsTrain']==1]['FamilySize'],hue=train['Survived'],ax=ax[0],palette='husl')\n", "sns.countplot(df[df['IsTrain']==1]['IsAlone'],hue=train['Survived'],ax=ax[1],palette='husl')"]}, {"metadata": {"_cell_guid": "4769ad58-5253-4abe-a2cc-79a431d7cfe5", "_uuid": "78bc458564d47282617857f2ca1b579088e630cc"}, "cell_type": "markdown", "source": ["from both figures, I can assume that if a passenger have family onboard, **the survival rate will increase to approximately 50%.**\n", "\n", "because we already have the information using is_alone feature only, *I'll just drop SibSp, Parch, and FamilySize*"]}, {"metadata": {"_cell_guid": "02ee9bc8-4e78-40ab-a1c3-4c27ec3613c2", "_uuid": "ef60ffd4bf434e186bea8dcd7694ae29e43ffc25"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df.drop(['SibSp','Parch','FamilySize'],axis=1,inplace=True)\n", "df.head()"]}, {"metadata": {"_cell_guid": "75766292-7592-4879-a622-dd0c9c8a343b", "_uuid": "642144db1f78b5d4236b1798544404415b9dd544"}, "cell_type": "markdown", "source": ["**E.4 Feature Engineering: Fare -> FareGroup**"]}, {"metadata": {"_cell_guid": "49f33987-ea55-4191-9b45-d93c69938cc7", "_uuid": "91d8bd9d68d4f30b59216e497e57de9db3ad71b5"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["f,ax = plt.subplots(1,2,figsize=(16,4))\n", "sns.distplot(df['Fare'],bins=10,ax=ax[0])\n", "sns.swarmplot(x='Pclass',y='Fare',data=df[df['IsTrain']==1],hue='Survived',ax=ax[1],palette='husl')"]}, {"metadata": {"_cell_guid": "e28b45e1-762a-49c8-a545-69117438d4dc", "_uuid": "cab9237ebbf3a65281c312cc7d8ea0a29ef3f989", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df['FareGroup'] = df['Fare']\n", "df.loc[df['FareGroup']<=50,'FareGroup'] = 0\n", "df.loc[(df['FareGroup']>50) & (df['FareGroup']<=100),'FareGroup'] = 1\n", "df.loc[(df['FareGroup']>100) & (df['FareGroup']<=200),'FareGroup'] = 2\n", "df.loc[(df['FareGroup']>200) & (df['FareGroup']<=300),'FareGroup'] = 3\n", "df.loc[df['FareGroup']>30,'FareGroup'] = 4"]}, {"metadata": {"_cell_guid": "7b6e400f-1c37-4d22-bc51-68dfdb2bd38e", "_uuid": "e45a08b22035d48d001c4c9b07119d1058ded5e8"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["sns.countplot('FareGroup',data=df[df['IsTrain']==1],hue='Survived',palette='husl')"]}, {"metadata": {"_cell_guid": "4192d3d3-7127-4922-a40c-8c41d3421807", "_uuid": "9bd4671dea64c7a684b45dd306c64e10ca8999a6"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df.drop('Fare',axis=1,inplace=True)\n", "df.head()"]}, {"metadata": {"_cell_guid": "d1e566d0-2787-415e-a3d5-870231826130", "_uuid": "d2f2e413c84af71cc1f04a22af9a2ee38b78802d"}, "cell_type": "markdown", "source": ["**E.5 Feature Engineering: Cabin -> Deck**"]}, {"metadata": {"_cell_guid": "14a8bb77-62a4-4e70-83bd-39d9bb57a375", "_uuid": "aa41aeee098a588e7bccba09221b115abe14ddcc", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df['Deck'] = df['Cabin']\n", "df.loc[df['Deck']!='No Cabin','Deck'] = df[df['Cabin']!='No Cabin']['Cabin'].str.split().apply(lambda x: np.sort(x)).str[0].str[0]\n", "df.loc[df['Deck']=='No Cabin','Deck'] = 'N/A'"]}, {"metadata": {"_cell_guid": "861dcf9b-9f8b-49c1-91ae-b215212e7bff", "_uuid": "f5de98115a7aebef67ec41b31ea2dd24396be9f0"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["sns.countplot(x='Deck',hue='Survived',data=df[df['IsTrain']==1],palette='husl')"]}, {"metadata": {"_cell_guid": "e80ccf66-2d71-4787-893e-5f9cb5606b67", "_uuid": "3379b601e6411b5f73dd641bfa629094b3573711"}, "cell_type": "markdown", "source": ["Well, now we can see clearly the survival rate based on passenger's Deck"]}, {"metadata": {"_cell_guid": "8eeba1bb-3620-40f5-bbe3-efb4a78a6e0e", "_uuid": "3264262063e02d2e97a6edf19956144e76fb0770"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df.drop('Cabin',axis=1,inplace=True)\n", "df.head()"]}, {"metadata": {"_cell_guid": "e94fc1f8-662a-4260-a89e-c38321a28b6f", "_uuid": "1c2ce9027b3ccc01c4ea87a5e24756460a7f8011"}, "cell_type": "markdown", "source": ["**F. FINAL DATA PREPARATION**\n", "\n", "now after we got the features, lastly on data preprocessing, we need to get dummies on categorical data based on newly fresh baked dataframe, they are: **Embarked, Sex, Pclass, Title, AgeGroup, FareGroup, Deck**. "]}, {"metadata": {"_cell_guid": "3a367d54-7031-4d79-967d-45790b77e0e2", "_uuid": "582dd4180fa8b57806909f2751964297d720a99c", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["def process_dummies(df,cols):\n", "    for col in cols:\n", "        dummies = pd.get_dummies(df[col],prefix=col,drop_first=True)\n", "        df = pd.concat([df.drop(col,axis=1),dummies],axis=1)\n", "    return df"]}, {"metadata": {"_cell_guid": "20cac1cd-d9e2-42d0-aa9e-8327e6f038c0", "_uuid": "605b61bd10237bf979cb4cb0929d7e4750cbafc1", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df = process_dummies(df,['Embarked','Sex','Pclass','Title','AgeGroup','FareGroup','Deck'])"]}, {"metadata": {"_cell_guid": "ffd7b68b-0d9a-4b52-b2a8-f92823ddcfce", "_uuid": "f674cea55e065317c7c193c211440a9ba07b3a10"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df.head()"]}, {"metadata": {"_cell_guid": "8f0ec972-ee7a-4766-b59f-e30becf53b76", "_uuid": "dea9c5dd885727638ee0930b9f96538da9a42234"}, "cell_type": "markdown", "source": ["Now All Set. Before we continue to prediction section, let's divide again our data to **dataset** (formerly train data) and **holdout** (formerly test data)"]}, {"metadata": {"_cell_guid": "d8820c79-91d4-4283-8453-744e62ee58c5", "_uuid": "f4e9106755f5b20c7be8f3fa24ca21fd40930bfb", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["dataset = df[df['IsTrain']==1]\n", "dataset.drop(['IsTrain','PassengerId'],axis=1,inplace=True)\n", "holdout = df[df['IsTrain']==0]\n", "test_id = holdout['PassengerId']\n", "holdout.drop(['IsTrain','PassengerId','Survived'],axis=1,inplace=True)"]}, {"metadata": {"_cell_guid": "89783675-b331-42f2-871a-cf107de9415e", "_uuid": "1a492a617d6f3ee15db65afe496c23c4ea51dbc3"}, "cell_type": "markdown", "source": ["**G. PREDICTION**\n", "\n", "In this section, I'll do some work starts from splitting the dataset and do *cross_validation* with it, and maybe some *parameter tuning* to get better prediction result. Stay tune!!!"]}, {"metadata": {"_cell_guid": "bacc3a4c-dbcb-4206-815a-9c487e7d2e12", "_uuid": "435b940150c591ece31e51afbeb2bf6ad1d40217"}, "cell_type": "markdown", "source": ["**G.1 Splitting the dataset**"]}, {"metadata": {"_cell_guid": "a65b079e-d4ab-4cd2-b4b0-a09842b5d083", "_uuid": "4e8e6e5677b2d69c244649ba8ca89c1e72262a3a", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["X = dataset.drop(['Survived'],axis=1)\n", "y = dataset['Survived'].astype('int')\n", "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)"]}, {"metadata": {"_cell_guid": "c11fde1f-430c-4130-b772-8c790bd18941", "_uuid": "1f9549419495beefe9bc7fefba8285bc18d903d9"}, "cell_type": "markdown", "source": ["**G.2 Cross Validation**\n", "\n", "Here, I'll do cross validation using 3 classifiers, SVM, Random Forest, and Logistic Regression. let's see which one give better result."]}, {"metadata": {"_cell_guid": "83e72663-94e7-4ed0-a14e-d2a738646fb6", "_uuid": "9d74f3f610d61339efb1d7b79b81975997f86555", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["svc = SVC()\n", "rfc = RandomForestClassifier()\n", "lgr = LogisticRegression()"]}, {"metadata": {"_cell_guid": "4f3298fa-4fa7-4e46-a051-37c42c8e1d38", "_uuid": "77122f9f878eaf0688753403ebd8965f45d4eff0"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["kfold = KFold(n_splits=10, random_state=7)\n", "print('SVM Classifier: ',cross_val_score(svc, X_train, y_train, cv=kfold).mean()*100)\n", "print('Random Forest: ',cross_val_score(rfc, X_train, y_train, cv=kfold).mean()*100)\n", "print('Logistic Regression: ',cross_val_score(lgr, X_train, y_train, cv=kfold).mean()*100)"]}, {"metadata": {"_cell_guid": "d45f9027-15ab-4351-b549-20c26bdeb7aa", "_uuid": "89bd3d8b6bd3f06e1d727d40a1eaedbcf991d4dc"}, "cell_type": "markdown", "source": ["> **Result:** Seems Logistic Regression works well here, let's try to submit our 1st prediction using Logistic Regression"]}, {"metadata": {"_cell_guid": "70caf9c9-295d-4f88-a49f-02b9bc19ebdf", "_uuid": "c158b0478fb9f3b70a704fa3a008176b180d5d2a", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["#lgr.fit(X,y)\n", "#predictions = lgr.predict(holdout) -- We got only 0.76 on submission score, need to improve"]}, {"metadata": {"_cell_guid": "b06cb5a1-c9cc-42d2-be6a-bfb6b160bf1c", "_uuid": "b40437025faa6de8780234527815615b9ea63c93"}, "cell_type": "markdown", "source": ["Let's try using Random Forest with n_estimators=1 and 1000"]}, {"metadata": {"_cell_guid": "be97b7ca-2075-42da-99ea-d1406f744280", "_uuid": "f6735090975783aaade1ceac0259a427e7d17949", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["#rfc.fit(X,y)\n", "#predictions = rfc.predict(holdout) -- Woa, we got 0.78947 on submission score, we should improve the score\n", "#rfc = RandomForestClassifier()\n", "#rfc.fit(X,y)\n", "#predictions = rfc.predict(holdout) -- 0.799 on submission score."]}, {"metadata": {"_cell_guid": "941c6867-5c88-4a63-83af-e4c20b0538e0", "_uuid": "61814886a23c8b6541eb63f3ee9fe47aa8b60f41"}, "cell_type": "markdown", "source": ["**G.3 XGBoost**\n", "\n", "How about using eXtreme Gradient Boosting?"]}, {"metadata": {"_cell_guid": "a8a858cf-5012-4ea5-9685-c4549543bc58", "_uuid": "43d53a96a1e7e4e3a8d7d13ffc2a45bf2254bfff", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["#xgb = XGBClassifier()\n", "#xgb.fit(X,y)\n", "#predictions = xgb.predict(holdout) -- we only get 0.77033"]}, {"metadata": {"_cell_guid": "69512adc-634c-4033-8d9b-3fa8e59eb07b", "_uuid": "6551fdebe3732185c9d05ed25a4a01e4a31c4531"}, "cell_type": "markdown", "source": ["Don' give up, let's try using common parameters based on this blog post: https://machinelearningmastery.com/configure-gradient-boosting-algorithm/"]}, {"metadata": {"_cell_guid": "d64fc879-40bc-41ab-bdb8-e676856c71a1", "_uuid": "c16656db3b3646fe979399da1be7e64cd6d52adf"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["xgb = XGBClassifier(n_estimators=500)\n", "xgb.fit(X,y)\n", "predictions = xgb.predict(holdout)"]}, {"metadata": {"_cell_guid": "a55ef266-e321-4d58-b128-3c5a8744bee4", "_uuid": "a0ddbb263d98e9e43245aa8e540933437a888b76"}, "cell_type": "markdown", "source": ["**H. SUBMISSION**\n", "\n", "Finally, let's submit our result"]}, {"metadata": {"_cell_guid": "1da493c7-26ef-4f48-8fb9-36e62f8cfc98", "_uuid": "9f90ec531fab1b2184f4aeb24f33b5ad55b32942", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["submission = pd.DataFrame({\n", "    'PassengerId': test_id,\n", "    'Survived': predictions\n", "})\n", "\n", "submission.to_csv('submission.csv',index=False)"]}, {"metadata": {"_cell_guid": "78c670bf-6f0e-453d-a67e-dd26780e32d4", "_uuid": "ad5ef6cdf53bd2d11599ee2430f2c221b5b92663"}, "cell_type": "markdown", "source": ["**MORE TO COME!!!**"]}, {"metadata": {"_cell_guid": "a0eed636-57a3-425e-8b5e-f19779c2ab87", "_uuid": "90409f888a513648e89db0ccc86429f95e2e9439", "collapsed": true}, "outputs": [], "cell_type": "code", "execution_count": null, "source": []}]}