{"cells":[{"metadata":{"_uuid":"6fb9571e9b4f7392471a6678831cf89b0b75217f"},"cell_type":"markdown","source":"This notebook was part of UpGrad initiative to their first cohort getting started with Kaggle competitions. To be compliant with rules, I am sharing everything that was discussed during those sessions. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"** Why do Kaggle**\n\n* Learning new things\n* strenghtnen intuition for ml algorithms and techniques\n* like competing with fellow kagglers"},{"metadata":{"trusted":true,"_uuid":"e7ae2db8143edcfb47dd5ef1476a29020b5a844a"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"141058f9b3039c810f0407dac3075a6428309a7f"},"cell_type":"markdown","source":"** Problem statement **\nhttps://www.kaggle.com/c/santander-customer-transaction-prediction\n\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Lets go ahead  and have a look at data\nDATA_PATH = \"../input/santander-customer-transaction-prediction/\"  \n\ntrain = pd.read_csv(str(Path(DATA_PATH) / \"train.csv\"))\ntest = pd.read_csv(str(Path(DATA_PATH) / \"test.csv\"))\n\nprint(\"Train and test shapes\", train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ca0505ff04c93527f3b6df2356835e399177784"},"cell_type":"code","source":"train.columns, test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90c75f194f2ace85b8afff8c58f731743899adf9"},"cell_type":"code","source":"train.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"507f517477450ff23dc75c6e3a0d6043530e79f7"},"cell_type":"code","source":"# https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html\ndef woe(X, y):\n    tmp = pd.DataFrame()\n    tmp[\"variable\"] = X\n    tmp[\"target\"] = y\n    var_counts = tmp.groupby(\"variable\")[\"target\"].count()\n    var_events = tmp.groupby(\"variable\")[\"target\"].sum()\n    var_nonevents = var_counts - var_events\n    tmp[\"var_counts\"] = tmp.variable.map(var_counts)\n    tmp[\"var_events\"] = tmp.variable.map(var_events)\n    tmp[\"var_nonevents\"] = tmp.variable.map(var_nonevents)\n    events = sum(tmp[\"target\"] == 1)\n    nonevents = sum(tmp[\"target\"] == 0)\n    tmp[\"woe\"] = np.log(((tmp[\"var_nonevents\"])/nonevents)/((tmp[\"var_events\"])/events))\n    tmp[\"woe\"] = tmp[\"woe\"].replace(np.inf, 0).replace(-np.inf, 0)\n    tmp[\"iv\"] = (tmp[\"var_nonevents\"]/nonevents - tmp[\"var_events\"]/events) * tmp[\"woe\"]\n    iv = tmp.groupby(\"variable\")[\"iv\"].last().sum()\n    return tmp[\"woe\"], tmp[\"iv\"], iv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c660653d879bc0cb89e5ef816d4f7dbfa68cf34"},"cell_type":"code","source":"iv_values = []\nfeats = [\"var_{}\".format(i) for i in range(200)]\ny = train[\"target\"]\nfor f in feats:\n    X = pd.qcut(train[f], 10, duplicates='drop')\n    _, _, iv = woe(X, y)\n    iv_values.append(iv)\n    \niv_inds = np.argsort(iv_values)[::-1][:50]\niv_values = np.array(iv_values)[iv_inds]\nfeats = np.array(feats)[iv_inds]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2ba56af1d90d7791cff5d79fca60148dcc5128f"},"cell_type":"code","source":"plt.figure(figsize=(10, 16))\nsns.barplot(y=feats, x=iv_values, orient='h')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d62e3279ff64621dfb2a56b83fb79cf796b58b13"},"cell_type":"markdown","source":"## EDA\n\n### Pointers\n* Check out existing kernels\nhttps://www.kaggle.com/gpreda/santander-eda-and-prediction\nhttps://www.kaggle.com/artgor/santander-eda-fe-fs-and-models\nhttps://www.kaggle.com/mjbahmani/santander-ml-explainability\n\n* Check distributions\n* Compare train and test distributions\n* Identify important features (Most of the times feature engineering is going to be around features with high predictive power)\n* Attach a logic to why featurea are important ( Note: data is anonymised  here so hard to do this)\n* Check previous solutions to similar problems\n\n\n### Observations\n* Data normalization and imputation\n* Weak corelations between features and target\n* IV values ??\n* Most variables have distribution close to normal\n* Almost no corelation between differnt variable - What does it mean ??\n* No NA values (already imputed??)\n* Some features seem to have been clipped at one end\n* Spikes in distributions (imputed values??)\n* less unique "},{"metadata":{"trusted":true,"_uuid":"2f871f855bfa01b20e704f3db4cfb96184d6de84"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold, cross_val_predict\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51d3df5841b97824bb84ba208723847fb571588e"},"cell_type":"code","source":"feats = [\"var_{}\".format(i) for i in range(200)]\nX = train[feats]\nX_test = test[feats]\ny = train[\"target\"]\n\ncvlist = list(StratifiedKFold(5, random_state=12345786).split(X, y))\nscaler = StandardScaler()\n\nX_sc = scaler.fit_transform(X)\nX_test_sc = scaler.fit_transform(X_test)\n\nlr = LogisticRegression()\ny_preds_lr = cross_val_predict(lr, X_sc, y, cv=cvlist, method=\"predict_proba\")[:, 1]\n\nlr.fit(X_sc, y)\ny_test_preds_lr = lr.predict_proba(X_test_sc)[:, 1] \nroc_auc_score(y, y_preds_lr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"448d6ceb8e3c409b7717862d76806bf5f98ce64f","trusted":true},"cell_type":"code","source":"sns.distplot(y_preds_lr)\nsns.distplot(y_test_preds_lr)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a52c0b997e9d908a9eb5f87c4df4cc15ec98be17"},"cell_type":"markdown","source":"### Method -1 : train on full and predict on test\n - rule  - scale boosting rounds by train data ratio to data during validation - 1500 "},{"metadata":{"trusted":true,"_uuid":"0a4aa700d3107eef3bde82be4fa16164e5c79c83"},"cell_type":"code","source":"import lightgbm as lgb\n#model = lgb.LGBMClassifier(n_estimators=2000, learning_rate=0.1, num_leaves=2, subsample=0.4, colsample_bytree=0.4)\n\n#y_preds_lgb = np.zeros((len(y)))\n#for i, (tr_idx, val_idx) in enumerate(cvlist):\n#    X_dev, y_dev = X.iloc[tr_idx], y.iloc[tr_idx]\n#    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n#    model.fit(X_dev, y_dev, eval_set=[(X_val, y_val)], eval_metric=\"auc\", verbose=50, early_stopping_rounds=200)\n#    val_preds = model.predict_proba(X_val)[:, 1]\n#    y_preds_lgb[val_idx] = val_preds\n#    print(\"Score for fold {} is {}\".format(i, roc_auc_score(y_val, val_preds)))\n    \n#print(\"Overall Score for oof predictions \", roc_auc_score(y, y_preds_lgb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01e713e43cbd38f70a379144685477f9937b2cf1"},"cell_type":"code","source":"#model = lgb.LGBMClassifier(n_estimators=1500, learning_rate=0.1, num_leaves=8, subsample=0.6, colsample_bytree=0.6)\n#model.fit(X, y)\n#y_test_preds_lgb = model.predict_proba(X_test)[:, 1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"776c87163fd6d7679daf72de35519fe1cef27c6f"},"cell_type":"code","source":"#sns.distplot(y_preds)\n#sns.distplot(y_test_preds_lgb)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7325305f639226cffa66bbb56c64533a446f1cff"},"cell_type":"markdown","source":"### Method 2 - use validation fold models to predict on test set\n"},{"metadata":{"trusted":true,"_uuid":"918ce86fe430a3c308fdd10fb3b22458971f5274"},"cell_type":"code","source":"from scipy.stats import gmean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"995f6d5432c34e1282814aeb064eb1c979a6dcaa"},"cell_type":"code","source":"np.mean([0.9, 0.9, 0.9, 0.98, 0.9])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84416e429f97925fb95d4cc98747ec3290f540cc"},"cell_type":"code","source":"gmean([0.9, 0.9, 0.9, 0.98, 0.9])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2676283a7ef759d651d92d45f595a48d3ae061ac"},"cell_type":"code","source":"import lightgbm as lgb\nmodel = lgb.LGBMClassifier(n_estimators=200000, learning_rate=0.05, num_leaves=2, subsample=0.45, colsample_bytree=0.45)\n\ny_preds_lgb = np.zeros((len(y)))\ntest_preds_allfolds = []\nfor i, (tr_idx, val_idx) in enumerate(cvlist):\n    X_dev, y_dev = X.iloc[tr_idx], y.iloc[tr_idx]\n    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n    model.fit(X_dev, y_dev, eval_set=[(X_val, y_val)], eval_metric=\"auc\", verbose=50, early_stopping_rounds=200)\n    val_preds = model.predict_proba(X_val)[:, 1]\n    test_preds = model.predict_proba(X_test)[:, 1]\n    test_preds_allfolds.append(test_preds)\n    y_preds_lgb[val_idx] = val_preds\n    print(\"Score for fold {} is {}\".format(i, roc_auc_score(y_val, val_preds)))\n    # break\nprint(\"Overall Score for oof predictions \", roc_auc_score(y, y_preds_lgb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1771a2c0c45b0bc8e03910a1ef68cf07b724c626"},"cell_type":"code","source":"y_test_preds_lgb = gmean(test_preds_allfolds, 0)\nsns.distplot(y_preds_lgb)\nsns.distplot(y_test_preds_lgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6ac38b880ae7ee03c2b225fb27ad627d67fc98c"},"cell_type":"code","source":"sub = test[[\"ID_code\"]]\nsub[\"target\"] = y_test_preds_lgb2\nsub.to_csv(\"submission_lgbm2_v1.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8cdad3215478319dbeca86682383342e0553d98"},"cell_type":"markdown","source":"### Modelling\n\nPointers:\n*  Validation strategy -- Random KFold, holdout or temporal split ??\n* What to trust validation score or LB socre?? trust score from more data; if test data is more we should treat LB as additional fold\n* Hyperparamter tuning -- Combination of manual tuning and bayesian optimization libraries like `hyperopt` and `scikit-optimize`. Initial tuninng on single fold and then move to 5 folds.\n* Always check validation and test set prediction distributions\n* ** Read forums and participate in discussions **"},{"metadata":{"trusted":true,"_uuid":"b98f2a12877be87a0b46c60670b10d8f290f4860"},"cell_type":"code","source":"weighted_preds = y_preds_lr* 0.05 + y_preds * 0.95\nroc_auc_score(y, weighted_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9780311c97f233f020fd9a4a6088ad0acc54b1bf"},"cell_type":"code","source":"public_sub = pd.read_csv(\"../input/santander-lgb-new-features-rank-mean-10-folds/submission_LGBM.csv\")\npublic_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81784c7a12644e58ed413c2100eb278d7e616978"},"cell_type":"code","source":"sub[\"target\"] = 0.1*sub[\"target\"] + 0.9*public_sub[\"target\"]\nsub.to_csv(\"submission_blend.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9f6a349ee0bea12bb49d57f7fbca6b5d5680337"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}