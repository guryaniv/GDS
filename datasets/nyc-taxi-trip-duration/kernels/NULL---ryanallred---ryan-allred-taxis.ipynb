{"metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"version": "3.6.1", "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python"}}, "nbformat": 4, "cells": [{"metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "6f3a1890af11d034c539186ef914582c450191d7", "_cell_guid": "cd00725b-1cb3-4673-bba3-7b06b333743c"}, "outputs": [], "source": ["import numpy as np \n", "import pandas as pd \n", "import matplotlib.pyplot as plt\n", "import xgboost as xgb\n", "import seaborn as sns\n", "from sklearn.model_selection import train_test_split\n", "import datetime as dt"], "cell_type": "code", "execution_count": 36}, {"metadata": {"scrolled": false, "_uuid": "4e31958a197ff0a66705d64dd484ea30bc184748", "_cell_guid": "98283a21-f778-431b-8565-529689338c32"}, "outputs": [], "source": ["# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files \n", "# in the input directory\n", "\n", "#from subprocess import check_output\n", "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')\n", "sample_submission = pd.read_csv('../input/sample_submission.csv')\n", "t0 = pd.datetime.now()\n", "np.random.seed(42)\n", "train.head(2)"], "cell_type": "code", "execution_count": 37}, {"metadata": {"_uuid": "1cadd3d9a19fd0fd62f0616c57b40ab117bd0fd4", "_cell_guid": "c706f099-1d55-4444-a71a-84d53103c312"}, "outputs": [], "source": ["# Look at column types\n", "print(train.dtypes)"], "cell_type": "code", "execution_count": 38}, {"metadata": {"_uuid": "015224d71788fe53358738f634c6945c2c1dd904", "_cell_guid": "4a0b9e20-8300-46c2-a41d-9c54e49eabc8"}, "outputs": [], "source": ["# Check Shape\n", "print('train shape: ', train.shape)\n", "print('test shape: ', test.shape)\n", "\n", "# Looks like the test dataset doesn't contain dropoff_datetime or trip_duration"], "cell_type": "code", "execution_count": 39}, {"metadata": {"_uuid": "c74c0c239c04b39efddbf2acee1c0d324e7ca3ca", "_cell_guid": "f9c69040-96f7-4d98-adbe-3c1d4adb98bc"}, "outputs": [], "source": ["# Check for missing values\n", "print(train.isnull().sum())"], "cell_type": "code", "execution_count": 40}, {"metadata": {"_uuid": "ac61735771f79ce44751113ce2eb4b381e092c5a", "_cell_guid": "1ab58b06-c5e0-4445-86d1-ceaea44528bd"}, "outputs": [], "source": ["# What are the values for store_and_fwd_flag ?\n", "train.store_and_fwd_flag.unique()"], "cell_type": "code", "execution_count": 41}, {"metadata": {"_uuid": "a261a9307a6d519ab858a62b0828c10d16bd6ada", "_cell_guid": "b2d2d561-8eb5-4c34-84b3-7d0eb7b65c89"}, "outputs": [], "source": ["# Make Binary store_and_fwd_flag\n", "train[\"store_and_fwd_flag\"].replace(('Y', 'N'), (1, 0), inplace=True)\n", "test[\"store_and_fwd_flag\"].replace(('Y', 'N'), (1, 0), inplace=True)\n", "\n", "train.head(2)"], "cell_type": "code", "execution_count": 42}, {"metadata": {"_uuid": "eddd7a6055608e973fc42af5cbc0ac73b78e25c3", "_cell_guid": "1c0a3845-5562-4a40-9638-3f9358512eb3"}, "outputs": [], "source": ["plt.hist(train['trip_duration'].values, bins=100)\n", "plt.xlabel('trip_duration')\n", "plt.ylabel('number of train records')\n", "plt.show()\n", "print('Hmmm... That\\'s not a very helpful graph... outliers? ')"], "cell_type": "code", "execution_count": 43}, {"metadata": {"_uuid": "e76cbea50b53ba219f486d3d031bbb07734b968d", "_cell_guid": "b7dc785e-02ba-461d-8cd8-985a9a278910"}, "outputs": [], "source": ["# What's the max trip duration? we've got some outliers.\n", "print(\"Trip Duration Min (seconds):\", train['trip_duration'].min())\n", "print(\"Trip Duration Max (seconds):\", train['trip_duration'].max())\n", "print(\"Max Trip Duration in Hours:\", train['trip_duration'].max()/3600)"], "cell_type": "code", "execution_count": 44}, {"metadata": {"_uuid": "27468047411b10280097b919bdb14e8b72930644", "_cell_guid": "09bb0757-496f-4e55-9df3-d0505ac38d9b"}, "outputs": [], "source": ["# Plot log of trip duration\n", "train['log_trip_duration'] = np.log(train['trip_duration'])\n", "plt.hist(train['log_trip_duration'].values, bins=100)\n", "plt.xlabel('log_trip_duration')\n", "plt.ylabel('number of train records')\n", "#plt.show()"], "cell_type": "code", "execution_count": 45}, {"metadata": {"_uuid": "2a47ed106b345636549f575f3ad383b52d4a91f2", "_cell_guid": "f00b7ba6-99c7-406d-8220-870f308f22b2"}, "outputs": [], "source": ["# # Haversine Formula for distance between two GPS Coordinates\n", "\n", "# # from math import radians, cos, sin, asin, sqrt\n", "\n", "# # def haversine(lon1, lat1, lon2, lat2):    \n", "# #     \"\"\"\n", "# #     Calculate the great circle distance between two points \n", "# #     on the earth (specified in decimal degrees)\n", "# #     Can verify values here: http://www.movable-type.co.uk/scripts/latlong.html\n", "# #     \"\"\"\n", "# #     # convert decimal degrees to radians \n", "# #     lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n", "\n", "# #     # haversine formula \n", "# #     dlon = lon2 - lon1 \n", "# #     dlat = lat2 - lat1 \n", "# #     a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n", "# #     c = 2 * asin(sqrt(a)) \n", "# #     r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n", "# #     return c * r\n", "\n", "# # train['haversine_dist_km'] = train.apply(lambda row: haversine(row['pickup_longitude'], row['pickup_latitude'], row['dropoff_longitude'], row['dropoff_latitude']), axis=1)\n", "# # test['haversine_dist_km'] = train.apply(lambda row: haversine(row['pickup_longitude'], row['pickup_latitude'], row['dropoff_longitude'], row['dropoff_latitude']), axis=1)\n", "\n", "# # train.head(2)\n", "\n", "# def haversine_array(lat1, lng1, lat2, lng2):\n", "#     lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n", "#     AVG_EARTH_RADIUS = 6371  # in km\n", "#     lat = lat2 - lat1\n", "#     lng = lng2 - lng1\n", "#     d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n", "#     h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n", "#     return h\n", "\n", "# def dummy_manhattan_distance(lat1, lng1, lat2, lng2):\n", "#     a = haversine_array(lat1, lng1, lat1, lng2)\n", "#     b = haversine_array(lat1, lng1, lat2, lng1)\n", "#     return a + b\n", "\n", "# def bearing_array(lat1, lng1, lat2, lng2):\n", "#     AVG_EARTH_RADIUS = 6371  # in km\n", "#     lng_delta_rad = np.radians(lng2 - lng1)\n", "#     lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n", "#     y = np.sin(lng_delta_rad) * np.cos(lat2)\n", "#     x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n", "#     return np.degrees(np.arctan2(y, x))\n", "\n", "# train.loc[:, 'distance_haversine'] = haversine_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n", "# train.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n", "# train.loc[:, 'direction'] = bearing_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n", "# # train.loc[:, 'pca_manhattan'] = np.abs(train['dropoff_pca1'] - train['pickup_pca1']) + np.abs(train['dropoff_pca0'] - train['pickup_pca0'])\n", "\n", "# test.loc[:, 'distance_haversine'] = haversine_array(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n", "# test.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n", "# test.loc[:, 'direction'] = bearing_array(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n", "# # test.loc[:, 'pca_manhattan'] = np.abs(test['dropoff_pca1'] - test['pickup_pca1']) + np.abs(test['dropoff_pca0'] - test['pickup_pca0'])\n", "\n", "# train.loc[:, 'center_latitude'] = (train['pickup_latitude'].values + train['dropoff_latitude'].values) / 2\n", "# train.loc[:, 'center_longitude'] = (train['pickup_longitude'].values + train['dropoff_longitude'].values) / 2\n", "# test.loc[:, 'center_latitude'] = (test['pickup_latitude'].values + test['dropoff_latitude'].values) / 2\n", "# test.loc[:, 'center_longitude'] = (test['pickup_longitude'].values + test['dropoff_longitude'].values) / 2"], "cell_type": "code", "execution_count": 46}, {"metadata": {"collapsed": true, "_uuid": "6417686f668043d6ffb8910017ec979951a5537b", "_cell_guid": "e4718f42-765f-47ea-af14-c72f95b8e1b6"}, "outputs": [], "source": ["# # Speed = distance / time\n", "# train.loc[:, 'avg_speed_h'] = 1000 * train['haversine_dist_km'] / train['trip_duration']"], "cell_type": "code", "execution_count": 47}, {"metadata": {"_uuid": "252fc4b2a44662d98df2bddae20fa7cf53367fc1", "_cell_guid": "e9cd3852-fe75-41ee-a3c4-bba916aaaf23"}, "outputs": [], "source": ["# # Datetime Features\n", "\n", "# train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\n", "# test['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\n", "# train.loc[:, 'pickup_date'] = train['pickup_datetime'].dt.date\n", "# test.loc[:, 'pickup_date'] = test['pickup_datetime'].dt.date\n", "# train['dropoff_datetime'] = pd.to_datetime(train.dropoff_datetime)\n", "# train['store_and_fwd_flag'] = 1 * (train.store_and_fwd_flag.values == 'Y')\n", "# test['store_and_fwd_flag'] = 1 * (test.store_and_fwd_flag.values == 'Y')\n", "# train['check_trip_duration'] = (train['dropoff_datetime'] - train['pickup_datetime']).map(lambda x: x.total_seconds())\n", "# duration_difference = train[np.abs(train['check_trip_duration'].values  - train['trip_duration'].values) > 1]\n", "# print('Trip_duration and datetimes are ok.') if len(duration_difference[['pickup_datetime', 'dropoff_datetime', 'trip_duration', 'check_trip_duration']]) == 0 else print('Ooops.')\n", "\n", "# train.loc[:, 'pickup_weekday'] = train['pickup_datetime'].dt.weekday\n", "# train.loc[:, 'pickup_hour_weekofyear'] = train['pickup_datetime'].dt.weekofyear\n", "# train.loc[:, 'pickup_hour'] = train['pickup_datetime'].dt.hour\n", "# train.loc[:, 'pickup_minute'] = train['pickup_datetime'].dt.minute\n", "# train.loc[:, 'pickup_dt'] = (train['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\n", "# train.loc[:, 'pickup_week_hour'] = train['pickup_weekday'] * 24 + train['pickup_hour']\n", "\n", "# test.loc[:, 'pickup_weekday'] = test['pickup_datetime'].dt.weekday\n", "# test.loc[:, 'pickup_hour_weekofyear'] = test['pickup_datetime'].dt.weekofyear\n", "# test.loc[:, 'pickup_hour'] = test['pickup_datetime'].dt.hour\n", "# test.loc[:, 'pickup_minute'] = test['pickup_datetime'].dt.minute\n", "# test.loc[:, 'pickup_dt'] = (test['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\n", "# test.loc[:, 'pickup_week_hour'] = test['pickup_weekday'] * 24 + test['pickup_hour']"], "cell_type": "code", "execution_count": 48}, {"metadata": {"_uuid": "4785a22a709e6de5d2e8ec7c4780c2cce5adeaa8", "_cell_guid": "3525cfd4-4d52-43dc-ad8c-246f39e95f6c"}, "outputs": [], "source": ["feature_names = list(train.columns)\n", "print(\"difference in datasets\", np.setdiff1d(train.columns, test.columns))\n", "#do_not_use_for_training = ['id', 'log_trip_duration', 'pickup_datetime', 'dropoff_datetime', 'trip_duration', 'check_trip_duration',\n", "#                           'pickup_date', 'avg_speed_h', 'avg_speed_m', 'pickup_lat_bin', 'pickup_long_bin',\n", "#                           'center_lat_bin', 'center_long_bin', 'pickup_dt_bin', 'pickup_datetime_group', 'dropoff_datetime',\n", "#                          'dropoff_day', 'dropoff_hour', 'dropoff_month', 'dropoff_second', 'dropoff_year']\n", "do_not_use_for_training = ['id', 'dropoff_datetime', 'log_trip_duration', 'trip_duration', 'pickup_datetime']\n", "feature_names = [f for f in train.columns if f not in do_not_use_for_training]\n", "print(feature_names)\n", "print('We have %i features.' % len(feature_names))\n", "train[feature_names].count()\n", "y = np.log(train['trip_duration'].values + 1)\n", "\n", "t1 = dt.datetime.now()\n", "print('Feature extraction time: %i seconds' % (t1 - t0).seconds)\n", "\n", "# train.head()"], "cell_type": "code", "execution_count": 49}, {"metadata": {"_uuid": "9d609bd24a341d520039036c317f47b1572295be", "_cell_guid": "51d378ca-0b1f-458a-94ed-3c53b94d7972"}, "outputs": [], "source": ["Xtr, Xv, ytr, yv = train_test_split(train[feature_names].values, y, test_size=0.2, random_state=1987)\n", "dtrain = xgb.DMatrix(Xtr, label=ytr)\n", "dvalid = xgb.DMatrix(Xv, label=yv)\n", "dtest = xgb.DMatrix(test[feature_names].values)\n", "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n", "\n", "# Try different parameters! My favorite is random search :)\n", "xgb_pars = {'min_child_weight': 50, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 10,\n", "            'subsample': 0.8, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n", "            'eval_metric': 'rmse', 'objective': 'reg:linear'}"], "cell_type": "code", "execution_count": 50}, {"metadata": {"_uuid": "b8eb6f55de7208ca008906560457f7cf126fdcef", "_cell_guid": "caf41594-e865-409b-a300-c37cdb3c684c"}, "outputs": [], "source": ["# You could try to train with more epoch\n", "model = xgb.train(xgb_pars, dtrain, 60, watchlist, early_stopping_rounds=50,\n", "                  maximize=False, verbose_eval=10)"], "cell_type": "code", "execution_count": 51}, {"metadata": {"_uuid": "9bfcb199a1eebc0eb03ea0c0ae64760dea106091", "_cell_guid": "033e8c37-1a52-4563-87f9-62313133903c"}, "outputs": [], "source": ["print('Modeling RMSLE %.5f' % model.best_score)\n", "t1 = dt.datetime.now()\n", "print('Training time: %i seconds' % (t1 - t0).seconds)"], "cell_type": "code", "execution_count": 52}, {"metadata": {"_uuid": "c1c83acac5d0e09b8c7569eecf3ab0499d1a549f", "_cell_guid": "2e905a4f-1942-40c6-8647-51d406628613"}, "outputs": [], "source": ["ypred = model.predict(dvalid)\n", "ytest = model.predict(dtest)\n", "print('Test shape OK.') if test.shape[0] == ytest.shape[0] else print('Oops')\n", "test['trip_duration'] = np.exp(ytest) - 1\n", "test[['id', 'trip_duration']].to_csv('taxi_trip_3.csv.gz', index=False, compression='gzip')\n", "\n", "print('Valid prediction mean: %.3f' % ypred.mean())\n", "print('Test prediction mean: %.3f' % ytest.mean())\n", "\n", "fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)\n", "sns.distplot(ypred, ax=ax[0], color='blue', label='validation prediction')\n", "sns.distplot(ytest, ax=ax[1], color='green', label='test prediction')\n", "ax[0].legend(loc=0)\n", "ax[1].legend(loc=0)\n", "plt.show()\n", "\n", "t1 = dt.datetime.now()\n", "print('Total time: %i seconds' % (t1 - t0).seconds)"], "cell_type": "code", "execution_count": 53}], "nbformat_minor": 1}