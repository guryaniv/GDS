{"cells":[{"metadata":{"_uuid":"b4578d48b219735043a4d2102119fb307d2fc83f"},"cell_type":"markdown","source":"# Date Expansion\nHere we'll use a simple linear model based on the travel vector and date of pickup from the taxi's pickup location to dropoff location which predicts the `fare_amount` of each ride.\n\nThis kernel uses some `pandas` and mostly `numpy` for the critical work.  There are many higher-level libraries you could use instead, for example `sklearn` or `statsmodels`.  \n\nTotal line in training data is 55.423.857 rows. We try to learn from every available rows. We use lightgbm for incremental learning and the result will predict test."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Initial Python environment setup...\nimport numpy as np # linear algebra\nimport pandas as pd # CSV file I/O (e.g. pd.read_csv)\nimport os # reading the input files we have access to\nimport time\nimport gc\n\nimport sys\n\n# Multiprocessing\n# from multiprocessing import Pool\n\n# Import Sklearn and lgbm\nimport lightgbm as lgbm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\ntry:\n    import cPickle as pickle\nexcept BaseException:\n    import pickle\n\n#Visualization\nfiles = os.listdir('../input')\nprint(files)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2da78a4bc3fd716303b9ce9f421aab6907d972f"},"cell_type":"code","source":"# %%time\n# Test Unit\n\n# training_step = list(range(0, 20_000_001, 1_000_000))\n# model = None\n# origin_cols = ['key',\n#  'fare_amount',\n#  'pickup_datetime',\n#  'pickup_longitude',\n#  'pickup_latitude',\n#  'dropoff_longitude',\n#  'dropoff_latitude',\n#  'passenger_count']\n# print(training_step)\n\n# for i in range(1, len(training_step)):\n#     start = time.time()\n#     files = os.listdir('../')\n#     print(files)\n#     if \"model.pkl\" not in files:\n#         print(\"No Model yet...\")\n#         model = None\n#     else:\n#         with open('../model.pkl', 'rb') as fin:\n#             model = pickle.load(fin)\n            \n#     data = pd.read_csv(\"../input/train.csv\", skiprows=training_step[i-1], nrows=training_step[i])\n#     data.columns = origin_cols\n#     model = incremental_learning(data, model)\n#     print(\"TRAINING NUMBER:\", i,\"Elapsed:\", time.time() - start, \"s\\n\")\n    \n#     del data\n#     with open('../model.pkl', 'wb') as fout:\n#         pickle.dump(model, fout)\n#     del model\n    \n\n# test_df = pd.read_csv(\"../input/train.csv\", skiprows=40_000_000, nrows=1_000_000)\n# test_df.columns = origin_cols\n\n# add_travel_vector_features(test_df)\n# test_df[\"pickup_datetime\"] = pd.to_datetime(test_df[\"pickup_datetime\"], infer_datetime_format=True)\n# test_X = pd.concat([test_df, timeExpansion(test_df[\"pickup_datetime\"])], axis=1)\n\n# test_y_true = test_X[\"fare_amount\"]\n# test_X.drop([\"key\", \"pickup_datetime\", \"fare_amount\"], axis=1, inplace=True)\n\n# print(\"Test Shape: \",test_X.shape)\n\n# test_y_pred = model.predict(test_X)\n# print (\"TEST MAE:\", mean_absolute_error(test_y_true, test_y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abbb4f9667e1969acf6ae27536894b28e30e5530"},"cell_type":"code","source":"# Main Pipeline\ndef incremental_learning(data, model):\n    start = time.time()\n    \n    data[\"pickup_datetime\"] = pd.to_datetime(data[\"pickup_datetime\"], infer_datetime_format=True)\n    print(\"Conversion took\", time.time() - start, \"s\")\n    add_travel_vector_features(data)\n    data = pd.concat([data, timeExpansion(data[\"pickup_datetime\"])], axis=1)\n    \n    \n    \n    X_tr, X_te, y_tr, y_te = train_test_split(\n        data.drop([\"key\", \"pickup_datetime\", \"fare_amount\"], axis=1), \n        data['fare_amount'], \n        test_size=0.2)\n    \n    del data\n    \n    params = {\n        'boosting_type': 'gbdt',\n        'objective': 'regression_l1',\n        'metric': {'l1'},\n        'num_leaves': 12,\n        'learning_rate': 0.1,\n        'feature_fraction': 0.9,\n        'bagging_fraction': 0.8,\n        'random_state': 77,\n        'n_jobs': 4,\n        'bagging_freq': 5,\n        'verbose': 2\n    }\n\n    \n    dset = lgbm.Dataset(X_tr, y_tr, free_raw_data=True)\n    model = lgbm.train(params, \n                       init_model = model,\n                       train_set = dset,\n                       keep_training_booster = True,\n                       num_boost_round = 100)\n    MAE = mean_absolute_error(y_te, model.predict(X_te))\n    print(\"Mean Absolute Error:\", MAE)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32ce5178691fc283912dffca04d2499dd81af692"},"cell_type":"code","source":"# Helper Function\n\n# def PandasMultiprocessing(Series, function, pool):\n#     start = time.time()\n#     n_cores = 4\n#     lin = np.linspace(0, len(Series), n_cores+1, dtype=\"int\")\n    \n#     print(\"Start Multiprocessing\")\n    \n#     result = pool.starmap_async(function, [[Series[lin[num-1]:lin[num]]] for num in range(1, len(lin))])    \n    \n#     converted = pd.concat(result.get())\n    \n#     print(\"Multiprocessing Took\", time.time() - start, \"s\")\n#     return converted\n\ndef partial_import(filename, skip, rows):\n    return pd.read_csv('..input/train.csv', skiprows=skip, nrows=rows)\n\ndef add_travel_vector_features(df):\n    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n    \ndef month_translation(number):\n    month_list = [\"jan\", \"feb\", \"mar\", \n                   \"apr\", \"may\", \"jun\", \"jul\", \n                   \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]\n    \n    for num, i in enumerate(month_list):\n        if num == number-1:\n            return i\n\ndef quarter_translation(number):\n    quarter_border = [0, 3, 6, 9, 12, 15, 18, 21, 24]\n    quarter_list = [\"11\", \"12\", \"13\", \"14\", \"21\", \"22\", \"23\", \"24\"]\n    for num, i in enumerate(range(1, len(quarter_border))):\n        if (number < quarter_border[i]) & (number >= quarter_border[i-1]):\n            return quarter_list[num]\n\ndef week_translation(number):\n    week_border = [0, 7, 14, 21, 31]\n    week_list = [\"1W\", \"2W\", \"3W\", \"4W\"]\n    for num, i in enumerate(range(1, len(week_border))):\n         if (number <= week_border[i]) & (number > week_border[i-1]):\n            return week_list[num]\n\n\n# add year, 12 month, week, and 8 quarter time status\ndef timeExpansion(timeSeries):\n    additional_cols = [\"year\", \"month\", \"quarter\", \"week\"]\n    dummy0 = pd.DataFrame(np.zeros((len(timeSeries), len(additional_cols)), 'int'), \n                         columns=additional_cols, \n                         index=timeSeries.index)\n    \n    dummy0[\"year\"] = [i.year for i in timeSeries]\n    dummy0[\"month\"] = [month_translation(i.month) for i in timeSeries]\n    dummy0[\"day\"] = [week_translation(i.day) for i in timeSeries]\n    dummy0[\"quarter\"] = [quarter_translation(i.hour) for i in timeSeries]\n    return pd.get_dummies(dummy0)\n\ndef predict_and_submit(submit=True):\n    if \"model.pkl\" in files:\n        with open('../model.pkl', 'rb') as fin:\n            estimator = pickle.load(fin)\n    \n    \n    test_df = pd.read_csv('../input/test.csv')\n    add_travel_vector_features(test_df)\n    test_df[\"pickup_datetime\"] = pd.to_datetime(test_df[\"pickup_datetime\"], infer_datetime_format=True)\n    test_X = pd.concat([test_df, timeExpansion(test_df[\"pickup_datetime\"])], axis=1)\n    test_X.drop([\"key\", \"pickup_datetime\"], axis=1, inplace=True)\n\n    print(\"Test Shape: \",test_X.shape)\n\n    # Predict fare_amount on the test set using our model (w) trained on the training set.\n    test_y_predictions = estimator.predict(test_X)\n\n    # Write the predictions to a CSV file which we can submit to the competition.\n    if submit:\n        submission = pd.DataFrame(\n            {'key': test_df.key, 'fare_amount': test_y_predictions},\n            columns = ['key', 'fare_amount'])\n        submission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2190dc797d8a47325692d88d47341cf803b999a9","scrolled":false},"cell_type":"code","source":"#MAIN Execution\ntraining_step = list(np.arange(40_000_000, 55_000_001, 1_000_000))\nestimator = None\norigin_cols = ['key',\n 'fare_amount',\n 'pickup_datetime',\n 'pickup_longitude',\n 'pickup_latitude',\n 'dropoff_longitude',\n 'dropoff_latitude',\n 'passenger_count']\n\nfor i in range(1, len(training_step)):\n    start = time.time()\n    files = os.listdir(\"../\")\n    if \"model.pkl\" in files:\n        with open('../model.pkl', 'rb') as fin:\n            estimator = pickle.load(fin)\n    \n    print(training_step[i-1], training_step[i])\n    train_df = pd.read_csv(\"../input/train.csv\", skiprows=training_step[i-1], nrows=training_step[i])\n    train_df.columns = origin_cols\n    \n    estimator = incremental_learning(train_df, estimator)\n    \n    print(\"Operation\", i, \"took \", time.time() - start, \" \\n\")\n    del train_df\n    with open('../model.pkl', 'wb') as fout:\n        pickle.dump(estimator, fout)\n    del estimator\n    gc.collect()\n    \npredict_and_submit()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80ed89470e25d75c0b99008b9c88861be9739da3"},"cell_type":"markdown","source":"## Ideas for Improvement\nThe output here will score an RMSE of $5.74, but you can do better than that!  Here are some suggestions:\n\n* Use better estimator such as Support Vector Machine, Xtreme Gradient Boosting, and more for capturing dynamics better.\n* Use absolute location data rather than relative.  Here we're only looking at the difference between the start and end points, but maybe the actual values -- indicating where in NYC the taxi is traveling -- would be useful.\n* Try to find more outliers to prune, or construct useful feature crosses.\n* Use the entire dataset -- here we're only using about 20% of the training data!"},{"metadata":{"_uuid":"8fd559ff5ca72a73091d5dfd5b7032522832e999"},"cell_type":"markdown","source":"This kernel based on Getting Started on NYC Taxi Fare Prediction"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}