{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import RidgeClassifier, RidgeClassifierCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom scipy import stats\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom decimal import Decimal as D\n\nsns.set(style = \"darkgrid\")\nxsize = 18.0\nysize = 12.0\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_json(\"../input/train.json\").set_index(\"id\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fad9e27e104057bcce513d4411da7d69fc9866be"},"cell_type":"code","source":"le = LabelEncoder()\ntrain_df[\"cuisine\"] = le.fit_transform(train_df[\"cuisine\"])\n\nx_train, x_valid, y_train, y_valid = train_test_split(train_df[\"ingredients\"], \n                                                      train_df[\"cuisine\"], test_size = 0.33)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e10028ed90dd2d4830fa30ba6feb563f8fd4693c"},"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(analyzer = \"word\", tokenizer = lambda x: x,\n                                  preprocessor = lambda x: x, token_pattern = None)\ntfidf_train = tfidf_vectorizer.fit_transform(x_train)\ntfidf_valid = tfidf_vectorizer.transform(x_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b8f1c616b56f15d3d323f8cda13d47181cfdf79"},"cell_type":"code","source":"ridge_clf = RidgeClassifier(alpha = 1.0, fit_intercept = True, normalize = False, \n                            copy_X = True, max_iter = None, tol = 0.001, class_weight = None, \n                            solver = \"auto\", random_state = None)\nridge_clf.fit(tfidf_train, y_train)\npred_train = ridge_clf.predict(tfidf_train)\npred_valid = ridge_clf.predict(tfidf_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65d65ec719febf69f413d87e69dded16964afc90"},"cell_type":"code","source":"print(\"Train Accuracy: \"+str(accuracy_score(y_train, pred_train)))\nprint(\"Valid Accuracy: \"+str(accuracy_score(y_valid, pred_valid)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b68ffbedee6dc319cdf4913212505941f7ab674","scrolled":false},"cell_type":"code","source":"alphas_array = np.geomspace(1e-6, 1e6, 50)\nnormalize_array = [False, True]\n\ntrain_accuracies = {}\nvalid_accuracies = {}\ndiff_accuracies = {}\n\nfor i, normalize in enumerate(normalize_array):\n    start_time = time.time()\n    print(\"(\"+str(i+1)+\") Starting normalize=\"+str(normalize))\n\n    train_accuracies[str(normalize)] = np.zeros(len(alphas_array))\n    valid_accuracies[str(normalize)] = np.zeros(len(alphas_array))\n\n    for k, alpha in enumerate(alphas_array):\n        start_time2 = time.time()\n        ridge_clf = RidgeClassifier(alpha = alpha, fit_intercept = True, normalize = normalize, \n                                    copy_X = True, max_iter = None, tol = 0.001, class_weight = None, \n                                    solver = \"sag\", random_state = None)\n        ridge_clf.fit(tfidf_train, y_train)\n        pred_train = ridge_clf.predict(tfidf_train)\n        pred_valid = ridge_clf.predict(tfidf_valid)\n        train_accuracies[str(normalize)][k] = accuracy_score(y_train, pred_train)\n        valid_accuracies[str(normalize)][k] = accuracy_score(y_valid, pred_valid)\n        end_time2 = time.time()\n        time_diff2 = end_time2 - start_time2\n        print(\"(\"+str(i+1)+\".\"+str(k+1)+\") Finished alpha=\"+str(\"%.2E\"%D(alpha))+\" in \"+str(\"%.2f\"%time_diff2)+\"s\")\n\n    diff_accuracies[str(normalize)] = np.absolute(train_accuracies[str(normalize)] - valid_accuracies[str(normalize)])\n\n    end_time = time.time()\n    time_diff = end_time - start_time\n    print(\"(\"+str(i+1)+\") Finished normalize=\"+str(\"%.2f\"%normalize)+\" in \"+str(\"%.2f\"%time_diff)+\"s\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e297832a8b02d8166297abe27ff398a5ca5d37f8"},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = len(normalize_array))\nfig.set_size_inches(xsize, len(normalize_array)*ysize)\n\naxes = np.array(axes).flatten()\n\nfor i, normalize in enumerate(normalize_array):\n    axes[i].semilogx(alphas_array, train_accuracies[str(normalize)], \"o:\", label = \"Train\")\n    axes[i].semilogx(alphas_array, train_accuracies[str(normalize)], \"o:\", label = \"Valid\")\n    axes[i].semilogx(alphas_array, diff_accuracies[str(normalize)], \"o:\", label = \"Difference\")\n    axes[i].set_title(\"Accuracy Metrics vs Regularization Strength for normalization=\"+str(normalize))\n    axes[i].set_xlabel(\"Regularization Strength\")\n    axes[i].set_ylabel(\"Accuracy Metrics\")\n    axes[i].legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"723731795cc81492422d497e6fd96653a3880b95"},"cell_type":"code","source":"false_xx = np.argmax(valid_accuracies[str(False)])\ntrue_xx = np.argmax(valid_accuracies[str(True)])\n\nalpha_best_false = alphas_array[false_xx]\ntrain_best_false = train_accuracies[str(False)][false_xx]\nvalid_best_false = valid_accuracies[str(False)][false_xx]\n\nalpha_best_true = alphas_array[true_xx]\ntrain_best_true = train_accuracies[str(True)][true_xx]\nvalid_best_true = valid_accuracies[str(True)][true_xx]\n\nprint(\"For normalize=\"+str(False)+\" alpha=\"+str(alpha_best_false))\nprint(\"Train Accuracy: \"+str(train_best_false))\nprint(\"Valid Accuracy: \"+str(valid_best_false))\nprint(\"\\n\")\nprint(\"For normalize=\"+str(True)+\" alpha=\"+str(alpha_best_true))\nprint(\"Train Accuracy: \"+str(train_best_true))\nprint(\"Valid Accuracy: \"+str(valid_best_true))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac4a633e49b7c55fc2aab51dc248494c4b8a0e03"},"cell_type":"code","source":"ridge_clf_normalize_false = RidgeClassifier(fit_intercept = True, normalize = False, copy_X = True, \n                                            max_iter = None, tol = 0.001, class_weight = None, \n                                            solver = \"auto\", random_state = None)\nparams = {\n    \"alpha\": stats.lognorm(0.8, scale = alpha_best_false)\n}\nfalse_clf = RandomizedSearchCV(ridge_clf_normalize_false, params, scoring = \"accuracy\", cv = 5)\nfalse_clf.fit(tfidf_train, y_train)\nprint(false_clf.best_params_)\n\nridge_clf_normalize_true = RidgeClassifier(fit_intercept = True, normalize = True, copy_X = True, \n                                            max_iter = None, tol = 0.001, class_weight = None, \n                                            solver = \"auto\", random_state = None)\nparams = {\n    \"alpha\": stats.lognorm(0.8, scale = alpha_best_true)\n}\ntrue_clf = RandomizedSearchCV(ridge_clf_normalize_true, params, scoring = \"accuracy\", cv = 5)\ntrue_clf.fit(tfidf_train, y_train)\nprint(true_clf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1314e1aea3e8a6d9718813cb06e3e313aa30bad9"},"cell_type":"code","source":"print(\"For normalize=\"+str(False)+\" alpha=\"+str(false_clf.best_params_[\"alpha\"]))\nprint(\"Train Accuracy: \"+str(false_clf.score(tfidf_train, y_train)))\nprint(\"Valid Accuracy: \"+str(false_clf.score(tfidf_valid, y_valid)))\nprint(\"\\n\")\nprint(\"For normalize=\"+str(True)+\" alpha=\"+str(true_clf.best_params_[\"alpha\"]))\nprint(\"Train Accuracy: \"+str(true_clf.score(tfidf_train, y_train)))\nprint(\"Valid Accuracy: \"+str(true_clf.score(tfidf_valid, y_valid)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e744c0a223ec82d4c20d25d0755eab32bc56174e"},"cell_type":"code","source":"norm = True if true_clf.score(tfidf_valid, y_valid) > false_clf.score(tfidf_valid, y_valid) else False\nalpha = true_clf.best_params_[\"alpha\"] if true_clf.score(tfidf_valid, y_valid) > false_clf.score(tfidf_valid, y_valid) else false_clf.best_params_[\"alpha\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe5a1743c4aab8170d8b0b62ab40c8edf4442dee"},"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(analyzer = \"word\", tokenizer = lambda x: x,\n                                  preprocessor = lambda x: x, token_pattern = None)\ntfidf_train = tfidf_vectorizer.fit_transform(train_df[\"ingredients\"])\ny_train = train_df[\"cuisine\"]\n\nridge_clf = RidgeClassifier(alpha = 1.0, fit_intercept = True, normalize = norm, \n                            copy_X = True, max_iter = None, tol = 0.001, class_weight = None, \n                            solver = \"auto\", random_state = None)\nridge_clf.fit(tfidf_train, y_train)\n\ntest_df = pd.read_json(\"../input/test.json\").set_index(\"id\")\ntfidf_test = tfidf_vectorizer.transform(test_df[\"ingredients\"])\ntest_df[\"cuisine\"] = ridge_clf.predict(tfidf_test)\ntest_df[\"cuisine\"] = le.inverse_transform(test_df[\"cuisine\"])\ntest_df.drop(columns = [\"ingredients\"], inplace = True)\ntest_df.to_csv(\"optimized_ridge_classifier_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f75ba8c38659a2b06bf9455c3ee7ca3c464b8596"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}