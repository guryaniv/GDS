{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "38b57db4-25fe-2b48-2a9a-bc6eacf152f0"
      },
      "source": [
        "The goal of this notebook is to showcase the strength of random forest. We found that this algorithm is especially suitable for this data set, returning 100% accuracy. There are several reasons that we come up with as to why this is the case:\n",
        "1) The data set strongly depends on a subset of features with clear separation between the positive and negative samples. This makes decision tree based methods an obvious approach because they readily divide the space without heuristic kernels (such as used in svm based methods)\n",
        "2) The imbalance of the data set is handled very well by random forest. This is not the case with decision tree because it tends to overfit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2bd3ad8c-a0c5-323f-d766-61791e8dd9d5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pl\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3f026a6c-412d-e8ad-03bc-e97b3732ace6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../input/creditcard.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5bddbf2d-a97e-4f96-f1ab-948ebdadfc97"
      },
      "source": [
        "Looking at some features(esp. V1 - V28), we see that most features were already normalized, so there is no need to process data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b27eb9f8-d491-eaee-ce4d-41cf6f2328a7"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1eb76371-01bf-03b3-30f8-82d52af05366"
      },
      "source": [
        "The data set is very skewed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d9944907-3d39-057c-89dc-c2cef4af1db8"
      },
      "outputs": [],
      "source": [
        "df.groupby(by='Class').apply(len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "82aff42d-0fbf-8286-4fe1-18f135b030ae"
      },
      "source": [
        "This is the central idea of this notebook. We use scikit-learn's implementation of random forest to show relative importance of features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ea630566-07f8-7c88-aeb5-35eca4810dde"
      },
      "outputs": [],
      "source": [
        "from sklearn import ensemble\n",
        "\n",
        "deci = ensemble.RandomForestClassifier()\n",
        "deci.fit(df.iloc[:, 0:30], df.Class)\n",
        "importances = deci.feature_importances_\n",
        "sorted_idx = np.argsort(importances)\n",
        "\n",
        "padding = np.arange(30) + 0.5\n",
        "pl.barh(padding, importances[sorted_idx], align='center')\n",
        "pl.yticks(padding, df.columns[sorted_idx])\n",
        "pl.xlabel(\"Relative Importance\")\n",
        "pl.title(\"Variable Importance\")\n",
        "pl.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1876bd69-f80b-80fd-e56d-aebdb33f18d7"
      },
      "source": [
        "Here we see that V17 decreases the most entropy, and hence the most useful when splitting the plane. This is actually not absolute though because features are selected at random when building random forest. In contrast, decision tree will indeed select splitting features in order of most useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "055a4c62-b4bf-0d18-8bc3-924b2c20ab5f"
      },
      "source": [
        "Here are some plots to show relative usefulness of features in decreasing order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "985a0ca9-9f7a-ea8d-e87e-3f8460861574"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "for feature in ['V14', 'V10', 'V17', 'V26', 'V7', 'V20']:\n",
        "    pl.title(feature)\n",
        "    sns.distplot(df[feature][df.Class==1])\n",
        "    sns.distplot(df[feature][df.Class==0])\n",
        "    pl.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "12c802fc-57fd-48ec-fe3f-1781dd5b84ab"
      },
      "source": [
        "As evident, we will use only top 6 features "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2e93a5df-223f-1a3a-a1ec-ee321dfbd009"
      },
      "outputs": [],
      "source": [
        "all_features = ['V7', 'V10', 'V18', 'V4', 'V9', 'V16', 'V14', 'V11', 'V17', 'V12', 'Class']\n",
        "features = ['V7', 'V10', 'V18', 'V4', 'V9', 'V16', 'V14', 'V11', 'V17', 'V12']\n",
        "truncated = df[all_features]\n",
        "truncated.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "84a17510-7b41-c662-f818-c0691574149f"
      },
      "source": [
        "Because of the imbalance, we give the test set and data set equal ratio of positive/negative samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3cc3fe10-090d-ca35-7b84-626e440353a1"
      },
      "outputs": [],
      "source": [
        "positive = truncated[truncated.Class==1]\n",
        "negative = truncated[truncated.Class==0]\n",
        "test_set = pd.concat((positive.iloc[::2, :], negative.iloc[::2, :]), axis=0)\n",
        "train_set = pd.concat((positive.iloc[1::2, :], negative.iloc[1::2, :]), axis=0)\n",
        "#shuffling\n",
        "print(test_set.tail(2))\n",
        "test_set = test_set.sample(frac=1).reset_index(drop=True)\n",
        "print(test_set.tail(2))\n",
        "train_set = train_set.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e97c6efe-8000-057f-5c08-33fcec1c6bf3"
      },
      "outputs": [],
      "source": [
        "print(test_set.groupby(df.Class).apply(len))\n",
        "print(train_set.groupby(df.Class).apply(len))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2a8b8278-22c9-4b8d-decb-00035beb6b11"
      },
      "source": [
        "Train and test with various methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d893728e-e715-4495-8905-ce6aae9d4dc0"
      },
      "outputs": [],
      "source": [
        "def train_and_test_with(mlfunc_list):\n",
        "    for func, name in mlfunc_list:\n",
        "        func.fit(train_set[features], train_set.Class)\n",
        "        print(name+'\\n', pd.crosstab(test_set.Class, func.predict(test_set[features])), '\\n')\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn import tree\n",
        "train_and_test_with([(ensemble.RandomForestClassifier(), 'random forest'), (ensemble.AdaBoostClassifier(), 'adaptive boosting'),\n",
        "                     (ensemble.BaggingClassifier(), 'bagging'), (ensemble.ExtraTreesClassifier(), 'extra tree'),\n",
        "                     (ensemble.GradientBoostingClassifier(), 'gradient boosting')])\n",
        "\n",
        "train_and_test_with([(tree.DecisionTreeClassifier(), 'decision tree'), (svm.SVC(), 'support vector machine')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "59faed1b-91db-672c-5ee7-127cb54612c7"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}