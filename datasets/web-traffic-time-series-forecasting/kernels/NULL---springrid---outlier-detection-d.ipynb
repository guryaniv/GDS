{"metadata": {"language_info": {"file_extension": ".py", "nbconvert_exporter": "python", "name": "python", "version": "3.5.2", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}, "anaconda-cloud": {}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "070bde90-d173-4607-bbaa-d1e295467668", "_uuid": "c58b9f3ea430f8bb4faa34f4ebd46e4381f78bbe"}, "source": "# Web Traffic Forecasting - Outlier Detection \n### by Springrid, Sweden :)", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "986fcbce-a5cd-4eb2-883f-7595780e58fe", "_uuid": "e0e78161a2f2dac53feeeb3393b382c2ed81c638"}, "source": "Table of Contents: \n* 1 Introduction\n    * 1.1 Load Data and Packages\n* 2 Outlier Detection\n    * 2.1 Language Trends\n        * 2.2.1 Fourier Transform Analysis\n    * 2.2 Apple Inc vs Others", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "472eedec-37d0-4888-96d5-dee0d1881fdd", "_uuid": "4f34e1ab47ca726429cdf8ea1dab53b36827f1e6"}, "source": "## 1 Introduction\nThis notebook is an exploration of the data from the Kaggle Web Traffic Forecasting competition. \n\nDataset is found here: https://www.kaggle.com/c/web-traffic-time-series-forecasting/data. The data set contains timeseries data of 145k Wikipedia pages with number of page visits per day during the time period of July, 1st, 2015 up until December 31st, 2016.\n\n### 1.1 Load Data and Packages\nI start by loading the necessary packages and data. I replace missing values with zeros for simplicity.", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "b6bdf9c6-2513-470c-a78b-5f6970aeeeb2", "_uuid": "bcdc8326e52d2db39986067e6581dce90c33fa4f", "collapsed": false}, "source": "%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport re\nimport os\nimport math\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport multiprocessing as mp\nfrom datetime import datetime\nfrom collections import Counter\nfrom scipy.fftpack import fft\n\nfrom fbprophet import Prophet\nfrom statsmodels.tsa.arima_model import ARIMA\nimport warnings\n\nkaggle_on = True\n\nif kaggle_on:\n    path = '../input/'\nelse:\n    path = 'data/'\n\ndf_train = pd.read_csv(path + 'train_1.csv', nrows=150000)\n\nnull_df = df_train.isnull().sum(axis=1)\ndf_train = df_train.fillna(0)\nprint('Len of data: ', len(df_train.index))\nprint('Number of pages with nan values: ', len(null_df[null_df > 0]))\nprint('Number of pages with all nan values: ', len(null_df[null_df == len(df_train.columns)-1]))", "outputs": [], "execution_count": 1}, {"cell_type": "markdown", "metadata": {"_cell_guid": "67f5824d-3085-4d94-bcdd-d6818c2d90f3", "_uuid": "f921dc8b3ee3009b900b0c80a9ee9a401db1f16b"}, "source": "In idea to handle missing values would be to forward fill with rolling average over previous 7 days no. of visits. For simplicity however, I will just replace all nan's with zeros for now.\n\nConvert all page view counts to integers to save memory.", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "039360ab-9cb9-41f5-a113-1c2169e21571", "_uuid": "7405b6ccd1d9a9cfd4b22e8458922200e95af4ea", "collapsed": true}, "source": "# Convert page views to integers\nfor col in df_train.columns[1:]:\n    df_train[col] = pd.to_numeric(df_train[col], downcast='integer')", "outputs": [], "execution_count": 2}, {"cell_type": "markdown", "metadata": {"_cell_guid": "0dc38184-af69-41da-a514-b88924f4ccc7", "_uuid": "1854493f28548829a4c86cc47bc7ed6341d40770"}, "source": "## 2 Outlier Detection\nTry to filter out som outliers. :)\n\n### 2.1 Apple Inc vs. Others\nGet and prepare data.", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "8c957035-44c4-46c4-9b5f-a69e04d17525", "_uuid": "8bc9ced63344ed74f74037ccffd145e5d350a9cd", "collapsed": false}, "source": "cols = df_train.columns[1:-1]\n\ndef filter_df(df, word):\n    df_new = df[df['Page'].str.contains(word)]\n    apple_pages = df_new.Page.values\n    df_new = df_new[cols].transpose()\n    df_new[word] = df_new.values.sum(axis=1)\n    return df_new[[word]]\n\nword_to_filter_by = ['Apple_Inc', 'Microsoft', 'Facebook', 'Google']\n\ndf_companies = pd.DataFrame()\nfor word in word_to_filter_by:\n    df_tmp = filter_df(df_train, word)\n    df_companies = pd.concat([df_companies, df_tmp], axis=1)\n\nprint(df_companies.idxmax(axis=0))\ndf_companies.plot()\n\n# mark Apple releases and other important dates during time period\nif False:\n    holidays = ['2015-11-26', '2015-12-25']\n    stock_dates = ['2016-08-10']\n    apple_dates = ['2015-07-15', '2015-09-09', '2015-09-25', '2015-10-13', '2015-10-26', '2015-11-11',\n                  '2016-03-31', '2016-04-19', '2016-09-16', '2016-10-27', '2016-12-19']\n    for date in holidays + stock_dates:\n        plt.axvline(df_companies.index.get_loc(date), color='black', linestyle='solid')\nplt.show()    ", "outputs": [], "execution_count": 3}, {"cell_type": "markdown", "metadata": {"_cell_guid": "7d99bd7a-cd27-428a-8818-6b15156904b4", "_uuid": "ef91201e44af53a8e2e3e89cce8c667c9edd396b"}, "source": "### 2.2 Filter Data and Plot w/ and w/o Outliers\nPlot histogram for each company and filter out some outliers. Compare results, looks promesing!", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "c92c6496-e81b-4d48-ba9b-75937f653b21", "_uuid": "fbaea44f147067e091ac8fd3fc40760d12efbbd7", "collapsed": false}, "source": "for col in df_companies.columns:\n    print(col)\n    fig, (ax0, ax1) = plt.subplots(nrows=2)\n    df_companies[col].hist(bins=100, ax=ax0)\n    q = df_companies[col].quantile(0.99)\n    df_companies_filt = df_companies[df_companies[col] < q]\n    df_companies_filt[col].hist(bins=100)\n    \n    fig, (ax00, ax11) = plt.subplots(nrows=2)\n    df_companies[col].plot(ax=ax00)\n    df_companies_filt[col].plot(ax=ax11)\n    plt.show()", "outputs": [], "execution_count": 4}, {"cell_type": "markdown", "metadata": {"_cell_guid": "156117f7-ccc6-4a5f-9f07-931ccd61a801", "_uuid": "b84eede15056936c1cb1024e7a3b991702f0a2cf"}, "source": "In the plots above, we see that we catch a lot of outliers quite nicely. \n\nFor each company keyword: \n* Plot 1 - histogram of original data\n* Plot 2 - histogram after outlier removal\n* Plot 3 - time series plot of original data\n* Plot 4 - time series plot after ouliter removal\n\nFor Apple, we got rid of the large spike at the beginning of 2016, the histogram show that the values lie in a closer range as expected as well. For Microsoft, we still have a couple of suspected outliers but not as many as before. The Facebook data still shows some larger values and the spikes are still there. Some more work and fine-tuning is needed here in order to get rid of them completely. However, it does look slightly better than before the filering. Finally, the Google data, not to much of a difference. Most importantly, we lost the big spike around late August 2016, yey!", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "94ee1f55-6f6f-4e6f-9320-f5f7b8d7b6d0", "_uuid": "8b22f77b34720f44ca1c280c6ccc0bf6636e5b89", "collapsed": true}, "source": "", "outputs": [], "execution_count": null}], "nbformat_minor": 1, "nbformat": 4}