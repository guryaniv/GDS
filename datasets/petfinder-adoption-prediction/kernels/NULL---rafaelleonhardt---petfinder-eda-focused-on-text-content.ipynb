{"cells":[{"metadata":{"_uuid":"c497f9d8717b5cfc68f1fb0ffcd5945a3b1ae972"},"cell_type":"markdown","source":"# Exploratory Data Analysis focused on text content\n\nIn this kernel I will explore the available text data for PetFinder.com competition.\n\nThe objective is to get any insights from available text content."},{"metadata":{"_uuid":"3243c6ef0ddfa5c56a3ec5dd353e1022aed84c51"},"cell_type":"markdown","source":"## Text data source\n\nWe have some text content into:\n* **Description** feature (train.csv): a short description about the pet.\n\n\n## Definitions\n\nThe following terms are used in this kernel:\n* Corpus: a corpus (plural corpora) or text corpus is a large and structured set of texts.\n* n-gram: a fragment of text consisting of 1 to n words, considering an n-gram as a single unit.\n* Unigram: a 1-gram (e.g. “cuteness”)\n* Bigram: a 2-gram (e.g. “Guard dog”).\n* Trigram is a 3-gram (e.g. “Domestic Short Hair”).\n* Term Frequency: summarizes how often a given word appears within a document.\n* Inverse Document Frequency: downscales words that appear a lot across documents.\n* TF-IDF: short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. \n* Stop words: are some of the most common, short function words, such as the, is, at, which, and on. Usually we remove them from our text input."},{"metadata":{"_uuid":"1403ff9b37470394ef70eb3fc414ce620f3d93b0"},"cell_type":"markdown","source":"## Import libraries\n\nSome libraries like sklearn to help us into the text analysis. "},{"metadata":{"trusted":true,"_uuid":"69b38aca518bc9034fd13382c0e8fad331d3b6e5","_kg_hide-input":true},"cell_type":"code","source":"# For TF-IDF\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom nltk.corpus import stopwords ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62b4acd6938019772f55c13fe1fc8ce80a9a7e0d","_kg_hide-input":true},"cell_type":"code","source":"# For Word Count Visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input/train\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e03df99cc3f9676105f683e9ed5e8df13bca0bb"},"cell_type":"markdown","source":"## About the data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true,"_kg_hide-input":true},"cell_type":"code","source":"# loading CSV data to check the Description content\ntrain_csv = pd.read_csv(\"../input/train/train.csv\")\ntrain_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7bb6a6eb4d044b5fbcb39937df1b36b0fcf82b31"},"cell_type":"markdown","source":"### Showing 20 random description samples"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"084b43418384200ec8858909905bccd3b8708456"},"cell_type":"code","source":"train_csv.sample(20).Description","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec7583d4c3065f4a5c2e5b8b80cd4699802caa2d"},"cell_type":"markdown","source":"### Non-english text content\n\nSome descriptions are not in English language, so we will need to clean it for the analysis."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"f548cb6cc1d51dc0fd1b803c589dc464575dfb50"},"cell_type":"code","source":"train_csv.loc[[6440,10779]].Description","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7089840b13edd1cc1890772d8a9cf963a6cd41e8"},"cell_type":"markdown","source":"### Removing records without Description"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"f77cb3d70babbca507961795ebe6cc6fdf13f4a9"},"cell_type":"code","source":"print('There are ' + str(len(train_csv[train_csv.Description.isna()])) + ' records without description. They were removed!')\ntrain_csv.dropna(subset=['Description'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93950047977eb95f711c5031ae74e5a7860d491b"},"cell_type":"markdown","source":"# Words Count\n\nShowing the words count from Description content."},{"metadata":{"trusted":true,"_uuid":"0c671e283a8b6933172adccb3bddc21ae4fea09d","_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"def get_top_n_words(corpus, n=None):\n    \"\"\"\n    List the top n words in a vocabulary according to occurrence in a text corpus.\n    \"\"\"\n    vec = CountVectorizer(\n            strip_accents='unicode',\n            analyzer='word',\n            token_pattern=r'\\w{3,}', # vectorize 3-character words or more\n            stop_words='english',\n            ngram_range=(1, 2),\n            max_features=30000\n        ).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\nwords_count_by_adoption_speed = []\nfor adoption_speed in range(5):\n    descriptions_by_adoption_speed = train_csv[train_csv.AdoptionSpeed == adoption_speed].Description\n    top_words = get_top_n_words(descriptions_by_adoption_speed, 25)\n    words_count_by_adoption_speed.append(pd.DataFrame(top_words, columns = ['Word', 'Count'])) \n    words_count_by_adoption_speed[adoption_speed].plot.bar(x='Word',y='Count',title=\"Top 25 words X Adoption Speed \" + str(adoption_speed))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d73394127c7f4d49d75839b0b99d7de921d3220"},"cell_type":"markdown","source":"# to be continued...\n\nWe can explore tecniques like stemming to improve\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}