{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a41eff60-1a01-3124-d01f-eff10e0ead95"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import keras\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "        \n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1b81cf5c-e3dc-5c41-ba48-7956c5769864"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('../input/train.csv').values.astype('float32')\n",
        "train_images = train_data[:,1:]\n",
        "train_labels = train_data[:,0].astype('int32')\n",
        "\n",
        "test_images = pd.read_csv('../input/test.csv').values.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8b3409e5-d70f-c3d5-3c16-5e384c9bdfe7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, train_size=0.8, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9474afdc-f21f-a209-8a23-3879a04e4350"
      },
      "outputs": [],
      "source": [
        "print(np.shape(train_images))\n",
        "print(np.shape(val_images))\n",
        "print(np.shape(train_labels))\n",
        "print(np.shape(val_labels))\n",
        "print(np.shape(test_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "209aba5e-9202-4e52-ec7e-ff8df6560641"
      },
      "outputs": [],
      "source": [
        "sample_images = train_images.reshape(train_images.shape[0], 28,28)\n",
        "for i in range(1,6):\n",
        "    plt.subplot(1,6,i)\n",
        "    plt.axis('off')\n",
        "    plt.set_cmap('gray')\n",
        "    plt.title(train_labels[i])\n",
        "    plt.imshow(sample_images[i])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "95bd2ffd-b1bb-7594-96f1-b3a7865b9cb6"
      },
      "outputs": [],
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)\n",
        "val_labels = to_categorical(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4d196d75-f357-2a8b-760a-9c20427bb5ea"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_generator = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=10.,\n",
        "               \n",
        ")\n",
        "\n",
        "val_data_generator = ImageDataGenerator(\n",
        "        rescale=1./255     \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "83a699c0-5c3f-c5e1-fd35-f61e89f7cfff"
      },
      "outputs": [],
      "source": [
        "np.random.seed(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "280c05c8-f046-341c-9559-f67bfabdfbc7"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "816b3c07-5aa8-4963-a720-5b9a00a58166"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Flatten, Activation\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import regularizers\n",
        "\n",
        "#Reshapa data from, 2-Dimension into 4-Dimension\n",
        "train_images = train_images.reshape(-1,28,28,1)\n",
        "val_images = val_images.reshape(-1,28,28,1)\n",
        "\n",
        "print(train_images.shape)\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=[3,3], input_shape=(28,28,1),\n",
        "                 padding=\"SAME\", kernel_initializer='he_normal', \n",
        "                 kernel_regularizer=regularizers.l2(1e-8)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(activation='relu'))\n",
        "print(model.output_shape)\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "print(model.output_shape)\n",
        "\n",
        "\n",
        "\n",
        "model.add( Conv2D( filters=80, kernel_size=[3,3], padding=\"SAME\", kernel_initializer='he_normal', \n",
        "                 kernel_regularizer=regularizers.l2(1e-8)\n",
        "                 ))          \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(activation='relu'))\n",
        "print(model.output_shape)\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "print(model.output_shape)\n",
        "\n",
        "model.add( Conv2D( filters=32, kernel_size=[3,3], padding=\"SAME\", kernel_initializer='he_normal', \n",
        "                 kernel_regularizer=regularizers.l2(1e-8)))          \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(activation='relu'))\n",
        "print(model.output_shape)\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "print(model.output_shape)\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "print(model.output_shape)\n",
        "     \n",
        "          \n",
        "model.add( Dense(units=100, activation='relu', kernel_initializer='he_normal'))\n",
        "print(model.output_shape)         \n",
        "\n",
        "          \n",
        "model.add( Dense(units=10, activation='softmax', kernel_initializer='he_normal'))\n",
        "print(model.output_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a4d85e51-efe1-be81-4dfd-6d1376c7b67d"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "adam = optimizers.Nadam(0.003)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "Check=[EarlyStopping(monitor='val_acc', min_delta=0.00001, patience=2, verbose=1, mode='auto'), \n",
        "       ModelCheckpoint(filepath=\"/tmp/model.hdf5\" , monitor='val_acc', verbose=2, save_best_only=True, mode='max')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4f726812-bdb9-90ef-61d8-d3bbf75fb8e8"
      },
      "outputs": [],
      "source": [
        "\n",
        "BATCH_SIZE = 25\n",
        "\n",
        "\n",
        "hist = model.fit_generator(data_generator.flow(train_images, train_labels, batch_size=BATCH_SIZE),\n",
        "             validation_data=val_data_generator.flow(val_images, val_labels, batch_size=BATCH_SIZE),\n",
        "             steps_per_epoch=len(train_images)/(BATCH_SIZE), validation_steps=len(val_images)/(BATCH_SIZE), epochs=3,callbacks=Check, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "452103ea-5b0b-93cf-b6f0-a733b1c6103e"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "saved_model =  load_model('/tmp/model.hdf5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "927f7560-01d7-239a-2ea6-d079f793c728"
      },
      "outputs": [],
      "source": [
        "print(hist.history.keys())\n",
        "plt.plot(hist.history['loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "250b58bc-0cca-2c45-eddf-8ab824d2161a"
      },
      "outputs": [],
      "source": [
        "test_images = test_images/255\n",
        "predictions = model.predict_classes(test_images.reshape(test_images.shape[0], 28, 28, 1), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "805b0307-111f-2f99-76d8-c97af8c993a0"
      },
      "outputs": [],
      "source": [
        "print(\"Predicted Samples are : \", predictions[:10])\n",
        "\n",
        "sample_test_images = test_images.reshape(test_images.shape[0], 28,28)\n",
        "      \n",
        "for i in range(10):\n",
        "    plt.subplot(1, 11, i+1)\n",
        "    plt.axis('off')\n",
        "    plt.set_cmap('gray')\n",
        "    plt.title(predictions[i])\n",
        "    plt.imshow(sample_test_images[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c8ce27d3-afae-54f7-56c3-f7e7f4d03c75"
      },
      "outputs": [],
      "source": [
        "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
        "                         \"Label\": predictions})\n",
        "submissions.to_csv(\"submission.csv\", index=False, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c9fe1d83-0705-e6a8-3d14-70921c4ab29a"
      },
      "outputs": [],
      "source": [
        "submissions.head()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}