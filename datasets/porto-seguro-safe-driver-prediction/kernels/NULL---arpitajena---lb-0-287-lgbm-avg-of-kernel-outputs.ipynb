{"cells": [{"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "64e96e6415e0907fe61a30fb7160fdd919816394", "collapsed": true, "_cell_guid": "ce51fab9-ab99-4a32-b20f-e1d5f3e495a4"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "4cceda5f1827757fee54746fc7b4b1ab15c07fa1", "collapsed": true, "_cell_guid": "9877d530-d0e6-4268-84b5-a1aa29f19c8b"}, "source": ["from sklearn.model_selection import StratifiedKFold\n", "from sklearn.model_selection import cross_val_score\n", "\n", "from lightgbm import LGBMClassifier\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n", "\n", "from rgf import *     # https://github.com/fukatani/rgf_python\n", "\n", "train = pd.read_csv('../input/porto-seguro-safe-driver-prediction/train.csv')\n", "test = pd.read_csv('../input/porto-seguro-safe-driver-prediction/test.csv')\n"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "6d2eb41e27dd875e9c49c7cccc8aaeab6306ddae", "collapsed": true, "_cell_guid": "3616c450-7be0-4be5-a684-2c9cae049c4e"}, "source": ["# The lgbm part of the code is infuenced by https://www.kaggle.com/yekenot/simple-stacker-lb-0-284\n", "# with a little modification\n", "# The output of this model is available under Input datasets section\n", "# Preprocessing \n", "id_test = test['id'].values\n", "target_train = train['target'].values\n", "\n", "train = train.drop(['target','id'], axis = 1)\n", "test = test.drop(['id'], axis = 1)\n", "\n", "col_to_drop = train.columns[train.columns.str.startswith('ps_calc_')]\n", "train = train.drop(col_to_drop, axis=1)  \n", "test = test.drop(col_to_drop, axis=1)  \n", "\n", "train = train.replace(-1, np.nan)\n", "test = test.replace(-1, np.nan)\n", "\n", "cat_features = [a for a in train.columns if a.endswith('cat')]\n", "\n", "for column in cat_features:\n", "\ttemp = pd.get_dummies(pd.Series(train[column]))\n", "\ttrain = pd.concat([train,temp],axis=1)\n", "\ttrain = train.drop([column],axis=1)\n", "    \n", "for column in cat_features:\n", "\ttemp = pd.get_dummies(pd.Series(test[column]))\n", "\ttest = pd.concat([test,temp],axis=1)\n", "\ttest = test.drop([column],axis=1)\n", "\n", "print(train.values.shape, test.values.shape)\n"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "92f0e9db0afea6020fb89343ef6bc154d06ed510", "collapsed": true, "_cell_guid": "5c5c18da-2e43-4e46-b50b-ec1f4d3a3516"}, "source": ["class Ensemble(object):\n", "    def __init__(self, n_splits, stacker, base_models):\n", "        self.n_splits = n_splits\n", "        self.stacker = stacker\n", "        self.base_models = base_models\n", "\n", "    def fit_predict(self, X, y, T):\n", "        X = np.array(X)\n", "        y = np.array(y)\n", "        T = np.array(T)\n", "\n", "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=2016).split(X, y))\n", "\n", "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n", "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n", "        for i, clf in enumerate(self.base_models):\n", "\n", "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n", "\n", "            for j, (train_idx, test_idx) in enumerate(folds):\n", "                X_train = X[train_idx]\n", "                y_train = y[train_idx]\n", "                X_holdout = X[test_idx]\n", "#                y_holdout = y[test_idx]\n", "\n", "                print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n", "                clf.fit(X_train, y_train)\n", "#                cross_score = cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc')\n", "#                print(\"    cross_score: %.5f\" % (cross_score.mean()))\n", "                y_pred = clf.predict_proba(X_holdout)[:,1]                \n", "\n", "                S_train[test_idx, i] = y_pred\n", "                S_test_i[:, j] = clf.predict_proba(T)[:,1]\n", "            S_test[:, i] = S_test_i.mean(axis=1)\n", "\n", "        results = cross_val_score(self.stacker, S_train, y, cv=3, scoring='roc_auc')\n", "        print(\"Stacker score: %.5f\" % (results.mean()))\n", "\n", "        self.stacker.fit(S_train, y)\n", "        res = self.stacker.predict_proba(S_test)[:,1]\n", "        return res"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "c419c7ee3724ba603192f170076cc7cbbe9b89a5", "collapsed": true, "_cell_guid": "439bb52e-07ad-4a16-8e1e-e2e24be38a6a"}, "source": ["# LightGBM params\n", "lgb_params = {}\n", "lgb_params['learning_rate'] = 0.02\n", "lgb_params['n_estimators'] = 650\n", "lgb_params['max_bin'] = 10\n", "lgb_params['subsample'] = 0.8\n", "lgb_params['subsample_freq'] = 10  \n", "lgb_params['min_child_samples'] = 500\n", "lgb_params['feature_fraction'] = 0.9\n", "lgb_params['bagging_freq'] = 1\n", "lgb_params['seed'] = 200\n", "\n", "lgb_params2 = {}\n", "lgb_params2['n_estimators'] = 1090\n", "lgb_params2['learning_rate'] = 0.02   \n", "lgb_params2['subsample'] = 0.7\n", "lgb_params2['subsample_freq'] = 2\n", "lgb_params2['num_leaves'] = 16\n", "lgb_params2['feature_fraction'] = 0.8\n", "lgb_params2['bagging_freq'] = 1\n", "lgb_params2['seed'] = 200\n", "\n", "\n", "lgb_params3 = {}\n", "lgb_params3['n_estimators'] = 1100\n", "lgb_params3['max_depth'] = 4\n", "lgb_params3['learning_rate'] = 0.02\n", "lgb_params3['feature_fraction'] = 0.95\n", "lgb_params3['bagging_freq'] = 1\n", "lgb_params3['seed'] = 200"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "f89c8c9afd176f62169f2218d3bfb628c4adb63e", "collapsed": true, "_cell_guid": "a4b8ffcc-74a3-4877-9f6f-a1290478cd47"}, "source": ["lgb_model = LGBMClassifier(**lgb_params)\n", "\n", "lgb_model2 = LGBMClassifier(**lgb_params2)\n", "\n", "lgb_model3 = LGBMClassifier(**lgb_params3)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_kg_hide-output": true, "_uuid": "6879edbcebec166584b455f838459631a35cfad7", "collapsed": true, "_cell_guid": "fb731ac0-5019-4354-b351-074dbb1161e9"}, "source": ["log_model = LogisticRegression()\n", "       \n", "stack = Ensemble(n_splits=6,\n", "        stacker = log_model,\n", "        base_models = (lgb_model, lgb_model2, lgb_model3))        \n", "        \n", "y_pred = stack.fit_predict(train, target_train, test)        \n", "\n", "sub_1 = pd.DataFrame()\n", "sub_1['id'] = id_test\n", "sub_1['target'] = y_pred"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "8de47079736e03e1e9a26132f4999daf547d68a1", "collapsed": true, "_cell_guid": "24ad6727-da97-4561-ade1-186b5df4cff7"}, "source": ["# All these datasets are from different kaggle kernels\n", "stacked_1 = pd.read_csv('../input/input-datasets/stacked_1.csv')\n", "xgb_submit = pd.read_csv('../input/input-datasets/xgb_submit_1.csv')\n", "Froza_and_Pascal = pd.read_csv('../input/input-datasets/Froza_and_Pascal.csv')\n", "rgf_submit = pd.read_csv('../input/input-datasets/rgf_submit.csv')\n", "gpari = pd.read_csv('../input/input-datasets/gpari.csv')\n", "\n", "# Ensemble and create submission \n", "\n", "sub = pd.DataFrame()\n", "sub['id'] = stacked_1['id']\n", "sub['target'] = np.exp(np.mean(\n", "\t[\t\n", "    sub_1['target'].apply(lambda x: np.log(x)),\\\n", "    Froza_and_Pascal['target'].apply(lambda x: np.log(x)),\\\n", "    rgf_submit['target'].apply(lambda x: np.log(x)),\\\n", "    gpari['target'].apply(lambda x: np.log(x)),\\\n", "\tstacked_1['target'].apply(lambda x: np.log(x)),\\\n", "\txgb_submit['target'].apply(lambda x: np.log(x))\\\n", "\t], axis =0))\n", "\n", "sub.to_csv('sub.csv.gz', index = False, compression = 'gzip')"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "97ac9ad3a0c3bd681c06f47c12baf2731ce9b0c8", "collapsed": true, "_cell_guid": "3c15d915-e97d-4ff9-b19f-65675f03f8fd"}, "source": [], "outputs": []}], "nbformat_minor": 1, "nbformat": 4, "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"file_extension": ".py", "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "version": "3.6.3"}}}