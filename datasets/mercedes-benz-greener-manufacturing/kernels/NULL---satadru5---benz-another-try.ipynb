{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d317244d-eb04-2370-5456-1fa627fe08e9"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.pipeline import make_pipeline, Pipeline, _name_estimators\n",
        "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import r2_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "51baf0af-6257-8593-c1af-04b7cf85a4fd"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')\n",
        "\n",
        "y_train = train['y'].values\n",
        "id_test = test['ID']\n",
        "num_train = len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "754dad7d-2ae7-9c13-3b9c-a39740a2f3b6"
      },
      "outputs": [],
      "source": [
        "df_all = pd.concat([train, test])\n",
        "df_all.drop(['y'], axis=1, inplace=True)\n",
        "\n",
        "# One-hot encoding of categorical/strings\n",
        "df_all = pd.get_dummies(df_all, drop_first=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b8ee6b53-3934-4f0c-f7b6-711c42d4d7d1"
      },
      "outputs": [],
      "source": [
        "df_all.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "86cee2a0-086c-5865-5f03-8861e4609d7e"
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "427b7c42-f9ea-12b4-8f06-d63b400802ed"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA, FastICA\n",
        "n_comp = 10\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=n_comp, random_state=42)\n",
        "pca2_results_train = pca.fit_transform(df_all)\n",
        "#pca2_results_test = pca.transform(test)\n",
        "\n",
        "# ICA\n",
        "ica = FastICA(n_components=n_comp, random_state=42)\n",
        "ica2_results_train = ica.fit_transform(df_all)\n",
        "#ica2_results_test = ica.transform(test)\n",
        "\n",
        "# Append decomposition components to datasets\n",
        "for i in range(1, n_comp+1):\n",
        "    df_all['pca_' + str(i)] = pca2_results_train[:,i-1]\n",
        "    #test['pca_' + str(i)] = pca2_results_test[:, i-1]\n",
        "    \n",
        "    df_all['ica_' + str(i)] = ica2_results_train[:,i-1]\n",
        "    #test['ica_' + str(i)] = ica2_results_test[:, i-1]\n",
        "    \n",
        "#y_train = train[\"y\"]\n",
        "y_mean = np.mean(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0ed2d629-0e59-603f-32d6-1866c78a6ae5"
      },
      "outputs": [],
      "source": [
        "train = df_all[:num_train]\n",
        "test = df_all[num_train:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7e0a251d-5168-d6e6-04a7-c21544f38dad"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# prepare dict of params for xgboost to run with\n",
        "xgb_params = {\n",
        "    'n_trees': 500, \n",
        "    'eta': 0.005,\n",
        "    'max_depth': 4,\n",
        "    'subsample': 0.95,\n",
        "    'objective': 'reg:linear',\n",
        "    'eval_metric': 'rmse',\n",
        "    'base_score': y_mean, # base prediction = mean(target)\n",
        "    'silent': 1\n",
        "}\n",
        "\n",
        "# form DMatrices for Xgboost training\n",
        "dtrain = xgb.DMatrix(train, y_train)\n",
        "dtest = xgb.DMatrix(test)\n",
        "\n",
        "# xgboost, cross-validation\n",
        "cv_result = xgb.cv(xgb_params, \n",
        "                   dtrain, \n",
        "                   num_boost_round=2000, # increase to have better results (~700)\n",
        "                   early_stopping_rounds=50,\n",
        "                   verbose_eval=50, \n",
        "                   show_stdv=False\n",
        "                  )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "954bc712-1b33-931f-84de-b3579820a82b"
      },
      "outputs": [],
      "source": [
        "num_boost_rounds = len(cv_result)\n",
        "print(num_boost_rounds)\n",
        "\n",
        "# train model\n",
        "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "47af628f-1012-a4cd-0520-7311334e39ef"
      },
      "outputs": [],
      "source": [
        "# check f2-score (to get higher score - increase num_boost_round in previous cell)\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# now fixed, correct calculation\n",
        "print(r2_score(dtrain.get_label(), model.predict(dtrain)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6529817f-c004-ecc9-7d0a-3aa7c7f81fcc"
      },
      "outputs": [],
      "source": [
        "# make predictions and save results\n",
        "y_pred = model.predict(dtest)\n",
        "output = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\n",
        "output.to_csv('xgboost-dummy.csv'.format(xgb_params['max_depth']), index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}