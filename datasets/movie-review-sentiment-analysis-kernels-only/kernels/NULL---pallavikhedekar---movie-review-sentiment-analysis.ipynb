{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport string\nfrom wordcloud import WordCloud # Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e20ecdc18fdefc7a4686206c999d4c2d7255362"},"cell_type":"markdown","source":"Submissions are evaluated on classification accuracy  for every parsed phrase. The sentiment labels are:\n\n    0 - negative\n    1 - somewhat negative\n    2 - neutral\n    3 - somewhat positive\n    4 - positive\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.tsv', sep=\"\\t\")\ntest = pd.read_csv('../input/test.tsv', sep=\"\\t\")\nsub = pd.read_csv('../input/sampleSubmission.csv', sep=\",\")\ntrain.head()\ntest.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6d5e13396f388e33e679b9451f1c5a0e9eca0d7"},"cell_type":"code","source":"train['sentiment_label'] = ''\ntrain.loc[train.Sentiment == 0, 'sentiment_label'] = 'Negative'\ntrain.loc[train.Sentiment == 1, 'sentiment_label'] = 'Somewhat Negative'\ntrain.loc[train.Sentiment == 2, 'sentiment_label'] = 'Neutral'\ntrain.loc[train.Sentiment == 3, 'sentiment_label'] = 'Somewhat Positive'\ntrain.loc[train.Sentiment == 4, 'sentiment_label'] = 'Positive'\ntrain.head()\ntrain.sentiment_label.value_counts()\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66d6e7f962948f74bbac2997005ef1892e91e3a4"},"cell_type":"markdown","source":"**Data Preprocessing and visualization**"},{"metadata":{"trusted":true,"_uuid":"8bc167d4d1e0adec646465b5fcf996cd9137468a"},"cell_type":"code","source":"from nltk.stem.wordnet import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\nfrom nltk.tokenize import word_tokenize\n\ndef clean_text(text):\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('[%s]' % re.escape(string.digits), '', text)\n    text = re.sub('[%s]' % re.escape(' +'), ' ', text)\n    text=re.sub('[^a-zA-Z]',' ',text)\n    text=[wordnet_lemmatizer.lemmatize(w) for w in word_tokenize(str(text).lower())]\n    text=' '.join(text)\n    text = text.lower()\n    text = text.strip()\n    return text\n\n    \ntrain['cleaned_phrase'] = ''\ntrain['cleaned_phrase'] = [clean_text(phrase) for phrase in train.Phrase]\ntest['cleaned_phrase'] = ''\ntest['cleaned_phrase'] = [clean_text(phrase) for phrase in test.Phrase]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33acaba662fee4b3f1b0a2ed23158821a491d14e"},"cell_type":"code","source":"train['phrase_length'] = [len(sent.split(' ')) for sent in train.cleaned_phrase]\ntest['phrase_length'] = [len(sent.split(' ')) for sent in test.cleaned_phrase]\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c77e74e3d07feb4e07cd804d90baa9f5d3805301"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fee7fd07a91b21b1f967aaffcaa4bc9d7b7b733"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nclasswise_count = train['sentiment_label'].value_counts()\nclasswise_count\nfig, ax = plt.subplots(1, 1,dpi=80, figsize=(10,5))\nsns.barplot(x=classwise_count.index,y=classwise_count)\nax.set_ylabel('Number of reviews')    \nax.set_xlabel('Sentiment Label')\nax.set_xticklabels(classwise_count.index , rotation=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb04e1365979aa7a434826f4bca045e445c77e08"},"cell_type":"code","source":"from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom nltk.corpus import stopwords\nStopwords = list(ENGLISH_STOP_WORDS) + stopwords.words()\ndef wordcloud(sentiment):\n    stopwordslist = Stopwords\n    ## extend list of stopwords with the common words between the 3 classes which is not helpful to represent them\n    stopwordslist.extend(['movie','movies','film','nt','rrb','lrb','make','work','like','story','time','little'])\n    reviews = train.loc[train.Sentiment.isin(sentiment)]\n    print(\"Word Cloud for Sentiment Labels: \", reviews.sentiment_label.unique())\n    phrases = ' '.join(reviews.cleaned_phrase)\n    words = \" \".join([word for word in phrases.split()])\n    wordcloud = WordCloud(stopwords=stopwordslist,width=3000,height=2500,background_color='white',).generate(words)\n    plt.figure(figsize=(10, 10))\n    plt.imshow(wordcloud.recolor(colormap=plt.get_cmap('Set2')), interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af2bbae94128035c8959eede30942987d183aa63"},"cell_type":"code","source":"wordcloud([3,4])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b04aaa32e3dfe73b2f774d40c2fe3761cd0b952"},"cell_type":"code","source":"wordcloud([0,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11ab5fc5a6cb0918ecb94826ffc31ba180014a32"},"cell_type":"code","source":"wordcloud([2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13c5d95ccce203fe0f3e401bdf380d92a9e3832f"},"cell_type":"code","source":"print('Number of sentences in training set:',len(train['SentenceId'].unique()))\nprint('Number of sentences in test set:',len(test['SentenceId'].unique()))\nprint('Average words per sentence in train:',train.groupby('SentenceId')['Phrase'].count().mean())\nprint('Average words per sentence in test:',test.groupby('SentenceId')['Phrase'].count().mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f76ef7359b6405b1cd3fbfa0bb44cffcb4775c8"},"cell_type":"markdown","source":"**classification with different algorithms**"},{"metadata":{"trusted":true,"_uuid":"b5f88596764368077efaed0eedc80dd5532bd1a2"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(ngram_range=(1, 3))\nfull_text = list(train['Phrase'].values) + list(test['Phrase'].values)\nvectorizer.fit(full_text)\ntrain_vectorized = vectorizer.transform(train['Phrase'])\ntest_vectorized = vectorizer.transform(test['Phrase'])\ny = train['Sentiment']\nfrom sklearn.model_selection import train_test_split\nx_train , x_val, y_train , y_val = train_test_split(train_vectorized,y,test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"131688e0d631bd4e6ee1c601c4180c7792c04f3b"},"cell_type":"code","source":"from sklearn.svm import LinearSVC\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import accuracy_score\n\nsvm = LinearSVC()\nsvm.fit(x_train,y_train)\nprint(classification_report( svm.predict(x_val) , y_val))\nprint(accuracy_score( svm.predict(x_val) , y_val ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22bade3dd501c25c2c56508f42f6c9dfdb2ce347"},"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import accuracy_score\nclassifier = linear_model.LogisticRegression(C=2.6, solver='sag')\nclassifier.fit(x_train, y_train)\nprint(classification_report( classifier.predict(x_val) , y_val))\nprint(accuracy_score( classifier.predict(x_val) , y_val ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1751d14bea2d88395ab596114f30664b4382a407"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import accuracy_score\nclassifier = RandomForestClassifier()\nclassifier.fit(x_train, y_train)\nprint(classification_report( classifier.predict(x_val) , y_val))\nprint(accuracy_score( classifier.predict(x_val) , y_val ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab7600e6a7c24301b915554f856db8c1905d07b1"},"cell_type":"markdown","source":"**Prepared Model With Keras**"},{"metadata":{"trusted":true,"_uuid":"8daafe332543c4979703b41a68af190176742d1d"},"cell_type":"code","source":"train_text=train.cleaned_phrase.values\ntest_text=test.cleaned_phrase.values\ntarget=train.Sentiment.values\ny=to_categorical(target)\nprint(train_text.shape,target.shape,y.shape)\n\n\nx_train,x_val,y_train,y_val=train_test_split(train_text,y,test_size=0.2,stratify=y,random_state=123)\nprint(x_train.shape,y_train.shape)\nprint(x_val.shape,y_val.shape)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93b9293f0b7c495964827a415785fc527daaf4f5"},"cell_type":"code","source":"from keras.preprocessing import sequence,text\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Embedding,LSTM,Conv1D,GlobalMaxPooling1D,Flatten,MaxPooling1D,GRU,SpatialDropout1D,Bidirectional\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import to_categorical\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adam\nfrom nltk import FreqDist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07b8882221b2c7a60393ebd31110514d5db8f394"},"cell_type":"code","source":"all_words=' '.join(x_train)\nall_words=word_tokenize(all_words)\ndist=FreqDist(all_words)\nnum_unique_word=len(dist)\nprint(num_unique_word)\nmax_features = num_unique_word\nmax_words = max(train.phrase_length)\nbatch_size = 128\nepochs = 3\nnum_classes=5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f3e2d3ac8e38887df1ac8de99ddf8b78ea40ed9"},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(x_train))\nx_train = tokenizer.texts_to_sequences(x_train)\nx_val = tokenizer.texts_to_sequences(x_val)\nx_test = tokenizer.texts_to_sequences(test_text)\n\n\nx_train = sequence.pad_sequences(x_train, maxlen=max_words)\nx_val = sequence.pad_sequences(x_val, maxlen=max_words)\nx_test = sequence.pad_sequences(x_test, maxlen=max_words)\nprint(x_train.shape,x_val.shape,x_test.shape)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ed6364b6898824ab20d81463f99d98eacdfabd7"},"cell_type":"code","source":"model1=Sequential()\nmodel1.add(Embedding(max_features,100,mask_zero=True))\nmodel1.add(LSTM(64,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\nmodel1.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\nmodel1.add(Dense(num_classes,activation='softmax'))\nmodel1.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04c73c1c8da9f006d64b4e5193386e1756cf565a"},"cell_type":"code","source":"%%time\nhistory1=model1.fit(x_train, y_train, validation_data=(x_val, y_val),epochs=10, batch_size=batch_size, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a15e878016eda167901a9f6d2fc4c2309a121edc"},"cell_type":"code","source":"y_pred1=model1.predict_classes(x_test,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67dd5d08451a59ef0273167e2d2712e378137559"},"cell_type":"code","source":"sub.Sentiment=y_pred1\nsub.to_csv('sub.csv',index=False)\nsub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}