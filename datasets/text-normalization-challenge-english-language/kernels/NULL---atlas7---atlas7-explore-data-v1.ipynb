{"metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "file_extension": ".py", "version": "3.6.1", "name": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat_minor": 1, "cells": [{"metadata": {"_uuid": "ad0af0c65e910db974308d445fbe794ef4273dd3", "scrolled": false, "_cell_guid": "e0f85e6a-50b1-4c6c-9a98-ad3506852598"}, "outputs": [], "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "execution_count": 1}, {"metadata": {"_uuid": "789b173ba7193fb0818d2174b05ae060074656b5", "_cell_guid": "95e119ec-5efe-4fbc-b941-1b030fa4693a"}, "cell_type": "markdown", "source": ["# What do we have here?"]}, {"metadata": {"_uuid": "6fcefc356383a8ede2c92d1ef1ed0a5bdfebf9d0", "_cell_guid": "0ecb0cb3-ea87-49b9-b1b7-4b19950f9300"}, "cell_type": "markdown", "source": ["Before doing any serious programming, let's just check out what we have (i.e. inputs), and what might be the expected submission work (i.e. output)."]}, {"metadata": {"_uuid": "8ed97dd1726f9a15a432f35dd5322ebfc75f5981", "_cell_guid": "bcfe3586-42d3-4e51-b030-779ea64bf6c2"}, "cell_type": "markdown", "source": ["## Training Set - Quick Peek"]}, {"metadata": {"_uuid": "dc9b4ea5cdac3cdbeb9c7832c2e432f06cd548b6", "_cell_guid": "5bc7596f-74a7-47b1-8f8d-c62f2e64cbf9"}, "cell_type": "markdown", "source": ["Let's take a look at the training dataset"]}, {"metadata": {"_uuid": "d546a31c3e707f1c9b95a932d924460c0c7c80c9", "collapsed": true, "_cell_guid": "22a6d38d-9892-4a96-9cf5-973931018276"}, "outputs": [], "cell_type": "code", "source": ["df_train = pd.read_csv('../input/en_train.csv')"], "execution_count": 2}, {"metadata": {"_uuid": "6e82ab80a31e3441d51851011b9e6a24dd4c89bf", "scrolled": false, "_cell_guid": "74a77724-a4d5-465d-8f86-5589ffee0859"}, "outputs": [], "cell_type": "code", "source": ["print(repr(df_train.head(20)))"], "execution_count": 3}, {"metadata": {"_uuid": "61db6803ebdaaf91f810d5569597cfea97f50da3", "_cell_guid": "ac581426-444e-4147-a9a5-f20fe5947368"}, "cell_type": "markdown", "source": ["Turns out `class` is a Python reserved keyword. To make life easier a bit downstream, let's rename it to `token_class` for safety. (this turns out to be a good idea as things like `df.token_class` works, whereas `df.class` will spill out error)."]}, {"metadata": {"_uuid": "c174f8e19faf2d50f437aa7c729ad3748920cf9f", "_cell_guid": "6035e3b7-f605-468f-90ab-ea036e61eeb3"}, "outputs": [], "cell_type": "code", "source": ["df_train.columns = [\"sentence_id\", \"token_id\", \"token_class\", \"before\", \"after\"]\n", "print(repr(df_train.head(20)))"], "execution_count": 4}, {"metadata": {"_uuid": "68cbd80f0dff53ac72c028eb2503b9aacddf5510", "_cell_guid": "e8e76c43-1073-499a-8325-b5bf0ff2afb3"}, "cell_type": "markdown", "source": ["For each sentence (`sentence_id`):\n", "\n", "- we read the written word (`before`) row-by-row.\n", "- we read the spoken word (`after`) row-by-row.\n", "\n", "For example, the written word `2006` is spoken as `two thousand six`.\n", "\n", "Each word within a sentence is defined by `token_id`.\n", "\n", "Each `token_id` has an assigned class (e.g. `PLAIN` for normal English, `DATE` for date, `LETTERS` for acronyms, etc.)"]}, {"metadata": {"_uuid": "9280662378a06fbc39c28c5ee2488541e38d9458", "_cell_guid": "4004e34a-0cbf-478b-9a74-8ea19393a7e1"}, "cell_type": "markdown", "source": ["## Test Set - Quick Peek"]}, {"metadata": {"_uuid": "313f662fba5ab8adeec0bbc9fdb30a0ca588748d", "_cell_guid": "54f6b570-1581-4aae-884c-34314083da68"}, "cell_type": "markdown", "source": ["Let's take a look at the test dataset"]}, {"metadata": {"_uuid": "896adb954d7b5393ce9a90a83164ba8c9609528f", "collapsed": true, "_cell_guid": "6c7d835c-5901-4cb8-b8c5-d46bba7d6814"}, "outputs": [], "cell_type": "code", "source": ["df_test = pd.read_csv('../input/en_test.csv')"], "execution_count": 5}, {"metadata": {"_uuid": "aee141da4a7525d02f2902dfcd2d5be88829db74", "_cell_guid": "eda57ec8-0b86-49bb-be48-22d1c1028952"}, "outputs": [], "cell_type": "code", "source": ["print(repr(df_test.head(20)))"], "execution_count": 6}, {"metadata": {"_uuid": "d9132d186542d067157afa6b4937c885f7c1e715", "_cell_guid": "1f820802-6c41-4589-a698-3806ca6de4ea"}, "cell_type": "markdown", "source": ["Note that test set only contains `before` (written word). Ther there is no `after` (spoken word). We will need to predict what `after` is."]}, {"metadata": {"_uuid": "e4f47cc1c8da3336a18195ee5e218849e8aadb63", "_cell_guid": "f473b60b-520c-476b-b637-b831711a6c0c"}, "cell_type": "markdown", "source": ["## Sample Submission - Quick Peek"]}, {"metadata": {"_uuid": "59cf057689248b1896b010a552276496f99326b7", "collapsed": true, "_cell_guid": "66f5f585-da18-4274-a152-005ef00363e2"}, "outputs": [], "cell_type": "code", "source": ["df_sample_submission = pd.read_csv('../input/en_sample_submission.csv')"], "execution_count": 7}, {"metadata": {"_uuid": "6117662ca7e2ea647f036dbe3c3bd3d08cd158a6", "_cell_guid": "176265e2-1e1b-427b-8943-6043fe9db6d8"}, "outputs": [], "cell_type": "code", "source": ["print(repr(df_sample_submission.head(20)))"], "execution_count": 8}, {"metadata": {"_uuid": "b4dc8b6938f3182089e21124c2d8a1d1eec26300", "_cell_guid": "e3a22c43-35cc-4d16-8214-381eb9d0f2a6"}, "cell_type": "markdown", "source": ["Note that sample submission contains the `after` column (predicted spoken word), for the corresponding `before` column (written word) in the test set. The `id` column takes the syntax of `<sentence_id>_<token_id>`. e.g. second sentence, third token will have an `id` of `1_2`. (zero index)."]}, {"metadata": {"_uuid": "278d820672eed162f780a3bff4eacff1dd7db0c0", "_cell_guid": "8eede727-2ca6-40b8-89ce-46485addde8c"}, "cell_type": "markdown", "source": ["# Explore Training Set"]}, {"metadata": {"_uuid": "6c78726f71507a4c968cf5c960d7eedc2fc2e9f4", "_cell_guid": "62dd47e1-86d6-4de9-bea4-d67f84afcbe2"}, "cell_type": "markdown", "source": ["Now we know that our objective is to predict the `after` column (predicted spoken word), based on the `before` vs `after` mapping training data, let's get a high level overview of what we have in our training data set. For example:\n", "\n", "- How many unique sentences? (`sentence_id`)\n", "- How many unique `token_class`?\n", "- How many unique `before`? (token in written form)\n", "- How many unique `after`? (token in spoken form)\n", "- How many sentences per `token_class`?\n", "- etc."]}, {"metadata": {"_uuid": "4ce390eb10dced51c0d4537dba8064316503c9ac", "scrolled": true, "_cell_guid": "767b79f1-ffb2-4b21-b3bc-787c6bc512cd"}, "outputs": [], "cell_type": "code", "source": ["print(\"Unique sentences: {:,d}\".format(df_train.sentence_id.unique().size))\n", "print(\"Unique token classes: {:,d}\".format(df_train.token_class.unique().size))\n", "print(\"Unique before: {:,d}\".format(df_train.before.unique().size))\n", "print(\"Unique after: {:,d}\".format(df_train.after.unique().size))"], "execution_count": 9}, {"metadata": {"_uuid": "6906c859236567198707bdc528fae306460a8238", "_cell_guid": "4a09a54a-ec9a-43a4-8cdd-cfb3effe252e"}, "outputs": [], "cell_type": "code", "source": ["print('sentences per class...')\n", "print('======================')\n", "print(repr(df_train.groupby(['token_class'])['sentence_id'].count()))"], "execution_count": 10}, {"metadata": {"_uuid": "f2bce7edd8d59d78068a0891c84d1aad3b036344", "_cell_guid": "f975867f-26c6-489f-bb94-b13ccd2af102"}, "cell_type": "markdown", "source": ["We have 16 unique token classes. Let's get a feel of what the tokens look like for each class. This is how we do a \"peek\" against one token class:"]}, {"metadata": {"_uuid": "25712470779bab230338174479ec8a53f00bc1bb", "scrolled": true, "_cell_guid": "cd90c5b6-1065-4df5-855b-3b4e7be3f4f0"}, "outputs": [], "cell_type": "code", "source": ["df_train[df_train['token_class'] == 'ADDRESS'].head(5)"], "execution_count": 11}, {"metadata": {"_uuid": "a7e2c8e66f83f58810db36aad681796df22bed6c", "_cell_guid": "505a11db-7834-490b-9c83-1782b464d219"}, "cell_type": "markdown", "source": ["To repeat this for all 16 token classes, we can write a simple function to do the job:"]}, {"metadata": {"_uuid": "77b5446a98e1b6df7c1309679be1ea6ba9c1b6c1", "collapsed": true, "_cell_guid": "41ee841b-b0f7-4495-8634-896adc0734c0"}, "outputs": [], "cell_type": "code", "source": ["def peek_tokens_by_class(token_classes, view_x):\n", "    for token_class in token_classes:\n", "        print(df_train[df_train['token_class'] == token_class].head(view_x))"], "execution_count": 12}, {"metadata": {"_uuid": "bf154d86499897583f18d8d76519d5c7a8b5830f", "_cell_guid": "0039f02f-732b-468a-9f49-9eaff325309d"}, "outputs": [], "cell_type": "code", "source": ["# Run it! Let's peak 10 samples from each token_class.\n", "peek_tokens_by_class(df_train.token_class.unique(), 10)"], "execution_count": 13}, {"metadata": {"_uuid": "6e71dace0063a1cde849145ec6b948bd8a326c3b", "_cell_guid": "cbd9fd62-256c-484c-9a55-344d148e32db"}, "cell_type": "markdown", "source": ["We have just learnt what the before (written form) vs after (spoken form) looks like for the 16 unique token classes. Notice that the `VERBATIM` class contains some non English characters (not sure what this is)."]}, {"metadata": {"_uuid": "6838135947fd1767bcb773f9b19c69a77c1bdffe", "collapsed": true, "_cell_guid": "c40fa01d-9b23-4849-b032-5f4dbe4bf78f"}, "cell_type": "markdown", "source": ["**Note to self** More analysis to come (work in progress)."]}, {"metadata": {"_uuid": "11837baa6c7bbdf9eccbc742dd1912ca3c343b4c", "collapsed": true, "_cell_guid": "e7f82d72-db25-46fa-890c-dac44c34b09d"}, "outputs": [], "cell_type": "code", "source": [], "execution_count": null}, {"metadata": {"collapsed": true}, "outputs": [], "cell_type": "code", "source": [], "execution_count": null}], "nbformat": 4}