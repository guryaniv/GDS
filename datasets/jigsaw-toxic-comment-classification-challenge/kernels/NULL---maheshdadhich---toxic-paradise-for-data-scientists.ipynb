{"cells": [{"cell_type": "markdown", "source": ["# Preamble \n", "In this problem, I think we have to fit figure out the category type of a given sentence. We are given sentences and there are different categories, I suspect that a same sentence can be of 2 categories ( We will check it in analysis). we will be doing feature engineering and will fitting a seperate guassian for each class of sentence (analogous to soft clustering) and will give probability for given sentence.\n", "\n", "In this kernel I will be starting features extraction for this competition, I will be extracting various features related to POS, tf_idf etc and then build a model to classify them. Lets start with following features - \n", "\n", "- **Grams features ** - grams features are nothing but n-grams features and represents \n", "- **Sentiment Analysis features ** - sentiment analysis features detect sentiments of given sentence \n", "- **POS features ** - Part of speech features for a sentense given \n", "\n", "**Note** - upvote if you like my kernel and all suggestions are welcome. \n"], "metadata": {"_cell_guid": "5782d729-bd55-4de5-975a-42011e17a9da", "_uuid": "62f9d064285ee9a9a888aa815b3f88543cbd7c51"}}, {"source": ["import pandas as pd\n", "import numpy as np \n", "import numpy as np\n", "from textblob import TextBlob\n", "import nltk\n", "import string\n", "import random\n", "import tensorflow as tf\n", "import os\n", "import io\n", "import sys\n", "import os\n", "import numpy as np\n", "import pandas as pd\n", "import nltk\n", "import gensim\n", "import csv, collections\n", "from textblob import TextBlob\n", "from sklearn.utils import shuffle\n", "from sklearn.svm import LinearSVC\n", "from sklearn.metrics import classification_report\n", "from sklearn.feature_extraction import DictVectorizer\n", "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n", "from sklearn.decomposition import TruncatedSVD\n", "from sklearn import ensemble, metrics, model_selection, naive_bayes\n", "from nltk.corpus import stopwords"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "6721792f-3a1b-44b3-a2d7-bb5b8b1fb739", "_uuid": "680a69e51219899546ff8abf70e253e86b060f08"}}, {"source": ["train = pd.read_csv(\"../input/train.csv\")\n", "train.head()"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "86ae4e28-028f-40c2-852e-e2142a87ecf9", "_uuid": "6422bb959fb4b35508a8c44c51e8b599ea12ec84"}}, {"source": ["test = pd.read_csv(\"../input/test.csv\")\n", "subm = pd.read_csv('../input/sample_submission.csv')\n", "test.head()"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "6a26e8b3-8a7b-496e-855b-66396a5260c2", "_uuid": "9d42155152c25d9d20941eea23218b87cf6689cf"}}, {"cell_type": "markdown", "source": ["## Sanity check"], "metadata": {"_cell_guid": "07b4a33a-b267-4fa1-84c0-fc4965175784", "_uuid": "5f940a1516bacd26697875ceb0a811fc4d8cad20"}}, {"source": ["print(\"Number of sentences in train data is {}\".format(train.shape[0]))\n", "print(\"Number of NAs in train_data {}\".format(train.isnull().sum()))\n", "categories = ['toxic','severe_toxic','obscene','threat','insult', 'identity_hate']\n", "sanity = pd.DataFrame(train.groupby(categories)['id'].count())\n", "sanity_copy = sanity.copy()\n", "sanity.reset_index(inplace = True)\n", "if sanity.shape[0] == 5:\n", "    print(\"One sentence falls into one category\")\n", "else:\n", "    print(\"They want us to train multiple models NN or GB, OR Gaussian miture models\")   "], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "8bd18e03-ca24-46ed-9d6e-79707da2dd37", "_uuid": "c9c9c5a411f304aea2526fbdd61d9c4222abf796"}}, {"cell_type": "markdown", "source": ["# Features' Extraction \n", "- **Grams features ** - grams features are nothing but n-grams features and represents \n", "- **Sentiment Analysis features ** - sentiment analysis features detect sentiments of given sentence \n", "- **POS features ** - Part of speech features for a sentense given "], "metadata": {"_cell_guid": "8a6afa1a-77cf-4b7d-a2c9-66a521e41ccf", "_uuid": "a8cc6ac460f890084b5e841ea9c3cc303a98e9e7"}}, {"source": ["train_df = train.copy() # just saving copy of train data \n", "test_df = test.copy()\n", "eng_stopwords = set(stopwords.words(\"english\"))\n", "import time\n", "start = time.time()\n", "def remove_noise(row):\n", "    \"\"\"function to remove unnecessary noise from the data - sentences\"\"\"\n", "    try:\n", "        text = row['comment_text']\n", "        text_splited = text.split(' ')\n", "        text_splited = [''.join(c for c in s if c not in string.punctuation) for s in text_splited]\n", "        noise_words = ['\\n', '\\n\\n']\n", "        text_splited = [''.join(c for c in s if c not in noise_words) for s in text_splited]\n", "        text_splited = [s for s in text_splited if s]\n", "        return(text_splited)\n", "    except:\n", "        return(row['comment_text'])\n", "    \n", "    \n", "    \n", "def grams_features(train_df, test_df):\n", "    \"\"\"function to extract grams features for a given sentence\"\"\"\n", "    tfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n", "    full_tfidf = tfidf_vec.fit_transform(train_df['comment_text'].values.tolist() + test_df['comment_text'].values.tolist())\n", "    train_tfidf = tfidf_vec.transform(train_df['comment_text'].values.tolist())\n", "    test_tfidf = tfidf_vec.transform(test_df['comment_text'].values.tolist())\n", "    return(train_tfidf, test_tfidf)\n", "        \n", "end = time.time()    \n", "print(\"Time taken in tf-idf is {}.\".format(end-start))"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "1ab4441d-08ed-4ec3-8e10-1aed3c5fc858", "_uuid": "46797514425b7e9fc11731ff671d533d82609388"}}, {"source": ["train_df['processed_text'] = train_df.apply(lambda row: remove_noise(row), axis = 1)\n", "test_df['processed_text'] = test_df.apply(lambda row: remove_noise(row), axis = 1)\n", "train_df.head()"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "234b1f55-e403-40fa-bc90-5107482e192c", "_uuid": "e2c6a7483a162b9c7f07354ee8b631602f664c15"}}, {"source": ["train_df.dropna(inplace = True)\n", "test_df.dropna(inplace = True)\n", "start = time.time()\n", "train_tfidf, test_tfidf = grams_features(train_df, test_df)\n", "end = time.time()\n", "print(\"Time taken in tf-idf is {}.\".format(end-start))"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "5fc47fec-4b93-4d93-a4a8-2b0e1e4899ea", "_uuid": "7e5c8b654508853c41a5d3cc26b558487bede1da"}}, {"cell_type": "markdown", "source": ["# NB-SVM \n", "I thought of developing model later but after looking at [Jeremy Howard's NB-SVM baseline (0.06 lb)](http://https://www.kaggle.com/jhoward/nb-svm-baseline-0-06-lb). I would also like to try this on whatever features I have. Lets make a basic model. All credits goes to Jeremy for next cell of code.\n", "\n"], "metadata": {"_cell_guid": "4a2307eb-7d37-4ba5-8cf2-55e8d7c6a068", "_uuid": "8ab42f6078a97f3d3c084014c59fadc554c4ef08"}}, {"source": ["label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n", "def pr(y_i, y):\n", "    p = x[y==y_i].sum(0)\n", "    return (p+1) / ((y==y_i).sum()+1)\n", "\n", "x=train_tfidf.sign()\n", "test_x = test_tfidf.sign()\n", "from sklearn.linear_model import LogisticRegression\n", "def get_mdl(y):\n", "    y = y.values\n", "    r = np.log(pr(1,y) / pr(0,y))\n", "    m = LogisticRegression(C=0.1, dual=True)\n", "    x_nb = x.multiply(r)\n", "    return m.fit(x_nb, y), r\n", "\n", "preds = np.zeros((len(test_df), len(label_cols)))\n", "\n", "for i, j in enumerate(label_cols):\n", "    print('fit', j)\n", "    m,r = get_mdl(train_df[j])\n", "    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "c27472ec-34ae-4830-8587-d3b3c388aec9", "_uuid": "1c49f9df36e13bbf2b9921013d38f9b7de8162ea"}}, {"source": ["submid = pd.DataFrame({'id': subm[\"id\"]})\n", "submission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\n", "submission.to_csv('submission.csv', index=False)"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {}}, {"cell_type": "markdown", "source": ["**Gaussian discriminant analysis is to be implemented soon ...**"], "metadata": {}}, {"source": [], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true}}], "nbformat": 4, "nbformat_minor": 1, "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.3", "mimetype": "text/x-python", "file_extension": ".py"}}}