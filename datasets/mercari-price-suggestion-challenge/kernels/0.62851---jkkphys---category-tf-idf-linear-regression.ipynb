{"metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"nbconvert_exporter": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "file_extension": ".py", "version": "3.6.3", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"metadata": {"_cell_guid": "d8f10ebd-b92a-4540-bf72-bfbbecd374aa", "_uuid": "1d9bbe803d5addd64fb8f6817598d3ec7421cd46"}, "source": ["11/29/2017: TF-IDF on name + item_description fed into a Linear Regression. Log transformed price to improve performance.\n", "\n", "I'm a huge proponent of the fact that simple regressors (linear or logistic) run the world. I wanted to put together a linear model that uses the category_name field to demonstrate that a linear regression is a nice baseline."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "90809387-d62c-4d62-819c-2c8226ac7a9b", "_uuid": "338519d51f8e60ed92184e0bec21a1241ff201f3"}, "outputs": [], "source": ["from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.model_selection import train_test_split, GridSearchCV\n", "from sklearn.metrics import mean_squared_log_error\n", "from sklearn.linear_model import SGDRegressor\n", "from sklearn.pipeline import Pipeline\n", "\n", "import pandas as pd\n", "import numpy as np\n", "import time\n", "import re\n", "\n", "seed = 101"], "cell_type": "code", "execution_count": 1}, {"metadata": {"collapsed": true, "_cell_guid": "d379a07e-5cda-4355-9a28-2c9ba69da885", "_uuid": "ee3c6cb68229ff8c447fab87bcf6440446cc5f8b"}, "outputs": [], "source": ["def tokenizer(text):\n", "    if text:\n", "        result = re.findall('[a-z]{2,}', text.lower())\n", "    else:\n", "        result = []\n", "    return result"], "cell_type": "code", "execution_count": 2}, {"metadata": {"_cell_guid": "0d6c758c-c481-49fd-92c3-14f8b851adff", "_uuid": "2d1ea007bc610fc619cb14b684625fbebbc81cc4"}, "outputs": [], "source": ["df = pd.read_csv('../input/train.tsv', sep='\\t')\n", "df.head()"], "cell_type": "code", "execution_count": 3}, {"metadata": {"_cell_guid": "c5e14c88-ea91-4f38-8589-a6432def3a4b", "_uuid": "3d32cc3d53f075eff74810c30f76a21b72c51590"}, "source": ["Now let's train a simple tfidf vectorizer on the combination of the item name and description."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "1bed2c0a-d8f6-45de-a64e-be91755d113e", "_uuid": "dd22fcd87d58bec7ae796850925f29b53222c554"}, "outputs": [], "source": ["df['item_description'].fillna(value='Missing', inplace=True)\n", "X = (df['name'] + ' ' + df['item_description']).values\n", "y = np.log1p(df['price'].values)\n", "\n", "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=seed)"], "cell_type": "code", "execution_count": 4}, {"metadata": {"_cell_guid": "8b617cab-259c-47a9-a0a8-db949cea3e26", "_uuid": "2115d7cde7a048c771a78755ad2e684da4d315cb"}, "outputs": [], "source": ["vect = TfidfVectorizer(tokenizer=tokenizer, stop_words='english')\n", "start = time.time()\n", "X_train_vect = vect.fit_transform(X_train)\n", "end = time.time()\n", "print('Time to train vectorizer and transform training text: %0.2fs' % (end - start))"], "cell_type": "code", "execution_count": 5}, {"metadata": {"_cell_guid": "27539ead-5d35-4b5e-a02c-63d310c9513d", "_uuid": "174cf9a77a2596a827d2e63a63725738ce00a279"}, "source": ["Now let's train a linear regression model."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "f3f289c3-84c1-4382-9012-949ca5dc3def", "_uuid": "62a2a24a93d57576c8aa982823a68b8756ee49cb", "scrolled": true}, "outputs": [], "source": ["# I was using a LinearRegression previously, but with the wider vocab it's too slow. \n", "# Let's use the SGDRegressor with ordinary least squares.\n", "# Also, using mean squared error as the eval metric, since negative values crash mean squared log error.\n", "\n", "model = SGDRegressor(loss='squared_loss', penalty='l2', random_state=seed, max_iter=5)\n", "params = {'penalty':['none','l2','l1'],\n", "          'alpha':[1e-4, 2e-4, 5e-4, 1e-3, 2e-3, 5e-3, 1e-2, 2e-2, 5e-2, 0.1]}\n", "gs = GridSearchCV(estimator=model,\n", "                  param_grid=params,\n", "                  scoring='neg_mean_squared_error',\n", "                  n_jobs=1,\n", "                  cv=5,\n", "                  verbose=3)\n", "start = time.time()\n", "gs.fit(X_train_vect, y_train)\n", "end = time.time()\n", "print('Time to train model: %0.2fs' % (end -start))"], "cell_type": "code", "execution_count": 6}, {"metadata": {"_cell_guid": "5e92c474-d9ad-4528-afb4-83106dcdfb97", "_uuid": "c22a251a5233490932edd78577046804ac0c9f59"}, "outputs": [], "source": ["model = gs.best_estimator_\n", "print(gs.best_params_)\n", "print(gs.best_score_)"], "cell_type": "code", "execution_count": 7}, {"metadata": {"_cell_guid": "3ea9beab-4b06-4b22-9ed4-99a103a4308e", "_uuid": "344f0b9270ca14f2c0d97b595ae7a0ea3657dd53"}, "source": ["Now let's package everything up nicely in a pipeline and run it over the test set to check the performance."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "5bd26628-3881-46f5-9280-d7493f45a58f", "_uuid": "0ce0f5b5ddae0294655c05798a7e8665970de23f"}, "outputs": [], "source": ["pipe = Pipeline([('vect',vect),('model',model)])\n", "start = time.time()\n", "y_pred = pipe.predict(X_test)\n", "end = time.time()\n", "print('Time to generate predictions on test set: %0.2fs' % (end - start))"], "cell_type": "code", "execution_count": 8}, {"metadata": {"_cell_guid": "506e5658-1da4-42f4-a6a9-8e41ec1472ab", "_uuid": "7e1ba629a30976584d6204b1c4ff0a6bb8998803"}, "outputs": [], "source": ["# Replace negative values with zero for the time being.\n", "print(np.sqrt(mean_squared_log_error(np.exp(y_test)-1, np.exp(y_pred)-1)))"], "cell_type": "code", "execution_count": 12}, {"metadata": {"_cell_guid": "14a1fa1f-0ede-495a-94f4-44b4c6730230", "_uuid": "969db0e4af320178ce69f491b4eea7ec01e6ef5b"}, "source": ["Okay, now let's read in the test data and generate our submission file."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "3ac5e29b-192d-4e29-abac-f4eff0a18861", "_uuid": "810bfc2601cef34d512ca0adf77ea93a9db18418"}, "outputs": [], "source": ["df_test = pd.read_csv('../input/test.tsv', sep='\\t')\n", "df_test.head()"], "cell_type": "code", "execution_count": 13}, {"metadata": {"_cell_guid": "7bfeba4b-a8dd-4fa9-85db-12b0c7d1626e", "_uuid": "4b1f965ff8f86293e36380446d455824c44d051d"}, "outputs": [], "source": ["df_test['item_description'].fillna('Missing', inplace=True)\n", "df_test['price'] = np.exp(pipe.predict((df_test['name'] + ' ' + df_test['item_description']).values))-1\n", "df_test.head()"], "cell_type": "code", "execution_count": 14}, {"metadata": {"collapsed": true, "_cell_guid": "75c3c83a-ad1e-4bea-98a9-0c377af0b1c7", "_uuid": "f37d62ba2d7ec386847c9f29e3ad3eaa844112a3"}, "outputs": [], "source": ["df_test[['test_id','price']].to_csv('output.csv', index=False)"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true}, "outputs": [], "source": [], "cell_type": "code", "execution_count": null}]}