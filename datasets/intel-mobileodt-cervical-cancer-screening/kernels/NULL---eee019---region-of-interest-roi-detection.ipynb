{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fd2b0e5d-702c-3f17-e280-fe6cf01e635f"
      },
      "source": [
        "## Region of Interest (ROI) detection using Machine Learning ##\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ff7a2a4c-c28f-e98a-75d2-8339cf02382e"
      },
      "source": [
        "By reading chattob's notebook \"Cervix segmentation (GMM)\" I got inspired to find the Region of Interest (ROI) using Supervised Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "537c2624-e01a-93ad-13a9-814f960544f8"
      },
      "source": [
        "I'm taking the next cell directly from here: https://www.kaggle.com/chattob/cervix-segmentation-gmm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "575d4c04-00b1-cfc8-83a6-cc95e7b93f62"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import math\n",
        "from sklearn import mixture\n",
        "from sklearn.utils import shuffle\n",
        "from skimage import measure\n",
        "from glob import glob\n",
        "import os\n",
        "\n",
        "TRAIN_DATA = \"../input/intel-mobileodt-cervical-cancer-screening/train\"\n",
        "\n",
        "types = ['Type_1']#,'Type_2','Type_3']\n",
        "type_ids = []\n",
        "\n",
        "for type in enumerate(types):\n",
        "    type_i_files = glob(os.path.join(TRAIN_DATA, type[1], \"*.jpg\"))\n",
        "    type_i_ids = np.array([s[len(TRAIN_DATA)+8:-4] for s in type_i_files])\n",
        "    type_ids.append(type_i_ids[:5])\n",
        "\n",
        "def get_filename(image_id, image_type):\n",
        "    \"\"\"\n",
        "    Method to get image file path from its id and type   \n",
        "    \"\"\"\n",
        "    if image_type == \"Type_1\" or \\\n",
        "        image_type == \"Type_2\" or \\\n",
        "        image_type == \"Type_3\":\n",
        "        data_path = os.path.join(TRAIN_DATA, image_type)\n",
        "    elif image_type == \"Test\":\n",
        "        data_path = TEST_DATA\n",
        "    elif image_type == \"AType_1\" or \\\n",
        "          image_type == \"AType_2\" or \\\n",
        "          image_type == \"AType_3\":\n",
        "        data_path = os.path.join(ADDITIONAL_DATA, image_type)\n",
        "    else:\n",
        "        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n",
        "\n",
        "    ext = 'jpg'\n",
        "    return os.path.join(data_path, \"{}.{}\".format(image_id, ext))\n",
        "\n",
        "def get_image_data(image_id, image_type):\n",
        "    \"\"\"\n",
        "    Method to get image data as np.array specifying image id and type\n",
        "    \"\"\"\n",
        "    fname = get_filename(image_id, image_type)\n",
        "    img = cv2.imread(fname)\n",
        "    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7909509f-01ee-6092-2981-973c11db71ac"
      },
      "source": [
        "Let's reshape the images to a fixed size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bd3d9b2d-c897-c6ca-0a47-0859cd8c632d"
      },
      "outputs": [],
      "source": [
        "reshaped_color = []\n",
        "for type in enumerate(types):\n",
        "    image_ids = type_ids[type[0]]\n",
        "    for image_id in image_ids:\n",
        "        img = get_image_data(image_id, type[1])\n",
        "        ar = img.shape[0] * 1.0 / 480\n",
        "        new_img = cv2.resize(img, (int(img.shape[1] / ar), 480))\n",
        "        new_img = new_img[:, :360, :]\n",
        "        x = np.zeros((480, 360, 3), dtype=np.uint8)\n",
        "        x[:new_img.shape[0], :new_img.shape[1], :] = new_img\n",
        "        reshaped_color.append(x)\n",
        "        plt.imshow(x)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "76962024-4e70-759f-12eb-06fc4bc626d1"
      },
      "source": [
        "Then manually, paint anything that it's not within the ROI, for example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f77250fa-d26c-2652-a81e-88b53a7260db"
      },
      "outputs": [],
      "source": [
        "names = [0, 10, 1013, 102, 104]\n",
        "for name in names:\n",
        "    img = cv2.imread('../input/region-of-interest-roi-detection-using-ml/{}.jpg'.format(name))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "372f211e-d5ef-66f5-1e5e-34a307295a7b"
      },
      "source": [
        "Next steps:\n",
        "\n",
        "Build the training dataset where features are the x and y position plus the R, G, B intensity of each pixel using a cv.filter2d\n",
        "\n",
        "Train it using XGBoost\n",
        "\n",
        "Use it to predict the ROI for Test files"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}