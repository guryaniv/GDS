{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # Plot\nimport seaborn as sns # Beautiful plots\n\n\n## Classifier of XGBosst\nfrom   xgboost import XGBClassifier\n\n## Package used for fine tuning\nfrom hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d390248fbee78d4223b6bd1731439f95b24210d"},"cell_type":"markdown","source":"**Metrics for the results**"},{"metadata":{"trusted":true,"_uuid":"50e3ca36decb11c7ac5bf904fcd838cac20d0cae"},"cell_type":"code","source":"# The following guy used it these 3 functions as metric:\n# https://www.kaggle.com/peterhurford/pets-lightgbm-baseline-with-all-the-data\n\n\n# These 3 functions have been taken from Ben Hamner's github repository\n# https://github.com/benhamner/Metrics\n\n\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**Pre-processing Data**"},{"metadata":{"trusted":true,"_uuid":"df748851ba054c984b2544e6031920f6adf0d93c"},"cell_type":"code","source":"df_train = pd.read_csv('../input/train/train.csv')\ndf_train.columns = ['type', 'name', 'age', 'breed1', 'breed2', 'gender', 'color1', 'color2',\n       'color3', 'maturity_size', 'fur_length', 'vaccinated', 'dewormed',\n       'sterilized', 'health', 'quantity', 'fee', 'state', 'rescuer_id',\n       'video_amt', 'description', 'pet_id', 'photo_amt', 'adoption_speed']\ndf_train['photo_amt'] = pd.to_numeric(df_train['photo_amt'], downcast='integer')\n\n## Shuffling\ndf_train = df_train.sample(frac=1)\n\n\nchosen_columns = ['type', 'age', 'breed1', 'breed2', 'gender', 'color1', 'color2',\n       'color3', 'maturity_size', 'fur_length', 'vaccinated', 'dewormed',\n       'sterilized', 'health', 'quantity', 'fee', 'state',\n       'video_amt', 'photo_amt']\n\n\n## Splitting in features and targets\ntarget   = df_train.adoption_speed\nfeatures = df_train[ chosen_columns  ]\n\n## Splitting in train and valid\ntrain_size      = int(len(features)*0.7)\nfeatures_train  = features[: train_size]\ntarget_train    = target  [: train_size]\nfeatures_valid  = features[train_size :]\ntarget_valid    = target  [train_size :]\n\nfeatures_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c03d69b96bbab3eeaf18d9dd7ca4fe06060465f8"},"cell_type":"markdown","source":"**Fine Tuning XGBoost**"},{"metadata":{"trusted":true,"_uuid":"51d6b4bf443e294a3f3f0199a5eb9b22357c0149"},"cell_type":"code","source":"## It is interesting to know how XGBoost classifies each feature.\ndef print_feature_importance(clf) :\n    sorted_idx = np.argsort(clf.feature_importances_)[::-1]\n    importance = \"Importance = [\"\n    for index in sorted_idx[:15] :\n        importance += chosen_columns[index] + \",\"\n        #print([features[index], clf.feature_importances_[index]])\n    print(importance + \"]\")\n\n## This function will be called several times. The parameters I'm tuning are max_depth, min_child_weight, subsample, and colsample_bytree    \ndef objective(space):\n    clf = XGBClassifier(\n        nthread          = 40,\n        #n_estimators     = 10000,\n\n        max_depth        = int(space['max_depth']),\n        min_child_weight = space['min_child_weight'],\n        subsample        = space['subsample'],\n        colsample_bytree = space['colsample_bytree']\n    )\n\n    eval_set  = [( features_train, target_train), ( features_valid, target_valid)]\n    clf.fit(features_train, target_train,\n            eval_set=eval_set,\n            eval_metric=\"merror\",\n            early_stopping_rounds=30,\n            verbose = False\n    )\n    print_feature_importance(clf)\n    \n    prediction_train = clf.predict(features_train)\n    prediction_valid = clf.predict(features_valid)\n    \n    kappa_train = quadratic_weighted_kappa(target_train, prediction_train)\n    kappa_valid = quadratic_weighted_kappa(target_valid, prediction_valid)\n    \n    print(\"space: %s, Kappa Train: %.3f, Kappa Valid: %.3f\" % (str(space), kappa_train, kappa_valid))\n    print(\"\")\n    return{'loss':1-kappa_valid, 'status': STATUS_OK }\n    \n    \nspace ={\n    #'max_depth'      : hp.quniform(\"max_depth\", 5, 30, 1),\n    'max_depth'       : 23,\n    #'min_child_weight': hp.quniform('min_child_weight', 0, 100, 1),\n    'min_child_weight': hp.quniform('min_child_weight', 20, 30, 1),\n    #'subsample'       : hp.quniform('subsample', 0.1, 1, 0.1),\n    'subsample'       : 1,\n    #'colsample_bytree': hp.quniform('colsample_bytree', 0.1, 1, 0.1),\n    'colsample_bytree': 0.6,\n    }\n\ntrials = Trials()\nbest = fmin(fn=objective,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=100,\n            trials=trials)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"036c74483587c41da4bdda1e9c9562add77d19f3"},"cell_type":"markdown","source":"**Training Final XGBoost model**"},{"metadata":{"trusted":true,"_uuid":"c50eb43c4e72ec80a9d8ce73593f12da376f2a3b"},"cell_type":"code","source":"clf = XGBClassifier(\n    subsample        = 0.8, \n    colsample_bytree = 0.6, \n    max_depth        = 22, \n    gamma            = 3.0, \n    min_child_weight = 52.0,    \n    silent=True)\n\neval_set  = [( features_train, target_train), ( features_valid, target_valid)]\n\nclf.fit(features_train, target_train,\n        eval_set=eval_set,\n        eval_metric=\"merror\",\n        early_stopping_rounds=30,\n        verbose = False\n)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc87b896b4c4acaaa50b19da0ea96da4c4f2ded4"},"cell_type":"markdown","source":"**Validating and Printing Metrics**"},{"metadata":{"trusted":true,"_uuid":"b1dde1a91c5837db947e6ef71838401f8ab26afa"},"cell_type":"code","source":"## Predictions and evaluation\nprediction_valid = clf.predict(features_valid)\naccuracy = (target_valid == prediction_valid).mean()\nkappa    = quadratic_weighted_kappa(target_valid, prediction_valid)\nprint(accuracy, kappa)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe1b08a374414274da6f63f8dfbc330f246b2ff1"},"cell_type":"markdown","source":"**Creating submission file**"},{"metadata":{"trusted":true,"_uuid":"a2d9346a842699a18d2b6aeb057ce966b918a0f8"},"cell_type":"code","source":"df_test = pd.read_csv('../input/test/test.csv')\ndf_test.columns = ['type', 'name', 'age', 'breed1', 'breed2', 'gender', 'color1', 'color2',\n       'color3', 'maturity_size', 'fur_length', 'vaccinated', 'dewormed',\n       'sterilized', 'health', 'quantity', 'fee', 'state', 'rescuer_id',\n       'video_amt', 'description', 'pet_id', 'photo_amt']\nfeatures_test   = df_test[ chosen_columns ]\nprediction_test = clf.predict(features_test)\n\nsubmission = pd.DataFrame(\n    { \n        'PetID'         : df_test.pet_id, \n        'AdoptionSpeed' : prediction_test\n    }\n)\n## submission.set_index('PetID')\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}