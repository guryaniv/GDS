{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.metrics import accuracy_score\nfrom kaggle.competitions import twosigmanews\n\n# Interactive graphs\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e11fe9c3d2fa5b48c3bd6d7ebc38c4edbb20af8","scrolled":true},"cell_type":"code","source":"env = twosigmanews.make_env()\n(market_train, news_train) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95afba5e03c6eeb6127333bd042d6f45bcff6004"},"cell_type":"code","source":"#market_train.loc[market_train['assetCode'] == 'AAPL.O', ['assetCode']]\ndata = []\ndf = market_train[(market_train['assetCode'] == 'AAPL.O')]\n\ndata.append(go.Scatter(\n    x = df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = df['close'].values,\n    name = 'APPL.O'\n))\n\nlayout = go.Layout(dict(title = \"Closing prices of Apple\",\n                       xaxis = dict(title = 'Year'),\n                       yaxis = dict(title = 'Price (USD)'),\n                       ), legend = dict(\n                        orientation='h'))\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ff36a42898341b3480948c1d418c7bc65f1745c"},"cell_type":"code","source":"data = []\ndf = df.loc[pd.to_datetime(df['time']) >= pd.to_datetime('2014-06-09').tz_localize('UTC')]\n\ndata.append(go.Scatter(\n    x = df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = df['close'].values,\n    name = 'APPL.O'\n))\n\nlayout = go.Layout(dict(title = \"Closing prices of Apple\",\n                       xaxis = dict(title = 'Year'),\n                       yaxis = dict(title = 'Price (USD)'),\n                       ), legend = dict(\n                        orientation='h'))\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed5a8c1eee28eb20f967dd7bc5e3392f2c0b6791"},"cell_type":"markdown","source":"**This is my first try to find the average sentiment for Apple. It looks like I should not keep all three (pos, neut, neg) in one graph as it is really hard to tell the overall sentiment. So...perhaps I need to make a function to determine the \"overall\" sentiment of the day. This way there will only be one datapoint per day and we could overlay this with the closing prices.**"},{"metadata":{"trusted":true,"_uuid":"94472fd525ef66a7a1cc8cd6d8cc81db87f80fd9","scrolled":true},"cell_type":"code","source":"news_df = news_train[(news_train['assetName'] == 'Apple Inc')]\nnews_df = news_df.loc[pd.to_datetime(news_df['time']) >= pd.to_datetime('2014-06-09').tz_localize('UTC')]\n\n# time = pd.to_datetime('2014-06-09').tz_localize('UTC')\n# time += pd.Timedelta(days=1)\n# time\n    \nstart_day = pd.to_datetime('2014-06-09').tz_localize('UTC')\nday_after = pd.to_datetime('2014-06-10').tz_localize('UTC')\nsent_count = 0\nsent_neg_total = 0\nsent_neut_total = 0\nsent_pos_total = 0\nsent_neg = []\nsent_neut = []\nsent_pos = []\ndates = []\n\n# Function that calculates the average sentiment for each day\nfor index, row in news_df.iterrows():\n    if pd.to_datetime(row['time']) > start_day and pd.to_datetime(row['time']) < day_after:\n        sent_count += 1\n        sent_neg_total += row['sentimentNegative']\n        sent_neut_total += row['sentimentNeutral']\n        sent_pos_total += row['sentimentPositive']\n    else:\n        if sent_count == 0:\n            sent_count = 1\n        sent_neg.append(sent_neg_total/sent_count)\n        sent_neut.append(sent_neut_total/sent_count)\n        sent_pos.append(sent_pos_total/sent_count)\n        sent_count = 0\n        sent_neg_total = 0\n        sent_neut_total = 0\n        sent_pos_total = 0\n        dates.append(start_day)\n        start_day += pd.Timedelta(days=1)\n        day_after += pd.Timedelta(days=1)\n\n# Plot average sentiment values for each day\nneg_sent = go.Scatter(\n    x = dates,\n    y = sent_neg,\n    mode = 'markers',\n    name = 'Negative Sentiment' \n)\n\nneut_sent = go.Scatter(\n    x = dates,\n    y = sent_neut,\n    mode = 'markers',\n    name = 'Neutral Sentiment' \n)\n\npos_sent = go.Scatter(\n    x = dates,\n    y = sent_pos,\n    mode = 'markers',\n    name = 'Positive Sentiment' \n)\n\ndata = [neg_sent, neut_sent, pos_sent]\n\nlayout = go.Layout(dict(title = \"Sentiment of Apple\",\n                       xaxis = dict(title = 'Year'),\n                       yaxis = dict(title = 'Sentiment Value'),\n                       ), legend = dict(\n                        orientation='h'))\npy.iplot(dict(data=data, layout=layout), filename='line-mode')\n\n\n######################################################################################\n# neg_sent = go.Scatter(\n#     x = news_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n#     y = news_df['sentimentNegative'].values,\n#     mode = 'markers',\n#     name = 'Negative Sentiment' \n# )\n\n# neut_sent = go.Scatter(\n#     x = news_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n#     y = news_df['sentimentNeutral'].values,\n#     mode = 'markers',\n#     name = 'Neutral Sentiment' \n# )\n\n# pos_sent = go.Scatter(\n#     x = news_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n#     y = news_df['sentimentPositive'].values,\n#     mode = 'markers',\n#     name = 'Positive Sentiment' \n# )\n\n# data = [neg_sent, neut_sent, pos_sent]\n\n# layout = go.Layout(dict(title = \"Sentiment of Apple\",\n#                        xaxis = dict(title = 'Year'),\n#                        yaxis = dict(title = 'Sentiment Value'),\n#                        ), legend = dict(\n#                         orientation='h'))\n# py.iplot(dict(data=data, layout=layout), filename='line-mode')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8d686d696434bde47129db81967a51c86fc4988"},"cell_type":"markdown","source":"**Now I am going to try and average each sentiment value into one. I will most likely need to have a weighting function, but this can come next. The reason for this is each news document has different urgency, sentiment word count, etc and those with higher urgency and more sentiment word count should probabaly be weighted more.**"},{"metadata":{"trusted":true,"_uuid":"415b7c4b0db17fcb0abf05ad03a5240eb393ce37"},"cell_type":"code","source":"news_df = news_train[(news_train['assetName'] == 'Apple Inc')]\nnews_df = news_df.loc[pd.to_datetime(news_df['time']) >= pd.to_datetime('2014-06-09').tz_localize('UTC')]\n\n# time = pd.to_datetime('2014-06-09').tz_localize('UTC')\n# time += pd.Timedelta(days=1)\n# time\n    \nstart_day = pd.to_datetime('2014-06-09').tz_localize('UTC')\nday_after = pd.to_datetime('2014-06-10').tz_localize('UTC')\nsent_count = 0\nsent_neg_total = 0\nsent_neut_total = 0\nsent_pos_total = 0\nsent_overall = []\ndates = []\n\n# Function that calculates the average sentiment for each day\nfor index, row in news_df.iterrows():\n    if pd.to_datetime(row['time']) > start_day and pd.to_datetime(row['time']) < day_after:\n        sent_count += 1\n        sent_neg_total += row['sentimentNegative']\n        sent_neut_total += row['sentimentNeutral']\n        sent_pos_total += row['sentimentPositive']\n    else:\n        if sent_count == 0:\n            start_day += pd.Timedelta(days=1)\n            day_after += pd.Timedelta(days=1)\n            sent_count = 0\n            sent_neg_total = 0\n            sent_neut_total = 0\n            sent_pos_total = 0\n        else:\n            sent_neg_total = sent_neg_total/sent_count\n            sent_neut_total = sent_neut_total/sent_count\n            sent_pos_total = sent_pos_total/sent_count\n            sent_overall.append(sent_pos_total - sent_neg_total)\n            sent_count = 0\n            sent_neg_total = 0\n            sent_neut_total = 0\n            sent_pos_total = 0\n            dates.append(start_day)\n            start_day += pd.Timedelta(days=1)\n            day_after += pd.Timedelta(days=1)\n\n# Plot average sentiment values for each day\noverall_sentiment = go.Scatter(\n    x = dates,\n    y = sent_overall,\n#     mode = 'markers',\n    name = 'Overall Sentiment Score' \n)\n\ndata = [overall_sentiment]\n\nlayout = go.Layout(dict(title = \"Sentiment of Apple\",\n                       xaxis = dict(title = 'Year'),\n                       yaxis = dict(title = 'Sentiment Value'),\n                       ), legend = dict(\n                        orientation='h'))\npy.iplot(dict(data=data, layout=layout), filename='line-mode')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba7410f789b5e7240f9e0f13098db821f148958f"},"cell_type":"markdown","source":"**Okay, still need to do something with weights and I do not use neutral value - not sure how to incorporate this. What I'm going to try to do now is combine the closing price graph with the overall sentiment to try and observe a correlation.**"},{"metadata":{"trusted":true,"_uuid":"67c18b5c1fb2aeb3db4e55ea51e58b5787cb29d9"},"cell_type":"code","source":"apple_close_price = (go.Scatter(\n    x = df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = df['close'].values,\n    name = 'APPL.O'\n))\n\ndata = [overall_sentiment, apple_close_price]\n\nlayout = go.Layout(dict(title = \"Sentiment of Apple\",\n                       xaxis = dict(title = 'Year'),\n                       yaxis = dict(title = 'Sentiment Value'),\n                       ), legend = dict(\n                        orientation='h'))\npy.iplot(dict(data=data, layout=layout), filename='line-mode')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad1252a7ff9f41b86fea7a1676a55027914f22f2"},"cell_type":"code","source":"market_train.loc[market_train['assetCode'] == 'A.N', ['time', 'assetCode']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e791f6ce7b3a8b834658dd3cb4dbd0e8cb7f938"},"cell_type":"code","source":"target_col = ['returnsOpenNextMktres10']\ncat_cols = ['assetCode']\nnum_cols = ['volume', 'close', 'open',\n       'returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n       'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n       'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n       'returnsClosePrevMktres10', 'returnsOpenPrevMktres10']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"549ddc1fe1131b3e76411541607e1d7dec468e4c"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nmarket_train = market_train.loc[pd.to_datetime(market_train['time']) >= pd.to_datetime('2009-01-01').tz_localize('UTC')]\n\ntrain_indices, val_indices = train_test_split(market_train.index.values, test_size = 0.25, random_state = 23)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"88541b60e3a3ac6e9ee625a7d964ace402c8aaf9"},"cell_type":"code","source":"# Handles categorical variables\n\ndef encode(encoder, x):\n    len_encoder = len(encoder)\n    try:\n        id = encoder[x]\n    except KeyError:\n        id = len_encoder\n    return id\n\nencoders = [{} for cat in cat_cols]\n\nfor i, cat in enumerate(cat_cols):\n    print('encoding %s ...' % cat, end = ' ')\n    encoders[i] = {l: id for id, l in enumerate(market_train.loc[train_indices, cat].astype(str).unique())}\n    market_train[cat] = market_train[cat].astype(str).apply(lambda x: encode(encoders[i], x))\n    print('Done')\n    \nembed_sizes = [len(encoder) + 1 for encoder in encoders]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true,"scrolled":false,"_uuid":"9331916f6c4cbb3d5bcab861eae2e570d0efa107"},"cell_type":"code","source":"encoders","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5bf2378577fd33be04381c60375c0a0fdb717a05"},"cell_type":"code","source":"# Handles numerical variables\nfrom sklearn.preprocessing import StandardScaler\nfrom datetime import datetime\n\nmarket_train[num_cols] = market_train[num_cols].fillna(0)\nprint('scaling numerical columns')\n\nscaler = StandardScaler()\nprint(market_train['time'].dtypes)\nmarket_train[num_cols] = scaler.fit_transform(market_train[num_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18e5e76f95e647df8e4ac508b4c40e38ec9b9c7c"},"cell_type":"code","source":"# Prepare data and get variables to calculate scoring metric\ndef get_input(market_train, indices):\n    X_num = market_train.loc[indices, num_cols].values\n    X = {'num': X_num}\n    for cat in cat_cols:\n        X[cat] = market_train.loc[indices, cat_cols].values\n    y = (market_train.loc[indices, 'returnsOpenNextMktres10'] >= 0).values\n    r = market_train.loc[indices, 'returnsOpenNextMktres10'].values\n    u = market_train.loc[indices, 'universe']\n    d = market_train.loc[indices, 'time'].dt.date\n    return X, y, r, u, d # r, u, and d are used to calculate the scoring metric\n\nX_train, y_train, r_train, u_train, d_train = get_input(market_train, train_indices)\nX_valid, y_valid, r_valid, u_valid, d_valid = get_input(market_train, val_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"767fd36a49f03fb0a90d7baa63ccffc5e4a7af44"},"cell_type":"code","source":"# Magic XG Boost Model\nfrom xgboost import XGBClassifier\nimport warnings\nwarnings.filterwarnings(action='ignore',category=DeprecationWarning)\n\nmodel = XGBClassifier(n_jobs = 4, n_estimators = 47, max_depth = 6)\nmodel.fit(X_train['num'], y_train.astype(int))\nconfidence_valid = model.predict(X_valid['num'])*2-1\nscore = accuracy_score(confidence_valid>0, y_valid)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"cd955122746aaf88f803a52b406f7a8423267090"},"cell_type":"code","source":"# Calculation of actual metric that is used for final score\nr_valid = r_valid.clip(-1,1) # get rid out outliers\nx_t_i = confidence_valid * r_valid * u_valid\ndata = {'day': d_valid, 'x_t_i' : x_t_i}\ndf = pd.DataFrame(data)\nx_t = df.groupby('day').sum().values.flatten()\nmean = np.mean(x_t)\nstd = np.std(x_t)\nscore_valid = mean / std\nprint(score_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06f71825e9ad13a8244b122b330687ddb5f3b352"},"cell_type":"code","source":"r_valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de1a9dddc1fa8ca457529ef4c37af9a96e7265ab"},"cell_type":"code","source":"x_t_i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"6ba5a21adc7c25da8369553462fb26ba70993ff9"},"cell_type":"code","source":"confidence_valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"978ab06d0f5ba76c407c9abc2b241b2443ac6ad5"},"cell_type":"code","source":"y_valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bdf4e98512c943a73dbf93b3752c76d6a5f8a9d"},"cell_type":"code","source":"plt.hist(confidence_valid, bins = 'auto')\nplt.title(\"predicted confidence\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}