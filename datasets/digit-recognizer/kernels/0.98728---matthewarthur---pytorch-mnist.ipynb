{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport torch \nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.datasets as dsets\nfrom skimage import transform\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport pandas as pd;\nimport numpy as np;\nfrom torch.utils.data import Dataset, DataLoader\n#from vis_utils import *\nimport random;\nimport math;\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"sample = pd.read_csv(\"../input/sample_submission.csv\") \nsample.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dc5e713c995cdc8d1e85eb27e79a6aa0367014d"},"cell_type":"code","source":"test = pd.read_csv(\"../input/test.csv\") \ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad9fb5fc082a4334030a2a4103b803119a99ed8e"},"cell_type":"code","source":"test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"937cc50c447c9545a645928f546b457ed0a910e3"},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\") \ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e52aafbc159d5422b093f53dfbf1015c0ff79b2f"},"cell_type":"code","source":"print(torch.__version__)\n!python --version","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3148d0be13d467a8056786ed251e7922ee67a541"},"cell_type":"code","source":"class Dataset(object):\n    \"\"\"An abstract class representing a Dataset.\n    All other datasets should subclass it. All subclasses should override\n    ``__len__``, that provides the size of the dataset, and ``__getitem__``,\n    supporting integer indexing in range from 0 to len(self) exclusive.\n    \"\"\"\n\n    def __getitem__(self, index):\n        raise NotImplementedError\n\n    def __len__(self):\n        raise NotImplementedError\n\n    def __add__(self, other):\n        return ConcatDataset([self, other])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8aed3fda8271e6113a755f9373fec616f8eae88"},"cell_type":"code","source":"class digitDataset(Dataset):\n    \n    def __init__(self, file_path, transform=None):\n        self.data = pd.read_csv(file_path)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        # load image as ndarray type (Height * Width * Channels)\n        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n        # in this example, i don't use ToTensor() method of torchvision.transforms\n        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n        image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape((1, 28, 28))\n        label = self.data.iloc[index, 0]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a49a28e5c9dd0ba01d0b2818a095359e9c7101cc"},"cell_type":"code","source":"class digitDatasetTrain(Dataset):\n    \n    def __init__(self, file_path, transform=None):\n        self.data = pd.read_csv(file_path)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        # load image as ndarray type (Height * Width * Channels)\n        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n        # in this example, i don't use ToTensor() method of torchvision.transforms\n        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n        image = self.data.iloc[index, 0:].values.astype(np.uint8).reshape((1, 28, 28))\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afcf602d73df8c2b3b2233da944f15adba01952e"},"cell_type":"code","source":"train_dataset = digitDataset('../input/train.csv', transform=None)\ntest_dataset = digitDatasetTrain('../input/test.csv', transform=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1d867f2af778cf2063dd4eaed054239184ff46d"},"cell_type":"code","source":"train_dataset.__getitem__(0)\ntest_dataset.__getitem__(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32e7fd58b177c176f599e1e2a16bc706ae4737b2"},"cell_type":"code","source":"class NeuralNet(nn.Module):\n    \"\"\"A Neural Network with a hidden layer\"\"\"\n    def __init__(self, input_size,hidden_size,output_size):\n        super(NeuralNet, self).__init__()\n        self.layer1 = nn.Linear(input_size, hidden_size)\n        self.layer2 = nn.Linear(hidden_size, output_size)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        output = self.layer1(x)\n        output = self.relu(output)\n        output = self.layer2(output)\n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49ec4641dabb10f349ff6c93bd12ae168254c5a5"},"cell_type":"code","source":"num_epochs = 5;\nbatch_size = 100;\nlearning_rate = 0.01;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64606b0219b31b8757834c3d79890dca8d96dd5e"},"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=batch_size,\n                                           shuffle=True);\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db4a0435176f9cf457fb841537a1138383d3d7d2"},"cell_type":"code","source":"test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                         batch_size=28000,\n                                         shuffle=False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7de6fd693c4fdaab5c8eab6457e7e0235cf61944"},"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(2))\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2))\n        self.fc = nn.Linear(7*7*32, 10)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"910afc5216598d6c2f9584860c154b81f23c245b"},"cell_type":"code","source":"#instance of the Conv Net\ncnn = CNN();\n#loss function and optimizer\ncriterion = nn.CrossEntropyLoss();\noptimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35a6be5e528d7419362373928325f91a126e14bc"},"cell_type":"code","source":"losses = [];\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        images = Variable(images.float())\n        labels = Variable(labels)\n        \n        # Forward + Backward + Optimize\n        optimizer.zero_grad()\n        outputs = cnn(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        losses.append(loss.item());\n        \n        if (i+1) % 100 == 0:\n            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c20a0ae9471deae8abe9d65551909f2278151d55"},"cell_type":"code","source":"cnn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d04c4e0c0e153299ecde3ab8eb7b7acd4de11fea"},"cell_type":"code","source":"\nfor i, (images) in enumerate(test_loader):\n        images = Variable(images.float())\n        outputs = cnn(images)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"777d0cf768f34aac0a760b179253eb7f33fda38f"},"cell_type":"code","source":"print(outputs.size())\nprint(outputs.type())\nprint(outputs.dim())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2aa45e93ef09ba6d1bb9c82d6e8b29fa0799b91"},"cell_type":"code","source":"print(outputs[[27999]])\nprint(outputs[:2, :])\noutarray = outputs.detach().numpy()\noutarray[[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3531a1b8fddeaa5fc2ba52ea4d090b548e7b7dc"},"cell_type":"code","source":"outarray2 = outarray.argmax(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"042a27b2a5cf12e459363ca81ac31e4f8a391ba0"},"cell_type":"code","source":"outarray2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dc87cfdb0984365e91d2ec2fbb67d1a48800568"},"cell_type":"code","source":"outarray2[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95cef6aadbe7932de634a8d56bdf0b1e78f753cf"},"cell_type":"code","source":"out3 = outarray2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ce3db9bb0e005a6935fbe48e6b42bf9bd05099e"},"cell_type":"code","source":"out3[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3d12858559bbdf3c46b1d84dff1e753da046a0e"},"cell_type":"code","source":"y = np.arange(28000)\ny1 = y + 1\nprint(y1[0:10])\nprint(out3[0:10])\nout3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5b44972cd395614732cb1ffee69848da511460a"},"cell_type":"code","source":"preds = np.column_stack((y1,out3))\npreds = preds.astype(int)\nprint(preds.size)\npreds[:, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61b6d8d61777a1cbb0b530836e1d01ed948b773e"},"cell_type":"code","source":"np.savetxt(\"submission1.csv\", preds, header=\"ImageId,Label\", delimiter=\",\",comments='', fmt='%i')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56832379df613e337f89ec113a9dd163749f45b8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}