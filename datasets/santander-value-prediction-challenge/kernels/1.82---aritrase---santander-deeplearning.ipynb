{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\nprint(\"Train rows and columns : \", train_df.shape)\nprint(\"Test rows and columns : \", test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6356dd02995929e947fa9a0f01ff47eacce7a62","collapsed":true},"cell_type":"code","source":"y = train_df['target'].copy()\ny = np.log1p(y)\nX = train_df.drop(labels=['target','ID'],axis=1)\nX_test = test_df.drop(labels=['ID'],axis=1)\n#X.head()\nprint(type(y))\nprint(X.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5895afbb21546911abd18b786ff98d6cc88d31d8"},"cell_type":"code","source":"# Function to find out % of missing values in each column\ndef missing_values_table(df): \n        mis_val = df.isnull().sum()\n        mis_val_percent = 100 * df.isnull().sum()/len(df)\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b297bb87606a1a2207a774deb8a60e74d6ddf37","collapsed":true},"cell_type":"code","source":"# Capturing the columns with more than 95% of missing values\nmis_val_table_ren_columns = missing_values_table(X)\n#print(mis_val_table_ren_columns)\nnan_col = list(mis_val_table_ren_columns[mis_val_table_ren_columns['% of Total Values']> 95].index)\nprint(nan_col) # no missing values column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71c0dba788b66a9fed5d75e04eb780336a3029cc","collapsed":true},"cell_type":"code","source":"#Finding out the no variation columns\n# 256 cols with no variation\nfor col in X.columns.values:\n    if(len(X[col].unique()) == 1):\n        nan_col.append(col)\nprint(len(nan_col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31c5c85dd3013e214fe6d9b904dd76e1c712e257","collapsed":true},"cell_type":"code","source":"# Drop these columns = missing values + no variance column\nX.drop(nan_col,inplace = True ,axis=1)\nX_test.drop(nan_col,inplace = True ,axis=1)\nprint(X.shape)\nprint(X_test.shape)\nprint(type(X))\nprint(type(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2040505c374e024daf695abe15dee3ed3907f412"},"cell_type":"code","source":"# Feature Scaling - StandardScaler\n\"\"\"\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX = sc_X.fit_transform(X)\nX_test = sc_X.transform(X_test)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3cf28ca1ec0993b15b8e766d9aa4a13a294a7ccd"},"cell_type":"code","source":"# Feature Scaling - normalize\nfrom sklearn.preprocessing import normalize\nX = normalize(X)\nX_test = normalize(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b0fd773c0bff67db2490c01993459b4c20ec756","collapsed":true},"cell_type":"code","source":"import numpy\nimport pandas\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"45de4cf2ea848fd32522c0c007fd4fd7bbe1ebc4"},"cell_type":"code","source":"# define base model\ndef baseline_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(1024, input_dim= 4735, kernel_initializer='normal', activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(512,kernel_initializer='normal', activation='tanh'))\n    model.add(Dropout(0.2))\n    model.add(Dense(200,kernel_initializer='normal', activation='tanh'))\n    model.add(Dropout(0.2))\n    model.add(Dense(150,kernel_initializer='normal', activation='tanh'))\n    model.add(Dropout(0.2))\n    model.add(Dense(100,kernel_initializer='normal', activation='tanh'))\n    model.add(Dropout(0.2))\n    model.add(Dense(50,kernel_initializer='normal', activation='tanh'))\n    model.add(Dropout(0.2))\n    model.add(Dense(1, kernel_initializer='normal', activation = 'linear'))\n    # Compile model\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2e9cda1a05d4028c280fc660cc3ab0861267ae8e"},"cell_type":"code","source":"# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n# evaluate model with standardized dataset\nestimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=500, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85af55cd863173fa6a46845a09913851f45a8586","collapsed":true},"cell_type":"code","source":"#kfold = KFold(n_splits=5, random_state=seed)\n#results = cross_val_score(estimator, X, y, cv=kfold)\n#print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93d5b28f36db808cf3b99d870c7c4776c0a8a130","collapsed":true},"cell_type":"code","source":"estimator.fit(\n        X, \n        y, \n        epochs=500,\n        #validation_data=(X_val, y_val),\n        #verbose=2\n        #callbacks=callbacks,\n        #shuffle=True\n    )\npred_nn = np.expm1(estimator.predict(X_test))\npred_nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7e64f9479fa2fa760942b5e76eba954249dc6765"},"cell_type":"code","source":"# Making a submission file #\nsub_df = pd.DataFrame({\"ID\":test_df[\"ID\"].values})\nsub_df[\"target\"] = pred_nn\nsub_df.to_csv(\"submission_dl_normalize.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a4bc21342201d6d95d5d79723c4af3a228c02180"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}