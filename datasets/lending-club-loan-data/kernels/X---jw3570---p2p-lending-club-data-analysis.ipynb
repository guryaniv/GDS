{"nbformat_minor": 1, "cells": [{"source": ["<h2>Exploring the dataset!</h2>"], "cell_type": "markdown", "metadata": {}}, {"source": ["<h3>Data</h3>\n", "<li>The original data set is an aggregate of issued loans from Lending Club through 2007-2015. It contains <b style=\"color:blue\">890</b> thousand observations and <b style=\"color:blue\">75</b> variables."], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "pd.set_option('max_columns',None)\n", "sns.set(style=\"white\", color_codes=True)\n", "%matplotlib inline\n", "\n", "df = pd.read_csv('../input/loan.csv') "], "cell_type": "code", "execution_count": 1}, {"source": ["<h3>Loan Information</h3>"], "cell_type": "markdown", "metadata": {}}, {"source": ["<h4>Loan Amount</h4>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["sns.set_style(\"whitegrid\")\n", "fig, axs = plt.subplots(1,2,figsize=(18,6))\n", "sns.distplot(df.loan_amnt, ax=axs[0])\n", "axs[0].set(xlabel='Loan Amount', \n", "       ylabel='% Distribution',title='Density Plot of Loan Amount')\n", "sns.violinplot(df.loan_amnt,color=\"g\", ax=axs[1])\n", "axs[1].set(xlabel='Loan Amount', \n", "       ylabel='Distribution',title='Violin Plot of Loan Amount')\n", "plt.legend()\n", "plt.show()"], "cell_type": "code", "execution_count": 2}, {"source": ["<h4>Loan Status</h4>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["plt.rcParams['figure.figsize'] = (9,9)\n", "def status_class(text):\n", "    if text=='Fully Paid':\n", "        return 'Fully Paid'\n", "    elif text=='Charged Off' or text=='Default':\n", "        return 'Default'\n", "    elif text=='Current' or text=='Issued':\n", "        return 'Current'\n", "    else:\n", "        return 'Late'\n", "\n", "df['status_class']=df['loan_status'].apply(status_class)\n", "df.groupby('status_class').size().plot(kind='pie')"], "cell_type": "code", "execution_count": 3}, {"source": ["<h4>Purpose</h4>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {"scrolled": false}, "source": ["plt.rcParams['figure.figsize'] = (9,9)\n", "df.groupby('purpose').size().plot(kind='pie')"], "cell_type": "code", "execution_count": 4}, {"source": ["<h4>Word Cloud of Title</h4>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["import nltk\n", "import collections as co\n", "l = []\n", "df['title'].apply(lambda x: l.append(x))\n", "s=str(l)"], "cell_type": "code", "execution_count": 5}, {"outputs": [], "metadata": {}, "source": ["plt.rcParams['figure.figsize'] = (9,6)\n", "from wordcloud import WordCloud, STOPWORDS\n", "\n", "text = s\n", "\n", "wordcloud = WordCloud(stopwords=STOPWORDS,background_color='white', max_words=120, width=800, height=400).generate(text)\n", "\n", "plt.imshow(wordcloud)\n", "plt.axis('off')\n", "plt.show()"], "cell_type": "code", "execution_count": 6}, {"source": ["<h3>Borrower Information</h3>"], "cell_type": "markdown", "metadata": {}}, {"source": ["<h4>Employment Length</h4>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["fig, axs = plt.subplots(1,2,figsize=(18,8))\n", "df.groupby('emp_length').size().plot(kind='pie',ax=axs[0])\n", "\n", "def emp_length_class(text):\n", "    if text=='< 1 year' or text=='1 year' or text=='2 years' or text=='3 years':\n", "        return '<=3 years'\n", "    elif text=='4 years' or text=='5 years' or text=='6 years':\n", "        return '4-6 years'\n", "    elif text=='7 years' or text=='8 years' or text=='9 years':\n", "        return '7-9 years'\n", "    elif text=='10+ years':\n", "        return '>=10 years'\n", "    else:\n", "        return None\n", "df['emp_length_class']=df['emp_length'].apply(emp_length_class)\n", "df.groupby('emp_length_class').size().plot(kind='pie',ax=axs[1])\n", "\n", "plt.show()"], "cell_type": "code", "execution_count": 7}, {"source": ["<h4>Annual Income</h4>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["plt.rcParams['figure.figsize'] = (9,6)\n", "df[\"annual_inc\"].plot.density(logx = True)"], "cell_type": "code", "execution_count": 8}, {"outputs": [], "metadata": {}, "source": ["plt.rcParams['figure.figsize'] = (9,9)\n", "def inc_class(num):\n", "    if num <= 50000:\n", "        return '<=50000'\n", "    elif num <= 75000:\n", "        return '50000-75000'\n", "    elif num <= 100000:\n", "        return '75000-100000'\n", "    elif num <= 125000:\n", "        return '100000-125000'\n", "    elif num <= 150000:\n", "        return '125000-150000'\n", "    else:\n", "        return '>150000'\n", "\n", "df['inc_class']=df['annual_inc'].apply(inc_class)\n", "df.groupby('inc_class').size().plot(kind='pie')"], "cell_type": "code", "execution_count": 9}, {"source": ["<h3>Interest Rate</h3>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["plt.rcParams['figure.figsize'] = (9,6)\n", "ax=sns.distplot(df.int_rate, color=\"r\")\n", "ax.set(xlabel='Interest Rate %', \n", "       ylabel='% Distribution',title='Density Plot of Interest Rate')\n", "\n", "plt.legend();"], "cell_type": "code", "execution_count": 10}, {"source": ["<h4>Interest Rate by Term / Employment Length / Application Type / Purpose</h4>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["fig, axes = plt.subplots(2, 2, figsize=(18,12))\n", "\n", "sns.boxplot(x='term', y='int_rate', data=df, ax=axes[0, 0])\n", "sns.boxplot(x='emp_length', y='int_rate', data=df, ax=axes[0, 1])\n", "plt.xticks(rotation=50)\n", "sns.boxplot(x='application_type', y='int_rate', data=df, ax=axes[1, 0])\n", "plt.xticks(rotation=90)\n", "sns.boxplot(x='purpose', y='int_rate', data=df, ax=axes[1, 1])\n", "plt.xticks(rotation=90)\n", "\n", "plt.show()"], "cell_type": "code", "execution_count": 11}, {"source": ["<h3>Credit Grade</h3>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["fig, axs = plt.subplots(1,2,figsize=(18,6))\n", "sns.countplot(df['grade'], order = ('A','B','C','D','E','F','G'), ax=axs[0])\n", "\n", "l = []\n", "for i in ['A', 'B', 'C', 'D', 'E', 'F', 'G']:\n", "    for j in ['1', '2', '3', '4', '5']:\n", "        l.append(i+j)     \n", "sns.countplot(df['sub_grade'], order = l, ax=axs[1])\n", "\n", "plt.show()"], "cell_type": "code", "execution_count": 12}, {"source": ["<h4>Interest Rate by Grade</h4>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["fig, axs = plt.subplots(1,2,figsize=(18,6))\n", "df[['grade','int_rate']].groupby('grade').mean().plot(kind='bar', ax=axs[0])\n", "sns.boxplot(x='grade', y='int_rate', data=df, order = 'ABCDEFG', ax=axs[1])\n", "plt.show()"], "cell_type": "code", "execution_count": 13}, {"source": ["<h4>Loan Amount by Grade</h4>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["fig, axs = plt.subplots(1,2,figsize=(18,6))\n", "\n", "def loan_class(num):\n", "    if num <= 10000:\n", "        return '<=10000'\n", "    elif num <= 20000:\n", "        return '10000-20000'\n", "    elif num <= 30000:\n", "        return '20000-30000'\n", "    else:\n", "        return '>30000'\n", "df['loan_class']=df['loan_amnt'].apply(loan_class)\n", "df.groupby(['grade','loan_class']).size().unstack().plot(kind='bar', ax=axs[0])\n", "sns.boxplot(x='grade', y='loan_amnt', data=df, order = 'ABCDEFG', ax=axs[1])\n", "plt.show()"], "cell_type": "code", "execution_count": 14}, {"source": ["<h4>Term by Grade</h4>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["df.groupby(['grade','term']).size().unstack().plot(kind='bar')"], "cell_type": "code", "execution_count": 15}, {"source": ["<h3>Default Situation</h3>"], "cell_type": "markdown", "metadata": {}}, {"source": ["<h4>Default by Grade</h4>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["grade_status = df[df['status_class']!='Current'].groupby(['status_class','grade']).size().unstack()\n", "COL_NUM = 3\n", "ROW_NUM = 3\n", "fig, axes = plt.subplots(ROW_NUM, COL_NUM, figsize=(12,12))\n", "\n", "for i, (grade, status_count) in enumerate(grade_status.items()): \n", "    ax = axes[int(i/COL_NUM), i%COL_NUM]\n", "    status_count.plot(kind='pie', ax=ax)\n", "    ax.set_title(grade)\n", "\n", "axes[2, 1].axis('off')\n", "axes[2, 2].axis('off')\n", "plt.tight_layout()"], "cell_type": "code", "execution_count": 16}, {"source": ["<h4>Default Rate by Purpose</h4>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["#Among 10 kinds of purposes, we only cares about 'Fully paid' and 'Chareged off'\n", "df_sub = df[(df[\"loan_status\"] == \"Fully Paid\") |(df[\"loan_status\"] == \"Charged Off\")]\n", "filtered_loans = df_sub\n", "fig, axs = plt.subplots(1,2,figsize=(14,7))\n", "sns.countplot(x='loan_status',data=filtered_loans,ax=axs[0])\n", "axs[0].set_title(\"Frequency of each Loan Status\")\n", "filtered_loans.loan_status.value_counts().plot(x=None,y=None, kind='pie', ax=axs[1],autopct='%1.2f%%')\n", "axs[1].set_title(\"Percentage of each Loan status\")\n", "plt.show()"], "cell_type": "code", "execution_count": 17}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["#Assign dummy variable to loan status\n", "mapping_dictionary = {\"loan_status\":{ \"Fully Paid\": 0, \"Charged Off\": 1}}\n", "filtered_loans = filtered_loans.replace(mapping_dictionary)"], "cell_type": "code", "execution_count": 18}, {"outputs": [], "metadata": {}, "source": ["plt.rcParams['figure.figsize'] = (9,6)\n", "purpose_=pd.pivot_table(filtered_loans, index = 'purpose',values = 'loan_status', aggfunc=[np.sum,len,np.mean])\n", "plt.show(purpose_['mean'].plot(kind = 'bar')) "], "cell_type": "code", "execution_count": 19}, {"outputs": [], "metadata": {}, "source": ["COL_NUM = 3\n", "ROW_NUM = 3\n", "fig, axes = plt.subplots(ROW_NUM, COL_NUM, figsize=(15,15))\n", "\n", "for i,g in enumerate(['A', 'B', 'C', 'D', 'E', 'F', 'G']):\n", "    p = pd.pivot_table(filtered_loans[filtered_loans['grade'] == g], index = 'purpose', values = 'loan_status', aggfunc=[np.sum,len,np.mean])['mean']\n", "    ax = axes[int(i/COL_NUM), i%COL_NUM]\n", "    p.plot(kind='bar', ax=ax)\n", "    ax.set_title(g)\n", "\n", "axes[2, 1].axis('off')\n", "axes[2, 2].axis('off')\n", "plt.tight_layout()"], "cell_type": "code", "execution_count": 20}, {"source": ["<h4>Default by State</h4>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["import itertools\n", "from sklearn import preprocessing\n", "import plotly.plotly as py\n", "import plotly.graph_objs as go\n", "from plotly import tools\n", "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n", "init_notebook_mode(connected=True)"], "cell_type": "code", "execution_count": 21}, {"outputs": [], "metadata": {}, "source": ["State_List = []\n", "for x in df['addr_state']:\n", "    if x not in State_List:\n", "        State_List.append(x)\n", "\n", "Loan_Amount = []\n", "Average_Balance = []\n", "Default_Rate = []\n", "Weighted_Rate = []\n", "Average_Income = []\n", "Average_Employment_Length = []\n", "Average_DTI = []\n", "Average_Inq_12 = []\n", "Average_Inq_6 = []\n", "\n", "for x in State_List:\n", "    new_df = df[df['addr_state'] == x]\n", "    \n", "    Loan_Sum = sum(new_df['funded_amnt'])\n", "    Loan_Amount.append(Loan_Sum)\n", "    \n", "    Average_Balance.append(Loan_Sum/len(new_df['funded_amnt']))\n", "    \n", "    Defaults = []\n", "    for value in new_df.loan_status:\n", "        if value == 'Default':\n", "            Defaults.append(1)\n", "        if value == 'Charged Off':\n", "            Defaults.append(1)\n", "        if value == 'Late (31-120 days)':\n", "            Defaults.append(1)   \n", "        if value == 'Late (16-30 days)':\n", "            Defaults.append(1)\n", "        if value == 'Does not meet the credit policy. Status:Charged Off':\n", "            Defaults.append(1) \n", "    Default_R = len(Defaults) / len(new_df.loan_status)  \n", "    Default_Rate.append(Default_R)\n", "    \n", "    new_df['weighted'] = (new_df['int_rate']/100)*new_df['funded_amnt']\n", "    Weighted_Sum = sum(new_df['weighted'])\n", "    Weighted_i_rate = Weighted_Sum / Loan_Sum\n", "    Weighted_Rate.append(Weighted_i_rate)\n", "    \n", "    Income_Average = np.mean(new_df['annual_inc'])\n", "    Average_Income.append(Income_Average)\n", "\n", "    Employ_Length = []\n", "    for term in new_df.emp_length:\n", "        if term == '10+ years':\n", "            Employ_Length.append(10)\n", "        if term == '< 1 year':\n", "            Employ_Length.append(0.5)    \n", "        if term == '1 year':\n", "            Employ_Length.append(1)\n", "        if term == '3 years':\n", "            Employ_Length.append(3)\n", "        if term == '8 years':\n", "            Employ_Length.append(8)\n", "        if term == '9 years':\n", "            Employ_Length.append(9)    \n", "        if term == '4 years':\n", "            Employ_Length.append(4)\n", "        if term == '5 years':\n", "            Employ_Length.append(5)\n", "        if term == '6 years':\n", "            Employ_Length.append(6)\n", "        if term == '2 years':\n", "            Employ_Length.append(2)    \n", "        if term == '7 years':\n", "            Employ_Length.append(7)\n", "        if term == 'n/a':\n", "            Employ_Length.append(0)  \n", "            \n", "    Average_Employment_Length.append(np.mean(Employ_Length))        \n", "    \n", "    DTI_Average = np.mean(new_df['dti'])\n", "    Average_DTI.append(DTI_Average)\n", "    \n", "    inquiry_average = np.mean(new_df['inq_last_12m'])\n", "    Average_Inq_12.append(inquiry_average)\n", "    \n", "    inquiry_average_6 = np.mean(new_df['inq_last_6mths'])\n", "    Average_Inq_6.append(inquiry_average_6)\n", "    \n", "from collections import OrderedDict\n", "combine_data = OrderedDict([ ('Loan_Funding',Loan_Amount),\n", "                         ('Average_Balance', Average_Balance),\n", "                         ('Default_Rate',  Default_Rate),\n", "                         ('Weighted_Rate', Weighted_Rate),\n", "                         ('Average_Income', Average_Income),\n", "                         ('Average_Employment_Length', Average_Employment_Length),\n", "                         ('Average_DTI', DTI_Average),\n", "                         ('12m_Inquiries', Average_Inq_12),\n", "                         ('6m_Inquiries', Average_Inq_6),   \n", "                         ('code', State_List)])\n", "\n", "df_plot = pd.DataFrame.from_dict(combine_data)\n", "df_plot = df_plot.round(decimals=2)"], "cell_type": "code", "execution_count": 22}, {"outputs": [], "metadata": {}, "source": ["for col in df_plot.columns:\n", "    df_plot[col] = df_plot[col].astype(str)\n", "\n", "    scl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],\\\n", "            [0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']]\n", "\n", "df_plot['text'] = df_plot['code'] + '<br>' +\\\n", "    '<br>'+'Weighted Rate: '+df_plot['Weighted_Rate']+'<br>'+\\\n", "    'Inquiries Last 12m: '+df_plot['12m_Inquiries']+'<br>'+\\\n", "    'Inquiries Last 6m: '+df_plot['6m_Inquiries']\n", "\n", "data = [ dict(\n", "        type='choropleth',\n", "        colorscale = scl,\n", "        autocolorscale = True,\n", "        locations = df_plot['code'],\n", "        z = df_plot['Default_Rate'], #.astype(int),\n", "        locationmode = 'USA-states',\n", "        text = df_plot['text'],\n", "        marker = dict(\n", "            line = dict (\n", "                color = 'rgb(255,255,255)',\n", "                width = 2\n", "            ) ),\n", "        colorbar = dict(\n", "            title = \"%\")\n", "        ) ]\n", "\n", "layout = dict(\n", "        title = 'Lending Club Portfolio<br> Default Rate By State <br> (Hover over state for other metrics)',\n", "        geo = dict(\n", "            scope='usa',\n", "            projection=dict( type='albers usa' ),\n", "            showlakes = True,\n", "            lakecolor = 'rgb(255, 255, 255)'),\n", "             )\n", "    \n", "fig = dict( data=data, layout=layout )\n", "iplot( fig, filename='d3-cloropleth-map' )"], "cell_type": "code", "execution_count": 23}, {"source": ["<h3>Other Maps</h3>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["for col in df_plot.columns:\n", "    df_plot[col] = df_plot[col].astype(str)\n", "\n", "    scl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],\\\n", "            [0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']]\n", "\n", "df_plot['text'] = df_plot['code'] + '<br>' +\\\n", "    'Avg Balance Per Borrower ($ USD): '+df_plot['Average_Balance']+'<br>'+\\\n", "    'Avg Employment Term Per Borrower (Years): '+df_plot['Average_Employment_Length']+'<br>'+\\\n", "    'Avg Annual Income Per Borrower ($ USD): '+df_plot['Average_Income']\n", "    \n", "\n", "data = [ dict(\n", "        type='choropleth',\n", "        colorscale = scl,\n", "        autocolorscale = False,\n", "        locations = df_plot['code'],\n", "        z = df_plot['Loan_Funding'], \n", "        locationmode = 'USA-states',\n", "        text = df_plot['text'],\n", "        marker = dict(\n", "            line = dict (\n", "                color = 'rgb(255,255,255)',\n", "                width = 2\n", "            ) ),\n", "        colorbar = dict(\n", "            title = \"$s USD\")\n", "        ) ]\n", "\n", "layout = dict(\n", "        title = 'Lending Club Portfolio<br> Total Funded By State <br> (Hover over state for other metrics)',\n", "        geo = dict(\n", "            scope='usa',\n", "            projection=dict( type='albers usa' ),\n", "            showlakes = True,\n", "            lakecolor = 'rgb(255, 255, 255)'),\n", "             )\n", "    \n", "fig = dict( data=data, layout=layout )\n", "iplot( fig, filename='d3-cloropleth-map' )"], "cell_type": "code", "execution_count": 24}, {"outputs": [], "metadata": {}, "source": ["state_average_int_rate=df.groupby('addr_state').agg({'int_rate':np.average,'id':np.count_nonzero,'annual_inc':np.average})\n", "state_average_int_rate.reset_index(inplace=True)\n", "state_average_int_rate['id']=state_average_int_rate['id'].astype(str)\n", "state_average_int_rate['interest']=state_average_int_rate['int_rate']\n", "state_average_int_rate['int_rate']= 'Average Interest Rate: ' + \\\n", "state_average_int_rate['int_rate'].apply(lambda x: str(round(x,2)))+ \"%\"\n", "state_average_int_rate['annual_inc']=(state_average_int_rate['annual_inc']/1000.0)\n", "state_average_int_rate['annual_inc']=state_average_int_rate['annual_inc'].apply(lambda x: str(round(x,2)))\n", "state_average_int_rate['text']='Number of Applicants: ' + state_average_int_rate['id']+'<br>'+ \\\n", "'Average Annual Inc: $'+ state_average_int_rate['annual_inc']+'k'\n", "\n", "scl= [[0,\"rgb(5, 10, 172)\"],[0.35,\"rgb(40, 60, 190)\"],[0.5,\"rgb(70, 100, 245)\"],\\\n", "            [0.6,\"rgb(90, 120, 245)\"],[0.7,\"rgb(106, 137, 247)\"],[1,\"rgb(220, 220, 220)\"]]\n", "\n", "data = [ dict(\n", "        type='choropleth',\n", "        colorscale = scl,\n", "        autocolorscale = False,\n", "        locations = state_average_int_rate['addr_state'],\n", "        z = state_average_int_rate['interest'].astype(float),\n", "        text=state_average_int_rate['text'],\n", "        locationmode = 'USA-states',\n", "        marker = dict(\n", "            line = dict (\n", "                color = 'rgb(255,255,255)',\n", "                width = 2\n", "            ) ),\n", "        colorbar = dict(\n", "            title = \"Interest Rates\")\n", "        ) ]\n", "\n", "layout = dict(\n", "        title = '<b>Interest Rate by US States</b><br>Additional Details: <br> Avreage Annual Inc \\t Number of Applicants',\n", "        geo = dict(\n", "            scope='usa',\n", "            projection=dict( type='albers usa' ),\n", "        \n", "             ))\n", "    \n", "fig = dict( data=data, layout=layout )\n", "iplot( fig, filename='d3-cloropleth-map' )"], "cell_type": "code", "execution_count": 25}, {"source": ["<h3>Correlation Matrix</h3>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["df2 = df.drop(['dti_joint','verification_status_joint','annual_inc_joint','il_util','mths_since_rcnt_il','all_util',\n", "               'max_bal_bc','open_rv_24m','open_rv_12m','total_cu_tl','total_bal_il','open_il_24m','open_il_12m',\n", "               'open_il_6m','open_acc_6m','inq_fi','inq_last_12m','desc','mths_since_last_record','mths_since_last_major_derog',\n", "               'mths_since_last_delinq','next_pymnt_d'],axis=1)\n", "df2 = df2.drop(['emp_title','total_rev_hi_lim','tot_coll_amt','tot_cur_bal'],axis=1)\n", "\n", "plt.rcParams['figure.figsize'] = (20,20)\n", "corr=df2.corr()\n", "corr = (corr)\n", "sns.set_palette(\"RdBu_r\")\n", "sns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 10}, xticklabels=corr.columns.values, yticklabels=corr.columns.values, cmap=\"RdBu_r\").set_title('Heatmap of Correlation Matrix')\n", "\n", "#  sns.plt.title('Heatmap of Correlation Matrix') "], "cell_type": "code", "execution_count": 26}, {"source": ["<h3>Data Cleaning</h3>"], "cell_type": "markdown", "metadata": {"collapsed": true}}, {"outputs": [], "metadata": {}, "source": ["import pandas as pd\n", "df = pd.read_csv('../input/loan.csv') \n", "\n", "df=df.drop(['id','member_id','funded_amnt','funded_amnt_inv','sub_grade','emp_title','issue_d','zip_code',\n", "            'out_prncp','out_prncp_inv','total_pymnt','total_pymnt_inv','total_rec_prncp','total_rec_int','total_rec_late_fee',\n", "            'recoveries','collection_recovery_fee','last_pymnt_d','last_pymnt_amnt','desc','url','title',\n", "            'initial_list_status','pymnt_plan','policy_code','application_type','earliest_cr_line','last_credit_pull_d',\n", "            'next_pymnt_d','addr_state'],axis=1)\n", "\n", "df=df.dropna(thresh=len(df)/2,axis=1)\n", "df=df.dropna()\n", "\n", "def status_binary(text):\n", "    if text=='Fully Paid':\n", "        return 0\n", "    elif text=='Current' or text=='Issued':\n", "        return -1\n", "    else:\n", "        return 1\n", "df['loan_status']=df['loan_status'].apply(status_binary)\n", "df=df[df['loan_status']!=-1]\n", "\n", "def purpose_class(text):\n", "    if text=='debt_consolidation' or text=='credit_card':\n", "        return 'refinance'\n", "    elif text=='house' or text=='home_improvement' or text=='renewable_energy' or text=='moving':\n", "        return 'home'\n", "    elif text=='car' or text=='major_purchase':\n", "        return 'major_purchase'\n", "    else:\n", "        return 'other'\n", "df['purpose']=df['purpose'].apply(purpose_class)\n", "\n", "dummy_df=pd.get_dummies(df[['home_ownership','verification_status','purpose','term']])\n", "df=df.drop(['home_ownership','verification_status','purpose','term'],axis=1)\n", "df=pd.concat([df,dummy_df],axis=1)\n", "\n", "mapping_dict={\n", "    'emp_length':{\n", "        '10+ years':10,\n", "        '9 years':9,\n", "        '8 years':8,\n", "        '7 years':7,\n", "        '6 years':6,\n", "        '5 years':5,\n", "        '4 years':4,\n", "        '3 years':3,\n", "        '2 years':2,\n", "        '1 year':1,\n", "        '< 1 year':0,\n", "        'n/a':0\n", "    },\n", "    'grade':{\n", "        'A':1,\n", "        'B':2,\n", "        'C':3,\n", "        'D':4,\n", "        'E':5,\n", "        'F':6,\n", "        'G':7,\n", "    }\n", "}\n", "df=df.replace(mapping_dict)\n", "\n", "cols = list(df)\n", "cols.insert(0, cols.pop(cols.index('loan_status')))\n", "df = df.ix[:, cols]\n", "df.head()"], "cell_type": "code", "execution_count": 27}, {"source": ["<h3>Machine Learning</h3>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["from sklearn.model_selection import train_test_split\n", "train, test = train_test_split(df, test_size = 0.3)\n", "x_train = train.iloc[0:,1:34]\n", "y_train = train[['loan_status']]\n", "x_test = test.iloc[0:,1:34]\n", "y_test = test[['loan_status']]"], "cell_type": "code", "execution_count": 28}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["method = ['Decision Tree','Random Forests','Logistic Regression']\n", "false_paid=pd.DataFrame([[0,0,0],[0,0,0]],columns=method,index=['train','test'])\n", "default_identified=pd.DataFrame([[0,0,0],[0,0,0]],columns=method,index=['train','test'])"], "cell_type": "code", "execution_count": 29}, {"source": ["<h3>Decision Tree</h3>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["from sklearn.tree import DecisionTreeClassifier\n", "from sklearn import tree\n", "model = tree.DecisionTreeClassifier(max_depth = 5,criterion='entropy',class_weight={0: 0.15, 1: 0.85})\n", "model.fit(x_train,y_train)\n", "\n", "from sklearn.metrics import confusion_matrix\n", "import numpy as np\n", "p_train=model.predict(x_train)\n", "p_test = model.predict(x_test)\n", "\n", "fully_paid,default = confusion_matrix(p_train,np.array(y_train))\n", "false_paid.loc['train','Decision Tree']=100*fully_paid[1]/(fully_paid[0]+fully_paid[1])\n", "default_identified.loc['train','Decision Tree']=100*default[1]/(default[1]+fully_paid[1])\n", "\n", "fully_paid,default = confusion_matrix(p_test,np.array(y_test))\n", "false_paid.loc['test','Decision Tree']=100*fully_paid[1]/(fully_paid[0]+fully_paid[1])\n", "default_identified.loc['test','Decision Tree']=100*default[1]/(default[1]+fully_paid[1])"], "cell_type": "code", "execution_count": 30}, {"source": ["<h3>Random Forests</h3>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["from sklearn.ensemble import RandomForestClassifier\n", "model = RandomForestClassifier(max_depth = 6,n_estimators= 10,class_weight={0: 0.15, 1: 0.85})\n", "model.fit(x_train,np.ravel(y_train))\n", "\n", "from sklearn.metrics import confusion_matrix\n", "p_train=model.predict(x_train)\n", "p_test = model.predict(x_test)\n", "\n", "fully_paid,default = confusion_matrix(p_train,np.array(y_train))\n", "false_paid.loc['train','Random Forests']=100*fully_paid[1]/(fully_paid[0]+fully_paid[1])\n", "default_identified.loc['train','Random Forests']=100*default[1]/(default[1]+fully_paid[1])\n", "\n", "fully_paid,default = confusion_matrix(p_test,np.array(y_test))\n", "false_paid.loc['test','Random Forests']=100*fully_paid[1]/(fully_paid[0]+fully_paid[1])\n", "default_identified.loc['test','Random Forests']=100*default[1]/(default[1]+fully_paid[1])"], "cell_type": "code", "execution_count": 31}, {"source": ["<h3>Logistic Regression</h3>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["from sklearn.linear_model import LogisticRegression\n", "import numpy as np\n", "model = LogisticRegression(class_weight={0: 0.15, 1: 0.85})\n", "model.fit(x_train, np.ravel(y_train))\n", "\n", "from sklearn.metrics import confusion_matrix\n", "p_train=model.predict(x_train)\n", "p_test = model.predict(x_test)\n", "\n", "fully_paid,default = confusion_matrix(p_train,np.array(y_train))\n", "false_paid.loc['train','Logistic Regression']=100*fully_paid[1]/(fully_paid[0]+fully_paid[1])\n", "default_identified.loc['train','Logistic Regression']=100*default[1]/(default[1]+fully_paid[1])\n", "\n", "fully_paid,default = confusion_matrix(p_test,np.array(y_test))\n", "false_paid.loc['test','Logistic Regression']=100*fully_paid[1]/(fully_paid[0]+fully_paid[1])\n", "default_identified.loc['test','Logistic Regression']=100*default[1]/(default[1]+fully_paid[1])"], "cell_type": "code", "execution_count": 32}, {"source": ["<h3>Comparison</h3>"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["print('The portion of predicted fully paid loans that will default(%)')\n", "print(false_paid)\n", "print('\\n')\n", "print('The portion of default loans that are correctly identified(%)')\n", "print(default_identified)"], "cell_type": "code", "execution_count": 33}, {"outputs": [], "metadata": {}, "source": ["import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "fig, axs = plt.subplots(1,2,figsize=(14,6))\n", "false_paid.T.plot(kind='bar',ax=axs[0])\n", "axs[0].set_title('The portion of predicted fully paid loans that will default (%)')\n", "default_identified.T.plot(kind='bar',ax=axs[1])\n", "axs[1].set_title('The portion of default loans that are correctly identified (%)')\n", "plt.show()"], "cell_type": "code", "execution_count": 34}, {"source": ["<h3>Further Consideration</h3>"], "cell_type": "markdown", "metadata": {}}, {"source": ["As a investor, We can use data to make investing decisions."], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {}, "source": ["from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LogisticRegression\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "X = df.drop(['loan_status'],axis=1)\n", "Y = df['loan_status']\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n", "weight = y_train*4 + 1 \n", "logreg = LogisticRegression()\n", "# logreg.fit(X_train, y_train)\n", "logreg.fit(X_train, y_train, sample_weight=weight)\n", "y_pred = logreg.predict(X_test)\n", "plt.figure(figsize=(5,5))\n", "sns.distplot(logreg.predict_proba(X_train)[:,1])\n", "plt.show()"], "cell_type": "code", "execution_count": 36}, {"outputs": [], "metadata": {}, "source": ["def profit_predict(X_test, y_test, y_pred, recovery_rate = 0):\n", "    pv = X_test[np.logical_not(y_pred)]['loan_amnt'].sum()\n", "    fv = sum(X_test[np.logical_and(np.logical_not(y_p), np.logical_not(y_test))]['loan_amnt'] * \n", "                    (X_test[np.logical_and(np.logical_not(y_p), np.logical_not(y_test))]['int_rate'] + 100)/100)\n", "    return fv / pv - 1\n", "\n", "import numpy as np\n", "profit = []\n", "for i in np.arange(0.02, 1, 0.01):\n", "    y_p = logreg.predict_proba(X_test)[:,1] > i\n", "    profit.append(profit_predict(X_test, y_test, y_p))\n", "plt.figure(figsize=(5,5))\n", "plt.plot(np.arange(0.02, 1, 0.01), profit)\n", "plt.show()"], "cell_type": "code", "execution_count": 37}, {"source": ["If we choose default probability of 8% as threshold, we can achieve a <b>5%</b> annul return!"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {"collapsed": true}, "source": [], "cell_type": "code", "execution_count": null}], "nbformat": 4, "metadata": {"language_info": {"version": "3.6.3", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "mimetype": "text/x-python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}}