{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4f8d9f8e-1d56-ff20-1a32-58c9cdb27cb8"
      },
      "source": [
        "This is part of a course project on NLP and deep learning (CS224n at Stanford). We aim to leverage principles of NLP to consistently predict tags of Stack Exchange posts across disciplines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "71d4e286-cc0c-c163-df14-ae9df9bc4ce3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8e4b34b7-0cf1-79e3-0d49-b1928fd0f163"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"../input/cooking.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a257a3ff-f24e-44f5-bfaa-060d60e04fb0"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "* Convert tags into lists\n",
        "* Remove html tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "07258c77-71bd-d4dc-7fcb-a6546dbcbb33"
      },
      "outputs": [],
      "source": [
        "df[\"tags\"] = df[\"tags\"].map(lambda x: x.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "128ff459-0803-49f9-45fa-f1fb3f4f61cb"
      },
      "outputs": [],
      "source": [
        "print(df.loc[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "91458628-4fb4-3a40-92ec-f4b6eddbbb38"
      },
      "outputs": [],
      "source": [
        "print(df.iloc[10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9abd5b4a-2366-7099-156b-0261865c2dad"
      },
      "source": [
        "## Feature Creation\n",
        "First test out bag-of-words approach to vectorize posts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d904c7b4-b6bc-1f21-624c-280f11dd6816"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             tokenizer = None,    \\\n",
        "                             preprocessor = None, \\\n",
        "                             stop_words = None,   \\\n",
        "                             max_features = 5000) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ff66b848-b892-9c4e-230a-87eece7f83de"
      },
      "outputs": [],
      "source": [
        "num_posts = df[\"content\"].size\n",
        "posts = []\n",
        "for i in range( 0, num_posts ):\n",
        "    posts.append( df[\"content\"][i] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7db5af5e-d13b-5e50-f3b0-ba38d116463e"
      },
      "outputs": [],
      "source": [
        "train_data_features = vectorizer.fit_transform(posts)\n",
        "train_data_features = train_data_features.toarray()\n",
        "\n",
        "print(train_data_features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6decf802-fcff-e0e3-3c6d-0830703f2654"
      },
      "source": [
        "First implementation of latent dirichlet allocation algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3828d83a-fe7b-227a-6ea4-b07caa8073ae"
      },
      "outputs": [],
      "source": [
        "type(df.loc[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "42ea1506-9566-a589-0acf-916053ea8d7f"
      },
      "outputs": [],
      "source": [
        "from gensim import corpora, models\n",
        "\n",
        "dictionary = corpora.Dictionary(df.loc[0:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c2ca3131-1569-6c29-6e53-471e9cba0e6c"
      },
      "source": [
        "## References:\n",
        "\n",
        "[1] https://www.kaggle.com/l3nnys/transfer-learning-on-stack-exchange-tags/useful-text-preprocessing-on-the-datasets\n",
        "\n",
        "[2] https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words\n",
        "\n",
        "[3] https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html\n",
        "\n",
        "[4] http://engineering.flipboard.com/2017/02/storyclustering?from=groupmessage&isappinstalled=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4cde8324-7844-2eaa-00ad-9d970daf9ab0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}