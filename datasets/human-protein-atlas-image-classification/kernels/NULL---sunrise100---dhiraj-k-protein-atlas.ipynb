{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image\nfrom scipy.misc import imread\n\nimport tensorflow as tf\nsns.set()\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64ca4d5b4e10ac3294f4c05cc681759900748e0f"},"cell_type":"code","source":"train_labels = pd.read_csv(\"../input/train.csv\")\ntrain_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_labels.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"241871a2959ca1a575b65db9aad2a8e8aab69024"},"cell_type":"code","source":"from os import listdir\n\nfiles = listdir(\"../input/train\")\nfor n in range(10):\n    print(files[n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cce9d2a36ad66527fc2062379dcc0e688fe70d14"},"cell_type":"code","source":"import cv2\npath_to_train = '../input/train/'\ndata = pd.read_csv('../input/train.csv')\n\ntrain_dataset_info = []\nfor name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n    train_dataset_info.append({\n        'path':os.path.join(path_to_train, name),\n        'labels':np.array([int(label) for label in labels])})\ntrain_dataset_info = np.array(train_dataset_info)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"867dead3f841ca14ba12aa1c825b5944c463009e"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_ids, test_ids, train_targets, test_target = train_test_split(\n    data['Id'], data['Target'], test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a9df33060272c6828eb6faf639cfa934feb9627"},"cell_type":"code","source":"class data_generator:\n    \n    def create_train(dataset_info, batch_size, shape, augument=True):\n        assert shape[2] == 3\n        while True:\n            random_indexes = np.random.choice(len(dataset_info), batch_size)\n            batch_images = np.empty((batch_size, shape[0], shape[1], shape[2]))\n            batch_labels = np.zeros((batch_size, 28))\n            for i, idx in enumerate(random_indexes):\n                image = data_generator.load_image(\n                    dataset_info[idx]['path'], shape)   \n                if augument:\n                    image = data_generator.augment(image)\n                batch_images[i] = image\n                batch_labels[i][dataset_info[idx]['labels']] = 1\n            yield batch_images, batch_labels\n            \n    \n    def load_image(path, shape):\n        B = np.array(Image.open(path+'_blue.png'))\n        Y = np.array(Image.open(path+'_yellow.png'))\n        R = np.array(Image.open(path+'_red.png'))\n        G = np.array(Image.open(path+'_green.png'))\n        \n        image = np.stack((\n            R/2 + Y/2, \n            G/2 + Y/2, \n            B),-1)\n        \n        image = cv2.resize(image, (shape[0], shape[1]))\n        image = np.divide(image, 255)\n        return image  \n                \n            \n    def augment(image):\n        augment_img = iaa.Sequential([\n            iaa.OneOf([\n                iaa.Affine(rotate=0),\n                iaa.Affine(rotate=90),\n                iaa.Affine(rotate=180),\n                iaa.Affine(rotate=270),\n                iaa.Fliplr(0.5),\n                iaa.Flipud(0.5),\n            ])], random_order=True)\n        \n        image_aug = augment_img.augment_image(image)\n        return image_aug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"285473568bebbe435985ec83018bb1be2362a039"},"cell_type":"code","source":"from imgaug import augmenters as iaa\ntrain_datagen = data_generator.create_train(\n    train_dataset_info, 5, (299,299,3), augument=True)\nimages, labels = next(train_datagen)\n\nfig, ax = plt.subplots(1,5,figsize=(25,5))\nfor i in range(5):\n    ax[i].imshow(images[i])\nprint('min: {0}, max: {1}'.format(images.min(), images.max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fc2fe6856ce945d6fb6c5fb9c3974842970dd86"},"cell_type":"code","source":"from keras.applications import InceptionResNetV2\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import LambdaCallback\nfrom keras.callbacks import Callback\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Activation\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Input\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Conv2D\nfrom keras.models import Model\n\nfrom keras import metrics\nfrom keras.optimizers import Adam \nfrom keras import backend as K\nimport tensorflow as tf\nimport keras\n\ndef create_model(input_shape, n_out):    \n    pretrain_model = InceptionResNetV2(include_top=False,weights='imagenet',input_shape=input_shape) \n    input_tensor = Input(shape=input_shape)\n    bn = BatchNormalization()(input_tensor)\n    x = pretrain_model(bn)\n    x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n    x = Flatten()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    output = Dense(n_out, activation='sigmoid')(x)\n    model = Model(input_tensor, output)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5518ea395d2af67c483722698cb9015c79958c25"},"cell_type":"code","source":"keras.backend.clear_session()\nmodel = create_model(input_shape=(224,224,3),n_out=28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a9a5fd1549dde4f0c50de61c27fd0f5e7a74f03"},"cell_type":"code","source":"def f1score(y_true, y_pred):\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f1score = 2*p*r / (p+r+K.epsilon())\n    f1score = tf.where(tf.is_nan(f1score), tf.zeros_like(f1score), f1score)\n    return K.mean(f1score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"180136a6ee05380701aa0d02295c8157947859c8"},"cell_type":"code","source":"checkpointer = ModelCheckpoint('../working/mymodel.h5',verbose=2, save_best_only=True)\n\ntrain_generator = data_generator.create_train(\n    train_dataset_info[train_ids.index], 15, (224,224,3), augument=False)\nvalidation_generator = data_generator.create_train(\n    train_dataset_info[test_ids.index], 256, (224,224,3), augument=False)\n\nmodel.layers[2].trainable = False\n\nmodel.compile(loss='binary_crossentropy',optimizer=Adam(1e-3),metrics=['acc', f1score])\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    validation_data=next(validation_generator),\n    epochs=10, \n    verbose=1,\n    callbacks=[checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6bf8334e1f149c4b79c4440cb423af449895436"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c2703cd70001a85086af262cee2096e57cfab26"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc7f03822de38c44fd167d359dabc7829b123685"},"cell_type":"code","source":"\n       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"207c79dd9e4b637d8dcbb9bb9b3a771b06a86e0a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f487202ae8b4931133af0f169de09e408ac502d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}