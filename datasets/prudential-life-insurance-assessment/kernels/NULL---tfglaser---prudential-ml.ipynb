{"cells":[
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "%matplotlib inline"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Imports\n\n# pandas\nimport pandas as pd\nfrom pandas import Series,DataFrame\n\n# numpy, matplotlib, seaborn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import cross_validation\nimport xgboost as xgb"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# get training & test csv files as a DataFrame\ntrain_df = pd.read_csv(\"../input/train.csv\" )\ntest_df    = pd.read_csv(\"../input/test.csv\")"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# There are some columns with non-numerical values(i.e. dtype='object'),\n# So, We will create a corresponding unique numerical value for each non-numerical value in a column of training and testing set.\n\nfrom sklearn import preprocessing\n\nfor f in train_df.columns:\n    if train_df[f].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(np.unique(list(train_df[f].values) + list(test_df[f].values)))\n        train_df[f] = lbl.transform(list(train_df[f].values))\n        test_df[f]       = lbl.transform(list(test_df[f].values))"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# fill NaN values\n\nfor f in train_df.columns:\n    if f == \"Response\": continue\n    if train_df[f].dtype == 'float64':\n        train_df[f].fillna(train_df[f].mean(), inplace=True)\n        test_df[f].fillna(test_df[f].mean(), inplace=True)\n    else:\n        train_df[f].fillna(train_df[f].median(), inplace=True)\n        test_df[f].fillna(test_df[f].median(), inplace=True)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# define training and testing sets\n# Remove Height and Weight. Rely on BMI\n\nX_train = train_df.drop([\"Response\", \"Id\", \"Ht\", \"Wt\"],axis=1)\ny_train = train_df[\"Response\"]\nX_test  = test_df.drop([\"Id\", \"Ht\", \"Wt\"],axis=1).copy()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# modify response values so that range of values is from 0-7 instead of 1-8\ny_train = y_train - 1"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Find the features that really matter in data set using Random Forest Classifier\n\nfeat_labels = X_train.columns\nforest = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\nforest.fit(X_train, y_train)\nimportances = forest.feature_importances_\nindices = np.argsort(importances)[::-1]\nimportances"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# identify the list of top features\n\nfor f in range(X_train.shape[1]):\n    print(\"%2d) %-*s %f\" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Use only top features\nX_train = forest.transform(X_train, threshold=.008)\nX_test = forest.transform(X_test, threshold=.008)\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Define different models\nforest = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\n\nlr = LogisticRegression(C=1.0, random_state=0)\n\nknn = KNeighborsClassifier(n_neighbors=15, p=2, metric='minkowski')\n\ngnb = GaussianNB()\n\nlsvc = LinearSVC()\n\nlsvm = SVC(kernel='linear')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Perform pre-processing to determine optimal data set size and tune model parameters\n\n\n# Determine optimal training data set size using learning curve methods\nimport matplotlib.pyplot as plt\nfrom sklearn.learning_curve import learning_curve\n\n    \ntrain_sizes, train_scores, test_scores = learning_curve(estimator=knn, X=X_train, y=y_train, \n                                                        train_sizes=np.linspace(0.1, 1.0, 5), cv=5)\n\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nplt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\nplt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\nplt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\nplt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\nplt.grid()\nplt.xlabel('Number of training samples')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.ylim([0.1, 1.2])\nplt.show()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn.learning_curve import validation_curve\n\n\nparam_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n\ntrain_scores, test_scores = validation_curve(estimator=lr, X=X_train, y=y_train, param_name='C',\n                                            param_range=param_range, cv=5)\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nplt.plot(param_range, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\nplt.fill_between(param_range, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\nplt.plot(param_range, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\nplt.fill_between(param_range, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\nplt.xscale('log')\nplt.grid()\nplt.xlabel('Parameter')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.ylim([0.4, 0.6])\nplt.show()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "nn_range = [10, 15, 20, 25, 30, 35]\ntrain_scores, test_scores = validation_curve(estimator=knn, X=X_train, y=y_train, param_name='n_neighbors',\n                                            param_range=nn_range, cv=5)\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nplt.plot(nn_range, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\nplt.fill_between(nn_range, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\nplt.plot(nn_range, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\nplt.fill_between(nn_range, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n\nplt.grid()\nplt.xlabel('Parameter')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.ylim([0.20, 0.65])\nplt.show()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "ne_range = [10, 100, 1000]\ntrain_scores, test_scores = validation_curve(estimator=forest, X=X_train, y=y_train, param_name='n_estimators',\n                                            param_range=ne_range, cv=5)\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nplt.plot(ne_range, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\nplt.fill_between(ne_range, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\nplt.plot(ne_range, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\nplt.fill_between(ne_range, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n\nplt.grid()\nplt.xlabel('Parameter')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.ylim([0.40, 0.85])\nplt.show()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# in addition to the original data sets for training (train_orig)and testing (test_orig)\n# split train_orig data into training and testing sets randomly so we can obtain a practice test set with outcomes\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.30, random_state=0)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Xgboost \n\nparams = {\"objective\": \"multi:softmax\", \"num_class\": 8}\n\nT_train_xgb = xgb.DMatrix(X_train, y_train)\nX_test_xgb  = xgb.DMatrix(X_test)\n\ngbm = xgb.train(params, T_train_xgb, 20)\ny_pred = gbm.predict(X_test_xgb)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# change values back to range of values is from 1-8 instead of 0-7\n\ny_pred = y_pred + 1\ny_pred = y_pred.astype(int)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Create submission\n\noutput = pd.DataFrame({\n        \"Id\": test_df[\"Id\"],\n        \"Response\": y_pred\n    })\noutput.to_csv(\"../input/output.csv\", index=False)"
 }
],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}, "nbformat": 4, "nbformat_minor": 0}