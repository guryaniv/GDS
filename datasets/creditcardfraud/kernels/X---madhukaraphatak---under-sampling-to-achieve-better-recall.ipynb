{"nbformat": 4, "nbformat_minor": 1, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"version": "3.6.3", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python"}}, "cells": [{"cell_type": "markdown", "source": ["Under Sampling in Credit Card Fraud Detection\n", "\n", "The data in input set is highly skewed towards the non-fradulent transaction. This makes classification tricky.  So in this kernel we can explore how undersampling will help to learn a better classifier. Also, we will be using recall as our evaluation metric as it's much for useful compared to accuracy score.\n"], "metadata": {"_cell_guid": "938c6d65-5880-466f-8ced-fa1c2447a152", "_uuid": "b5e09dd09aac5a8289c972a66405d00f87614021"}}, {"cell_type": "code", "execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "metadata": {"_cell_guid": "18ce1c0c-e890-498d-831f-b5cb4a0297f2", "_uuid": "c04f3c856e49d6debc95efe3f30b3777446df7c5"}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["## Read the data\n", "df = pd.read_csv(\"../input/creditcard.csv\")\n", "df.head()"], "metadata": {"_cell_guid": "8a108e2d-e457-4afb-9376-67e43f3756aa", "_uuid": "d3f4f48c59e842b3069aa6f02753dbac4107f704"}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["## Plot the distribution of data\n", "%matplotlib inline\n", "sns.countplot(x='Class', data=df)"], "metadata": {"_cell_guid": "3ac19056-a0fe-4ddf-83fa-bf133e3bdc7e", "_uuid": "9a2f7992f23955babab89b58a602fa86f0ba4344"}, "outputs": []}, {"cell_type": "markdown", "source": ["From the above graph you can observe that data is really skewed for class 0 which indicates the non fradulant transactions."], "metadata": {"_cell_guid": "7c5fc6df-9eb7-49ed-af5d-508ede07c981", "_uuid": "db0ed28e3686e6b6d5f172f142b915cf90d7567c"}}, {"cell_type": "code", "execution_count": null, "source": ["from sklearn.preprocessing import StandardScaler\n", "from sklearn.cross_validation import train_test_split\n", "\n", "df['normal_amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1,1))\n", "df = df.drop(['Amount','Time'], axis=1)\n", "X = df.loc[:,df.columns != 'Class']\n", "y = df.loc[:,df.columns == 'Class']\n", "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)"], "metadata": {"_cell_guid": "9ca0ea73-0ab4-4f14-81f0-0a4c3bb7a12e", "_uuid": "22546b393aaac6757c14fd42de896ad7cc1d0fff"}, "outputs": []}, {"cell_type": "markdown", "source": ["Below code trains a logisitc regression model on original data. As you can observe from the output,\n", "recall is pretty poor. But accuracy is pretty high."], "metadata": {"_cell_guid": "e584edca-b982-4a23-9e65-383667797e57", "_uuid": "8d6707df7767a3f86990beae07861a7d3d16740b"}}, {"cell_type": "code", "execution_count": null, "source": ["# Calculate the recall score for logistic Regression on Skewed data\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import recall_score,accuracy_score\n", "lr = LogisticRegression()\n", "lr.fit(X_train,y_train)\n", "y_pred = lr.predict(X_test)\n", "print(recall_score(y_test,y_pred,average=None))\n", "print(accuracy_score(y_test,y_pred))\n"], "metadata": {"_cell_guid": "56bdaac7-406b-4dc6-b5d5-ad978b7ddf0e", "_uuid": "28202eaf1a64fd7ab95cf6a18d80670e8077edd1"}, "outputs": []}, {"cell_type": "markdown", "source": ["To improve the recall, let's implement undersampling. Here the code is trying to reduce the number\n", "of non fraudulent transactions equivalent to fraudulent ones."], "metadata": {"_cell_guid": "9e962ee9-99a1-4967-92e4-a440772eca8b", "_uuid": "68ef1596f824e5b6dec14fe67deeb079222ad826"}}, {"cell_type": "code", "execution_count": null, "source": ["# Undersample the data\n", "no_frauds = len(df[df['Class'] == 1])\n", "non_fraud_indices = df[df.Class == 0].index\n", "random_indices = np.random.choice(non_fraud_indices,no_frauds, replace=False)\n", "fraud_indices = df[df.Class == 1].index\n", "under_sample_indices = np.concatenate([fraud_indices,random_indices])\n", "under_sample = df.loc[under_sample_indices]"], "metadata": {"_cell_guid": "91cf8d86-8e23-444e-b479-bb0d45e7dfdb", "_uuid": "c74102b78239baf9d1f54c7a0ff6cdbfe2fac0a4", "collapsed": true}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["## Plot the distribution of data for undersampling\n", "%matplotlib inline\n", "sns.countplot(x='Class', data=under_sample)"], "metadata": {"_cell_guid": "5b65fa94-9425-4036-8e8b-569b427d6e7c", "_uuid": "16f5a8e7a6236829a344ba2494fb9ccc14703e35", "collapsed": true}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["X_under = under_sample.loc[:,under_sample.columns != 'Class']\n", "y_under = under_sample.loc[:,under_sample.columns == 'Class']\n", "X_under_train, X_under_test, y_under_train, y_under_test = train_test_split(X_under,y_under,test_size = 0.3, random_state = 0)"], "metadata": {"_cell_guid": "f5840b38-ac6f-4c27-b8c2-f230b5c5f9e2", "_uuid": "99834363577da8eed403890e4450ba8ff5d0c8ef", "collapsed": true}, "outputs": []}, {"cell_type": "markdown", "source": ["Below code trains the logistic regression on undersampled data. From the result, you can observe that the recall is much better."], "metadata": {"_cell_guid": "ad15226c-700f-4874-8695-1c565b4d8102", "_uuid": "32d738d6d6ab8f4488f220aa81854dc2c1b35a26"}}, {"cell_type": "code", "execution_count": null, "source": ["lr_under = LogisticRegression()\n", "lr_under.fit(X_under_train,y_under_train)\n", "y_under_pred = lr_under.predict(X_under_test)\n", "print(recall_score(y_under_test,y_under_pred))\n", "print(accuracy_score(y_under_test,y_under_pred))"], "metadata": {"_cell_guid": "f9d93162-045d-4d42-b2da-159543c86939", "_uuid": "102c9d018cc7f68eeea5983ace70381eeb8e77a1", "collapsed": true}, "outputs": []}, {"cell_type": "markdown", "source": ["It also generalises good enough for full data."], "metadata": {"_cell_guid": "3eb5e8b0-9b95-43ee-b60c-430898b3f076", "_uuid": "2153738315898b1a14846dff6d5da69689acab8a"}}, {"cell_type": "code", "execution_count": null, "source": ["## Recall for the full data\n", "y_pred_full = lr_under.predict(X_test)\n", "print(recall_score(y_test,y_pred_full))\n", "print(accuracy_score(y_test,y_pred_full))"], "metadata": {"_cell_guid": "5f4f57af-cc20-48b8-a311-a2cb6c408d6a", "_uuid": "7b988dd9b80470d246d4b77df1b8215b5c34b667", "collapsed": true}, "outputs": []}, {"cell_type": "markdown", "source": ["Rather than doing sampling explicitely we can use class_weight property to achive the same effect."], "metadata": {"_cell_guid": "80b7aa69-5d90-4881-b223-4ce832cf0b9b", "_uuid": "de41bcea4fde978a569606a05d3144749a247ca9"}}, {"cell_type": "code", "execution_count": null, "source": ["lr_balanced = LogisticRegression(class_weight = 'balanced')\n", "lr_balanced.fit(X_train,y_train)\n", "y_balanced_pred = lr_balanced.predict(X_test)\n", "print(recall_score(y_test,y_balanced_pred))\n", "print(accuracy_score(y_test,y_balanced_pred))"], "metadata": {"_cell_guid": "2afdfd14-034a-4335-8d29-6e19d4a1c4c4", "_uuid": "ea95eeeafc9a45d036a9f005f0882faecbe04242", "collapsed": true}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["from sklearn.metrics import confusion_matrix\n", "confusion_matrix_value = confusion_matrix(y_test,y_balanced_pred)"], "metadata": {"_cell_guid": "fc06d9b8-8e33-4356-9a1a-c1922f86e58a", "_uuid": "f86310042aa7bf4d4a932ac97eb08148ba5b6ba2", "collapsed": true}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["sns.set(font_scale=1.4)\n", "confusion_matrix_value\n", "#sns.heatmap(confusion_matrix_value, annot=True)"], "metadata": {"_cell_guid": "fd2cdd34-689d-414d-93ea-12bb00469914", "_uuid": "069512b802219f3e2a43c3e05c4daef2348e9b13", "collapsed": true}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": [], "metadata": {"_cell_guid": "520fd423-6e64-470e-97c7-529f7c953d30", "_uuid": "381bfa424cea0808903151dc356593e4bb2f9403", "collapsed": true}, "outputs": []}]}