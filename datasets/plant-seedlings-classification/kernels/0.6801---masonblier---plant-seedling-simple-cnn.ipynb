{"cells":[{"metadata":{"_uuid":"4d2dfe1439b6de18ab6b71576ec8387127137a7e"},"cell_type":"markdown","source":"My first exploration of CNNs with Kaggle. Based on [Towards Data Science Building a CNN in Keras](https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5) and some others. I use a simple single-CNN-layer network with a wide 10px convolution, achieves ~50% accuracy after 10 epoches."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport glob\nimport os\nimport cv2\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport imageio as im\nfrom keras import models\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils import np_utils\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport seaborn as sns\nimport matplotlib\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ebebacb450a64a2397b89342425cccc205130f1"},"cell_type":"markdown","source":"Load dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# load images dataset\ndef loadImagesData(glob_path):\n    images = []\n    names = []\n    for img_path in glob.glob(glob_path):\n        # load/resize images with cv2\n        names.append(os.path.basename(img_path))\n        images.append(cv2.resize(cv2.imread(img_path, cv2.IMREAD_COLOR), \n                   (100,100), interpolation=cv2.INTER_CUBIC))\n    return (images,names)\n# map of training label to list of images\ntrainData = {}\nfor label in os.listdir('../input/train/'):\n    (images,names) = loadImagesData(f\"../input/train/{label}/*.png\")\n    trainData[label] = images\nprint(\"train labels:\", \",\".join(trainData.keys()))\n# show some data\nplt.figure(figsize=(5,5))\ncolumns = 5\nfor i, label in enumerate(trainData.keys()):\n    plt.subplot(len(trainData.keys()) / columns + 1, columns, i + 1)\n    plt.imshow(trainData[label][0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58c931bf13e202ab764610127db491a50a1f97fc"},"cell_type":"markdown","source":"Build / encode training dataset"},{"metadata":{"trusted":true,"_uuid":"2e84e9d72b89413ef4c210d3307fa7d3954039e4"},"cell_type":"code","source":"# build x/y dataset\ntrainList = []\nfor label in trainData.keys():\n    for image in trainData[label]:\n        trainList.append({\n            'label': label,\n            'data': image\n        })\n# shuffle dataset\nrandom.shuffle(trainList)\n# dataframe and display\ntrain_df = pd.DataFrame(trainList)\ngc.collect()\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9218f1c436280600e8e6958f7191b25037b9896"},"cell_type":"markdown","source":"Encode x training data as 4d array"},{"metadata":{"trusted":true,"_uuid":"8ccbb2bbfc72d3ae0f4158241efc8a2f79a00f5a"},"cell_type":"code","source":"# encode training data\ndata_stack = np.stack(train_df['data'].values)\ndfloats = data_stack.astype(np.float32)\nall_x = np.multiply(dfloats, 1.0 / 255.0)\nall_x.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06377ee48032535acb6a71bfad768a7caaef3249"},"cell_type":"markdown","source":"Encode y label data"},{"metadata":{"trusted":true,"_uuid":"900a570247d6d32167260a8273e385646b55c3e0"},"cell_type":"code","source":"# encode labels\nle = LabelEncoder()\nle.fit(list(trainData.keys()))\nle_y = le.transform(train_df['label'])\n# convert to keras categorical one-hot\nall_y = np_utils.to_categorical(le_y)\nall_y[0:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5dd4aa8ffc63b50c1ac3f97a3963bb29fcc8ddaa"},"cell_type":"code","source":"# split test/training data\ntrain_x,test_x,train_y,test_y=train_test_split(all_x,all_y,test_size=0.2,random_state=7)\nprint(train_x.shape,test_x.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ebf96ac57ad5c2662f45f9ff5a84b788f0d737c"},"cell_type":"markdown","source":"Create the CNN model"},{"metadata":{"trusted":true,"_uuid":"8df7144ef28c47930d428e87cf59f9cf10750a40"},"cell_type":"code","source":"# create the network\nnum_filters = 8\nkernel_size = (10, 10)\ninput_shape = train_x.shape[1:]\nclf = Sequential()\n# some models\ndef simplerNet(clf):\n    # a wide-filter cnn of my own design!\n    # its not very good, but I like it\n    clf.add(Conv2D(num_filters, kernel_size, padding='same', input_shape=input_shape, activation = 'relu'))\n    clf.add(MaxPooling2D(pool_size=(2, 2)))\n    clf.add(Flatten())\n    clf.add(Dense(units = 12, activation = 'softmax'))\ndef tdsNet(clf):\n    # from towards data science keras cnn tutorial\n    # performs much better (70% accuracy after 20 epochs)\n    clf.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=input_shape))\n    clf.add(Conv2D(32, kernel_size=3, activation='relu'))\n    clf.add(Flatten())\n    clf.add(Dense(units = 12, activation = 'softmax'))\nsimplerNet(clf)\n# show summary\nclf.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cb1fb86c44b9fb82595a7f23fdc3e329bfd1268"},"cell_type":"code","source":"# compile with same parameters as vanilla cnn\nopt = adam(lr=0.0001, decay=1e-6)\nclf.compile(optimizer = opt,\n            loss = 'categorical_crossentropy', \n            metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc50c7a03f5116c3b40cf638b243ed1ccddb0a3c"},"cell_type":"code","source":"# data augmenter\n# this dataset has many varied sizes and poor centering,\n# so resizing and shifting training data helps network\ndatagen = ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip=True,  # randomly flip images\n    vertical_flip=False)  # randomly flip images\ndatagen.fit(train_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e4311f12d126bdf99a935674a784bea7960ee52","scrolled":true},"cell_type":"code","source":"# train model\nbatch_size = 32\nhistory = clf.fit_generator(datagen.flow(train_x, train_y,\n                            batch_size=batch_size),\n                            steps_per_epoch= (train_x.shape[0] // batch_size),\n                            epochs = 32,\n                            validation_data=(test_x, test_y),\n                            workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7ceb4a346049f8118db325cbd0a232f68b7a730"},"cell_type":"code","source":"# plot model metrics from\n#  https://stackoverflow.com/questions/51006505/how-training-and-test-data-is-split-keras-on-tensorflow\nprint(history.history.keys())\n# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff782043ca320cc33ae470a1424e3862efdacd7c"},"cell_type":"code","source":"# confusion matrix of labels\npre_cls=clf.predict_classes(all_x)    \ncm1 = confusion_matrix(le.transform(train_df['label']),pre_cls)\n# from https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823\ndef print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    return fig\nclass_names = list(le.classes_)\nprint_confusion_matrix(cm1, class_names)\nNone","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40ad6a2a5a6856c55f4d803217a8af813a1eece9"},"cell_type":"code","source":"# evaluate data accuracy against split test set\nscore, acc = clf.evaluate(test_x,test_y)\nprint('Test score:', score)\nprint('Test accuracy:', acc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6254330d004d1fd6918c765f6833240bb9651ee7"},"cell_type":"markdown","source":"Make submission file"},{"metadata":{"trusted":true,"_uuid":"ee3ddfa8f72fc757bbaebafff92050473b93e4dd"},"cell_type":"code","source":"# load test image datas\n(test_images, test_names) = loadImagesData(f\"../input/test/*.png\")\ndata_stack = np.stack(test_images)\ndfloats = data_stack.astype(np.float32)\nunknown_x = np.multiply(dfloats, 1.0 / 255.0)\n# predict\npredicted = np.argmax(clf.predict(unknown_x), axis=1)\npredicted_labels = le.inverse_transform(predicted)\nsubmission_df = pd.DataFrame({'file':test_names,'species':predicted_labels})\nsubmission_df.to_csv('submission.csv', index=False)\nlen(submission_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc41f493401a844a0c171c1a68664002618d95c1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}