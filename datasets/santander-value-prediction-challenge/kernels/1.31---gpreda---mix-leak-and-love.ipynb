{"cells":[{"metadata":{"_uuid":"aee30abf88388a5d59d4a9de7eddd3a9dd6466af"},"cell_type":"markdown","source":"<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b8/Banco_Santander_Logotipo.svg\" width=\"800\"></img>\n\n<h1><center><font size=\"6\">Combine Leak Exploit and Model with Selected Features</font></center></h1>\n\n\n# <a id='0'>Content</a>\n\n- <a href='#1'>Introduction</a>  \n- <a href='#2'>Load packages</a>  \n- <a href='#3'>Read the data</a>  \n- <a href='#4'>Exploit the leak</a> \n- <a href='#5'>Build a model</a>\n- <a href='#6'>Averaging and submission</a> \n- <a href='#7'>References</a>"},{"metadata":{"_uuid":"ca74d0f4599053376ea1c1c51dbf421ce178c937"},"cell_type":"markdown","source":"# <a id=\"1\">Introduction</a>  \n\nIn this Kernel we combine the  creation of a model with selected features [1][2] with exploatation of the leak (as identified by Giba [3] and developed by Moshin [4])\n\n<a href=\"#0\"><font size=\"1\">Go to top</font></a>"},{"metadata":{"_uuid":"3af5fbf2a44c9669869faa0d139b0e9736b8a9c1"},"cell_type":"markdown","source":"# <a id=\"2\">Load packages</a>"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9ba785c83a3fb3d1043d75dc279ac883fe43f032"},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nfrom sklearn import model_selection\nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom scipy.stats import mode, skew, kurtosis, entropy\nfrom sklearn.ensemble import ExtraTreesRegressor\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport dask.dataframe as dd\nfrom dask.multiprocessing import get\n\nfrom tqdm import tqdm, tqdm_notebook\ntqdm.pandas(tqdm_notebook)\n\n\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Print all rows and columns\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nIS_LOCAL = False\n\nimport os\n\nif(IS_LOCAL):\n    PATH=\"../input/santander-value-prediction-challenge/\"\nelse:\n    PATH=\"../input/\"\nprint(os.listdir(PATH))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb402019c985a93325bb9c68102cc87fb15d07c0"},"cell_type":"markdown","source":"# <a id=\"3\">Read the data</a>"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"2c9e3ecd7432c44106d65b6010d892b1448aa440"},"cell_type":"code","source":"train = pd.read_csv(PATH+\"train.csv\")\ntest = pd.read_csv(PATH+\"test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95608d6b07a300f6f6dc915f68df8a3ce81cd3dd"},"cell_type":"markdown","source":"<a href=\"#0\"><font size=\"1\">Go to top</font></a>\n\n# <a id=\"4\">Exploit the leak</a>"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"92cfd0a3a5703d6b72e8a2d63fe51b8984ff5b28"},"cell_type":"code","source":"NLAGS = 29 #number of lags for leak calculation","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"b3bb1f52f0ce07232ef3f7f2c28e4a62ed56ce93"},"cell_type":"code","source":"all_cols = [f for f in train.columns if f not in [\"ID\", \"target\"]]\ny = np.log1p(train[\"target\"]).values\ncols = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1',\n        '15ace8c9f', 'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9',\n        'd6bb78916', 'b43a7cfd5', '58232a6fb', '1702b5bf0', '324921c7b',\n        '62e59a501', '2ec5b290f', '241f0f867', 'fb49e4212', '66ace2992',\n        'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7', '1931ccfdd',\n        '703885424', '70feb1494', '491b9ee45', '23310aa6f', 'e176a204a',\n        '6619d81fc', '1db387535', 'fc99f9426', '91f701ba2', '0572565c2',\n        '190db8488', 'adb64ff71', 'c47340d97', 'c5a231d81', '0ff32eb98']","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"734eb986781f47528dd38cb4db9b60e93082f12e"},"cell_type":"code","source":"def _get_leak(df, cols, lag=0):\n    \"\"\" To get leak value, we do following:\n       1. Get string of all values after removing first two time steps\n       2. For all rows we shift the row by two steps and again make a string\n       3. Just find rows where string from 2 matches string from 1\n       4. Get 1st time step of row in 3 (Currently, there is additional condition to only fetch value if we got exactly one match in step 3)\"\"\"\n    series_str = df[cols[lag+2:]].apply(lambda x: \"_\".join(x.round(2).astype(str)), axis=1)\n    series_shifted_str = df[cols].shift(lag+2, axis=1)[cols[lag+2:]].apply(lambda x: \"_\".join(x.round(2).astype(str)), axis=1)\n    target_rows = series_shifted_str.progress_apply(lambda x: np.where(x == series_str)[0])\n    target_vals = target_rows.apply(lambda x: df.loc[x[0], cols[lag]] if len(x)==1 else 0)\n    return target_vals\n\ndef get_all_leak(df, cols=None, nlags=15):\n    \"\"\"\n    We just recursively fetch target value for different lags\n    \"\"\"\n    df =  df.copy()\n    for i in range(nlags):\n        print(\"Processing lag {}\".format(i))\n        df[\"leaked_target_\"+str(i)] = _get_leak(df, cols, i)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4963f1eb9fba606a9a2f5c65e531934eeee3f2d5"},"cell_type":"markdown","source":"We initialize the test **target** column with the mean of train **target** values."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"27f13be2e846a20f6d3c9d9ba8be6a5db950eea6"},"cell_type":"code","source":"test[\"target\"] = train[\"target\"].mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c4f28ad0170fcda102ba79c2b728e44db045d00"},"cell_type":"markdown","source":"Before applying the **get_all_leaks** function, we create a unique dataframe with all selected columns in train and test sets."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"bf6a2331db1e82689e13fd6f93838a85fead8a8c"},"cell_type":"code","source":"all_df = pd.concat([train[[\"ID\", \"target\"] + cols], test[[\"ID\", \"target\"]+ cols]]).reset_index(drop=True)\nall_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f2f21616ddf7edb0fd94a0acbf771c02ea10a1f"},"cell_type":"markdown","source":"Main calculation for leaks."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"18fa2372d2996d97a76939766e105e261e1cf14d"},"cell_type":"code","source":"all_df = get_all_leak(all_df, cols=cols, nlags=NLAGS)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e0b546c7fd9441c0ba381a5d20e8b8094df7a53"},"cell_type":"markdown","source":"Then we join both train and test sets with all_df leaky columns."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ececa313e576fded493bc7e52069f9300357b594"},"cell_type":"code","source":"leaky_cols = [\"leaked_target_\"+str(i) for i in range(NLAGS)]\ntrain = train.join(all_df.set_index(\"ID\")[leaky_cols], on=\"ID\", how=\"left\")\ntest = test.join(all_df.set_index(\"ID\")[leaky_cols], on=\"ID\", how=\"left\")\ntrain[[\"target\"]+leaky_cols].head(10)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"5a77f7e4dc3abf0aa8555f0208810ea3b380cdeb"},"cell_type":"markdown","source":"We calculate the mean for non-zero columns."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"726857289ad40242b4f8cfff32163ade9c6f89ff"},"cell_type":"code","source":"train[\"nz_mean\"] = train[all_cols].apply(lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1)\ntest[\"nz_mean\"] = test[all_cols].apply(lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c4d3d4eec8a4aab5de57d033ceb0841bfd7fa96"},"cell_type":"markdown","source":"Start with the first lag and recursivelly fill zeros."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"aef7f1af831e82536cba0f41687fd8475dc7dab1"},"cell_type":"code","source":"train[\"compiled_leak\"] = 0\ntest[\"compiled_leak\"] = 0\nfor i in range(NLAGS):\n    train.loc[train[\"compiled_leak\"] == 0, \"compiled_leak\"] = train.loc[train[\"compiled_leak\"] == 0, \"leaked_target_\"+str(i)]\n    test.loc[test[\"compiled_leak\"] == 0, \"compiled_leak\"] = test.loc[test[\"compiled_leak\"] == 0, \"leaked_target_\"+str(i)]\n    \nprint(\"Leak values found in train and test \", sum(train[\"compiled_leak\"] > 0), sum(test[\"compiled_leak\"] > 0))\nprint(\"% of correct leaks values in train \", sum(train[\"compiled_leak\"] == train[\"target\"])/sum(train[\"compiled_leak\"] > 0))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"314adbffd327b8c5a13914f5c5e7abb282fc0daa"},"cell_type":"markdown","source":"We replace with the non-zeros mean the compiled leaks equal with zero."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"1b590ad4e07b32f1fce0873c0e334b7ee1dcffdf"},"cell_type":"code","source":"train.loc[train[\"compiled_leak\"] == 0, \"compiled_leak\"] = train.loc[train[\"compiled_leak\"] == 0, \"nz_mean\"]\ntest.loc[test[\"compiled_leak\"] == 0, \"compiled_leak\"] = test.loc[test[\"compiled_leak\"] == 0, \"nz_mean\"]\nnp.sqrt(mean_squared_error(y, np.log1p(train[\"compiled_leak\"]).fillna(14.49)))\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"42db14d2fc493846a24e6c46b7afc13282e0b6fb"},"cell_type":"code","source":"sub1 = test[[\"ID\"]]\nsub1[\"target\"] = test[\"compiled_leak\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32a344af82b539dac36710cbd096925124ffa0c7"},"cell_type":"markdown","source":"<a href=\"#0\"><font size=\"1\">Go to top</font></a>\n\n\n# <a id=\"5\">Build a model</a>"},{"metadata":{"_uuid":"6105f59aec898dbb5056197532f0f9703124e1bf"},"cell_type":"markdown","source":"## Model parameters"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"168eb1a29ec00d2d16efcf17bc976312b5df1993"},"cell_type":"code","source":"NUMBER_KFOLDS  = 5\nNFOLDS = 5 #folds number for CV\nMAX_ROUNDS = 3000 #lgb iterations\nEARLY_STOP = 100 #lgb early stop \nVERBOSE_EVAL = 200 #Print out metric result","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"3a02b985aac26946d8049cc20ad7116ef345cde9"},"cell_type":"code","source":"train = pd.read_csv(PATH+\"train.csv\")\ntest = pd.read_csv(PATH+\"test.csv\")\nall_cols = [c for c in train.columns if c not in ['ID', 'target']]\nleak_col = []\nfor c in all_cols:\n    leak1 = np.sum((train[c]==train['target']).astype(int))\n    leak2 = np.sum((((train[c] - train['target']) / train['target']) < 0.05).astype(int))\n    if leak1 > 30 and leak2 > 3500:\n        leak_col.append(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7b8d06aef844c9d3ef9fac5a6462682c1a2937ef"},"cell_type":"code","source":"print('Leak columns: ',len(leak_col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7269cf7fb665f96f80df46b6d621827d27def221"},"cell_type":"code","source":"print('Leak columns: ',leak_col)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"79c139384ed5813034a1bc577d51714e5e9e3f9a"},"cell_type":"code","source":"col = list(leak_col)\ntrain_lk = train[col +  ['ID', 'target']]\ntest_lk = test[col +  ['ID']]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"7281ea633b1b694238e0c6f74a90a7b8792d76c2"},"cell_type":"code","source":"for df in [train_lk, test_lk]:\n    df[\"nz_mean\"] = df[col].apply(lambda x: x[x!=0].mean(), axis=1)\n    df[\"nz_max\"] = df[col].apply(lambda x: x[x!=0].max(), axis=1)\n    df[\"nz_min\"] = df[col].apply(lambda x: x[x!=0].min(), axis=1)\n    df[\"ez\"] = df[col].apply(lambda x: len(x[x==0]), axis=1)\n    df[\"mean\"] = df[col].apply(lambda x: x.mean(), axis=1)\n    df[\"max\"] = df[col].apply(lambda x: x.max(), axis=1)\n    df[\"min\"] = df[col].apply(lambda x: x.min(), axis=1)\n    df[\"kurtosis\"] = df[col].apply(lambda x: x.kurtosis(), axis=1)\ncol += ['nz_mean', 'nz_max', 'nz_min', 'ez', 'mean', 'max', 'min', 'kurtosis']","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"9513b47b23c893bb5b1999f0d3e614ea7738f14e"},"cell_type":"code","source":"for i in range(2, 100):\n    train_lk['index'+str(i)] = ((train_lk.index + 2) % i == 0).astype(int)\n    test_lk['index'+str(i)] = ((test_lk.index + 2) % i == 0).astype(int)\n    col.append('index'+str(i))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e0108340477e435aef5bff739309e8152eda10b"},"cell_type":"markdown","source":"Merge test_lk with prepared sub1 = test[ID, target] calculated before by exploiting the leal."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"4a9a589037db0a1c5c767f11a3084d25d40fad4b"},"cell_type":"code","source":"test_lk = pd.merge(test_lk, sub1, how='left', on='ID',)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0013a712c91b1a502a4d5132afc38652d7115bdd"},"cell_type":"markdown","source":"Replace zeros with NAs in both train_lk and test_lk and merge train_lk with test_lk in train_lk"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"0d6ea6692c000d4b18130504ec0a730559b54dbc"},"cell_type":"code","source":"from scipy.sparse import csr_matrix, vstack\ntrain_lk = train_lk.replace(0, np.nan)\ntest_lk = test_lk.replace(0, np.nan)\ntrain_lk = pd.concat((train_lk, test_lk), axis=0, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82e884188bb59651851772803033690aa92bfcf1"},"cell_type":"markdown","source":"Run the lgb model."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"b1bab1a7b24ef076e9d40cbf95117ba479e31eb7"},"cell_type":"code","source":"test_lk['target'] = 0.0\nfolds = NFOLDS\nfor fold in range(folds):\n    x1, x2, y1, y2 = model_selection.train_test_split(train_lk[col], \n                                                      np.log1p(train_lk.target.values), \n                                                      test_size=0.20, \n                                                      random_state=fold)\n    params = {'learning_rate': 0.02,\n              'max_depth': 7, \n              'boosting': 'gbdt', \n              'objective': 'regression', \n              'metric': 'rmse', \n              'is_training_metric': True, \n              'feature_fraction': 0.9, \n              'bagging_fraction': 0.8, \n              'bagging_freq': 5, \n              'seed':fold}\n    model = lgb.train(params, \n                      lgb.Dataset(x1, label=y1), \n                      MAX_ROUNDS, \n                      lgb.Dataset(x2, label=y2), \n                      verbose_eval=VERBOSE_EVAL, \n                      early_stopping_rounds=EARLY_STOP)\n    test_lk['target'] += np.expm1(model.predict(test_lk[col], \n                                num_iteration=model.best_iteration))\ntest_lk['target'] /= folds\nsub1 = test_lk[['ID', 'target']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2dd15440fedb52d6f20562979f89824cc43c337"},"cell_type":"markdown","source":"<a href=\"#0\"><font size=\"1\">Go to top</font></a>\n\n# <a id=\"6\">Average and submission</a>"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"5328adc95c13660a16e1d3c64bcb5b55f8a20250"},"cell_type":"code","source":"#submission\ntest_lk[['ID', 'target']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"37726424166ca893c4779b995aa70ddaae7c347e"},"cell_type":"markdown","source":"# <a id=\"7\">References</a>  \n\n\n[1] <a href=\"https://www.kaggle.com/ogrellier\">olivier</a>, <a href=\"https://www.kaggle.com/ogrellier/santander-46-features\">Santander_46_features</a>   \n[2] <a href=\"https://www.kaggle.com/the1owl\">the1owl</a>, <a href=\"https://www.kaggle.com/the1owl/love-is-the-answer\">Love is the answer</a>   \n[3] <a href=\"https://www.kaggle.com/titericz\">Giba</a>, <a href=\"https://www.kaggle.com/titericz/the-property-by-giba\">The Property of Giba</a>   \n[4] <a href=\"https://www.kaggle.com/tezdhar\">Mohsin Hasan</a>, <a href=\"https://www.kaggle.com/tezdhar/breaking-lb-fresh-start\">Breaking LB - Fresh Start</a>   \n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}