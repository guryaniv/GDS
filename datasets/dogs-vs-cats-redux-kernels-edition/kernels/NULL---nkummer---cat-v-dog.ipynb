{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2135f09d-953a-c925-4f48-49b3f233770b"
      },
      "source": [
        "# Dog vs. Cat Detection\n",
        "\n",
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dd259d66-41ba-4ed8-96a5-3d2ad756d0ee"
      },
      "outputs": [],
      "source": [
        "#Pre do something"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6d32a1f6-ce4d-ceac-f1cf-6d56d2605f7a"
      },
      "source": [
        "## Import Data\n",
        "the next step is to import the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1ac2d061-7c82-829b-de97-240a1b3ae2f1"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = '../input/train/' #training directory\n",
        "TEST_DIR = '../input/test/' #testing directory\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "60b97bbf-3812-5b2e-60e3-98b88257d7e1"
      },
      "source": [
        "Pre-define a function that will take the labels from the image name (thanks to other kernels on Kaggle)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "76003fc7-60d8-7307-f9f9-c36b9f8ee4a6"
      },
      "outputs": [],
      "source": [
        "def label_img(img):\n",
        "    word_label = img.split('.')[-3]\n",
        "    if word_label == 'cat': return [1,0] #[cat, not dog]\n",
        "    elif word_label == 'dog': return [0,1] #[not cat, dog]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0c6afd7b-13b9-4b00-4e2f-82b576115099"
      },
      "source": [
        "## Retrieve training data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4e8af393-1893-0bf4-d0b4-88546a295ef5"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm      # percentage progress bar\n",
        "def create_train_data():\n",
        "    training_data = []\n",
        "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
        "        label = label_img(img)\n",
        "        path = os.path.join(TRAIN_DIR,img)\n",
        "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
        "        training_data.append([np.array(img),np.array(label)])\n",
        "    shuffle(training_data)\n",
        "    np.save('train_data.npy', training_data)\n",
        "    return training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4d97ff5f-8830-ff83-f684-2b3026294c5a"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm \n",
        "IMG_SIZE=50 #Define short image size\n",
        "\n",
        "def create_train_data():\n",
        "    X = [] #training images\n",
        "    Y = [] #training labels\n",
        "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
        "        label = label_img(img)\n",
        "        path=os.path.join(TRAIN_DIR, img)\n",
        "        im=cv2.imread(path)\n",
        "        sh=im.shape\n",
        "        if sh[0] < sh[1]:  # Find the shortest dimension\n",
        "            im1=im[0:sh[0],0:sh[0]]\n",
        "            im2=im[0:sh[0],(sh[1]-sh[0]):sh[1]]\n",
        "            #rint(\"\"\n",
        "        else:\n",
        "            im1=im[0:sh[1],0:sh[0]]\n",
        "            im2=im[(sh[0]-sh[1]):sh[0],0:sh[1]]\n",
        "        #Resize images to make them smaller\n",
        "        im1 = cv2.resize(im1, (IMG_SIZE,IMG_SIZE))\n",
        "        im2 = cv2.resize(im2, (IMG_SIZE,IMG_SIZE))\n",
        "        #Append the two images together\n",
        "        imn=np.append(im1,im2,axis=0)\n",
        "        X.append(np.array(imn))\n",
        "        Y.append(np.array(label))\n",
        "    return(X,Y)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d8b19ef9-746b-31b4-e9a9-d0faeb50cfed"
      },
      "source": [
        "Run the new function to create the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e469c5a1-b968-0d41-980c-268d0a4150aa"
      },
      "outputs": [],
      "source": [
        "X,Y = create_train_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2b29abe9-1370-7dee-58d2-7a40207efa4f"
      },
      "source": [
        "Try some of the images to make sure what they look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "94a189f1-a664-3d81-9f2a-1fa1cbda5224"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "index=random.randint(0,25000-1)\n",
        "plt.imshow(X[index])\n",
        "Y[index]\n",
        "X[index].shape\n",
        "\n",
        "X, Y = shuffle(X, Y)\n",
        "Xtrain=X[0:20000-1]\n",
        "Ytrain=Y[0:20000-1]\n",
        "Xtest=X[(20000-1):25000-1]\n",
        "Ytest=Y[(20000-1):25000-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0c4e1642-cf25-283e-38b1-c2cd76255859"
      },
      "source": [
        "## Define the Neural Network\n",
        "This next section will define the neural network for the detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e745b294-a800-8f43-f0e0-e0ce924e14bb"
      },
      "outputs": [],
      "source": [
        "import tflearn\n",
        "from tflearn.data_utils import shuffle, to_categorical\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.estimator import regression\n",
        "from tflearn.data_preprocessing import ImagePreprocessing\n",
        "from tflearn.data_augmentation import ImageAugmentation\n",
        "\n",
        "#Pre-process the images\n",
        "# Real-time data preprocessing\n",
        "img_prep = ImagePreprocessing()\n",
        "img_prep.add_featurewise_zero_center()\n",
        "img_prep.add_featurewise_stdnorm()\n",
        "\n",
        "# Real-time data augmentation\n",
        "img_aug = ImageAugmentation()\n",
        "img_aug.add_random_flip_leftright()\n",
        "img_aug.add_random_rotation(max_angle=25.)\n",
        "\n",
        "\n",
        "# Convolutional network building\n",
        "network = input_data(shape=[None, 100, 50, 3], #Define input layer\n",
        "                     data_preprocessing=img_prep, #set data_preprocessing\n",
        "                     data_augmentation=img_aug)\n",
        "\n",
        "network = conv_2d(network, 32,3, activation='relu') #convolve data once\n",
        "network = max_pool_2d(network,2) #down sample (reduce data)\n",
        "network = conv_2d(network, 64, 3, activation='relu')\n",
        "network = conv_2d(network, 64, 3, activation='relu')\n",
        "network = max_pool_2d(network,2) #down sample (reduce data)\n",
        "network = max_pool_2d(network, 2)\n",
        "network = fully_connected(network, 512, activation='relu')\n",
        "network = dropout(network, 0.5)\n",
        "network = fully_connected(network, 2, activation='softmax')\n",
        "network = regression(network, optimizer='adam',\n",
        "                     loss='categorical_crossentropy',\n",
        "                     learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d325747c-d885-b4d6-03f0-8645f9fcb735"
      },
      "source": [
        "Run the training iterations repeatedly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bee3eaa9-767c-9b26-39ff-03ec9e6b394f"
      },
      "outputs": [],
      "source": [
        "#Define the model\n",
        "model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path='dog-cat.tfl.ckpt')\n",
        "model.fit(Xtrain, Ytrain, n_epoch=3, \n",
        "          shuffle=True, \n",
        "          validation_set=(Xtest, Ytest),\n",
        "          show_metric=True, \n",
        "          batch_size=96, \n",
        "          run_id='catvdog')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "02bd0cc6-681b-9f8d-2b33-004332f191f9"
      },
      "source": [
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "\n",
        "convnet = input_data(shape=[None, 2*IMG_SIZE, IMG_SIZE, 3], name='input')\n",
        "\n",
        "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "convnet = fully_connected(convnet, 1024, activation='relu')\n",
        "convnet = dropout(convnet, 0.8)\n",
        "\n",
        "convnet = fully_connected(convnet, 2, activation='softmax')\n",
        "convnet = regression(convnet, optimizer='adam', learning_rate=0.001, loss='categorical_crossentropy', name='targets')\n",
        "\n",
        "model = tflearn.DNN(convnet, tensorboard_dir='log')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "43cfff9e-06b6-371c-4c9d-800e40550c4f"
      },
      "source": [
        "model.fit(Xtrain, Ytrain, \n",
        "          n_epoch=2, \n",
        "          validation_set=(Xtest, Ytest),\n",
        "          snapshot_step=50000, \n",
        "          show_metric=True, \n",
        "          run_id='catvdog')"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}