{"cells": [{"cell_type": "code", "source": ["import pandas as pd\n", "import numpy as np\n", "import nltk, re, math, collections\n", "from nltk.corpus import stopwords\n", "from nltk.corpus import wordnet\n", "import matplotlib.pylab as plt\n", "import operator"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "1261794d6a169358bb3dac782ff10ef1bcf442ee", "_cell_guid": "c4ebfa46-b455-4e27-8f30-300b72dcc40f", "collapsed": true}}, {"cell_type": "code", "source": ["train_v = pd.read_csv('../input/training_variants')\n", "test_v = pd.read_csv('../input/test_variants')\n", "train_t = pd.read_csv('../input/training_text',sep='\\|\\|',skiprows=1,engine='python',names=[\"ID\",\"Text\"])\n", "test_t = pd.read_csv('../input/test_text',sep='\\|\\|',skiprows=1,engine='python',names=[\"ID\",\"Text\"])\n", "\n", "train = pd.merge(train_v, train_t, how='left', on='ID').fillna('')\n", "y_labels = train['Class'].values\n", "\n", "test = pd.merge(test_v, test_t, how='left', on='ID').fillna('')\n", "test_id = test['ID'].values"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "7a332e02a3ff6468f1ba0061019b71f666dca54e", "_cell_guid": "844942d4-01dd-4fae-a66f-1e3e41cb657b", "collapsed": true}}, {"cell_type": "code", "source": ["c1, c2, c3, c4, c5, c6, c7, c8, c9 = \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n", "\n", "for i in train[train[\"Class\"]==1][\"ID\"]:\n", "    c1+=train[\"Text\"][i]+\" \"\n", "\n", "\n", "for i in train[train[\"Class\"]==2][\"ID\"]:\n", "    c2+=train[\"Text\"][i]+\" \"\n", "\n", "for i in train[train[\"Class\"]==3][\"ID\"]:\n", "    c3+=train[\"Text\"][i]+\" \"\n", "    \n", "for i in train[train[\"Class\"]==4][\"ID\"]:\n", "    c4+=train[\"Text\"][i]+\" \"\n", "    \n", "for i in train[train[\"Class\"]==5][\"ID\"]:\n", "    c5+=train[\"Text\"][i]+\" \"\n", "    \n", "    \n", "for i in train[train[\"Class\"]==6][\"ID\"]:\n", "    c6+=train[\"Text\"][i]+\" \"\n", "    \n", "for i in train[train[\"Class\"]==7][\"ID\"]:\n", "    c7+=train[\"Text\"][i]+\" \"\n", "    \n", "for i in train[train[\"Class\"]==8][\"ID\"]:\n", "    c8+=train[\"Text\"][i]+\" \"\n", "    \n", "    \n", "for i in train[train[\"Class\"]==9][\"ID\"]:\n", "    c9+=train_t[\"Text\"][i]+\" \""], "outputs": [], "execution_count": null, "metadata": {"_uuid": "6566c17ccd2fbdf72e2d027b803621d7657e1a32", "_cell_guid": "1d1b992e-6957-44d9-88a7-057a59c05c7a", "collapsed": true}}, {"cell_type": "code", "source": ["def tokenize(_str):\n", "    stops = set(stopwords.words(\"english\"))\n", "    tokens = collections.defaultdict(lambda: 0.)\n", "    wnl = nltk.WordNetLemmatizer()\n", "    for m in re.finditer(r\"(\\w+)\", _str, re.UNICODE):\n", "        m = m.group(1).lower()\n", "        if len(m) < 2: continue\n", "        if m in stops: continue\n", "        if m.isnumeric():continue\n", "        m = wnl.lemmatize(m)\n", "        tokens[m] += 1 \n", "    return tokens\n"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "763fe6bd3b64989f8db197356dc1e0eae3fea1b5", "_cell_guid": "575ecbf6-ebf6-469f-9877-0247e4bf761c", "collapsed": true}}, {"cell_type": "code", "source": ["texts_for_training=[]\n", "texts_for_test=[]\n", "num_texts_train=len(train)\n", "\n", "print(\"Tokenizing training texts\")\n", "for i in range(0,num_texts_train):\n", "    if((i+1)%1000==0):\n", "        print(\"Text %d of %d\\n\"%((i+1), num_texts_train))\n", "    texts_for_training.append(tokenize(train[\"Text\"][i]))"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "d77196d4787ded115df10882462a6546f9e29ef1", "_cell_guid": "bf8ca681-430e-4b5e-9d8c-8ceee1279f6e"}}, {"cell_type": "code", "source": ["print(\"Generating cluster 1\")\n", "cluster1=tokenize(c1)\n", "\n", "print(\"Generating cluster 2\")\n", "cluster2=tokenize(c2)\n", "\n", "print(\"Generating cluster 3\")\n", "cluster3=tokenize(c3)\n", "\n", "print(\"Generating cluster 4\")\n", "cluster4=tokenize(c4)\n", "\n", "print(\"Generating cluster 5\")\n", "cluster5=tokenize(c5)\n", "\n", "print(\"Generating cluster 6\")\n", "cluster6=tokenize(c6)\n", "\n", "print(\"Generating cluster 7\")\n", "cluster7=tokenize(c7)\n", "\n", "print(\"Generating cluster 8\")\n", "cluster8=tokenize(c8)\n", "\n", "print(\"Generating cluster 9\")\n", "cluster9=tokenize(c9)\n"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "fb81041ad0320d032d6a9363c7ad3fdb1940c523", "_cell_guid": "141dc53f-67c4-4002-bf89-c177c4e63e38"}}, {"cell_type": "code", "source": ["def uniqsPerClass(clase, objective, exact):\n", "\n", "    uniqs = collections.defaultdict(lambda: 0.)\n", "\n", "    for t, v in clase.items():\n", "        apears=0\n", "        if t in cluster1:\n", "            apears+=1\n", "        if t in cluster2:\n", "            apears+=1\n", "        if t in cluster3:\n", "            apears+=1\n", "        if t in cluster4:\n", "            apears+=1\n", "        if t in cluster5:\n", "            apears+=1\n", "        if t in cluster6:\n", "            apears+=1\n", "        if t in cluster7:\n", "            apears+=1  \n", "        if t in cluster8:\n", "            apears+=1\n", "        if t in cluster9:\n", "            apears+=1\n", "    \n", "        if exact:            \n", "            if apears==objective:\n", "                uniqs[t]=v\n", "        else:\n", "            if apears<(objective+1):\n", "                uniqs[t]=v\n", "    return uniqs\n"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "17f334c0eaeac3eece02c03593dfddf5e63401d1", "_cell_guid": "a523c0dd-8071-41ae-a687-d261726a80d7", "collapsed": true}}, {"cell_type": "code", "source": ["uniC1=uniqsPerClass(cluster1,1,False)\n", "uniC2=uniqsPerClass(cluster2,1,False)\n", "uniC3=uniqsPerClass(cluster3,1,False)\n", "uniC4=uniqsPerClass(cluster4,1,False)\n", "uniC5=uniqsPerClass(cluster5,1,False)\n", "uniC6=uniqsPerClass(cluster6,1,False)\n", "uniC7=uniqsPerClass(cluster7,1,False)\n", "uniC8=uniqsPerClass(cluster8,1,False)\n", "uniC9=uniqsPerClass(cluster9,1,False)\n"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "a22fdc872d2e8a2e766ced27216e96f4da460f92", "_cell_guid": "7dc43be9-7d9d-454e-bbce-b6bb2947dbd3", "collapsed": true}}, {"cell_type": "code", "source": ["def termsComps(file):\n", "    c1,c2,c3,c4,c5,c6,c7,c8,c9=0.,0.,0.,0.,0.,0.,0.,0.,0.\n", "    for t, v in file.items():\n", "        if t in uniC1:\n", "            c1+=v\n", "        if t in uniC2:\n", "            c2+=v\n", "        if t in uniC3:\n", "            c3+=v\n", "        if t in uniC4:\n", "            c4+=v\n", "        if t in uniC5:\n", "            c5+=v\n", "        if t in uniC6:\n", "            c6+=v\n", "        if t in uniC7:\n", "            c7+=v\n", "        if t in uniC8:\n", "            c8+=v\n", "        if t in uniC9:\n", "            c9+=v\n", "        suma=c1+c2+c3+c4+c5+c6+c7+c8+c9\n", "        if suma==0:\n", "            suma=1\n", "            \n", "    return [c1/suma,c2/suma,c3/suma,c4/suma,c5/suma,c6/suma,c7/suma,c8/suma,c9/suma]"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "5b2ab1f0ed30088d073a3a0eb303ad9b8e2cabe5", "_cell_guid": "b19cee32-27ab-463a-bf3b-73c9eede083c", "collapsed": true}}, {"cell_type": "code", "source": ["uniqsTextMatr=[]\n", "for file in texts_for_training:\n", "    uniqsTextMatr.append(termsComps(file))\n", "\n", "uniqText = pd.DataFrame(uniqsTextMatr, columns=['class'+str(c+1) for c in range(9)])\n", "uniqText['RealClass'] = train[\"Class\"]\n", "\n"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "e8e953ce650b37b094cc115ce907b3567bb05060", "_cell_guid": "8ffe79b2-eea4-4ff2-bbda-e5c05f1edd85", "collapsed": true}}, {"cell_type": "code", "source": ["uniqText.to_csv('uniqtrain.csv',index=False)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "d73730980113bf87f5ca7cfb9b19d4363645d5d0", "_cell_guid": "9f916c22-a6aa-4813-916e-52af3e6712ae", "collapsed": true}}, {"cell_type": "code", "source": [], "outputs": [], "execution_count": null, "metadata": {"_uuid": "a422cd7ed9ceb48e492a74abbb7abfdadf8fe66f", "_cell_guid": "bb1f54ca-e36d-4743-988a-6d33c4890693", "collapsed": true}}], "nbformat_minor": 1, "nbformat": 4, "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python", "file_extension": ".py", "version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}}}