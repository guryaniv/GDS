{"cells":[{"metadata":{"_uuid":"433d5179a610d98f37047ea6c4a7b2b0dd826207"},"cell_type":"markdown","source":"# How to cluster the datasets?\nAccording to some kernels like [here](https://www.kaggle.com/erikgarcia/data-is-an-hypersphere) the target transaction depends on the euclidean distance. I want to find out, if there are any significant cluster in the 200 dimensions.\nBecause of the size there are view clustering methods you can use. <br>\nAt the end of this kernel the new features are save and can be used for training a model."},{"metadata":{"_uuid":"97abe9b2e957df119574644ed9b6017394710f84"},"cell_type":"markdown","source":"## In this kernel I will use a efficient implementation of [DBSCAN](https://hdbscan.readthedocs.io/en/latest/basic_hdbscan.html). "},{"metadata":{"_uuid":"d18228cb44aaf36c79cd1c9ad8f85d3bb4e5aa7b","trusted":true},"cell_type":"code","source":"!pip install hdbscan","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f458fcfec4ab4b00d527d0b4290a8eb6c3066da","trusted":true},"cell_type":"code","source":"import hdbscan","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"757eb6ceba3bbabf83c93fc547cd471c8eeaf29a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score, train_test_split, KFold\nfrom sklearn.cluster import SpectralClustering, AgglomerativeClustering, DBSCAN, KMeans, FeatureAgglomeration\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom tqdm import tqdm\nimport gc\nimport time\ngc.enable()\nfrom numba import jit","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93de5c3a30df3e82f2486fe94a5f17e259b5869f","trusted":true},"cell_type":"code","source":"%%time\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nX_test_ID = test.ID_code.values\ny = train.target.values\n\ncols = [i for i in test.columns if \"var\" in i]\ntrain = train[cols+[\"target\"]]\ntest = test[cols]\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e84a31e8efd1e86b516a6012cbd384c237d4c7ad","trusted":true},"cell_type":"code","source":"df = pd.concat([train,test], axis=0)\nscaler = StandardScaler()\ndf[cols] = scaler.fit_transform(df[cols])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"081a8c99ff267c86037403d7d566a6e076247bb5"},"cell_type":"markdown","source":"# KMeans"},{"metadata":{"_uuid":"fa083b99ae037dc84c5c63f3adc6fd12a0c21a93","trusted":true,"scrolled":true},"cell_type":"code","source":"%%time\nsample_size = 10000\n\nfor sample_size in [df.shape[0]]:\n\n    for m,n in enumerate([5,10,20,40]): # \n    #     print(f\"\\r {m}: clusters: {n}\", flush=True, end=\"\")\n\n        n_clusters = n\n        start = time.time()\n        cluster = KMeans(n_clusters=n_clusters, init=\"k-means++\", n_init=1, max_iter=200, tol=0.0001, \n                         precompute_distances=\"auto\", verbose=0, random_state=None, copy_x=True, n_jobs=-1, algorithm=\"auto\")\n\n        cluster.fit(df.head(sample_size)[cols])\n        end = time.time()\n        print(\"{:.2f} Seconds | Clusters: {} | Sample size: {:.2f}% of total.\".format(end-start, n_clusters, sample_size/df.shape[0]))\n        y_pred = cluster.labels_\n\n        train[f\"kmeans_{m+1}\"] = y_pred[:200000]\n        test[f\"kmeans_{m+1}\"] = y_pred[200000:]\n        del cluster\n        gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d54ee3d9c1fadfd68f8c898ac56172b85d9ccea5"},"cell_type":"markdown","source":"## KMeans just splits all the data in n cluster with almost the same size but the frequency of the target is in some clusters higher."},{"metadata":{"trusted":true,"_uuid":"2a58d2626163fa5f1bceb1e2d7f8c2576280be41","_kg_hide-input":true},"cell_type":"code","source":"kmdf = train[[\"kmeans_3\", \"target\"]].sort_values(by=\"target\")\nplt.figure(figsize=(12,8))\nx = kmdf[kmdf.target==0].kmeans_3\ny = kmdf[kmdf.target==1].kmeans_3\nplt.hist([x,y], bins=60, label=[\"target = 0\", \"target = 1\"]);\nplt.legend(loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a58d2626163fa5f1bceb1e2d7f8c2576280be41","scrolled":false},"cell_type":"code","source":"kmdf = train[train.kmeans_3==18]\n\nsns.pairplot(kmdf[cols[:3]+[\"target\"]], hue=\"target\", vars=cols[:3]);\nsns.pairplot(train[cols[:3]+[\"kmeans_1\"]], hue=\"kmeans_1\", vars=cols[:3]);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc61383d6d88f50cf49c45f0a7e3ffc620d0b222"},"cell_type":"markdown","source":"# Now GMM\n## GMM works like KMeans but takes the density into account\nThe compution time increases with the number of clusters."},{"metadata":{"trusted":true,"_uuid":"d8f4457a3b56c56da86e9cd5a6f33eeadf5bd5cd"},"cell_type":"code","source":"%%time\nsample_size = 10000\n\nfor sample_size in [int(df.shape[0]*1)]:\n    for m,n in enumerate([5,10,20]): # \n\n        n_clusters = n\n        start = time.time()\n        cluster = GaussianMixture(n_components=n_clusters, covariance_type=\"full\", tol=0.001, reg_covar=1e-06, \n                                  max_iter=100, n_init=1, init_params=\"kmeans\", weights_init=None, \n                                  means_init=None, precisions_init=None, random_state=None, \n                                  warm_start=False, verbose=0, verbose_interval=10)\n\n        y_pred = cluster.fit_predict(df.head(sample_size)[cols])\n        end = time.time()\n        print(\"{:.2f} Seconds | Clusters: {} | Sample size: {:.2f}% of total.\".format(end-start, n_clusters, sample_size/df.shape[0]))\n#         y_pred = cluster.labels_\n\n        train[f\"gmm_{m+1}\"] = y_pred[:200000]\n        test[f\"gmm_{m+1}\"] = y_pred[200000:]\n        del cluster\n        gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cd91bfaafec65ee3f339cc7a54a8ab7f1628b7b","_kg_hide-input":true},"cell_type":"code","source":"kmdf = train[[\"gmm_3\", \"target\"]].sort_values(by=\"target\")\nplt.figure(figsize=(12,8))\nx = kmdf[kmdf.target==0].gmm_3\ny = kmdf[kmdf.target==1].gmm_3\nplt.hist([x,y], bins=30, label=[\"target = 0\", \"target = 1\"]);\nplt.legend(loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a62ab308741caaeaf9e31c85e54f96eb99166a9"},"cell_type":"code","source":"kmdf = train[train.gmm_1==3]\n\nsns.pairplot(kmdf[cols[:3]+[\"target\"]], hue=\"target\", vars=cols[:3]);\nsns.pairplot(train[cols[:3]+[\"gmm_1\"]], hue=\"gmm_1\", vars=cols[:3]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49cf3e878e5bae678a99da23b18f03951e46c284"},"cell_type":"markdown","source":"# FeatureAgglomeration and hdbscan"},{"metadata":{"trusted":true,"_uuid":"4a39eabfe441730bb0f5de6d936dbef8a9557c65"},"cell_type":"code","source":"%%time\nagglo = FeatureAgglomeration(affinity='euclidean', compute_full_tree='auto',\n                               connectivity=None, linkage='complete', memory=None, n_clusters=4)\nagglo.fit(df[cols])\nreduced = agglo.transform(df[cols])\n\nfor m in range(reduced.shape[-1]):\n\n    train[f\"fagg_{m+1}\"] = reduced[:200000, m]\n    test[f\"fagg_{m+1}\"] = reduced[200000:, m]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbe409b6e71fec4705b4aeac5eaa4c1a58379a8c"},"cell_type":"code","source":"fagg_cols = [i for i in train.columns if \"fagg\" in i]\n\nsns.pairplot(train[fagg_cols+[\"target\"]], hue=\"target\", vars=fagg_cols);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c4e0c7d9c987119a9838c08f8b9cbb71e658e88"},"cell_type":"code","source":"train.to_pickle(\"train_scaled_clustered.pkl\")\ntest.to_pickle(\"test_scaled_clustered.pkl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc85a21f4d589aea62053dfcfc56405d32769117"},"cell_type":"markdown","source":"## TODO hdbscan\nDBSCAN needs more carefully selected parameters to get useful results"},{"metadata":{"_uuid":"457deafc483297910f59f4b3ea50653478e6e968"},"cell_type":"markdown","source":"<font color=blue>You are welcome to take the code or the transformed datasets. If you find something interesting about the created features or you know a fast clustering method I should test, let me know.</font>"},{"metadata":{"trusted":true,"_uuid":"a60deb371bc8f187cb17451d4af8ba0437371ad9"},"cell_type":"code","source":"# def create_clusterer(alpha=0.5):\n#     clusterer = hdbscan.HDBSCAN(algorithm='prims_kdtree', allow_single_cluster=False, alpha=alpha,\n#                             approx_min_span_tree=True, cluster_selection_method='eom',\n#                             core_dist_n_jobs=-1, gen_min_span_tree=False, leaf_size=40,\n#                             match_reference_implementation=False, metric='euclidean', \n#                             min_cluster_size=7, min_samples=None, p=None,\n#                             prediction_data=False)\n#     return clusterer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd77e1e6c605928a871af01456a345ca23f5341b"},"cell_type":"code","source":"# t = []\n# sizes = [reduced.shape[0]] # \n# for alpha in [0.5]:\n\n#     for sample_size in sizes:\n#         clusterer = create_clusterer(alpha)\n#         gc.collect()\n#         start = time.time()\n#         clusterer.fit(reduced[:sample_size])\n#         end = time.time()\n#         t.append(end-start)\n#         dist = np.unique(clusterer.labels_, return_counts=True)\n#         dist = dist[-1]/dist[-1].sum()\n#         print(\"Sample Size: {} | Time: {:.2f} Seconds| N_Clusters: {} | alpha: {}\".format(sample_size, (end-start), dist, alpha))\n        \n#         y_pred = clusterer.labels_\n#         train[f\"hdbscan_{m+1}\"] = y_pred[:200000]\n#         test[f\"hdbscan_{m+1}\"] = y_pred[200000:]\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}