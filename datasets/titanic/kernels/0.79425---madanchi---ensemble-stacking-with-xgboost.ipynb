{"cells":[{"metadata":{"_cell_guid":"c40cf708-6d84-c9e0-f0ac-bcb2bb49e0ba","_uuid":"402309a47a2dff82014c837b946698608e82a381"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"3ede2b94-76f2-b9d3-7c89-8f0075c7c039","_uuid":"3fe882dac43ef93745a83458f9fd6aaac23db51d","trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \nGradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.svm import SVC\nfrom sklearn.cross_validation import KFold","execution_count":148,"outputs":[]},{"metadata":{"_cell_guid":"047b8123-5dfd-23a3-59b3-df1af8a3c604","_uuid":"c007ac0aec12cccd35c42a753196bbc31a3cecfd","trusted":true,"collapsed":true},"cell_type":"code","source":"#Print you can execute arbitrary python code\ntrain_df = pd.read_csv(\"../input/train.csv\" )\ntest_df = pd.read_csv(\"../input/test.csv\" )\nPassengerId = test_df['PassengerId']\ncombine = [train_df, test_df]","execution_count":149,"outputs":[]},{"metadata":{"_cell_guid":"55240904-aacc-114b-24a8-78606e6075ad","_uuid":"19f0b87a8f648450004a51fde7bffce6d88aecac","trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":"train_df = train_df.drop(['Ticket', 'Cabin','PassengerId'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin','PassengerId'], axis=1)\ncombine = [train_df, test_df]\n\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Ms')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Ms')\n    dataset['Title'] = dataset['Title'].replace('Miss', 'Mrs')\n\ntitle_mapping = {\"Mr\": 1, \"Ms\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df = train_df.drop(['Name'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\n\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)  \n\nguess_ages = np.zeros((2,3))\nfor dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n    dataset['Age'] = dataset['Age'].astype(int)\n    \ntrain_df['AgeBand'] = pd.cut(train_df['Age'], 5)\nfor dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\ntrain_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\nfor dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    dataset.loc[ dataset['FamilySize'] <= 1, 'FamilySize'] = 0\n    dataset.loc[(dataset['FamilySize'] > 1) & (dataset['FamilySize'] <= 4), 'FamilySize'] = 1\n    dataset.loc[(dataset['FamilySize'] > 4) & (dataset['FamilySize'] <= 5), 'FamilySize']   = 2\n    dataset.loc[ dataset['FamilySize'] > 5, 'FamilySize'] = 3\ntrain_df = train_df.drop(['Parch', 'SibSp'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp'], axis=1)\ncombine = [train_df, test_df]\nfor dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass    \nfreq_port = train_df.Embarked.dropna().mode()[0]\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)    \nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\ntest_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ntrain_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ncombine = [train_df, test_df]     \nfor dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    dataset['Age*Fare']=dataset.Age * dataset.Fare\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]  ","execution_count":150,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2af5bb35d60fda838ceb00b70d2eaa466554732"},"cell_type":"code","source":"train_df.head()\ntest_df.head()\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":151,"outputs":[]},{"metadata":{"_cell_guid":"069917c4-ea61-c5d9-719c-2826f21626e1","_uuid":"cffb947e8466e8f60659cc1e1d0d0455dc708451","trusted":true},"cell_type":"code","source":"corr = train_df.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(corr, vmax=1, annot=True, square=True)\nplt.title('feature correlations')","execution_count":152,"outputs":[]},{"metadata":{"_cell_guid":"e3f6b3d0-f346-84a2-de02-a3f588055405","_uuid":"2adbd91e89c798dfb9c173d4daba895f8d9e5cb4","trusted":true,"collapsed":true},"cell_type":"code","source":"#Set parameters for ensembling\nntrain = train_df.shape[0]\nntest = test_df.shape[0]\nseed = 10\nnfolds = 5\nkf = KFold(ntrain, n_folds = nfolds, random_state=seed)","execution_count":153,"outputs":[]},{"metadata":{"_cell_guid":"556bb52e-a7a2-e459-2d5d-188835aa4a15","_uuid":"d0782eea7f22ea4ec2ffc549074b8e73da522cfa","trusted":true,"collapsed":true},"cell_type":"code","source":"#Sklearn custom class\n\nclass SklearnHandler(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n        self.clf = clf(**params)\n        \n    def train(self, x_train, y_train):\n        self.clf.fit(x_train, y_train)\n        \n    def predict(self, x):\n        return self.clf.predict(x)\n    \n    def fit(self, x, y):\n        return self.clf.fit(x,y)\n    \n    def feature_importances(self, x, y):\n        return self.clf.fit(x, y).feature_importances_","execution_count":154,"outputs":[]},{"metadata":{"_cell_guid":"5aac09bf-107e-6710-488a-fdbc57ec5392","_uuid":"e16e0b7cda1c7a048acdcc7777913b043d6d7e3a","trusted":true,"collapsed":true},"cell_type":"code","source":"#Class to get out-of-fold predictions\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((nfolds, ntest))\n    \n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n        \n        clf.train(x_tr, y_tr)\n        \n        oof_train[test_index] = clf.predict(x_te)\n        oof_test_skf[i, :] = clf.predict(x_test)\n        \n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1,1), oof_test.reshape(-1, 1)","execution_count":155,"outputs":[]},{"metadata":{"_cell_guid":"f282ee5f-a851-03c9-a562-4f04bb214bf2","_uuid":"5247c8616607b0da1551e91bf52a93bec9be5c7d","trusted":true,"collapsed":true},"cell_type":"code","source":"#Create parameters for all classifiers\n#Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 1000,\n    'warm_start': True,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n#Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':1000,\n    'max_depth': 9,\n    'min_samples_split': 6,\n    'min_samples_leaf': 4,\n    'verbose': 0\n}\n\n#AdaBoost parameters\nada_params = {\n    'n_estimators': 1000,\n    'learning_rate' : 0.75\n}\n\n#Gradient Boosting parameters\ngb_params = {\n    'n_estimators': 1000,\n    'max_depth': 5,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n\n#Support Vector Classifier parameters \nsvc_params = {\n    'kernel' : 'linear',\n    'C' : 0.025\n    }","execution_count":157,"outputs":[]},{"metadata":{"_cell_guid":"fb04b468-8ba0-df57-a941-6e15ffde3c8c","_uuid":"a4501743471c130f5d4058fe076117a87e93c63e","trusted":true,"collapsed":true},"cell_type":"code","source":"#Create models\nrf = SklearnHandler(clf=RandomForestClassifier, seed=seed, params=rf_params)\net = SklearnHandler(clf=ExtraTreesClassifier, seed=seed, params=et_params)\nada = SklearnHandler(clf=AdaBoostClassifier, seed=seed, params=ada_params)\ngb = SklearnHandler(clf=GradientBoostingClassifier, seed=seed, params=gb_params)\nsvc = SklearnHandler(clf=SVC, seed=seed, params=svc_params)","execution_count":105,"outputs":[]},{"metadata":{"_cell_guid":"f0b958c1-6af0-4522-cb0f-5dc7965ac16f","_uuid":"d031d86f53e94e4185abc40386b1ca6dde72a02a","trusted":true,"collapsed":true},"cell_type":"code","source":"#Create arrays for the models\ny_train = train_df['Survived'].ravel()\ntrain_df = train_df.drop(['Survived'], axis=1)\nx_train = train_df.values\nx_test = test_df.values ","execution_count":158,"outputs":[]},{"metadata":{"_cell_guid":"2d448d88-b787-9794-6bb9-82e8c0e26a27","_uuid":"fb904c8cfafdbd8f97db147248810c7d304dcdf1","trusted":true},"cell_type":"code","source":"#Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\nsvc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier\n\nprint(\"Training is complete\")","execution_count":159,"outputs":[]},{"metadata":{"_cell_guid":"27e32edf-a85b-39ce-fdb5-e20c0ed65444","_uuid":"53f901f56164687f9087d16ea40f50ba67bf089c","trusted":true},"cell_type":"code","source":"rf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)","execution_count":160,"outputs":[]},{"metadata":{"_cell_guid":"03eb4c4b-03d9-7e34-f664-0af573b7cf4d","_uuid":"1a27be8b864e062259b12ca3af5ec2fb4fcdb8aa","trusted":true,"collapsed":true},"cell_type":"code","source":"cols = train_df.columns.values\n#Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_feature,\n     'Extra Trees  feature importances': et_feature,\n      'AdaBoost feature importances': ada_feature,\n    'Gradient Boost feature importances': gb_feature,                            \n    })","execution_count":161,"outputs":[]},{"metadata":{"_cell_guid":"330228b3-0659-2e33-1755-55c52a43f5d3","_uuid":"797e2553b15b0f7e5c08ab7677540b341f4fc9c1","trusted":true,"collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.barplot(feature_dataframe['features'], feature_dataframe['Random Forest feature importances'])","execution_count":73,"outputs":[]},{"metadata":{"_cell_guid":"98bf73c3-62ca-7982-d1e3-4853a3ac35c2","_uuid":"610845aba5da56632c09621a6c062d50e4f30f4f","trusted":true,"collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.barplot(feature_dataframe['features'], feature_dataframe['Extra Trees  feature importances'])","execution_count":74,"outputs":[]},{"metadata":{"_cell_guid":"2e8262cd-2c01-af94-8d50-84259f5fd615","_uuid":"323500a9d43a50d600056665c5353e9c50f5c007","trusted":true,"collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.barplot(feature_dataframe['features'], feature_dataframe['AdaBoost feature importances'])","execution_count":24,"outputs":[]},{"metadata":{"_cell_guid":"443bb8e7-a739-c623-0e1c-7da80eade7c3","_uuid":"b2e67547fad00993339f10039583aae5288f89d7","trusted":true,"collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.barplot(feature_dataframe['features'], feature_dataframe['Gradient Boost feature importances'])","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"c66797b2-804e-2e0c-a2a3-569772da07a5","_uuid":"5e3b665101fbf74713ddfaad8f3e1b8ffcb36c3a","trusted":true},"cell_type":"code","source":"#Create the new column containing the average of values\n\nfeature_dataframe['mean'] = feature_dataframe.mean(axis= 1) # axis = 1 computes the mean row-wise\nfeature_dataframe","execution_count":162,"outputs":[]},{"metadata":{"_cell_guid":"2ecbd240-5e33-ec80-3f06-4d355f3430ab","_uuid":"8cff889621d9ead5ec22ea1c888c8bfe154646db","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.barplot(feature_dataframe['features'], feature_dataframe['mean'])","execution_count":163,"outputs":[]},{"metadata":{"_cell_guid":"9a4ff943-89b9-2a6f-2d30-955cf9c339e7","_uuid":"c590bb14166ac2de9445a201b48ed5647d01083c","trusted":true,"scrolled":true},"cell_type":"code","source":"base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n     'ExtraTrees': et_oof_train.ravel(),\n     'AdaBoost': ada_oof_train.ravel(),\n      'GradientBoost': gb_oof_train.ravel(),\n    })\nbase_predictions_train.head()","execution_count":164,"outputs":[]},{"metadata":{"_cell_guid":"36f8f61b-c951-a151-d613-96e6393f9ede","_uuid":"2f8b43d87926430954cf5f5303fbcc33990a5d32","trusted":true},"cell_type":"code","source":"corr = base_predictions_train.astype(float).corr()\nplt.figure(figsize=(15,15))\nsns.heatmap(corr, vmax=1, annot=True, square=True)\nplt.title('feature correlations')","execution_count":165,"outputs":[]},{"metadata":{"_cell_guid":"1654b26e-bc85-4389-a298-12ec669ce17b","_uuid":"fdbb093b65124502c75987abff2467560e7eea26","trusted":true,"collapsed":true},"cell_type":"code","source":"x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)\nx_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)","execution_count":166,"outputs":[]},{"metadata":{"_cell_guid":"aa2dc209-c188-2207-5a90-cb388122d837","_uuid":"afcd8ab625507f0facd2e4349e8c9121ff02f0db","trusted":true,"collapsed":true},"cell_type":"code","source":"gbm = xgb.XGBClassifier(\n n_estimators= 2000,\n max_depth= 4,\n min_child_weight= 2,\n gamma=0.9,                        \n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread= -1,\n scale_pos_weight=1).fit(x_train, y_train)\npredictions = gbm.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7c4f921a-a763-22a9-1b12-38fb9f93a6f4","_uuid":"799447d697f9805c66f873ecb536bbaadb0fae09","trusted":true,"collapsed":true},"cell_type":"code","source":"# Generate Submission File \nStackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,\n                            'Survived': predictions })\nStackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)","execution_count":81,"outputs":[]}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}