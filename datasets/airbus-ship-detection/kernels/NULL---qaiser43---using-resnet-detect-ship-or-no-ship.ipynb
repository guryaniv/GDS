{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport gc\nprint(os.listdir(\"../input\"))\nimport numpy as np \nimport pandas as pd\nimport time\n\n# Any results you write to the current directory are saved as output.\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/airbus-ship-detection/train_ship_segmentations_v2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efd2ea308ca04f91749ada2dbf67f62b447b5d18","scrolled":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b13464005e7ab0af595b62cc1162d19015dff6e"},"cell_type":"code","source":"list(train.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf7fd68627ba9fb3e48f7e1b80a50cf8e5eba8d0"},"cell_type":"code","source":"train['exist_ship'] = train['EncodedPixels'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54665ce582a6c29499e5f81ab7547f723e95eed7"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06e55fcf5061e5d02dd81dffb0a75f63f6359b28","scrolled":true},"cell_type":"code","source":"train['exist_ship'] != 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0938180caa3d59ebdf3290fda7673502750fcac"},"cell_type":"code","source":"train.loc[train['exist_ship'] != 0 , 'exist_ship'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"759b355ad0730b12f4f097dbacae23677974a4e6"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f1f7626b0c64fac65b29609bb6adf7e32015533"},"cell_type":"code","source":"del train['EncodedPixels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2fd2bf07e24695fd4cef7b4351c3def2ac213c9"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"617d3eb4b674814c1c1102c27c79cff363278bf4"},"cell_type":"code","source":"print(len(train['ImageId']))\nprint(train['ImageId'].value_counts().shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7943ba7be3b0bc580a4fe131416f42ff58c875fd"},"cell_type":"code","source":"train_gp = train.groupby(['ImageId']).sum().reset_index()\ntrain_gp.loc[train_gp['exist_ship']>0,'exist_ship']=1\n\ntrain_sample = train_gp.sample(5000)\ntest_sample = train_gp.sample(1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"399ad229cab10b52df239c4246fad61d0cef57e4"},"cell_type":"code","source":"print(train_gp['exist_ship'].value_counts())\nprint(train_sample['exist_ship'].value_counts())\nprint(test_sample['exist_ship'].value_counts())\nprint (train_sample.shape)\nprint (test_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc1e684fa398a89fa776099349e91a43c2a81324"},"cell_type":"code","source":"from keras.utils import np_utils\nimport numpy as np\nfrom glob import glob\n\nTrain_path = '../input/airbus-ship-detection/train_v2/'\nTest_path = '../input/airbus-ship-detection/test_v2/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a3a1ced6a5960dbdb0cf8b08850c453ec4d4ef2"},"cell_type":"code","source":"# define function to load train, test, and validation datasets\ndef load_dataset(path):\n    files_array = []\n    if str(path) == str(Train_path):\n        data = np.array(train_sample['ImageId'])\n        data_targets = np_utils.to_categorical(np.array(train_sample['exist_ship']), 133)\n\n        for idx, element in  enumerate(data): \n            files_array.append(Train_path + element)\n\n        data = np.array(files_array)\n    else:\n        data = np.array(test_sample['ImageId'])\n        data_targets = np_utils.to_categorical(np.array(test_sample['exist_ship']), 133)\n\n        for idx, element in  enumerate(data): \n            files_array.append(Train_path + element)\n\n        data = np.array(files_array)\n    \n    return data, data_targets\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c03f5db8401150ff745195b65d004d5d6d4acf6f","scrolled":false},"cell_type":"code","source":"# load train, test, and validation datasets\ntrain_files, train_targets = load_dataset(Train_path)\ntest_files, test_targets = load_dataset(Test_path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36e3af228f3c10fb13558b57f83c7112bb027d97"},"cell_type":"code","source":"from keras.preprocessing import image \nfrom tqdm import tqdm\n\ndef path_to_tensor(img_path):\n    # loads RGB image as PIL.Image.Image type\n    img = image.load_img(img_path, target_size=(224, 224))\n    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n    x = image.img_to_array(img)\n    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n    return np.expand_dims(x, axis=0)\n\ndef paths_to_tensor(img_paths):\n    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n    return np.vstack(list_of_tensors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32606644a49f5b7410ad884f156931ab24a6ee5e"},"cell_type":"code","source":"from PIL import ImageFile                            \nImageFile.LOAD_TRUNCATED_IMAGES = True                 \n\n\ntest_tensors = paths_to_tensor(test_files).astype('float32')/255\ntrain_tensors = paths_to_tensor(train_files).astype('float32')/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5511ab3de12eee3c4adc5895217eafd5c6f726d8"},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50\n\nimg_width, img_height = 224, 224\n#model = ResModel(weights = 'imagenet')\nmodel = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5', include_top=True, input_shape = (224, 224, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53ce6783378c55ba0a913a8211ae49276bbe4b80"},"cell_type":"code","source":"from keras.applications.resnet50 import preprocess_input, decode_predictions\n\ndef ResNet50_predict_labels(img_path):\n    # returns prediction vector for image located at img_path\n    img = preprocess_input(path_to_tensor(img_path))\n    pred = model.predict(img)\n    print('Predicted:', decode_predictions(pred, top=3))\n    return np.argmax(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6489b151480e7da640d2c05acc8a9dffac0dabc6"},"cell_type":"code","source":"### returns \"True\" if a dog is detected in the image stored at img_path\ndef dog_detector(img_path):\n    prediction = ResNet50_predict_labels(img_path)\n    return ((prediction <= 268) & (prediction >= 151)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6ee6ab422b4948c1799693f58e46960e37aa828"},"cell_type":"code","source":"human_files = np.array(glob(Test_path+ \"*\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cdf5ee2980bf6ddc8b13cda3c41f68d98246828"},"cell_type":"code","source":"human_files_short = human_files[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abd0e50951023cdce29e0794e89ab6b67aa0b761"},"cell_type":"code","source":"import cv2                \nimport matplotlib.pyplot as plt                        \n%matplotlib inline \n\nfor human_file in human_files_short:\n    fd = dog_detector(human_file)\n    img = cv2.imread(human_file)\n    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(cv_rgb)\n    plt.show()\n        ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}