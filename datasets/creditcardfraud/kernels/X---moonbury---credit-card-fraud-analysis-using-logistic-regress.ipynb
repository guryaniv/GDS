{"nbformat_minor": 1, "nbformat": 4, "cells": [{"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "metadata": {"_cell_guid": "dd5ae007-0e8b-45d7-a6cf-b5865a333b9f", "_uuid": "e726e1fc1495ceb262a644cddfe4fb0cf18a5dec"}, "execution_count": null, "cell_type": "code"}, {"source": ["print(\"The dataset contain 30 features and a resulting column 'Class'.\\nAs said, this is a highly unbalanced problem. \\nThere are 2 output values (0,1) and only 0.172% of positive value (1).\")\n", "data=pd.read_csv('../input/creditcard.csv')\n", "\n", "import warnings\n", "warnings.filterwarnings('ignore')"], "outputs": [], "metadata": {"_cell_guid": "c06c1f8e-5184-4fda-a9ed-7808dcb4a96c", "scrolled": true, "_uuid": "5e2f2c3e1086726636ba02c9dd64dc790fb4b0c5"}, "execution_count": null, "cell_type": "code"}, {"source": ["data.describe()"], "outputs": [], "metadata": {"_cell_guid": "cdc96be1-8f5e-4431-8ed3-d5dd59ace930", "_uuid": "769d9738d44c6588d16be9bb8c5b2022a9eb1f59"}, "execution_count": null, "cell_type": "code"}, {"source": ["print(\"Prepare the X and y values. Since it is imbalanced data, use SMOTE to resample the data.\")\n", "print(\"If using SMOTE, we can achieve better recall (90%), otherwise, 54% recall.\")\n", "\n", "from sklearn.cross_validation import train_test_split\n", "from collections import Counter\n", "y = data['Class']\n", "cols = set(data.columns)\n", "cols.remove('Class')\n", "cols.remove('Time')\n", "cols.remove('Amount')\n", "X = data[list(cols)]\n", "\n", "print('Original dataset shape {}'.format(Counter(y)))\n", "X_org = X\n", "y_org = y\n", "\n", "from imblearn.over_sampling import SMOTE \n", "sm = SMOTE(random_state=42)\n", "X_res, y_res = sm.fit_sample(X, y)\n", "print('Resampled dataset shape {}'.format(Counter(y_res)))"], "outputs": [], "metadata": {"_cell_guid": "55b22448-a147-4b85-b4ac-b3471a8e71c2", "_uuid": "d850a6648037a9abb28f0cc2101bc23dfcbef5e6"}, "execution_count": null, "cell_type": "code"}, {"source": ["from sklearn.preprocessing import StandardScaler\n", "from sklearn.preprocessing import MinMaxScaler\n", "\n", "print(\"Apply Standaraization and Normailzation to the data\")\n", "centering = StandardScaler(with_mean=True, with_std=False)\n", "X_res = centering.fit_transform(X_res)\n", "scaling = MinMaxScaler(feature_range=(0,1))\n", "X_res = scaling.fit_transform(X_res)\n", "\n", "centering = StandardScaler(with_mean=True, with_std=False)\n", "X = centering.fit_transform(X)\n", "scaling = MinMaxScaler(feature_range=(0,1))\n", "X = scaling.fit_transform(X)"], "outputs": [], "metadata": {"_cell_guid": "299f6891-7ca8-44a0-b631-9531596767e4", "_uuid": "2d1feea4bc179d5c06ff389915267399765886d0"}, "execution_count": null, "cell_type": "code"}, {"source": ["print(\"Split the data into 80% training and 20% testing. I try other ratio but this gives me better result.\\n\")\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=101)\n", "print(\"Split the data into 80% training data and 20% testing data.\")\n", "print(\"# of training data:\",  X_train.shape[0])\n", "print(\"# of testing data:\",  y_test.shape[0])\n", "\n", "X_res_train, X_res_test, y_res_train, y_res_test = train_test_split(X_res, y_res, train_size=0.80, random_state=101)\n", "print(\"Split the data into 80% training data and 20% resampled testing data.\")\n", "print(\"# of training data:\",  X_res_train.shape[0])\n", "print(\"# of testing data:\",  y_res_test.shape[0])"], "outputs": [], "metadata": {"_cell_guid": "a88a8034-2c96-4d59-86e9-cb942da0d6da", "_uuid": "f592bfb2459607427ef0430b9f77c7d4b42edc66"}, "execution_count": null, "cell_type": "code"}, {"source": ["print(\"prepare the confusion matrix function\")\n", "\n", "import matplotlib.pyplot as plt\n", "import itertools\n", "\n", "def plot_confusion_matrix(cm, classes,normalize=True,title='Confusion matrix',\n", "                          cmap=plt.cm.Blues):\n", "    if normalize:\n", "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n", "        print(\"Normalized confusion matrix\")\n", "    else:\n", "        print('Confusion matrix, without normalization')\n", "\n", "    #print(cm)\n", "\n", "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n", "    plt.title(title)\n", "    plt.colorbar()\n", "    tick_marks = np.arange(len(classes))\n", "    plt.xticks(tick_marks, classes, rotation=45)\n", "    plt.yticks(tick_marks, classes)\n", "\n", "    fmt = '.2f' if normalize else 'd'\n", "    thresh = cm.max() / 2.\n", "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n", "        plt.text(j, i, format(cm[i, j], fmt),\n", "                 horizontalalignment=\"center\",\n", "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n", "\n", "    plt.tight_layout()\n", "    plt.ylabel('True label')\n", "    plt.xlabel('Predicted label')"], "outputs": [], "metadata": {"_cell_guid": "b7c8c187-9dfb-42d1-b05c-f40554b0366c", "_uuid": "07119412a92c3f6d5d69502633d87c07e1c90d7d"}, "execution_count": null, "cell_type": "code"}, {"source": ["from sklearn.metrics import classification_report, accuracy_score,recall_score\n", "from sklearn.metrics import confusion_matrix\n", "import matplotlib.pylab as pylab\n", "\n", "print(\"Train the logistic Regression with the sampled data and see.\")\n", "from sklearn.linear_model import LogisticRegression\n", "\n", "regr = LogisticRegression()\n", "regr.fit(X_res_train, y_res_train)\n", "y_res_train_pred = regr.predict(X_res_train)\n", "y_res_test_pred = regr.predict(X_res_test)\n", "\n", "print(\"Training data accuracy:\", accuracy_score(y_res_train, y_res_train_pred))\n", "print(\"Training data recall:\", recall_score(y_res_train, y_res_train_pred))\n", "print(\"Testing data accuracy:\", accuracy_score(y_res_test, y_res_test_pred))\n", "print(\"Testing data recall:\", recall_score(y_res_test, y_res_test_pred))\n", "print(\"Classification Report\")\n", "print(classification_report(y_res_test, y_res_test_pred))\n", "\n", "#print(np.mean(regr.predict_proba(X_test)))\n", "\n", "# Compute confusion matrix\n", "cnf_matrix = confusion_matrix(y_res_test, y_res_test_pred)\n", "np.set_printoptions(precision=2)\n", "\n", "# Plot non-normalized confusion matrix\n", "plt.figure()\n", "plot_confusion_matrix(cnf_matrix,classes=['True','False'])\n", "plt.show()\n", "\n", "print(\"The result is good on both training and testing data.\")"], "outputs": [], "metadata": {"_cell_guid": "bcfca8ae-06a0-45db-91d4-add8abb3c0c0", "_uuid": "3b9e440f47a03744df916b996030ec3989c00b88"}, "execution_count": null, "cell_type": "code"}, {"source": ["print(\"Use the same function on original data and see.\\n\")\n", "y_train_pred = regr.predict(X_train)\n", "y_test_pred = regr.predict(X_test)\n", "\n", "print(\"Training data Accuracy:\", accuracy_score(y_train, y_train_pred))\n", "print(\"Training data recall:\", recall_score(y_train, y_train_pred))\n", "print(\"Testing data Accuracy:\", accuracy_score(y_test, y_test_pred))\n", "print(\"Testing data recall:\", recall_score(y_test, y_test_pred))\n", "print(\"Classification Report\")\n", "print(classification_report(y_test, y_test_pred))\n", "\n", "from sklearn.metrics import confusion_matrix\n", "import matplotlib.pylab as pylab\n", "\n", "# Compute confusion matrix\n", "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n", "np.set_printoptions(precision=2)\n", "\n", "# Plot non-normalized confusion matrix\n", "plt.figure()\n", "plot_confusion_matrix(cnf_matrix,classes=['True','False'])\n", "\n", "plt.show()\n", "\n", "print(\"The result is not bad too on both training and testing data.\")"], "outputs": [], "metadata": {"_cell_guid": "4f635a5c-eecf-4737-92bb-5dea0a7e6444", "_uuid": "697f3087ba4fe98ce65aeb5ec2b49b2f7009fb6a"}, "execution_count": null, "cell_type": "code"}, {"source": ["print(\"next, I will use GridSearchCV to find the best hyperparameters.\")"], "outputs": [], "metadata": {"_cell_guid": "dff714d7-7ab3-4902-9cab-7bfa28e13119", "_uuid": "58ce3c61d3e0066bed7ee5be785f50fd571a4d15"}, "execution_count": null, "cell_type": "code"}, {"source": ["print(\"Use GridSearchCV to find the best paramters for logistic Regression and test on the data again.\")\n", "print(\"You can see the C value is larger than usual and I will like to give more penalty for false result.\")\n", "print(\"I find that C=100 can raise 1% recall.\")\n", "\n", "from sklearn.grid_search import GridSearchCV\n", "\n", "parameters = {\n", "    'tol': [0.00001, 0.0001, 0.001],\n", "    'C': [1, 50, 100]\n", "}\n", "\n", "clfgs = GridSearchCV(LogisticRegression(random_state=101, n_jobs=1),\n", "                     param_grid=parameters,\n", "                     cv=3,\n", "                     n_jobs=1,\n", "                     scoring='recall'\n", "                    )\n", "clfgs.fit(X_res_train, y_res_train)\n", "clf = clfgs.best_estimator_\n", "\n", "print(clfgs.best_estimator_)\n", "print(\"The best classifier score:\",clfgs.best_score_)\n", "\n", "y_res_train_pred = clf.predict(X_res_train)\n", "y_res_test_pred = clf.predict(X_res_test)\n", "\n", "print(\"Use the best classifer to run the sampled data\")\n", "#print(\"Print the classification Report\")\n", "#print(classification_report(y_test, y_test_pred))\n", "print(\"Training sampled data accuracy:\", accuracy_score(y_res_train, y_res_train_pred))\n", "print(\"Training sampled data recall:\", recall_score(y_res_train, y_res_train_pred))\n", "print(\"Testing sampled data accuracy:\", accuracy_score(y_res_test, y_res_test_pred))\n", "print(\"Testing sampled data recall:\", recall_score(y_res_test, y_res_test_pred))\n", "\n", "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n", "plot_confusion_matrix(cnf_matrix,classes=['True','False'])\n", "plt.show()\n", "\n", "y_train_pred = clf.predict(X_train)\n", "y_test_pred = clf.predict(X_test)\n", "\n", "print(\"Use the best classifer to run the original data\")\n", "#print(\"Print the classification Report\")\n", "#print(classification_report(y_test, y_test_pred))\n", "print(\"Training data accuracy:\", accuracy_score(y_train, y_train_pred))\n", "print(\"Training data recall:\", recall_score(y_train, y_train_pred))\n", "print(\"Testing data accuracy:\", accuracy_score(y_test, y_test_pred))\n", "print(\"Testing data recall:\", recall_score(y_test, y_test_pred))\n", "\n", "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n", "plot_confusion_matrix(cnf_matrix,classes=['True','False'])\n", "plt.show()"], "outputs": [], "metadata": {"_cell_guid": "221fbe37-b848-4e6a-b39d-d04f86d7e947", "_uuid": "8066aa12c281eb9486e6bc55d117bbd42f44b037"}, "execution_count": null, "cell_type": "code"}, {"source": ["print(\"I try couple tol and C and found that the best values are C=100 , tol=0.001\")"], "outputs": [], "metadata": {"_cell_guid": "94b97649-8d16-483f-9239-358fbe8fb301", "_uuid": "464beeab36fa4337049b7b2371adba1d13a2ddea"}, "execution_count": null, "cell_type": "code"}, {"source": ["print(\"Next, we will try the SGD classifier\")\n", "\n", "print(\"Train the SGDClassifier with the sampled data and see.\")\n", "from sklearn.linear_model import SGDClassifier\n", "\n", "clf = SGDClassifier(random_state=101, n_jobs=1)\n", "clf.fit(X_res_train, y_res_train)\n", "y_res_train_pred = clf.predict(X_res_train)\n", "y_res_test_pred = clf.predict(X_res_test)\n", "\n", "print(\"Training data accuracy:\", accuracy_score(y_res_train, y_res_train_pred))\n", "print(\"Training data recall:\", recall_score(y_res_train, y_res_train_pred))\n", "print(\"Testing data accuracy:\", accuracy_score(y_res_test, y_res_test_pred))\n", "print(\"Testing data recall:\", recall_score(y_res_test, y_res_test_pred))\n", "print(\"Classification Report\")\n", "print(classification_report(y_res_test, y_res_test_pred))\n", "\n", "# Compute confusion matrix\n", "cnf_matrix = confusion_matrix(y_res_test, y_res_test_pred)\n", "np.set_printoptions(precision=2)\n", "\n", "# Plot non-normalized confusion matrix\n", "plt.figure()\n", "plot_confusion_matrix(cnf_matrix,classes=['True','False'])\n", "plt.show()\n"], "outputs": [], "metadata": {"_cell_guid": "03b83fc4-3b9a-4a9c-9155-0e50fe48c346", "_uuid": "4081b92f6d5d1b4919c72825b29f5afac4d03fc0"}, "execution_count": null, "cell_type": "code"}, {"source": ["print(\"The result for SGDC is worst than Logistic on recall.\")"], "outputs": [], "metadata": {"_cell_guid": "a613ea50-61f1-4697-bf6d-df1e709f94f9", "_uuid": "672b8182751f86fa9503d858f877c4d3b389286f"}, "execution_count": null, "cell_type": "code"}, {"source": ["'''\n", "print(\"Use GridSearchCV to find the best paramters for SGDClassifier\")\n", "from sklearn.grid_search import GridSearchCV\n", "\n", "parameters = {\n", "    #'loss': ('log','hinge'),\n", "    'epsilon': [0.01,0.001,0.0001],\n", "    'learning_rate': ('optimal','constant'),\n", "    'eta0': [0.01,0.001,0.0001],\n", "}\n", "\n", "clfgs = GridSearchCV(SGDClassifier(random_state=101, n_jobs=1),\n", "                     param_grid=parameters,\n", "                     cv=3,\n", "                     n_jobs=1,\n", "                     scoring='recall'\n", "                    )\n", "\n", "clfgs.fit(X_res_train, y_res_train)\n", "clf = clfgs.best_estimator_\n", "\n", "print(clfgs.best_estimator_)\n", "print(\"The best classifier score:\",clfgs.best_score_)\n", "\n", "y_res_test_pred = clf.predict(X_res_test)\n", "y_test_pred = clf.predict(X_test)\n", "\n", "print(\"Use the best classifer to run the test data\")\n", "print(\"Print the classification Report\")\n", "print(classification_report(y_test, y_test_pred))\n", "\n", "print(\"Testing data Accuracy:\", accuracy_score(y_test, y_test_pred))\n", "print(\"Testing data recall:\", recall_score(y_test, y_test_pred))\n", "\n", "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n", "plot_confusion_matrix(cnf_matrix,classes=['True','False'])\n", "plt.show()\n", "'''"], "outputs": [], "metadata": {"_cell_guid": "23f3e3fc-8b8e-4b72-bb55-b1dfde826572", "_uuid": "bfec548c7ffb227e190ea42afb7dde235cbebfef"}, "execution_count": null, "cell_type": "code"}, {"source": ["print(\"SGDClassifer is worst than Logistic Regression.\\nIn general, I can achieve 90% reacll. Let's read more on how to improve the recall.\")"], "outputs": [], "metadata": {"_cell_guid": "d8fd70f7-9adf-43c8-a906-e04f0c784618", "_uuid": "c9fec4e3e8e44bea8101c1394aae3d9d59c6dd11"}, "execution_count": null, "cell_type": "code"}, {"source": ["print(\"let's examine the Time and Amount.\")\n", "import matplotlib.pyplot as plt\n", "import plotly.plotly as py\n", "fig, (ax1, ax2) = plt.subplots(2)\n", "\n", "ax1.set_title('Amount and Time on Fraud')\n", "ax1.scatter(data['Amount'], data['Class'])\n", "ax2.scatter(data['Time'], data['Class'])\n", "print(\"It seems that amount is an important feature.\")\n", "\n", "print(data.shape)\n", "print(data[data['Amount'] < 2000].shape)"], "outputs": [], "metadata": {"_cell_guid": "05517708-2f50-4b07-aae1-649bc62c749a", "_uuid": "c530ee9e0d76bb2ac96508bfb8596b04381c8871"}, "execution_count": null, "cell_type": "code"}, {"source": ["from sklearn.metrics import cohen_kappa_score\n", "print(\"It is said that cohen kappa can give some insign on imbalanced data.\")\n", "print(\"Training data cohen kappa score:\", cohen_kappa_score(y_train, y_train_pred))\n", "print(\"Testing data cohen kappa score:\", cohen_kappa_score(y_test, y_test_pred))\n", "print(\"Resampled training data cohen kappa score:\", cohen_kappa_score(y_res_train, y_res_train_pred))\n", "print(\"Resampled testing data cohen kappa score:\", cohen_kappa_score(y_res_test, y_res_test_pred))"], "outputs": [], "metadata": {"_cell_guid": "e1d530b3-7166-447b-8ccb-47e5604a8d44", "_uuid": "cdf96da86bd2bdbed995a8c6f30c781189d5d95b"}, "execution_count": null, "cell_type": "code"}, {"source": [], "outputs": [], "metadata": {"_cell_guid": "56669596-cdbf-4ca5-b17d-2f2a40749fa2", "collapsed": true, "_uuid": "b6fdb4039445e0e9078082da80467278889e4f9c"}, "execution_count": null, "cell_type": "code"}], "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "file_extension": ".py", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3"}}}