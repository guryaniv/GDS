{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "metadata": {
        "_cell_guid": "16ec4d41-e5c0-e56e-3bd6-3fcd880589d6",
        "_active": false,
        "collapsed": false
      },
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "cell_type": "code",
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "7ac70167-ac42-8874-e501-4dfabb35d85c",
        "_active": false,
        "collapsed": false
      },
      "source": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\n\ndef warn(*args, **kwargs): pass\nimport warnings\nwarnings.warn = warn\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cross_validation import StratifiedShuffleSplit\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ndef encode(train, test):\n\tle = LabelEncoder().fit(train.species) \n\tlabels = le.transform(train.species)           # encode species strings\n\tclasses = list(le.classes_)                    # save column names for submission\n\ttest_ids = test.id                             # save test ids for submission\n    \n\ttrain = train.drop(['species', 'id'], axis=1)  \n\ttest = test.drop(['id'], axis=1)\n    \n\treturn train, labels, test, test_ids, classes\n\ntrain, labels, test, test_ids, classes = encode(train, test)\n\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n\nn_folds = 5\n\nskf = list(StratifiedKFold(labels, n_folds))\n\n\nclfs = [\n    RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n    RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n    ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n    ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n    GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=50),\n]\n\ndataset_blend_train = np.zeros((train.shape[0], len(clfs)))\ndataset_blend_test = np.zeros((test.shape[0], len(clfs)))\n\nprint(np.shape(train))\nfor j, clf in enumerate(clfs):\n    dataset_blend_test_j = np.zeros((test.shape[0], len(skf)))\n   \n    for i, (idx_train, idx_test) in enumerate(skf):\n        X_train = train.loc[idx_train]\n        y_train = labels[idx_train]\n        X_test = train.loc[idx_test]\n        y_test = labels[idx_test]\n        clf.fit(X_train, y_train)\n       \n        y_submission=clf.predict_proba(X_test)\n        \n        dataset_blend_train[idx_test, j] = y_submission[:,1]\n        dataset_blend_test_j[:,i]=clf.predict_proba(test)[:,1]\n    dataset_blend_test[:,j] = dataset_blend_test_j.mean(1)\n    \n",
      "execution_count": 3,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "busy"
    },
    {
      "metadata": {
        "_cell_guid": "49b9cd57-fc09-315e-a03f-b274f2d69deb",
        "_active": true,
        "collapsed": false
      },
      "source": "import xgboost as xgb\nclf = xgb.XGBClassifier(n_estimators=500\nclf.fit(dataset_blend_train, labels)\npredictions = clf.predict_proba(dataset_blend_test)\n\nsub = pd.DataFrame(predictions, columns=classes)\nsub.insert(0, 'id', test_ids)\nsub.reset_index()\nsub.to_csv('submit.csv', index = False)\nsub.head()",
      "execution_count": null,
      "cell_type": "code",
      "outputs": []
    }
  ]
}