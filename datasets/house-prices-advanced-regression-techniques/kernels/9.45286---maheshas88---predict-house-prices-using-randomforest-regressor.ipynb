{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#set random seed for the whole session\nrandom.seed(123)\n\n#import the train dataset\nhouse_train=pd.read_csv(\"../input/train.csv\")\nhouse_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#test data\nhouse_test = pd.read_csv(\"../input/test.csv\")\nhouse_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b447221bcaafefadfb4d740aface169ec64c059b"},"cell_type":"code","source":"#the dataset contains several numeric features as well as categorical.\nhouse_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5677e6acb68658143fe17369049e94d33fd9667"},"cell_type":"code","source":"house_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f174e0577aa16392e663f5d72acf5b8973da8ddc"},"cell_type":"code","source":"nums = house_train.select_dtypes(include=['float64','int64']).columns\nprint(nums)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0242c6048199013e9bb73951eb71b857a03202a4"},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(x = house_train['LotFrontage'], y = house_train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=11)\nplt.xlabel('LotFrontage', fontsize=11)\nplt.show()\n\nhouse_train = house_train.drop(house_train[(house_train['LotFrontage']>300) & (house_train['SalePrice']<300000)].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fecfd8b42e51c4a652873c94960f093961a88000"},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(x = house_train['LotArea'], y = house_train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=11)\nplt.xlabel('LotArea', fontsize=11)\nplt.show()\nhouse_train = house_train.drop(house_train[(house_train['LotArea']>200000) & \n                                           (house_train['SalePrice']<=400000)].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d81ec2f7969d3e503e6b59bfe89474242acf061"},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(x = house_train['GrLivArea'], y = house_train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=11)\nplt.xlabel('GrLivArea', fontsize=11)\nplt.show()\nhouse_train = house_train.drop(house_train[(house_train['GrLivArea']>4000) & \n                                           (house_train['SalePrice']<=200000)].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e5ade2f386fe4bd3e417a3b1ccb4cc9d851cced"},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(x = house_train['OverallQual'], y = house_train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=11)\nplt.xlabel('OverallQual', fontsize=11)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59c91924544eb32a8d38e44185d2ecd4d095e990"},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(x = house_train['GarageArea'], y = house_train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=11)\nplt.xlabel('GarageArea', fontsize=11)\nplt.show()\nhouse_train = house_train.drop(house_train[(house_train['GarageArea']>1300) & \n                                           (house_train['SalePrice']<=200000)].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"047effd5ed4f4e3c7e520316650b8a3b7ede0913"},"cell_type":"code","source":"#take dependent variable in aseprate list and drop it from train dataframe\ntrain_y = house_train['SalePrice']\nhouse_train.drop(columns='SalePrice', inplace=True)\n\n#concatenate train and test data to perform common operations on both\nentire_data = pd.concat([house_train, house_test])\n\n##column Id is not needed\nentire_data.drop(columns='Id')\nprint(entire_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9518be368aeb28050e18e76b509e98a2655880eb"},"cell_type":"code","source":"#list the null values and their count in each col\nnull_cols = entire_data.columns[entire_data.isnull().any()]\nentire_data[null_cols].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ed730db1e0dfb3255a960882b7f2c0c7624a007"},"cell_type":"code","source":"#take the columns that are of type object and replace null values with \"Negative\". \"Negative\"\n#could mean missing or not available according to each column. We cant afford to drop rows with\n#null vals as the training dataset is not too much already.\nobjects = entire_data.select_dtypes(include=['object']).columns\nfor col in objects:\n    entire_data[col] = entire_data[col].fillna(\"Negative\")\n\n#replace numerical cols missing vals with the mean of the column\nnums = entire_data.select_dtypes(include=['float64','int64']).columns\nfor col in nums:\n    entire_data[col] = entire_data[col].fillna(entire_data[col].mean()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c50c516b132ec13733f5c25d392535092adb74b"},"cell_type":"code","source":"null_cols = entire_data.columns[entire_data.isnull().any()]\nentire_data[null_cols].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4575b7c18e24ecdc91b13863405158bfb933758"},"cell_type":"code","source":"entire_data = pd.get_dummies(entire_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14d1b4f5faf5661fd0e45c0422f3c1818ee81ea3"},"cell_type":"code","source":"#the dependent variable saleprice is right skewed with a peak. It makes sense to unskew it. \n#Log transfroming the column values gives it a more normal distribution. Other transformations like \n#BoxCox can also be used here.\n\n#Below graph shows the actual skew before tansformation of saleprice\nsns.distplot(train_y, color=\"c\", kde=False)\nplt.title(\"Skewness of Sale Price\")\nplt.ylabel(\"Total Number\")\nplt.xlabel(\"Sale Price\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3dc07b2b84571f9d79927af31f13af7b68faa99f"},"cell_type":"code","source":"#logtransofrm \ntrain_y = np.log1p(train_y)\n\n#skewness after transformation for saleprice\nsns.distplot(train_y, color=\"c\", kde=False)\nplt.title(\"Skewness of Sale Price\")\nplt.ylabel(\"Total Number\")\nplt.xlabel(\"Sale Price\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9949d95d007dbd787dfdbc8a187288fe838aad7e"},"cell_type":"code","source":"from scipy.stats import skew\n\n#in the dataset several features are skewed. This not augur well for a model to predict the right values.\n#Here the features which are numeric alone are taken and its skew measured. If skew is more than a threshold\n#it is logtransformed. \n\nnumerics = entire_data.dtypes[entire_data.dtypes != \"object\"].index\nskewed_feats = entire_data[numerics].apply(lambda x: skew(x.dropna()))\nskewed_feats = skewed_feats[skewed_feats > 0.70]\nskewed_feats = skewed_feats.index\nentire_data[skewed_feats] = np.log1p(entire_data[skewed_feats])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba8f33cd654088d054cd3b28ac7db65659130a1b"},"cell_type":"code","source":"#train test split\ntrain_x = entire_data[:house_train.shape[0]]\ntest_x = entire_data[house_train.shape[0]:]\nprint(len(train_x))\nprint(len(test_x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3c4a6ab01a58b727abba7e6c713451e9429927e"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n#Model\nmodel = RandomForestRegressor(random_state=123, n_estimators=300, verbose=1, \n                              n_jobs=-1, oob_score=True)\n\nparam_grid = {\n    'bootstrap': [True],\n    'max_features': ['auto','sqrt','log2'],\n    'n_estimators': [300,400,500,600,700],\n    'random_state': [0,1,42,123]\n}\n\ngrid_search = GridSearchCV(estimator = model, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)\ngrid_search.fit(train_x, train_y)\n\nbest_rf = grid_search.best_estimator_\nbest_rf.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c34f4d6a39fdee31017c152d51f0be4d01603241"},"cell_type":"code","source":"#predict using the model\ny_pred = best_rf.predict(test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc29e5061be77582ad188213b2f52c3cebb3781a"},"cell_type":"code","source":"#submission\nsub_file = pd.read_csv('../input/sample_submission.csv',sep=',')\nsub_file.SalePrice=y_pred\nsub_file.to_csv('Submission1.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}