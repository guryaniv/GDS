{"cells": [{"metadata": {"collapsed": true, "_cell_guid": "f16ac0de-de1c-4b65-a85e-a3227fbe0c47", "_uuid": "47787be314e3cc68e7071ae827aef9710fc8341a"}, "source": ["MAKE_SUBMISSION = True          # Generate output file.\n", "CV_ONLY = False                 # Do validation only; do not generate predicitons.\n", "LEARNING_RATE = 0.007            # shrinkage rate for boosting rounds\n", "ROUNDS_PER_ETA = 20             # maximum number of boosting rounds times learning rate\n", "OPTIMIZE_FUDGE_FACTOR = True    # Optimize factor by which to multiply predictions.\n", "                                # (Interesting that this wants a fudge factor < 1,\n", "                                #  whereas the Q4 2016 validation wanted > 1.\n", "                                #  Suggests that the 4th quarter is the issue.)\n", "FUDGE_FACTOR_SCALEDOWN = 0.1    # exponent to reduce optimized fudge factor for prediction\n", "                                # (Close to 0 since I don't think the concept makes sense here)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_execution_state": "idle", "collapsed": true, "_cell_guid": "1c1a4c8e-9379-47b8-aa2e-3df8e5d22918", "_uuid": "a6d445499b3664bf165ab992f309a417471707f4"}, "source": ["import numpy as np\n", "import pandas as pd\n", "import xgboost as xgb\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.metrics import mean_absolute_error\n", "import datetime as dt\n", "from datetime import datetime\n", "import gc\n", "import patsy\n", "import statsmodels.api as sm\n", "import statsmodels.formula.api as smf\n", "from statsmodels.regression.quantile_regression import QuantReg"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_execution_state": "idle", "collapsed": true, "_cell_guid": "a6cc2bdd-9d38-4f66-8903-3ce019f7109a", "_uuid": "43ea1cf09b04ca53bb99c95d428b4624572ba75a"}, "source": ["properties = pd.read_csv('../input/properties_2016.csv')\n", "prop2017 = pd.read_csv('../input/properties_2017.csv')\n", "\n", "# Number of properties in the zip\n", "zip_count = properties['regionidzip'].value_counts().to_dict()\n", "# Number of properties in the city\n", "city_count = properties['regionidcity'].value_counts().to_dict()\n", "# Median year of construction by neighborhood\n", "medyear = properties.groupby('regionidneighborhood')['yearbuilt'].aggregate('median').to_dict()\n", "# Mean square feet by neighborhood\n", "meanarea = properties.groupby('regionidneighborhood')['calculatedfinishedsquarefeet'].aggregate('mean').to_dict()\n", "# Neighborhood latitude and longitude\n", "medlat = properties.groupby('regionidneighborhood')['latitude'].aggregate('median').to_dict()\n", "medlong = properties.groupby('regionidneighborhood')['longitude'].aggregate('median').to_dict()\n", "\n", "train = pd.read_csv(\"../input/train_2016_v2.csv\")\n", "for c in properties.columns:\n", "    properties[c]=properties[c].fillna(-1)\n", "    if properties[c].dtype == 'object':\n", "        lbl = LabelEncoder()\n", "        lbl.fit(list(properties[c].values))\n", "        properties[c] = lbl.transform(list(properties[c].values))\n", "        \n", "train2017 = pd.read_csv('../input/train_2017.csv')\n", "for c in prop2017.columns:\n", "    prop2017[c]=prop2017[c].fillna(-1)\n", "    if prop2017[c].dtype == 'object':\n", "        lbl = LabelEncoder()\n", "        lbl.fit(list(prop2017[c].values))\n", "        prop2017[c] = lbl.transform(list(prop2017[c].values))\n", "        "], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "b5752c23-b3d7-4403-ab0b-2813d88e14f5", "_uuid": "dfe82baffa246f7ebe77d472de49ee6a6d43a419"}, "source": ["train_df = train.merge(properties, how='left', on='parcelid')\n", "train2017_df = train2017.merge(prop2017, how='left', on='parcelid')"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "101437b6-c54e-4452-9c81-a824818d651a", "_uuid": "95c7a84848e30fa37a75d319b9e7e04deaff9ef9"}, "source": ["del train\n", "del train2017\n", "gc.collect()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "d9460c6d-bf39-4bfb-a584-f3aafcabc8fa", "_uuid": "9722eb834d3cf02e943b8c85bf99e7a7515173e4"}, "source": ["# Inputs to features that depend on target variable\n", "# (Ideally these should be recalculated, and the dependent features recalculated,\n", "#  when fitting to the full training set.  But I haven't implemented that yet.)\n", "\n", "# Standard deviation of target value for properties in the city/zip/neighborhood\n", "citystd = train_df.groupby('regionidcity')['logerror'].aggregate(\"std\").to_dict()\n", "zipstd = train_df.groupby('regionidzip')['logerror'].aggregate(\"std\").to_dict()\n", "hoodstd = train_df.groupby('regionidneighborhood')['logerror'].aggregate(\"std\").to_dict()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "058d3299-005e-4458-a8cd-cd3c4d854190", "_uuid": "4b9916ad9eb1d2a0b1aab78e71191c34a78a9b77"}, "source": ["def calculate_features(df):\n", "    # Nikunj's features\n", "    # Number of properties in the zip\n", "    df['N-zip_count'] = df['regionidzip'].map(zip_count)\n", "    # Number of properties in the city\n", "    df['N-city_count'] = df['regionidcity'].map(city_count)\n", "    # Does property have a garage, pool or hot tub and AC?\n", "    df['N-GarPoolAC'] = ((df['garagecarcnt']>0) & \\\n", "                         (df['pooltypeid10']>0) & \\\n", "                         (df['airconditioningtypeid']!=5))*1 \n", "\n", "    # More features\n", "    # Mean square feet of neighborhood properties\n", "    df['mean_area'] = df['regionidneighborhood'].map(meanarea)\n", "    # Median year of construction of neighborhood properties\n", "    df['med_year'] = df['regionidneighborhood'].map(medyear)\n", "    # Neighborhood latitude and longitude\n", "    df['med_lat'] = df['regionidneighborhood'].map(medlat)\n", "    df['med_long'] = df['regionidneighborhood'].map(medlong)\n", "\n", "    df['zip_std'] = df['regionidzip'].map(zipstd)\n", "    df['city_std'] = df['regionidcity'].map(citystd)\n", "    df['hood_std'] = df['regionidneighborhood'].map(hoodstd)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "e389a360-b1dc-4257-b3c3-fea69026863d", "_uuid": "d816890fe0edcab13c415144e76ecd12938ab17e"}, "source": ["dropvars = ['parcelid', 'airconditioningtypeid', 'buildingclasstypeid',\n", "            'buildingqualitytypeid', 'regionidcity']\n", "droptrain = ['logerror', 'transactiondate']"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "720a950e-5392-4571-8fd6-e849a9c6967e", "_uuid": "233443f9b4c2af79e91d235fdc4f660ff1d630bc"}, "source": ["calculate_features(train_df)\n", "calculate_features(train2017_df)\n", "\n", "print('Shape train_df: {}\\n'.format(train_df.shape))\n", "print('Shape train2017_df: {}\\n'.format(train2017_df.shape))\n", "\n", "x_valid = train2017_df.drop(dropvars+droptrain, axis=1)\n", "y_valid = train2017_df[\"logerror\"].values.astype(np.float32)\n", "\n", "print('Shape x_valid: {}\\n'.format(x_valid.shape))\n", "print('Shape y_valid: {}\\n'.format(y_valid.shape))\n", "\n", "train_df=train_df[ train_df.logerror > -0.4 ]\n", "train_df=train_df[ train_df.logerror < 0.419 ]\n", "\n", "x_train=train_df.drop(dropvars+droptrain, axis=1)\n", "y_train = train_df[\"logerror\"].values.astype(np.float32)\n", "\n", "print('Shape x_train: {}\\n'.format(x_train.shape))\n", "print('Shape y_train: {}\\n'.format(y_train.shape))\n", "\n", "y_mean = np.mean(y_train)\n", "n_train = x_train.shape[0]"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_execution_state": "idle", "collapsed": true, "_cell_guid": "d0c5819c-0873-4b49-a8a7-5295632ccbb9", "_uuid": "f3a9ea8db9161705b9e0d61a82736b44c7dfcb01"}, "source": ["if not CV_ONLY:\n", "    test_df = prop2017\n", "    calculate_features(test_df)\n", "    x_test = test_df.drop(dropvars, axis=1)\n", "    print('Shape test: {}'.format(x_test.shape))\n", "    del test_df"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_execution_state": "idle", "collapsed": true, "_cell_guid": "03fb6b2f-5166-4646-8445-304765a404ad", "_uuid": "c6d653da30197972f12f1a7a0ea4d0a36f28c554"}, "source": ["del train_df\n", "gc.collect()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_execution_state": "idle", "collapsed": true, "_cell_guid": "de59798a-1b8a-4d0e-a92c-846577f4406b", "_uuid": "c8c1043d72790dc926ae76f398487e8313caeed1"}, "source": ["xgb_params = {  # best as of 2017-09-28 13:20 UTC\n", "    'eta': LEARNING_RATE,\n", "    'max_depth': 7, \n", "    'subsample': 0.6,\n", "    'objective': 'reg:linear',\n", "    'eval_metric': 'mae',\n", "    'lambda': 5.0,\n", "    'alpha': 0.65,\n", "    'colsample_bytree': 0.5,\n", "    'base_score': y_mean,'taxdelinquencyyear'\n", "    'silent': 1\n", "}\n", "\n", "dtrain = xgb.DMatrix(x_train, y_train)\n", "dvalid_x = xgb.DMatrix(x_valid)\n", "dvalid_xy = xgb.DMatrix(x_valid, y_valid)\n", "if not CV_ONLY:\n", "    dtest = xgb.DMatrix(x_test)\n", "    del x_test"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_execution_state": "idle", "collapsed": true, "_cell_guid": "45e61d05-da7f-4841-811a-3a95c86a3306", "_uuid": "dd0776733ec3d3ac960b9ab9ac6e518a99e012d9"}, "source": ["del x_train\n", "gc.collect()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"scrolled": true, "collapsed": true, "_cell_guid": "de8e97e6-d681-465b-a68a-6178e7593e49", "_uuid": "fe6761fd44aaf7a5c063897c9ca3b90b957b7108"}, "source": ["num_boost_rounds = round( ROUNDS_PER_ETA / xgb_params['eta'] )\n", "early_stopping_rounds = round( num_boost_rounds / 20 )\n", "print('Boosting rounds: {}'.format(num_boost_rounds))\n", "print('Early stoping rounds: {}'.format(early_stopping_rounds))"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_execution_state": "idle", "collapsed": true, "_cell_guid": "95d8ac93-f2ff-4ce3-9cb6-8044d73f8600", "_uuid": "09c99f75bcfb64225f390eee5e5dbf4f47f4103b"}, "source": ["evals = [(dtrain,'train'),(dvalid_xy,'eval')]\n", "model = xgb.train(xgb_params, dtrain, num_boost_round=num_boost_rounds,\n", "                  evals=evals, early_stopping_rounds=early_stopping_rounds, \n", "                  verbose_eval=10)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_execution_state": "idle", "collapsed": true, "_cell_guid": "c241b1e2-d2c6-4936-a6ee-282a4e90ca27", "_uuid": "02a37067bd8ba72b050d6634e9994b234bdf6389"}, "source": ["valid_pred = model.predict(dvalid_x, ntree_limit=model.best_ntree_limit)\n", "print( \"XGBoost validation set predictions:\" )\n", "print( pd.DataFrame(valid_pred).head() )\n", "print(\"\\nMean absolute validation error:\")\n", "mean_absolute_error(y_valid, valid_pred)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "7dd798fb-9160-4a48-9b52-9bc16f582e0f", "_uuid": "dbd7ae96da81ab900d6eee1c186b2b56f17e4fc8"}, "source": ["if OPTIMIZE_FUDGE_FACTOR:\n", "    mod = QuantReg(y_valid, valid_pred)\n", "    res = mod.fit(q=.5)\n", "    print(\"\\nLAD Fit for Fudge Factor:\")\n", "    print(res.summary())\n", "\n", "    fudge = res.params[0]\n", "    print(\"Optimized fudge factor:\", fudge)\n", "    print(\"\\nMean absolute validation error with optimized fudge factor: \")\n", "    print(mean_absolute_error(y_valid, fudge*valid_pred))\n", "\n", "    fudge **= FUDGE_FACTOR_SCALEDOWN\n", "    print(\"Scaled down fudge factor:\", fudge)\n", "    print(\"\\nMean absolute validation error with scaled down fudge factor: \")\n", "    print(mean_absolute_error(y_valid, fudge*valid_pred))\n", "else:\n", "    fudge=1.0"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_execution_state": "idle", "collapsed": true, "_cell_guid": "c8f7bb43-015e-4c2c-a1bd-afa92219bd87", "_uuid": "a710f272857376365c6a02929197a06be72ae28b"}, "source": ["if not CV_ONLY:\n", "    pred = fudge*model.predict(dtest, ntree_limit=model.best_ntree_limit)\n", "        \n", "    print( \"XGBoost test set predictions:\" )\n", "    print( pd.DataFrame(pred).head() )"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_execution_state": "idle", "collapsed": true, "_cell_guid": "8d793a38-6df2-45e7-a725-cc2161ed3cee", "_uuid": "b85616fbde70ef9d6fe220ef12947fb5d2dd3df6"}, "source": ["if MAKE_SUBMISSION and not CV_ONLY:\n", "   y_pred=[]\n", "\n", "   for i,predict in enumerate(pred):\n", "       y_pred.append(str(round(predict,4)))\n", "   y_pred=np.array(y_pred)\n", "\n", "   output = pd.DataFrame({'ParcelId': properties['parcelid'].astype(np.int32),\n", "           '201610': y_pred, '201611': y_pred, '201612': y_pred,\n", "           '201710': y_pred, '201711': y_pred, '201712': y_pred})\n", "   # set col 'ParceID' to first col\n", "   cols = output.columns.tolist()\n", "   cols = cols[-1:] + cols[:-1]\n", "   output = output[cols]\n", "\n", "   output.to_csv('sub{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "50d1d19d-26e8-4227-aa77-7d452d6c7d36", "_uuid": "c5ab53465012b552d5b08be82864f972d02946e4"}, "source": ["print(\"Mean absolute validation error without fudge factor: \", )\n", "print( mean_absolute_error(y_valid, valid_pred) )\n", "if OPTIMIZE_FUDGE_FACTOR:\n", "    print(\"Mean absolute validation error with fudge factor:\")\n", "    print( mean_absolute_error(y_valid, fudge*valid_pred) )"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "b66c3b07-5941-44ab-b2f2-58fc46071055", "_uuid": "b26353143ba91c98ba970f5051bc9656b39c9bb4"}, "source": [], "execution_count": null, "cell_type": "code", "outputs": []}], "nbformat": 4, "metadata": {"language_info": {"pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.1"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat_minor": 1}