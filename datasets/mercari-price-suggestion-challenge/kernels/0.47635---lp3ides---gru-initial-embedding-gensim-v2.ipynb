{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_kg_hide-output":false,"trusted":false,"collapsed":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\n%matplotlib inline\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nimport numpy as np \nimport pandas as pd \nimport os, re, pickle, collections\nimport tensorflow as tf\nimport random, math\nfrom gensim.models import Word2Vec\nfrom time import time","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a700d4a9543a63b2e86443e61a1aee97470ba08","collapsed":true,"_cell_guid":"2fe15d7e-1991-41b8-8bd3-0313075639e6","trusted":false},"cell_type":"code","source":"# some functions to do cleaning of text fields, and splitting out general category from sub categories\ndef prepare_data(df):\n    def _clean(text):\n        return re.sub(r'[^\\w\\s]','',text)\n    def _lower(text):\n        return text.lower()\n    for column in ['name', 'brand_name', 'item_description', 'item_condition_id']:\n        df[column] = df[column].astype(str).apply(_clean).apply(_lower)\n    df['category_name'] = df['category_name'].astype(str).apply(_lower)\n    # general categories\n    def _split_cat(text): \n        cats = text.split(\"/\")\n        if len(cats) >=3:\n            return cats[0:3]\n        else: return (\"No Label\", \"No Label\", \"No Label\") \n    df['general_cat'], df['subcat_1'], df['subcat_2'] = zip(*df['category_name'].apply(lambda x: _split_cat(x)))\n    # generate the length of item descripiton\n    def _length(text):\n        tokens = re.sub(r'[^\\w\\s]','',text).lower()\n        return len(tokens.split())\n    df['desc_len'] = df['item_description'].apply(_length)\n    # string together the remaining text fields, also get the length\n    def _concat_(df):\n        text = \"\"\n        for col in ['name', 'general_cat', 'subcat_1', 'subcat_2', 'brand_name', 'item_condition_id']:\n            text = text + (df[col]) + \" \"\n        return text\n    df['other_info'] = df.loc[:, ['name', 'general_cat', 'subcat_1', 'subcat_2', 'brand_name', 'item_condition_id']].apply(_concat_, axis=1)\n    df['other_info_len'] = df['other_info'].apply(_length)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7947db880667f5154e0c10ebeb95f769ce9c6096","_cell_guid":"91362c47-565d-4029-8c27-b79670bd7ddb"},"cell_type":"markdown","source":"Read in data and do some cleaning"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false,"collapsed":true},"cell_type":"code","source":"# df = pd.read_csv(\"../input/train.tsv\", sep='\\t', nrows=1000)\ndf = pd.read_csv(\"../input/train.tsv\", sep='\\t')\ndf.head()\ndf = prepare_data(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9797ce96b3e75350f808c6b7898287aa95632fa6","_cell_guid":"5576193e-a8f1-41b0-b2ad-afce63a37ea3"},"cell_type":"markdown","source":"Build the corpus; the skip-gram model will be applied to this corpus via gensim implementation"},{"metadata":{"_uuid":"c0dbcf630ac6db8f594a2b4f8c650cd6f9a27bc1","collapsed":true,"_cell_guid":"f10589b0-cd27-46dd-b810-080b38b0f54f","trusted":false},"cell_type":"code","source":"corpus = []\nfor row in range(len(df)):\n    for column in ['other_info', 'item_description']:\n        tokens = (df.loc[row, column].split())\n        corpus.append(tokens)\n# get word2vec embeddings using gensim\nembedding_size = 50\nvocab_size = 50000\nw2v_model = Word2Vec(corpus, size=embedding_size, min_count=0, max_vocab_size=vocab_size, workers=8, negative=5, sg=1, iter=1, \n                 batch_words=10000, sorted_vocab=1)\n\nwords = list(w2v_model.wv.vocab)\ndictionary = {}\nword_embeddings = np.zeros((len(words), embedding_size), dtype=float)\nrow = 0\nfor word in words:\n    dictionary[word] = len(dictionary)\n    word_embeddings[row, :] = w2v_model.wv.get_vector(word)\n    row += 1\nreverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\npickle.dump(word_embeddings, open(\"word_embeddings.p\", \"wb\"))\ndel w2v_model, words, corpus","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81de2d34c93e0d7569cadc525c4bcaf37ce39b71","collapsed":true,"_cell_guid":"a08712c8-bada-4d15-a4b3-851279bb0b97","trusted":false},"cell_type":"code","source":"word_embeddings = word_embeddings.astype(\"float32\") # to get dtype to conform with tensorflow graph later on","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f00ae13e82510c6735403077332000cebaa7d31e","_cell_guid":"a74f852b-8e7e-4fe4-a75c-3672645bbe77","collapsed":true},"cell_type":"markdown","source":"Prepare data for RNN-GRU model\n\nConvert strings in data to integer indices according to the dictionary mapping\n\nOnly need to keep: log price, item_description, item_desc_len, and other_info, and other_info_len\n\nModel is to extract information from item_description, as well as other information such as name, brand, category, and item condition, to predict prices. Two RNNs are used, one for item_description, and one for other information"},{"metadata":{"_uuid":"4eea0d6ed91ff1eb4988226f4067b299f728563f","_cell_guid":"1fc857d9-a3a3-4f7c-94b1-65c655e93a51","trusted":false,"collapsed":true},"cell_type":"code","source":"max_D, max_O = 75, 20\ndef to_array(df):\n    def _to_array(df, column, max_length):\n        # convert a sequence of words as a string to a list of corresponding dictionary indices\n        # output is a list of length max_length\n        indices = np.zeros((len(df), max_length))\n        length = np.zeros((len(df),1))\n        for row in range(len(df)):\n            tokens = df.loc[row, column].split()\n            i = 0\n            for token in tokens:\n                if token in dictionary: \n                    indices[row, i] = dictionary[token]\n                    i += 1\n                if i == max_length: break\n            length[row] = i\n        return indices, length\n    desc_ind, desc_len = _to_array(df, 'item_description', max_D)\n    other_ind, other_len = _to_array(df, 'other_info', max_O)\n    data = np.hstack((desc_ind, other_ind, desc_len, other_len))\n    if 'price' in df.columns: \n        log_price = np.log(df['price']+1).values.reshape((len(df),1)).astype('float32')\n        data = np.hstack((data, log_price))\n    return data\n\ndata = to_array(df)\ndel df\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a1d495f420c2565386bc69f34c843a076947716","_cell_guid":"2c454efd-14ce-4d0a-93d5-d490c7b409b1","trusted":false,"collapsed":true},"cell_type":"code","source":"def train_valid_split(array):\n    train_id_1 = np.arange(len(array)//3) * 3\n    train_id_2 = np.arange(len(array)//3) * 3 + 1\n    valid_id = np.arange(len(array)//3) * 3 + 2\n    train_id = np.hstack((train_id_1, train_id_2))\n    train = array[train_id, :]\n    valid = array[valid_id, :]\n    return train, valid\ntrain, valid = train_valid_split(data)\ntrain.shape, valid.shape\ndel data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d65479e6f215c29f07f8eb8470fe4bc6bb7246b4","collapsed":true,"_cell_guid":"1827831f-4207-4813-9a90-8d9b97a10193","trusted":false},"cell_type":"code","source":"# helper function to get a batch of data for training\ndef get_batch(array, start, size):\n    if start + size > len(array):\n        end = len(array)\n    else: end = start + size\n    batch = array[start:end, :]\n    if end == len(array): start = 0\n    else: start = start + size\n    return batch, start","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a03c15056ce38c077b94a31793bf332172a87e4","collapsed":true,"_cell_guid":"f817a1fa-5fd8-4adb-9cfc-8e0fe24d80a7","trusted":false},"cell_type":"code","source":"word_dim = 50\nassert word_dim == embedding_size\nnum_hidden = 50 # dimensionality of the hidden state of the RNN cell (LSTM in this case)\nlearning_rate = 0.001 # consider experimenting with the learning rate","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e5acbb7281a57521d534c353227a06eba7b7680","_cell_guid":"c58a2a8f-e766-43a8-8d6c-b2f563fe8f75","trusted":false,"collapsed":true},"cell_type":"code","source":"tf.reset_default_graph()\ngraph = tf.Graph()\nwith graph.as_default():\n    with tf.device('/gpu:0'):\n        desc_indices = tf.placeholder(tf.int32, shape=[None, max_D])\n        info_indices = tf.placeholder(tf.int32, shape=[None, max_O])\n        desc_seq_length = tf.placeholder(tf.int8, [None,])\n        info_seq_length = tf.placeholder(tf.int8, [None,])\n        log_price = tf.placeholder(tf.float32, [None,1])\n        embeddings = tf.Variable(word_embeddings)\n\n        x_desc = tf.nn.embedding_lookup(embeddings, desc_indices) # this is of shape batch_size, max_T, word_dim\n        x_desc = tf.unstack(x_desc, max_D, 1) \n        x_info = tf.nn.embedding_lookup(embeddings, info_indices) # this is of shape batch_size, max_I, word_dim\n        x_info = tf.unstack(x_info, max_O, 1) \n\n        gru_cell = tf.nn.rnn_cell.GRUCell(num_hidden)\n        outputs_desc, state_desc = tf.nn.static_rnn(gru_cell, x_desc, sequence_length=desc_seq_length, dtype=tf.float32)\n        outputs_info, state_info = tf.nn.static_rnn(gru_cell, x_info, sequence_length=info_seq_length, dtype=tf.float32)\n\n        weights_desc = tf.Variable(tf.random_normal([num_hidden,1]))\n        weights_info = tf.Variable(tf.random_normal([num_hidden,1]))\n        biases = tf.Variable(tf.random_normal([1,1]))\n\n        pred = tf.matmul(state_desc, weights_desc) + tf.matmul(state_info, weights_info) + biases\n        error = log_price - pred\n        loss = tf.sqrt(tf.reduce_mean(tf.square(error))) # root mean square log error\n        train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n        \n        init = tf.global_variables_initializer()\n    saver = tf.train.Saver()\nprint(\"flow graph constructed\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0a22e11c1da25f3f66d0f3c5625e64879b0ce75","collapsed":true,"_cell_guid":"87aaf9c5-5506-4b72-a0c5-2c7a92106977","trusted":false},"cell_type":"code","source":"def get_feed_dict(batch):\n    if batch.shape[1] == 98:\n        feed_dict={ desc_indices: batch[:, 0:75],\n                    info_indices: batch[:, 75:95],\n                    desc_seq_length: batch[:, 95],\n                    info_seq_length: batch[:, 96],\n                    log_price: batch[:, 97:98]}\n    else:\n        feed_dict={ desc_indices: batch[:, 0:75],\n                    info_indices: batch[:, 75:95],\n                    desc_seq_length: batch[:, 95],\n                    info_seq_length: batch[:, 96],\n                    }\n    return feed_dict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89c18d97572986810fd6bbb65b83c339f7a5ba99","collapsed":true,"_cell_guid":"4287609b-bdef-484f-8797-89fb7de4683e","trusted":false},"cell_type":"code","source":"def predict(session, data, batch_size):\n    start = 0\n    for step in range(len(data)//batch_size + 1):\n        batch, start = get_batch(data, start, batch_size)\n        pred_ = sess.run(pred, feed_dict=get_feed_dict(batch))\n        if step == 0:\n            pred_all = np.array(pred_)\n        else:\n            pred_all = np.vstack((pred_all, pred_))\n    assert len(pred_all) == len(data)\n    return pred_all","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"807508bfe9c7c0bd9e8579964b99827f39f75404","_cell_guid":"e5838a75-07c3-427d-a415-4d720eb9da8d","trusted":false,"collapsed":true},"cell_type":"code","source":"train_start, valid_start, time_initial = 0, 0, time()\nbatch_size, epochs = 500, 2\nno_batches = len(train)//batch_size + 1\navg_loss, time_0 = 0, time()\nwith tf.Session(config=tf.ConfigProto(allow_soft_placement=True), graph=graph) as sess:\n    init.run()\n    for epoch in range(epochs):\n        for step in range(no_batches):\n            if step % 1000 == 0: print(step)\n            batch, train_start = get_batch(train, train_start, batch_size)\n            _, loss_step = sess.run([train_op, loss], feed_dict=get_feed_dict(batch))\n            avg_loss += loss_step\n        avg_loss /= no_batches\n        print(\"epoch: %2d, average loss: %.3f, time: %2.2f\" \n              %(epoch, avg_loss, time()-time_0))\n        avg_loss, time_0 = 0, time()\n        # calculate validation statistics\n        valid_pred = predict(sess, valid, batch_size)\n        valid_log_price = valid[:, 97:98]\n        valid_rsme = np.sqrt(np.mean((valid_pred - valid_log_price)**2))\n        print(\"validation rsme: %.4f\" %valid_rsme)\n        \n        save_path = saver.save(sess,\"./params.ckpt\")\n        print(\"saved parameters to: \", save_path)\n        \n    print(\"done training\")\n    print(\"total training time is: %4d\" %(time() - time_initial))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0be1161ad2a3577cbc8ba478e72c6ba0c954a1ed","_cell_guid":"cd3b704c-3d9e-4688-8d24-c6031c299f32","trusted":false,"collapsed":true},"cell_type":"code","source":"del train, valid\n# test = pd.read_csv(\"../input/test_stg2.tsv\", sep='\\t', nrows=12345)\ntest = pd.read_csv(\"../input/test_stg2.tsv\", sep='\\t')\ntest = prepare_data(test)\ntest = to_array(test)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6bb9c2f57a10687e2f17eb70338a821235d7fef4","_cell_guid":"4fda506d-9c34-48bf-9213-661631ca330d","trusted":false,"collapsed":true},"cell_type":"code","source":"with tf.Session(config=tf.ConfigProto(allow_soft_placement=True), graph=graph) as sess:\n    saver.restore(sess, \"./params.ckpt\")\n    test_pred = predict(sess, test, batch_size)\n    prices = np.exp(test_pred) - 1\n    assert len(test_pred) == len(test)\nout = pd.DataFrame(prices)\nout = out.reset_index().rename(columns={\"index\":\"test_id\", 0:\"price\"})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44bc3e7de4ff4c5a5b77eb04f19d6fb70ab2583d","_cell_guid":"0469408f-3b47-479f-a59b-0a22198d12b0","trusted":false,"collapsed":true},"cell_type":"code","source":"out.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"474816fccecf42179ae86f14ce2227457a89f66b","_cell_guid":"277318b1-4eb5-4d21-a027-467b042ca08a","trusted":false,"collapsed":true},"cell_type":"code","source":"out.to_csv(\"./out.csv\", index=False)\nprint(\"output saved to csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}