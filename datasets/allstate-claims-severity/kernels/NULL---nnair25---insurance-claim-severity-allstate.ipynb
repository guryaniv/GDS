{"metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "file_extension": ".py", "version": "3.6.4", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}}}, "cells": [{"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "#Header Files \n", "import numpy as np \n", "import pandas as pd \n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.preprocessing import OneHotEncoder\n", "from sklearn.model_selection import train_test_split\n", "\n", "from sklearn.linear_model import LinearRegression\n", "from sklearn.metrics import mean_absolute_error\n", "from xgboost import XGBRegressor\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_cell_guid": "b8b5e55d-89b7-42e0-8bd2-563470ce047d", "_uuid": "a6b75ecb8950e170488011de1d8f2c3f987295b2"}}, {"source": ["#Load Dataset\n", "DF= pd.read_csv(\"../input/train.csv\")\n", "DF_Test = pd.read_csv(\"../input/test.csv\")\n", "\n", "#To show all the columns and rows\n", "pd.set_option('display.max_rows',None)\n", "pd.set_option('display.max_columns', None)\n", "\n", "#Take a look at the dataset\n", "print(DF.head(5))\n", "\n", "#Storing the ID from test for future prediction\n", "ID= DF_Test['id']\n", "#Dropping ID because it is meaningless\n", "DF.drop('id',axis=1, inplace=True)\n", "DF_Test.drop('id',axis=1, inplace=True)\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": ["**Data Statistics**"], "cell_type": "markdown", "metadata": {}}, {"source": ["#For numerical/continous values\n", "print(\"Cont. Features\")\n", "print(\"-\"*75)\n", "print(DF.describe())\n", "\n", "#For categorical values\n", "print(\"Cat. Features\")\n", "print(\"-\"*75)\n", "print(DF.describe(include=['O']))"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": ["**Data Visualisation**"], "cell_type": "markdown", "metadata": {}}, {"source": ["#Taking only numerical values\n", "size=15\n", "split=116\n", "ContDF=DF.iloc[:,split:]\n", "\n", "#Name of all columns\n", "Col=ContDF.columns\n", "\n", "#Plotting violin plot for all columns\n", "n_rows=5\n", "n_columns=3\n", "\n", "for i in range(n_rows):\n", "    fg,ax = plt.subplots(nrows=1, ncols=n_columns,figsize=(12,8))\n", "    for j in range(n_columns):\n", "        sns.violinplot(y=Col[i*n_columns+j], data=ContDF,ax=ax[j])\n", "        "], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": ["**Observations:**\n", "\n", "cont1, cont3, cont6 has lot of values close to 0.5\n", "\n", "cont2 has several spikes at several values\n", "\n", "cont 4 has values spread evenly from 0.2-0.5\n", "\n", "cont 5 has lot of values close to 0.3  ..........Similarly you can read the plot and interpret\n", "\n", "What's really interesting is that 'loss' column(our target variable) is heavily skewed\n", "(Need to apply log function)"], "cell_type": "markdown", "metadata": {}}, {"source": ["DF['loss']=np.log1p(DF['loss'])\n", "#Let's visualise the new plot\n", "sns.violinplot(data=DF, y='loss')\n", "plt.show()\n", "\n", "#PLOT shows that skew has been corrected to a large extent"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": ["**Data Correlation**"], "cell_type": "markdown", "metadata": {}}, {"source": ["\n", "CorrMatrix= ContDF.corr().abs()\n", "\n", "#Heatmap\n", "plt.subplots(figsize=(13, 9))\n", "sns.heatmap(CorrMatrix,annot=True)\n", "sns.heatmap(CorrMatrix, mask=CorrMatrix < 1, cbar=False)\n", "plt.show()\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": ["**Observation:**\n", "\n", "All those pairs showing high correlation(>0.85), one of them can be removed{Cont11-Cont12, Cont1-Cont9, Cont6-Cont10}\n", "    "], "cell_type": "markdown", "metadata": {}}, {"source": ["**Conversion of Categorical Variables**"], "cell_type": "markdown", "metadata": {}}, {"source": ["labellist = []\n", "Col= DF.columns\n", "for i in range(0,split):\n", "    train = DF[Col[i]].unique()\n", "    test = DF[Col[i]].unique()\n", "    labellist.append(list(set(train) | set(test)))    \n", "\n", "\n", "\n", "#Hot encoding all categorical attributes\n", "categ = []\n", "for i in range(0, split):\n", "    #Label encode\n", "    label_encoder = LabelEncoder()\n", "    label_encoder.fit(labellist[i])\n", "    feature = label_encoder.transform(DF.iloc[:,i])\n", "    feature = feature.reshape(DF.shape[0], 1)\n", "    #One hot encode\n", "    onehot_encoder = OneHotEncoder(sparse=False,n_values=len(labellist[i]))\n", "    feature = onehot_encoder.fit_transform(feature)\n", "    categ.append(feature)\n", "\n", "# Make a nd.numpyarray\n", "encoded_categ = np.column_stack(categ)\n", "\n", "\n", "\n", "#Combine encoded attributes with continuous attributes\n", "DF_encoded = np.concatenate((encoded_categ,DF.iloc[:,split:].values),axis=1)\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": ["**Data Splitting**"], "cell_type": "markdown", "metadata": {}}, {"source": ["#number of rows and columns\n", "r, c = DF_encoded.shape\n", "\n", "#create an array which has indexes of columns\n", "i_cols = []\n", "for i in range(0,c-1):\n", "    i_cols.append(i)\n", "\n", "#y is the target variable, X is the remaining  data\n", "X = DF_encoded[:,0:(c-1)]\n", "y = DF_encoded[:,(c-1)]\n", "\n", "\n", "X_train, X_test, y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=7)"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": ["**Data Prediction and Evaulation**"], "cell_type": "markdown", "metadata": {}}, {"source": ["1. Linear Regression"], "cell_type": "markdown", "metadata": {}}, {"source": ["model = LinearRegression(n_jobs=-1)\n", "#Accuracy of the model \n", "model.fit(X_train,y_train)\n", "result = mean_absolute_error(np.expm1(Y_test), np.expm1(model.predict(X_test)))\n", "\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": ["Mean Absolute Error achieved is 1278"], "cell_type": "markdown", "metadata": {}}, {"source": ["model = XGBRegressor(n_estimators=1000,seed=7)\n", "#Accuracy of the model \n", "model.fit(X_train,y_train)\n", "result = mean_absolute_error(np.expm1(Y_test), np.expm1(model.predict(X_test)))\n", "            \n", "\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}, {"source": ["Mean Absolute Error achieved is 1170"], "cell_type": "markdown", "metadata": {}}], "nbformat_minor": 1, "nbformat": 4}