{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "05d3d868-9931-6586-b78a-6d105de06de8"
      },
      "outputs": [],
      "source": [
        "# %matplotlib inline\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import dicom\n",
        "import os\n",
        "import scipy.ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage import measure, morphology\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "\n",
        "#from __future__ import division, print_function, absolute_import\n",
        "# Import tflearn and some helpers\n",
        "import tflearn\n",
        "from tflearn.data_utils import shuffle\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.estimator import regression\n",
        "from tflearn.data_preprocessing import ImagePreprocessing\n",
        "from tflearn.data_augmentation import ImageAugmentation\n",
        "import pickle\n",
        "\n",
        "# Some constants\n",
        "INPUT_FOLDER = 'stage1/'\n",
        "\n",
        "# Load the scans in given folder path\n",
        "def load_scan(path):\n",
        "    slices = [dicom.read_file(path + s) for s in os.listdir(path)]\n",
        "    slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n",
        "    try:\n",
        "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
        "    except:\n",
        "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
        "\n",
        "    for s in slices:\n",
        "        s.SliceThickness = slice_thickness\n",
        "\n",
        "    return slices\n",
        "\n",
        "\n",
        "def get_pixels_hu(slices):\n",
        "    image = np.stack([s.pixel_array for s in slices])\n",
        "    # Convert to int16 (from sometimes int16),\n",
        "    # should be possible as values should always be low enough (<32k)\n",
        "    image = image.astype(np.int16)\n",
        "\n",
        "    # Set outside-of-scan pixels to 0\n",
        "    # The intercept is usually -1024, so air is approximately 0\n",
        "    image[image == -2000] = 0\n",
        "\n",
        "    # Convert to Hounsfield units (HU)\n",
        "    for slice_number in range(len(slices)):\n",
        "\n",
        "        intercept = slices[slice_number].RescaleIntercept\n",
        "        slope = slices[slice_number].RescaleSlope\n",
        "\n",
        "        if slope != 1:\n",
        "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
        "            image[slice_number] = image[slice_number].astype(np.int16)\n",
        "\n",
        "        image[slice_number] += np.int16(intercept)\n",
        "\n",
        "    return np.array(image, dtype=np.int16)\n",
        "\n",
        "\n",
        "def get_datas(files, count=-1):\n",
        "\n",
        "    if count != -1:\n",
        "        size = len(files)\n",
        "    else:\n",
        "        size = count\n",
        "\n",
        "    datas = [0 for i in range(size)]\n",
        "\n",
        "    for i,f in enumerate(files):\n",
        "        slices = load_scan(INPUT_FOLDER + f + '/')\n",
        "        datas[i] = get_pixels_hu(slices)\n",
        "        if count == i:\n",
        "            break\n",
        "    return datas\n",
        "\n",
        "\n",
        "def resample(image, scan, new_spacing=[1, 1, 1]):\n",
        "    # Determine current pixel spacing\n",
        "    spacing = np.array([scan[0].SliceThickness] + scan[0].PixelSpacing, dtype=np.float32)\n",
        "    print(\"spacing: \", spacing)\n",
        "\n",
        "    resize_factor = spacing / new_spacing\n",
        "    new_real_shape = image.shape * resize_factor\n",
        "    new_shape = np.round(new_real_shape)\n",
        "    real_resize_factor = new_shape / image.shape\n",
        "    new_spacing = spacing / real_resize_factor\n",
        "\n",
        "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
        "\n",
        "    return image, new_spacing\n",
        "\n",
        "\n",
        "def batch2D(image):\n",
        "    for i in range(len(image)):\n",
        "        if i > 0:\n",
        "            image[0] += image[i]\n",
        "\n",
        "    image[0] = image[0]/len(image)\n",
        "\n",
        "    return np.array(image[0], dtype=np.int16)\n",
        "\n",
        "\n",
        "def plot_3d(image, threshold=-300):\n",
        "    # Position the scan upright,\n",
        "    # so the head of the patient would be at the top facing the camera\n",
        "    p = image.transpose(2, 1, 0)\n",
        "\n",
        "    verts, faces = measure.marching_cubes(p, threshold)\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
        "    mesh = Poly3DCollection(verts[faces], alpha=0.70)\n",
        "    face_color = [0.45, 0.45, 0.75]\n",
        "    mesh.set_facecolor(face_color)\n",
        "    ax.add_collection3d(mesh)\n",
        "\n",
        "    ax.set_xlim(0, p.shape[0])\n",
        "    ax.set_ylim(0, p.shape[1])\n",
        "    ax.set_zlim(0, p.shape[2])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def largest_label_volume(im, bg=-1):\n",
        "    vals, counts = np.unique(im, return_counts=True)\n",
        "\n",
        "    counts = counts[vals != bg]\n",
        "    vals = vals[vals != bg]\n",
        "\n",
        "    if len(counts) > 0:\n",
        "        return vals[np.argmax(counts)]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def segment_lung_mask(image, fill_lung_structures=True):\n",
        "    # not actually binary, but 1 and 2.\n",
        "    # 0 is treated as background, which we do not want\n",
        "    binary_image = np.array(image > -320, dtype=np.int8) + 1\n",
        "    labels = measure.label(binary_image)\n",
        "\n",
        "    # Pick the pixel in the very corner to determine which label is air.\n",
        "    #   Improvement: Pick multiple background labels from around the patient\n",
        "    #   More resistant to \"trays\" on which the patient lays cutting the air\n",
        "    #   around the person in half\n",
        "    background_label = labels[0, 0, 0]\n",
        "\n",
        "    # Fill the air around the person\n",
        "    binary_image[background_label == labels] = 2\n",
        "\n",
        "    # Method of filling the lung structures (that is superior to something like\n",
        "    # morphological closing)\n",
        "    if fill_lung_structures:\n",
        "        # For every slice we determine the largest solid structure\n",
        "        for i, axial_slice in enumerate(binary_image):\n",
        "            axial_slice = axial_slice - 1\n",
        "            labeling = measure.label(axial_slice)\n",
        "            l_max = largest_label_volume(labeling, bg=0)\n",
        "\n",
        "            if l_max is not None:  # This slice contains some lung\n",
        "                binary_image[i][labeling != l_max] = 1\n",
        "\n",
        "    binary_image -= 1  # Make the image actual binary\n",
        "    binary_image = 1 - binary_image  # Invert it, lungs are now 1\n",
        "\n",
        "    # Remove other air pockets insided body\n",
        "    labels = measure.label(binary_image, background=0)\n",
        "    l_max = largest_label_volume(labels, bg=0)\n",
        "    if l_max is not None:  # There are air pockets\n",
        "        binary_image[labels != l_max] = 0\n",
        "\n",
        "    return binary_image\n",
        "\n",
        "\n",
        "MIN_BOUND = -1000.0\n",
        "MAX_BOUND = 400.0\n",
        "\n",
        "\n",
        "def normalize(image):\n",
        "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
        "    image[image > 1] = 1.\n",
        "    image[image < 0] = 0.\n",
        "    return image\n",
        "\n",
        "\n",
        "PIXEL_MEAN = 0.25\n",
        "\n",
        "def zero_center(image):\n",
        "    image = image - PIXEL_MEAN\n",
        "    return image\n",
        "\n",
        "print (\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1fb94db6-ff11-1811-8416-f607d8a32e89"
      },
      "outputs": [],
      "source": [
        "print(\"start\")\n",
        "df = pd.read_csv('stage1_labels.csv')\n",
        "\n",
        "num_train = 15\n",
        "num_test = 5\n",
        "num_validation = 5\n",
        "\n",
        "training_files = df['id'].tolist()[:num_train + num_validation]\n",
        "training_class = df['cancer'].tolist()[:num_train + num_validation]\n",
        "\n",
        "test_files = pd.read_csv('stage1_sample_submission.csv')['id'].tolist()\n",
        "\n",
        "\n",
        "train_and_validation = get_datas(training_files, num_train + num_validation)\n",
        "train_data = train_and_validation[:num_train]\n",
        "train_y = training_class[:num_train]\n",
        "validation_data = train_and_validation[-num_validation:]\n",
        "validation_y = training_class[-num_validation:]\n",
        "\n",
        "test_data = get_datas(test_files, num_test)\n",
        "\n",
        "batched_imgs = np.empty([num_train, 512, 512], dtype=np.int16)\n",
        "for i in range(num_train):\n",
        "    batched_imgs[i] = batch2D(train_data[i])\n",
        "\n",
        "imgs2d = np.empty([num_train, 32, 32], dtype=np.int16)\n",
        "for i in range(num_train):\n",
        "    imgs2d[i] = scipy.ndimage.interpolation.zoom(batched_imgs[i], 1/16, mode='nearest')\n",
        "    \n",
        "print(imgs2d.shape)\n",
        "print(batched_imgs.shape)\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "95d8eec4-e47d-2d7a-ca1c-127b045eb210"
      },
      "outputs": [],
      "source": [
        "print (\"started\")\n",
        "img_prep = ImagePreprocessing()\n",
        "img_prep.add_featurewise_zero_center()\n",
        "img_prep.add_featurewise_stdnorm()\n",
        "\n",
        "# Create extra synthetic training data by flipping, rotating and blurring the\n",
        "# images on our data set.\n",
        "img_aug = ImageAugmentation()\n",
        "img_aug.add_random_flip_leftright()\n",
        "img_aug.add_random_rotation(max_angle=25.)\n",
        "img_aug.add_random_blur(sigma_max=3.)\n",
        "\n",
        "# Define our network architecture:\n",
        "\n",
        "# Input is a 32x32 image with 3 color channels (red, green and blue)\n",
        "network = input_data(shape=[None, 32, 32, 1],\n",
        "                     data_preprocessing=img_prep,\n",
        "                     data_augmentation=img_aug)\n",
        "\n",
        "# Step 1: Convolution\n",
        "network = conv_2d(network, 32, 1, activation='relu')\n",
        "\n",
        "# Step 2: Max pooling\n",
        "network = max_pool_2d(network, 2)\n",
        "\n",
        "# Step 3: Convolution again\n",
        "network = conv_2d(network, 64, 1, activation='relu')\n",
        "\n",
        "# Step 4: Convolution yet again\n",
        "network = conv_2d(network, 64, 1, activation='relu')\n",
        "\n",
        "# Step 5: Max pooling again\n",
        "network = max_pool_2d(network, 2)\n",
        "\n",
        "# Step 6: Fully-connected 512 node neural network\n",
        "network = fully_connected(network, 512, activation='relu')\n",
        "\n",
        "# Step 7: Dropout - throw away some data randomly during training to prevent over-fitting\n",
        "network = dropout(network, 0.5)\n",
        "\n",
        "# Step 8: Fully-connected neural network with two outputs (0=isn't a bird, 1=is a bird) to make the final prediction\n",
        "network = fully_connected(network, 2, activation='softmax')\n",
        "\n",
        "# Tell tflearn how we want to train the network\n",
        "network = regression(network, optimizer='adam',\n",
        "                     loss='categorical_crossentropy',\n",
        "                     learning_rate=0.001)\n",
        "\n",
        "# Wrap the network in a model object\n",
        "model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path='bird-classifier.tfl.ckpt')\n",
        "\n",
        "# Train it! We'll do 100 training passes and monitor it as it goes.\n",
        "test_res = []\n",
        "model.fit(imgs2d, train_y, n_epoch=100, shuffle=True, validation_set=(vimgs2d, validation_y),\n",
        "          show_metric=True, batch_size=96,\n",
        "          snapshot_epoch=True,\n",
        "          run_id='bird-classifier')\n",
        "\n",
        "# Save model when training is complete to a file\n",
        "model.save(\"bird-classifier.tfl\")\n",
        "print(\"Network trained and saved as bird-classifier.tfl!\")batched_vimgs = np.empty([num_validation, 512, 512], dtype=np.int16)\n",
        "for i in range(num_validation):\n",
        "    batched_vimgs[i] = batch2D(validation_data[i])\n",
        "\n",
        "vimgs2d = np.empty([num_validation, 32, 32], dtype=np.int16)\n",
        "for i in range(num_train):\n",
        "    vimgs2d[i] = scipy.ndimage.interpolation.zoom(batched_vimgs[i], 1/16, mode='nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "825adb63-584b-df32-2494-745e72661b29"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fe036cbb-3c0a-0f14-98a8-385f433fbc3a",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}