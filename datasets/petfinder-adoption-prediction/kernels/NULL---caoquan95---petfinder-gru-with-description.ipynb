{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nimport os\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense, GRU\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc2d3b7b30dd99f3f810a3fc6fb0857e093ff900"},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/petfinder-adoption-prediction/train/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc5d0d9a02aebb0deff79323c16b3ef62b8a671c"},"cell_type":"code","source":"data = train_df[['AdoptionSpeed', \"Description\"]]\ndata = data[data['Description'] != '']\ndescriptions = data['Description'].apply(lambda x: re.sub(r\"[^a-z0-9 ]+\", \"\", str(x).lower()))\nlabels = data['AdoptionSpeed']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31afc383aefe4e8e2d7d9e1d56738b8ae89f8a80"},"cell_type":"code","source":"labels_oh = to_categorical(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ac23206afd57f943ef03f970cc40a1d108296b5"},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=1000)\ntokenizer.fit_on_texts(descriptions)\nword_index = tokenizer.word_index\n\nprint('Found %s unique tokens' % len(word_index))\nsequences = tokenizer.texts_to_sequences(descriptions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cedf478e53354b5d4117e8f90fc96f810f76252"},"cell_type":"code","source":"max_len = 100\nmax_words = 10000\ntraining_sample = 10000\nval_sample = 12000\npadded_sequences = pad_sequences(sequences, maxlen=max_len)\nprint(\"Shape of data: \", padded_sequences.shape)\nprint(\"Shape of labels: \", labels_oh.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53bc6a5845fff93ed98a4b775a9a3805ebf9b538"},"cell_type":"code","source":"# Shuffle the data\nindices = np.arange(data.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea2d2ea7e17be9015b39f6c02c6ad77cc98c076c"},"cell_type":"code","source":"np.random.shuffle(indices)\npadded_sequences = padded_sequences[indices]\nlabels = labels[indices]\n\nx_train = padded_sequences[:training_sample]\ny_train = labels_oh[:training_sample]\nx_val = padded_sequences[training_sample: val_sample]\ny_val = labels_oh[training_sample: val_sample]\nx_test = padded_sequences[val_sample: ]\ny_test = labels_oh[val_sample: ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86d17b2a21eef7522d19aacf9425759c31e833e3"},"cell_type":"code","source":"# load Glove word embedding\nembeddings_index = {}\nf = open(\"../input/glove6b300dtxt/glove.6B.300d.txt\")\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\nprint('Found %s word vectors.' % len(embeddings_index))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52e4d657080926588106f1bc2cd8ded6a7570309"},"cell_type":"code","source":"embedding_dim = 300\nembedding_matrix = np.zeros((max_words, embedding_dim))\nfor word, i in word_index.items():\n    if i < max_words:\n        embedding_vector = embedding_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcaa6ae559def6dd203a0a7ef090dc80faa43bd5"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(max_words, embedding_dim, input_length=max_len))\nmodel.add(GRU(64, return_sequences=True))\nmodel.add(GRU(64))\nmodel.add(Dense(5, activation=\"softmax\"))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4caba7a536a721ceab5d4efd6ff9bf3646e4d617"},"cell_type":"code","source":"model.layers[0].set_weights([embedding_matrix])\nmodel.layers[0].trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efe1ca1dcf4240913ad193a28d58f1f6475efd4a","scrolled":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\nhistory = model.fit(x_train, y_train,\n    epochs=10,\n    batch_size=256,\n    validation_data=(x_val, y_val))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e6b1a7e0f7bd592e8216ce789a71d1f845e0ff3"},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb5b9e767bc7be1c6ce1dc509ae6037baadc8a17"},"cell_type":"code","source":"epochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92c425ff2b9b0e970bc5dfd7944f6620e815f0e2"},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb07038af23572a88b686c5d908d0a8202055a87"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}