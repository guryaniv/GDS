{"metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python", "file_extension": ".py", "version": "3.6.1"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat": 4, "nbformat_minor": 1, "cells": [{"metadata": {"_uuid": "da53179e62f8bc17219b9635c69df920890e6130", "_cell_guid": "8b8f88ce-330d-4042-8d42-fbd8d0b3d5d9", "_execution_state": "idle"}, "source": "### Keras based model LB 0.98ish", "outputs": [], "execution_count": null, "cell_type": "markdown"}, {"metadata": {"_uuid": "85e15a25edb1746c5c280d08975b2bda4455cecd", "trusted": false, "_cell_guid": "27399160-44de-4b0e-965e-1f19e4d1a827", "_execution_state": "idle"}, "source": "import gc, os, sys, time\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport cv2\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import KFold\nfrom sklearn import metrics\n\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers import Dense, Flatten, Dropout\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers", "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "98b53cb358bf5f975ff50cc1d45029417ebbe607", "trusted": false, "_cell_guid": "de83179f-8bfd-4859-8d90-7ed46cec9ec7"}, "source": "!cd ../input; ls", "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "651ec3909b9da676951fb2faa8a996f4a8e05d39", "trusted": false, "_cell_guid": "d5e5a3db-11fc-4cef-9be1-8e73a2fe29b8", "_execution_state": "idle"}, "source": "df_train = pd.read_csv('../input/train_labels.csv')\ndf_test = pd.read_csv('../input/sample_submission.csv')\nprint(df_train.head())", "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "4c964aa94330dc112a598082560df1225cd9ef5c", "trusted": false, "_cell_guid": "b548212d-d7cc-492b-8938-bd707d05e53d", "_execution_state": "idle"}, "source": "print(df_test.head())\nx_train = []\ny_train = []\nx_test = []", "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "ffed693a81f6b9a8b16d96646777d24f992ca1d0", "trusted": false, "_cell_guid": "6b0c781b-4502-4b19-b9db-3f7275336c98", "_execution_state": "idle"}, "source": "for name, tag in tqdm(df_train.values, miniters=300):\n    #print(name)\n    img = cv2.imread('../input/train/{}.jpg'.format(name))\n    x_train.append(cv2.resize(img, (128, 128)))\n    y_train.append(tag)\n    \nfor name, tag in tqdm(df_test.values, miniters=300):\n    #print(name)\n    img = cv2.imread('../input/test/{}.jpg'.format(int(name)))\n    x_test.append(cv2.resize(img, (128, 128)))", "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "cd22333a658affbf2ed0a2088b12eb51874b576e", "trusted": false, "_cell_guid": "942e5dfe-d4ec-462f-b86c-07c8dcb04515", "_execution_state": "idle"}, "source": "y_train = np.array(y_train, np.uint8)\nx_train = np.array(x_train, np.float32)/255.\nx_test  = np.array(x_test, np.float32)/255.\n\nprint(x_train.shape)\nprint(y_train.shape)\n\nnum_folds = 5\ncount_folds = 0\n\nsum_score = 0\n\nyfull_test = []\nyfull_train = []\n\nkf = KFold(n_splits=num_folds, shuffle=True, random_state=1)\neval_func = metrics.roc_auc_score", "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "16cfcbc03597b4dba733ebf2b8df65f3b82c2829", "_cell_guid": "43128ac3-657b-4b71-9877-50f3bfeafd09", "trusted": false, "collapsed": true, "_execution_state": "idle"}, "source": "def model_func():\n    model = Sequential()\n    model.add(BatchNormalization(input_shape=(128, 128, 3)))\n    # Without BatchNormalization\n    # model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n    model.add(Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(16, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(256, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    \n    model.add(Dense(1024, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    opt = optimizers.Adam(lr = 0.001, decay = 1e-6)\n    model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics=['accuracy'])\n    #print(model.summary())\n    return model", "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "0961d0bcc5c232ff208a65cc479687479599517e", "_cell_guid": "a6c95c07-d9e9-4ff5-b665-1a8718c4224e", "trusted": false, "collapsed": true, "_execution_state": "idle"}, "source": "def run_net(train_x, train_y, test_x, kf):      \n    preds_train = np.zeros(len(train_x), dtype = np.float)\n    preds_test = np.zeros(len(test_x), dtype = np.float)\n    train_loss = []; test_loss = []\n\n    i = 1\n    \n    for train_index, test_index in kf.split(train_x):\n        start_time = time.time()\n        x_tr = train_x[train_index]; x_te = train_x[test_index]\n        y_tr = train_y[train_index]; y_te = train_y[test_index]\n\n        datagen = ImageDataGenerator(\n            rotation_range = 30,\n            width_shift_range = 0.2,\n            height_shift_range = 0.2,\n            shear_range = 0.2,\n            zoom_range = 0.2,\n            horizontal_flip = True,\n            vertical_flip = True,\n            fill_mode = 'nearest')\n        datagen.fit(x_tr)\n\n        model = model_func()\n        earlystop = EarlyStopping(monitor='val_loss', patience = 15, verbose=0, mode='auto')\n        model.fit_generator(datagen.flow(x_tr, y_tr, batch_size = 160),\n            validation_data = (x_te, y_te), callbacks = [earlystop],\n            steps_per_epoch = len(x_train) / 160, epochs = 100, verbose = 2)\n\n        train_loss.append(eval_func(y_tr, model.predict(x_tr)[:, 0]))\n        test_loss.append(eval_func(y_te, model.predict(x_te)[:, 0]))\n\n        preds_train[test_index] = model.predict(x_te)[:, 0]\n        preds_test += model.predict(test_x)[:, 0]\n\n        print('KFold {0}: Train: {1:0.5f} Validation: {2:0.5f}'.format(i, train_loss[-1], test_loss[-1]))\n        i += 1\n\n    preds_test /= num_folds\n    return preds_train, preds_test", "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "29d38c958714524a6170ad0fc25deb52fef3a7d7", "trusted": false, "_cell_guid": "ca15ab93-45b4-41a4-9e90-400d573b7953", "_execution_state": "idle"}, "source": "train_predictions, test_predictions = run_net(x_train, y_train, x_test, kf)", "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "669c2055ee97268ee44a658f8f50d4345acdc033", "_cell_guid": "190f43b7-64f4-4ea4-b185-2fca869240ff", "trusted": false, "collapsed": true, "_execution_state": "idle"}, "source": "df_test['invasive'] = test_predictions\ndf_test.to_csv('submission_v2.csv', index=False)", "outputs": [], "execution_count": null, "cell_type": "code"}]}