{"cells":[{"metadata":{"_uuid":"c3d6623fa046a86b021975dfa1c5b370e98c22c4"},"cell_type":"markdown","source":"# Further analysis of the geospatial data\nThere has been some excellent work done on analysing the geospatial data and I would just like to extend it a little more with my findings especially the transposed latitude and longitude.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Read 50,000 rows of data\ntrain = pd.read_csv('../input/train.csv', nrows = 1000000)\ntest = pd.read_csv('../input/test.csv')\ntrain.head(n=5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Zero values for latitude and longitude\nAs mentioned in other notebooks there are some issues with the geo data such as zero latitude and longitude. Not much we can do with these but drop the rows."},{"metadata":{"trusted":true,"_uuid":"8575fb72e47d92027cfadf1638275975dd563fbd","collapsed":true},"cell_type":"code","source":"print(\"Number of rows with zero values.\")\nprint(\"Missing data in column\", train[(train.isna())].shape[0])\nprint(\"Pickup longitude\", train[(train.pickup_longitude == 0.0)].shape[0])\nprint(\"Pickup latitude\", train[(train.pickup_latitude == 0.0)].shape[0])\nprint(\"Dropoff longitude\", train[(train.dropoff_longitude == 0.0)].shape[0])\nprint(\"Dropoff latitude\", train[(train.dropoff_latitude == 0.0) ].shape[0])\n# Drop out these missing data rows.\ntrain = train.dropna()\n# Drop zero value\ntrain = train[(train.pickup_longitude != 0.0 ) & \\\n              (train.pickup_latitude != 0.0) & \\\n              (train.dropoff_longitude != 0.0) &\\\n              (train.dropoff_latitude != 0.0)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4030181b079514f65211483638aa981b81d6f78"},"cell_type":"markdown","source":"## Some latitude and longitude may be transposed\nAnother issue I have seen which hasn't been discussed is where the latitude and longitude have been transposed. \n\nHere is an example row where latitude and longitude are swapped."},{"metadata":{"trusted":true,"_uuid":"ba695824ca2d6d1b5b431b41178015763a6bacc5","collapsed":true},"cell_type":"code","source":"train[(train.pickup_latitude < -73.0 ) & (train.pickup_latitude > -75.0) & \n      (train.pickup_longitude > 40.4) & (train.pickup_latitude < 41.0) &\n      (train.dropoff_latitude < -73.0 ) & (train.dropoff_latitude > -75.0) &\n      (train.dropoff_longitude > 40.4) & (train.dropoff_latitude < 41.0)].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba5d4793582737d1a869091ffd2d0ca755581d22","collapsed":true},"cell_type":"code","source":"print(\"Calculating how many rows have transposed latitude and longitude\")\n# Pickup & dropoff lat/lon transposed.\nprint(\"Number of pickup & dropoff lat/lon transposed:\", \n      train[(train.pickup_latitude < -73.0 ) & (train.pickup_latitude > -75.0) & \n      (train.pickup_longitude > 40.4) & (train.pickup_latitude < 41.0) &\n      (train.dropoff_latitude < -73.0 ) & (train.dropoff_latitude > -75.0) &\n      (train.dropoff_longitude > 40.4) & (train.dropoff_latitude < 41.0)].shape[0])\n# Pickup lat/lon transposed but dropoff ok\nprint(\"Number of pickup lat/lon transposed but dropoff ok:\", \ntrain[(train.pickup_latitude < -73.0 ) & (train.pickup_latitude > -75.0) & \n      (train.pickup_longitude > 40.4) & (train.pickup_latitude < 41.0) &\n      (train.dropoff_latitude > -73.0 ) & (train.dropoff_latitude < -75.0) &\n      (train.dropoff_longitude < 40.4) & (train.dropoff_latitude > 41.0)].shape[0])\n# Pickup lat/lon ok but dropoff transposed\nprint(\"Number of pickup lat/lon ok but dropoff transposed:\", \ntrain[(train.pickup_latitude > -73.0 ) & (train.pickup_latitude < -75.0) & \n      (train.pickup_longitude < 40.4) & (train.pickup_latitude > 41.0) &\n      (train.dropoff_latitude > -73.0 ) & (train.dropoff_latitude < -75.0) &\n      (train.dropoff_longitude < 40.4) & (train.dropoff_latitude > 41.0)].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab4d2f63b042fa1bb4b1d3c0a462acae2d502f61"},"cell_type":"markdown","source":"From 50,000 rows we only have 19 that have swapped values, which is a very small number. Let's see if they are valid by plotting them."},{"metadata":{"trusted":true,"_uuid":"8bb7e734d38c71d1e3278e50184cfca1be1ade46","collapsed":true},"cell_type":"code","source":"# Code from https://www.kaggle.com/breemen/nyc-taxi-fare-data-exploration kernek by Albert van Breemen.\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Grab out the rows which have transposed values\ndf_swap = train[(train.pickup_latitude < -73.0 ) & (train.pickup_latitude > -75.0) & \n      (train.pickup_longitude > 40.4) & (train.pickup_latitude < 41.0) &\n      (train.dropoff_latitude < -73.0 ) & (train.dropoff_latitude > -75.0) &\n      (train.dropoff_longitude > 40.4) & (train.dropoff_latitude < 41.0)]\n\nnyc_map = plt.imread('https://aiblog.nl/download/nyc_-75_40_-73_41.5.png')\nBB = (-74.25, -73.5, 40.4, 41.0)\n\n# Plot them on the map to have a look at them\nfig, axs = plt.subplots(1,1, figsize=(16,10))\naxs.scatter(df_swap.pickup_latitude, df_swap.pickup_longitude, zorder=1, c='r')\naxs.scatter(df_swap.dropoff_latitude, df_swap.dropoff_longitude, zorder=1, c='b')\naxs.plot([df_swap.pickup_latitude, df_swap.dropoff_latitude], [df_swap.pickup_longitude, df_swap.dropoff_longitude], 'k-', lw=1)\naxs.set_xlim((BB[0], BB[1]))\naxs.set_ylim((BB[2], BB[3]))\naxs.set_title('Pickup locations')\naxs.imshow(nyc_map, zorder=0, extent=[-74.25, -73.5, 40.4, 41.0]);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70ccf975e35f1068ce45f4de77103793ca22dbdf"},"cell_type":"markdown","source":"These trips all seem to be in a particular region so perhaps a particular taxi company is reporting the data incorrectly.\n\nHere is some code which could be easily included to swap the values when they are found."},{"metadata":{"trusted":true,"_uuid":"80bb6e746564ab6699b29eb42b3e1fc5796a0af6","collapsed":true},"cell_type":"code","source":"train['pickup_longitude'] = train['pickup_longitude'].where(train.pickup_longitude < 39 , train['pickup_latitude'])\ntrain['pickup_latitude'] = train['pickup_latitude'].where(train.pickup_latitude > -73 , train['pickup_longitude'])\ntrain['dropoff_longitude'] = train['dropoff_longitude'].where(train.dropoff_longitude < 39 , train['dropoff_latitude'])\ntrain['dropoff_latitude'] = train['dropoff_latitude'].where(train.dropoff_latitude > -73 , train['dropoff_longitude'])\n#\nprint(\"Check that values have been swapped: \", train[(train.pickup_latitude < -73.0 ) & (train.pickup_latitude > -75.0) & \n      (train.pickup_longitude > 40.4) & (train.pickup_latitude < 41.0) &\n      (train.dropoff_latitude < -73.0 ) & (train.dropoff_latitude > -75.0) &\n      (train.dropoff_longitude > 40.4) & (train.dropoff_latitude < 41.0)].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e102c630da051c898b38b1821c0333aa4915da0"},"cell_type":"markdown","source":"## Taxi that don't move\nSome of the geo-coordinates have the lat long in the same location."},{"metadata":{"trusted":true,"_uuid":"7a4a276e28029af34d30c81d28b9576f8ce64e7a","collapsed":true},"cell_type":"code","source":"print(\"Number of rows where lat/lon doesn't change: \", train[(train.pickup_longitude == train.dropoff_longitude) & \\\n              (train.pickup_latitude == train.dropoff_latitude)].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4af25d1364f84b8174f8bb84f41676cbeb46c14","collapsed":true},"cell_type":"code","source":"train[(train.pickup_longitude == train.dropoff_longitude) & \\\n              (train.pickup_latitude == train.dropoff_latitude)].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28f7b1665070fd94b404a4c0702e6ea1f940a5c4"},"cell_type":"markdown","source":"Technically, if you jump in a taxi and they turn on the meter you could be hit with the flag fall $2.50 + fees and sucharges. Looking at the values they are a lot larger so its more likely that the gps didn't update and it would be best top drop these rows.\n\nLet's drop out these rows."},{"metadata":{"trusted":true,"_uuid":"d5b8dbfb9f71affb567a961eb792a5b267685c42","collapsed":true},"cell_type":"code","source":"train = train[(train.pickup_longitude != train.dropoff_longitude) & \\\n              (train.pickup_latitude != train.dropoff_latitude)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45c367b8f1f39f2c3e551ce459d390fad6af217c"},"cell_type":"markdown","source":"## Ensure lat and long are reasonable\nSimply go through the lat and lon and make sure they are in a reasonable range for NYC."},{"metadata":{"trusted":true,"_uuid":"b6a9c97127223e97765b2017ef960b5fed1d54a4","collapsed":true},"cell_type":"code","source":"start = train.shape[0]\ntrain = train[(train.pickup_longitude <= -73.0 ) & \\\n              (train.pickup_longitude >= -75.0) & \\\n              (train.pickup_latitude >= 40.4) & \\\n              (train.dropoff_latitude <= 41.0) & \\\n              (train.dropoff_longitude <= -73.0 ) & \\\n              (train.dropoff_longitude >= -75.0) & \\\n              (train.dropoff_latitude >= 40.4) & \\\n              (train.dropoff_latitude <= 41.0)]\nprint(\"Dropped {} with unreasonable lat or lon\".format(start - train.shape[0]))\nstart = train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef2f9bb8d251d378e1e62b52b58110f43d25dfa7"},"cell_type":"markdown","source":"## Calculate distance\nNeed to calculate the distance from pickup to drop off. Not the best method as it doesn't follow the path the taxi would need to travel but can be a good approximation.\n\nAs the distance we calculate is a straight line, then a fare calculate on this number show always be lower than the fare amount as a taxi will travel a great distance. If this is not the case we will drop the row."},{"metadata":{"trusted":true,"_uuid":"016455a444f9dd3e7ac767e6366b9384d6dd6682","collapsed":true},"cell_type":"code","source":"from geopy import distance\n# Calculate distance function\ndef calc_dist(x):\n    try:\n        dist = round(distance.distance((x[0], x[1]),(x[2], x[3])).feet, 0)\n    except ValueError as e:\n        print(\"ERROR \", x, e)\n        dist = 0\n    return dist\n\ntrain['distance'] = train[[\"pickup_latitude\", \"pickup_longitude\", \"dropoff_latitude\",\"dropoff_longitude\"]].apply(calc_dist, axis=1)\n# Make sure distance and fare are resonable, fare should always be bigger than a straight line distance\nbefore = train.shape[0]\ntrain = train[((train.distance/1056)*0.50 < train.fare_amount)]\nprint(\"Dropping {} rows due to fare less than resonable amount according to distance\".format(before-train.shape[0]))\ntrain.head()\n# Create feature for test set\ntest['distance'] = test[[\"pickup_latitude\", \"pickup_longitude\", \"dropoff_latitude\",\"dropoff_longitude\"]].apply(calc_dist, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74c28dbe925535e42b51b780147dbac6e9129892"},"cell_type":"markdown","source":"## Bin latitude and longitude and look at trips\nGiven that taxi fares are calculated at 0.50 per 0.2 mile, I thought putting the geospatial data into bins that are 0.2 miles would increase the signal within the data.\n\nUsing the geopy module to insure the calculations are correct for around NYC. Work out at the right bin size might be."},{"metadata":{"trusted":true,"_uuid":"c4852904f836b1ce373aa0545ac9054060baf2bf","collapsed":true},"cell_type":"code","source":"from geopy import distance\n\nnyc_lat = 40.730610\nnyc_lon = -73.935242\nlon_step = 0.003\nlat_step = 0.01\n\n# If the lon moves by 0.03 how far is that\nprint(\"Longitude increasing by {} is {} miles\".format(lon_step, round(distance.distance((nyc_lon, lat_step),(nyc_lon+lon_step, lat_step)).miles, 2)))\n# If the lat moves by 0.03 how far is that\nprint(\"Latitude increasing by {} is {} miles\".format(lat_step, round(distance.distance((nyc_lon, lat_step),(nyc_lon, lat_step+lat_step)).miles, 2)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8934334b697af38e0afb7ca36e8780559438795"},"cell_type":"markdown","source":"Using a lon_step of 0.003 and a lat_step would seem reasonable."},{"metadata":{"trusted":true,"_uuid":"bb6ed8245df38d2a3361a61c4ac6a69e8077c58a","collapsed":true},"cell_type":"code","source":"def bin_data(df):\n    pickup_groups = df.groupby([\"pickup_latitude\", \"pickup_longitude\"])\n    dropoff_groups = df.groupby([\"dropoff_latitude\", \"dropoff_longitude\"])\n    trip_groups = df.groupby([\"pickup_latitude\", \"pickup_longitude\", \"dropoff_latitude\", \"dropoff_longitude\"])\n    print(\"Before bin:\")\n    print(\"Number of pickup locations: \",pickup_groups.ngroups)\n    print(\"Number of dropoff locations: \",dropoff_groups.ngroups)\n    print(\"Number of trips: \", trip_groups.ngroups)\n    #\n    # Create the bin size.\n    lon_step = 0.003\n    lat_step = 0.01\n    print(\"Lat bin size {} and long bin size {}\\n\".format(lat_step, lon_step))\n    to_bin_lon = lambda x: np.floor(x / lon_step) * lon_step\n    to_bin_lat = lambda x: np.floor(x / lat_step) * lat_step\n    df[\"pickup_latbin\"] = df.pickup_latitude.map(to_bin_lat)\n    df[\"pickup_lonbin\"] = df.pickup_longitude.map(to_bin_lon)\n    df[\"dropoff_latbin\"] = df.dropoff_latitude.map(to_bin_lat)\n    df[\"dropoff_lonbin\"] = df.dropoff_longitude.map(to_bin_lon)\n    pickup_groups = df.groupby([\"pickup_latbin\", \"pickup_lonbin\"])\n    dropoff_groups = df.groupby([\"dropoff_latbin\", \"dropoff_lonbin\"])\n    trip_groups = df.groupby([\"pickup_latbin\", \"pickup_lonbin\",\"dropoff_latbin\", \"dropoff_lonbin\"])\n    print(\"After bin:\")\n    print(\"New number of pickup locations: \",pickup_groups.ngroups)\n    print(\"New number of dropoff locations: \",dropoff_groups.ngroups)\n    print(\"New number of trips: \", trip_groups.ngroups)\n\n    return df\ntrain = bin_data(train)\ntest = bin_data(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1cfaf10e0b9562a1975cf9ffab5af9c9bdacf8c"},"cell_type":"markdown","source":"Let's take a quick look a the new bins and see if it looks reasonable and it does."},{"metadata":{"trusted":true,"_uuid":"5307198e0bdba2cb235b8a42969cf8e507b7c134","collapsed":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5bd8fa23e055215cbb5a719ab92c7cef95f5ca9","collapsed":true},"cell_type":"code","source":"# We can drop off the columns\ntrain = train.drop(['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'], axis=1)\ntest = test.drop(['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8825125f907cbafffd06538aaa49debf0c8020d6"},"cell_type":"markdown","source":"## Extract features from pickup date time\nLooking at the way fares are calculated:\n\n1. 50c/60secs in slow or stopped - traffic is more likely to heavier during peak out, so extracting the hour is important\n2. 50c surcharge 8pm to 6am\n3. $1 surcharge 4pm to 8pm weekdays, excluding holidays\n\nWe need to extract three: hour, weekday & public holiday. Might be worth converting the GMT time to NYC timezone to ensure ensure the correct date/time is used."},{"metadata":{"trusted":true,"_uuid":"1386684adc85b67c1093d8cf71cad5f00b66cd91","collapsed":true},"cell_type":"code","source":"def convert_date(df):\n    df['pickup_datetime'] = pd.to_datetime(df.pickup_datetime, format='%Y-%m-%d %H:%M:%S %Z', utc=True)\n    # Add New York timezone\n    df['pickup_datetime'] = df.pickup_datetime.dt.tz_convert('America/New_York')\n    df['year'] = df.pickup_datetime.dt.year\n    df['pickup_hour'] = df.pickup_datetime.dt.hour\n    # day of week 0 Monday to 6 Sunday, we can capture weekend with < 5\n    df['weekend'] = df.pickup_datetime.dt.dayofweek < 5\n    # Add in surcharge period\n    df['surcharge'] = ((df.pickup_hour >= 20) | (df.pickup_hour <= 5))\n    # Drop pickup_datetime as we have extracted everything we need\n    df = df.drop('pickup_datetime', axis=1)\n\n    return df\ntrain = convert_date(train)\ntest = convert_date(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e7cf0292a85bf99f76352e5c24ca5b6485fed7a","collapsed":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4424c34256c4d04bf45317bc3134550acda66e4","collapsed":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"900b9436f97454fc5e109619902e80996f14e331"},"cell_type":"markdown","source":"## Train a model on the data"},{"metadata":{"trusted":true,"_uuid":"1f7813ce0a15d14dc62b57f1bff3efab6a4f2d16","collapsed":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\n\nmodel = Pipeline((\n        (\"standard_scaler\", StandardScaler()),\n        (\"rf_tree\", RandomForestRegressor())\n    ))\n\nX = train.iloc[:,2:].astype('float64', axis=1)\ny = np.ravel(train.fare_amount.values)\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.25)\nmodel.fit(X=train_X, y=train_y)\npredict_y = model.predict(X=test_X)\nrmse = np.sqrt(mean_squared_error(test_y, predict_y))\ncompare = pd.DataFrame()\ncompare['train_y'] = test_y\ncompare['predict_y'] = predict_y\ncompare['RSE'] = np.sqrt(np.square(test_y - predict_y))\nprint(\"RMSE: \", rmse)\ncompare.head(n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"640f9a10b1e4e7bad4ae43729282e0fda63c47f3","collapsed":true},"cell_type":"code","source":"# Cross validate to see how robust the results are\nscores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\nprint(\"Cross validated RMSE:\", np.sqrt(np.mean(scores)*-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21e3d77d369e713a5b7b67bc0f5ccff439f3101b","collapsed":true},"cell_type":"code","source":"test_X = test.iloc[:,1:].astype('float64', axis=1)\n\nmodel.fit(X=X, y=y)\ny_pred_final = model.predict(test_X)\n\nsubmission = pd.DataFrame(\n    {'key': test.key, 'fare_amount': y_pred_final},\n    columns = ['key', 'fare_amount'])\nsubmission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87b517493b3ca378f4e84efec3def49eb3f42e4a","collapsed":true},"cell_type":"code","source":"submission.head(n=5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd6fee75921b463edb5e2182a6a2ce27b45b4c55"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"9e0cfda5e1329c8fe73636607b7195f92f6c6262"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"5407600d7948f851747766c11b49104abe4a4253"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}