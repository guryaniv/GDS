{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom tqdm import tqdm\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndef load_data(dataframe=None, batch_size=16, mode='categorical'):\n    if dataframe is None:\n        dataframe = pd.read_csv('../input/train.csv')\n    dataframe['has_cactus'] = dataframe['has_cactus'].apply(str)\n    gen = ImageDataGenerator(rescale=1./255., validation_split=0.1, horizontal_flip=True, vertical_flip=True)\n\n    trainGen = gen.flow_from_dataframe(dataframe, directory='../input/train/train', x_col='id', y_col='has_cactus', has_ext=True, target_size=(32, 32),\n        class_mode=mode, batch_size=batch_size, shuffle=True, subset='training')\n    testGen = gen.flow_from_dataframe(dataframe, directory='../input/train/train', x_col='id', y_col='has_cactus', has_ext=True, target_size=(32, 32),\n        class_mode=mode, batch_size=batch_size, shuffle=True, subset='validation')\n    \n    return trainGen, testGen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ace6772b68f4734fe103fa6ceb1ddcfc44f3e0cb"},"cell_type":"code","source":"from keras.layers import Conv2D, MaxPool2D, Dense, BatchNormalization, Activation, GlobalAveragePooling2D\nfrom keras.models import Sequential, Model\nfrom keras.regularizers import l2\n\ndef baseline_model():\n    model = Sequential()\n\n    model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(32, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(32, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPool2D())\n\n    model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPool2D())\n\n    model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPool2D())\n\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(2, activation='softmax'))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e9796541d79aab446e542f42504e3835602cf4d"},"cell_type":"code","source":"from keras.optimizers import Adam, SGD\nfrom keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n\n\ndef train_baseline():\n    batch_size = 32\n    trainGen, valGen = load_data(batch_size=batch_size)\n    model = baseline_model()\n\n    opt = Adam(1e-3)\n    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n    cbs = [ReduceLROnPlateau(monitor='loss', factor=0.5, patience=1, min_lr=1e-5, verbose=1)]\n\n    model.fit_generator(trainGen, steps_per_epoch=4922, epochs=3, validation_data=valGen, \n        validation_steps=493, shuffle=True, callbacks=cbs)\n        \n    return model\n    \ndef predict_baseline(model):\n    testdf = pd.read_csv('../input/sample_submission.csv')\n    pred = np.empty((testdf.shape[0],))\n    for n in tqdm(range(testdf.shape[0])):\n        data = np.array(Image.open('../input/test/test/'+testdf.id[n]))\n        data = data.astype(np.float32) / 255.\n        pred[n] = model.predict(data.reshape((1, 32, 32, 3)))[0][1]\n    \n    testdf['has_cactus'] = pred\n    testdf.to_csv('sample_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9cbb653b85c17c602d9a13568e02a32c13ec0fd"},"cell_type":"code","source":"model = train_baseline()\npredict_baseline(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37da3aa9e2d886926cc9f1052bc1032253067e98"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}