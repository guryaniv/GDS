{"cells":[{"metadata":{"_uuid":"a4febf06eb3c4ef5db7f1a1331f4f7dd665b1383"},"cell_type":"markdown","source":"**InceptionV3**\n\n* https://ai.googleblog.com/2016/03/train-your-own-image-classifier-with.html\n* https://arxiv.org/abs/1512.00567"},{"metadata":{"_uuid":"f29c2f904c5ca9e18e7c74ade7ec00c9b2c8bb13","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nimport pandas as pd\n\n# fix dimension ordering issue\n# https://stackoverflow.com/questions/39547279/loading-weights-in-th-format-when-keras-is-set-to-tf-format\nfrom keras import backend as K\nK.set_image_dim_ordering('th')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"901ee568434f8bef80924d40e68527ef26e4da98"},"cell_type":"code","source":"from keras.applications.inception_v3 import InceptionV3\nweights = '../input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5'\nmodel = InceptionV3(weights=weights)\nprint (model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be8ad98e245d38c1a72898c5a8c38598d641f6d0","collapsed":true},"cell_type":"code","source":"from os import makedirs\nfrom os.path import join, exists, expanduser\n\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)\n!cp  ../input/inceptionv3/* ~/.keras/models/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b30c44303e5560674a213ae8ee409053f1a87f2","collapsed":true},"cell_type":"code","source":"from keras.applications.inception_v3 import preprocess_input, decode_predictions\nimport time\n\ncurrent_milli_time = lambda: int(round(time.time() * 1000))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbb61f8392e2a6813669c7659eb0ded25d76ff05"},"cell_type":"code","source":"from keras.preprocessing import image\nimg_path = \"../input/dogs-vs-cats-redux-kernels-edition/train/dog.4444.jpg\"\nimg = image.load_img(img_path, target_size=(224, 224))\nimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"944e8a95333ef7a5cd33acdf3bcc7c66a6848989"},"cell_type":"code","source":"img = image.img_to_array(img)\nimg = np.expand_dims(img, axis=0)\nimg = preprocess_input(img)\n\nstart = current_milli_time()\npreds = model.predict(img)\nend = current_milli_time()\nprint('Predicted in {} ms: {}'.format(end-start, decode_predictions(preds, top=3)[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58899ee64f6fc8bead14957e7fc7e891acfd1497"},"cell_type":"code","source":"from keras.preprocessing import image\nimg_path = \"../input/dogs-vs-cats-redux-kernels-edition/train/cat.5555.jpg\"\nimg = image.load_img(img_path, target_size=(224, 224))\nimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b816d5627b7d63883ffbe13419453d16730c7301"},"cell_type":"code","source":"img = image.img_to_array(img)\nimg = np.expand_dims(img, axis=0)\nimg = preprocess_input(img)\n\nstart = current_milli_time()\npreds = model.predict(img)\nend = current_milli_time()\nprint('Predicted in {} ms: {}'.format(end-start, decode_predictions(preds, top=3)[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caa1f0f4d97b46dc86088c4f6a0f3c9caad409ef"},"cell_type":"code","source":"from keras.preprocessing import image\nimg_path = \"../input/flowers-recognition/flowers/flowers/daisy/34539556222_f7ba32f704_n.jpg\"\nimg = image.load_img(img_path, target_size=(224, 224))\nimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f78e8150882cd0ed8c939aa407f4562c234a47a"},"cell_type":"code","source":"img = image.img_to_array(img)\nimg = np.expand_dims(img, axis=0)\nimg = preprocess_input(img)\n\nstart = current_milli_time()\npreds = model.predict(img)\nend = current_milli_time()\nprint('Predicted in {} ms: {}'.format(end-start, decode_predictions(preds, top=3)[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8261a3fdce3109632db141a35a13acd36da6ee6"},"cell_type":"code","source":"from keras.preprocessing import image\nimg_path = \"../input/flowers-recognition/flowers/flowers/rose/9609569441_eeb8566e94.jpg\"\nimg = image.load_img(img_path, target_size=(224, 224))\nimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9eb863072fc186f7735ed3bccf8d23ead6f411b9"},"cell_type":"code","source":"img = image.img_to_array(img)\nimg = np.expand_dims(img, axis=0)\nimg = preprocess_input(img)\n\nstart = current_milli_time()\npreds = model.predict(img)\nend = current_milli_time()\nprint('Predicted in {} ms: {}'.format(end-start, decode_predictions(preds, top=3)[0]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}