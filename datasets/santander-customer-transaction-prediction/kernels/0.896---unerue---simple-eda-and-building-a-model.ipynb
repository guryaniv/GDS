{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nfrom scipy import stats\n\nsns.set_style(style='white')\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nprint(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d86a9f50d73dc692812ee1b7b9ffe6361da2a140"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"792eedd805fc3750afe75f30a95b4f7ae803a275"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5a9a7b4c9b2389833bd570cc3225f07408e3fd7"},"cell_type":"code","source":"# Dependent variable = categorical\n# Independent variables = numerical or ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c331d3ef06de6e07731f82180f29d81404d58a6b"},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(5, 3), dpi=100)\ntrain['target'].value_counts().plot(kind='bar', ax=ax)\nfor p in ax.patches:\n    ax.annotate('{:,}'.format(p.get_height()), (p.get_x() + .13, p.get_height() + 3000),  fontsize=10)\n\nax.tick_params(axis='both', rotation=0, labelleft=False)\nax.set_ylim(0, 200000)\nax.grid(axis='y', linestyle='--')\nax.set_title('')\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cf6bc0a9f3903b8cc1a2e1aeb391a3d4123e371"},"cell_type":"code","source":"# Class imbalance\n# Too many columns, so we will not get much information at once.\nprint(len(train.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d673f7e5e6f7e656aba9263fdb645114ec39ce5d"},"cell_type":"markdown","source":"## Boxplot\n\nWe know that the dependent variable (target) is a binary, 0 and 1. It is a categorical value and I used a box plot to visualize it.\n\nI don't know what the original value on independent variable (features) is because it's pre-processed, but I think the its distribution is a numerical type."},{"metadata":{"trusted":true,"_uuid":"8846a3b570a741695db474d95e7fb3cf34f4df69"},"cell_type":"code","source":"melted1 = pd.melt(train.iloc[:, np.r_[1, 2:42]], id_vars='target')\nmelted2 = pd.melt(train.iloc[:, np.r_[1, 42:82]], id_vars='target')\nmelted3 = pd.melt(train.iloc[:, np.r_[1, 82:122]], id_vars='target')\nmelted4 = pd.melt(train.iloc[:, np.r_[1, 122:162]], id_vars='target')\nmelted5 = pd.melt(train.iloc[:, np.r_[1, 162:202]], id_vars='target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"542b231041a222f9de668a5d0c68841d4eb428ae"},"cell_type":"code","source":"fig, axes = plt.subplots(5, 1, figsize=(25, 15), dpi=100)\n\nfor i, df in enumerate([melted1, melted2, melted3, melted4, melted5]):\n    sns.boxplot(x='variable', y='value', hue='target', data=df, ax=axes.flat[i])\n    axes.flat[i].grid(axis='x', linestyle='--')\n    axes.flat[i].legend(loc='upper right', ncol=2, frameon=True)\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b53769e68410a94bd141c012bde5063b762d3673"},"cell_type":"markdown","source":"## ANOVA\n\nI just wanted to see the variance between groups by dividing one variable by 0 and 1.\n\nFor example, the \"var_0\" variable is divided into two based on the value of the target variable, and then compare the variances of the two groups generated."},{"metadata":{"trusted":true,"_uuid":"e3ede816779e5b4a7bd103823bc2cce25c12bc94"},"cell_type":"code","source":"# Statistical test\n# Check p-values\n# ANOVA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d485ef5a652379298a09cffa4c1d2ee443d39bc"},"cell_type":"code","source":"result = pd.DataFrame(columns=['var_names', 'p-values'])\nresult['var_names'] = train.columns[2:].tolist()\np_vals = []\nfor col in train.columns:\n    if col not in ['ID_code', 'target']:\n        _ = train.loc[:, ['target', col]].pivot(columns='target')\n        statics, p_value = stats.f_oneway(_.iloc[:,0].dropna(), _.iloc[:,1].dropna())\n        p_vals.append(p_value)\nresult['p-values'] = p_vals\nresult = result.assign(disparity=np.log(1./result['p-values'].values))\nresult.sort_values(by='disparity', ascending=False, inplace=True)\n\nfig, ax = plt.subplots(figsize=(5, 35), dpi=100)\nsns.barplot(y='var_names', x='disparity', data=result, color='lightsalmon', ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07fbca0f96c9d76f1f23050f670478412ee8b3a4"},"cell_type":"code","source":"print(len(train.columns))\nprint(len(result[result['p-values'] < 0.05]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"113d29f7444e517639f183ce9963c2d98fb92f61"},"cell_type":"markdown","source":"## Logistic Regression\n\nSince the independent variables are numeric and the dependent variables are categorical, statistical tests were performed using logistic regression."},{"metadata":{"trusted":true,"_uuid":"65b7494ea4f3b4a909041a738ab56af169ea883a"},"cell_type":"code","source":"logit_mod = sm.Logit(train['target'], train.iloc[:, 2:])\nlogit_res = logit_mod.fit(disp=0)\nprint(logit_res.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db732528369adb8e64a8b5a2033a09ec5b2dcb07"},"cell_type":"code","source":"variables = logit_res.pvalues[logit_res.pvalues < 0.05].index.tolist()\nprint(len(variables))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85e484afdb177761fe1217e1e74a822c4c777b78"},"cell_type":"markdown","source":"## Builing a simple model using LightGBM"},{"metadata":{"trusted":true,"_uuid":"b6854ebd41cfd36b56e1a3c2535a289ee281f75c"},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f46940afd9eb744d2335205e84ad83a14337b84f"},"cell_type":"code","source":"param = {\n    'num_leaves': 5,\n    'max_depth': 15,\n    'save_binary': True,\n    'seed': 42,\n    'objective': 'binary',\n    'boosting_type': 'gbdt',\n    'verbose': 1,\n    'metric': 'auc',\n    'is_unbalance': True,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11589c0f6352adac63b2f471f384c811a3a2b7d0"},"cell_type":"code","source":"train_preds = np.zeros(len(train))\ntest_preds = np.zeros(len(test))\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor train_index, valid_index in skf.split(train[variables], train['target']):\n    train_data = lgb.Dataset(train.loc[train_index, variables], \n                             label=train.loc[train_index, 'target'])\n    valid_data = lgb.Dataset(train.loc[valid_index, variables], \n                             label=train.loc[valid_index, 'target'])\n    \n    bst = lgb.train(param, train_data, num_boost_round=2000, valid_sets=valid_data, \n                    verbose_eval=500, early_stopping_rounds=30)\n    train_preds[valid_index] = bst.predict(train.loc[valid_index, variables], \n                                           num_iteration=bst.best_iteration)\n    test_preds += bst.predict(test[variables], num_iteration=bst.best_iteration) / 5\n\nprint('Accuracy {}'.format(accuracy_score(train['target'], np.where(train_preds > 0.5, 1, 0))))\nprint('ROC AUC Score: {}'.format(roc_auc_score(train['target'], train_preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c04fa8ae8f2e7c3cbf1239da19bd6669bd05ca1"},"cell_type":"code","source":"import itertools\n\nfig, ax = plt.subplots(figsize=(5,5), dpi=100)\nclasses = train.target.unique()\ncm = confusion_matrix(train.target, np.where(train_preds > 0.5, 1, 0))\ncs = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\nfig.colorbar(cs)\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes)\nplt.yticks(tick_marks, classes)\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    ax.text(j, i, format(cm[i, j]),\n            horizontalalignment='center',\n            color='white' if cm[i, j] > thresh else 'black')\nax.set_ylabel('True label')\nax.set_xlabel('Predicted label')\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08ff7bd75091862db8e6e8dacc3e402dfc9cd431"},"cell_type":"code","source":"submission = pd.DataFrame({'ID_code': test['ID_code'],\n                           'target': test_preds})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}