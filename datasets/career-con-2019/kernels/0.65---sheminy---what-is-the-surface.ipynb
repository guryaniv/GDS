{"cells":[{"metadata":{"_uuid":"242fd5bd6b392bbcbe89692f4f51a41b89dc84a1"},"cell_type":"markdown","source":"# Introduction\nIn this kernel I tried to make easy and fast way to get fine perfomance. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfrom tqdm import tqdm\nimport gc\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nfrom catboost import CatBoostClassifier, Pool, cv\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93cf43660bc6f42a3c7d632060e0a75867ef87cf"},"cell_type":"markdown","source":"# The Main Info\nAs we can see we have *train set *and *test set* almost same shape and In this case we see that classes imbalanced enough. "},{"metadata":{"trusted":true,"_uuid":"52a268d81d6f770a5ade9446362604655307e583","_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"print(\"Files in the input folder:\")\nprint(os.listdir(\"../input\"))\ntrain = pd.read_csv('../input/X_train.csv')\ntest = pd.read_csv('../input/X_test.csv')\ny = pd.read_csv('../input/y_train.csv')\nsub = pd.read_csv('../input/sample_submission.csv')\nprint(\"\\nX_train shape: {}, X_test shape: {}\".format(train.shape, test.shape))\nprint(\"y_train shape: {}\".format(y.shape))\ny[\"surface\"].value_counts().plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"adca1c7365768c6ef18e286571ffa500a9d86649"},"cell_type":"markdown","source":"# Feature Engineering\nThis part was taken from [Surface Recognition Baseline kernel](http://www.kaggle.com/jsaguiar/surface-recognition-baseline)."},{"metadata":{"trusted":true,"_uuid":"d19900514a26cd9b7368fa58ee0598c444a1761c"},"cell_type":"code","source":"def feature_extraction(raw_frame):\n    frame = pd.DataFrame()\n    raw_frame['angular_velocity'] = raw_frame['angular_velocity_X'] + raw_frame['angular_velocity_Y'] + raw_frame['angular_velocity_Z']\n    raw_frame['linear_acceleration'] = raw_frame['linear_acceleration_X'] + raw_frame['linear_acceleration_Y'] + raw_frame['linear_acceleration_Y']\n    raw_frame['velocity_to_acceleration'] = raw_frame['angular_velocity'] / raw_frame['linear_acceleration']\n    \n    for col in tqdm(raw_frame.columns[3:]):\n        frame[col + '_mean'] = raw_frame.groupby(['series_id'])[col].mean()\n        frame[col + '_std'] = raw_frame.groupby(['series_id'])[col].std()\n        frame[col + '_max'] = raw_frame.groupby(['series_id'])[col].max()\n        frame[col + '_min'] = raw_frame.groupby(['series_id'])[col].min()\n        frame[col + '_max_to_min'] = frame[col + '_max'] / frame[col + '_min']\n        \n        frame[col + '_mean_abs_change'] = raw_frame.groupby('series_id')[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        frame[col + '_abs_max'] = raw_frame.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n    return frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a05d09f41d4dd17aa91c29a913c72a58d277dcd"},"cell_type":"code","source":"%%time\ntrain_df = feature_extraction(train)\ntest_df = feature_extraction(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"987e3071cbaaa00aa9d4a14a4c6227a2883927b9"},"cell_type":"markdown","source":"# Data preparing\nHere we are encoding labels to numeric values and split into validation and train set. For all of this we use **LabelEncoder** and **train_test_split** from **Scikit-learn**."},{"metadata":{"trusted":true,"_uuid":"71b0097b914779d46c36d209aac0bcd3d731427a"},"cell_type":"code","source":"Y = y[\"surface\"].values\nlbe = LabelEncoder().fit(Y)\nY = lbe.transform(Y)\nX = train_df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cd7438a9023ed9bf87364bed87cb3a1b7f22a0b"},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\ninp = Pool(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_uuid":"1d0c33f1d3aa1b73c7a6b7aff4b809af83d00482"},"cell_type":"markdown","source":"# Model and Prediction\nIn this case we use **CatBoostClassifier** which evalute by simple **Accuracy** optimized via **MultiClass loss function** with **early stopping**.\n(about all CatBoost metrics you can read [here](https://tech.yandex.com/catboost/doc/dg/concepts/loss-functions-docpage/#loss-functions))"},{"metadata":{"trusted":true,"_uuid":"6f33b532377d911b7555722e5453187414fec636"},"cell_type":"code","source":"%%time\nmodel = CatBoostClassifier(\n    loss_function='MultiClass',\n    eval_metric='Accuracy',\n    learning_rate=0.03,\n    task_type=\"GPU\",\n    iterations=100000,\n    random_seed=42,\n    od_type='Iter',\n    early_stopping_rounds=400,\n    verbose=0\n)\nmodel.fit(inp, eval_set=(X_val, y_val))\nprint('Validation: ', model.get_best_score()['validation_0'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8701423735096d907c15eaee4eaacba4583b06a9"},"cell_type":"code","source":"pred = lbe.inverse_transform(model.predict(test_df.values).reshape(-1).astype(int))\nsub.surface = pred\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}