{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a7e4fe69-5bec-f07e-0958-81d3b701e9ae"
      },
      "source": [
        "Get data in, clean up, simple distance measure. Note: Neural Nets would likely be a good solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "94c90fd8-1f29-c734-71b8-7a33d87ea51f"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import warnings\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from Levenshtein import *\n",
        "from nltk.corpus import *\n",
        "from nltk import ChartParser\n",
        "from subprocess import check_output\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6a769f07-aa90-2329-b171-ce4f545a39ce"
      },
      "source": [
        "Read input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d021cbc8-69ce-c06f-d2d5-08758cedb41b"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('../input/test.csv', encoding='ISO-8859-1').fillna(\"\")\n",
        "train = pd.read_csv('../input/train.csv', encoding ='ISO-8859-1').fillna(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "15592c91-1321-02d6-ffd3-9e7900fa2d55"
      },
      "source": [
        "For testing, cut down size of test and train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9402ec73-82f7-9242-85b2-3085f605cac8"
      },
      "outputs": [],
      "source": [
        "\n",
        "unique_ids1 = train['id'].unique()\n",
        "rand_ids1 = [unique_ids1[i] for i in sorted(random.sample(range(len(unique_ids1)), 1000)) ]\n",
        "train = train[train.id.isin(rand_ids1)]\n",
        "\n",
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2a3aea4e-2027-befa-7300-9fb4e6835de7"
      },
      "outputs": [],
      "source": [
        "unique_ids2 = test['test_id'].unique()\n",
        "rand_ids2 = [unique_ids2[i] for i in sorted(random.sample(range(len(unique_ids2)), 1000)) ]\n",
        "test = test[test.test_id.isin(rand_ids2)]\n",
        "\n",
        "test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "228209b2-5c9c-5e24-98c0-b8ad1f146be1"
      },
      "source": [
        "Get stopwords, to remove."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0fba178b-7902-4d9f-35e5-10e89a491f08"
      },
      "outputs": [],
      "source": [
        "\n",
        "stopwords = stopwords.words('english')\n",
        "print(stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4f212af6-96b2-c109-f672-b7bca25ead3c"
      },
      "source": [
        "Check test and train now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e2e873b4-e52d-5666-9da0-70d068e99a12"
      },
      "outputs": [],
      "source": [
        "test.info()\n",
        "\n",
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1acb9373-a69c-1bb6-7108-2f3294e77404"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3efd78dc-691b-b8d2-0236-446b45d3f3e9"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cd092eb7-1e27-2a79-3f0f-12200342246d"
      },
      "source": [
        "Plot for duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "80ff991d-f902-d1f6-f05f-8843dc9f89de"
      },
      "outputs": [],
      "source": [
        "train.groupby(\"is_duplicate\")['id'].count().plot.bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "80bda22f-5d2c-6acf-d606-21e18fea1910"
      },
      "source": [
        "Remove all special characters, split by spaces, and remove stopword entries in list for train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f042fa95-f1f1-e0ee-f617-666c6d2a80eb"
      },
      "outputs": [],
      "source": [
        "train = train.dropna()              \n",
        "train['question1'] = train['question1'].apply(lambda x: x.rstrip('?'))\n",
        "train['question2'] = train['question2'].apply(lambda x: x.rstrip('?'))\n",
        "train['question1'] = train['question1'].str.lower().str.split(' ')\n",
        "train['question2'] = train['question2'].str.lower().str.split(' ')\n",
        "train['question1'] = train['question1'].apply(lambda x: [item for item in x if item not in stopwords])\n",
        "train['question2'] = train['question2'].apply(lambda x: [item for item in x if item not in stopwords])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3d06667e-87da-55fd-770b-4142742c5ef0"
      },
      "outputs": [],
      "source": [
        "#test = test.dropna()     \n",
        "test['question1'] = test['question1'].apply(lambda x: x.rstrip('?'))\n",
        "test['question2'] = test['question2'].apply(lambda x: x.rstrip('?'))\n",
        "test['question1'] = test['question1'].str.lower().str.split(' ')\n",
        "test['question2'] = test['question2'].str.lower().str.split(' ')\n",
        "test['question1'] = test['question1'].apply(lambda x: [item for item in x if item not in stopwords])\n",
        "test['question2'] = test['question2'].apply(lambda x: [item for item in x if item not in stopwords])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "600d4286-1d6e-2672-839c-ad44b874dc79"
      },
      "source": [
        "Get features, len, common word count, percentage of common words, seqratio similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3b2d19cc-f191-c709-ee79-3220c614d399"
      },
      "outputs": [],
      "source": [
        "train['Common'] = train.apply(lambda row: len(list(set(row['question1']).intersection(row['question2']))), axis=1)\n",
        "test['Common'] = test.apply(lambda row: len(list(set(row['question1']).intersection(row['question2']))), axis=1)\n",
        "\n",
        "train['Average'] = train.apply(lambda row: 0.5*(len(row['question1'])+len(row['question2'])), axis=1)\n",
        "test['Average'] = test.apply(lambda row: 0.5*(len(row['question1'])+len(row['question2'])), axis=1)\n",
        "\n",
        "train['Percentage'] = train.apply(lambda row: row['Common'] * 100.0 / (row['Average'] + 1), axis=1)\n",
        "test['Percentage'] = test.apply(lambda row: 1 if row['Average'] == 0 else row['Common']/(row['Average']), axis=1)\n",
        "\n",
        "train['seqratio'] = train.apply(lambda row: seqratio(row['question1'], row['question2']) * 100.0, axis=1)\n",
        "test['seqratio'] = test.apply(lambda row: seqratio(row['question1'], row['question2']) * 100.0, axis=1)\n",
        "\n",
        "train['avg2'] = train.apply(lambda row: (row['seqratio'] + row['Percentage']) / 200.0, axis=1)\n",
        "test['avg2'] = test.apply(lambda row: (row['seqratio'] + row['Percentage']) / 200.0, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f1aee1ae-0b4d-5b4d-33c9-c894506d1afe"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1e57ac7c-db25-ea1a-d887-5cea8dad77ea"
      },
      "source": [
        "Check correlations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1785826c-df63-a0d9-1def-69bdb6341ee8"
      },
      "outputs": [],
      "source": [
        "train.corr()['is_duplicate']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ed2acbe7-9df1-0dbd-04cf-bbbb4cb0b70d"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Check these for later\n",
        "#dfTrain = pd.DataFrame({'test_id' : range(0,2345796)})\n",
        "#dfTest = pd.DataFrame({'test_id' : range(0,2345796)})\n",
        "#dfTrain[['Common', 'Average', 'Percentage', 'seqratio', 'avg2']] = scaler.fit_transform(train[['Common', 'Average', 'Percentage', 'seqratio', 'avg2']])\n",
        "#dfTest[['Common', 'Average', 'Percentage', 'seqratio', 'avg2']] = scaler.fit_transform(test[['Common', 'Average', 'Percentage', 'seqratio', 'avg2']])\n",
        "\n",
        "#df = pd.DataFrame({'test_id' : range(0,2345796)})\n",
        "#df.fillna(0, inplace = True)\n",
        "#df['is_duplicate'] = pd.Series(test['avg2'])\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler().fit(train[['Common', 'Average', 'Percentage', 'seqratio', 'avg2']])\n",
        "\n",
        "X = scaler.transform(train[['Common', 'Average', 'Percentage', 'seqratio', 'avg2']])\n",
        "y = train['is_duplicate']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "clf = LogisticRegression()\n",
        "grid = {\n",
        "    'C': [1e-6, 1e-3, 1e0],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "cv = GridSearchCV(clf, grid, scoring='neg_log_loss', n_jobs=-1, verbose=1)\n",
        "cv.fit(X_train, y_train)\n",
        "\n",
        "retrained = cv.best_estimator_.fit(X, y)\n",
        "\n",
        "scaler = MinMaxScaler().fit(test[['Common', 'Average', 'Percentage', 'seqratio', 'avg2']])\n",
        "\n",
        "X_submission = scaler.transform(test[['Common', 'Average', 'Percentage', 'seqratio', 'avg2']])\n",
        "y_submission = retrained.predict_proba(X_submission)[:,1]\n",
        "\n",
        "dftest = pd.read_csv(\"../input/test.csv\").fillna(\"\")\n",
        "submission = pd.DataFrame({'test_id': dftest['test_id'], 'is_duplicate': y_submission})\n",
        "submission.head()\n",
        "\n",
        "print(submission.shape)\n",
        "submission.to_csv('submit.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "36aa7177-a8fd-bcde-54ea-3f893ded1680"
      },
      "outputs": [],
      "source": [
        "submission.head(10)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}