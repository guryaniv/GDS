{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Modeling\nimport lightgbm as lgb\n\nMAX_EVALS = 500\nN_FOLDS = 10\n\nimport matplotlib.pyplot as plt\nimport pandas as pd \nimport numpy as np\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nnp.random.seed(203)\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\nfrom matplotlib import pyplot as plt\nfrom timeit import default_timer as timer\n\nimport random\n\n#Suppress warnings from pandas\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('fivethirtyeight')\n\n# Memory management\nimport gc \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edc5707990f31aa6b429d1ac0dded846202b17a2"},"cell_type":"markdown","source":"**Credits**:\n* [Start Here: A Gentle Introduction e1d8c7](https://www.kaggle.com/thaer2018/start-here-a-gentle-introduction-e1d8c7/edit)\n* [WillKoehrsen: Hyperparameter Optimization](https://github.com/WillKoehrsen/hyperparameter-optimization/blob/master/Bayesian%20Hyperparameter%20Optimization%20of%20Gradient%20Boosting%20Machine.ipynb)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ca2ca551c92be463bee857b7cbc5b1c1f5163a5"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fb01c9589cd557e9c119b39d600a3a2bf18ac0f"},"cell_type":"code","source":"test_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8d75cfa14d99ea6b4eab6a437ceb27b24d300ec"},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73137c297c74f34736c5c67d330123c0a9516e76"},"cell_type":"code","source":"# Function to calculate missing values by column# Funct \ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"468f2d8f42fa561839d749caf8d94d4bec4035a6"},"cell_type":"code","source":"# Missing values statistics\nmissing_values = missing_values_table(train_df)\nmissing_values.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf94e5199fb14c09591efb3cbecb14ebe8dfb143"},"cell_type":"code","source":"# Missing values statistics\nmissing_values = missing_values_table(test_df)\nmissing_values.head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"190d6c4634c94dfdf2d58ec15f7ab73acb2299b5"},"cell_type":"markdown","source":"The only 'object' type column is the Customer Index."},{"metadata":{"trusted":true,"_uuid":"870a413a73f05822a3d8b59a21d7ab5b9d73167c"},"cell_type":"code","source":"# Number of each type of column\ntrain_df.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d50c8e82a58a693833a8659a3efc9a68a32e10e4"},"cell_type":"code","source":"X_train, y_train = train_test_split(train_df, test_size=0.2)\n\n# Extract the labels and format properly\ntrain_labels = np.array(X_train['target'].astype(np.int32)).reshape((-1,))\ntest_labels = np.array(y_train['target'].astype(np.int32)).reshape((-1,))\n\n# Drop the unneeded columns\ntrain = X_train.drop(columns = ['ID_code', 'target'])\ntest = y_train.drop(columns = ['ID_code','target'])\n\n# Convert to numpy array for splitting in cross validation\nfeatures = np.array(train)\ntest_features = np.array(test)\nlabels = train_labels[:]\n\nprint('Train shape: ', train.shape)\nprint('Test shape: ', test.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d567f4a98d73007b402729faa3e2f734e29464a7"},"cell_type":"code","source":"plt.hist(labels, edgecolor = 'k'); \nplt.xlabel('Label'); plt.ylabel('Count'); plt.title('Counts of Labels');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f80244c858714e4834c6be9f32701e883d71fde7"},"cell_type":"code","source":"# Model with default hyperparameters\nmodel = lgb.LGBMClassifier()\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"817f4f7d059aa948ddf34f044cc7c3c7f788bbc3"},"cell_type":"code","source":"start = timer()\nmodel.fit(features, labels)\ntrain_time = timer() - start\n\npredictions = model.predict_proba(test_features)[:, 1]\nauc = roc_auc_score(test_labels, predictions)\n\nprint('The baseline score on the test set is {:.4f}.'.format(auc))\nprint('The baseline training time is {:.4f} seconds'.format(train_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cd556e6d8c36c674ae4812b19be6bc3af6fd388"},"cell_type":"code","source":"# Hyperparameter grid\nparam_grid = {\n    'class_weight': [None, 'balanced'],\n    'boosting_type': ['gbdt', 'goss', 'dart'],\n    'num_leaves': list(range(30, 150)),\n    'learning_rate': list(np.logspace(np.log(0.005), np.log(0.2), base = np.exp(1), num = 1000)),\n    'subsample_for_bin': list(range(20000, 300000, 20000)),\n    'min_child_samples': list(range(20, 500, 5)),\n    'reg_alpha': list(np.linspace(0, 1)),\n    'reg_lambda': list(np.linspace(0, 1)),\n    'colsample_bytree': list(np.linspace(0.6, 1, 10))\n}\n\n# Subsampling (only applicable with 'goss')\nsubsample_dist = list(np.linspace(0.5, 1, 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c736ee257a9ec3beb08be981f3e5199c644d63e9"},"cell_type":"code","source":"plt.hist(param_grid['learning_rate'], color = 'r', edgecolor = 'k');\nplt.xlabel('Learning Rate', size = 14); plt.ylabel('Count', size = 14); plt.title('Learning Rate Distribution', size = 18);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69b345a97903c60f232070359956e3047e36e1a5"},"cell_type":"code","source":"# Randomly sample parameters for gbm\nparams = {key: random.sample(value, 1)[0] for key, value in param_grid.items()}\nparams","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d532f0bfb8ffe37ad98060eb5b1a46c48c573343"},"cell_type":"code","source":"params['subsample'] = random.sample(subsample_dist, 1)[0] if params['boosting_type'] != 'goss' else 1.0\nparams","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5017766c08bb77a6a6f50dd934180ae13d4cac09"},"cell_type":"code","source":"#Create a lgb dataset\ntrain_set = lgb.Dataset(features, label = labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be0aa3bee224dd3820ec88af0a523e2bf0aeed72"},"cell_type":"code","source":"# Perform cross validation with 10 folds\nr = lgb.cv(params, train_set, num_boost_round = 10000, nfold = 10, metrics = 'auc', \n           early_stopping_rounds = 100, verbose_eval = False, seed = 50)\n\n# Highest score\nr_best = np.max(r['auc-mean'])\n\n# Standard deviation of best score\nr_best_std = r['auc-stdv'][np.argmax(r['auc-mean'])]\n\nprint('The maximium ROC AUC on the validation set was {:.5f} with std of {:.5f}.'.format(r_best, r_best_std))\nprint('The ideal number of iterations was {}.'.format(np.argmax(r['auc-mean']) + 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"955a6b21cc038713efb685905aa6f0dbb7012d0f"},"cell_type":"code","source":"# Dataframe to hold cv results\nrandom_results = pd.DataFrame(columns = ['loss', 'params', 'iteration', 'estimators', 'time'],\n                       index = list(range(MAX_EVALS)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee546c24a0dc4f2609fd990d79525478f995ba32"},"cell_type":"code","source":"def random_objective(params, iteration, n_folds = N_FOLDS):\n    \"\"\"Random search objective function. Takes in hyperparameters\n       and returns a list of results to be saved.\"\"\"\n\n    start = timer()\n    \n    # Perform n_folds cross validation\n    cv_results = lgb.cv(params, train_set, num_boost_round = 10000, nfold = n_folds, \n                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n    end = timer()\n    best_score = np.max(cv_results['auc-mean'])\n    \n    # Loss must be minimized\n    loss = 1 - best_score\n    \n    # Boosting rounds that returned the highest cv score\n    n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n    \n    # Return list of results\n    return [loss, params, iteration, n_estimators, end - start]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14165288e76e1d21aba8319ab64991a1640806d2"},"cell_type":"code","source":"%%capture\n\nrandom.seed(50)\n\n# Iterate through the specified number of evaluations\nfor i in range(MAX_EVALS):\n    \n    # Randomly sample parameters for gbm\n    params = {key: random.sample(value, 1)[0] for key, value in param_grid.items()}\n    \n    print(params)\n    \n    if params['boosting_type'] == 'goss':\n        # Cannot subsample with goss\n        params['subsample'] = 1.0\n    else:\n        # Subsample supported for gdbt and dart\n        params['subsample'] = random.sample(subsample_dist, 1)[0]\n        \n        \n    results_list = random_objective(params, i)\n    \n    # Add results to next row in dataframe\n    random_results.loc[i, :] = results_list","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}