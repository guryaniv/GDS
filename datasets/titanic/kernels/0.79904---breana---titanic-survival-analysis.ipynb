{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d7b4f5bd-c438-21cf-b149-31ebcfe61c70"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "titanic=pd.read_csv(\"../input/train.csv\")\n",
        "titanic_test=pd.read_csv(\"../input/test.csv\")\n",
        "\n",
        "titanic.head()\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "64a07246-ec14-d683-2f95-4f294c2c209c"
      },
      "outputs": [],
      "source": [
        "#Let's look at the data\n",
        "titanic.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1f7084ff-f8c7-0f1e-ab24-5fc89177339a"
      },
      "outputs": [],
      "source": [
        "#Age has some missing values (count=714, all other counts=891)\n",
        "#We can use the median age to fill in the missing values\n",
        "\n",
        "titanic[\"Age\"]=titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
        "\n",
        "#Let looks at the values again to see what is looks like now\n",
        "titanic.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d4def7e8-d051-f3c3-f590-957a3b59e102"
      },
      "outputs": [],
      "source": [
        "#Convert Character variables to numeric \n",
        "#Characters varaibles include: Name, Sex, Ticket, Cabin and Embarked\n",
        "#We will not use name, ticket and cabin in our prediction so we can ignore those ones for now\n",
        "\n",
        "#lets convert Sex to numeric by assinging all 'male' values to the number 0 and all  'female' values to the number 1\n",
        "titanic.loc[titanic['Sex']=='male','Sex']=0\n",
        "titanic.loc[titanic['Sex']=='female','Sex']=1\n",
        "\n",
        "#Now lets conver 'Embarked' to numeric\n",
        "#Embarked has some missing values so we need to deal with those first. S is the most common embarked locations so we will assume all missing values are S\n",
        "titanic['Embarked']=titanic['Embarked'].fillna('S')\n",
        "\n",
        "#Now we will convert 'Embarked' to numeric:\n",
        "#S=0\n",
        "#C=1\n",
        "#Q=2\n",
        "titanic.loc[titanic['Embarked']=='S','Embarked']=0\n",
        "titanic.loc[titanic['Embarked']=='C','Embarked']=1\n",
        "titanic.loc[titanic['Embarked']=='Q','Embarked']=2\n",
        "print(titanic['Embarked'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cca78fca-900e-0ab2-5fd7-738e058d4508"
      },
      "outputs": [],
      "source": [
        "#Build a Linear Regression Model\n",
        "#Import linear regression class from sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#import the sklearn helper for cross validation\n",
        "from sklearn.cross_validation import KFold\n",
        "\n",
        "#Determine what the predictors will be:\n",
        "predictors=['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "\n",
        "#Initalize the algorithm class\n",
        "alg=LinearRegression()\n",
        "\n",
        "#Create cross Validation folds for the train dataset\n",
        "\n",
        "#Set random_state to ensure we get the same splits every time we run this\n",
        "\n",
        "kf=KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
        "\n",
        "predictions=[]\n",
        "for train, test in kf:\n",
        "    #The predictors from our new training dataset\n",
        "    train_predictors=(titanic[predictors].iloc[train,:])\n",
        "    #The target variables we're using for our algorithm\n",
        "    train_target=titanic[\"Survived\"].iloc[train]\n",
        "\n",
        "    #Now lets train the algorithm with our predictors and target\n",
        "    alg.fit(train_predictors, train_target)\n",
        "\n",
        "    \n",
        "    #Now we can make predictions on our new test dataset\n",
        "    test_predictions=alg.predict(titanic[predictors].iloc[test,:])\n",
        "    predictions.append(test_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3d959628-8fe2-973a-f0e7-b611f088af15"
      },
      "outputs": [],
      "source": [
        "#Define error metric, we'll use percentage of correct predictions\n",
        "\n",
        "#we need to concatenate are 3 numpy array for predictions\n",
        "predictions=np.concatenate(predictions, axis=0)\n",
        "\n",
        "#We need the predictions to be 0 or 1\n",
        "predictions[predictions>0.5]=1\n",
        "predictions[predictions<=0.5]=0\n",
        "\n",
        "#Calculate accuracy\n",
        "accuracy=sum(predictions[predictions==titanic[\"Survived\"]])/len(predictions)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c15d659-fe05-0c1f-4ba5-d4585b045cf4"
      },
      "outputs": [],
      "source": [
        "#Our accuracy is not very good in our first model (78.3%)\n",
        "#Lets try using logistic regression to output values between 0 and 1\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#Import the cross validation package\n",
        "from sklearn import cross_validation\n",
        "\n",
        "#initalize our algorithm\n",
        "alg=LogisticRegression(random_state=1)\n",
        "\n",
        "#compute the accuracy score for all the cross validation fold\n",
        "\n",
        "scores=cross_validation.cross_val_score(alg,titanic[predictors],titanic[\"Survived\"], cv=3)\n",
        "\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9afd0c36-650b-b936-4597-af87a9b3856d"
      },
      "outputs": [],
      "source": [
        "#Now we need to repeat the steps above on the titanic_test data set to submit our predictions\n",
        "\n",
        "#Fill missing age with median age from Titanic Dataset\n",
        "titanic_test['Age']=titanic_test['Age'].fillna(titanic['Age'].median())\n",
        "\n",
        "#Convert Sex to numeric\n",
        "titanic_test.loc[titanic_test['Sex']=='male','Sex']=0\n",
        "titanic_test.loc[titanic_test['Sex']=='female','Sex']=1\n",
        "\n",
        "#fill missing Embarked data with S\n",
        "titanic_test['Embarked']=titanic_test['Embarked'].fillna('S')\n",
        "\n",
        "#Convert Embarked to numeric\n",
        "titanic_test.loc[titanic_test['Embarked']=='S', 'Embarked']=0\n",
        "titanic_test.loc[titanic_test['Embarked']=='C', 'Embarked']=1\n",
        "titanic_test.loc[titanic_test['Embarked']=='Q', 'Embarked']=2\n",
        "\n",
        "#The test dataset has a missing Fare so we will use the median of Titanic_test fares\n",
        "titanic_test['Fare']=titanic_test['Fare'].fillna(titanic_test['Fare'].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "159e6ea9-c6de-110c-515b-6e04801ee9dd"
      },
      "outputs": [],
      "source": [
        "#Now we just build an algorithm on the training data and make predictions on the test data\n",
        "\n",
        "#Initalize the algorithm\n",
        "alg=LogisticRegression(random_state=1)\n",
        "\n",
        "#Train the algorithm using all the training data\n",
        "alg.fit(titanic[predictors],titanic[\"Survived\"])\n",
        "\n",
        "#And make the predictions on the test data\n",
        "predictions=alg.predict(titanic_test[predictors])\n",
        "\n",
        "#Create a datafram with only the passangerID and Survived\n",
        "\n",
        "submission=pd.DataFrame({\n",
        "    \"PassengerId\":titanic_test[\"PassengerId\"],\n",
        "    \"Survived\":predictions\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bfbeda0f-6b03-4f02-b700-05cdfb447f0b"
      },
      "outputs": [],
      "source": [
        "#Our Logisitc Regression accuracy was not great (~75%), so lets try to improve our model\n",
        "\n",
        "#import sklearn random forest implementation\n",
        "from sklearn import cross_validation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "predictors=['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "\n",
        "#Initialize are algorthm w/defaul parameters:\n",
        "    #n_estimators is the number of trees we want to make\n",
        "    #min_samples_split is the minimum number of rows we need to make a split\n",
        "    #min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\n",
        "    \n",
        "alg=RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2)\n",
        "    \n",
        "#Make cross validations predictions\n",
        "scores=cross_validation.cross_val_score(alg,titanic[predictors],titanic['Survived'],cv=3)\n",
        "    \n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5171913e-5315-d8a7-e63e-1afbfbac032b"
      },
      "outputs": [],
      "source": [
        "#Lets add some additional Variables to see if we can improve our model:\n",
        "\n",
        "titanic['FamilySize']=titanic['SibSp']+titanic['Parch']\n",
        "\n",
        "#Length of name could imply how wealthy someone is\n",
        "titanic['NameLength']=titanic['Name'].apply(lambda x: len(x))\n",
        "\n",
        "#Use a regular expression to extract titles from name:\n",
        "import re\n",
        "\n",
        "#Create a function to search names for titles\n",
        "def get_title(name):\n",
        "    title_search=re.search(' ([A-za-z]+)\\.', name)\n",
        "    #If a title is found extract it and return it\n",
        "    if title_search:\n",
        "        return title_search.group(1)\n",
        "    return \"\"\n",
        "\n",
        "titles=titanic[\"Name\"].apply(get_title)\n",
        "\n",
        "\n",
        "#Map each title to an integer so we can include it in our model, some titles are rare and were grouped with other titels:\n",
        "title_mapping={'Mr':1,'Miss':2, 'Mrs':3,'Master':4,'Dr':5,'Rev':6,'Major':7,'Col':8,'Mlle':8,'Mme':8,\n",
        "               'Don':9,'Lady':10,'Countess':10,'Jonkheer':10,'Sir':9,'Capt':7,'Ms':2}\n",
        "\n",
        "for k,v in title_mapping.items():\n",
        "    titles[titles==k]=v\n",
        "    \n",
        "print(pd.value_counts(titles))\n",
        "\n",
        "titanic[\"Title\"]=titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06ad4a6c-f501-6d6d-9745-efe7faae5111"
      },
      "outputs": [],
      "source": [
        "#A persons survival might have been influenced by if their family members survived, we can use last name and familysize to get a unique familyID variable\n",
        "\n",
        "import operator\n",
        "\n",
        "#A dictionary mapping family name to id\n",
        "family_id_mapping={}\n",
        "\n",
        "#A function to get the id given a row\n",
        "def get_family_id(row):\n",
        "    last_name=row[\"Name\"].split(\",\")[0]\n",
        "    family_id=\"{0}{1}\".format(last_name, row['FamilySize'])\n",
        "    \n",
        "    #We can now lookup a family ID in the mapping\n",
        "    if family_id not in family_id_mapping:\n",
        "        if len(family_id_mapping)==0:\n",
        "            current_id=1\n",
        "        else:\n",
        "            current_id=(max(family_id_mapping.items(), key=operator.itemgetter(1))[1]+1)\n",
        "        family_id_mapping[family_id]=current_id\n",
        "    return family_id_mapping[family_id]\n",
        "\n",
        "family_ids=titanic.apply(get_family_id,axis=1)\n",
        "\n",
        "#compress all families smaller than 3 into 1 code\n",
        "family_ids[titanic['FamilySize']<3]=-1\n",
        "\n",
        "titanic['FamilyId']=family_ids\n",
        "\n",
        "print(pd.value_counts(family_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d20af24c-27f3-2163-6c37-cadb81ae2d3e"
      },
      "outputs": [],
      "source": [
        "#feature selection is an important part of model building\n",
        "#We can use univariate feature selection to help determine which columns correlate most closely with what we're trying to predict(Survived)\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "#Lets update our predictors first\n",
        "predictors=['Pclass', 'Sex','Age','SibSp','Parch','Fare','Embarked','FamilySize','Title','FamilyId']\n",
        "\n",
        "#Perform feature selection\n",
        "selector=SelectKBest(f_classif,k=5)\n",
        "selector.fit(titanic[predictors],titanic[\"Survived\"])\n",
        "\n",
        "#Get p-values for each selector\n",
        "scores=-np.log10(selector.pvalues_)\n",
        "\n",
        "#plot the scores\n",
        "import matplotlib.pyplot as plt\n",
        "plt.bar(range(len(predictors)),scores)\n",
        "plt.xticks(range(len(predictors)),predictors,rotation='vertical')\n",
        "plt.show()\n",
        "\n",
        "#Lets build the model with the 4 best predictors\n",
        "predictors=['Pclass','Sex','Fare','Title']\n",
        "\n",
        "alg=RandomForestClassifier(random_state=1,n_estimators=150,min_samples_split=8, min_samples_leaf=4)\n",
        "\n",
        "scores=cross_validation.cross_val_score(alg,titanic[predictors],titanic[\"Survived\"],cv=3)\n",
        "\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dd735bf0-a7b6-ee17-0745-bcaa8b5fc26e"
      },
      "outputs": [],
      "source": [
        "#Gradient boosting classifier builds on decisions trees, this method uses the error from previous trees to build new trees\n",
        "#This method can lead to overfitting, you can help this by limiting the number of trees and the tree depth\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "algorithms= [\n",
        "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3),[\"Pclass\",\"Sex\",\"Age\",\"Fare\",\"Embarked\",\"FamilySize\",\"Title\",\"FamilyId\"]],\n",
        "[LogisticRegression(random_state=1),[\"Pclass\",\"Sex\",\"Fare\",\"FamilySize\",\"Title\",\"Age\",\"Embarked\"]]\n",
        "]\n",
        "\n",
        "#Initialize the cross validation folds\n",
        "kf=KFold(titanic.shape[0],n_folds=3,random_state=1)\n",
        "\n",
        "predictions=[]\n",
        "for train, test in kf:\n",
        "    train_target=titanic[\"Survived\"].iloc[train]\n",
        "    full_test_predictions=[]\n",
        "    for alg, predictors in algorithms:\n",
        "        alg.fit(titanic[predictors].iloc[train,:],train_target)\n",
        "        test_predictions=alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
        "        full_test_predictions.append(test_predictions)\n",
        "    test_predictions=(full_test_predictions[0]+full_test_predictions[1])/2\n",
        "    test_predictions[test_predictions<=.5]=0\n",
        "    test_predictions[test_predictions>.5]=1\n",
        "    predictions.append(test_predictions)\n",
        "        \n",
        "predictions=np.concatenate(predictions,axis=0)\n",
        "\n",
        "accuracy=sum(predictions[predictions==titanic[\"Survived\"]])/len(predictions)\n",
        "\n",
        "print(accuracy)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3adc3341-1ea1-1ad3-e16c-6bb550e24608"
      },
      "outputs": [],
      "source": [
        "#Now we need to add the variables we created to our test set so we can run the predictions on it\n",
        "\n",
        "titles=titanic_test[\"Name\"].apply(get_title)\n",
        "\n",
        "title_mapping['Dona']=10\n",
        "print(title_mapping)\n",
        "\n",
        "for k,v in title_mapping.items():\n",
        "    titles[titles==k]=v\n",
        "titanic_test[\"Title\"]=titles\n",
        "\n",
        "print(pd.value_counts(titanic_test['Title']))\n",
        "\n",
        "titanic_test[\"FamilySize\"]=titanic_test['SibSp']+titanic_test['Parch']\n",
        "\n",
        "print(family_id_mapping)\n",
        "\n",
        "family_ids=titanic_test.apply(get_family_id,axis=1)\n",
        "family_ids[titanic_test[\"FamilySize\"]<3]=-1\n",
        "titanic_test[\"FamilyId\"]=family_ids\n",
        "\n",
        "titanic_test['NameLength']=titanic_test['Name'].apply(lambda x : len(x))\n",
        "\n",
        "print(titanic_test[\"NameLength\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "43697711-4312-5ce2-48a9-0e5e6c41e8a1"
      },
      "outputs": [],
      "source": [
        "#Now lets make our predictions on the test dataset and create a submission dataframe\n",
        "predictors=['Pclass','Sex','Age','Fare','Embarked','FamilySize','Title','FamilyId']\n",
        "\n",
        "algorithms=[\n",
        "    [GradientBoostingClassifier(random_state=1,n_estimators=25, max_depth=3),predictors],\n",
        "    [LogisticRegression(random_state=1),['Pclass','Sex','Fare','FamilySize','Title','Age','Embarked']]\n",
        "]\n",
        "\n",
        "full_predictions=[]\n",
        "for alg, predictors in algorithms:\n",
        "    alg.fit(titanic[predictors],titanic[\"Survived\"])\n",
        "    predictions=alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
        "    full_predictions.append(predictions)\n",
        "    \n",
        "predictions=(full_predictions[0]*3+full_predictions[1])/4\n",
        "predictions[predictions<=.5]=0\n",
        "predictions[predictions>.5]=1\n",
        "predictions=predictions.astype(int)\n",
        "\n",
        "submission=pd.DataFrame({\n",
        "    \"PassengerId\": titanic_test[\"PassengerId\"],\n",
        "    \"Survived\":predictions\n",
        "})\n",
        "submission.to_csv(\"submission.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a7ff9075-d879-e5ae-a30b-fed5f48739cd"
      },
      "outputs": [],
      "source": [
        "#Looking for ways to improve the model\n",
        "titanic.head(40)\n",
        "Families=titanic[titanic['FamilySize']>3]\n",
        "cabin=titanic[titanic['Cabin'].notnull()]\n",
        "cabin.head(100)\n",
        "Fortune=titanic[titanic['']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "af70bc57-cf80-3b8d-1b03-c7df7966e291"
      },
      "outputs": [],
      "source": [
        "#Trying to improve the model with additiona Features:\n",
        "\n",
        "#Cabin Features\n",
        "\n",
        "#number of women in family\n",
        "\n",
        "#National origin of Last name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eabcbb9c-6eda-8f05-9163-e8dcad867246"
      },
      "outputs": [],
      "source": [
        "#Trying to imporve the model itself:\n",
        "\n",
        "#try randomforest classifier in the ensemble\n",
        "\n",
        "#Support Vector Machine\n",
        "\n",
        "#Neural networks\n",
        "\n",
        "#Boosting with different base classifier\n",
        "algorithms= [\n",
        "    [GradientBoostingClassifier(random_state=1, n_estimators=30, max_depth=3),[\"Pclass\",\"Sex\",\"Age\",\"Fare\",\"Embarked\",\"FamilySize\",\"Title\",\"FamilyId\"]],\n",
        "[LogisticRegression(random_state=1),[\"Pclass\",\"Sex\",\"Fare\",\"FamilySize\",\"Title\",\"Age\",\"Embarked\"]]\n",
        "]\n",
        "\n",
        "#Initialize the cross validation folds\n",
        "kf=KFold(titanic.shape[0],n_folds=3,random_state=1)\n",
        "\n",
        "predictions=[]\n",
        "for train, test in kf:\n",
        "    train_target=titanic[\"Survived\"].iloc[train]\n",
        "    full_test_predictions=[]\n",
        "    for alg, predictors in algorithms:\n",
        "        alg.fit(titanic[predictors].iloc[train,:],train_target)\n",
        "        test_predictions=alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
        "        full_test_predictions.append(test_predictions)\n",
        "    test_predictions=(full_test_predictions[0]+full_test_predictions[1])/2\n",
        "    test_predictions[test_predictions<=.5]=0\n",
        "    test_predictions[test_predictions>.5]=1\n",
        "    predictions.append(test_predictions)\n",
        "        \n",
        "predictions=np.concatenate(predictions,axis=0)\n",
        "\n",
        "accuracy=sum(predictions[predictions==titanic[\"Survived\"]])/len(predictions)\n",
        "\n",
        "print(accuracy)\n",
        "        "
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}