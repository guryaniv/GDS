{"cells":[{"metadata":{"_uuid":"f56739b3ec12f34e5a2d1ae2c701d82a861bcf0d"},"cell_type":"markdown","source":"**IMPORTING LIBRARIES **"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"560320c535c10e64dc922c94d0ca6a3fb964a810"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb5f4d991f26ad7d60e4b578b3b520ed010e2da3"},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pydicom \nimport glob, pylab\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbf8c17f9716a3f22719d19973ce01a2db1ae63c"},"cell_type":"markdown","source":"**STORING DATA INTO THE DATAFRAME**"},{"metadata":{"_kg_hide-output":false,"trusted":true,"scrolled":true,"_uuid":"a6cf9ffe2528f4d58cf5284a3caf6dd32af299bd"},"cell_type":"code","source":"# We have to take the train CSV file and view it \ntraindata=pd.read_csv('../input/stage_1_train_labels.csv')\nprint(traindata.iloc[0])\ntraindata.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d251e731f9085f8e5fee5298bbff9080a72bdc0d"},"cell_type":"markdown","source":"sns.countplot(traindata['Target'])\nplt.show()"},{"metadata":{"trusted":true,"_uuid":"a9c64d8090972044c167142aa30c95cd6a86fcab"},"cell_type":"code","source":"classlabels=pd.read_csv('../input/stage_1_detailed_class_info.csv')\n#print(classlabels.sample(5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b9101e93b56c6a73fab812adc098281618bd9fb"},"cell_type":"markdown","source":"**MERGING THE DATA FRAME WITH CLASS LABELS **********"},{"metadata":{"trusted":true,"_uuid":"1db7f04aa8d4bc49153bb8ee87e38af2adf8058d"},"cell_type":"code","source":"#traindata=ftrainingdata\nftrainingdata=traindata.merge(classlabels)\n#print(ftrainingdata)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2c576fdbb6e14df0f04b74d85afb31c02e20300"},"cell_type":"markdown","source":"sns.countplot(ftrainingdata['Target'])\n plt.show()"},{"metadata":{"trusted":true,"_uuid":"f6b91fd6e92d15504630522f670e9779f20fb5fb"},"cell_type":"markdown","source":"a=1755\npatientId=ftrainingdata['patientId'][a]\ndcmfile='../input/stage_1_train_images/%s.dcm'% patientId\ndcmdata=pydicom.dcmread(dcmfile)\nprint (patientId)"},{"metadata":{"_uuid":"f77ca7da4c662b66612f5862b88bf8b9aa7765a2"},"cell_type":"markdown","source":"**VISUALIZING DATA **"},{"metadata":{"trusted":true,"_uuid":"0047f92bd769132482a296c2d149dcf7b814ced1"},"cell_type":"markdown","source":"im = dcmdata.pixel_array\nprint(type(im))\npylab.imshow(im, cmap=pylab.cm.gist_gray)\nprint(ftrainingdata['Target'][a])"},{"metadata":{"_uuid":"3ce1d568a1a12908ac24c83a571b7f98562843b5"},"cell_type":"markdown","source":"**CROPPING THE IMAGE TO THE AREA OF INTEREST **"},{"metadata":{"trusted":true,"_uuid":"8b79ba2f88a365b2c62b99ecd1f47de986b650d2"},"cell_type":"markdown","source":"startx= int(ftrainingdata['x'][a])\nstarty=int(ftrainingdata['y'][a])\ncropy=int(ftrainingdata['height'][a])\ncropx=int(ftrainingdata['width'][a])\ncropped = im[starty:starty+cropy,startx:startx+cropx]\n#cropped.reshape(28,28)\n#size=(28, 28)\n#cv2.resize(cropped, size).flatten()\ncroppedd=cv2.resize(cropped, (28, 28))\npylab.imshow(croppedd, cmap=pylab.cm.gist_gray)\ntrainx=croppedd\nprint(ftrainingdata['Target'][a])\nprint(croppedd.shape)"},{"metadata":{"trusted":true,"_uuid":"682102b1c6504780f0f0c60edc990849781b61d4"},"cell_type":"markdown","source":"channels=1\nimage_height=28\nimage_width=28\ninputdata = np.ndarray(shape=(1000, channels, image_height, image_width),\n                     dtype=np.float32)\nprint(len(ftrainingdata))"},{"metadata":{"trusted":true,"_uuid":"c50b493606d74917c725eaf4e496c25883b2abdb"},"cell_type":"markdown","source":"for y in range (0,1000):\n a=y\n patientId=ftrainingdata['patientId'][a]\n dcmfile='../input/stage_1_train_images/%s.dcm'% patientId\n dcmdata=pydicom.dcmread(dcmfile)\n im = dcmdata.pixel_array \n if ftrainingdata['Target'][a] == 1:\n  print (x)\n  startx= int(ftrainingdata['x'][a])\n  starty=int(ftrainingdata['y'][a])\n  cropy=int(ftrainingdata['height'][a])\n  cropx=int(ftrainingdata['width'][a])\n  cropped = im[starty:starty+cropy,startx:startx+cropx]\n  trainx=np.array(cv2.resize(cropped, (28, 28)))\n  inputdata[x] = trainx\n  x += 1 \n \n  \n# else:\n # trainx[x]=cv2.resize(im, (28, 28))      \nif a==99:\n    print(\"Transfer done\")\n   # pylab.imshow(dataset, cmap=pylab.cm.gist_gray)\nprint (inputdata.shape)\nprint (trainx.shape)\nprint(x)"},{"metadata":{"trusted":true,"_uuid":"ae2f283cc50c7e471c25a1c44f6231d2396ea589"},"cell_type":"code","source":"inputtd = np.ndarray(shape=(1000,28, 28), dtype=np.float32)\ninputtd.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bf833855b3aeb1310005aae213111ed2d15d18b"},"cell_type":"markdown","source":"**#START A LOOP FOR TRAINING INPUT DATA \n#START A DATA FRAME \n#MAKE A LIST FOR OUTPUT DTRAINING DATA \n#NEED TO INITIALIZE VARIABLES **\n#"},{"metadata":{"trusted":true,"_uuid":"38bb8a2d3a10928fed0c75683183bf6ca245983a"},"cell_type":"code","source":"outputtd=ftrainingdata['Target'][0:1000]\nx=0\nfor index in range (0,1000):\n a=index   \n patientId=ftrainingdata['patientId'][a]\n dcmfile='../input/stage_1_train_images/%s.dcm'% patientId\n dcmdata=pydicom.dcmread(dcmfile)\n im=dcmdata.pixel_array\n #crop=cv2.resize(im, (28, 28))\n #pylab.imshow(crop, cmap=pylab.cm.gist_gray)\n #inputtd=cv2.resize(im, (28, 28))\n inpu=np.array(cv2.resize(im, (28, 28)))\n inputtd[x] = inpu\n x += 1    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"282f619bfa6c8517fb578c3ffa7208059fa2fc77"},"cell_type":"code","source":"inn=inputtd \ninn= inn.reshape(1000,28,28,1)\ninn.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6534f1e1ce21b0aaf66247109536e7a2025ff28"},"cell_type":"markdown","source":"**Desinging the DNN architecture **"},{"metadata":{"trusted":true,"_uuid":"816431fe37206974113c86e3c25224b6cb4e4526"},"cell_type":"code","source":"import keras \noutputtd= keras.utils.to_categorical(outputtd,num_classes=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47fca93bd6efbd97ea9bbae72ecfb185087aa939"},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(inn,outputtd,test_size=0.5,random_state=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f34398a79f3238ef411bec5cab917050e40b1c1a"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Convolution2D(32,3,data_format='channels_last',activation='relu',input_shape=(28,28,1)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(20))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer = 'adadelta', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3125db75ac51ae6c2b18fb34f3e5adea65bdb1eb"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"733599222ec4822b8af221c15fbf6fb8e8a3f3ea"},"cell_type":"code","source":"model.fit(x_train,y_train,validation_data=(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5f6cc14d1402381963e241b47e3a7b1d099ff9f"},"cell_type":"code","source":"model.evaluate(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"995b665133f39622e66cb1d989610a5a05657959"},"cell_type":"markdown","source":"**we have alhamdulillah completed the EDA and we are in to our first CNN, there are problems shown up due to the changes in the categories of output but in sha allah we will solve it, positively by tomorrow **\nThis is just an test run that we are trying to acomplish, we will later have to selectively pixelate the ct scans and will have to flow them again, and finally should be able to detect the x y coordinates of the systems.** as observed on 9/7/2018**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}