{"nbformat_minor": 1, "cells": [{"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "92c0fc8c4608dd4dbcf97e33fd5c356700ee60ef", "_cell_guid": "1ea46683-90fb-4ccf-8375-c95c4cf4eeb7"}, "execution_count": 1}, {"source": ["\"\"\"\n", "Ref: https://www.kaggle.com/the1owl/surprise-me\n", "\"\"\"\n", "\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn import preprocessing\n", "from sklearn.model_selection import GridSearchCV\n", "import xgboost as xgb\n", "\n", "# Data wrangling brought to you by the1owl\n", "# https://www.kaggle.com/the1owl/surprise-me\n", "\n", "data = {\n", "    'tra':\n", "    pd.read_csv('../input/air_visit_data.csv'),\n", "    'as':\n", "    pd.read_csv('../input/air_store_info.csv'),\n", "    'hs':\n", "    pd.read_csv('../input/hpg_store_info.csv'),\n", "    'ar':\n", "    pd.read_csv('../input/air_reserve.csv'),\n", "    'hr':\n", "    pd.read_csv('../input/hpg_reserve.csv'),\n", "    'id':\n", "    pd.read_csv('../input/store_id_relation.csv'),\n", "    'tes':\n", "    pd.read_csv('../input/sample_submission.csv'),\n", "    'hol':\n", "    pd.read_csv('../input/date_info.csv').rename(columns={\n", "        'calendar_date': 'visit_date'\n", "    })\n", "}\n", "\n", "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n", "\n", "for df in ['ar', 'hr']:\n", "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n", "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n", "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n", "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n", "    data[df]['reserve_datetime_diff'] = data[df].apply(\n", "        lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n", "    data[df] = data[df].groupby(\n", "        ['air_store_id', 'visit_datetime'], as_index=False)[[\n", "            'reserve_datetime_diff', 'reserve_visitors'\n", "        ]].sum().rename(columns={\n", "            'visit_datetime': 'visit_date'\n", "        })\n", "    print(data[df].head())\n", "\n", "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n", "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n", "data['tra']['year'] = data['tra']['visit_date'].dt.year\n", "data['tra']['month'] = data['tra']['visit_date'].dt.month\n", "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n", "\n", "data['tes']['visit_date'] = data['tes']['id'].map(\n", "    lambda x: str(x).split('_')[2])\n", "data['tes']['air_store_id'] = data['tes']['id'].map(\n", "    lambda x: '_'.join(x.split('_')[:2]))\n", "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n", "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n", "data['tes']['year'] = data['tes']['visit_date'].dt.year\n", "data['tes']['month'] = data['tes']['visit_date'].dt.month\n", "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date\n", "\n", "unique_stores = data['tes']['air_store_id'].unique()\n", "stores = pd.concat(\n", "    [\n", "        pd.DataFrame({\n", "            'air_store_id': unique_stores,\n", "            'dow': [i] * len(unique_stores)\n", "        }) for i in range(7)\n", "    ],\n", "    axis=0,\n", "    ignore_index=True).reset_index(drop=True)\n", "\n", "#sure it can be compressed...\n", "tmp = data['tra'].groupby(\n", "    ['air_store_id', 'dow'],\n", "    as_index=False)['visitors'].min().rename(columns={\n", "        'visitors': 'min_visitors'\n", "    })\n", "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n", "tmp = data['tra'].groupby(\n", "    ['air_store_id', 'dow'],\n", "    as_index=False)['visitors'].mean().rename(columns={\n", "        'visitors': 'mean_visitors'\n", "    })\n", "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n", "tmp = data['tra'].groupby(\n", "    ['air_store_id', 'dow'],\n", "    as_index=False)['visitors'].median().rename(columns={\n", "        'visitors': 'median_visitors'\n", "    })\n", "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n", "tmp = data['tra'].groupby(\n", "    ['air_store_id', 'dow'],\n", "    as_index=False)['visitors'].max().rename(columns={\n", "        'visitors': 'max_visitors'\n", "    })\n", "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n", "tmp = data['tra'].groupby(\n", "    ['air_store_id', 'dow'],\n", "    as_index=False)['visitors'].count().rename(columns={\n", "        'visitors': 'count_observations'\n", "    })\n", "stores = pd.merge(stores, tmp, how='left', on=['air_store_id', 'dow'])\n", "\n", "stores = pd.merge(stores, data['as'], how='left', on=['air_store_id'])\n", "lbl = preprocessing.LabelEncoder()\n", "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n", "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n", "\n", "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n", "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n", "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n", "\n", "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date'])\n", "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date'])\n", "\n", "train = pd.merge(data['tra'], stores, how='left', on=['air_store_id', 'dow'])\n", "test = pd.merge(data['tes'], stores, how='left', on=['air_store_id', 'dow'])\n", "\n", "for df in ['ar', 'hr']:\n", "    train = pd.merge(\n", "        train, data[df], how='left', on=['air_store_id', 'visit_date'])\n", "    test = pd.merge(\n", "        test, data[df], how='left', on=['air_store_id', 'visit_date'])\n", "\n", "col = [\n", "    c for c in train\n", "    if c not in ['id', 'air_store_id', 'visit_date', 'visitors']\n", "]\n", "train = train.fillna(-1)\n", "test = test.fillna(-1)\n", "\n", "# XGB starter template borrowed from @anokas\n", "# https://www.kaggle.com/anokas/simple-xgboost-starter-0-0655\n", "\n", "print('Binding to float32')\n", "\n", "for c, dtype in zip(train.columns, train.dtypes):\n", "    if dtype == np.float64:\n", "        train[c] = train[c].astype(np.float32)\n", "\n", "for c, dtype in zip(test.columns, test.dtypes):\n", "    if dtype == np.float64:\n", "        test[c] = test[c].astype(np.float32)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "9f76f0746af8615cfd5bce97633076cdfbb8d6a3", "_cell_guid": "4a8d9fec-78c4-4db7-bbea-5ffa1d077681"}, "execution_count": 2}, {"source": ["train_x = train.drop(['air_store_id', 'visit_date', 'visitors'], axis=1)\n", "train_y = np.log1p(train['visitors'].values)\n", "print(train_x.shape, train_y.shape)\n", "test_x = test.drop(['id', 'air_store_id', 'visit_date', 'visitors'], axis=1)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "8020e3bb9d82fb932a408febcd0d0c3114d5f0b6", "_cell_guid": "311223da-3ad5-439e-8933-79c6c4887927"}, "execution_count": 3}, {"source": ["# parameter tuning of xgboost\n", "# start from default setting\n", "boost_params = {'eval_metric': 'rmse'}\n", "xgb0 = xgb.XGBRegressor(\n", "    max_depth=8,\n", "    learning_rate=0.01,\n", "    n_estimators=10000,\n", "    objective='reg:linear',\n", "    gamma=0,\n", "    min_child_weight=1,\n", "    subsample=1,\n", "    colsample_bytree=1,\n", "    scale_pos_weight=1,\n", "    seed=27,\n", "    **boost_params)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "fc2f8fd8d641b43cba059f915d867f3c2fead688", "collapsed": true, "_cell_guid": "b49f6b02-d389-4635-a736-7daa179ece1f"}, "execution_count": 4}, {"source": ["xgb0.fit(train_x, train_y)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "1ac68b702d77d8ef324d5a37adc4c0fbcf1e1055", "scrolled": true, "_cell_guid": "83c298d9-d53a-4687-804f-c9ff48c2b1f7"}, "execution_count": 7}, {"source": ["predict_train_y = xgb0.predict(train_x)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "741012d2d33b25a1be211737486ee753cefc8eab", "collapsed": true, "_cell_guid": "c1c5faad-b244-4e72-a5fd-ea2ffefd8ef2"}, "execution_count": 8}, {"source": ["predict_y = xgb0.predict(test_x)\n", "test['visitors'] = np.expm1(predict_y)\n", "test[['id', 'visitors']].to_csv(\n", "    'xgb0_submission.csv', index=False, float_format='%.3f')  # LB0.495"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "369ae9ed4f87e03b925c6a3210cafa648f0bf786", "collapsed": true, "_cell_guid": "a15c6c30-a766-4cbd-b922-234c959639c6"}, "execution_count": 9}, {"source": ["from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n", "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n", "from sklearn import metrics"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "94287e20eda3e13afc364395dd5e3b270bdd4b12", "collapsed": true, "_cell_guid": "7b0b9158-f006-4c41-8bfa-2b31fa84cde0"}, "execution_count": 10}, {"source": ["def RMSLE(y, pred):\n", "    return metrics.mean_squared_error(y, pred)**0.5\n", "n_folds=5\n", "def rmse_cv(model):\n", "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train_x)\n", "    rmse = np.sqrt(-cross_val_score(model, train_x, train_y, scoring='neg_mean_squared_error', cv=kf))\n", "    return(rmse)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "33a1db4f4c8092fb6d88d801f93c8ad23566cb43", "collapsed": true, "_cell_guid": "a3351b3a-0a00-4da2-8057-31486fac57ea"}, "execution_count": 11}, {"source": ["RMSLE(train_y,predict_train_y)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "a0d5ac414d5d179c14ec357b3ccd7cf137d4f37b", "scrolled": true, "_cell_guid": "deae1e72-9d54-4a48-9a53-b3c77971a36f"}, "execution_count": 12}, {"source": ["rmse_cv(xgb0)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "154538b5ca654ac901ad9811c624f5b96374ea68", "scrolled": true, "collapsed": true, "_cell_guid": "aba6064c-58fc-4d8e-93db-6185d897b2d8"}, "execution_count": null}, {"source": [], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "a8c60077f47e588fd24a8b025a574565f0b2ce35", "collapsed": true, "_cell_guid": "f99fb234-d33d-432a-b1bb-b28e45b7185f"}, "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "version": "3.6.4", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}