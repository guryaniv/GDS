{"cells":[{"metadata":{"_cell_guid":"953275d8-c751-4a44-a2c7-903211676e87","_uuid":"504ae0070a0402f176f0f9764124607d7b644263"},"cell_type":"markdown","source":"Read data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","scrolled":true,"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n%matplotlib inline\n\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\n\nimport os\nprint(os.listdir(\"../input\"))\n# Import all of them \nsales=pd.read_csv(\"../input/sales_train.csv\")\n\n# settings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nitem_cat=pd.read_csv(\"../input/item_categories.csv\")\nitem=pd.read_csv(\"../input/items.csv\")\nsub=pd.read_csv(\"../input/sample_submission.csv\")\nshops=pd.read_csv(\"../input/shops.csv\")\ntest=pd.read_csv(\"../input/test.csv\")\nshops.describe().T","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"f3a03178-4d66-4bec-8e10-9878a3b6cb5a","_uuid":"6ceb76aaea661140711e1073f369ba24aad0f4db","collapsed":true,"trusted":false},"cell_type":"code","source":"N_SESSIONS = 34","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e5ce6d19-ddca-49ce-a511-4117299845de","_uuid":"422c9136b5c853e2ffd04350907c03a90fc4efa2","scrolled":true,"trusted":true},"cell_type":"code","source":"# Now we convert the raw sales data to monthly sales, broken out by item & shop\nsales_piv= sales.pivot_table(index=['item_id','shop_id'], columns='date_block_num',values='item_cnt_day',aggfunc=np.sum,fill_value=0).reset_index()\nsales_piv.head()","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ef05f784b4b1a9729abf22b6297d0001d782d81"},"cell_type":"code","source":"seasonsindex=sales_piv.drop(['item_id','shop_id'],axis=1).sum()/sales_piv.drop(['item_id','shop_id'],axis=1).sum().mean()","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"c1493abe-5edc-4d6e-bfcf-cf8d56944f14","_uuid":"6c5bc4d56b74cee2079f01f3b3a39682210ebaac","collapsed":true,"trusted":true},"cell_type":"code","source":"# Merge the monthly sales data to the test data\nTest=pd.merge(test, item, how='inner', on='item_id')\nTest = pd.merge(Test, sales_piv, on=['item_id','shop_id'], how='left').fillna(0)\n#add category\nTestcat=Test['item_category_id']\nTest = Test.drop(labels=['ID', 'shop_id', 'item_id','item_name','item_category_id'], axis=1).T\n\n\n# times series ARIMA uitgeschakeld\n#Ttrain=Test.append(Test.diff(1).dropna())\n#Ttrain=Ttrain.append(pd.rolling_mean(Test,12)).dropna()\n#Ttrain=Ttrain.T\n#cluster in 9 groups\n#from sklearn.cluster import KMeans\n#clu=KMeans(n_clusters=9)\n#Ttrain['clu']=clu.fit_predict(Ttrain)\n#Ttrain['cat']=Testcat\n\nTtrain=Test.T","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"c74b6aff-83a4-4503-8aad-4c3d14d83282","_uuid":"d7ee3e6e3fced5dc3a090d5870465b9c71ab3aa7","collapsed":true,"trusted":true},"cell_type":"code","source":"ALPHA = 0.06\nBETA = 0.98\nGAMMA= 0.48\n\ndef create_filtered_prediction(train_ts, alpha, beta):\n    train_time_filtered_ts = np.zeros((train_ts.shape[0], N_SESSIONS), dtype=np.float)\n    train_time_filtered_ts[0, :] = train_ts[0, :N_SESSIONS]\n    train_memontum_ts = np.zeros((train_ts.shape[0], N_SESSIONS), dtype=np.float)\n    prediction_ts = np.zeros((train_ts.shape[0], N_SESSIONS+1), dtype=np.float)\n    for i in range(1, N_SESSIONS):\n        train_time_filtered_ts[:, i] = (1-alpha) * (train_time_filtered_ts[:, i-1] + \\\n                                                    train_memontum_ts[:, i-1]) + alpha * train_ts[:, i]\n        train_memontum_ts[:, i] = (1-beta) * train_memontum_ts[:, i-1] + \\\n                                  beta * (train_time_filtered_ts[:, i] - train_time_filtered_ts[:, i-1])\n        prediction_ts[:, i+1] = train_time_filtered_ts[:, i] + train_memontum_ts[:, i]\n    return prediction_ts\n\n\ndef trixps(y,a0,b0,alpha,beta,gamma,initialSeasonalIndices,period,m):\n    #St = np.zeros((len(y),len(y[0])), dtype=np.float)\n    St = Bt =It= Ft = np.zeros((len(y),len(y[0]) +m ), dtype=np.float)\n    #print(y.shape,St.shape)\n    #Initialize base values\n    #St[:,1] = a0;\n    #Bt[:,1] = b0;\n     \n    for i in range(period):\n        It[:,i] = initialSeasonalIndices[i]\n    Ft[:,m] = (St[:,0] + (m * Bt[:,0])) * It[:,0] #;//This is actually 0 since Bt[0] = 0\n    Ft[:,m + 1] = (St[:,1] + (m * Bt[:,1])) * It[:,1] #;//Forecast starts from period + 2\n\n    #//Start calculations\n    for i in range( 2,len(y[0])):\n        #//Calculate overall smoothing\n        if (i - period) >= 0:\n            St[:,i] = alpha * y[:,i] / It[:,i - period] + (1.0 - alpha) * (St[:,i - 1] + Bt[:,i - 1])\n        else:\n            St[:,i] = alpha * y[:,i] + (1.0 - alpha) * (St[:,i - 1] + Bt[:,i - 1])\n        #//Calculate trend smoothing\n            Bt[:,i] = gamma * (St[:,i] - St[:,i - 1]) + (1 - gamma) * Bt[:,i - 1]\n\n        #//Calculate seasonal smoothing\n        if (i - period) >= 0:\n            It[:,i] = beta * y[:,i] / St[:,i] + (1.0 - beta) * It[:,i - period]\n        #//Calculate forecast\n        if  (i + m) >= period:\n            Ft[:,i + m] = (St[:,i] + (m * Bt[:,i])) * It[:,i - period + m]\n    return Ft\n\n#predictions = create_filtered_prediction(Ttrain.values, ALPHA, BETA)","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"6eedb635-1f86-4079-afc2-d9af448449d6","_uuid":"217f182e32e2988393af3458b23c3136232fdb80","trusted":true},"cell_type":"code","source":"p=trixps(Ttrain.values,0.5,1,ALPHA,BETA,GAMMA,seasonsindex,12,1)","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"0839237f-3da3-48e9-9765-671515f3fd60","_uuid":"8938b8069984424b925f8a7b9d658c3a59ed1851","trusted":true},"cell_type":"code","source":"print( p.shape,Ttrain.shape )","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"bc7df068-1317-45c1-8009-b4d76d5d0fc4","_uuid":"974f48b0090b5fe582f54be58cc2ecce0ac10226","trusted":true},"cell_type":"code","source":"knownmonth=32\nunknownmonth=33\ndef rmse(predictions, targets):\n    return np.sqrt(((predictions - targets) ** 2).mean())\nprint(Ttrain.shape)\nyo=Ttrain.iloc[:,unknownmonth]\nyo.colomns=[unknownmonth,'di','ma']\n#print(yo)\nAi=0.02\nGi=0.3\nBi=0.5\np=trixps(Ttrain.values[:,:unknownmonth],0.5,1,Ai,Bi,Gi,seasonsindex,12,1)\nerrorm = rmse(yo[unknownmonth], p[:,unknownmonth])\nerrormb=errorm\nerrorma=errorm\ndirecta=0.01\ndirectg=0.09\ndirectb=0.095\nfor xi in range(5):\n    #ALPHA=Ai/100\n    if abs(directb)>0.001:\n        for yi in range(3):\n            #BETA=Bi\n            if abs(directg)>0.001:\n                for zi in range(3):\n                    #GAMMA=Gi\n                    #p= create_filtered_prediction(Ttrain.values, ALPHA, BETA)\n                    p=trixps(Ttrain.values[:,:unknownmonth],0.5,1,Ai,Bi,Gi,seasonsindex,12,1)\n                    error = rmse(yo[unknownmonth], p[:,unknownmonth])\n                    print('alpha %.3f beta %.3f gamma %.3f month %d directg %.3f directb %.3f- Error %.2f' % (Ai,Bi,Gi,knownmonth,directg,directb,error) ) \n                    errorbigger=(error>errorm)\n                    if errorbigger:\n                        directg=directg*-1.9\n                    else:\n                        directg=directg*0.5                \n                    Gi+=directg\n                    errorm=error\n            else:\n                p=trixps(Ttrain.values[:,:unknownmonth],0.5,1,Ai,Bi,Gi,seasonsindex,12,1)\n                error = rmse(yo[unknownmonth], p[:,unknownmonth])\n                print('alpha %.3f beta %.3f gamma %.3f month %d directg %.3f directb %.3f- Error %.2f' % (Ai,Bi,Gi,knownmonth,directg,directb,error) )                 \n            errorbiggerb=(error>errormb)\n            if errorbiggerb:\n                directb=directb*-1.7                \n            else:\n                directb=directb*0.5\n            errormb=error\n            errorm=error\n            Bi+=directb                \n    else:\n        p=trixps(Ttrain.values[:,:unknownmonth],0.5,1,Ai,Bi,Gi,seasonsindex,12,1)\n        error = rmse(yo[unknownmonth], p[:,unknownmonth])\n        print('alpha %.3f beta %.3f gamma %.3f month %d directg %.3f directb %.3f- Error %.2f' % (Ai,Bi,Gi,knownmonth,directg,directb,error) )                 \n\n    errorbiggera=(error>errorma)\n    if errorbiggera:\n        directa=directa*-1.7                \n    else:\n        directa=directa*0.5\n    errorma=error\n    errormb=error\n    errorm=error\n    Ai+=directa               \n\n            #predictions","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"47c76681-8e00-4c09-835b-f1c1799f5520","_uuid":"84693eacc78b5bdcfad778f212e3fc4a5ff67ced","collapsed":true,"trusted":true},"cell_type":"code","source":"    Ai=0.021\n    Bi=0.599\n    Gi=0.175\n    p=trixps(Ttrain.values[:,:unknownmonth+1],0.5,1,Ai,Bi,Gi,seasonsindex,12,1)\n        #error = rmse(yo[unknownmonth], p[:,unknownmonth])","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"4bfbe69b-667b-488e-b68b-5d4791be579b","_uuid":"0688debcec78b20d69d26f9d2fcb246a0bb3b517","collapsed":true,"trusted":true},"cell_type":"code","source":"sub[\"item_cnt_month\"] = np.clip(p[:, unknownmonth], 0, 20)\nsub.to_csv(\"submitalpha25bet057.csv\",index=False)\n                  #.format(ALPHA))","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"5764d790-d349-43e3-a50a-6f0f7ded8666","_uuid":"5bc893959c346bc2f80af9c7268f2f9e6c779afd","trusted":true},"cell_type":"code","source":"TEXPtr=Ttrain.T.append(pd.DataFrame(p).T  )\nTEXPtr","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"aa7a3c46-16f9-4e6c-82f4-9b64d470d58d","_uuid":"cc6cbbb6fa43e944e89a33dcfc7f6af60bc7156f","trusted":true},"cell_type":"code","source":"def regresseer(meltx,month):\n    from sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor,AdaBoostRegressor,GradientBoostingRegressor\n    from sklearn.neighbors import KNeighborsRegressor\n    from sklearn.linear_model import LinearRegression,RidgeCV,ARDRegression,ElasticNet,PassiveAggressiveClassifier,HuberRegressor,TheilSenRegressor,LarsCV,Lasso,RANSACRegressor,LassoLarsIC,LogisticRegression,OrthogonalMatchingPursuit,ElasticNetCV\n    from sklearn.neural_network import MLPRegressor\n    from sklearn.preprocessing import PolynomialFeatures\n    from sklearn.tree import DecisionTreeRegressor\n    from sklearn.isotonic import IsotonicRegression\n    xtr = pd.merge( meltx.iloc[:,:month],meltx.iloc[:,int(month+1):],left_index=True, right_index=True )\n    ytr = meltx.iloc[:,month]\n    print(xtr.shape,ytr.shape)\n    #train = meltx[meltx['date_block_num'] < month]\n    #val = meltx[meltx['date_block_num'] == month]\n    #print(train.shape,train.columns,val.shape)\n    #xtr, xts = train.drop(['item_cnt_day'], axis=1), val.drop(['item_cnt_day'], axis=1)\n    #ytr, yts = train['item_cnt_day'].values, val['item_cnt_day'].values\n    #poly = PolynomialFeatures(1)\n    #xtr=poly.fit_transform(xtr)\n    #xts=poly.fit_transform(xts)\n    #mdl =AdaBoostRegressor(DecisionTreeRegressor(max_depth=8), n_estimators=7, random_state=1)  #0.64\n    mdl = KNeighborsRegressor()  #0.64\n    mdl = ExtraTreesRegressor(n_estimators=10)  #0.65\n    #mdl = RandomForestRegressor(n_estimators=1000, n_jobs=-1, random_state=0) #0.66\n    #mdl = MLPRegressor() #0.68\n    #mdl =DecisionTreeRegressor(max_depth=8)  #0.71\n    #mdl=TheilSenRegressor()  #0.72   \n    #mdl=RANSACRegressor() #0.78\n    #mdl=HuberRegressor() #0.83    \n    #mdl = LinearRegression()  #1.03\n    #mdl=ElasticNet(random_state=0) #1;04    \n    #mdl = GradientBoostingRegressor(loss='quantile') #1.06\n    #mdl = LarsCV()  #1.04\n    #mdl= Lasso() #1.04\n    #mdl=LassoLarsIC() #1.20    \n    #mdl=PassiveAggressiveClassifier() #sleh 1.9\n    #mdl=LogisticRegression() #ultratraag\n    #mdl=ElasticNetCV() #1.13\n    #mdl=OrthogonalMatchingPursuit()\n    #mdl = ARDRegression()  # ultratraag\n    #mdl = IsotonicRegression() \n    #mdl= RidgeCV() #1.04\n    mdl.fit(xtr, ytr)\n    #print(mdl.coef_,mdl.intercept_)\n    px = mdl.predict(meltx.iloc[:,1:])\n\n    \n    return ytr,px\n\n#p=trixps(Ttrain.values[:,:unknownmonth],0.5,1,Ai,Bi,Gi,[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],12,1)\n#array stacken\n#TEXPtr=Ttrain.T.append(pd.DataFrame(p).T  )\n\nyts,p=regresseer(TEXPtr.T,unknownmonth)\n\nerror = rmse(yts, p)\nprint('month %d - Error %.5f' % (unknownmonth, error))\n\n","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"65a1442f-710c-4726-8c40-65ad39c39100","_uuid":"a66a05462d86e2cb69dcabe14f8818da7408a385","trusted":false,"collapsed":true},"cell_type":"code","source":"subm=pd.DataFrame([])\nsubm['ID']=test['ID']\nsubm['item_cnt_month']=np.clip(p,0,20)\nsubm.to_csv('submission2.csv',index=False)\nsubm","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}