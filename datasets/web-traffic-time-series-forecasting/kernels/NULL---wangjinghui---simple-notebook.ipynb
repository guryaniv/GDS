{"cells": [{"source": ["**Note:This is an extension of currently existing Kernel**\n", "\n", "[www.kaggle.com/muonneutrino/wikipedia-traffic-data-exploration](http://www.kaggle.com/muonneutrino/wikipedia-traffic-data-exploration)"], "metadata": {"_cell_guid": "24d26389-203f-43e4-ae73-10176b30db91", "_uuid": "252b810174612d8ab0e9ad60585b3144e52d301d"}, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "7d65ff07-8b25-468e-8112-a3c07c9883c9", "_uuid": "5c4d951329233ad3e5a7bc6409d59323dff792f7", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O \n", "import matplotlib.pyplot as plt\n", "import re\n", "import seaborn as sb\n", "%matplotlib inline"]}, {"outputs": [], "metadata": {"_cell_guid": "5c5cbbdd-e267-4ddf-854a-9aa59c68f1f8", "_uuid": "43ecae5d01138acc55102d43925ce4a6a2a11ebd"}, "execution_count": null, "cell_type": "code", "source": ["# missing value processing\n", "train = pd.read_csv('../input/train_1.csv').fillna(0)\n", "train.head()"]}, {"outputs": [], "metadata": {"_cell_guid": "8bf70331-a985-4e87-bf21-c7fdbb10d2ed", "_uuid": "62ed1ad2c7d30ac3b9967216c984c75749a5c013", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["# extract web page language information\n", "def get_language(page):\n", "    res = re.search('[a-z][a-z].wikipedia.org',page)\n", "    if res:\n", "        return res.group()[:2]     # result fo the match converted to a str obj\n", "    return 'na'"]}, {"outputs": [], "metadata": {"_cell_guid": "1542c908-ff43-492e-89c2-79a728751b9f", "_uuid": "68b4f5534d16f4f42250eaf69d4b6812ca5ebad7", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["# add language column \n", "train['language'] = train['Page'].map(get_language)"]}, {"outputs": [], "metadata": {"_cell_guid": "3ccdc087-b7a8-4dae-97c5-bb767ff8a081", "_uuid": "cabaf1f353a2a89be33bafe612ec1827949bb72a"}, "execution_count": null, "cell_type": "code", "source": ["# statistics of different languages\n", "sb.countplot(train['language'])"]}, {"outputs": [], "metadata": {"_cell_guid": "800dccf8-e762-453b-98ae-333f7019fb53", "_uuid": "60787ebc865e52ecc06520462b5e8d4e78cf0950", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["# \u3000use dict cave different language DF\n", "lang_sets = {}\n", "lang_sets['en'] = train[train.language=='en'].iloc[:,0:-1]\n", "lang_sets['ja'] = train[train.language=='ja'].iloc[:,0:-1]\n", "lang_sets['de'] = train[train.language=='de'].iloc[:,0:-1]\n", "lang_sets['na'] = train[train.language=='na'].iloc[:,0:-1]\n", "lang_sets['fr'] = train[train.language=='fr'].iloc[:,0:-1]\n", "lang_sets['zh'] = train[train.language=='zh'].iloc[:,0:-1]\n", "lang_sets['ru'] = train[train.language=='ru'].iloc[:,0:-1]\n", "lang_sets['es'] = train[train.language=='es'].iloc[:,0:-1]"]}, {"outputs": [], "metadata": {"_cell_guid": "22558aae-f338-4d84-8773-a848133eba32", "_uuid": "2cec88eca4ddb2b5a3d85a10ec63fc8985b3651a", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["# daily average pageviews for each language \n", "sums = {}\n", "for key in lang_sets:\n", "    sums[key] = lang_sets[key].iloc[:,1:].sum(axis=0) / lang_sets[key].shape[0]"]}, {"outputs": [], "metadata": {"_cell_guid": "510eed79-8703-4a4a-9e5e-d80b385bb306", "_uuid": "af7d43a64513e23178ed71e9fdd4b4655c273da8"}, "execution_count": null, "cell_type": "code", "source": ["# DataFrame\n", "traffic_sum = pd.DataFrame(sums) \n", "traffic_sum.columns=['German','English','Spanish','French',\n", "                     'Japanese','Nan','Russian','Chinese'] \n", "traffic_sum.plot(figsize=(12,6),grid=True)"]}, {"outputs": [], "metadata": {"_cell_guid": "0c04c58c-7498-4833-82c0-fa613f90a6f7", "_uuid": "96616b58d8663b25781b302ecb14d95ccfa625b5"}, "execution_count": null, "cell_type": "code", "source": ["# import dependent libraries\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import MinMaxScaler\n", "# Keras\n", "from keras.models import Sequential\n", "from keras.layers import Dense\n", "from keras.layers import LSTM"]}, {"outputs": [], "metadata": {"_cell_guid": "b5824b21-151e-45e0-bd55-d0c3b0eaf8f6", "_uuid": "51e188ccffdbeb42f7f53d6fc83c46ba22deabf1", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["# build model\n", "def LSTM_Model(train_x,train_y,batch_size=10,epochs=100,verbose=0):\n", "    regressor = Sequential()\n", "    # add LSTM layer\n", "    regressor.add(LSTM(units= 8, activation='relu', input_shape = (None,1)))\n", "    # add Dense layer\n", "    regressor.add(Dense(units=1))\n", "    # compile \n", "    regressor.compile(optimizer = 'rmsprop',loss='mean_squared_error')\n", "    # fitting data\n", "    regressor.fit(train_x, train_y, batch_size = batch_size, epochs=epochs, verbose = verbose)\n", "    return regressor"]}, {"outputs": [], "metadata": {"_cell_guid": "f4b5784d-35dd-40d4-b8eb-bbdbcd3cf212", "_uuid": "18c5f9a524be6ff2cea9fda83aa81fd4e51fb18e", "scrolled": true}, "execution_count": null, "cell_type": "code", "source": ["# scaling data(daily pageviews for each language )\n", "sc = MinMaxScaler()\n", "scaling_sum = sc.fit_transform(traffic_sum)\n", "scale_sum = pd.DataFrame(scaling_sum)\n", "scale_sum.columns = traffic_sum.columns\n", "scale_sum.head()"]}, {"outputs": [], "metadata": {"_cell_guid": "e2bec2dd-701a-441b-b313-96b9409a1413", "_uuid": "3e8412e764e8bc9601241ca38ba202dfdfb05069", "scrolled": false}, "execution_count": null, "cell_type": "code", "source": ["models = {}    # save different models\n", "for language in scale_sum.columns:\n", "    X = np.array(scale_sum[language])[0:549]\n", "    Y = np.array(scale_sum[language])[1:550]\n", "    \n", "    # splitting dataset\n", "    train_x, test_x , train_y, test_y = train_test_split(X, Y, test_size = 0.3, random_state=0)\n", "    train_x = np.reshape(train_x,(384, 1, 1))\n", "    train_y = np.reshape(train_y, (-1, 1))\n", "    test_x = np.reshape(test_x, (165, 1, 1))\n", "    test_y = np.reshape(test_y, (-1, 1))\n", "    # training data\n", "    model = LSTM_Model(train_x, train_y,10, 100)\n", "    # save model\n", "    models[language] = model\n", "    # test result\n", "    predict = model.predict(test_x)\n", "    \n", "    # show test result\n", "    plt.figure(figsize=(12,6))\n", "    plt.plot(test_y, c='r', label='Real web view')\n", "    plt.plot(predict, c='g', label='Predicted view')\n", "    plt.title(language + ' wiki page view forecasting')\n", "    plt.xlabel('days')\n", "    plt.legend()\n", "    plt.grid(True)\n", "    plt.show()"]}, {"source": ["###randomly selected different language webpage test model"], "metadata": {"_cell_guid": "a490e9d0-644b-4b11-90af-1fcbcfaf2246", "_uuid": "dcf53ed9a8ab5c0a38b0ec2ba31c9a3a0a9e833b"}, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "9041124a-7ba3-4497-9670-aaf729edc965", "_uuid": "7fad4af3542e66114d4a6e8304cb62223cbf3c2e", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["def plot_cruve(real, pred, page):\n", "    plt.figure(figsize=(10,5))\n", "    plt.plot(real, c='r', label='Real web view')\n", "    plt.plot(pred, c='g', label='Predicted view')\n", "    plt.title(page)\n", "    plt.xlabel('days')\n", "    plt.legend()\n", "    plt.grid(True)\n", "    plt.show()"]}, {"outputs": [], "metadata": {"_cell_guid": "35395ab9-a414-4266-bb44-6ec777b351de", "_uuid": "28cc7ab619f1faa0e164a4236de0bef0d7c11ca9", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["# mapping dictionary\n", "lang_dict={'English':'en','Chinese':'zh','German':'de','Nan':'na',\n", "           'Japanese':'ja','French':'fr','Spanish':'es','Russian':'ru'}"]}, {"outputs": [], "metadata": {"_cell_guid": "5f59f38e-3cad-4bba-89dc-7d42aae211ba", "_uuid": "bbf87d771cc733f2d1c8fe1e5bfab2e3103da74b", "scrolled": false}, "execution_count": null, "cell_type": "code", "source": ["for language in models.keys():\n", "    # random number\n", "    index = np.random.randint(10000)\n", "    # randomly selected different language webpage test model\n", "    data = lang_sets[lang_dict[language]].iloc[index, 1:]\n", "    page = lang_sets[lang_dict[language]].iloc[index, 0]\n", "    real_data = np.array(data)[1:550].reshape(-1,1)\n", "    test_data = np.array(data)[0:549].reshape(549, 1, 1)\n", "    # predict\n", "    pred = models[language].predict(test_data)\n", "    # show \n", "    plot_cruve(real_data, pred, page  )"]}], "metadata": {"language_info": {"nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "file_extension": ".py", "version": "3.6.1", "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 1, "nbformat": 4}