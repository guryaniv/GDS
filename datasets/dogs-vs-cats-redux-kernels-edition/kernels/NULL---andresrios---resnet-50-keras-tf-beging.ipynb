{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom os import *\nimport os, cv2, random\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\nimport numpy as np\nfrom keras.datasets import mnist\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker\nimport seaborn as sns\n%matplotlib inline \n\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.utils import np_utils\n\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e02f4c30b751353381be0b00b1926b98e7b9f01f","scrolled":true,"collapsed":true},"cell_type":"code","source":"model = ResNet50(weights='imagenet')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1dca55e580db3e1a8a7ab706178ae8c2b6388a20"},"cell_type":"markdown","source":"# Preprocessing Train and Test Data "},{"metadata":{"trusted":true,"_uuid":"648f58be1b6c2800f8d6e06ee11a5593b0b8235f","collapsed":true},"cell_type":"code","source":"def read_image(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n    img =cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n    img=cv2.cvtColor(file, cv2.COLOR_BGR2RGB)\n\n    return np.array(img).reshape((3,224,224))\n\n\ndef prep_data(images):\n    count = len(images)\n    data = np.ndarray((count, ROWS, COLS,CHANNELS), dtype=np.uint8)\n\n    for i, image_file in enumerate(images):\n        image = read_image(image_file)\n        data[i] = image.T\n        if i%250 == 0: print('Processed {} of {}'.format(i, count))\n    \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b947095882c51db2464eb0199efad40efdb48c15","collapsed":true},"cell_type":"code","source":"TRAIN_DIR = \"../input/dogs-vs-cats-redux-kernels-edition/train/\"\nTEST_DIR = '../input/dogs-vs-cats-redux-kernels-edition/test/'\nROWS = 224\nCOLS = 224\nCHANNELS = 3\ntrain_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\ntrain_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog.' in i]\ntrain_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat.' in i]\n\ntest_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n\n# slice datasets for memory efficiency on Kaggle Kernels, delete if using full dataset\ntrain_images = train_dogs[:1000] + train_cats[:1000]\nrandom.shuffle(train_images)\ntest_images =  test_images[:25]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d26226b327fb66a8e1412802882b91b844464be7"},"cell_type":"code","source":"def read_image(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n    img =cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    return np.array(img).reshape((3,224,224))\n\n\ndef prep_data(images):\n    count = len(images)\n    data = np.ndarray((count, ROWS, COLS,CHANNELS), dtype=np.uint8)\n\n    for i, image_file in enumerate(images):\n        image = read_image(image_file)\n        data[i] = image.T\n        if i%250 == 0: print('Processed {} of {}'.format(i, count))\n    \n    return data\n\n\ntrain = prep_data(train_images)\ntest = prep_data(test_images)\n\nprint(\"Train shape: {}\".format(train.shape))\nprint(\"Test shape: {}\".format(test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a470a24f80009dfa864dd48587bceb3fac3340d0"},"cell_type":"code","source":"model.input_shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97c8d1fb28b1ae4f6f33eefc93a161d2d153fdad"},"cell_type":"markdown","source":"**Generating the Labels**\n\nWe're dealing with a binary classification problem here - (1) dog (0) cat. The lables can be created by looping over the file names in the train directory. It's nice to see the training data is perfectly balanced."},{"metadata":{"trusted":true,"_uuid":"02f6450eba512481840bb55b0736bec90802f84d"},"cell_type":"code","source":"labels = []\nfor i in train_images:\n    if 'dog.' in i:\n        labels.append(1)\n    else:\n        labels.append(0)\n\nsns.countplot(labels)\nplt.title('Cats and Dogs')\nfrom keras.utils import to_categorical\nlabels = to_categorical(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"918037ebc4a8162eb3e82a2e95c36cdcf4cd7a8d"},"cell_type":"code","source":"def show_cats_and_dogs(idx):\n    dog = read_image(train_dogs[idx])\n    dog = np.array(dog).reshape((224,224,3))\n\n    cat = read_image(train_cats[idx])\n    cat = np.array(cat).reshape((224,224,3))\n\n    pair = np.concatenate((cat, dog), axis=1)\n    plt.figure(figsize=(10,5))\n    plt.imshow(pair)\n    plt.show()\n    \nfor idx in range(0,2):\n    show_cats_and_dogs(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ccde7f0676282139e809b95e1034819d0a868f7"},"cell_type":"code","source":"#np.array([dog[0].T for i, dog in enumerate(train) if i<1]).shape\nenumerate(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1dfea715f8f0d0c68ffe53e6b11b70a7345d5179"},"cell_type":"code","source":"'''dog_avg = np.array([dog[0].T for i, dog in enumerate(train) if labels[i]==1]).mean(axis=1)\nplt.imshow(dog_avg)\nplt.title('Your Average Dog')'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f8f91c87913f67dd4f624e6b9bde096a063286e1"},"cell_type":"code","source":"'''cat_avg = np.array([cat[0].T for i, cat in enumerate(train) if labels[i]==0]).mean(axis=1)\nplt.imshow(cat_avg)\nplt.title('Your Average Cat')'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04f3a9d20672029751c4a98584db7a42f70eabe7"},"cell_type":"markdown","source":"# Finish Preprocessing Train and Test Data "},{"metadata":{"trusted":true,"_uuid":"f27f836e00b00a15ddd31dfffe1c12d80c397391"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f0ce36639c1126d2c2447ed339091cd4bd9e237"},"cell_type":"code","source":"model.inputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e02f4c30b751353381be0b00b1926b98e7b9f01f","scrolled":true,"collapsed":true},"cell_type":"code","source":"#Create a New Model based on ResNEt50 \ninput_shape = (224, 224, 3)\n\nK.set_learning_phase(1)\nbase_model = ResNet50(weights='imagenet', include_top=True, input_shape=input_shape)\nbase_model.layers.pop()\nbase_model.outputs = [base_model.layers[-1].output]\nbase_model.layers[-1].outbound_nodes = []\n\nx = base_model.layers[-1].output\n#x = Flatten(name='flatten')(x)\npredictions = Dense(2, activation='softmax', name='predictions')(x)\nmodel_01 = Model(inputs=base_model.input, outputs=predictions)\n\nfor layer in model.layers[0:111]:\n    layer.trainable = False\noptimizer = RMSprop(lr=1e-4)\nmodel_01.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08edf08111efd8901f1b66c280c669a766cdbf7e"},"cell_type":"code","source":"model_01.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3bf378bac29df1e5c432530f8c79c6e4188f51f","collapsed":true},"cell_type":"code","source":"#optimizer = RMSprop(lr=1e-4)\n#objective = 'binary_crossentropy'\n#model_01.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"827a12920b075ed3b7caf29812ae32dd8da10df7","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5f517afaa8505672205542b17577cacf3eab8963"},"cell_type":"code","source":"nb_epoch = 15\nbatch_size = 10\n\n## Callback for loss logging per epoch\nclass LossHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n        self.val_losses = []\n        \n    def on_epoch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')        \n        \ndef run_catdog():\n    \n    history = LossHistory()\n    model_01.fit(x=train, y=labels, batch_size=batch_size, nb_epoch=nb_epoch,\n              validation_split=0.25, verbose=0, shuffle=True, callbacks=[history, early_stopping])\n    \n\n    predictions = model_01.predict(test, verbose=0)\n    return predictions, history\n\npredictions, history = run_catdog()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"914a9123528e338e229afcc6453ad636b07aa6f9"},"cell_type":"code","source":"loss = history.losses\nval_loss = history.val_losses\n\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('VGG-16 Loss Trend')\nplt.plot(loss, 'blue', label='Training Loss')\nplt.plot(val_loss, 'green', label='Validation Loss')\nplt.xticks(range(0,nb_epoch)[0::2])\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08fe7eee8d64b7bc3bcb83678a19930ff0939682"},"cell_type":"code","source":"for i in range(0,10):\n    if predictions[i, 0] >= 0.5: \n        print('I am {:.2%} sure this is a Dog'.format(predictions[i][0]))\n    else: \n        print('I am {:.2%} sure this is a Cat'.format(1-predictions[i][0]))\n     \n    x=np.array(test[i].T).reshape((224,224,3))\n    plt.imshow(x)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"589f0ac465ee66b534cdd393991e48a7b5f0ed79","collapsed":true},"cell_type":"code","source":"import tensorflow as tf\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1875a10eb230bc47677926147db06d18a4d95f0a","collapsed":true},"cell_type":"code","source":"model_01.weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb9e0bca2cc0d57898abb2cc82cd14d966106c1e","collapsed":true},"cell_type":"code","source":"#print(os.listdir(\"../input/dogs-vs-cats-redux-kernels-edition/test\"))\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52391db03c73763bd50e6ad4ca615a5d1b21456d","collapsed":true},"cell_type":"code","source":"len(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ae630b60c1110878f31b5fb420ed78af81e5787","collapsed":true},"cell_type":"code","source":"img_path = test_images[18]\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\n#x = test[0]\n\nx = np.expand_dims(x, axis=0)\n'''x = np.float32(x)\nprint(x.shape,\nx.dtype)'''\nx = preprocess_input(x)\n\npreds = model_01.predict(x)\n# decode the results into a list of tuples (class, description, probability)\n# (one such list for each sample in the batch)\nprint('Predicted:', (preds.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35d54c7fbcb70cc8bd024f272cbd7f8a832fa2ff","collapsed":true},"cell_type":"code","source":"model.input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b90e27bc796a923372128832f4227d9208627f81","collapsed":true},"cell_type":"code","source":"def show_cats_and_dogs(idx):\n    dog = read_image(test_images[idx])\n    dog = np.array(dog).reshape((224,224,3))\n\n    plt.figure(figsize=(10,5))\n    plt.imshow(dog)\n    plt.show()\n    \nshow_cats_and_dogs(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f889bab199012cf352eda77d1b8d521a6b7d35f","collapsed":true},"cell_type":"code","source":"img_path = '../input/tets-resnet/sasha.jpeg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\npreds = model.predict(x)\n# decode the results into a list of tuples (class, description, probability)\n# (one such list for each sample in the batch)\nprint('Predicted:', decode_predictions(preds, top=3)[0])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}