{"cells":[{"metadata":{"_uuid":"a57b25afd6f76ecb432db2336421b3c89cc9c65a"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"491d99edb798250d917ce5e35c3aed73ece41829"},"cell_type":"markdown","source":"# Contents\n1.  [Dataset Importing](#1)\n2. [Data preprocessing](#2)\n3. [Explorative Data Analysis](#3)\n4. [Dimension Reduction : PCA method](#4)\n5. [Regression Anlaysis](#5) \n5. [Neural Network Analysis](#6)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport itertools\nfrom itertools import chain\nfrom sklearn.feature_selection import RFE\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, learning_curve, train_test_split\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score,mean_squared_error\nimport keras\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"389408cbead21eb522536a60d2cbfd82c33010b4"},"cell_type":"markdown","source":"# <a id=\"1\"></a><br> Dataset import"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/kc_house_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6672a2d16d712615cd6914fffd3444ac01dc53f8"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6600e54bd1956edc3c007b46800a58fb245190d"},"cell_type":"code","source":"print(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a91ab101fc752022e8b567df809297b31054e8b"},"cell_type":"markdown","source":"# <a id=\"2\"></a><br> Data Preprocessing"},{"metadata":{"trusted":true,"_uuid":"fae606df49b1ff46dc4ffbce952d42c6806d2cdc"},"cell_type":"code","source":"## Column years passed after recent built or renovate is added ##\n\ndata['year_pass'] = 0\ndata['year_pass'] = data.yr_renovated-data.yr_built\ndata.year_pass = pd.Series([x+2018 if x <0 else x for x in data.year_pass])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"369777ae572a01b0c4ab81f9722b777d5fbc834f"},"cell_type":"code","source":"## Column 'id' and 'zipcode' are withdrawn since I thought that they don't have meaningful implication ## \n\ndata.drop(columns=['date','id','zipcode'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6038f7509218cf79d13ff40364a1ce9fcf0374c6"},"cell_type":"markdown","source":"# <a id=\"3\"></a><br> Explorative Data Analysis"},{"metadata":{"trusted":true,"_uuid":"f30ccf0bec3606ac02cedd6298f9eee18a92313c"},"cell_type":"code","source":"def plot_distribution(column1,column2, size_bin) :  \n    tmp1 = data[column1].head()\n    tmp2 = data[column2].head()\n    hist_data = [tmp1, tmp2]\n    \n    group_labels = ['malignant', 'benign']\n    colors = ['#FFD700', '#7EC0EE']\n\n    fig = ff.create_distplot(hist_data, group_labels, colors = colors, show_hist = True, bin_size = size_bin, curve_type='kde')\n    \n    fig['layout'].update(title = column1)\n\n    py.iplot(fig, filename = 'Density plot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f71e61c52a8aa212d94be87d12ca6d64348ac56"},"cell_type":"code","source":"import random\ndef dist_plot(column,ran):\n    \n    color = ['c','orange','lightgrey']\n    data[column].plot.hist(color=color[ran],figsize=(10,6),bins=100)\n    plt.title(column+\" Distribution\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"eb8068778804dce02ece18673b1f220af474f9e5"},"cell_type":"code","source":"for i,j in enumerate(data.columns[1:]):\n    col_index = int(i) % 3\n    dist_plot(j,col_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"85ad7fe89df6097f713eb63cfe0bfdbccc073dda"},"cell_type":"code","source":"### Showing correlation matrix and heatmap figure\n\ncorr_mat = data.corr()\nplt.figure(figsize=(12,8))\nsns.heatmap(corr_mat)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c44be70457154580ec70250b6fc969ec54b4bbd"},"cell_type":"markdown","source":"# <a id=\"4\"></a><br> Dimension Reduction : PCA method"},{"metadata":{"trusted":true,"_uuid":"43de975a1c3976e1ffdbf1fa55824fe5e095e0ed"},"cell_type":"code","source":"target_pca = data['price']\ndata_pca = data.drop('price', axis=1)\n\ntarget_pca = pd.DataFrame(target_pca)\n\n### normalizing data\nX_pca = data_pca.values\nX_std = StandardScaler().fit_transform(X_pca)\n\npca = PCA(svd_solver='full')\npca_std = pca.fit(X_std, target_pca).transform(X_std)\n\npca_std = pd.DataFrame(pca_std)\npca_std = pca_std.merge(target_pca, left_index = True, right_index = True, how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4264de12be09a7a062fa6aac93f05ddae3a1e90"},"cell_type":"code","source":"var_pca = pd.DataFrame(pca.explained_variance_ratio_)\nvar_pca = var_pca.T\n\n#----------SUM AND DROP COMP [7:30]\ncol_list = list(v for v in chain(pca_std.columns[10:18])) \nvar_pca['OTHERS_COMP'] = var_pca[col_list].sum(axis=1)\nvar_pca.drop(var_pca[col_list],axis=1,inplace=True)\nvar_pca = var_pca.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33fcf245f6a79ba90159788b8ae0db7c2ea127cd"},"cell_type":"code","source":"### table of variances explained by each components\nvar_pca","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca19dcc858dd4feb5eaea098a247fe243bc83dc5"},"cell_type":"code","source":"labels = ['Component1','Component2','Component3','Component4','Component5','Component6','Component7','Component8','Component9','Component10','other Components']\ntrace = go.Pie( labels=labels, values=var_pca[0],\n              opacity=1,\n              textfont=dict(size=15)\n              )\nlayout = dict(title=\"Variances explained by Each Componets: \" + \"10 Components among 17 are explaining 89.6%\")\n\nfig = dict(data=[trace], layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd39851b489b555b7a50460b9eb57136e9fc7ea3"},"cell_type":"markdown","source":"# <a id=\"5\"><a/><br> Regession Analysis"},{"metadata":{"trusted":true,"_uuid":"d79f1ece9af146e332a06c47f664e2c116457259"},"cell_type":"code","source":"train_data, test_data = train_test_split(data, train_size=0.8, random_state=3)\nY_train = train_data.price \nX_train = train_data.iloc[:,2:]\nY_test  = test_data.price\nX_test  = test_data.iloc[:,2:]\nY_train = np.array(Y_train, dtype=pd.Series).reshape(-1,1)\nY_test = np.array(Y_test, dtype=pd.Series).reshape(-1,1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b0f7d627020463ba2d0bf0056956bebcd14a54a"},"cell_type":"code","source":"lm = LinearRegression()\nlm.fit(np.array(X_train), np.array(Y_train))\npred = lm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b61efa93bb3ec4dab8234a6fa36b1b5968f519a0"},"cell_type":"code","source":"print( \"Mean Squared Error is : \"+ str(np.sqrt(mean_squared_error(Y_test,pred))))\nprint( \"Linear Regression Score is : \" + str(lm.score(X_test,Y_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"feff1a703d52ca659bfa848b91f39ad467935c56"},"cell_type":"markdown","source":"# Lasso Regularization doesn't provide better Result...."},{"metadata":{"trusted":true,"_uuid":"c7313f073917d8bbf463681bb99c64589a5f2df7"},"cell_type":"code","source":"lasso = Lasso()\nlasso.fit(np.array(X_train), np.array(Y_train))\npred1 = lasso.predict(X_test)\n\nprint( \"Mean Squared Error is : \"+ str(np.sqrt(mean_squared_error(Y_test,pred1))))\nprint( \"Linear Regression Score is : \" + str(lasso.score(X_test,Y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0b43251bf2058c3f73c783e13caa750e5bab518"},"cell_type":"markdown","source":"# <a id=\"6\"></a><br> Neural Network Analysis"},{"metadata":{"trusted":true,"_uuid":"020154b46b104ab676c3d61a4973f10a5b845298"},"cell_type":"code","source":"data.iloc[:,1:].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8129cc23b37f284f0b2c6674bbaa697136771a24","scrolled":true},"cell_type":"code","source":"### model fitting using deep learning\nfrom keras.callbacks import EarlyStopping\nearly_stopping_monitor = EarlyStopping(patience=5)\n\npredictors = X_train\ntarget = Y_train\n# Specify the model\nn_cols = predictors.shape[1]\nmodel = Sequential()\nmodel.add(Dense(50, activation='relu', input_shape = (n_cols,)))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(1))\n\n# Compile the model\n\nmodel.compile(optimizer='adam', loss='mean_squared_error',metrics=['mae'])\n\n# Fit the model\nhist = model.fit(predictors,target, batch_size=100, epochs=100, validation_split=0.2,verbose=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f7f7c56cb3f7ace0777994f5c5f51341998bd9c2"},"cell_type":"code","source":"hist.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c506d83585d4a511aa1eec9a0938e2908143f9f"},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nplt.plot(hist.history['mean_absolute_error'])\nplt.plot(hist.history['val_mean_absolute_error'])\nplt.xticks(range(0,100,5))\nplt.xlabel(\"epoch\",fontsize=15)\n#plt.plot(hist.history['val_loss'])\nplt.legend(['Train','Test'],loc='upper right',fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcb0188e30879f1376f916750bbb7c9f12974983"},"cell_type":"code","source":"print(\"Mean Absolute Error(MAE) for Training set is : \" + str(hist.history['mean_absolute_error'][99]))\nprint(\"Mean Absolute Error(MAE) for Validation set is : \" + str(hist.history['val_mean_absolute_error'][99]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}