{"cells":[{"metadata":{"_cell_guid":"e81ee64d-e474-4662-9036-ce23df615199","_uuid":"b6269c0e8f417f82daf093dda8fa0da6d2c57d86"},"cell_type":"markdown","source":"# Introduction\n**This will be your workspace for Kaggle's Machine Learning education track.**\n\nYou will build and continually improve a model to predict housing prices as you work through each tutorial.  Fork this notebook and write your code in it.\n\nThe data from the tutorial, the Melbourne data, is not available in this workspace.  You will need to translate the concepts to work with the data in this notebook, the Iowa data.\n\nCome to the [Learn Discussion](https://www.kaggle.com/learn-forum) forum for any questions or comments. \n\n# Write Your Code Below\n\n"},{"metadata":{"_cell_guid":"86b26423-563a-4fa1-a595-89e25ff93089","_uuid":"1c728098629e1301643443b1341556a15c089b2b","collapsed":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ntrain.dropna(axis=0, subset = ['SalePrice'], inplace = True)\n\ntarget = train.SalePrice\n\ncols_with_missing = [col for col in train.columns \n                                 if train[col].isnull().any()]                                  \ncandidate_train_predictors = train.drop(['Id', 'SalePrice'] + cols_with_missing, axis=1)\ncandidate_test_predictors = test.drop(['Id'] + cols_with_missing, axis=1)\n\nlow_cardinality_cols = [cname for cname in candidate_train_predictors.columns if \n                                candidate_train_predictors[cname].nunique() < 10 and\n                                candidate_train_predictors[cname].dtype == \"object\"]\nnumeric_cols = [cname for cname in candidate_train_predictors.columns if \n                                candidate_train_predictors[cname].dtype in ['int64', 'float64']]\nmy_cols = low_cardinality_cols + numeric_cols\ntrain_predictors = candidate_train_predictors[my_cols]\ntest_predictors = candidate_test_predictors[my_cols]\n\none_hot_encoded_training_predictors = pd.get_dummies(train_predictors)\n","execution_count":41,"outputs":[]},{"metadata":{"_cell_guid":"1f3eceea-33b0-4636-9b83-320a1c8f434c","_uuid":"53941e1856096b2902375ca61e3cd0d4f3386520","scrolled":false,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef get_mae(X, y):\n    return -1 * cross_val_score(RandomForestRegressor(50), \n                                X, y, \n                                scoring = 'neg_mean_absolute_error').mean()\n\npredictors_without_categoricals = train_predictors.select_dtypes(exclude=['object'])\n\nmae_without_categoricals = get_mae(predictors_without_categoricals, target)\n\nmae_one_hot_encoded = get_mae(one_hot_encoded_training_predictors, target)\n\nprint('Mean Absolute Error when Dropping Categoricals: ' + str(int(mae_without_categoricals)))\nprint('Mean Abslute Error with One-Hot Encoding: ' + str(int(mae_one_hot_encoded)))","execution_count":42,"outputs":[]},{"metadata":{"_cell_guid":"c0a6468a-3cc3-4e36-acce-f086fad3c65d","_uuid":"e3feeb64c03c3e00ecc238865693d20bb3cf316a","collapsed":true,"trusted":true},"cell_type":"code","source":"my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': target})\nmy_submission.to_csv('submission.csv', index=False)","execution_count":44,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}