{"cells":[{"metadata":{"_uuid":"b2d3c0b15e6e08625a3352ce75b2671ea73198e7"},"cell_type":"markdown","source":"# Base line model to show how to use tf with Object detection API for inference on the open images dataset\n\n## Overview\nThis is my very first Kaggle kernel! So happy....\nThis kernel is a proof of concept for using the tf object detection api on the data. I have noticed that many people are detered by Kaggle inability to access the outside world (like colab) so they are not using pre-trained models. The way to do that is to upload the pre trained models as private dataset. In this case I used the goodle trained model from their zoo. It is exptremely slow (44 seconds per image) so on the test set would take.... would take... mmmm very long time.\n\n## Data used in this kernel\nLabels for the open images dataset from https://github.com/tensorflow/models/blob/master/research/object_detection/data/oid_bbox_trainable_label_map.pbtxt)\n\nModels from:\nhttp://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_oid_14_10_2017.tar.gz\nhttp://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_oid_2018_01_28.tar.gz\n(I thought there were problems with the newer model but it turned out to be my mistake. The 2017 model is frcnn.pb, the 2018 is frcnn2.pb)\n\nI have also uploaded the tf models git as a dataset but haven't played with it directly.\n\nThe model is faster rcnn with inception v2 as base.\nIt is a very slow process but you can see how it performs on the leaderboard (with few tweaks) currently number 4"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"import tensorflow as tf\nimport cv2 as cv\n\n#just double checking that GPU is actually reconized\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7f81aabd0b9d2463c29634f5e6a5669f65d4496","collapsed":true},"cell_type":"code","source":"#load labels\ndf = pd.read_csv('../input/openimages-labels/labels.csv')\ndf.set_index('id', drop=False)\nprint(df.head(5))\n#not a pandas expert.... there must be a way to search for the id but this is good enough (id-1)\nprint(df.loc[4,'display'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5a3b895964a69b41520f26aaeeb1ffb69d29b63","collapsed":true},"cell_type":"code","source":"# Read the graph.\nwith tf.gfile.FastGFile('../input/frcnn-tf-model/frcnn2.pb', 'rb') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8fcc7456f0728e83507f72099481335d56bb243","collapsed":true},"cell_type":"code","source":"#this takes a while...\nwith tf.Session() as sess:\n    # Restore session\n    sess.graph.as_default()\n    tf.import_graph_def(graph_def, name='')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c31cc1c67419aa99c32a3f86241f10d62074b91","collapsed":true},"cell_type":"code","source":"#do the actual inference\nimport time\n\nwith tf.Session() as sess:\n    # Read and preprocess an image.\n    img = cv.imread('../input/google-ai-open-images-object-detection-track/test/challenge2018_test/00febf2235f60610.jpg')\n    rows = img.shape[0]\n    cols = img.shape[1]\n    inp = cv.resize(img, (300, 300))\n    inp = inp[:, :, [2, 1, 0]]  # BGR2RGB\n    s = time.time()\n    # Run the model\n    out = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),\n                    sess.graph.get_tensor_by_name('detection_scores:0'),\n                    sess.graph.get_tensor_by_name('detection_boxes:0'),\n                    sess.graph.get_tensor_by_name('detection_classes:0')],\n                   feed_dict={'image_tensor:0': inp.reshape(1, inp.shape[0], inp.shape[1], 3)})\n    print(\"it took {} seconds for one image\".format(time.time()-s))\n    # Visualize detected bounding boxes.\n    num_detections = int(out[0][0])\n    print(num_detections)\n    preds_list=[]\n    for i in range(num_detections):\n        classId = int(out[3][0][i])\n        score = float(out[1][0][i])\n        bbox = [float(v) for v in out[2][0][i]]\n        if score > 0.3:\n            x = bbox[1] * cols\n            y = bbox[0] * rows\n            right = bbox[3] * cols\n            bottom = bbox[2] * rows\n            cv.rectangle(img, (int(x), int(y)), (int(right), int(bottom)), (125, 255, 51), thickness=3)\n            className = df.loc[classId-1, 'display']\n            print(\"classID {}, name {}, score {}\".format(classId, className, score))\n            preds_list.append(className)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8231b06c24e4a69a657def7f2d21f1529015eaa","collapsed":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nplt.imshow(img, aspect='auto')\nplt.show()\npreds_list","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}