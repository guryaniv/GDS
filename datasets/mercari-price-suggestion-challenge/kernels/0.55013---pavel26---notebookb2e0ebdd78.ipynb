{"nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "version": "3.6.4", "mimetype": "text/x-python", "name": "python"}}, "nbformat_minor": 1, "cells": [{"outputs": [], "cell_type": "code", "execution_count": null, "source": ["from datetime import datetime\n", "import numpy as np\n", "import pandas as pd\n", "from scipy import sparse\n", "\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.cross_validation import train_test_split\n", "from sklearn.linear_model import Ridge\n", "from sklearn.linear_model import RidgeCV\n", "from sklearn.pipeline import FeatureUnion\n", "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n", "import xgboost as xgb\n", "import math\n", "from sklearn.metrics import mean_squared_error\n", "from sklearn.grid_search import GridSearchCV\n", "\n", "# set seed\n", "np.random.seed(42)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "# from subprocess import check_output\n", "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "metadata": {"collapsed": true, "_uuid": "3570a09f878825f9fda8195e95ad1eaf0d1a7980", "_cell_guid": "945451ec-93bd-4b82-8559-140232d7b33c"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["%%time\n", "\n", "trainData = pd.read_table('../input/train.tsv')\n", "testData = pd.read_table('../input/test.tsv')\n", "\n", "print(trainData.shape, testData.shape)"], "metadata": {"collapsed": true, "_uuid": "922ba6a51c24f1b94ec8f8a0b5c9e8deee8fe515", "_cell_guid": "4020a355-b404-41da-bc3c-282c750a5a32"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["trainData = trainData.drop(trainData[(trainData.price < 3.0)].index)\n", "trainData.shape"], "metadata": {"collapsed": true, "_uuid": "d53990ed7365039ed605b5b66fe37f06bb4d205b", "_cell_guid": "d15e7cbc-2e92-442b-9bbd-850c13d24fd1"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["%%time\n", "# get name and description lengths\n", "def wordCount(text):\n", "    try:\n", "        if text == 'No description yet':\n", "            return 0\n", "        else:\n", "            text = text.lower()\n", "            words = [w for w in text.split(\" \")]\n", "            return len(words)\n", "    except: \n", "        return 0\n", "trainData['descLen'] = trainData['item_description'].apply(lambda x: wordCount(x))\n", "testData['descLen'] = testData['item_description'].apply(lambda x: wordCount(x))\n", "trainData['nameLen'] = trainData['name'].apply(lambda x: wordCount(x))\n", "testData['nameLen'] = testData['name'].apply(lambda x: wordCount(x))\n", "trainData.head()"], "metadata": {"collapsed": true, "_uuid": "e6cf00b14a4bf1e4a79995a6c68f5590b320a11c", "_cell_guid": "25209a03-8dd6-4982-a580-c9ff7875d341"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["%%time\n", "# split category name into 3 parts\n", "def split_cat(text):\n", "    try: return text.split(\"/\")\n", "    except: return (\"No Label\", \"No Label\", \"No Label\")\n", "trainData['subcat_1'], trainData['subcat_2'], trainData['subcat_3'] = \\\n", "zip(*trainData['category_name'].apply(lambda x: split_cat(x)))\n", "testData['subcat_1'], testData['subcat_2'], testData['subcat_3'] = \\\n", "zip(*testData['category_name'].apply(lambda x: split_cat(x)))"], "metadata": {"collapsed": true, "_uuid": "0d1dddc301f344b3dcbd520ee250348d46f2a4d8", "_cell_guid": "a31302c6-60b7-46da-89c0-8b6e7f967a88"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["%%time\n", "fullData = pd.concat([trainData,testData])\n", "brands = set(fullData['brand_name'].values)\n", "trainData.brand_name.fillna(value=\"missing\", inplace=True)\n", "testData.brand_name.fillna(value=\"missing\", inplace=True)\n", "\n", "missing = len(trainData.loc[trainData['brand_name'] == 'missing'])\n", "def brandfinder(line):\n", "    brand = line[0]\n", "    name = line[1]\n", "    namesplit = name.split(' ')\n", "    if brand == 'missing':\n", "        for x in namesplit:\n", "            if x in brands:\n", "                return name\n", "    if name in brands:\n", "        return name\n", "    return brand\n", "trainData['brand_name'] = trainData[['brand_name','name']].apply(brandfinder, axis = 1)\n", "testData['brand_name'] = testData[['brand_name','name']].apply(brandfinder, axis = 1)\n", "found = missing-len(trainData.loc[trainData['brand_name'] == 'missing'])\n", "print(found)"], "metadata": {"collapsed": true, "_uuid": "5b572a93ef01101d19c91c54412c92a132f70072", "_cell_guid": "39f98551-563a-4df9-8786-e9e5d599f1fe"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["%%time\n", "# Scale target variable to log.\n", "# trainData[\"target\"] = np.log1p(trainData.price)\n", "\n", "# Split training examples into train/dev examples.\n", "trainData, devData = train_test_split(trainData, random_state=42, train_size=0.9)\n", "\n", "# Calculate number of train/dev/test examples.\n", "n_trains = trainData.shape[0]\n", "n_devs = devData.shape[0]\n", "n_tests = testData.shape[0]\n", "print(\"Training on\", n_trains, \"examples\")\n", "print(\"Validating on\", n_devs, \"examples\")\n", "print(\"Testing on\", n_tests, \"examples\")\n", "\n", "# Concatenate train - dev - test data for easy to handle\n", "fullData = pd.concat([trainData, devData, testData])"], "metadata": {"collapsed": true, "_uuid": "8b964d10340dfd19b9565ddc4850f344770b4514", "_cell_guid": "63815bd6-f73c-4ed7-a603-39fcf7131697"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["%%time\n", "\n", "# Filling missing values\n", "def fill_missing_values(df):\n", "    df.category_name.fillna(value=\"missing\", inplace=True)\n", "    df.brand_name.fillna(value=\"missing\", inplace=True)\n", "    df.item_description.fillna(value=\"missing\", inplace=True)\n", "    df.item_description.replace('No description yet',\"missing\", inplace=True)\n", "    return df\n", "\n", "print(\"Filling missing data ...\")\n", "fullData = fill_missing_values(fullData)\n", "print(fullData.category_name[1])"], "metadata": {"collapsed": true, "_uuid": "fc1a9835e779a009696cacae01107480d9c0126a", "_cell_guid": "0a4d3ce3-0718-4007-a5e7-29145246da29"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["%%time\n", "\n", "print(\"Processing categorical data...\")\n", "le = LabelEncoder()\n", "\n", "le.fit(fullData.category_name)\n", "fullData['category'] = le.transform(fullData.category_name)\n", "\n", "le.fit(fullData.brand_name)\n", "fullData.brand_name = le.transform(fullData.brand_name)\n", "\n", "le.fit(fullData.subcat_1)\n", "fullData.subcat_1 = le.transform(fullData.subcat_1)\n", "\n", "le.fit(fullData.subcat_2)\n", "fullData.subcat_2 = le.transform(fullData.subcat_2)\n", "\n", "le.fit(fullData.subcat_3)\n", "fullData.subcat_3 = le.transform(fullData.subcat_3)\n", "\n", "del le"], "metadata": {"collapsed": true, "_uuid": "468720e988788007e1a382e1763b5e169b09ac8f", "_cell_guid": "f8831f3b-3612-406a-88e6-6e1edf1aa580"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["%%time\n", "\n", "print(\"Handling missing values...\")\n", "fullData['category_name'] = fullData['category_name'].fillna('missing').astype(str)\n", "fullData['subcat_1'] = fullData['subcat_1'].astype(str)\n", "fullData['subcat_2'] = fullData['subcat_2'].astype(str)\n", "fullData['subcat_3'] = fullData['subcat_3'].astype(str)\n", "fullData['brand_name'] = fullData['brand_name'].fillna('missing').astype(str)\n", "fullData['shipping'] = fullData['shipping'].astype(str)\n", "fullData['item_condition_id'] = fullData['item_condition_id'].astype(str)\n", "fullData['descLen'] = fullData['descLen'].astype(str)\n", "fullData['nameLen'] = fullData['nameLen'].astype(str)\n", "fullData['item_description'] = fullData['item_description'].fillna('No description yet').astype(str)"], "metadata": {"collapsed": true, "_uuid": "24fb040f590668f5b2450abf4335d89535cb8a31", "_cell_guid": "a34dd1e1-abff-454c-be95-2402d8afee7b"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["%%time\n", "\n", "print(\"Vectorizing data...\")\n", "default_preprocessor = CountVectorizer().build_preprocessor()\n", "def build_preprocessor(field):\n", "    field_idx = list(fullData.columns).index(field)\n", "    return lambda x: default_preprocessor(x[field_idx])\n", "\n", "vectorizer = FeatureUnion([\n", "    ('name', CountVectorizer(\n", "        ngram_range=(1, 2),\n", "        max_features=100000,\n", "        stop_words='english',\n", "        preprocessor=build_preprocessor('name'))),\n", "    ('category_name', CountVectorizer(\n", "        token_pattern='.+',\n", "        max_features=20000,\n", "        stop_words='english',\n", "        preprocessor=build_preprocessor('category_name'))),\n", "    ('subcat_1', CountVectorizer(\n", "        token_pattern='.+',\n", "        stop_words='english',\n", "        preprocessor=build_preprocessor('subcat_1'))),\n", "    ('subcat_2', CountVectorizer(\n", "        token_pattern='.+',\n", "        stop_words='english',\n", "        preprocessor=build_preprocessor('subcat_2'))),\n", "    ('subcat_3', CountVectorizer(\n", "        token_pattern='.+',\n", "        stop_words='english',\n", "        max_features=20000,\n", "        preprocessor=build_preprocessor('subcat_3'))),\n", "    ('brand_name', CountVectorizer(\n", "        token_pattern='.+',\n", "        stop_words='english',\n", "        preprocessor=build_preprocessor('brand_name'))),\n", "    ('shipping', CountVectorizer(\n", "        token_pattern='\\d+',\n", "        preprocessor=build_preprocessor('shipping'))),\n", "    ('item_condition_id', CountVectorizer(\n", "        token_pattern='\\d+',\n", "        preprocessor=build_preprocessor('item_condition_id'))),\n", "    ('item_description', TfidfVectorizer(\n", "        ngram_range=(1, 3),\n", "        max_features=20000,\n", "        stop_words='english',\n", "        preprocessor=build_preprocessor('item_description'))),\n", "])\n", "\n", "X = vectorizer.fit_transform(fullData.values)"], "metadata": {"collapsed": true, "_uuid": "b81fdab4b08fc93fe7b43a501aac4e52e8b5e436", "_cell_guid": "13d97089-0908-498a-bc3a-c27abebb98ac"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["X = sparse.hstack((X, fullData[['nameLen', 'descLen']].astype(float).as_matrix()), format = 'csr')\n", "\n", "trainData[\"target\"] = np.log1p(trainData.price)\n", "devData[\"target\"] = np.log1p(devData.price)\n", "\n", "X_train = X[:n_trains]\n", "Y_train = trainData.target.values.reshape(-1, 1)\n", "\n", "X_dev = X[n_trains:n_trains+n_devs]\n", "Y_dev = devData.target.values.reshape(-1, 1)\n", "\n", "X_test = X[n_trains+n_devs:]\n", "\n", "print(X.shape, X_train.shape, X_dev.shape, X_test.shape)"], "metadata": {"collapsed": true, "_uuid": "748f962c0ad6e8220153003ff91a581f23c0c23b", "_cell_guid": "59b54bac-9e05-4ba8-b942-4b9045f0e5d3"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# del trainData\n", "# del testData\n", "# del fullData"], "metadata": {"collapsed": true, "_uuid": "c773137cee9a14871175dd0fd540badb8bcd5a02", "_cell_guid": "4a2e62d5-cde9-4029-ae94-6859b7cc2e73"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["%%time\n", "%env JOBLIB_TEMP_FOLDER=/tmp\n", "\n", "xgb_model = xgb.XGBRegressor()\n", "\n", "xgb_parameters = {'n_estimators': [100],\n", "              'subsample': [0.5],\n", "              'colsample_bytree': [0.1],\n", "              'colsample_bylevel': [0.1],\n", "              'reg_lambda': [0.7],\n", "              'reg_alpha': [0.3],\n", "              'seed': [42]}\n", "\n", "\n", "xgb_clf = GridSearchCV(xgb_model, xgb_parameters, n_jobs=-1, cv=3, \n", "                   scoring='neg_mean_squared_error')\n", "\n", "xgb_clf.fit(X_train, Y_train)\n", "\n", "print('XGBoost training score: ', mean_squared_error(Y_train, xgb_clf.predict(X_train)))\n", "print('XGBoost validation score: ', mean_squared_error(Y_dev, xgb_clf.predict(X_dev)))"], "metadata": {"collapsed": true, "scrolled": true, "_uuid": "0a8c922fe17b2e516bdcba5d25e97adb9e5291d3", "_cell_guid": "48f5c95c-3a82-4bbb-96ed-c292d15ce430"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# xgb_pred_test = np.expm1(xgb_clf.predict(X_test))\n", "\n", "# submissionData = pd.DataFrame({\n", "#         \"test_id\": testData.test_id,\n", "#         \"price\": xgb_pred_test.reshape(-1),\n", "# })\n", "\n", "# submissionData.to_csv(\"./xgb_submission_first.csv\", index=False)"], "metadata": {"collapsed": true, "_uuid": "8af6cce6a01f8a2e12dce931919cd3195b454d90", "_cell_guid": "c1d8b718-8fbb-4ea5-8b3b-53354c9dd49d"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["%%time\n", "ridge_model = Ridge(\n", "    fit_intercept=True, alpha=[10.0],\n", "    normalize=False, solver='sag', tol=0.05, random_state=42)\n", "\n", "ridge_model.fit(X_train, Y_train)\n", "\n", "print('Ridge training score: ', mean_squared_error(Y_train, ridge_model.predict(X_train)))\n", "print('Ridge validation score: ', mean_squared_error(Y_dev, ridge_model.predict(X_dev)))"], "metadata": {"collapsed": true, "_uuid": "23e9cdb02892b1c6c51031876d4677bb3878b454", "_cell_guid": "97dbc38a-4f93-40fb-a844-239c8ac0d122"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# ridge_pred_test = np.expm1(ridge_model.predict(X_test))\n", "\n", "# submissionData = pd.DataFrame({\n", "#         \"test_id\": testData.test_id,\n", "#         \"price\": ridge_pred_test.reshape(-1),\n", "# })\n", "\n", "# submissionData.to_csv(\"./ridge_submission_first.csv\", index=False)"], "metadata": {"collapsed": true, "_uuid": "f8958feb0a54e893e8fd1987e6cf786e3481fe12", "_cell_guid": "8693040f-4761-405b-bf7f-4b731edd4e92"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["%%time\n", "\n", "xgb_pred_dev = np.expm1(xgb_clf.predict(X_dev))\n", "ridge_pred_dev = np.expm1(ridge_model.predict(X_dev))\n", "\n", "xgb_pred_test = np.expm1(xgb_clf.predict(X_test))\n", "ridge_pred_test = np.expm1(ridge_model.predict(X_test))\n", "\n", "def aggregate_predicts2(Y1, Y2,ratio):\n", "    assert Y1.shape == Y2.shape\n", "    return Y1 * ratio + Y2 * (1.0 - ratio)\n", "\n", "#ratio optimum finder\n", "best = 0\n", "lowest = 0.99\n", "for i in range(100):\n", "    r = i*0.01\n", "    Y_dev_preds = aggregate_predicts2(xgb_pred_dev, ridge_pred_dev, r)\n", "    fpred = mean_squared_error(Y_dev, Y_dev_preds)\n", "    if fpred < lowest:\n", "        best = r\n", "        lowest = fpred\n", "    print(str(r) + \" - score for XGBoost + Ridge on dev set:\", fpred)\n"], "metadata": {"collapsed": true, "_uuid": "07e49e7a00d65e0f239cee368ede37d2db5c46c2", "_cell_guid": "20bb9fb5-b739-41cc-a391-af7aa8fced42"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["weighted_preds = aggregate_predicts2(xgb_pred_test, ridge_pred_test, best)\n", "\n", "submissionData = pd.DataFrame({\n", "        \"test_id\": testData.test_id,\n", "        \"price\": weighted_preds.reshape(-1),\n", "})\n", "\n", "submissionData.to_csv(\"./ridge_xgb_weighted_submission.csv\", index=False)"], "metadata": {"collapsed": true, "_uuid": "030f42870cf5f6f1f88e2a056a6e5e8186ea3c1c", "_cell_guid": "154de846-ab98-424d-a25f-e817a7febeba"}}]}