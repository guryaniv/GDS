{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\ndir_f = '../input/'\ndir_list = os.listdir(dir_f)\n#print(dir_list)\n\ndf = pd.read_csv('../input/train.csv')\ndf = df.drop('id', axis=1)\ndf.head()","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print('# unique',len(df.species.unique()))\nprint('# rows', len(df.index))","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"2879f285-f8c1-4c80-afb6-6facecc3a819","_uuid":"b36772bdc3dabe76a7104dc59a41a4cbe7ce8487"},"cell_type":"markdown","source":"**K Nearest Neighbors (p=1)**"},{"metadata":{"_cell_guid":"492385f1-008d-4f6c-a616-99035d4327fc","_uuid":"ce2b8c0b039ab74493b3bf5259b6e72253197162","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\ntarget = 'species'\nX = df.drop(target,axis=1)\ny = df[target]\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n\nknn = KNeighborsClassifier(n_neighbors=1, p=1)\nknn.fit(X_train, y_train)\nacc = knn.score(X_val, y_val)\nprint('accuracy', acc)","execution_count":24,"outputs":[]},{"metadata":{"_cell_guid":"d3ab4489-a31b-4e48-8711-43e130c1097b","_uuid":"198db7d827fef98b5956c39d3ee0533f0a40d430"},"cell_type":"markdown","source":"**Neural Network**"},{"metadata":{"_cell_guid":"8e676abe-db90-4ff8-8503-e0f36e921f5a","_uuid":"b52857999d685832a780d77198c265707640c648","trusted":true},"cell_type":"code","source":"# Import necessary modules\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import SGD, Adam\nfrom sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\ntarget = lb_make.fit_transform(df['species'])\ntarget = to_categorical(target)\nX = df.drop('species',axis=1)\n\ndef simple_NN(input_shape, nodes_per=[60], hidden=0, out=2, act_out='softmax', act_hid='relu', drop=True, d_rate=0.1):\n  \"\"\"Generate a keras neural network with arbitrary number of hidden layers each having the same number of nodes\"\"\"\n  model = Sequential()\n  model.add(Dense(nodes_per[0],activation=act_hid,input_shape=input_shape))\n  if drop == True:\n      model.add(Dropout(d_rate))\n  try:\n    if hidden != 0:\n      for i,j in zip(range(hidden), nodes_per[1:]):\n          model.add(Dense(j,activation=act_hid))\n          if drop == True:\n              model.add(Dropout(d_rate))\n    model.add(Dense(out,activation=act_out))\n    return(model)\n  except:\n    print('Error in generating hidden layers')\n                  \nmodel = simple_NN((X.shape[1],), nodes_per=[60], hidden=0, out=len(df.species.unique()), drop=True)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\nearly_stopping_monitor = EarlyStopping(patience=5)                  \nhistory = model.fit(X,target,epochs=1000, validation_split=0.1, callbacks=[early_stopping_monitor], verbose=False)\nprint('model trained')","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"d64eec2a-5521-4fce-b9b4-4a20be9ba9ec","_uuid":"179fb4d3e033fb7790801ffc24bd55d4b69761c7"},"cell_type":"markdown","source":"**Plot Model Statistics**"},{"metadata":{"_cell_guid":"6610395d-2f18-454a-b784-2804dacc8564","_uuid":"27b0fa329233ed540ed44021527438e27cb9f996","trusted":true},"cell_type":"code","source":"def plt_perf(name, p_loss=False, p_acc=False, val=False, size=(15,9), save=False):\n  \"\"\"Plot model statistics for keras models\"\"\"\n  if p_loss or p_acc:\n    if p_loss:\n      plt.figure(figsize = size)\n      plt.title('Loss')\n      plt.plot(name.history['loss'], 'b', label='loss')\n      if val:\n        plt.plot(name.history['val_loss'], 'r', label='val_loss')\n      plt.xlabel('Epochs')\n      plt.ylabel('Value')\n      plt.legend()\n      plt.show()\n      if save:\n        plt.savefig('loss.png')\n    if p_acc:\n      plt.figure(figsize = size)\n      plt.title('Accuracy')\n      plt.plot(name.history['acc'], 'b', label='acc')\n      if val:\n        plt.plot(name.history['val_acc'], 'r', label='val_acc')\n      plt.xlabel('Epochs')\n      plt.ylabel('Value')\n      plt.legend()\n      plt.show()\n      if save:\n        plt.savefig('acc.png')\n  else:\n    print('No plotting since all parameters set to false.')\n    \nplt_perf(history, p_loss=True, p_acc=True, val=True)","execution_count":27,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}