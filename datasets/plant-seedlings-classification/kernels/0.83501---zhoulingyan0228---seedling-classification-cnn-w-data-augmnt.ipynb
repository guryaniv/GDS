{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport math\nimport sklearn\nimport sklearn.preprocessing\nimport skimage\nimport skimage.io\nimport skimage.color\nimport seaborn as sns\nimport random\nimport os\nimport cv2\nimport glob\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7b482bd02d28a20c947c543ccd8679353f041e7","collapsed":true},"cell_type":"code","source":"TRAIN_DIR = '../input/train'\nTEST_DIR = '../input/test'\nIMG_HW = 256\n\nlabels_all = os.listdir(TRAIN_DIR)\nN_CLASSES = len(labels_all)\nlabelEncoder = sklearn.preprocessing.LabelEncoder()\nlabelEncoder.fit(labels_all)\n\ntrain_files = glob.glob(TRAIN_DIR+'/*/*.png')\ntrain_labels = [f.split('/')[3] for f in train_files]\ntest_files = glob.glob(TEST_DIR+'/*.png')\n\ntrain_files, train_labels = sklearn.utils.shuffle(train_files, train_labels)\ntrain_labels_encoded = labelEncoder.transform(train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dda3c9240a82793ba902c43b91053ff44da7618"},"cell_type":"code","source":"pd.Series(train_labels_encoded).plot.hist();","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"def jitter(img, max_jitter=25):\n    pts1 = np.array(np.random.uniform(-max_jitter, max_jitter, size=(4,2))+np.array([[0,0],[0,IMG_HW],[IMG_HW,0],[IMG_HW,IMG_HW]])).astype(np.float32)\n    pts2 = np.array([[0,0],[0,IMG_HW],[IMG_HW,0],[IMG_HW,IMG_HW]]).astype(np.float32)\n    M = cv2.getPerspectiveTransform(pts1,pts2)\n    return cv2.warpPerspective(img,M,(IMG_HW,IMG_HW))\n\ndef rotate(img, rotation=None):\n    if rotation == None:\n        rotation = random.randint(0, 360)\n    M = cv2.getRotationMatrix2D((IMG_HW/2,IMG_HW/2),90,1)\n    return cv2.warpAffine(img,M,(IMG_HW,IMG_HW))\n    \ndef resize(img):\n    return cv2.resize(img, (IMG_HW, IMG_HW))\n\ndef train_generator(train_files, train_labels_encoded, augments = 20, img_per_batch=100):\n    idx = 0\n    maxIdx = len(train_files)\n    while True:\n        train_batch = []\n        labels_batch = []\n        for _ in range(img_per_batch):\n            img = resize(skimage.io.imread(train_files[idx])/255.)\n            if img.shape==(256,256,4):\n                img = skimage.color.rgba2rgb(img)\n            train_batch.append(img)\n            labels_batch.append(train_labels_encoded[idx])\n            for _ in range(augments):\n                train_batch.append(rotate(jitter(img)))\n                labels_batch.append(train_labels_encoded[idx])\n            idx = (idx+1)%maxIdx\n        yield np.array(train_batch), np.array(labels_batch)\n\ndef steps_per_epoch(train_files, train_labels_encoded, augments = 20, img_per_batch=100):\n    return int(math.ceil(len(train_files) /img_per_batch))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c39229de568184001a8a5f717fedb2630084cc6e","collapsed":true},"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), strides=2, padding='same', activation='relu', \n                                 kernel_initializer=tf.keras.initializers.Orthogonal(),\n                                 input_shape=(IMG_HW, IMG_HW, 3)))\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), strides=2, padding='same', activation='relu', \n                                 kernel_initializer=tf.keras.initializers.Orthogonal()))\nmodel.add(tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, padding='same'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), strides=2, padding='same', activation='relu'))\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), strides=2, padding='same', activation='relu'))\nmodel.add(tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, padding='same'))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(N_CLASSES, activation='softmax'))\nmodel.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n              optimizer=tf.keras.optimizers.Adam(0.00005),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bca036b026f7804c0b6e3203c8ee9d5783ea60ef","collapsed":true},"cell_type":"code","source":"EPOCHS = 30\nAUGMENTS = 2\nIMG_PER_BATCH = 50\nmodel.fit_generator(train_generator(train_files, train_labels_encoded, AUGMENTS, IMG_PER_BATCH), epochs=EPOCHS, steps_per_epoch=steps_per_epoch(train_files, train_labels_encoded, AUGMENTS, IMG_PER_BATCH), verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfacea8e80cf863a2a9ff7c5ffde35c9d8462174","collapsed":true},"cell_type":"code","source":"def test_generator(test_files):\n    for f in test_files:\n        img = resize(skimage.io.imread(f)/255.)\n        if img.shape==(256,256,4):\n            img = skimage.color.rgba2rgb(img)\n        yield np.array([img])\n    \npredicted_probs = model.predict_generator(test_generator(test_files), steps=len(test_files))\npredicted_classes = np.argmax(predicted_probs, axis=1)\nout_df = pd.DataFrame({'file':[f.split('/')[3] for f in test_files], \n                       'species': labelEncoder.inverse_transform(predicted_classes)})\nout_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}