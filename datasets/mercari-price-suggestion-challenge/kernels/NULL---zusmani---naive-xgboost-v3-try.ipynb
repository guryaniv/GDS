{"nbformat": 4, "cells": [{"cell_type": "code", "source": ["import pandas as pd\n", "import numpy as np\n", "import xgboost as xgb\n", "import time\n", "\n", "def change_datatype(df):\n", "    for col in list(df.select_dtypes(include=['int']).columns):\n", "        if np.max(df[col]) <= 127 and np.min(df[col]) >= -128:\n", "            df[col] = df[col].astype(np.int8)\n", "        elif np.max(df[col]) <= 255 and np.min(df[col]) >= 0:\n", "            df[col] = df[col].astype(np.uint8)\n", "        elif np.max(df[col]) <= 32767 and np.min(df[col]) >= -32768:\n", "            df[col] = df[col].astype(np.int16)\n", "        elif np.max(df[col]) <= 65535 and np.min(df[col]) >= 0:\n", "            df[col] = df[col].astype(np.uint16)\n", "        elif np.max(df[col]) <= 2147483647 and np.min(df[col]) >= -2147483648:\n", "            df[col] = df[col].astype(np.int32)\n", "        elif np.max(df[col]) <= 4294967296 and np.min(df[col]) >= 0:\n", "            df[col] = df[col].astype(np.uint32)\n", "    for col in list(df.select_dtypes(include=['float']).columns):\n", "        df[col] = df[col].astype(np.float32)\n", "        \n", "def count_words(key):\n", "    return len(str(key).split())\n", "\n", "def count_numbers(key):\n", "    return sum(c.isalpha() for c in key)\n", "\n", "def count_upper(key):\n", "    return sum(c.isupper() for c in key)\n", "\n", "def get_mean(df, name, target, alpha=0):\n", "    group = df.groupby(name)[target].agg([np.sum, np.size])\n", "    mean = train[target].mean()\n", "    series = (group['sum'] + mean*alpha)/(group['size']+alpha)\n", "    series.name = name + '_mean'\n", "    return series.to_frame().reset_index()\n", "\n", "def add_words(df, name, length):\n", "    x_data = []\n", "    for x in df[name].values:\n", "        x_row = np.ones(length, dtype=np.uint16)*0\n", "        for xi, i in zip(list(str(x)), np.arange(length)):\n", "            x_row[i] = ord(xi)\n", "        x_data.append(x_row)\n", "    return pd.concat([df, pd.DataFrame(x_data, columns=[name+str(c) for c in range(length)]).astype(np.uint16)], axis=1)\n", "\n", "start_time = time.time()\n", "c_categories = ['name', 'category_name', 'brand_name', 'item_description']\n", "c_means = ['category_name', 'item_condition_id', 'brand_name']\n", "c_texts = ['name', 'item_description']\n", "c_ignors = ['name', 'item_description', 'brand_name', 'category_name', 'train_id', 'test_id', 'price']\n", "\n", "train = pd.read_csv('../input/train.tsv', sep='\\t')\n", "test = pd.read_csv('../input/test.tsv', sep='\\t')\n", "test['price'] = -1\n", "\n", "df = pd.concat([train, test]).reset_index()\n", "change_datatype(df)\n", "df = df.fillna('')\n", "df = add_words(df, 'name', 43) \n", "df = add_words(df, 'item_description', 60)\n", "\n", "for c in c_categories:\n", "     df[c+'_cat'] = pd.factorize(df[c])[0]\n", "\n", "for c in c_texts:\n", "    df[c + '_c_words'] = df[c].apply(count_words)\n", "    df[c + '_c_upper'] = df[c].apply(count_upper)\n", "    df[c + '_c_numbers'] = df[c].apply(count_numbers)\n", "    df[c + '_len'] = df[c].str.len()\n", "    df[c + '_mean_len_words'] = df[c + '_len']/df[c + '_c_words']\n", "    df[c + '_mean_upper'] = df[c + '_len']/df[c + '_c_upper']\n", "    df[c + '_mean_numbers'] = df[c + '_len']/df[c + '_c_numbers']\n", "    \n", "#------- begin feature engineering (Leandro dos Santos Coelho)\n", "df['fe001'] = np.square(df[\"name_mean_len_words\"])\n", "df['fe002'] = np.square(df[\"item_description_mean_len_words\"])\n", "df['fe003'] = np.tanh(df[\"name_mean_len_words\"])\n", "df['fe004'] = np.tanh(df[\"item_description_mean_len_words\"])\n", "df['fe005'] = df[\"name_mean_len_words\"]**2.37\n", "df['fe006'] = df[\"item_description_mean_len_words\"]**2.15\n", "#------- end feature engineering (Leandro dos Santos Coelho)\n", "\n", "d_median = df.median(axis=0)\n", "d_mean = df.mean(axis=0)\n", "\n", "def transform_df(df):\n", "    df = pd.DataFrame(df)\n", "    dcol = [c for c in df.columns if c not in c_ignors]\n", "    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n", "    for c in dcol: #standard arithmetic\n", "        df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n", "        df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n", "        df[c+str('_sq')] = np.power(df[c].values,2).astype(np.float32)\n", "        df[c+str('_sqr')] = np.square(df[c].values).astype(np.float32)\n", "    return df\n", "\n", "def multi_transform(df):\n", "    print('Init Shape: ', df.shape)\n", "    p = Pool(cpu_count())\n", "    df = p.map(transform_df, np.array_split(df, cpu_count()))\n", "    df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n", "    p.close(); p.join()\n", "    print('After Shape: ', df.shape)\n", "    return df\n", "\n", "df = multi_transform(df)\n", "print(\"Final DF shape: \", df.shape())\n", "test = df[df['price'] == -1]\n", "train = df[df['price'] != -1]\n", "del df\n", "print(\"Final Train shape: \", train.shape())\n", "print(\"Final Test shape: \", test.shape())\n", "\n", "train, valid = np.split(train.sample(frac=1), [int(.75*train.shape[0])])\n", "\n", "for c in c_means:\n", "    mean = get_mean(train, c, 'price')\n", "    test = test.merge(mean, on=[c], how='left')\n", "    train = train.merge(mean, on=[c], how='left')\n", "    valid = valid.merge(mean, on=[c], how='left')\n", "\n", "col = [c for c in train.columns if c not in c_ignors]\n", "\n", "dtrain = xgb.DMatrix(train[col], train['price'])\n", "dvalid  = xgb.DMatrix(valid[col],  valid['price'])\n", "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n", "\n", "params = {'eta': 0.02, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'booster' : 'gbtree',\n", "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'seed': 99, 'silent': True}\n", "\n", "model = xgb.train(params, dtrain, 1000, watchlist, verbose_eval=10, early_stopping_rounds=20)\n", "test['price'] = model.predict(xgb.DMatrix(test[col]), ntree_limit=model.best_ntree_limit)\n", "\n", "test.loc[test['price'] < 0, 'price'] = 0\n", "test['test_id'] = test['test_id'].astype(int)\n", "test[['test_id', 'price']].to_csv(\"xgb_submission.csv\", index = False)\n", "print(\"Finished ...\")\n", "tt = (time.time() - start_time)/60\n", "print(\"Total time %s min\" % tt)"], "execution_count": null, "outputs": [], "metadata": {"_kg_hide-output": false, "collapsed": true, "_uuid": "d0b7ec16e0d07064fdb865c652c0a270a8c7c598", "_cell_guid": "11f04a05-ceb3-45f2-bf87-20f94dd289cb"}}, {"cell_type": "code", "source": [], "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "4180b3be9914cc09e02909b8946af62f1c641a1e", "_cell_guid": "b5835cca-8e67-488c-9bcf-9404a93f8e2a"}}], "nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "nbconvert_exporter": "python", "version": "3.6.3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}}