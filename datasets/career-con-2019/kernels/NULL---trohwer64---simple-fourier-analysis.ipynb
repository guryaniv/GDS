{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\ntrain_x = pd.read_csv('../input/X_train.csv')\ntrain_y = pd.read_csv('../input/y_train.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"129f54f0d178636073d3386a2bca45656a1ba971"},"cell_type":"markdown","source":"My hope was, that different surface types yield (visible) differences in the frequency spectrum of the sensor measurements. Machine learning techniques might learn frequency filters on their own, but why don't give the machine a little head start?\nSo I computed the the cyclic FFT for the angular velocity and linear acceleration sensors and plotted mean and standard deviation of the absolute values of the frequency components per training surface category (leaving out the frequency 0 (i.e. constants like sensor bias, earth gravity, ...).\nThe sensors show some different frequency characterists (see plots below), but unfortunately the surface categories have all similar (to the human eye) shapes, varying mostly in total power, and the standard deviations are high (compared to differences in the means). So there are no nice strong characteristic peaks for surface types. But that does not mean, that there is nothing detectable by more sophisticated statistical methods.\nThis article [http://www.kaggle.com/christoffer/establishing-sampling-frequency](http://www.kaggle.com/christoffer/establishing-sampling-frequency) makes a convincing case, that the sampling frequency is around 400Hz, so according to that you would see the frequency range to 3-200 Hz in the diagrams (and aliased higher frequencies)."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def prepare_data(t):\n    def f(d):\n        d=d.sort_values(by=['measurement_number'])\n        return pd.DataFrame({\n         'lx':[ d['linear_acceleration_X'].values ],\n         'ly':[ d['linear_acceleration_Y'].values ],\n         'lz':[ d['linear_acceleration_Z'].values ],\n         'ax':[ d['angular_velocity_X'].values ],\n         'ay':[ d['angular_velocity_Y'].values ],\n         'az':[ d['angular_velocity_Z'].values ],\n        })\n\n    t= t.groupby('series_id').apply(f)\n\n    def mfft(x):\n        return [ x/math.sqrt(128.0) for x in np.absolute(np.fft.fft(x)) ][1:65]\n\n    t['lx_f']=[ mfft(x) for x in t['lx'].values ]\n    t['ly_f']=[ mfft(x) for x in t['ly'].values ]\n    t['lz_f']=[ mfft(x) for x in t['lz'].values ]\n    t['ax_f']=[ mfft(x) for x in t['ax'].values ]\n    t['ay_f']=[ mfft(x) for x in t['ay'].values ]\n    t['az_f']=[ mfft(x) for x in t['az'].values ]\n    return t\n\nt=prepare_data(train_x)\n\nt=pd.merge(t,train_y[['series_id','surface','group_id']],on='series_id')\nt=t.rename(columns={\"surface\": \"y\"})\n\ndef aggf(d, feature):\n    va= np.array(d[feature].tolist())\n    mean= sum(va)/va.shape[0]\n    var= sum([ (va[i,:]-mean)**2 for i in range(va.shape[0]) ])/va.shape[0]\n    dev= [ math.sqrt(x) for x in var ]\n    return pd.DataFrame({\n        'mean': [ mean ],\n        'dev' : [ dev ],\n    })\n\ndisplay={\n'hard_tiles_large_space':'r-.',\n'concrete':'g-.',\n'tiled':'b-.',\n\n'fine_concrete':'r-',\n'wood':'g-',\n'carpet':'b-',\n'soft_pvc':'y-',\n\n'hard_tiles':'r--',\n'soft_tiles':'g--',\n}\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(14, 8*7))\n#plt.margins(x=0.0, y=0.0)\n#plt.tight_layout()\n# plt.figure()\n\nfeatures=['lx_f','ly_f','lz_f','ax_f','ay_f','az_f']\ncount=0\n\nfor feature in features:\n    stat= t.groupby('y').apply(aggf,feature)\n    stat.index= stat.index.droplevel(-1)\n    b=[*range(len(stat.at['carpet','mean']))]\n\n    count+=1\n    plt.subplot(len(features)+1,1,count)\n    for i,(k,v) in enumerate(display.items()):\n        plt.plot(b, stat.at[k,'mean'], v, label=k)\n        # plt.errorbar(b, stat.at[k,'mean'], yerr=stat.at[k,'dev'], fmt=v)\n   \n    leg = plt.legend(loc='best', ncol=3, mode=\"expand\", shadow=True, fancybox=True)\n    plt.title(\"sensor: \" + feature)\n    plt.xlabel(\"frequency component\")\n    plt.ylabel(\"amplitude\")\n\ncount+=1\nplt.subplot(len(features)+1,1,count)\nk='concrete'\nv=display[k]\nfeature='lz_f'\nstat= t.groupby('y').apply(aggf,feature)\nstat.index= stat.index.droplevel(-1)\nb=[*range(len(stat.at['carpet','mean']))]\n\nplt.errorbar(b, stat.at[k,'mean'], yerr=stat.at[k,'dev'], fmt=v)\nplt.title(\"sample for error bars (lz_f, surface concrete)\")\nplt.xlabel(\"frequency component\")\nplt.ylabel(\"amplitude\")\n\nplt.show()\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}