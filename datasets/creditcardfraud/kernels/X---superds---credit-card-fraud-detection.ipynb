{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.callbacks import Callback\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout\nfrom keras.layers.advanced_activations import PReLU, LeakyReLU\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import SGD\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve,average_precision_score\ndata = pd.read_csv(\"../input/creditcard.csv\")\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"14e176004e84f0f4e365ea943435824d872b8f69","collapsed":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"43524e879d9dc1b0772cb5233a6297c1e67659f6"},"cell_type":"code","source":"# drop \"time\"\ndata.drop(['Time'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d56137e18c7eee516b4361294b16c42b2f596bc","collapsed":true},"cell_type":"code","source":"# Split target var from data\ntarget = data['Class']\ndata.drop(['Class'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0535ffc4abe0aa29397b5747a0dc5bff6305a75","collapsed":true},"cell_type":"code","source":"#Split train and test set.\ntrain_x,test_x,train_y,test_y=train_test_split(data,target,test_size=0.2,stratify=target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20366a5c8bb1549ac35c9bdde96c3d181b433348","collapsed":true},"cell_type":"code","source":"for col in train_x.columns:\n    avg = np.mean(train_x[col])\n    std = np.std(train_x[col])\n    train_x.loc[:,col] = (train_x[col]-avg)/std\n    test_x.loc[:,col] = (test_x[col] - avg)/std","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eaf16d1eabe7507b63be818d7df23f10244ad93a"},"cell_type":"markdown","source":"# Set up some hyper-parameters"},{"metadata":{"trusted":true,"_uuid":"9c77d0565ead6de81fda5cfa32e5ebeb09e9ddca","collapsed":true},"cell_type":"code","source":"nn_params = {\n            'batch_size':128,\n            'nb_epoch':10,\n            'verbose':1, \n            'callbacks':[],\n            'validation_split':0.,\n            'validation_data':None,\n            'shuffle':True,\n            'class_weight':{0:0.1,1:0.2},#{0:0.0396, 1:0.9604},\n            'normalize':False,#Whether to notmalize\n            'categorize_y':True\n            }","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04550beb158954f9455dfa93b8ef0cb29d3f38ae"},"cell_type":"markdown","source":"# Design the structure of your neural networks"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5e7837b746b97c4546eadcd7b31cbc950e1f6765"},"cell_type":"code","source":"def build_model(nn_input_dim_NN):\n    model = Sequential()\n    model.add(Dropout(0.2, input_shape=(nn_input_dim_NN,)))\n    model.add(Dense(input_dim=nn_input_dim_NN, output_dim=120, init='uniform'))\n    model.add(LeakyReLU(alpha=.00001))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(input_dim=120,output_dim=280, init='uniform'))\n    model.add(LeakyReLU(alpha=.00001))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(input_dim=280,output_dim=100, init='uniform', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n    model.add(Dense(input_dim=100,output_dim=2, init='uniform', activation='softmax'))    \n    sgd = SGD(lr=0.015, decay=1e-6, momentum=0.9, nesterov=True)\n    \n#     model.compile(optimizer=sgd, loss='binary_crossentropy',class_mode='binary')   \n    model.compile(optimizer=sgd, loss='binary_crossentropy')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ff24d5a1404fc6f45e53aa661495049eb217230"},"cell_type":"markdown","source":"# Design wrapper class"},{"metadata":{"trusted":true,"_uuid":"bff90b7bccdc2f5d75bbb4c838b45757cd99d91d","collapsed":true},"cell_type":"code","source":"class IntervalEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=10):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict_proba(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            #logging.info(\"interval evaluation - epoch: {:d} - score: {:.6f}\".format(epoch, score))\n            print (\"interval evaluation - epoch: {:d} - score: {:.6f}\".format(epoch, score))\nclass NNWrapper(object):\n    def __init__(self,nn,batch_size=128, nb_epoch=100, verbose=1, callbacks=[],\n            validation_split=0., validation_data=None,shuffle=True,\n            show_accuracy=False, class_weight=None, normalize=False, categorize_y=False):\n        self.nn = nn\n        self.batch_size = batch_size\n        self.nb_epoch = nb_epoch\n        self.verbose = verbose\n        self.callbacks = callbacks\n        self.validation_split = validation_split\n        self.validation_data = validation_data\n        self.shuffle = shuffle\n        self.class_weight = class_weight\n        self.normalize = normalize\n        self.categorize_y = categorize_y\n        #set initial weights\n        self.init_weight = self.nn.get_weights()    \n    def train(self, X, y, validation_data=None):\n        if self.normalize:\n            self.mean = np.mean(X,axis=0)\n            self.std = np.std(X,axis=0) + 1 #CAUSION!!!\n            X = (X - self.mean)/self.std\n        if self.categorize_y:\n            #Converts a class vector (integers) to binary class matrix.\n            y = np_utils.to_categorical(y)\n        if validation_data != None:\n            self.validation_data = validation_data\n            if self.normalize:\n                self.validation_data[0] = (validation_data[0] - self.mean)/self.std\n            if self.categorize_y:\n                self.validation_data[1] = np_utils.to_categorical(validation_data[1])        \n        \n        #set initial weights\n#         self.nn.set_weights(self.init_weight)\n\n        #set callbacks\n        if validation_data is None:\n            self.callbacks = [IntervalEvaluation(validation_data=(X, y), interval=10)]\n        else:\n            self.callbacks = [IntervalEvaluation(validation_data=(self.validation_data[0], \n                                                                  self.validation_data[1]), interval=10)]\n        return self.nn.fit(X, y, batch_size=self.batch_size, nb_epoch=self.nb_epoch, verbose=self.verbose, callbacks=self.callbacks, \n                           validation_split=self.validation_split, validation_data=self.validation_data, shuffle=self.shuffle, class_weight=self.class_weight)\n        \n    def predict(self, X, batch_size=128, verbose=1):\n        if self.normalize:\n            X = (X - self.mean)/self.std\n        return self.nn.predict_proba(X, batch_size=batch_size, verbose=verbose)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ad401c10086cebb3e0a1894a65bd9ad696ab9ea"},"cell_type":"markdown","source":"# Initialize your network"},{"metadata":{"trusted":true,"_uuid":"d769f594c644690ee025641a29e68fd986d0fd60","collapsed":true},"cell_type":"code","source":"structure = build_model(train_x.shape[1])\nnn_model = NNWrapper(nn=structure,**nn_params)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c59290e0aa8744267bed6c27c69a7ec4f200454"},"cell_type":"markdown","source":"# Train your network"},{"metadata":{"trusted":true,"_uuid":"7f9fb3a0a29fb864f2a1109bcb587c06727ad444","collapsed":true},"cell_type":"code","source":"nn_model.train(train_x,train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88081b7d39645db88d02dc642bf387d620bb7955","collapsed":true},"cell_type":"code","source":"pred = nn_model.predict(test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84bc55ac7dcb48b783989b134851d247b1378a54","collapsed":true},"cell_type":"code","source":"precision, recall, _ = precision_recall_curve(test_y, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8139cbf075a147e74ac6001678cc5278072d7d7","collapsed":true},"cell_type":"code","source":"average_precision_score(test_y,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fbbc3a63127cb4e5706db7601484cd0460614ab","collapsed":true},"cell_type":"code","source":"plt.plot(precision,recall, lw=2, color='red') \nplt.xlabel('precision')\nplt.ylabel('recall')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4479a6697cb11b65165de544c7b39dd7d033d44b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}