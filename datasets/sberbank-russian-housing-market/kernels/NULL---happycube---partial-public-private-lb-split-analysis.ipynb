{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ac06cd79-9189-6d2b-9a83-012d19327beb"
      },
      "source": [
        "I decided to study the effects of different 35/65% random splits on hold out data and determined the differences were potentially significant.  To demo this, I forked Reynaldo's kernel..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d7179ccb-7e6d-7bec-46fe-80394a3ca067"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn import model_selection, preprocessing, metrics\n",
        "import xgboost as xgb\n",
        "import datetime\n",
        "#now = datetime.datetime.now()\n",
        "\n",
        "otrain = pd.read_csv('../input/train.csv')\n",
        "\n",
        "train = otrain.iloc[0:24000].copy()\n",
        "test = otrain.iloc[24000:].copy()\n",
        "\n",
        "id_test = test.id\n",
        "\n",
        "\n",
        "y_train = train[\"price_doc\"]\n",
        "x_train = train.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
        "x_test = test.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
        "\n",
        "lbl1 = {}\n",
        "lbl2 = {}\n",
        "\n",
        "for c in x_train.columns:\n",
        "    if x_train[c].dtype == 'object':\n",
        "        lbl1[c] = preprocessing.LabelEncoder()\n",
        "        lbl1[c].fit(list(x_train[c].values)) \n",
        "        x_train[c] = lbl1[c].transform(list(x_train[c].values))\n",
        "        #x_train.drop(c,axis=1,inplace=True)\n",
        "        \n",
        "for c in x_test.columns:\n",
        "    if x_test[c].dtype == 'object':\n",
        "        lbl2[c] = preprocessing.LabelEncoder()\n",
        "        lbl2[c].fit(list(x_test[c].values)) \n",
        "        x_test[c] = lbl2[c].transform(list(x_test[c].values))\n",
        "        #x_test.drop(c,axis=1,inplace=True)        \n",
        "\n",
        "xgb_params = {\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 5,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'objective': 'reg:linear',\n",
        "    'eval_metric': 'rmse',\n",
        "    'silent': 1\n",
        "}\n",
        "\n",
        "dtrain = xgb.DMatrix(x_train, y_train)\n",
        "dtest = xgb.DMatrix(x_test)\n",
        "\n",
        "cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n",
        "    verbose_eval=50, show_stdv=True)\n",
        "cv_output[['train-rmse-mean', 'test-rmse-mean']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "04d55ef1-8010-57aa-43d0-4015eed54cf3"
      },
      "outputs": [],
      "source": [
        "num_boost_rounds = len(cv_output)\n",
        "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round= num_boost_rounds)\n",
        "\n",
        "y_predict = model.predict(dtest)\n",
        "output = pd.DataFrame({'id': id_test, 'price_doc': y_predict})\n",
        "#output.head()\n",
        "\n",
        "def rmsle(tgt, preds):\n",
        "    return np.sqrt(sklearn.metrics.mean_squared_log_error(tgt, preds))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d8755e94-a689-ba27-a0ed-7e681f27114e"
      },
      "outputs": [],
      "source": [
        "# oops, but i don't feel like rerunning that code ;)\n",
        "import sklearn.metrics\n",
        "\n",
        "# now split the held-back predicted output and run several different 35/65% splits on it...\n",
        "\n",
        "sp = int(len(test) * .35)\n",
        "\n",
        "for seeds in [0, 1337, 31337, 71331, 12345, 54321]:\n",
        "    ind = output.index.copy()\n",
        "    np.random.seed(seeds)\n",
        "    ind = np.random.permutation(ind)\n",
        "    \n",
        "    tmp = test[['price_doc', 'id']].copy()\n",
        "    tmp['preds'] = output.price_doc\n",
        "    \n",
        "    tmp = tmp.loc[ind]\n",
        "    \n",
        "    print(rmsle(tmp.iloc[0:sp].price_doc, tmp.iloc[0:sp].preds), rmsle(tmp.iloc[sp:].price_doc, tmp.iloc[sp:].preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c101a5c3-020f-9f84-f4a9-1624031f1f11"
      },
      "outputs": [],
      "source": [
        "# let's also take the entire HB area for comparison...\n",
        "print(rmsle(tmp.price_doc, tmp.preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9c7f6ad1-a052-8338-a248-ab1f11bbbfde"
      },
      "source": [
        "As you can see, the 35/65 scores are rarely close.  It is very likely (but NOT certain) that the LB shakeup will be significant at the end!\n",
        "\n",
        "A run on a home system running the same docker container, given xgb seed of 12345 gave me these results:\n",
        "\n",
        "    0.397478374522 0.420745197489\n",
        "    0.41342785749 0.412390991909\n",
        "    0.399848227388 0.419535052541\n",
        "    0.424963481769 0.406031620705\n",
        "    0.406878538719 0.415881614054\n",
        "    0.408207325049 0.41518027333\n",
        "    0.412754054895\n",
        "\n",
        "This indicates that there is a ~25% chance a model with slightly better HB score (i.e. CV) will perform worse on the private leaderboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7bafeff8-570d-300c-0273-a667342206c0"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}