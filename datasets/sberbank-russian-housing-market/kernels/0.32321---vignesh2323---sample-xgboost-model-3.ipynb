{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a3a5583a-56f8-271b-5c93-42ca97faaadc"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "from sklearn import model_selection, preprocessing, ensemble\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\", color_codes=True)\n",
        "sns.set(font_scale=1)\n",
        "\n",
        "import plotly.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "from plotly import tools\n",
        "\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3495e9eb-28ed-4746-067a-0fdd48128882"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import operator\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "import xgboost as xgb\n",
        "import random\n",
        "from sklearn import model_selection, preprocessing, ensemble\n",
        "from sklearn.metrics import log_loss\n",
        "from pandas import DataFrame\n",
        "import seaborn as sns\n",
        "color = sns.color_palette()\n",
        "sns.set(style=\"whitegrid\", color_codes=True)\n",
        "sns.set(font_scale=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fedbc31f-a071-bf5b-27d4-7b56525fb046"
      },
      "outputs": [],
      "source": [
        "df_train=pd.read_csv('../input/train.csv',parse_dates=['timestamp'])\n",
        "df_test=pd.read_csv('../input/test.csv',parse_dates=['timestamp'])\n",
        "df_train[\"price_doc\"].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "31ab123e-3503-20fc-2c5d-c3f80029fea6"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_train=df_train.pop('price_doc').values\n",
        "id_test = df_test['id']\n",
        "\n",
        "num_train = len(df_train)\n",
        "train_df = pd.concat([df_train, df_test])\n",
        "train_df['month'] = train_df.timestamp.dt.month\n",
        "train_df['year'] = train_df.timestamp.dt.year\n",
        "\n",
        "# Add month-year\n",
        "month_year = (train_df.timestamp.dt.month + train_df.timestamp.dt.year * 100)\n",
        "month_year_cnt_map = month_year.value_counts().to_dict()\n",
        "train_df['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
        "\n",
        "# Add week-year count\n",
        "week_year = (train_df.timestamp.dt.weekofyear + train_df.timestamp.dt.year * 100)\n",
        "week_year_cnt_map = week_year.value_counts().to_dict()\n",
        "train_df['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
        "\n",
        "\n",
        "# Other feature engineering\n",
        "train_df['rel_floor'] = train_df['floor'] / train_df['max_floor'].astype(float)\n",
        "train_df['rel_kitch_sq'] = train_df['kitch_sq'] / train_df['full_sq'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2438e855-0abd-48d2-7f7a-044a4664bba4"
      },
      "outputs": [],
      "source": [
        "train_df.pop('timestamp').values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ad424c5c-a33c-b2ab-5e14-4a231d576e00"
      },
      "outputs": [],
      "source": [
        "train_df1 = pd.DataFrame()\n",
        "train_df1[\"full_sq\"]=train_df[\"full_sq\"]\n",
        "train_df1[\"floor\"]=train_df[\"floor\"]\n",
        "train_df1[\"life_sq\"]=train_df[\"life_sq\"]\n",
        "train_df1[\"build_year\"]=train_df[\"build_year\"]\n",
        "train_df1[\"max_floor\"]=train_df[\"max_floor\"]\n",
        "train_df1[\"mth_id\"] = train_df[\"mth_id\"]\n",
        "train_df1[\"kitch_sq\"] = train_df[\"kitch_sq\"]\n",
        "train_df1[\"num_room\"] = train_df[\"num_room\"]\n",
        "train_df1[\"material\"] = train_df[\"material\"]\n",
        "train_df1[\"Age_building\"] = train_df[\"Age_building\"]\n",
        "train_df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7bf26a1a-9d77-d3e9-60bb-3059990c1621"
      },
      "outputs": [],
      "source": [
        "# Deal with categorical values\n",
        "train_df_numeric = train_df.select_dtypes(exclude=['object'])\n",
        "train_df_obj =train_df.select_dtypes(include=['object']).copy()\n",
        "\n",
        "for c in train_df_obj:\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(train_df_obj[c].values)) \n",
        "        train_df_obj[c] = lbl.transform(list(train_df_obj[c].values))\n",
        "\n",
        "train_df_values = pd.concat([train_df_numeric, train_df_obj], axis=1)\n",
        "\n",
        "X_all = train_df_values.values\n",
        "print(X_all.shape)\n",
        "\n",
        "x_train = X_all[:num_train]\n",
        "x_test = X_all[num_train:]\n",
        "\n",
        "train_df_columns=train_df_values.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "08e791e6-90b4-7c5b-3850-ca516530e720"
      },
      "outputs": [],
      "source": [
        "\n",
        "xgb_params = {\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 8,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'objective': 'reg:linear',\n",
        "    'eval_metric': 'rmse',\n",
        "    'silent': 1\n",
        "}\n",
        "dtrain = xgb.DMatrix(x_train, y_train, feature_names=train_df_columns)\n",
        "dtest = xgb.DMatrix(x_test, feature_names=train_df_columns)\n",
        "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=100)\n",
        "\n",
        "# plot the important features #\n",
        "fig, ax = plt.subplots(figsize=(12,18))\n",
        "xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d9b9f410-61a5-d426-c114-17b92c4f89fb"
      },
      "outputs": [],
      "source": [
        "cv_result = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n",
        "    verbose_eval=True, show_stdv=False)\n",
        "cv_result[['train-rmse-mean', 'test-rmse-mean']].plot()\n",
        "num_boost_rounds = len(cv_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c008fe26-0c13-abd0-be1c-d1d975560514"
      },
      "outputs": [],
      "source": [
        "num_boost_rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0fd2928b-9ce7-86fc-a86e-c40d3cc95283"
      },
      "outputs": [],
      "source": [
        "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5365febd-8240-704c-f513-1ecd4a0d3f0e"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(dtest)\n",
        "\n",
        "df_sub = pd.DataFrame({'id': id_test, 'price_doc': y_pred})\n",
        "\n",
        "df_sub.to_csv('sub.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}