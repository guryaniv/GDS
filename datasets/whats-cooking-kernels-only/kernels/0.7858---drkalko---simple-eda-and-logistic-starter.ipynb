{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport re\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom scipy.sparse import csr_matrix, hstack\n\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n%matplotlib inline\nfrom tqdm import tqdm\n#tqdm.pandas()\n\n# Feature engineering\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Fitting\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport gc\nimport os\nDATA_PATH = \"../input\"\nprint(os.listdir(DATA_PATH))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ebaecc6b2eeac9c805728cc95fa430f172b69a20","trusted":true},"cell_type":"code","source":"debug = False\ntrain = pd.read_json(os.path.join(DATA_PATH, 'train.json')).set_index('id')\ntest = pd.read_json(os.path.join(DATA_PATH, 'test.json')).set_index('id')\nif debug is True:\n    train = train.sample(100)\n    test = test.sample(100)\n\nprint(\"Training Data Shape: \", train.shape)\nprint(\"Testing Data Shape: \", test.shape)\n\nprint(\"Number of cuisines: \", train.cuisine.nunique())\n# Remove single-ingredient entries \ntrain = train[train['ingredients'].str.len()>1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ce0298f3a28dbe4d40135bbc0ad09b51c7462e2"},"cell_type":"code","source":"traindex = train.index\ntestdex = test.index\n\ntrain_size = train.shape[0]\n\ny_train = train.cuisine.copy()\n\ndf = pd.concat([train[['ingredients']], test], axis = 0)\nprint(\"All Data Shape: \", df.shape)\ndf_index = df.index\n\nfeatures_df = pd.DataFrame(index=df.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a44ffc1dfd6ef8ebeab548b5e7798ab16b24d53"},"cell_type":"code","source":"sns.countplot(y=train.cuisine, order=train.cuisine.value_counts().reset_index()[\"index\"])\nplt.title(\"Cuisine Distribution in training data\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fb0d4265f4b47e0a0f7a45b85b2b3643959a0f8"},"cell_type":"code","source":"train['ings'] = train['ingredients'].apply(lambda x: \",\".join(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9751badcbd4f2480ff4e40dcb4e0fd3676802d48","trusted":true},"cell_type":"code","source":"withoz = train[train['ings'].str.contains(\"oz\\.\")]\nif len(withoz) > 0:\n    sns.countplot(y=withoz.cuisine, order=withoz.cuisine.value_counts().reset_index()[\"index\"])\n    plt.title(\"Cuisine Distribution for (oz) in ingredients\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bdbb76782465b77345cdd8f4c2201424b4475230"},"cell_type":"markdown","source":"Apparently using \"oz.\" doesn't give any extra info as distribution of cuisines stays almost the same"},{"metadata":{"_uuid":"c6fde19102c92012ca5b3d5ef0cb2d492140cdb3","trusted":true},"cell_type":"code","source":"fr_accents = ['é', 'è', 'ê', 'ë', 'à', 'â', 'î', 'ô', 'ù', 'û', 'ç']\nwith_fr_accent = train[train['ings'].str.contains(\"|\".join(fr_accents))]\nif len(with_fr_accent) > 0:\n    sns.countplot(y=with_fr_accent.cuisine, order=with_fr_accent.cuisine.value_counts().reset_index()[\"index\"])\n    plt.title(\"Cuisine Distribution for French accents in ingredients\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0088438ac2f21a191255c1be05cb50d81d614ded"},"cell_type":"code","source":"features_df['fr_accents'] = df.ingredients.apply(lambda x: \",\".join(x)).str.contains(\"|\".join(fr_accents)).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d10a31fe1f25f5e856e51831c815009e3ef632f8","trusted":true},"cell_type":"code","source":"es_accents = ['á', 'é', 'í', 'ó', 'ú', 'ü', 'ñ']\nwith_es_accent = train[train['ings'].str.contains(\"|\".join(es_accents))]\nif len(with_es_accent) > 0:\n    sns.countplot(y=with_es_accent.cuisine, order=with_es_accent.cuisine.value_counts().reset_index()[\"index\"])\n    plt.title(\"Cuisine Distribution for Spanish accents in ingredients\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b8147d6e80f5c9554d0c68b2e91648994ab9fd8"},"cell_type":"markdown","source":"Hmm, doesn't look like spanish or mexican. Still, let's try"},{"metadata":{"trusted":true,"_uuid":"f8daff09d58e16fc01418271d97bc6c4505367fc"},"cell_type":"code","source":"features_df['es_accents'] = df.ingredients.apply(lambda x: \",\".join(x)).str.contains(\"|\".join(es_accents)).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ba493769a26630fd7475b07ca4d0db3256bce8a","trusted":true},"cell_type":"code","source":"train.drop(['ings'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fc5699731b138ab96955ba931cb383eb727c6f5"},"cell_type":"markdown","source":"Let's iterate over all ingredients and build a map from ingredient to cuisines"},{"metadata":{"_uuid":"4a77ba3db0d1723890e2b30dc6b029bdd2f03f14","trusted":true},"cell_type":"code","source":"ingredient_dict = {}\nfor _, row in train.iterrows():\n    for ing in row['ingredients']:\n        ingredient_dict.setdefault(ing, []).append(row['cuisine'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1756fa57b3f7bbccbf15cef73f87090d36cf3d8"},"cell_type":"markdown","source":"Now let's have a look at ingredients that are endemic to certain cuisine:"},{"metadata":{"_uuid":"25b40e895f727f72fb01b2b3ce5c3daacab713c9","trusted":true},"cell_type":"code","source":"endemic_ingredient_dict = {}\nfor ing, cui in ingredient_dict.items():\n    if len(cui) <= 1:\n        endemic_ingredient_dict[ing] = cui[0]\nlen(endemic_ingredient_dict)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"797083f7fda8e3f58a1095ddd146518ae4a49a15"},"cell_type":"markdown","source":"Trying to use this info"},{"metadata":{"trusted":true,"_uuid":"983bda48ac37a5b57847be91d74f1812a8598a0a"},"cell_type":"code","source":"cuisines = train.cuisine.unique()\nprint(cuisines)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33b3ce03397a33a7a430235cd04aba4c23f0d6b8"},"cell_type":"code","source":"for cui in cuisines:\n    features_df[cui] = 0\nfor ing, cui in endemic_ingredient_dict.items():\n    features_df.loc[df.ingredients.apply(lambda x: \",\".join(x)).str.contains(ing),cui] = 1\n\nfeatures_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80534ec115f877e9b5b250c8366eccbc6c44282e","trusted":true},"cell_type":"code","source":"del test; del train; gc.collect();","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"vect = CountVectorizer(tokenizer=lambda x: [i.strip() for i in x.split(',')], lowercase=False)\ndummies = vect.fit_transform(df['ingredients'].apply(','.join)) \n\nfull_matrix = csr_matrix(hstack([dummies, features_df]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"965ad58baa24781ac3926a484476110596bd2eda","trusted":true},"cell_type":"code","source":"X_train = full_matrix[:train_size,:]\nX_test = full_matrix[train_size:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94643a5843ecce23d6078997bdcda8a0774c9d8b"},"cell_type":"code","source":"print('All data matrix shape:', full_matrix.shape)\nprint('Train data matrix shape:', X_train.shape)\nprint('Test data matrix shape:', X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"624b7d2b5d76fdabc42906e39b63d6cb2e61f9cb","scrolled":true,"trusted":true},"cell_type":"code","source":"%%time\nclassifier = LogisticRegression(multi_class='multinomial', \n                                solver='saga', \n                                verbose=1, \n                                n_jobs=-1)\n#score = cross_validate(classifier, X_train, y_train, cv=5)\n#print(score[\"test_score\"].mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"829c55545f974aba3c8412a449d6e58ba1fb6af8","trusted":true},"cell_type":"code","source":"#cvscore = score[\"test_score\"].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b880868c2eee6b0bc3339f46b92b4a4fc6e634a"},"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import GridSearchCV\ncv_params = {'C': np.logspace(-1, 2, 20), 'multi_class': ['ovr', 'multinomial']}\n#gridsearch = GridSearchCV(classifier, cv_params, cv=5, verbose=0, n_jobs=-1)\n#gridsearch.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3da606839c16404fd2085644e2e0a23f9cd784a"},"cell_type":"code","source":"#cvscore = gridsearch.best_score_\nbestC = 1.8329807108324356\n#print(gridsearch.best_params_)\n#print(gridsearch.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2542f07019a186248d536e56b29ffa4c59680b5","trusted":true},"cell_type":"code","source":"%%time\nclassifier = LogisticRegression(C=bestC,\n                                multi_class='ovr', \n                                solver='saga', \n                                verbose=1, \n                                n_jobs=-1)\n\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f71e815cd56626fc63c34723013879732332c609","trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_train)\n#y_true = label_encoder.inverse_transform(y_train)\n\nprint(f'accuracy score on train data: {accuracy_score(y_train, y_pred)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c03b74fe4465d1f5fa3c3ec61b15ae9765ae89f9"},"cell_type":"code","source":"def write_submission_file(prediction, index, filename,\n                          path_to_sample=os.path.join(DATA_PATH,'sample_submission.csv')):\n    #submission = pd.read_csv(path_to_sample, index_col='id')\n    submission = pd.Series(prediction, index=index).rename('cuisine')\n    #submission['cuisine'] = prediction\n    submission.to_csv(filename, header=True, index=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a20a9e7e5fd8dedb6ae05d163dbed0c59f840d69","trusted":true},"cell_type":"code","source":"# make submission\ny_pred = classifier.predict(X_test)\nwrite_submission_file(y_pred, testdex, \"logistic_cv_sub.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}