{"cells":[{"metadata":{"_uuid":"3e1f73c07d3cf1a07f3d1a0e15e8bd5566145e1f"},"cell_type":"markdown","source":"It is interesting to me how non-random the Id column seems to be in the dataset."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn import model_selection, neighbors","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"Let's make a simple plot of the joint distribution of the Id and Cover_Type columns."},{"metadata":{"trusted":true,"_uuid":"1896d0942d4386bcc89abad6625ee108ab514ad7","collapsed":true},"cell_type":"code","source":"df = pd.read_csv('../input/forest-cover-type-kernels-only/train.csv')\nfig, ax = plt.subplots(figsize=(10, 9))\nsns.stripplot('Cover_Type', 'Id', data=df, jitter=True, ax=ax, size=2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a98e280470dc6fad2d414deb1f7a7aad22126046"},"cell_type":"markdown","source":"It's clear that a huge amount of information about the Cover_Type is contained in the Id column. To confirm this, let's build a k-NN classifier on just the Id data and see how well it performs on our validation set."},{"metadata":{"trusted":true,"_uuid":"f6a42b373649b4edd846ad0be2db740a2552514f","collapsed":true},"cell_type":"code","source":"X = np.array(df['Id']).reshape(-1, 1)\ny = df['Cover_Type']\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n\n# Grid search to determine best k\naccuracies=[]\nfor k in range(1, 31):\n    clf = neighbors.KNeighborsClassifier(n_neighbors=k, p=1, n_jobs=-1)\n    clf.fit(X_train, y_train)\n    accuracy = clf.score(X_test, y_test)\n    accuracies.append(accuracy)\n    \nbest_k = np.argmax(accuracies) + 1 # best k is consistently 1\nprint('Highest-performing k: {} (acc: {})'.format(best_k, max(accuracies)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20cb2f78ddc19b974e8f6770d7dd709d2a77c13c"},"cell_type":"markdown","source":"The 1-NN algorithm achieves between 0.52 and 0.55 accuracy on the validation set (since there are seven balanced classes, random classification would yield only 14% accuracy), which is impressive considering it only uses the Id of the observations to make its predictions. Of course, this classifier cannot be used on the test set, since the test set operates on a different range of Ids. However, it can be interesting to make the same study we made on the training set on the best-performing publicly available submission. At the time of writing, it is the one from this kernel: https://www.kaggle.com/codename007/forest-cover-type-eda-baseline-model"},{"metadata":{"trusted":true,"_uuid":"4c828d9bddfa2b4e16d344b66828404c1dea6ca3","collapsed":true},"cell_type":"code","source":"df = pd.read_csv('../input/forest-cover-type-eda-baseline-model/etc.csv')\nfig, [ax1, ax2] = plt.subplots(1, 2, sharey=True, figsize=(18, 9))\nax1.set_title('Unshuffled')\nax2.set_title('Shuffled (for comparison)')\nsns.stripplot('Cover_Type', 'Id', data=df, jitter=True, ax=ax1, size=0.5)\nnp.random.shuffle(df['Id'])\nsns.stripplot('Cover_Type', 'Id', data=df, jitter=True, ax=ax2, size=0.5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0453e98ce9d42fece669749327c64108e951efe"},"cell_type":"markdown","source":"Once again there is clear structure in the joint distribution of cover types and Ids. This shows that the dataset's Ids were not shuffled, which has implications for how private CV scores compare to public LB."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}