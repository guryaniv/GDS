{"cells":[{"metadata":{"_uuid":"85d8d22a69fcba94c0c95da70dfcb70dfdd6ad7a"},"cell_type":"markdown","source":"This notebook holds information on how to address the MNIST data recognition with a Simple Neural Network and a Convolutional Neural Network.\nAs the notebook is the updated version of the older one, the Neural Netowrk was commented out without running it for the second time. With the original simple Net the accuracy on the test data has been ~94-96%."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\n# Load the data (you can use pandas, but I'm more comfortable working with numpy)\ntrain = np.genfromtxt(\"../input/train.csv\", delimiter=',', skip_header = 1)\ntest = np.genfromtxt(\"../input/test.csv\", delimiter=',', skip_header = 1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4c9a1ff450da8e37f52fecd9e4b4ec293112363"},"cell_type":"code","source":"#Here we need to get our value for the labels in a seperate variable\n#and these are specific labels, so let's seperate them\nlabels = train[:,0]\n#and let us get our image information into another variable\nimages = train[:,1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12fdf3ce0cb722c5fa6b1cacae4eb7c0bf951c98"},"cell_type":"code","source":"print(len(labels))\nprint(len(images))\nprint()\nprint(labels.ndim)\nprint(images.ndim)\nprint()\nprint(labels.shape)\nprint(images.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14a3606f8fcb9c033374eda7be6d437b7a3b85eb"},"cell_type":"code","source":"#Let's see our data values and distribution of the information\nimport seaborn as sns\nsns.distplot(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d611714be1766041597a777b192d7e2e263402bf"},"cell_type":"code","source":"sns.kdeplot(labels, shade=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38f282cab38072629ebb8716668c877e2bf7ebca"},"cell_type":"code","source":"#Though here is an interesting issue\n#It's better to make numbers more uniform for this approach or at least distributed more densly\n#Say from 0 to 1\nsns.kdeplot(images[666], shade=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c66acef90089044b8b7aed163d4882b701624960"},"cell_type":"code","source":"print(np.amax(images))\nprint(np.amin(images))\n#As we confirm - values vary between 0 and 255 (standard shading though)\n#Let's create a new variable to address that\nnew_images = images/255\nprint(np.amax(new_images))\nprint(np.amin(new_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"978eb91fa841c047ec05ac905630dc3c47c332ff"},"cell_type":"code","source":"#Visually not much changed, but it will matter in general later\n#As such distribution in theory should allow for a better learning practice and rate and accuracy and other fancy stuff\nsns.kdeplot(new_images[666], shade=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9f6d644659ea9dd0748f146d8ab2b9170edc835"},"cell_type":"code","source":"#What we see is not much but it's something and we do recognize that at least we are on the right track\n#Now let's come to building a simple neural network\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Activation\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f83a5390c2447fb2d4e65b59fb5e7f9655f33b2f"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(32, input_dim=new_images.shape[1], activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(10, activation='softmax')) #We will have 10 classes to predict of numbers, so we need a 10 at the output\n\noptimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\nmodel.compile(loss='mean_squared_error', optimizer=optimizer, metrics =['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7c9287b26ca9d80838c816ee794fbfd5ba8efda"},"cell_type":"code","source":"#And of course, before doing anything - dedicate a small sample of data to the validation set\nvalid_images = new_images[40000:,:]\nvalid_labels = labels[40000:]\n\ntrain_images = new_images[:40000,:]\ntrain_labels = labels[:40000]\n\nprint(valid_images.shape)\nprint(len(valid_images))\nprint(valid_labels.shape)\nprint(len(valid_labels))\nprint()\nprint(train_images.shape)\nprint(len(train_images))\nprint(train_labels.shape)\nprint(len(train_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"adfc27ba57942a8d2c2cbc50104b84ef3750ae51"},"cell_type":"code","source":"#And let us binarize our data for the predictions sake\nfrom sklearn.preprocessing import LabelBinarizer\nonehot = LabelBinarizer()\nY_train = onehot.fit_transform(train_labels)\nY_val   = onehot.transform(valid_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d185a14c7484407aa0e2d5827d5a446b9a44a3d"},"cell_type":"code","source":"print(Y_train[0])\nprint(train_labels[0])\nprint()\nprint(Y_val[50])\nprint(valid_labels[50])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a10f9e7c0b9fdf2055073d658f5698fdbfa2120"},"cell_type":"code","source":"#Comence the training of our model\n#model.fit(train_images, Y_train, epochs=32, batch_size=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"137588ef01483d2e5a97cd12c3b2b5ab74c583e3"},"cell_type":"code","source":"#We can make a short evaluation of how well our model seems to work\n#model.evaluate(valid_images,Y_val)\n#The second score is of accuracy, hence on validation set we are predicting roughly 96% of values correctly.\n#That is 1920 out of 2000.\n#After every itteration of committing the code the values can change a little bit...just go with the approx. average of 96%","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bc44ea9e8184435eae1f94d89f9f5fc1ad8314c"},"cell_type":"code","source":"#We convert our binarized values back into it's original form and can compare what is the situation for the first 20\n#values and how they got predicted from our model\n#temp_val = onehot.inverse_transform(Y_val)\n#for zzz in range(0,20):\n#    print(onehot.inverse_transform(model.predict(valid_images[zzz].reshape(1,-1)))==temp_val[zzz])\n    \n#reshaping is just a weird part of restructuring the matrix, so that the prediction would work\n#though in reality it changes nothing...I cannot explain it actually properly, but otherwise the model would just not work\n#with what we feed it with :(","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a88d3330939c28595ee9ad6022fa4bd191b1180"},"cell_type":"markdown","source":"So then, let us do what anyone would do. Predict our test set."},{"metadata":{"trusted":true,"_uuid":"dc2ea0cf0b32088526de2db5fc6b408a125a1ec3"},"cell_type":"code","source":"#Naturally we do not have any labels, so we do not have to care about them, but will have to use our onehot type binarizing\n#converted further, as it is what our model will be predicting.\n#print(test.shape) #just to remember what are we working with","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb2540c943a66873d03dfdb787786912d08e21bf"},"cell_type":"code","source":"#I will do this in a most inefficient way for creating of a submission file\n#final_list = [] #this is what we will populate with our data\n#for number in range(test.shape[0]):\n#    temp_holder = []\n#    temp_var = int(onehot.inverse_transform(model.predict(test[number].reshape(1,-1)))) #int is added as otherwise value is predicted\n                                                                                        #in an inconvenient array([value]) format\n#    temp_holder.append(number+1)\n#    temp_holder.append(temp_var)\n#    final_list.append(temp_holder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9dd703453083892e5cb4a4582736a802ac55baa8"},"cell_type":"code","source":"#here is the example of the \"issue\" that was addressed\n#print(int(onehot.inverse_transform(model.predict(test[5].reshape(1,-1)))))\n#print(onehot.inverse_transform(model.predict(test[5].reshape(1,-1))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df44d960bea6354149c27ab77ebb5d659b9bb6df"},"cell_type":"code","source":"#Before saving it into a file, let's look up how the numbers are distributed in our list\n#play_list = np.array(final_list)\n#print(play_list.shape)\n#and we want our values to be visualized so let's dedicate a variable to it for a moment\n#play_vizual = play_list[:,1]\n#print(play_vizual.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"240b82dba598762b3729ba3c15c89c7ffbcb8506"},"cell_type":"code","source":"#This will get us a rough idea\n#sns.distplot(play_vizual)\n#well, we can see that distribution looks...plausible, as no one value is dominated, so maybe it's actually ok\n#let's save our file","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4be1a2574ecab9f6222639b1ae9ce810cf402722"},"cell_type":"markdown","source":"Alternative approach utilizes a CNN structure, as we can also work with numbers as images. Though we need to reshape our matricies first."},{"metadata":{"trusted":true,"_uuid":"f25cdd7ea809ab4869908996610f484e8d8fc581"},"cell_type":"code","source":"#This is our train data. It's shape is 40000x784\ntrain_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c513f522778f2bb0d35d7ce10128eade710d607"},"cell_type":"code","source":"#If we make \"pictures\" out of this information instead of flat signals, we could utilize a Convolutional Neural Network (CNN)\n#To not make any mistakes, the following structure could be utilized, though there are more elegant ways of solving this task also:\ntrain_images_cnn = []\nfor value in range(train_images.shape[0]):\n    temp_val = np.reshape(train_images[value], (28,28))\n    train_images_cnn.append(temp_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"101b1c6362f6d8d6e8f9c5c01082861e54c1b921"},"cell_type":"code","source":"#And now we have our pictures\nnp.array(train_images_cnn).shape\n#save it\ntrain_images_cnn_final = np.array(train_images_cnn)\\\n#and re-shape for 4 dimensional concept (I have no explanation for this, it just doesn't work without it)\nX = train_images_cnn_final.reshape(train_images_cnn_final.shape[0], train_images_cnn_final.shape[1], train_images_cnn_final.shape[2], 1)\ntrain_images_cnn_final = X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eaee8d3c9afbb256cf0e43612f570564d69674de"},"cell_type":"code","source":"train_images_cnn_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"7f2dc3e77df095e41fc5c8094d233a1c9d03166e"},"cell_type":"code","source":"#The structure for a cnn we can use as the following\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.layers import Dense, Conv2D, Flatten, Input, Conv3D, Conv1D, InputLayer, MaxPooling2D\nfrom sklearn.preprocessing import LabelBinarizer\n\nmodel = Sequential()\nmodel.add(InputLayer(input_shape=(28, 28, 1)))\nmodel.add(Conv2D(256, kernel_size=4, activation='relu'))\nmodel.add(Conv2D(128, kernel_size=4, activation='relu'))\nmodel.add(MaxPooling2D((2, 2), strides=2, padding='same'))\nmodel.add(Conv2D(128, kernel_size=2, activation='relu'))\nmodel.add(Conv2D(64, kernel_size=1, activation='relu'))\nmodel.add(MaxPooling2D((2, 2), strides=2, padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))\noptimizer = Adam (lr = 0.0001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fa6d43a5d8bec7e9924be7aaa030ae273df4b3f"},"cell_type":"code","source":"#Because of how it trains, there is no need even to go into more than 6-10 epochs. There is even a higher chance that then we will overfit the data.\nmodel.fit(train_images_cnn_final, Y_train, epochs=10, batch_size=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d618296b75503f38e50c85abdd332b803bb725f"},"cell_type":"code","source":"#We can evaluate the performance of our model on the set aside validation data\n#First we need to prepare it though. \nvalid_images_cnn = []\nfor value in range(valid_images.shape[0]):\n    temp_val = np.reshape(valid_images[value], (28,28))\n    valid_images_cnn.append(temp_val)\n\nvalid_images_cnn_final = np.array(valid_images_cnn)\n#and re-shape for 4 dimensional concept (I have no explanation for this, it just doesn't work without it)\nZ = valid_images_cnn_final.reshape(valid_images_cnn_final.shape[0], valid_images_cnn_final.shape[1], valid_images_cnn_final.shape[2], 1)\nvalid_images_cnn_final = Z\n\nmodel.evaluate(valid_images_cnn_final,Y_val)\n\n#Accuracy between 98-99%...very nice. Let's move forward.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b56d98fe9f6570b1e7cea0e27e7e133f98bc3b67"},"cell_type":"code","source":"#We convert our binarized values back into it's original form and can compare what is the situation for the first 20 values and how they got predicted from our model\ntemp_val = onehot.inverse_transform(Y_val)\nfor zzz in range(0,20):\n    print(onehot.inverse_transform(model.predict(valid_images_cnn_final[zzz].reshape(1, 28, 28, -1)))==temp_val[zzz])\n    \n#reshaping is just a weird part of restructuring the matrix, so that the prediction would work\n#though in reality it changes nothing...I cannot explain it actually properly, wait...I already mentioned this earlier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57b8b1fa02281e470bb7d081b1a052e28b1c65e3"},"cell_type":"code","source":"print(test.shape) #just to remember what are we working with, and this time we need to again reshape the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aedf831ea2ed880c1b0f09700040722caf842a3c"},"cell_type":"code","source":"#First let's get our data in a presentable form to the model\n#A horrible approach is used where the same variable is just recycled...don't do this in the real world\ntest_images = []\nfor value in range(test.shape[0]):\n    temp_val = np.reshape(test[value], (28,28))\n    test_images.append(temp_val)\n\ntest_images = np.array(test_images)\nL = test_images.reshape(test_images.shape[0], test_images.shape[1], test_images.shape[2], 1)\ntest_images = L\n#But hey...as long as it works...for now\nprint(test_images.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e4b0d15cb182d853772b2f752e448add416ad04"},"cell_type":"code","source":"#Let's make predictions\nfinal_list = []\nfor number in range(test_images.shape[0]):\n    temp_holder = []\n    temp_var = int(onehot.inverse_transform(model.predict(test_images[number].reshape(1, 28, 28, -1)))) \n    temp_holder.append(number+1)\n    temp_holder.append(temp_var)\n    final_list.append(temp_holder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7557e552d2afb06dca3a5efa0684a85aea862d9d"},"cell_type":"code","source":"#Before saving it into a file, let's look up how the numbers are distributed in our list\nplay_list = np.array(final_list)\nprint(play_list.shape)\n#and we want our values to be visualized so let's dedicate a variable to it for a moment\nplay_vizual = play_list[:,1]\nprint(play_vizual.shape)\n#This will get us a rough idea\nsns.distplot(play_vizual)\n#well, we can see that distribution looks...plausible, as no one value is dominated, so maybe it's actually ok\n#let's save our file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"feb87e72f58c47857c2e9a90388f9a079c5be2b5"},"cell_type":"code","source":"#We can download the file and make few adjustments in excel ourselves if needed\n#But this version should present the final file for submission as it is\nnp.savetxt('digits_prediction.csv', final_list, delimiter = ',', header = 'ImageId,Label', fmt='%1.f', comments='')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}