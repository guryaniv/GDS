{"cells":[{"metadata":{"_uuid":"7115d7c653811b6cf0e7ad5d77c57c5ac13224c1"},"cell_type":"markdown","source":"# Cross Validation Considerations for Movie Review Sentiment Analysis\n\nThis kernel describes and compares stratified k-fold cross validation and group k-fold cross validation for the [Stanford parsed Rotten Tomatoes dataset](https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only/data)."},{"metadata":{"_uuid":"3417725d807d2f88a7e9b150270a4736540f76b4","trusted":true},"cell_type":"code","source":"import pandas as pd\n\npd.set_option('display.max_colwidth', -1)\n\ndata = pd.read_csv('../input/train.tsv', delimiter='\\t')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dce1a93ca8140ed20cece9e962559d28d5cad785"},"cell_type":"markdown","source":"### Class Balance"},{"metadata":{"_uuid":"3b86e1370aaf38622964f066ccf3e8ac25cd8d7a","trusted":true},"cell_type":"code","source":"print(\"Sentiment Count:\", data['Sentiment'].size)\nprint(\"Sentiment Distribution:\", data['Sentiment'].value_counts(normalize=True), sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d61e66c3d95d5f3cae2455de7dc05e8e735918b"},"cell_type":"markdown","source":"The data is not evenly distributed between classes. So validation splits should be stratified, i.e. each split should have roughly the same distribution. \n\nAlso, while outside the scope of this kernel, [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall) might be better metrics than accuracy. It may be worth trying training methods that boost the importance of the under represented classes, such as [oversampling](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis) or class weighting."},{"metadata":{"_uuid":"835aea4f6eab787eeabfbf18dd3e83de0fde957b"},"cell_type":"markdown","source":"## Cross Validation Methods"},{"metadata":{"_uuid":"0dad83a3ccddbb6b2c9222a6724248ce83d72c0c"},"cell_type":"markdown","source":"### Stratified K-Fold\n\nPreserve the Sentiment distribution in each fold.\n\nhttp://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold"},{"metadata":{"_uuid":"2360bd85c5b7135d74edd280dbd43e689a7eb70c","scrolled":false,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\nfor f, split in enumerate(skf.split(data, data['Sentiment'])):\n    print(\"Fold\", f + 1, \"-----\")\n    test = data.iloc[split[1]]\n    print(\"Size:\", test.size)\n    print(\"Sentiment Distribution:\", test['Sentiment'].value_counts(normalize=True), \"\", sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff507a738ca5c1b8e29a96088efbd831c2cd7447"},"cell_type":"markdown","source":"There's a possible issue with stratified k-fold for this data set, however.\nLets look at the distribution of SentenceID 1 across folds."},{"metadata":{"_uuid":"e49a257ee32658cd65a3a14cadbdd9936bb6054f","trusted":true},"cell_type":"code","source":"Id = 1\n\nprint(\"SentenceId\", Id, \"Sentiment Counts:\\n\")\nfor f, split in enumerate(skf.split(data, data['Sentiment'])):\n    print(\"Fold \", f + 1, \":\", sep='')\n    test = data.iloc[split[1]]\n    if Id in test['SentenceId'].values:\n        print(test['Sentiment'][test['SentenceId'] == Id].value_counts(sort=False), \"\\n\")\n    else:\n        print(\"None\\n\")\n    \n    # use this later\n    if f == 0:\n        split1 = split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a598a3d034ce809cb1adafb0f180a9d3b994e0e1"},"cell_type":"markdown","source":"This is what the train and test set will look like for fold 1, SentenceId 1."},{"metadata":{"_uuid":"b601d583499978c4f3241ec550b437d362f45e03","scrolled":false,"trusted":true},"cell_type":"code","source":"train = data.iloc[split1[0]]\ntest = data.iloc[split1[1]]\n\nprint(\"Train -----\\nSentenceId =\", Id, \"Counts:\")\nprint(train['Sentiment'][train['SentenceId'] == Id].value_counts(sort=False))\ndisplay(train[(train['SentenceId'] == Id)])\n\nprint(\"Test -----\\nSentenceId =\", Id, \"Counts:\")\nprint(test['Sentiment'][test['SentenceId'] == Id].value_counts(sort=False))\ndisplay(test[(test['SentenceId'] == Id)])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6211dc7f233cf3a94a19178d7ad926cd8fba9f22"},"cell_type":"markdown","source":"Notice how similar the phrases are between the train and test sets. Since a large proportion of the phrases in both sets are neutral, the model will appear to perform decently on SentenceId 1 if it classifies all phrases as neutral. I think with this data set, a favorable metric from stratified k-fold cross validation may be telling us how well the model has learned to recognize SentenceId, instead of evaluating the model's ability to recognize sentiment. \n\nWhen folds get cross contaminated like this, models get a misleading boost in performance. What we want is for the cross validation metrics to tell us how the model will generalize with unseen data. "},{"metadata":{"_uuid":"d9852499c850f97b4ceabd1cd52e166861267a60"},"cell_type":"markdown","source":"### Group K-Fold\n\nConfine each SentenceId to a single fold.\n\nhttp://scikit-learn.org/stable/modules/cross_validation.html#group-k-fold"},{"metadata":{"_uuid":"a4f7929488b5d504ebfcbcbfe90c3e8ca7f33136","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\n\ngkf = GroupKFold(n_splits=5)\nprint(\"SentenceId\", Id, \"Sentiment Counts:\\n\")\nfor f, split in enumerate(gkf.split(data, groups=data['SentenceId'])):\n    print(\"Fold \", f + 1, \":\", sep='')\n    test = data.iloc[split[1]]\n    if Id in test['SentenceId'].values:\n        print(test['Sentiment'][test['SentenceId'] == Id].value_counts(sort=False), \"\\n\")\n    else:\n        print(\"None\\n\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1378626e0a4578077c4ee45952a878d181564f5"},"cell_type":"markdown","source":"Now, with group k-fold, SentimentId 1 is kept in one fold. \n\nGroup k-fold doesn't specifically stratify though. However with this data set, each fold still has a sentiment distribution that is close to the over all distribution."},{"metadata":{"_uuid":"d1755ff84db82bb0cb603bd3507d00232dbc12ea","trusted":true},"cell_type":"code","source":"for f, split in enumerate(gkf.split(data, groups=data['SentenceId'])):\n    print(\"Fold\", f + 1, \"-----\")\n    test = data.iloc[split[1]]\n    print(\"Size:\", test.size)\n    print(\"Sentiment Distribution:\", test['Sentiment'].value_counts(normalize=True), \"\", sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0190cf7fe3659a55fd44b3acc7300c46c5430896"},"cell_type":"markdown","source":"## Model Example\n\nThis is a basic logistic regression [pipeline](http://scikit-learn.org/stable/modules/pipeline.html#pipeline) that uses tf-idf for features.\nI use a grid search with group k-fold to find the best value for the strenth of the l2 penalty.\nOnce the best value for `C` is selected, I'll get the pipeline accuracy reported by stratified k-fold and group k-fold cross validation. Then I'll use the same pipeline to predict on the test set.\n\nHypotheses:\n- stratified k-fold will report the highest accuracy even though the pipeline is the same\n- the test set accuracy will be closer to the group k-fold accuracy"},{"metadata":{"_uuid":"1cfabede8c49d06e3af5cbd42aa4250bfdcd4734","scrolled":true,"trusted":true},"cell_type":"code","source":"import nltk\nimport numpy as np\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('tfidf',  TfidfVectorizer()),\n    ('lr', LogisticRegression())\n])\n\nanalyzer = TfidfVectorizer().build_analyzer()\nstemmer = nltk.stem.SnowballStemmer('english')\n\npipeline.set_params(\n    tfidf__analyzer=lambda x: (stemmer.stem(w) for w in analyzer(x)),\n    tfidf__ngram_range=(1,2),\n    lr__solver='sag',\n    lr__multi_class='multinomial',\n    lr__penalty='l2', \n    lr__tol=0.001, \n    lr__verbose=False)\n\nparam_grid = {\n    'lr__C': np.linspace(1, 3, 11) # I think the value is close to 2 based on previous testing, and want to reduce runtime\n}\n\ngs = GridSearchCV(\n    pipeline, \n    param_grid=param_grid,\n    cv=gkf,\n    verbose=1,\n    return_train_score=False)\n\ngs.fit(data['Phrase'], y=data['Sentiment'], groups=data['SentenceId'])\nprint(\"Best C:\", gs.best_params_['lr__C'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed10650e3a37237dee9620a3c65a3cea318f1f18"},"cell_type":"markdown","source":"Using the best value for `C`, I'll get the pipeline accuracy reported by stratified k-fold and group k-fold."},{"metadata":{"_uuid":"4e1f32c088fe6094c9ecde221b7a474957bd8d0c","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_validate\n\npipeline.set_params(lr__C=gs.best_params_['lr__C'])\n\nprint(\"Running stratified k-fold...\", end='')\nskf_results = cross_validate(\n    pipeline, \n    X=data['Phrase'], \n    y=data['Sentiment'], \n    cv=skf, \n    return_train_score=False, \n    verbose=False)\nprint(\" done.\")\n\nprint(\"Running group k-fold...\", end='')\ngkf_results = cross_validate(\n    pipeline, \n    X=data['Phrase'], \n    y=data['Sentiment'], \n    groups=data['SentenceId'], \n    cv=gkf, \n    return_train_score=False, \n    verbose=False)\nprint(\" done.\\n\")\n\nprint(\"Stratified k-fold average accuracy:\", np.mean(skf_results['test_score']))\nprint(\"Group k-fold average accuracy:\", np.mean(gkf_results['test_score']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6162b123ab466d3e9cc5e124d4a704a1a915e47"},"cell_type":"markdown","source":"Now I'll fit the same pipeline on the entire train set and then predict on the test set."},{"metadata":{"_uuid":"5bcd4984eaf136fcb7b64bd88515ff645436352f","trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/test.tsv', delimiter='\\t')\ntest_pred = pipeline.fit(data['Phrase'], y=data['Sentiment']).predict(test['Phrase'])\n\nsubmission = pd.concat([test['PhraseId'], pd.Series(test_pred, name='Sentiment')], axis=1)\nsubmission.to_csv('sample_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}