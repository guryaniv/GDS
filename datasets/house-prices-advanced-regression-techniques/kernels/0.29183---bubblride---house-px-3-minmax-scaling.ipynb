{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nfrom pctl_scale import PercentileScaler  # pip install pctl-scale\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Summary\n* X: Only ratio-scale with many distinct values (e.g. square feet something). Not using nominal or ordinal-scale variables, nor ratio-scale with few distinct values (e.g. number of bathrooms)\n* Data prep: `pctl_scale.PercentileScaler` to transform all values within the 5% and 95% percentile like MinMax and all outliers with growth saturations formulas towards 0 or 1. \n* Missing Values are set `0.0` assuming that the feature just don't exist for the example. For example if the measure \"kitchen size in square feet\" is missing, maybe there is no kitchen at all.\n* y: Use the `MinMaxScaler` scaler\n* Model assumptions: Multiplies weights with input data in some way. Thus, multiplying with `0.0` will automagically ignore missing values (set to `0.0`)\n\nWhat model?\n\n* Linear Regression\n* Baseline model\n    * Identify high correlations between target and predictors $|\\rho(y, x_i)|>0.4$ with p-values below 0.01\n    * For given $x_i$ (see before) find pairs $(x_i, x_j)$ with a high p-value indicating a poor relationship\n    * Estimate $y=\\theta_0 + \\theta_1 x_i + \\sum_{j=2}^{?} \\theta_j x_j + \\epsilon$\n"},{"metadata":{"_uuid":"9895b542924be884574deaa4794fe15b632c9e12"},"cell_type":"markdown","source":"## Data Prep"},{"metadata":{"trusted":true,"_uuid":"75579f3db0f51cee290fc6c1ca697c54f11a4492"},"cell_type":"code","source":"def dataprep_fit(df):\n    #df2 = df.copy()\n    transformer = dict()\n\n    # X with PercentileScaler\n    col_predictor = [\n        'LotArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n        '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageArea',\n        'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch',\n        'PoolArea', 'MiscVal', 'LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n    lo = .05\n    up = .95\n    naimpute = 0\n    \n    for i, s in enumerate(col_predictor):\n        # compute percentiles\n        obj = PercentileScaler(upper=up, lower=lo, naimpute=naimpute)\n        obj.fit(df[s])\n        # store and apply\n        transformer[s] = obj\n        #df2[s] = obj.transform(df[s])  \n    \n    # y ... just keept it plai\n    col_target = ['SalePrice']\n\n    for i, s in enumerate(col_target):\n        tmp = df[s].values.reshape(-1, 1)\n        obj = MinMaxScaler()\n        obj.fit(tmp)\n        # store and apply\n        transformer[s] = obj\n        #df2[s] = obj.transform(tmp)  \n        \n    # done\n    return transformer, col_predictor, col_target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75579f3db0f51cee290fc6c1ca697c54f11a4492"},"cell_type":"code","source":"def dataprep_transform(df, transformer, xcols, ycols):\n    x = pd.DataFrame(index=df.index)\n    for i, s in enumerate(xcols):\n        obj = transformer[s]\n        x[s] = obj.transform(df[s].values.reshape(-1, 1))\n\n    if ycols:\n        y = pd.DataFrame(index=df.index)\n        for i, s in enumerate(ycols):\n            obj = transformer[s]\n            y[s] = obj.transform(df[s].values.reshape(-1, 1))\n    else:\n        y = None\n        \n    return x, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"facd4da1de0d2e7273e0e36c7bb65f7a585a875d"},"cell_type":"code","source":"#df = pd.read_csv('../input/train.csv', dtype=str)  # throws errors\ndf = pd.read_csv('../input/train.csv')\n\n# fit transform\ntransformer, xcols, ycols = dataprep_fit(df)\nx0, y0 = dataprep_transform(df, transformer, xcols, ycols)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e2f2ed40ad7e0e19127070dfb64422d8b7ef227"},"cell_type":"markdown","source":"## Build a model - Still Linear Regression"},{"metadata":{"trusted":true,"_uuid":"60c95d2d0955c3c5ac83df06a16b49d05c825f63"},"cell_type":"code","source":"xcols = ['GrLivArea', 'BsmtFinSF2', '3SsnPorch', 'MiscVal', 'LowQualFinSF', 'PoolArea']\ny = y0.values\nX = x0[xcols].values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6036f302d5e1380390c9ec588b7d1bf83777c0e0"},"cell_type":"markdown","source":"some splitting"},{"metadata":{"trusted":true,"_uuid":"34760b2f151ca1db458f5b1a22208e821a45b77a"},"cell_type":"code","source":"y_train = y[:1200]\nX_train = X[:1200,:]\n\ny_valid = y[1201:]\nX_valid = X[1201:,:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fee1c7147f15cbb343c4fbdcec41ed87e8370941"},"cell_type":"markdown","source":"some CV "},{"metadata":{"trusted":true,"_uuid":"cd13f5794ef71f3bceb42cdeca6a05b92f714df1","scrolled":true},"cell_type":"code","source":"hyperparam = {\n    #\"fit_intercept\": [True, False]\n}\n\nopti = GridSearchCV(\n    estimator = LinearRegression(\n        normalize=False,\n        copy_X=True,\n        fit_intercept=True\n    ),\n    param_grid = hyperparam, \n    cv = 10,\n    n_jobs = -1,\n    return_train_score = True\n)\n\nopti.fit(X=X_train, y=y_train)\n\nprint(opti.best_estimator_, \"\\n\",\n      opti.best_params_, \"\\n\")\n\nprint(\"{0:8.4f} [CV average score of the best model]\".format(\n      opti.best_score_ ) )\n\nbestmodel = opti.best_estimator_\nprint(\"{0:8.4f} [Performance on the leave-one out validation/test set]\".format(\n      r2_score(y_valid, bestmodel.predict(X_valid))) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b8e4a67b63c3652ef106b248aad54a06bdc619f"},"cell_type":"code","source":"bestmodel.coef_.round(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69c76f088838adfd12707cab403068af655b1e13"},"cell_type":"markdown","source":"Submit it"},{"metadata":{"trusted":true,"_uuid":"ff6d7e4deff791c9157bd302691495eb63108d78"},"cell_type":"code","source":"df_test = pd.read_csv('../input/test.csv')\n\nxcols = ['GrLivArea', 'BsmtFinSF2', '3SsnPorch', 'MiscVal', 'LowQualFinSF', 'PoolArea']\nx_test, _ = dataprep_transform(df_test, transformer, xcols, None)\n\ny_output = bestmodel.predict(x_test.values)\ny_predicted = transformer['SalePrice'].inverse_transform(y_output)\n\nresult = pd.DataFrame(columns=['Id', 'SalePrice'], index=df_test.index)\nresult['Id'] = df_test['Id']\nresult['SalePrice'] = y_predicted\n\n#result\nresult.to_csv('linear-regression-2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7acf72680ddc8dffd094df755507e47ee1541b4b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}