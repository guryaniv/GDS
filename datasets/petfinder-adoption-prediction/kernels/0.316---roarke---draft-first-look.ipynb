{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n% matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/train/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2eae8b45c4a9a92309b00c10a6093d54bb26c3f"},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b0c610ab13b51bc64d4909d57891ae7f0a6e3d5"},"cell_type":"markdown","source":"The PetFinder competition is a pretty straight-forward prediction challenge. The outcome variable that we're interested in is the *AdoptionSpeed* variable which is a measure of how quickly a pet is adopted from a shelter. This is a categorical value that takes a range from 0 to 4, where:\n\n0 - Pet was adopted on the same day as it was listed. \n1 - Pet was adopted between 1 and 7 days (1st week) after being listed. \n2 - Pet was adopted between 8 and 30 days (1st month) after being listed. \n3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed. \n4 - No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days).\n\nEssentially, this is a multi-classification problem.\n\n## Exploratory Data Analysis\nTo get started, we'll want to do preliminary EDA on the training data. "},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"0698525a1be941673eabf4b177ac995d9e7328c0"},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a13903386344ec655f45e0399fa3c67ecd59b4c4"},"cell_type":"code","source":"#Gender - Gender of pet (1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets)\nsns.set(style=\"darkgrid\")\nax = sns.countplot(x=\"Gender\", data=df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa494ddb2536a1db6079583fe0c72342ff223462"},"cell_type":"code","source":"#Type - Type of animal (1 = Dog, 2 = Cat)\n#We'll add type of animal to the plot above\nax = sns.countplot(x=\"Type\", hue=\"Gender\", data=df_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3df5d9fd3750d953697e4206ede8cacc8b70cf6"},"cell_type":"markdown","source":"## Age\nFrom the summary statistics above, we can observe that the mean age of animal is ~10.5 months, with 75% of total being less than or equal to 12 months of age. Most of these adopted animals represent \"puppies\" and \"kittens\". Furthermore, 25% of adopted animals are 2 months or younger and 50% of adopted animals are 3 months or younger. Anecdotally, as a pet owner myself, I believe that people are typically looking to adopt animals as young as possible and in the US the earliest cats and dogs are available for adoption is 8 weeks old, or 2 months. Without even diving further than the summary, it appears that the dataset agrees with this notion... young puppies and kittens are the highest demand animals!\n\nThe oldest animal in our data set is 255 months old. We'll probably want to modify the feature of **Age** a bit to *cap* the value at some maximum. Before we do this, we'll continue our EDA process.\n\nBelow, we've plotted a histogram binned by **Age** for each Gender and Type combination. Each combo has a similar profile, althought it appears that cat adoptions are even more heavily skewed towards animals less than or equal to 12 months in age compared to dogs."},{"metadata":{"trusted":true,"_uuid":"ddb5ac7df895eabf4ced77af5744a5c37270f8ca"},"cell_type":"code","source":"g = sns.FacetGrid(df_train, row=\"Type\", col=\"Gender\", margin_titles=True)\nbins = np.linspace(0, 36, 12)\ng.map(plt.hist, \"Age\", color=\"steelblue\", bins=bins)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2d8f3df89e3adf396ecdcd17860e4799b6b8e46"},"cell_type":"code","source":"df_train[df_train['Type'] == 1]['Age'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64924b160b937bb6f65671c10cc6947866957f5c"},"cell_type":"code","source":"df_train[df_train['Type'] == 2]['Age'].describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0347f6f8f58a96b8512321430eadc94f913ef917"},"cell_type":"markdown","source":"Sure enough, it's clear that on average, cats are about 5.5 months younger than dogs at adoption age."},{"metadata":{"_uuid":"b15f69276bb6ac490c73f841356dd3999cda3de8"},"cell_type":"markdown","source":"## Breed\nBesides **Age**, **Type**, and **Gender**, the **Breed** of the animal will also factor in significantly. It's unusual to find a *pure-breed* animal at a shelter, thus, we'll probably find that most of the animals in our dataset are of *mixed-breed* type. Also, we anticipate that breed factors in more heavily for dogs than for cats. Let's take a look and see if these hypotheses hold up."},{"metadata":{"trusted":true,"_uuid":"e474407dcf0bbcfd4cb9fc9d27f03b49c4deb335"},"cell_type":"code","source":"sum(df_train['Breed2'] == 0) / len(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1fec63cacd928be94fb9f245571eb99ed45c594"},"cell_type":"code","source":"#ax = sns.countplot(x=\"Breed1\", data=df_train)\ndf_train_by_breed = df_train.groupby('Breed1').agg(['count', 'mean'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ed0c1e212aa83b9d91f8976786281fb7f602037"},"cell_type":"code","source":"df_train_by_breed.sort_values(by=[('Type', 'count')], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ba89330863212d2110a92501dbe16c3a21b47ca"},"cell_type":"code","source":"ax = sns.countplot(x=\"AdoptionSpeed\", hue=\"Gender\", data=df_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80041faeee3d4e1fcc54b6362e9a7fde2a5cb754"},"cell_type":"markdown","source":"# Modeling\nThere's so much more EDA that we could, and will do, but let's do a little model development to give us a starting point. To get started, we're just going to use the data in the form that it is given. We will go back later and do some feature engineering to improve the model. That said, we've already loaded the training data. Now we want to divide the training set into two smaller groups that we'll call the *training set* and *development set*.\n* training set - used to train our model  \n* development set - used to evaluate the results from our trained model  "},{"metadata":{"trusted":true,"_uuid":"02c10f75df505377bbb93108a5858d872113460a"},"cell_type":"code","source":"Y = df_train['AdoptionSpeed'].values\nX = df_train.drop(['AdoptionSpeed', 'Name', 'Description', 'PetID', 'RescuerID'], axis=1).values\n\nnp.random.seed(0)\nshuffle = np.random.permutation(np.arange(X.shape[0]))\nX, Y = X[shuffle], Y[shuffle]\ncutoff = int(0.75*len(X))\n\ntrain_data, train_labels = X[:cutoff], Y[:cutoff]\ntest_data, test_labels = X[cutoff:], Y[cutoff:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbf67122d2c8cea8a116519af18db824f45224b2"},"cell_type":"markdown","source":"Good, our data is now in a format that we can work with. Note that we converted the data from a *DataFrame* to a numpy *Matrix*. We're going to utilize Decision Trees for our baseline model.\n## Decision Tree Model\nThe scikit-learn **Tree** package will be used to develop a basic Decision Tree model.   \nhttps://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html  \nWe'll follow these steps to make our predictions:\n1. Define Decision Tree model and hyperparameters\n2. Train model\n3. Make predictions on Development Set\n4. Evaluate results"},{"metadata":{"trusted":true,"_uuid":"4ce585899dd8f9d8a652acdaedff02ca7e86b5bf"},"cell_type":"code","source":"# some decision tree and random forest imports\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import cohen_kappa_score, confusion_matrix, make_scorer\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b367894aa0fbdc6922ae28055a4ae98b91fe918"},"cell_type":"code","source":"dt = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", random_state=0, max_depth=5)\ndt.fit(train_data, train_labels)\ny_preds = dt.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62c5c25d3da04125dfd9648a9f936df7f3b99762"},"cell_type":"code","source":"## Let's define the kappa scoring metric for use in our evaluations\ndef metric(y1,y2):\n    return cohen_kappa_score(y1,y2, weights='quadratic')\n\n# Make scorer for scikit-learn\nscorer = make_scorer(metric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbdb875f8b4236da88c37d67e1b6eaf59f239d91"},"cell_type":"code","source":"metric(y_preds, test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4c2f8239a020ff63201abb0b923b0f2ecbd1c96"},"cell_type":"code","source":"# Create a loop to iterate through max_depth options\nfor i in np.arange(5, 100,5):\n    dt = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", random_state=0, max_depth=7, min_samples_split=i)\n    dt.fit(train_data, train_labels)\n    y_preds = dt.predict(test_data)\n    print ('Cohen kappa score:', metric(y_preds, test_labels), 'Max Depth: ', i)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44fe5349b382d8bfa8dfd018b6e063bffd21df79"},"cell_type":"markdown","source":"So, our very basic decision tree doesn't do a great job of predicting the class. The best results using a limited set of hyperparameters is a \\kappa score of ~0.317 which would currently put our model at 568/713 participants. We can do much, much better than this. Before considering alternative approaches like SVM's and neural net's, we can restrict our first baseline model to decision trees. Here are some things we'll want to do to improve this model:\n* more hyperparameters tuning\n* feature engineering\n* ensemble methods (bagging, boosting, random forests, etc.)"},{"metadata":{"trusted":true,"_uuid":"1a912d7727e4e37f8d40565ef23d486d6c4dc0ed"},"cell_type":"markdown","source":"### Hyperparameter Tuning - Cross-Validation\nOne of the more useful tools we have at our disposal with scikitlearn is the GridSearchCV function. This will allow us to perform k-folds cross-validation on our dataset running through all the different combinations of hyperparameters that we set for it.   \nhttps://scikit-learn.org/stable/modules/cross_validation.html   "},{"metadata":{"trusted":true,"_uuid":"224665ac1437a18f7e934c73d1ab02ff0fe8030d"},"cell_type":"code","source":"dt = RandomForestClassifier()\n#param_grid = {'criterion': ['gini', 'entropy']}\n             #'max_depth': np.arange(0,15),\n             #'min_samples_split': np.arange(10,100,10)}\n\nrand_forest_grid = {\n    'bootstrap': [True, False],\n    'max_depth': [10, 25, 50, 85],\n    'max_features': ['auto'],\n    'min_samples_leaf': [10, 15, 25],\n    'min_samples_split': [10, 15, 25],\n    'n_estimators': [150, 200, 215]\n}\ndt_gridsearch = GridSearchCV(estimator=dt, param_grid = rand_forest_grid, cv = 3, n_jobs = -1,verbose = 1,scoring=scorer)\ndt_gridsearch.fit(train_data, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85a27ac5db2b4ba499d6dd52f780907b1ccd3505"},"cell_type":"code","source":"print(dt_gridsearch.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"bc72cf1657ed20bf95040a7c51535ec2ca52ae7e"},"cell_type":"code","source":"metric(dt_gridsearch.predict(test_data), test_labels)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e1f4f4056de233e50c394e0b8939ee1a1b48fbd"},"cell_type":"markdown","source":"### Principle Component Analysis\n[reserved]"},{"metadata":{"_uuid":"d4c8bf978125c3586a036a5fc52e40cb95fe3153"},"cell_type":"markdown","source":"## Create Submission File"},{"metadata":{"trusted":true,"_uuid":"8c21ffd7ec05629bb341be077947d916d5f54d40"},"cell_type":"code","source":"df_sub = pd.read_csv('../input/test/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ff6e9eeccefcbca828ba1361ae639c9794b11cf"},"cell_type":"code","source":"rand_forest_preds = dt_gridsearch.predict(df_sub.drop(['Name', 'Description', 'PetID', 'RescuerID'], axis=1).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5cab01207ca9e10324edc1d767fb3117d2913c2"},"cell_type":"code","source":"# Store predictions for Kaggle Submission\nsubmission_df = pd.DataFrame(data={'PetID' : df_sub['PetID'], \n                                   'AdoptionSpeed' : rand_forest_preds})\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}