{"cells": [{"metadata": {"_cell_guid": "ab7d7229-938a-406b-a02d-5ea41d13cf91", "_uuid": "17a33ae07b3c42f8eb24c72970cb514e68365826"}, "cell_type": "markdown", "source": ["This a single catboost prediction using the new 2017 data. My understanding is that we can replace the 2016 properties data with the 2017 properties data and combine the training data from 2017 and 2016 into a single train set to make prediction for the three months in 2017. The three months in 2016 should be now irrelevant and I use it just for sanity check that everything continues to work since it is still possible to use LB to test the 2016 predistion (the score is 0.06435 - improved slightly from the one based on 2016 data - perhaps because of some data leakage and because we have more data)."]}, {"metadata": {}, "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.model_selection import train_test_split\n", "import gc\n", "import datetime as dt\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.cluster import MiniBatchKMeans\n", "from catboost import CatBoostRegressor\n", "\n", "myfolder = '../input/'\n", "print('loading files...')\n", "\n", "prop = pd.read_csv(myfolder+'properties_2017.csv',low_memory=False)\n", "prop.rename(columns={'parcelid': 'ParcelId'}, inplace=True)   # make it the same as sample_submission\n", "train = pd.read_csv(myfolder+'train_2016_v2.csv')\n", "train.rename(columns={'parcelid': 'ParcelId'},inplace=True)\n", "sample = pd.read_csv(myfolder+'sample_submission.csv')\n", "print(train.shape, prop.shape, sample.shape)\n", "train17 = pd.read_csv(myfolder+'train_2017.csv')\n", "train17.rename(columns={'parcelid': 'ParcelId'},inplace=True)\n", "print(train17.shape)\n", "train=pd.concat([train,train17])\n", "del train17\n", "print(train.shape)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["print('preprocessing, fillna, dtypes ...')\n", "\n", "prop['longitude']=prop['longitude'].fillna(prop['longitude'].median()) / 1e6   #  convert to float32 later\n", "prop['latitude'].fillna(prop['latitude'].median()) / 1e6\n", "prop['censustractandblock'].fillna(prop['censustractandblock'].median()) / 1e12\n", "train = train[train['logerror'] <  train['logerror'].quantile(0.9975)]  # exclude 0.5% of outliers\n", "train = train[train['logerror'] >  train['logerror'].quantile(0.0025)]\n", "\n", "print('qualitative ...')\n", "qualitative = [f for f in prop.columns if prop.dtypes[f] == object]\n", "prop[qualitative] = prop[qualitative].fillna('Missing')\n", "for c in qualitative:  prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values)).astype(int)\n", "\n", "print('smallval ...')\n", "smallval = [f for f in prop.columns if np.abs(prop[f].max())<100]\n", "prop[smallval] = prop[smallval].fillna('Missing')\n", "for c in smallval:  prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values)).astype(np.int8)\n", "\n", "print('other ...')\n", "other=['regionidcounty','fips','propertycountylandusecode','propertyzoningdesc','propertylandusetypeid']\n", "prop[other] = prop[other].fillna('Missing')\n", "for c in other:  prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values)).astype(int)\n", "\n", "randomyears=pd.Series(np.random.choice(prop['yearbuilt'].dropna().values,len(prop)))\n", "prop['yearbuilt']=prop['yearbuilt'].fillna(randomyears).astype(int)\n", "med_yr=prop['yearbuilt'].quantile(0.5)\n", "prop['New']=prop['yearbuilt'].apply(lambda x: 1 if x > med_yr else 0).astype(np.int8)  # adding a new feature\n", "\n", "prop['unitcnt'] = prop['unitcnt'].fillna(1).astype(int)    \n", "prop['Condo']=prop['unitcnt'].apply(lambda x: 1 if x > 1 else 0).astype(np.int8)    # adding a new feature\n", "    \n", "feat_to_drop=[ 'finishedsquarefeet50', 'finishedfloor1squarefeet', 'finishedsquarefeet15', \n", "              'finishedsquarefeet13','assessmentyear']\n", "prop.drop(feat_to_drop,axis=1,inplace=True)   # remove because too many missing or irrelevant\n", "\n", "prop['lotsizesquarefeet'].fillna(prop['lotsizesquarefeet'].quantile(0.001),inplace=True)\n", "prop['finishedsquarefeet12'].fillna(prop['finishedsquarefeet12'].quantile(0.001),inplace=True)\n", "prop['calculatedfinishedsquarefeet'].fillna(prop['finishedsquarefeet12'],inplace=True)\n", "prop['taxamount'].fillna(prop['taxamount'].quantile(0.001),inplace=True)\n", "prop['landtaxvaluedollarcnt'].fillna(prop['landtaxvaluedollarcnt'].quantile(0.001),inplace=True)\n", "prop.fillna(0,inplace=True)\n", "    \n", "print('quantitative ...')   \n", "quantitative = [f for f in prop.columns if prop.dtypes[f] == np.float64]\n", "prop[quantitative] = prop[quantitative].astype(np.float32) \n", "\n", "cfeatures = list(prop.select_dtypes(include = ['int64', 'int32', 'uint8', 'int8']).columns)\n", "for c in qualitative:  prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values))\n", "\n", "# some quantitative features have a limited number of values (eg ZIP code)    \n", "for c in ['rawcensustractandblock',  'regionidcity',  'regionidneighborhood',  'regionidzip',  'censustractandblock'] :\n", "    prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values))\n", "\n", "gc.collect()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["print('create new features and the final dataframes ...')\n", "\n", "#replace latitudes and longitudes with 500 clusters  (similar to ZIP codes)\n", "coords = np.vstack(prop[['latitude', 'longitude']].values)\n", "sample_ind = np.random.permutation(len(coords))[:1000000]\n", "kmeans = MiniBatchKMeans(n_clusters=500, batch_size=100000).fit(coords[sample_ind])\n", "prop['Cluster'] = kmeans.predict(prop[['latitude', 'longitude']])\n", "\n", "prop['Living_area_prop'] = prop['calculatedfinishedsquarefeet'] / prop['lotsizesquarefeet']\n", "prop['Value_ratio'] = prop['taxvaluedollarcnt'] / prop['taxamount']\n", "prop['Value_prop'] = prop['structuretaxvaluedollarcnt'] / prop['landtaxvaluedollarcnt']\n", "prop['Value_prop'].fillna(0,inplace=True)\n", "prop['Taxpersqrtfoot']=prop['taxamount'] / prop['finishedsquarefeet12']\n", "\n", "train['transactiondate'] = pd.to_datetime(train.transactiondate)\n", "train['Month'] = train['transactiondate'].dt.month.astype(np.int8)\n", "train['Day'] = train['transactiondate'].dt.day.astype(np.int8)\n", "train['Season'] = train['Month'].apply(lambda x: 1 if x in [1,2,9,10,11,12] else 0).astype(np.int8)\n", "\n", "month_err=(train.groupby('Month').aggregate({'logerror': lambda x: np.mean(x)})- train['logerror'].mean()).values\n", "train['Meanerror']=train['Month'].apply(lambda x: month_err[x-1]).astype(np.float32)\n", "\n", "train['abserror']=train['logerror'].abs()\n", "month_abs_err=(train.groupby('Month').aggregate({'abserror': lambda x: np.mean(x)})- train['abserror'].mean()).values\n", "train['Meanabserror']=train['Month'].apply(lambda x: month_abs_err[x-1]).astype(np.float32)\n", "train.drop(['abserror'], axis=1,inplace=True)\n", "\n", "for c in ['Meanerror','Meanabserror']: train[c]=LabelEncoder().fit(list(train[c].values)).transform(list(train[c].values))\n", "for c in ['Meanerror','Meanabserror']: train[c]=train[c].astype(np.int8)\n", "\n", "print(prop.shape, train.shape)\n", "gc.collect()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["# define X,y that can be used either as the training set or be split into train and eval sets (combine prop and train)\n", "# and define X_test for the final prediction to submit (combine prop and sample)\n", "\n", "X = train.merge(prop, how='left', on='ParcelId')\n", "y = X['logerror']\n", "X.drop(['ParcelId', 'logerror', 'transactiondate'], axis=1,inplace=True)\n", "\n", "features=list(X.columns)\n", "cfeatures = list(X.select_dtypes(include = ['int64', 'int32', 'uint8', 'int8']).columns)\n", "\n", "X_test = (sample.merge(prop, on='ParcelId', how='left')).loc[:,features]\n", "X_test['Season']=np.int8(1)\n", "X_test['Day']=np.int8(15)\n", "X_test['Month']=np.int8(10) \n", "X_test['Meanerror']=np.int8(10)\n", "X_test['Meanabserror']=np.int8(10)\n", "\n", "print(X.shape, y.shape, X_test.shape)\n", "del prop, train\n", "gc.collect()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["print('catboost training ...')\n", "X_train, X_eval, y_train, y_eval = train_test_split(X,y, test_size=0.15, random_state=1)\n", "model = CatBoostRegressor(iterations=1000,learning_rate=0.002, depth=7, loss_function='MAE', \n", "                          eval_metric='MAE', random_seed=1)\n", "model.fit(X_train, y_train, eval_set=(X_eval, y_eval), use_best_model=True, verbose=False, plot=True)\n", "pred1 = model.predict(X_train)\n", "pred2 = model.predict(X_eval)\n", "print(' catboost MAE train  {:.4f}'.format(np.mean(np.abs(y_train.values-pred1) )))\n", "print(' catboost MAE eval   {:.4f}'.format(np.mean(np.abs(y_eval.values-pred2) )))\n", "del pred1, pred2\n", "gc.collect()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["FeatImp=pd.DataFrame(model.feature_importances_, index=features, columns=['Importance'])\n", "FeatImp=FeatImp.sort_values('Importance')\n", "FeatImp.plot(kind='barh', figsize=(8,14))\n", "plt.show()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["print('catboost predict and submit ...')\n", "\n", "for month in [ 10,11,12]:\n", "    print('month ',month)\n", "    X_test['Month']=np.int8(month) \n", "    X_test['Meanerror']=X['Meanerror'].loc[X['Month']==month].mean().astype(np.int8)\n", "    X_test['Meanabserror']=X['Meanerror'].loc[X['Month']==month].mean().astype(np.int8)\n", "    pred = model.predict(X_test)\n", "    sample['2016' + str(month)] = pred*1.05\n", "    sample['2017' + str(month)] = pred\n", "    print(' catboost MAE {}  {:.4f}'.format(month,np.mean(np.abs(sample['2017' + str(month)]-0) )))\n", "\n", "sample.to_csv('submission_cat1.csv', index = False, float_format = '%.5f')\n", "gc.collect()"], "execution_count": null, "cell_type": "code", "outputs": []}], "nbformat": 4, "metadata": {"language_info": {"pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.1"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat_minor": 1}