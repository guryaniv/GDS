{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f120f3bd-6839-09ce-ff13-86d0cac8ed5d"
      },
      "source": [
        "##First we need to import the libraries we are going to use\n",
        "Here we need two full libraries:\n",
        "**numpy** (linear algebra and mathematics) and **pandas** (data manipulation and i/o)\n",
        "\n",
        "We also need some bits from **sklearn** - in particular the RandomForestRegressor and the preprocessing unit.\n",
        "\n",
        "It is good practice to only import the bits you need from sklearn as it is quite a memory-intensive library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "643fb711-439a-08bd-5b89-a0aa108f38d9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor # import the random forest model\n",
        "from sklearn import  preprocessing # used for label encoding and imputing NaNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b68b3e1e-8f6a-fdeb-bf0c-9225290f7881"
      },
      "source": [
        "##Next we import the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3fdfa29c-5223-903c-a080-228793fa561e"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('../input/train.csv',)\n",
        "test_df = pd.read_csv('../input/test.csv')\n",
        "macro_df = pd.read_csv('../input/macro.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a7388a1f-4422-acb7-5d8e-b8c264131412"
      },
      "source": [
        "## We assign our prediction variable and set our training set\n",
        "We also set a column vector containing the id's for our predictions and trim the train and test sets removing the id and timestamp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6ffd06af-6322-6204-dbc4-19021446b6db"
      },
      "outputs": [],
      "source": [
        "id_test = test_df.id\n",
        "y_train = train_df[\"price_doc\"]\n",
        "x_train = train_df.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
        "x_test = test_df.drop([\"id\", \"timestamp\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3c976d8a-3067-7d7b-b6b0-3ea27458fedd"
      },
      "source": [
        "### *The code below can be used to cross-validate the training set. The first piece calculates the cross-validation scores and the second plots them visually based on the number of trees.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1b9c0881-992b-f1e6-23ad-5d00c765e9bc"
      },
      "outputs": [],
      "source": [
        "#from sklearn.cross_validation import cross_val_score # We also need the cross validation functionality\n",
        "#scores = list()\n",
        "#scores_std = list()\n",
        "\n",
        "#print('Start learning...')\n",
        "#n_trees = [10, 50, 75]\n",
        "#for n_tree in n_trees:\n",
        "#        print(n_tree)\n",
        "#        recognizer = RandomForestRegressor(n_tree)\n",
        "#        score = cross_val_score(recognizer, x_train, y_train)\n",
        "#        scores.append(np.mean(score))\n",
        "#        scores_std.append(np.std(score))\n",
        "\n",
        "#sc_array = np.array(scores)\n",
        "#std_array = np.array(scores_std)\n",
        "#print('Score: ', sc_array)\n",
        "#print('Std  : ', std_array)\n",
        "\n",
        "\n",
        "#plt.plot(n_trees, scores)\n",
        "#plt.plot(n_trees, sc_array + std_array, 'b--')\n",
        "#plt.plot(n_trees, sc_array - std_array, 'b--')\n",
        "#plt.ylabel('CV score')\n",
        "#plt.xlabel('# of trees')\n",
        "#plt.savefig('cv_trees.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ac99119d-9a91-8e14-4f40-f9a2eb6d5d14"
      },
      "source": [
        "##Numerical encoding of features\n",
        "We need to assign a numeric value to each of the features in our training and test sets. \n",
        "Sklearn's preprocessing unit has a tool called LabelEncoder() which can do just that for us. \n",
        "\n",
        "We could equally combine train and test here and fit this just once  (Maybe we should?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9214e935-6c80-b474-f786-6f217748b816"
      },
      "outputs": [],
      "source": [
        "for c in x_train.columns:\n",
        "    if x_train[c].dtype == 'object':\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(x_train[c].values)) \n",
        "        x_train[c] = lbl.transform(list(x_train[c].values))\n",
        "        \n",
        "for c in x_test.columns:\n",
        "    if x_test[c].dtype == 'object':\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(x_test[c].values)) \n",
        "        x_test[c] = lbl.transform(list(x_test[c].values))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3e0049e1-d287-f74a-c72c-5aff2734cf7a"
      },
      "source": [
        "##Addressing problems with NaN in the data\n",
        "As we saw from our EDA there were quite a lot of NaN in the data. Our model won't know what to do with these so we need to replace them with something sensible.\n",
        "\n",
        "There are quite a few options we can use - the mean, median, most_frequent, or a numeric value like 0. Playing with these will give different results, for now I have it set to use the mean.\n",
        "\n",
        " This uses the mean of the column in which the missing value is located. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b2cef487-b99d-5d4d-12e2-2c81c3d9e575"
      },
      "outputs": [],
      "source": [
        "imputer = preprocessing.Imputer(missing_values='NaN', strategy = 'mean', axis = 0)\n",
        "x_train = imputer.fit_transform(x_train)\n",
        "x_test = imputer.fit_transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7dc9e93f-03e4-9da5-befe-af482fb4517c"
      },
      "source": [
        "## The three step process below is common across many sklearn models\n",
        "\n",
        "**First** we set an object variable \"Model\" equal to the model we want to fit. In this case we are dealing with a regression problem and want to fit a Random Forest model so we choose RandomForestRegressor\n",
        "\n",
        "The parameter labelled 3 below indicates the number of trees we would like in our forest. The default is 10 - I have chosen 3 here for speed. \n",
        "\n",
        "The **second** step in the process is to train the model. We do this with our x and y training data. Remember that the y_train set is just the prediction we would like to make - in this instance the price price_doc. The x_train data is the information we are going to use to make that prediction. \n",
        "\n",
        "**Thirdly** once we have fit the model we can then use it to make a prediction. We do this by called Model.Predict. We are looking to predict the house prices for our test data so we pass the test-data to the predict method and assign it to y_predict. This will contain our predicted set of house prices. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a6f7f557-f4b2-87d4-80fa-a015d470f993"
      },
      "outputs": [],
      "source": [
        "Model = RandomForestRegressor(3)\n",
        "Model.fit(x_train, y_train)\n",
        "y_predict = Model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0b58a792-9780-68af-6ec5-7f8cd92483d7"
      },
      "source": [
        "##Output the data to CSV for submission\n",
        "Finally we take the id_test vector we created earlier and combine it with our y_predictions to create our CSV for output. \n",
        "\n",
        "We are utilising the very useful panda's data frame to do this and it's associated method \"to_csv\" can write our file out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fd911a21-3a25-cf2c-a717-de24ae404462"
      },
      "outputs": [],
      "source": [
        "output = pd.DataFrame({'id': id_test, 'price_doc': y_predict})\n",
        "\n",
        "output.to_csv('RandomForest.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}