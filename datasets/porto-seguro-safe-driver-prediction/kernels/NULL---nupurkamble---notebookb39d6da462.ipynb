{"cells": [{"metadata": {"_cell_guid": "ae9ba5eb-27c3-4773-849d-46c990c90c10", "_uuid": "d7a7a7227819a8ff57d62c621a1385bf713c0ed1", "scrolled": true}, "execution_count": null, "source": ["import csv\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.svm import SVC\n", "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.cross_validation import StratifiedKFold \n", "import matplotlib as plt\n", "from sklearn.model_selection import ShuffleSplit\n", "train =  pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')\n", "print('Test and Train files loaded')\n", "print(\"train shape: %s\", str(train.shape))\n", "print(\"test shape: %s\", str(test.shape))"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "a681fc91-f294-4926-bbd4-2223fc83948c", "_uuid": "d5c320bc0e5a8439aabe9663cd111d44c66f048e", "collapsed": true}, "execution_count": null, "source": ["target = train.target.values\n", "train = train.drop('target',axis=1)\n", "train = train.drop('id',axis=1)\n", "test = test.drop('id',axis=1)\n", "print('train '+str(train.shape))\n", "print('test '+str(test.shape))\n", "print(train.columns.values == test.columns.values)\n", "print(train.columns.values)\n", "print(test.columns.values)\n", "print(target.shape)"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "079ee380-6c7f-4116-a341-a97c23be132e", "scrolled": true, "_uuid": "51415ce7737c81e21c7e9e75b422adcee9d0022c", "collapsed": true}, "execution_count": null, "source": ["\n", "train_df = train\n", "train_df['label'] = 'train'\n", "score_df = test\n", "score_df['label'] = 'score'\n", "concat_df = pd.concat([train_df , score_df])\n", "l=[]\n", "for i in concat_df.values:\n", "    if 'cat' in i:\n", "        l.append(i)\n", "for i in l:\n", "    concat_df[i] = concat_df[i].astype(object)\n", "\n", "# Create your dummies\n", "features_df = pd.get_dummies(concat_df, columns=l)\n", "# Split your data\n", "train_df = features_df[features_df['label'] == 'train']\n", "test_df = features_df[features_df['label'] == 'score']\n", "features_df.shape\n", "print(train_df.shape)\n", "print(score_df.shape)\n", "train_df.head(3)"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "44445d5a-89cb-44ef-94ba-9a78786886df", "_uuid": "1523d03a680dff1739dada1e730d6d6539334333", "collapsed": true}, "execution_count": null, "source": ["train = train_df.drop('label',axis=1)\n", "test = score_df.drop('label',axis=1)\n", "print(train.shape)\n", "print(test.shape)\n", "test.head(4)"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "c055f72c-a08d-4cf9-80a6-48ef5afb2829", "_uuid": "4ceb160926060021924ef6a03b08e76b93007ee7", "collapsed": true}, "execution_count": null, "source": ["#python3.5\n", "import csv\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.svm import SVC\n", "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.cross_validation import StratifiedKFold \n", "import matplotlib as plt\n", "from sklearn.model_selection import ShuffleSplit\n", "y=target\n", "X=train.values\n", "test = test.values\n", "print(X.shape)\n", "print(target.shape)\n"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "aed40a09-7920-4784-9bf9-ad481968c5f0", "_uuid": "335257546df68c141b1fb8237764736bb13b3d58", "collapsed": true}, "execution_count": null, "source": ["n_folds = 4                                    \n", "skf = StratifiedKFold(y, n_folds, shuffle = False, random_state = 14)\n", "print(test.shape)\n", "print(target)"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "eb7bb1c9-8bad-4543-9c8f-806576138b92", "_uuid": "9a169f008c32dff0c5cd3528cc89695c9a809b6f", "collapsed": true}, "execution_count": null, "source": ["from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import accuracy_score\n", "#We pass X and y as numpyarray\n", "def stacking(X,y,clfs,test,clf_names):\n", "    '''Inputs: X:numpy array of features of training set excluding label or response or target\n", "               y:numpy array of labels or response or target\n", "               clfs: classifier list \n", "               test: test set without labels and only features set\n", "       Output:List of [blend_train:metafeatures, blend_test:meta predictions of test, y:label, test:test'''\n", "    \n", "    clf_length = (len(clfs))\n", "    x_rows = (X.shape[0])\n", "    test_rows = int(test.shape[0])\n", "    blend_train = np.zeros((x_rows,clf_length))#construct a 2d list containing rows=len of X and no of columns=len(classifier list) \n", "    blend_test = np.zeros((test_rows,clf_length),dtype = float)#construct a 2d list containing rows = len of test and no of columns = len(classifier list)\n", "    \n", "    a=clf_names\n", "    for i, clf in enumerate(clfs):#iterate over classifiers from list\n", "        blend_test_j = np.zeros((test.shape[0], len(skf)))#we take mean of all entries in each row blend_test_j and store it in blend_test\n", "        print('classifier: %s'%(a[i]))\n", "        for j, (train,cv) in enumerate(skf):\n", "            xtrain = X[train]\n", "            ytrain = y[train]\n", "            xtest = X[cv]\n", "            ytest = y[cv]\n", "            clf.fit(xtrain,ytrain)\n", "            accuracy = accuracy_score(ytest,clf.predict(xtest))\n", "            logloss = log_loss(ytest,clf.predict_proba(xtest))\n", "            blend_train[cv,i] = clf.predict_proba(xtest)[:,1]#collect meta features(predictions over cross validation indices)\n", "            blend_test_j[:,j] =clf.predict_proba(test)[:,1]#predict the test set and take mean every time once for loop exits.  \n", "            print('fold= %s and logloss is %s and accuracy is %s'%(str(j),str(logloss),str(accuracy))) \n", "        #print blend_test_j\n", "        blend_test[:,i] = blend_test_j.mean(1)#Calculate mean of each row of predictions. \n", "    return [blend_train,blend_test,y,test]"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "1bca6119-83b8-4cac-a2f8-488b255b14e9", "_uuid": "cfac46942b4c8e2f4e149bc98f9131027a3349ac", "collapsed": true}, "execution_count": null, "source": ["from sklearn.metrics import log_loss\n", "from sklearn.metrics import make_scorer\n", "from sklearn.model_selection import GridSearchCV\n", "clfs = [RandomForestClassifier(n_estimators=500, n_jobs=-1, criterion='gini'),\n", "            RandomForestClassifier(n_estimators=500, n_jobs=-1, criterion='entropy'),\n", "            ExtraTreesClassifier(n_estimators=500, n_jobs=-1, criterion='gini'),\n", "            ExtraTreesClassifier(n_estimators=500, n_jobs=-1, criterion='entropy'),\n", "            GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=300)]\n", "stack = stacking(X,y,clfs,test,['rf1','rf2','et1','et2','gb'])"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "c878cb12-2984-4352-8132-a4160812deb5", "_uuid": "045f17fb9b2a990c4a674169063af5fd8216f9d8", "collapsed": true}, "execution_count": null, "source": ["#So, far we have blend_train,y and blend_test\n", "#Now, training is done on bend_train,y and predictions are made on blend_test\n", "blend_train = stack[0]\n", "print(blend_train)\n", "print('Shape of blend_train is: %s'%(str(blend_train.shape)))\n", "\n", "blend_test = stack[1]\n", "print(blend_test)\n", "print('Shape of blend_test is: %s'%(str(blend_test.shape)))\n", "\n", "#Now, we train on blend_train as meta features on LogisticRegression.You can use SVM too\n", "print('Blending Procedure')\n", "clf = LogisticRegression()\n", "clf.fit(blend_train, y)"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "81dcada6-dfec-47e8-8cfb-70938d212a26", "_uuid": "4d768852274b3b899f13311f0d665c0537ea9096", "collapsed": true}, "execution_count": null, "source": ["y_submission = clf.predict_proba(blend_test)[:,1]#save first column or column of your choice in submission\n", "print(\"Linear stretch of predictions to [0,1]\")# we scale the probabilities between 0 to 1 \n", "y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())#we can also use X-mean/Xdev to normalize\n", "print(\"Saving Results.\")"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "376a3817-921e-4f41-8a96-7cb45b8f86fc", "_uuid": "6f16009c354da00e34af4d44b482526b10a61bd4", "collapsed": true}, "execution_count": null, "source": ["idc = pd.read_csv('test.csv')\n", "idc = idc.iloc[:,0].values\n", "idc"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "5bb6a940-0f26-4da4-97ed-a4161714b9fe", "_uuid": "b53db46919ccf27aa92a5ec1faeef839b2836721", "collapsed": true}, "execution_count": null, "source": ["tmp = np.vstack([idc, y_submission]).T#transpose the horizontal to vertical\n", "np.savetxt(fname='submission.csv', X=tmp, fmt='%d,%0.9f',\n", "               header='id,target', comments='')"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "7e84e987-ffc4-4b42-8941-45216515fb2d", "_uuid": "d1a565896696eb541ff1efe9c5a9fd441c15f96f", "collapsed": true}, "execution_count": null, "source": [], "cell_type": "code", "outputs": []}], "nbformat": 4, "metadata": {"anaconda-cloud": {}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.1", "file_extension": ".py", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 1}