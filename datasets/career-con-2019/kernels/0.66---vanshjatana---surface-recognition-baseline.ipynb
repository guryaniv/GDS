{"cells":[{"metadata":{"_uuid":"0bdb16c8857a71796083efc7931be1ddbfb3e1c6"},"cell_type":"markdown","source":"<h2>Introduction</h2>\n\nIn this competition, participants must help robots recognize the floor surface they’re standing on using data collected from sensors."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport time\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\nimport lightgbm as lgb\nsns.set()\n\nprint(\"Files in the input folder:\")\nprint(os.listdir(\"../input\"))\ntrain = pd.read_csv('../input/X_train.csv')\ntest = pd.read_csv('../input/X_test.csv')\ny = pd.read_csv('../input/y_train.csv')\nsub = pd.read_csv('../input/sample_submission.csv')\nprint(\"\\nX_train shape: {}, X_test shape: {}\".format(train.shape, test.shape))\nprint(\"y_train shape: {}, submission shape: {}\".format(y.shape, sub.shape))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d50258454728fceb9c41c64fceb8f5469c5cb39"},"cell_type":"markdown","source":"<h3>Data structure</h3>\n\nEach series has 128 measurements, that's why there are almost half million rows at x_train, but only 3810 outputs (y_train). For each measurement we have ten features, which are basically the orientation, angular velocity and acceleration in three dimensions. The orientation channel has a fourth dimension since it's using [quaternions](https://en.wikipedia.org/wiki/Conversion_between_quaternions_and_Euler_angles).\n\nThis is a classification problem with nine possible classes (floor surfaces):"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"c878f65e9b0acd193f56fd3f80cefbe5ff6ac9c9"},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title(\"Training labels\")\nax = sns.countplot(y='surface', data=y)\ny.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2439bee10a17fa0891d79fb2d8839095a97bd4c8"},"cell_type":"markdown","source":"Each group_id is a unique recording session and has only one surface type:"},{"metadata":{"trusted":true,"_uuid":"81ad190a65666227365562294a71f380b0678844"},"cell_type":"code","source":"y.groupby('group_id').surface.nunique().max()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70fee1fef5e8b68dfdf9516bd5280b0d9a0dbc26"},"cell_type":"markdown","source":"<h2>Feature Engineering</h2>"},{"metadata":{"trusted":true,"_uuid":"f702056ed81992936c1c19c22c6b9be0ce18a737"},"cell_type":"code","source":"def feature_extraction(raw_frame):\n    frame = pd.DataFrame()\n    raw_frame['angular_velocity'] = raw_frame['angular_velocity_X'] + raw_frame['angular_velocity_Y'] + raw_frame['angular_velocity_Z']\n    raw_frame['linear_acceleration'] = raw_frame['linear_acceleration_X'] + raw_frame['linear_acceleration_Y'] + raw_frame['linear_acceleration_Y']\n    raw_frame['velocity_to_acceleration'] = raw_frame['angular_velocity'] / raw_frame['linear_acceleration']\n    \n    for col in raw_frame.columns[3:]:\n        frame[col + '_mean'] = raw_frame.groupby(['series_id'])[col].mean()\n        frame[col + '_std'] = raw_frame.groupby(['series_id'])[col].std()\n        frame[col + '_max'] = raw_frame.groupby(['series_id'])[col].max()\n        frame[col + '_min'] = raw_frame.groupby(['series_id'])[col].min()\n        frame[col + '_max_to_min'] = frame[col + '_max'] / frame[col + '_min']\n        \n        frame[col + '_mean_abs_change'] = raw_frame.groupby('series_id')[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        frame[col + '_abs_max'] = raw_frame.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n    return frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ecbcaabbb8c10975ae036502a2910c0b5639922"},"cell_type":"code","source":"train_df = feature_extraction(train)\ntest_df = feature_extraction(test)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b629f1a1143fc050226ce1ba5c252c82b4a4596a"},"cell_type":"markdown","source":"<h2>Gradient Boosting</h2>\n\nThe standard metric for multiclass classification is *multi_logloss* in lightgbm, so I added a custom evaluation metric for multiclass accuracy. Another possible metric is *multi_error*, but there is no description in the documentation."},{"metadata":{"trusted":true,"_uuid":"6e623728912dad21e5e7bd6865a42022dacc271c"},"cell_type":"code","source":"le = LabelEncoder()\ntarget = le.fit_transform(y['surface'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dad8691d2ced37e199dcb6efbc73628b5d8ff010"},"cell_type":"code","source":"params = {\n    'num_leaves': 54,\n    'min_data_in_leaf': 10,\n    'objective': 'multiclass',\n    'max_depth': 7,\n    'learning_rate': 0.01,\n    \"boosting\": \"gbdt\",\n    \"bagging_freq\": 5,\n    \"bagging_fraction\": 0.8126672064208567,\n    \"bagging_seed\": 11,\n    \"verbosity\": -1,\n    'reg_alpha': 0.1302650970728192,\n    'reg_lambda': 0.3603427518866501,\n    \"num_class\": 9,\n    'nthread': -1\n}\n\ndef multiclass_accuracy(preds, train_data):\n    labels = train_data.get_label()\n    pred_class = np.argmax(preds.reshape(9, -1).T, axis=1)\n    return 'multi_accuracy', np.mean(labels == pred_class), True\n\nt0 = time.time()\ntrain_set = lgb.Dataset(train_df, label=target)\neval_hist = lgb.cv(params, train_set, nfold=10, num_boost_round=9999,\n                   early_stopping_rounds=100, seed=19, feval=multiclass_accuracy)\nnum_rounds = len(eval_hist['multi_logloss-mean'])\n# retrain the model and make predictions for test set\nclf = lgb.train(params, train_set, num_boost_round=num_rounds)\npredictions = clf.predict(test_df, num_iteration=None)\nprint(\"Timer: {:.1f}s\".format(time.time() - t0))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8722ace35075936db8f47b812055101a57fdb5e5"},"cell_type":"markdown","source":"The following plots show the mean logloss and accuracy at each iteration (blue line). The red lines are the standard deviation between folds."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"5696f9084ff904b75d9c45345e5a80c56c6c5f84"},"cell_type":"code","source":"v1, v2 = eval_hist['multi_logloss-mean'][-1], eval_hist['multi_accuracy-mean'][-1]\nprint(\"Validation logloss: {:.4f}, accuracy: {:.4f}\".format(v1, v2))\nplt.figure(figsize=(10, 4))\nplt.title(\"CV multiclass logloss\")\nnum_rounds = len(eval_hist['multi_logloss-mean'])\nax = sns.lineplot(x=range(num_rounds), y=eval_hist['multi_logloss-mean'])\nax2 = ax.twinx()\np = sns.lineplot(x=range(num_rounds), y=eval_hist['multi_logloss-stdv'], ax=ax2, color='r')\n\nplt.figure(figsize=(10, 4))\nplt.title(\"CV multiclass accuracy\")\nnum_rounds = len(eval_hist['multi_accuracy-mean'])\nax = sns.lineplot(x=range(num_rounds), y=eval_hist['multi_accuracy-mean'])\nax2 = ax.twinx()\np = sns.lineplot(x=range(num_rounds), y=eval_hist['multi_accuracy-stdv'], ax=ax2, color='r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"306818f07d2cb567bdbb40eeaa0e176a63986f8a"},"cell_type":"markdown","source":"<h3>Feature importance</h3>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"36d668de3cce594146324de9127239d29740897f"},"cell_type":"code","source":"importance = pd.DataFrame({'gain': clf.feature_importance(importance_type='gain'),\n                           'feature': clf.feature_name()})\nimportance.sort_values(by='gain', ascending=False, inplace=True)\nplt.figure(figsize=(10, 20))\nax = sns.barplot(x='gain', y='feature', data=importance)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"202e04279ac005e40fd0cc50ce25d6ffe89887c0"},"cell_type":"markdown","source":"<h3>Submission</h3>"},{"metadata":{"trusted":true,"_uuid":"026ba1eab1a2152e951b7e6538087361ac65ec03"},"cell_type":"code","source":"sub['surface'] = le.inverse_transform(predictions.argmax(axis=1))\nsub.to_csv('lgb_submission2.csv', index=False)\nsub.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab8be9176b38ec5ffd01805f4703e9bc0bb37d9d"},"cell_type":"markdown","source":"<h3>Work in progress...</h3>"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}