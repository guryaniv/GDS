{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# Import the required libraries \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\nimport numpy as np\nimport json\n\n# Dataset Preparation\nprint (\"Read Dataset ... \")\ndef read_dataset(path):\n\treturn json.load(open(path)) \ntrain = read_dataset('../input/train.json')\ntest = read_dataset('../input/test.json')\n\n# Text Data Features\nprint (\"Prepare text data of Train and Test ... \")\ndef generate_text(data):\n\ttext_data = [\" \".join(doc['ingredients']).lower() for doc in data]\n\treturn text_data \n\ntrain_text = generate_text(train)\ntest_text = generate_text(test)\ntarget = [doc['cuisine'] for doc in train]\n\n# Feature Engineering \nprint (\"TF-IDF on text data ... \")\ntfidf = TfidfVectorizer(binary=True)\ndef tfidf_features(txt, flag):\n    if flag == \"train\":\n    \tx = tfidf.fit_transform(txt)\n    else:\n\t    x = tfidf.transform(txt)\n    x = x.astype('float16')\n    return x \n\nX = tfidf_features(train_text, flag=\"train\")\nX_test = tfidf_features(test_text, flag=\"test\")\n\n# Label Encoding - Target \nprint (\"Label Encode the Target Variable ... \")\nlb = LabelEncoder()\ny = lb.fit_transform(target)\n\n## to one-hot\ndef to_onehot(input_):\n    output_ = np.zeros((len(input_), max(input_)+1))\n    for i in range(len(input_)):\n        output_[i][input_[i]] = 1\n    return output_\n    \ny = to_onehot(y)    ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import BatchNormalization, Dense, Dropout, concatenate, Input, Flatten, add, Activation\nfrom keras.callbacks import EarlyStopping\n# from keras.utils import plot_model\n\ninside_dim = 256\nbatch_size = 32\nepochs = 20\nblock_n = 10\n\ndef dense_layer(x):\n    x = Dense(inside_dim, input_dim=inside_dim, activation=\"relu\")(x)\n    x = BatchNormalization()(x)\n    x = Dropout(rate=0.5)(x)  \n    return x\n\ndef dense_block(input_):\n    x = input_\n    y = dense_layer(x)\n    y = dense_layer(y)\n    x = add([x, y])\n    x = Activation('relu')(x)\n#     x = concatenate([x, y])\n#     x = Flatten()(x)\n    return x\n\ndef dense_net(input_, n):\n    for _ in range(n):\n        input_ = dense_block(input_)\n    return input_\n\n    \ninputs = Input(shape=(3010,))    \nx = Dense(inside_dim, input_dim=3010, activation=\"relu\")(inputs)\nx = BatchNormalization()(x)    \nx = Dropout(rate=0.5)(x)   \n\nx = dense_net(input_=x, n=block_n)\n\n# model = Sequential()\n# model.add(Dense(inside_dim, input_dim=3010, activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(rate=0.5))\n\n# model.add(Dense(inside_dim, input_dim=inside_dim, activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(rate=0.5))\n# model.add(Dense(inside_dim, input_dim=inside_dim, activation=\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(rate=0.5))\n# model.add(Dense(inside_dim, input_dim=inside_dim, activation=\"relu\"))\n# model.add(BatchNormalization())\n\n# ## for output\n# model.add(Dense(20, input_dim=inside_dim, activation=\"softmax\"))\noutputs = Dense(20, input_dim=inside_dim, activation=\"softmax\")(x)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\n\nmodel.summary()\n\n# callback = [EarlyStopping(monitor='loss', patience=5)]\n\nmodel.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n# model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks=callback)\nmodel.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c9603f49505368273b54cd04c05485edaadee2b","collapsed":true},"cell_type":"code","source":"output_name = \"GPU_test_2.csv\"\n\n\n\ndef onthot_to_label(input_):\n    output_ = np.zeros(len(input_))\n    for i in range(len(input_)):\n        output_[i] = int(np.argmax(input_[i]))\n    output_ = output_.astype('int8')\n    return output_\n\n# Predictions \nprint (\"Predict on test data ... \")\ny_test = model.predict(X_test)\ny_test = onthot_to_label(y_test)\ny_pred = lb.inverse_transform(y_test)\n\n# Submission\nprint (\"Generate Submission File ... \")\ntest_id = [doc['id'] for doc in test]\nsub = pd.DataFrame({'id': test_id, 'cuisine': y_pred}, columns=['id', 'cuisine'])\nsub.to_csv(output_name, index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"159d7580dacbbbe6623b9779f54d2521719b1a5b","collapsed":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"745403ca9e164b840d9e7b14b9e4efc30422db4a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}