{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5fe6c549-5b17-843f-961a-5722d9daffa8"
      },
      "source": [
        "There's lots of duplicate questions which are the same, except for a different location. Here's a set of features using this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "89cc583d-3e87-7ebe-a512-f4ffc9c8ce6d"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import re\n",
        "\n",
        "from subprocess import check_output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4373b91e-931f-8535-f262-9bd4511aec2f"
      },
      "source": [
        "We need a list of locations. I download files from Geonames myself, but Kaggle has this nice new multi-dataset thing, so let's try that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ba70d3fd-71b6-accc-ad02-2f590e4c1285"
      },
      "outputs": [],
      "source": [
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "print(check_output([\"ls\", \"../input/quora-question-pairs\"]).decode(\"utf8\"))\n",
        "print(check_output([\"ls\", \"../input/movehub-city-rankings\"]).decode(\"utf8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "062726b1-84c2-8115-1740-4e84d8de4177"
      },
      "outputs": [],
      "source": [
        "dataset = \"train\" # Obviously you want to run this on the test set as well\n",
        "\n",
        "df = pd.read_csv(\"../input/quora-question-pairs/{}.csv\".format(dataset))\n",
        "locations = pd.read_csv(\"../input/movehub-city-rankings/cities.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eb1b19b8-fac2-acf4-70b5-93145917daca"
      },
      "outputs": [],
      "source": [
        "# There's lots of room to add more locations, but start with just countries\n",
        "countries = set(locations['Country'].dropna(inplace=False).values.tolist())\n",
        "all_places = countries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aad7478a-67ce-17f9-8fff-249e60871c40"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Turn it into a Regex\n",
        "regex = \"|\".join(sorted(set(all_places)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6e06d8d1-f1ac-7497-b708-7f1259a9e7d5"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "subset = 10000 # Remove the subsetting \n",
        "\n",
        "results = []\n",
        "print(\"processing:\", df[0:subset].shape)\n",
        "for index, row in tqdm(df[0:subset].iterrows()):\n",
        "    q1 = str(row['question1'])\n",
        "    q2 = str(row['question2'])\n",
        "\n",
        "    rr = {}\n",
        "\n",
        "    q1_matches = []\n",
        "    q2_matches = []\n",
        "\n",
        "    if (len(q1) > 0):\n",
        "        q1_matches = [i.lower() for i in re.findall(regex, q1, flags=re.IGNORECASE)]\n",
        "\n",
        "    if (len(q2) > 0):\n",
        "        q2_matches = [i.lower() for i in re.findall(regex, q2, flags=re.IGNORECASE)]\n",
        "\n",
        "    rr['z_q1_place_num'] = len(q1_matches)\n",
        "    rr['z_q1_has_place'] =len(q1_matches) > 0\n",
        "\n",
        "    rr['z_q2_place_num'] = len(q2_matches) \n",
        "    rr['z_q2_has_place'] = len(q2_matches) > 0\n",
        "\n",
        "    rr['z_place_match_num'] = len(set(q1_matches).intersection(set(q2_matches)))\n",
        "    rr['z_place_match'] = rr['z_place_match_num'] > 0\n",
        "\n",
        "    rr['z_place_mismatch_num'] = len(set(q1_matches).difference(set(q2_matches)))\n",
        "    rr['z_place_mismatch'] = rr['z_place_mismatch_num'] > 0\n",
        "\n",
        "    results.append(rr)     \n",
        "\n",
        "out_df = pd.DataFrame.from_dict(results)\n",
        "#out_df.to_csv(\"../features/{}_place_matches.csv\".format(dataset), index=False, header=True)\n",
        "out_df.to_csv(\"{}_place_matches.csv\".format(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1e466f10-6fd3-4d11-e2c2-16d1750f1967"
      },
      "outputs": [],
      "source": [
        "print(check_output([\"ls\", \"./\"]).decode(\"utf8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7af01054-35d4-ae82-a6eb-7276564dd23e"
      },
      "source": [
        "All done!\n",
        "\n",
        "Upvote if you like it!"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}