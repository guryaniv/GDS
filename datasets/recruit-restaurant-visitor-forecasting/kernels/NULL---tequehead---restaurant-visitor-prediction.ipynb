{"cells": [{"outputs": [], "metadata": {"_cell_guid": "250a8faa-34db-4b6a-8b17-e83c5761a31e", "scrolled": false, "_uuid": "d6c3fcdc1423823976daadccdb64a36bd54bc103"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "# import ggplot\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "data = {\n", "    'tra': pd.read_csv('../input/air_visit_data.csv'),\n", "    'as': pd.read_csv('../input/air_store_info.csv'),\n", "    'hs': pd.read_csv('../input/hpg_store_info.csv'),\n", "    'ar': pd.read_csv('../input/air_reserve.csv'),\n", "    'hr': pd.read_csv('../input/hpg_reserve.csv'),\n", "    'id': pd.read_csv('../input/store_id_relation.csv'),\n", "    'tes': pd.read_csv('../input/sample_submission.csv'),\n", "    'hol': pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date': 'visit_date'})\n", "}\n", "\n", "# Any results you write to the current directory are saved as output.\n", "\n", "# print(data)"], "execution_count": null, "cell_type": "code"}, {"outputs": [], "metadata": {}, "source": ["air_visit_count = data['tra'].groupby(data['tra']['visit_date'])['visitors'].sum()\n", "plt.figure(figsize = (15, 7))\n", "plt.plot(air_visit_count.index, air_visit_count)\n", "plt.ylabel('Number of visitors', fontsize = 20)\n", "plt.legend()\n", "\n", "air_visit_data = data['tra']\n", "air_visit_data['visit_date'] = pd.to_datetime(air_visit_data['visit_date'])\n", "air_visit_data['day_of_week'] = air_visit_data['visit_date'].dt.dayofweek\n", "median_visitors_per_day = air_visit_data.groupby(['day_of_week'])['visitors'].median()\n", "\n", "air_visit_data['month'] = air_visit_data['visit_date'].dt.month\n", "median_visitors_per_month = air_visit_data.groupby(['month'])['visitors'].median()\n", "\n", "fig, (ax1, ax2) = plt.subplots(ncols = 2, sharey = True, figsize = (14, 4))\n", "sns.barplot(x = median_visitors_per_day.index, y = median_visitors_per_day, ax = ax1)\n", "sns.barplot(x = median_visitors_per_month.index, y = median_visitors_per_month, ax = ax2)\n", "\n", "\n", "# air_visit_data['visit_date'] = pd.to_datetime(air_visit_data['visit_date'])\n"], "execution_count": null, "cell_type": "code"}, {"outputs": [], "metadata": {"collapsed": true}, "source": ["# print(data['tra'])\n", "air_total_visits = data['tra'].groupby('visit_date').sum()\n", "air_mean_visits = data['tra'].groupby('visit_date').mean()\n", "air_median_visits = data['tra'].groupby('visit_date').median()\n", "# air_total_visits.describe()\n", "# air_total_visits.groups['2016-01-01']\n", "# air_total_visits.groups.keys()\n", "# for key in air_total_visits.groups:\n", "# tmp = air_total_visits.groups['2016-01-01']\n", "plt.figure('Total visits per day')\n", "plt.plot(air_total_visits)\n", "plt.figure('Mean visits per day')\n", "plt.plot(air_mean_visits)\n", "plt.figure('Median visits per day')\n", "plt.plot(air_median_visits)\n"], "execution_count": null, "cell_type": "code"}, {"outputs": [], "metadata": {"collapsed": true, "_cell_guid": "af80d473-75de-48a8-9290-331af823b986", "_uuid": "5f399b036df7aa765b1b1d021e75caff2b1408d2"}, "source": ["# Setting up a Gradient Boosting Regressor model\n", "params = {'n_estimators': 100, # Number of boosting estimators ?\n", "         'max_depth': 5, # Maximum depth of individual regression estimators\n", "         'min_samples_split': 200, # Minimum # of samples to split an internal node\n", "         'min_samples_leaf': 50, # Minimum # of samples to be a leaf node\n", "         'learning_rate': 0.005, # Shrinks the contribution of each tree by learning_rate\n", "         'max_features': 9, # Number of features to consider when looking for a best split\n", "         'subsample': .8, # Fraction of samples to be used for fitting the individual base learners\n", "         'loss': 'ls'} # Least squares\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"], "execution_count": null, "cell_type": "code"}], "nbformat": 4, "nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.3", "name": "python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}}