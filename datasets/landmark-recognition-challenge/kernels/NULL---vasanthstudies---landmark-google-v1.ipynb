{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport tensorflow as tf\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"13e62b37-d0d0-4fc0-b88d-24ae1bf8f7c9","_uuid":"8c95491ae3512254dd083cdec3a19fb0a59ac2c7","trusted":false,"collapsed":true},"cell_type":"code","source":"#find landmarks, so determine unique number of classes\ntrain_data= pd.read_csv('../input/train.csv')\ntest_data= pd.read_csv('../input/test.csv')\nsubmission = pd.read_csv(\"../input/sample_submission.csv\")\n\nunique_landmark = pd.DataFrame(train_data.landmark_id.value_counts())\n# print(len(unique_landmark))\n#print(unique_landmark)\n\n\nunique_landmark.reset_index(inplace=True)\nunique_landmark.columns = ['landmark_id','count']\n\nclsses_number= len(unique_landmark) #gives number of clases\nclasses=[unique_landmark.landmark_id]\n\nprint(classes)\n# land_count_data= pd.DataFrame()\n\nimage_size=128\nchannels= 3 # color image\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"894ac19c-68b1-496b-abfe-ea655fac3895","collapsed":true,"_uuid":"0909412bf70d457a0e9355e2ac5ceb9ca9664a0e","trusted":false},"cell_type":"code","source":"import os, errno\nimport shutil","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7b7b7405-f23a-4d4b-9e6f-154d6e128aeb","_uuid":"788d59f0d3e07d11c331d20edec01ea5a730c9b7","trusted":false,"collapsed":true},"cell_type":"code","source":"dir_path = \"/images\"\ntrain_files=\"/train\"\nfull_image_path=\"/images/train/dummy\"\ndirect_path=dir_path+train_files\ndirectory = os.path.dirname(os.getcwd()+full_image_path) # /kaggle/working/images/train\n#print(os.listdir(directory))\n\n#print(os.listdir(os.getcwd()+direct_path))\n# try:\n#     shutil.rmtree(\"image\")\n# except OSError as e:\n#     print (\"Error: %s - %s.\" % (e.filename,e.strerror))\n    \ntry:\n   if not os.path.exists(directory):\n        os.makedirs(directory)\n        print(\"Created!\")\nexcept OSError as e:\n    if e.errno != errno.EEXIST:\n        print(\"Some unwanted error!\")\n\n# f = open(os.path.join(directory, 'file.txt'), 'w')\n# f.write('This is the new file.')\n# f.close()\n\n# print(os.listdir('/'))\nprint(directory)\nprint(os.listdir(directory))\n# with open(os.path.join(directory, 'file.txt'), 'r') as ins:\n#     array = []\n#     for line in ins:\n#         print(line)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fb5e79c1-3fb8-46d2-9e21-6745cbd174a4","_uuid":"1231cc935a2cd1837b8535b7a31912dab4fa226c","trusted":false,"collapsed":true},"cell_type":"code","source":"import sys, os, multiprocessing, csv\nfrom urllib import request, error\nfrom PIL import Image\nfrom io import BytesIO\nprint(directory)\nprint(os.listdir(directory))\n\ndef parse_data(data_file):\n    csvfile = open(data_file, 'r')\n    csvreader = csv.reader(csvfile)\n    key_url_list = [line[:2] for line in csvreader]\n    print(key_url_list[1:])\n    return key_url_list[1:]  # Chop off header\n\n\ndef download_image(key_url):\n    out_dir = sys.argv[2]\n    (key, url) = key_url\n    filename = os.path.join(out_dir, '{}.jpg'.format(key))\n\n    if os.path.exists(filename):\n        print('Image {} already exists. Skipping download.'.format(filename))\n        return 0\n\n    try:\n        response = request.urlopen(url)\n        image_data = response.read()\n    except:\n        print('Warning: Could not download image {} from {}'.format(key, url))\n        return 1\n\n    try:\n        pil_image = Image.open(BytesIO(image_data))\n    except:\n        print('Warning: Failed to parse image {}'.format(key))\n        return 1\n\n    try:\n        pil_image_rgb = pil_image.convert('RGB')\n    except:\n        print('Warning: Failed to convert image {} to RGB'.format(key))\n        return 1\n\n    try:\n        pil_image_rgb.save(filename, format='JPEG', quality=90)\n    except:\n        print('Warning: Failed to save image {}'.format(filename))\n        return 1\n    \n    return 0\n\n\ndef loader(file_path, ouput_dir):\n#     if len(sys.argv) != 3:\n#         print('Syntax: {} <data_file.csv> <output_dir/>'.format(sys.argv[0]))\n#         sys.exit(0)\n    (data_file, out_dir) = (file_path,ouput_dir)\n\n    if not os.path.exists(out_dir):\n        os.mkdir(out_dir)\n    print(\"Cominggggggggggggggg\")\n    key_url_list = parse_data(data_file)\n    pool = multiprocessing.Pool(processes=20)  # Num of CPUs\n    failures = sum(tqdm.tqdm(pool.imap_unordered(download_image, key_url_list), total=len(key_url_list)))\n    print('Total number of download failures:', failures)\n    pool.close()\n    pool.terminate()\n\nloader('../input/train.csv',directory)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a6af2506-4849-4e7f-8c9c-2d8f8bd2a614","collapsed":true,"_uuid":"b03292d429e74b585519a1dc98e444b77b00964b","trusted":false},"cell_type":"code","source":"# # import wget\n# url = 'https://i1.wp.com/python3.codes/wp-content/uploads/2015/06/Python3-powered.png?fit=650%2C350'  \n# # wget.download(url, 'images/train/image_1.jpg')\n# post_payload = { \"event\": { \"Title\": \"Something, sometime, something, Python\"} }\n# post_headers = {'Content-Type': 'application/xml'}\n# urlretrieve(url=url,filename= \"images/train/image_1.jpg\",data=post_payload)\n# #urlretrieve(url,, headers)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"_cell_guid":"aab0fa56-2345-4293-a2a8-9ebd974be37c","collapsed":true,"_uuid":"88effbfddb474a952132d46a8402a9c669715481","trusted":false},"cell_type":"code","source":"# from urllib.request import urlretrieve\n\n# import csv\n\n# id_tr=[]\n# url_tr=[]\n# land_tr=[]\n\n# with open('../input/train.csv') as fileOpen:\n#     data = csv.reader(fileOpen)\n#     next(data) #bypassinh header in csv\n#     img_count = 0  # start at 1\n    \n# #     with open(os.path.join(dir_path, 'image_train.csv'), 'a+b') as csvfile:\n# #         filewriter = csv.writer(csvfile, delimiter=',',\n# #                             quotechar='|', quoting=csv.QUOTE_MINIMAL)\n#     for row in data:\n#     #         print(row[1])\n#             try:\n#                 img_count += 1\n#                 print(os.path.join(directory, 'image_{0}.jpg').format(img_count))\n#                 urlretrieve(row[1],\n#                         \"images/train/image_1.jpg\")\n#             except Exception as e :    \n#                 print(e)\n#                 print(row[1])\n#                 continue  # continue to next row\n                \n# #             filewriter.writerow(row[0], row[1], row[2])\n#             id_tr.append(row[0]) \n#             url_tr.append(row[1]) \n#             land_tr.append(row[2]) \n#         #         print(row[1])\n        \n# data_to_submit = pd.DataFrame({\n#     'id':id_tr,\n#     'url':url_tr,\n#     'landmark_id':land_tr\n# })","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"30216da9-a2c4-4abe-86e0-04fa06aed6cf","collapsed":true,"_uuid":"49d38825d7fe68df70c5e7eaa300f88741595e9f","trusted":false},"cell_type":"code","source":"# data_to_submit.to_csv(os.path.join(dir_path, 'image_train.csv'),header=None,index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"\n# filter_size_conv1 = 3 \n# num_filters_conv1 = 32\n\n# filter_size_conv2 = 3\n# num_filters_conv2 = 32\n\n# filter_size_conv3 = 3\n# num_filters_conv3 = 64\n    \n# fc_layer_size = 128\n\n# x= tf.placeholder(tf.float32, shape=[None, img_size,image_size,channels], name='x')\n\n# y= tf.placeholder(tf.float32, shape=[None, clsses_number], name='y')\n\n\n\n# weight1=tf.Variable(tf.truncated_normal([filter_size_conv1, filter_size_conv1, channels,  num_filters_conv1],stddev=0.02 ))\n\n# weight2=tf.Variable(tf.truncated_normal([filter_size_conv2, filter_size_conv2, num_filters_conv1,  num_filters_conv2],stddev=0.02 ))\n\n# weight3=tf.Variable(tf.truncated_normal([filter_size_conv3, filter_size_conv3, num_filters_conv2,  num_filters_conv3],stddev=0.02 ))\n\n\n# bias1=tf.Variable(tf.constant(0.05, shape=[num_filters_conv1]))\n\n# bias2=tf.Variable(tf.constant(0.05, shape=[num_filters_conv2]))\n\n# bias3=tf.Variable(tf.constant(0.05, shape=[num_filters_conv3]))\n\n\n# #FC layer weghts and biases\n\n\n\n# def convolutional_operations(inputs,weight, bias):\n    \n#     layer= tf.nn.conv2d(input= inputs, filter=weight, strides=[1,1,1,1], padding='SAME')\n#     layer = tf.add(layer, bias)\n    \n#     layer= tf.nn.max_pool(value=layer, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n    \n#     activation_layer= tf.nn.relu(layer)\n    \n#     return activation_layer\n\n# weight_fc1=tf.Variable(tf.truncated_normal([],stddev=0.02 ))\n#     weight_fc2=\n    \n\n# def fc_operations(inputs, weights, bias):\n#     layer = tf.add(tf.matmul(input, weights) , biases)\n#     activation_layer= tf.nn.relu(layer)\n    \n#     return activation_layer\n\n\n# conv_layer1=convolutional_operations(inputs=x ,weight=weight1 , bias=bias1)\n\n# conv_layer2=convolutional_operations(inputs=conv_layer1 ,weight=weight2 , bias=bias2)\n\n# conv_layer3=convolutional_operations(inputs=conv_layer2 ,weight=weight3 , bias=bias3)\n\n# #calcuate fc layer shape, same but get it from conv_layer3\n\n# layer_resize= conv_layer3,[-1,].get_shape()\n# features_size= layer_resize[1:4].num_elements()\n# fc_layer=tf.reshape(conv_layer3,[-1,features_size]) # or tf.reshape(conv_layer3,[-1,3,3,filter_size_conv3])\n    \n# weghts_fc1=tf.Variable(tf.truncated_normal([ fc_layer.get_shape()[1:4].num_elements(),  fc_layer_size],stddev=0.02 ))\n# bias_fc1=tf.Variable(tf.constant(0.05, shape=[fc_layer_size]))\n# fc_layer1= fc_operations(inputs=fc_layer, weights=weghts_fc1, bias=bias_fc1 )\n\n# weghts_fc2=tf.Variable(tf.truncated_normal([  fc_layer_size, clsses_number],stddev=0.02 ))\n# bias_fc2=tf.Variable(tf.constant(0.05, shape=[clsses_number]))\n# fc_layer2= fc_operations(inputs=fc_layer1, weights=weghts_fc2, bias=bias_fc2 )\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c57bf66a-ba16-45bd-90b2-c13c5147ec79","collapsed":true,"_uuid":"20ec5a326e67fc91baa7b6328cda8becb84614a0","trusted":false},"cell_type":"code","source":"# cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=fc_layer2, labels=y)\n# cost= tf.reduce_mean(cross_entropy)\n\n# optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n\n# y_predict = tf.argmax(fc_layer2, dimension=1) #predict class like: 0 0 0 1 0 0 0\n# y_class = tf.argmax(y, dimension=1) #y class like: 0 0 0 1 0 0 0\n# correctly_predicted = tf.equal(y_predict, y_class)\n\n# accuracy= tf.reduce_mean(tf.cast(correctly_predicted ,float32))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ee6f32b2-97a9-454c-9538-99b414ebdda1","collapsed":true,"_uuid":"d006a1d66a8f6134640dfb16f9b23dcab26bc9dd","trusted":false},"cell_type":"code","source":"# session= tf.Session()\n# session.run(tf.global_variables_initializer())\n# epoch=100\n\n# with session as sess:\n    \n#     for i in range(epoch):\n#         sess.run([optimizer,cost],feed_dcit={x:, y: } )\n        \n#         if i % 10 = 0:\n            \n#             accuracy = sess.run([accuracy], feed_dcit={x:test, y:test })\n#             print(\"accuracy {}\"%(accuracy))\n            \n\n            \n            \n        \n    \n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"585c7361-f938-4dde-8c7e-838d4a274919","collapsed":true,"_uuid":"e17f4e56ced64c91c7011e018dbc3fbbb9ed91de","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}