{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c6319b06-e6bd-91a6-f1fb-62a2288a49d8"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a8dcc109-9ea9-11d0-9eb8-d195c0dcc67b"
      },
      "outputs": [],
      "source": [
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input/train\"]).decode(\"utf8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7c8b65d1-9e08-1121-958c-bc8442af5a26"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "train= glob.glob(\"../input/train/**/*.jpg\")+glob.glob(\"../input/additional/**/*.jpg\")\n",
        "train = pd.DataFrame([[p.split('/')[3],p.split('/')[4],p] for p in train], columns = ['type','image','path'])\n",
        "test = glob.glob(\"../input/test/*.jpg\")\n",
        "test = pd.DataFrame([[p.split('/')[3],p] for p in test], columns = ['image','path'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4496b4a6-2b5e-79a6-78c4-d40d0934b9de"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageFilter, ImageStat, Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "\n",
        "types = train.groupby('type', as_index=False).count()\n",
        "types.plot(kind='bar', x='type', y='path', figsize=(7,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3be2df98-df97-ce0c-054e-ecadfa9403fd"
      },
      "outputs": [],
      "source": [
        "types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "81d9ddc1-1adb-231e-c04b-432d4894528a"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "def im_multi(path):\n",
        "    try:\n",
        "        im_stats_im_ = Image.open(path)\n",
        "        return [path, {'size': im_stats_im_.size}]\n",
        "    except:\n",
        "        print(path)\n",
        "        return [path, {'size': [0,0]}]\n",
        "\n",
        "def im_stats(im_stats_df):\n",
        "    im_stats_d = {}\n",
        "    p = Pool(cpu_count())\n",
        "    ret = p.map(im_multi, im_stats_df['path'])\n",
        "    for i in range(len(ret)):\n",
        "        im_stats_d[ret[i][0]] = ret[i][1]\n",
        "    im_stats_df['size'] = im_stats_df['path'].map(lambda x: ' '.join(str(s) for s in im_stats_d[x]['size']))\n",
        "    return im_stats_df\n",
        "\n",
        "train = im_stats(train)\n",
        "sizes = train.groupby('size', as_index=False)['path'].count()\n",
        "_ = sizes.plot(kind='bar', x='size', y='path', figsize=(7,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e98204d4-3fed-4770-1b9b-1011fee0b3ee"
      },
      "outputs": [],
      "source": [
        "sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f9452504-bac2-67d8-b367-d9629d4ed944"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import log_loss\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "\n",
        "def get_im_cv2(path):\n",
        "    img = cv2.imread(path)\n",
        "    resized = cv2.resize(img, (64, 64), cv2.INTER_LINEAR)\n",
        "    return [path, resized]\n",
        "\n",
        "def normalize_image_features(paths):\n",
        "    imf_d = {}\n",
        "    p = Pool(cpu_count())\n",
        "    ret = p.map(get_im_cv2, paths)\n",
        "    for i in range(len(ret)):\n",
        "        imf_d[ret[i][0]] = ret[i][1]\n",
        "    ret = []\n",
        "    fdata = [imf_d[f] for f in paths]\n",
        "    fdata = np.array(fdata, dtype=np.uint8)\n",
        "    fdata = fdata.transpose((0, 3, 1, 2))\n",
        "    fdata = fdata.astype('float32')\n",
        "    fdata = fdata / 255\n",
        "    return fdata\n",
        "\n",
        "#train = glob.glob('../input/train/**/*.jpg') + glob.glob('../input/additional/**/*.jpg')\n",
        "print(len(train))\n",
        "#train = pd.DataFrame([[p.split('/')[3],p.split('/')[4],p] for p in train], columns = ['type','image','path'])\n",
        "train = train[train['size'] != '0 0'].reset_index(drop=True) #remove bad images\n",
        "train_data = normalize_image_features(train['path'])\n",
        "#np.save('train.npy', train_data, allow_pickle=True, fix_imports=True)\n",
        "#train_data = np.load('train.npy')\n",
        "\n",
        "le = LabelEncoder()\n",
        "train_target = le.fit_transform(train['type'].values)\n",
        "#np.save('train_target.npy', train_target, allow_pickle=True, fix_imports=True)\n",
        "#train_target = np.load('train_target.npy')\n",
        "\n",
        "def create_model(opt_):\n",
        "    model = Sequential()\n",
        "    model.add(ZeroPadding2D((1, 1), input_shape=(3, 64, 64)))\n",
        "    model.add(Convolution2D(8, 3, 3))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(12))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(6))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=opt_, loss='sparse_categorical_crossentropy', metrics=['accuracy']) #loss='binary_crossentropy' not working\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, nb_epoch=10, batch_size=15, verbose=2)\n",
        "opts_ = ['adamax'] #['adadelta','sgd','adagrad','adam','adamax']\n",
        "epochs = np.array([10])\n",
        "batches = np.array([15])\n",
        "param_grid = dict(nb_epoch=epochs, batch_size=batches, opt_=opts_)\n",
        "grid = GridSearchCV(estimator=model, cv=StratifiedKFold(n_splits=2), param_grid=param_grid, verbose=20)\n",
        "grid_result = grid.fit(train_data, train_target)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "for params, mean_score, scores in grid_result.grid_scores_:\n",
        "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))\n",
        "#print(\"Log Loss...\", log_loss(train_target, grid_result.predict(train_data)))\n",
        "\n",
        "test_data = normalize_image_features(test['path'])\n",
        "#np.save('test.npy', test_data, allow_pickle=True, fix_imports=True)\n",
        "#test_data = np.load('test.npy')\n",
        "test_id = test.image.values\n",
        "#np.save('test_id.npy', test_id, allow_pickle=True, fix_imports=True)\n",
        "#test_id = np.load('test_id.npy')\n",
        "\n",
        "pred = grid_result.predict_proba(test_data)\n",
        "df = pd.DataFrame(pred, columns=le.classes_)\n",
        "df['image_name'] = test_id\n",
        "df.to_csv('submission.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}