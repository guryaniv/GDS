{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5191cf5e2d4ee35572f1ffe024e565b46f112e35"},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import ReduceLROnPlateau # Reduce learning rate when a metric has stopped improving.\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d83d00a9597f1733d75ae4262da94b59c95b5145"},"cell_type":"code","source":"# Load the data\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"610a0739f21f4b81bc8cad11bddd8f537b405a11"},"cell_type":"code","source":"train.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9933a0dc67aabd702ab5b8e91f06bbe402dcfa90"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdc9a0e28a07f204ffed56dcd2f69a5f99487d8d"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fddc29364cc8384f3217c787146b795320eee6df"},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52b0cf074815d1819fb05151475e8d625c667fcc"},"cell_type":"code","source":"X_train=train.drop('label',axis=1)\ny_train=train['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e6ef78e7dc2126d8c7436eef96e6e167a40609f"},"cell_type":"code","source":"sns.countplot(x=y_train)\ny_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"653eef5758ccfed1f110fd13c1f3a7b8ebb6523b"},"cell_type":"code","source":"# checking for null values\nX_train.isnull().any().value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76f55013d7fe60c34a847b8e3bb3b584811e98cb"},"cell_type":"code","source":"test.isnull().any().value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82beb6c2ef3b743080d700dcf9e4ec3bff451f4f"},"cell_type":"code","source":"print('max value in one digit matrix',X_train.iloc[0].max())\nprint('min value in one digit matrix' , X_train.iloc[1].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d55840d40a1ae348b94692c3c2f6a1523e9092b7"},"cell_type":"code","source":"#Normalization the data\nX_train = X_train / 255.0\ntest = test / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c2621bf4bcfb66bf6e277de2bfdb3bf5358bd02"},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81ec1cd8c9607ce63902ef4708b38e14a2ceb4ec"},"cell_type":"markdown","source":"If one component of shape is the special value -1, the size of that dimension is computed so that the total size remains constant. In particular, a shape of [-1] flattens into 1-D. At most one component of shape can be -1.\n                                                           \n[https://docs.scipy.org/doc/numpy-1.10.4/reference/generated/numpy.reshape.html](http://)"},{"metadata":{"trusted":true,"_uuid":"8e45f47f069b87aad6b6cac9771396668387ae14"},"cell_type":"code","source":"# reshapping image in three dimension\nX_train = X_train.values.reshape(-1,28,28,1) # -1 it is an unknown dimension and we want numpy to figure it out.it is length of array\ntest = test.values.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b254cddf2847c084700fb280f5e0bf5ac27fee3e"},"cell_type":"code","source":"print('shape of full data', X_train.shape)\nprint('shape of one digit', X_train[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba28c4db5c2a52b3ccbd55e83e14416dc6aadaf1"},"cell_type":"code","source":"# applying ONE-HOT-ENCODING\ny_train=to_categorical(y_train,num_classes=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52a74f199d8907ecd54f6dcfb2c44f63deb1a23c"},"cell_type":"code","source":"# splitting the data into training and validation data\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3272e924107f9d6b14348112bffd350fc1e41520"},"cell_type":"markdown","source":"## Building the model"},{"metadata":{"trusted":true,"_uuid":"39eb2f1c16545d1a64b6b8957d161b18ec619a42"},"cell_type":"code","source":"#initialzing the model\nmodel=Sequential()\n\n# first Convolution layer\nmodel.add(Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu',input_shape=(28,28,1)))\n\n# Second Convoultion layer\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n\n#polling the layers\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n# third Convolution layer\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n# fourth Convoultion layer\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n\n# Second polling layer\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n# flattening the output from Convolution and polling layers\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a826875f7405978a2e7dd56fb828c4d76b1ea046"},"cell_type":"markdown","source":"## Defining the optimizer"},{"metadata":{"trusted":true,"_uuid":"7a1e1c0cd6953afb45ea6ec2675a1ee39dc25ce0"},"cell_type":"code","source":"# Define the optimizer\noptimizer = RMSprop()\n# compling the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# decreases the learning rate during training\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, \n                                            factor=0.5, min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a67dcf7934b81b52d8d8b1d95f98f3c7fe9088f"},"cell_type":"markdown","source":"## DATA AUGMENTATION"},{"metadata":{"trusted":true,"_uuid":"e109660a56873bce65acf0c273a15daf2e0d0ad9"},"cell_type":"code","source":"# vertical_flip nor horizontal_flip since it could have lead to misclassify symetrical numbers such as 6 and 9.\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train) #Only required if featurewise_center or featurewise_std_normalization or zca_whitening are set to True.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c797fd576ac56d6b7a6fdd5883ec9b3865385fb"},"cell_type":"code","source":"batch_size=30\nnb_train=len(X_train)\nnb_val=len(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd99a369edc59c1d5920c7549262a2cdf97d590d"},"cell_type":"code","source":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = 20,verbose = 1, \n                              steps_per_epoch=nb_train // batch_size, \n                              validation_data = (X_val,y_val),\n                              validation_steps=nb_val//batch_size\n                              ,callbacks=[learning_rate_reduction])\nmodel.save('Digit_recognizer.h5')\nmodel.save_weights('Weight_file_for_Digit_recognizer.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8939aa43bd19d52d034ddc9469f7a59b5cd5b1f6"},"cell_type":"code","source":"# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ffad02a2aef7f1ded6d447d173663d07f14d81cd"},"cell_type":"markdown","source":"## Predicting the result"},{"metadata":{"trusted":true,"_uuid":"c90feb1fb6ebc0ae9197deb94b3828017feb1b76"},"cell_type":"code","source":"prob_pred= model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(prob_pred,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2de8ce0ca054c06964f04fffb1fd50bd560f87e4"},"cell_type":"markdown","source":"# Visualizing the result"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"f3d001b254925dd1114e970d75ff514bd61694ab"},"cell_type":"code","source":"for i in range(10):\n    plt.imshow(test[i].reshape(28,28),cmap='gray')\n    plt.title('Predicted {}'.format(results[i]))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07e7fdddf26d839bf6024cec3435bb655d44663c"},"cell_type":"code","source":"results = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"my_submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2b1ebaec7978d0a1b92652fd8f0f3228aed7c53"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}