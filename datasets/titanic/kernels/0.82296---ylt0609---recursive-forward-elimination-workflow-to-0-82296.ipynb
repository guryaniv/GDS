{"cells":[{"metadata":{"_uuid":"d3b142619061e76c43c531e36ec525e1d636c0ed"},"cell_type":"markdown","source":"<a id='Introduction'></a>\n# Introduction\n\n*  Recursive Forward Elimination Workflow\n\n**The workflow could prevent us from noise and redundancy of feature. Sometimes we just put all feature together but doesn't see what is actually happening. If we join one feature at once and test, a clear staged sum up comes. You'll see how this feature works. Is it good, bad, or others needed.** That's the idea of Recursive Foward Elimination Workflow. We'll try this for the in-sample training set, Out-Of-Bag validation set (a kind of CV), and the leader board.\n\n\n* RandomForest\n\nWe'll show the pros and cons of RandomForest. Intro\n\n\n* Sex-Pclass-table\n\nInstead of checking your CV score, we suppose a target distribution which makes the passengers survived or dead and get close to it with our machine learning algorithm. That hypothesis supposed by Oscar Takeshita in his article [Divide and Conquer section 4.1](https://www.kaggle.com/pliptor/divide-and-conquer-0-82296), I think it pretty makes sense. If you wanna to conquer above 0.84, this kernel might show you some inspiration.\n\n* If you are the pure beginners, check some EDA report and make your own model first, you'll check this kernel soonly.\n\nRecommended:[Pytanic](https://www.kaggle.com/headsortails/pytanic) by Head or Tails, comprehensive content, take you a lot of time but worthy.\n"},{"metadata":{"_uuid":"02d3e5d6f42f5b4ac4e262544cfe109f6974e0d7"},"cell_type":"markdown","source":"<a id='The Iterative Process'></a>"},{"metadata":{"_uuid":"f8fb7cdae6f3dc8e9ab17b9956dc12a698d2feae"},"cell_type":"markdown","source":"# The Iterative Process\nThere are a lot of kernels show you an approach with a streamlined style which is NOT TRUE! We always got stuck in our analysis, found out something might work, engineered it, made EDA of it, then try and failed finally. So it's a plenty of messy work on my jupyter book. This kernel will show you an iterative workflow which is more realistic. It basically follows this cycle:\n\n* EDA --> Selected Features --> Modeling --> Estimated then back to EDA"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# loading package\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n%matplotlib inline\nsns.set()\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, learning_curve, train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.metrics import confusion_matrix, classification_report\n# loading data\ndf_train = pd.read_csv(\"../input/train.csv\")\ndf_test = pd.read_csv(\"../input/test.csv\")\ndf_data = df_train.append(df_test)\n# for display dataframe\nfrom IPython.display import display\nfrom IPython.display import display_html\ndef display_side_by_side(*args):\n    html_str=''\n    for df in args:\n        html_str+=df.to_html()\n    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n# ignore warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"7aa884d9f5918d0efc5353e844b06351065fe3db"},"cell_type":"markdown","source":"<a id='Base Model'></a>"},{"metadata":{"_uuid":"fb96f92b86c314920e84b31fcc39056cf4db8f10"},"cell_type":"markdown","source":"# Base Model\nThe base model is the lowest score we can get. Normally the coin tossing solution (just 0.5 probability survived or died). Here we start with Sex & Pclass only. "},{"metadata":{"_uuid":"bea2e0ccede09a8ebc10d2d5a3b68acb05551350"},"cell_type":"markdown","source":"<a id='Model Picking'></a>"},{"metadata":{"_uuid":"23b7ff9729c30bb1f977a6521c461d0fafe75278"},"cell_type":"markdown","source":"# Model Picking\n\nYou need to pick 1~3 models and understand how it works. \nA different model needs different data preprocessing sometimes, and different performance on the feature weight also. So make sure what model you pick then we control some kind of variable. Search the tags model comparison and pick one. Here we pick RandomForest"},{"metadata":{"trusted":true,"_uuid":"745ae6d32b5c577db1701f6a579e9eee7cf447ba","collapsed":true},"cell_type":"code","source":"# Convert Sex\ndf_data['Sex_Code'] = df_data['Sex'].map({'female' : 1, 'male' : 0}).astype('int')\n# split training set the testing set\ndf_train = df_data[:len(df_train)]\ndf_test = df_data[len(df_train):]\n# Inputs set and labels\nX = df_train.drop(labels=['Survived','PassengerId'],axis=1)\nY = df_train['Survived']","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"7f8f647c97b5c3921752e01ecaddced171efa9f2"},"cell_type":"markdown","source":"<a id='Feature Scaling'></a>"},{"metadata":{"_uuid":"f020bdf032d6328725c7cf4195301e295b8df074"},"cell_type":"markdown","source":"# Feature Scaling\nFeature Scaling keeps our features weights the same in a distance-based model such as SVM, LogReg, LinearReg...etc. If you want to start with that. Then you needed.\n\nOn the other hand, the tree-based model works via the impurity function such as Decision Tree, Random Forest, Gradient Boosted Decision Tree...etc.\ne.g. cut age feature at 14 makes two groups purer. then you don't need feature scaling."},{"metadata":{"_uuid":"fecdd5136e1908d0ebae94fb39f14e81bdc3a578"},"cell_type":"markdown","source":"<a id='RandomForest'></a>"},{"metadata":{"_uuid":"40f6d4bffc25599fd432af6aa70819c33e3264d9"},"cell_type":"markdown","source":"# RandomForest\n Pros: \n* The large margin like boundary makes our solution more robust against the noise. \n* Efficient for both small and big dataset because we can train the decision\ntree parallelly and mash them up.\n* Self-validate by out-of-bag estimation( a kind of cross-validation) makes workflow simple.\n\nCons:\n\n* Bagging and random-subspace decision tree ensemble so that we don't know how and why it predicts so.\n* Performance depends on the random_state which might be unstable. we should check the stability by adding/dropping one tree."},{"metadata":{"_uuid":"5ddbea63ba792c37869305bc8dfabefac8b3072f"},"cell_type":"markdown","source":"<a id='Setting and Hyperparameters'></a>"},{"metadata":{"_uuid":"b033e44e7816bcfdab58f9a375a1eda7d677646f"},"cell_type":"markdown","source":"# Setting and Hyperparameters\nBe careful about you have set the random_state or not. The two reasons below:\n* make your solution repeatable\n* make your observation without the model variance\n\nThe min_sample_leaf, min_sample splits, max depth are all some kind of prevent your model from overfitting. \n\nOur goal is feature testing not finding out the optimal solution now. So simply set min_sample splits = 20 is fine."},{"metadata":{"_uuid":"e653a50c2e1b565694ba586970bca607a6146741"},"cell_type":"markdown","source":"<a id='Out Of Bag Estimate'></a>"},{"metadata":{"_uuid":"24dee4c6a1638924c8e2241669cf203bee076436"},"cell_type":"markdown","source":"# Out Of Bag Estimate\n\n\nOut Of Bag estimate is a kind of cross-validation, the RandomForest composed of Decision Trees(DT) which training with a subset of whole data.\nThen, the data remained is an unseen data which could be validated the DT\nperformance. If you set n_estimators = 250, then 250 DTs are built and validated with their out of bag data. the method was proved mathemetically that the effect just like train_test_splits and testing set = 0.33 approximately(actually 1/e).\n\n* Pro:\nMake our workflow more efficient and clear code.\n* Con:\nWe can't check the confusion matrix easily with the current sklearn method.\nIf you want to check it, then use train_test split to get a validation set."},{"metadata":{"trusted":true,"_uuid":"23134ed46da9b8fab3cf33b879d324182b269e9a","collapsed":true},"cell_type":"code","source":"# Show Baseline\nBase = ['Sex_Code','Pclass']\nBase_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\nBase_Model.fit(X[Base], Y)\nprint('Base oob score :%.5f' %(Base_Model.oob_score_),'   LB_Public : 0.76555')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c5a31bb3ade5294becd629929399b74aa22f9a7a"},"cell_type":"code","source":"# submission if you want\n'''# submits\nX_Submit = df_test.drop(labels=['PassengerId'],axis=1)\n\nBase_pred = Base_Model.predict(X_Submit[Base])\n\nsubmit = pd.DataFrame({\"PassengerId\": df_test['PassengerId'],\n                      \"Survived\":Base_pred.astype(int)})\nsubmit.to_csv(\"submit_Base.csv\",index=False)''';","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"d079aa73b3691af68a416f99e6d0072cf43de541"},"cell_type":"markdown","source":"<a id='Checkpoint'></a>"},{"metadata":{"_uuid":"e7b98862e68a1c96e3b1aab1d64e38a44ea08dba"},"cell_type":"markdown","source":"# Checkpoint\n\nFirst checkpoint here, if you engineered several features and you got an LB score below 0.76555.\nIt probably means your features are too noisy or you tune your hyperparameters too much to overfit! Restart with Sex and Pclass features only, add the one feature once and test it on LB."},{"metadata":{"_uuid":"37d21db09fddc84822263b266d9a4abda35b4ca7"},"cell_type":"markdown","source":"<a id='Model Evaluation'></a>"},{"metadata":{"_uuid":"4ba022e06bfadc281b5f4d9a053c47171754e875"},"cell_type":"markdown","source":"# Model Evaluation\nWell, normally a confusion matrix is presented here. you could do it if you like.\n\nHowever, one thing here, Sex & Pclass get the same score with Sex only which be mentioned in [How am I doing with my score section 2-3](https://www.kaggle.com/pliptor/how-am-i-doing-with-my-score) by Oscar.\nI also believe that a great predictor distinguished the sex parts well. So it's our target distribution below which we wanna to get close to."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a0511eb4ab92fd079c9f045a8b927b9e42877deb"},"cell_type":"code","source":"# A function about in-sample correct dataframe\ndef Correct_classified_df(model, training_df, labels_df):\n    kfold = StratifiedKFold(n_splits=10)\n    correct_X = training_df\n    corret_classified_index = []\n    # fit in-sample by cross- validation\n    for train_index, val_index in kfold.split(correct_X, labels_df):\n        #print(\"Train:\",train_index,\"Val:\",val_index);\n        FITT = model.fit(X = correct_X.iloc[train_index], y = labels_df.iloc[train_index])\n        pred = FITT.predict(correct_X.iloc[val_index,:])\n        #print(pred)\n        #print(labels_df.iloc[val_index])\n        corret_classified_index.append(\n        labels_df.iloc[val_index][pred == labels_df.iloc[val_index]].index.values)\n        #print(correct_X.iloc[val_index])\n    whole_index=np.concatenate(corret_classified_index)\n\n    # whole_index\n    correct_classified_df = correct_X[correct_X.index.isin(whole_index)]\n    correct_classified_df['Survived'] = labels_df[correct_X.index.isin(whole_index)]\n    return correct_classified_df","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb468b5fc8ecd0ea2376ff2a94b7bbd84b086e74","collapsed":true},"cell_type":"code","source":"# In-sample correct\nBase_correct = Correct_classified_df(Base_Model, X[Base], Y)\n# Compare with what we wish\ntem = [df_data, Base_correct]\ntem_factor_df = []\nfor i in tem:\n    tem_factor_df.append(pd.pivot_table( i, values='Survived',index='Sex_Code',columns='Pclass').round(3))\n# display\ndisplay(pd.concat([tem_factor_df[0], tem_factor_df[1]],keys=['Data', 'Base'], axis = 1))\n# visualization\ng = sns.FacetGrid(data=df_data, row='Sex', col='Pclass',margin_titles=True)\ng.map(sns.countplot,'Survived')","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"cbc570bfc10ba9b9a7be293f0d3ea332325b9293"},"cell_type":"markdown","source":"<a id='Sex-Pclass-table'></a>"},{"metadata":{"_uuid":"45ee997d0ee6aa4cf603ea35583dcab9232ece09"},"cell_type":"markdown","source":"# Sex-Pclass-table\n\nThe survival with respect to Sex & Pclass is shown above. We can see that our Pclass and Sex base model predict Pclass = 1 and Pclass = 2 all men died and all woman survived. The women in Pclass = 1 and Pclass = 2 all survived is basically true by checking the in-sample distribution. I think our model did well at the two parts. There are four parts remained that we are going to predict. **Suppose the in-sample distribution is a probably approximately correct target in both LB public and private, good features will bring us closer to it and improve both CV and LB.**"},{"metadata":{"_uuid":"60e06cd8f9620865bc85a87fa7e8bc65f12bef2a"},"cell_type":"markdown","source":"<a id='Adding Fare'></a>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Adding Fare\n\n* Another good feature which gives us \"a richer person --> a higher social status --> more probability to survive\".\nWe can check that easily by the pivot_table with Fare_median and the box plot with Log_Fare.\n\n* A skew numerical feature which is harder to display and might not be good in the regression problem. We show the Log_Fare which also capture the relation with respect to Survived. Note that we adjust Fare --> Fare + 1 that makes all values could be presented.\n"},{"metadata":{"trusted":true,"_uuid":"c98364dfcf58da6a93695cd1fb84a277d9438ba4","collapsed":true},"cell_type":"code","source":"# there is some bugs in log-scale of boxplot. \n# alternatively, we transform x into log10(x) for visualization.\nfig, ax = plt.subplots( figsize = (18,7) )\ndf_data['Log_Fare'] = (df_data['Fare']+1).map(lambda x : np.log10(x) if x > 0 else 0)\nsns.boxplot(y='Pclass', x='Log_Fare',hue='Survived',data=df_data, orient='h'\n                ,ax=ax,palette=\"Set3\")\nax.set_title(' Log_Fare & Pclass vs Survived ',fontsize = 20)\npd.pivot_table(df_data,values = ['Fare'], index = ['Pclass'], columns= ['Survived'] ,aggfunc = 'median' ).round(3)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"d5aac3da23a63838d1087468c7680142d8894b48"},"cell_type":"markdown","source":"<a id='How many bins should we cut?'></a>"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1f17b73219d6ad0ae7cfbcd29fbc1f956b990fe8"},"cell_type":"markdown","source":"# How many bins should we cut?\nWe know that cutting the numerical feature into bins reduce noise. Let's image about that:\n* If the bins --> infinity, then our bins are too delicate and back into numerical.\n* If the bins --> one, then our bin is too rough to capture the pattern inside the feature."},{"metadata":{"trusted":true,"_uuid":"936124956530bac5dc04da3cbb6fb24e999be48d","collapsed":true},"cell_type":"code","source":"# Filling missing values\ndf_data['Fare'] = df_data['Fare'].fillna(df_data['Fare'].median())\n\n# Making Bins\ndf_data['FareBin_4'] = pd.qcut(df_data['Fare'], 4)\ndf_data['FareBin_5'] = pd.qcut(df_data['Fare'], 5)\ndf_data['FareBin_6'] = pd.qcut(df_data['Fare'], 6)\n\nlabel = LabelEncoder()\ndf_data['FareBin_Code_4'] = label.fit_transform(df_data['FareBin_4'])\ndf_data['FareBin_Code_5'] = label.fit_transform(df_data['FareBin_5'])\ndf_data['FareBin_Code_6'] = label.fit_transform(df_data['FareBin_6'])\n\n# cross tab\ndf_4 = pd.crosstab(df_data['FareBin_Code_4'],df_data['Pclass'])\ndf_5 = pd.crosstab(df_data['FareBin_Code_5'],df_data['Pclass'])\ndf_6 = pd.crosstab(df_data['FareBin_Code_6'],df_data['Pclass'])\n\ndisplay_side_by_side(df_4,df_5,df_6)\n\n# plots\nfig, [ax1, ax2, ax3] = plt.subplots(1, 3,sharey=True)\nfig.set_figwidth(18)\nfor axi in [ax1, ax2, ax3]:\n    axi.axhline(0.5,linestyle='dashed', c='black',alpha = .3)\ng1 = sns.factorplot(x='FareBin_Code_4', y=\"Survived\", data=df_data,kind='bar',ax=ax1)\ng2 = sns.factorplot(x='FareBin_Code_5', y=\"Survived\", data=df_data,kind='bar',ax=ax2)\ng3 = sns.factorplot(x='FareBin_Code_6', y=\"Survived\", data=df_data,kind='bar',ax=ax3)\n# close FacetGrid object\nplt.close(g1.fig)\nplt.close(g2.fig)\nplt.close(g3.fig)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"f154d2490e5bdcb51a1e6a1945dda30b8b9cf012"},"cell_type":"markdown","source":"A wider range of bins to experiment should be done when you fork. If we cut bins = 3 ~ 8, the model performs better or not. Feel free when you encounter such a problem and you'll get a deep insight from yourself.\n\n\nThe dashed line indicated the coin toss gauss of the model when it doesn't capture any pattern. We use both RFECV and LB to check how many bins work well."},{"metadata":{"trusted":true,"_uuid":"1cdb89ed9404e6878fd43ed5bb38986cb2fe8164","collapsed":true},"cell_type":"code","source":"# splits again beacuse we just engineered new feature\ndf_train = df_data[:len(df_train)]\ndf_test = df_data[len(df_train):]\n# Training set and labels\nX = df_train.drop(labels=['Survived','PassengerId'],axis=1)\nY = df_train['Survived']\n# show columns\nX.columns","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"8c90185b98bf855be0a2c121fc686aa8373f5513"},"cell_type":"markdown","source":"* <a id=' Modeling'></a>"},{"metadata":{"_uuid":"d88c69409a0c84fce2b019025b88695cf894ff39"},"cell_type":"markdown","source":"## Modeling"},{"metadata":{"_uuid":"a340ca33227f06048c64c7e9cc9d00aa0cb5aae0"},"cell_type":"markdown","source":"<a id='First shot'></a>"},{"metadata":{"_uuid":"f853461dbd04f2fe09d5d64400f99056cf5000e5"},"cell_type":"markdown","source":"### First shot \nWe need to try once on LB with randomly pick one fare bin to make sure the selected feature works better than Sex + Pclass. Here we pick bins = 4"},{"metadata":{"trusted":true,"_uuid":"67ad1ea6f9b5841f2d0d39ab29d06a7d2ae40135","collapsed":true},"cell_type":"code","source":"# oob : 0.8054 split = 20,30,40 oob : 0.79012 split = 50\nbin_4 = ['Sex_Code','Pclass','FareBin_Code_4']\nbin_4_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\nbin_4_Model.fit(X[bin_4], Y)\nprint('bin_4 oob score :%.5f' %(bin_4_Model.oob_score_),'   LB_Public : 0.7790')","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"1176249542efeffa24b926d128a299865e184593"},"cell_type":"markdown","source":"We got 0.7790 which is better than 0.7655. The Fare feature works. Now we improve our result by RFECV and LB to choose bins.\n\nNote: \n* If you tune the min_sample_split = 5,10,15, the result is the same. Because we set 250 trees to regularized the overfitting trees boundary.\n* If you tune the min_sample_split = 30,40,45, the result is the same. \nBecause we set 250 trees by aggregating them to capture more pattern that one tree cannot achieve. \n* If you tune the min_sample_split = 50 up, then the model tends to underfit\nthat cannot capture the pattern although we aggregate them."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6b91b72610374d34f8a4e13ad7fa4bddd8350534"},"cell_type":"code","source":"# submission if you want\n'''# submits\nX_Submit = df_test.drop(labels=['PassengerId'],axis=1)\n\nbin_4_pred = bin_4_Model.predict(X_Submit[bin_4])\n\nsubmit = pd.DataFrame({\"PassengerId\": df_test['PassengerId'],\n                      \"Survived\":bin_4_pred.astype(int)})\nsubmit.to_csv(\"../output/submit_bin_4.csv\",index=False)''';","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"f1a51ae4aebeb320973f88ef6adaff5de3201473"},"cell_type":"markdown","source":"<a id='Compare bins using RFECV'></a>"},{"metadata":{"_uuid":"b6da9d98970ce017a9560d9b0566780bf56ce275"},"cell_type":"markdown","source":"### Compare bins using RFECV\nThe RFECV is a method of Feature Selection named Recursive Forward Elimination Cross-Validation which is adding one feature once to test on CV. If your feature brings too less pattern CV decrease. But when CV increase, probably means that the feature brings enough pattern or just fit the noise in it which is overfitting.\nSo, a double check on LB to make sure our result is significant.\n\nPros:\n* Concluding the feature interaction with the target. i.e. male in Pclass = 1 will survive more than Pclass = 3. It is what chi-square or others single feature testing cannot achieve.\n\nCons:\n* Obviously, it will take a long time to select feature which is bad if the dataset is large.\n* Depends on cv score but such kind of small dataset, it still overfits if we tune the hyperparameters too much. So I set min_sample_splits = 20 to prevent it happened.\n\n\n More detail about RFECV in [doc](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html) and an application that  [3 Strategies Analyzing Age and Their Impact](https://www.kaggle.com/ylt0609/3-strategies-analyzing-age-and-their-impact)\n"},{"metadata":{"trusted":true,"_uuid":"160f06d8373ed99bb41e83cb673ecadc6cb8cbc8","collapsed":true},"cell_type":"code","source":"compare = ['Sex_Code','Pclass','FareBin_Code_4','FareBin_Code_5','FareBin_Code_6']\nselector = RFECV(RandomForestClassifier(n_estimators=250,min_samples_split=20),cv=10,n_jobs=-1)\nselector.fit(X[compare], Y)\nprint(selector.support_)\nprint(selector.ranking_)\nprint(selector.grid_scores_*100)","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"d05e47b57ea89f92b16135461c5c5ed5fe7a77da"},"cell_type":"markdown","source":"It looks like that FareBin=6 captures more pattern, let's evaluate on different model random state and CV random state to make sure the result is not occasional."},{"metadata":{"trusted":true,"_uuid":"ab71e014afd70d5d6cf710f9050b78b5b0b2e711","collapsed":true},"cell_type":"code","source":"score_b4,score_b5, score_b6 = [], [], []\nseeds = 7 # kaggle kernel is unstable if you use too much computational resource\n# I set seed = 10 normally when coding with my jupyter-notebook\nfor i in range(seeds):\n    diff_cv = StratifiedKFold(n_splits=10,shuffle=True,random_state=i)\n    selector = RFECV(RandomForestClassifier(random_state=i,n_estimators=250,min_samples_split=20),cv=diff_cv,n_jobs=-1)\n    selector.fit(X[compare], Y)\n    score_b4.append(selector.grid_scores_[2])\n    score_b5.append(selector.grid_scores_[3])\n    score_b6.append(selector.grid_scores_[4])","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"780c920ed7785a712c8b85cb0cf96fdaf4f90c3d","collapsed":true},"cell_type":"code","source":"# to np.array\nscore_list = [score_b4, score_b5, score_b6]\nfor item in score_list:\n    item = np.array(item*100)\n# plot\nfig = plt.figure(figsize= (18,8) )\nax = plt.gca()\nax.plot(range(seeds), score_b4,'-ok',label='bins = 4')\nax.plot(range(seeds), score_b5,'-og',label='bins = 5')\nax.plot(range(seeds), score_b6,'-ob',label='bins = 6')\nax.set_xlabel(\"Seed #\", fontsize = '14')\nax.set_ylim(0.783,0.815)\nax.set_ylabel(\"Accuracy\", fontsize = '14')\nax.set_title('bins = 4 vs bins = 5 vs bins = 6', fontsize='20')\nplt.legend(fontsize = 14,loc='upper right')","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"62a41a9e78a400787d42161a1fe5441683f8461c"},"cell_type":"markdown","source":"\nIt seems that bins = 6 capture more information with higher accuracy. Upon now we continue to test on LB to make sure there is no overfitting."},{"metadata":{"trusted":true,"_uuid":"d342cc53fe517513d099f179dff88acde7c94a6d","collapsed":true},"cell_type":"code","source":"b4, b5, b6 = ['Sex_Code', 'Pclass','FareBin_Code_4'], ['Sex_Code','Pclass','FareBin_Code_5'], ['Sex_Code','Pclass','FareBin_Code_6']\nb4_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\nb4_Model.fit(X[b4], Y)\nb5_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\nb5_Model.fit(X[b5], Y)\nb6_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\nb6_Model.fit(X[b6], Y)\nprint('b4 oob score :%.5f' %(b4_Model.oob_score_),'   LB_Public : 0.7790')\nprint('b5 oob score :%.5f '%(b5_Model.oob_score_),' LB_Public : 0.79425')\nprint('b6 oob score : %.5f' %(b6_Model.oob_score_), '  LB_Public : 0.77033')","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"c175220dbf4d05e06c439cd10b7a5df9d4ec364b"},"cell_type":"markdown","source":"> <a id='Checkpoint_Fare'></a>"},{"metadata":{"_uuid":"c6903b87c232179177cb8cfa7a50f9a1295d978f"},"cell_type":"markdown","source":"### Checkpoint\n\n**bins = 5 WIN!** Set bins=6 will bring more noise and make model predict worse on LB. Now we get 0.79425 on LB score.\n\nYou can play the hyperparameter min_sample_split here, too. I have not done it, and I believe the similar effect happens that we discussed prior section."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3b9f4b99754e757ae91c68c671d350a38aeee808"},"cell_type":"code","source":"# submission if you want\n'''# submits\nX_Submit = df_test.drop(labels=['PassengerId'],axis=1)\n\nbin_5_pred = bin_5_Model.predict(X_Submit[bin_5])\n\nsubmit = pd.DataFrame({\"PassengerId\": df_test['PassengerId'],\n                      \"Survived\":bin_5_pred.astype(int)})\nsubmit.to_csv(\"submit_bin_5.csv\",index=False)''';","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"04f920b0600a07ec05f0ea47f71eafbf240bd6b8"},"cell_type":"markdown","source":"<a id='Model Evaluation_Fare'></a>"},{"metadata":{"_uuid":"766bb8e5138d97ae04c752e55929281475eb4670"},"cell_type":"markdown","source":"## Model Evaluation"},{"metadata":{"trusted":true,"_uuid":"e6a9cec58769847f21503c52bfeee291f409e3dd","collapsed":true},"cell_type":"code","source":"# In-Sample correct\nb5_correct = Correct_classified_df(b5_Model, X[b5], Y)\n# Compare \ntem = [df_data, Base_correct, b5_correct]\ntem_factor_df = []\nfor i in tem:\n    tem_factor_df.append(pd.pivot_table( i, values='Survived',index='Sex_Code',columns='Pclass').round(3))\n# display\ndisplay(pd.concat([ tem_factor_df[0], tem_factor_df[1], tem_factor_df[2] ],keys=['Data', 'Base','Adding_FareBin'], axis = 1))","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"871c96e90c3b2a3c553e6c246815d9534d0238b8"},"cell_type":"markdown","source":"Look the 3 tables, the FareBin=5 feature capture the female survival pattern in Pclass = 3. But how about the pattern in pclass = 1,2,3 male?** I think it does. But the Sex predictor is too strong to outstrip the impact of FareBin=5.**\nA solution might help is reconstructing the training dataset which you could give it a try. \n\nIn this section, we achieve more accuracy by adding the Fare feature which \nseparates some women into dead in Pclass = 3."},{"metadata":{"_uuid":"f7185bd5a0087f6d1a93084d77a8c7ea4fb72905"},"cell_type":"markdown","source":"<a id='Adding Connected_Survival'></a>"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5f834bf713c78cb7a49282c0f6782474238688eb"},"cell_type":"markdown","source":"# Adding Connected_Survival\nThis feature was found out in [Blood is thicker than water & friendship forever](https://www.kaggle.com/shunjiangxu/blood-is-thicker-than-water-friendship-forever/code) by S.Xu. You can also find out in Pytanic by Heads and Tails which collected a series of EDA. It's awesome and valuable features. S.Xu explore that based on family_size and fare. We take another approach from the feature Ticket. The both are roughly the same to capture the pattern."},{"metadata":{"trusted":true,"_uuid":"3983db15a1c000f256e2dde7c175a5033d419da2","collapsed":true},"cell_type":"code","source":"df_train['Ticket'].describe()\n# count - unique != 0 which means there are duplicated","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f4fa6f7c1625af6b6428adf3d9531a612085fca","collapsed":true},"cell_type":"code","source":"# Family_size\ndf_data['Family_size'] = df_data['SibSp'] + df_data['Parch'] + 1\n# how about the fare values of deplicate tickets \ndeplicate_ticket = []\nfor tk in df_data.Ticket.unique():\n    tem = df_data.loc[df_data.Ticket == tk, 'Fare']\n    #print(tem.count())\n    if tem.count() > 1:\n        #print(df_data.loc[df_data.Ticket == tk,['Name','Ticket','Fare']])\n        deplicate_ticket.append(df_data.loc[df_data.Ticket == tk,['Name','Ticket','Fare','Cabin','Family_size','Survived']])\ndeplicate_ticket = pd.concat(deplicate_ticket)\ndeplicate_ticket.head(8)","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"3707944cd0215cce8809c2861a06eefa7e53eb6f"},"cell_type":"markdown","source":"We check out the dataframe of deplicated_ticket by easily tune the # of df.head() and found out that people have duplicates always with the same Fare. Furthermore, they died or survived together.\nLet's separate them into families and friends."},{"metadata":{"trusted":true,"_uuid":"2a0ce460eb6e5325fe5572968535a7edfbee5fcf","collapsed":true},"cell_type":"code","source":"print('people keep the same ticket: %.0f '%len(deplicate_ticket))\nprint('friends: %.0f '%len(deplicate_ticket[deplicate_ticket.Family_size == 1]))\nprint('families: %.0f '%len(deplicate_ticket[deplicate_ticket.Family_size > 1]))\ndf_fri = deplicate_ticket.loc[(deplicate_ticket.Family_size == 1) & (deplicate_ticket.Survived.notnull())].head(7)\n# add a title friends\ndf_fami = deplicate_ticket.loc[(deplicate_ticket.Family_size > 1) & (deplicate_ticket.Survived.notnull())].head(7)\n# add a title families\ndisplay(df_fri,df_fami)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a4679df560f7a37121f12f7c97eda1f8275374d","collapsed":true},"cell_type":"code","source":"# the same ticket family or friends\ndf_data['Connected_Survival'] = 0.5 # default \nfor _, df_grp in df_data.groupby('Ticket'):\n    if (len(df_grp) > 1):\n        for ind, row in df_grp.iterrows():\n            smax = df_grp.drop(ind)['Survived'].max()\n            smin = df_grp.drop(ind)['Survived'].min()\n            passID = row['PassengerId']\n            if (smax == 1.0):\n                df_data.loc[df_data['PassengerId'] == passID, 'Connected_Survival'] = 1\n            elif (smin==0.0):\n                df_data.loc[df_data['PassengerId'] == passID, 'Connected_Survival'] = 0\n# prints\nprint('people keep the same ticket: %.0f '%len(deplicate_ticket))\nprint('friends: %.0f '%len(deplicate_ticket[deplicate_ticket.Family_size == 1]))\nprint('families: %.0f '%len(deplicate_ticket[deplicate_ticket.Family_size > 1]))\nprint(\"people have connected information : %.0f\" %(df_data[df_data['Connected_Survival']!=0.5].shape[0]))\ndf_data.groupby('Connected_Survival')['Survived'].mean().round(3)","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"849c17066279ccd3cdc634eaf637e50950ccad4c"},"cell_type":"markdown","source":"There are 496 people have connected_survival information. And a pivot_table of Connected_Survival shows this is a useful feature."},{"metadata":{"_uuid":"c1a02c6bc68f371a8e8f0eb61bb3665cda3ea899"},"cell_type":"markdown","source":"<a id='Modeling Connected_Survival'></a>"},{"metadata":{"_uuid":"84549b9e58adc5bb7e2e617785aea27a0e163713"},"cell_type":"markdown","source":"## Modeling"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"39f01638d6fc670c8fa481a60e70012d0ff67ff0"},"cell_type":"code","source":"# splits again beacuse we just engineered new feature\ndf_train = df_data[:len(df_train)]\ndf_test = df_data[len(df_train):]\n# Training set and labels\nX = df_train.drop(labels=['Survived','PassengerId'],axis=1)\nY = df_train['Survived']","execution_count":19,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b186f3a96be33e88f4741b402f1644bc0b33c78a","collapsed":true},"cell_type":"code","source":"connect = ['Sex_Code','Pclass','FareBin_Code_5','Connected_Survival']\nconnect_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\nconnect_Model.fit(X[connect], Y)\nprint('connect oob score :%.5f' %(connect_Model.oob_score_),'   LB_Public : 0.80832')","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"34fe5b8b90bacb61b9b6e70db96ee9d06cf49095"},"cell_type":"markdown","source":"<a id='Checkpoint Connected_Survival'></a>"},{"metadata":{"_uuid":"43cb6311122b4dc4ee6b5f9bd9d80780539b4b81"},"cell_type":"markdown","source":"### Checkpoint\nWhen we add Connect_Survival, we achieve 0.80832 on LB and 0.82043 oob.\nIt's quite a beneficial feature!"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3c5c74e530cdab490b57d1356f312a2295ccca63"},"cell_type":"code","source":"# submission if you want\n'''# submits\nX_Submit = df_test.drop(labels=['PassengerId'],axis=1)\n\nconnect_pred = connect_Model.predict(X_Submit[connect])\n\nsubmit = pd.DataFrame({\"PassengerId\": df_test['PassengerId'],\n                      \"Survived\":connect_pred.astype(int)})\nsubmit.to_csv(\"submit_connect.csv\",index=False)''';","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"3619231300dd388b880cae2eb96d4e2f96236b48"},"cell_type":"markdown","source":"<a id='Model Evaluation Connected_Survival'></a>"},{"metadata":{"_uuid":"8738c400bd9a9f87dbf060a035824c3b9d508fee"},"cell_type":"markdown","source":"## Model Evaluation"},{"metadata":{"trusted":true,"_uuid":"fbde4a879323b308df647a83d717b2449870c45e","collapsed":true},"cell_type":"code","source":"# In-Sample correct\nconnect_correct = Correct_classified_df(connect_Model, X[connect], Y)\n# Compare \ntem = [df_data, Base_correct, b5_correct,connect_correct]\ntem_factor_df = []\nfor i in tem:\n    tem_factor_df.append(pd.pivot_table( i, values='Survived',index='Sex_Code',columns='Pclass').round(3))\n# display\nkeys=['Data', 'Base','Adding_FareBin','Adding_Connected']\ndisplay(pd.concat([ tem_factor_df[0], tem_factor_df[1], tem_factor_df[2],tem_factor_df[3] ],keys=keys, axis = 1))","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"a585ea05fe1b4c86b153933ff8acac1058d7ac67"},"cell_type":"markdown","source":"\nIn this section, we see that Connect_Survival separated more women dead with their families(friends) and some male survived in Pclass = 3. The male in Pclass = 3 survived might be adult or minor. If you want, just check the connect_correct dataframe then you found out what your model had done."},{"metadata":{"_uuid":"63cdad80205b368da98b14ce5c4b94587e1f005e"},"cell_type":"markdown","source":"<a id='Adding Age'></a>"},{"metadata":{"_uuid":"182b37b824cc64794128973bb9141aaff8dd511b"},"cell_type":"markdown","source":"# Adding Age\nWe'll face a missing value problem that lost 20% data here. An analysis of Age feature and a better strategy was done in [3 Strategies Analyzing Age and Their Impact](https://www.kaggle.com/ylt0609/3-strategies-analyzing-age-and-their-impact).\n\nMy conclusion is:\n\nThe Age feature might be a useless feature but we could extract the minor.\nThe Minor survived more and probably interact well with the Connect_Survival feature. "},{"metadata":{"trusted":true,"_uuid":"4dc843e0b693290030fd4b44f704442650533c2b","collapsed":true},"cell_type":"code","source":"# extracted title using name\ndf_data['Title'] = df_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ndf_data['Title'] = df_data['Title'].replace(['Capt', 'Col', 'Countess', 'Don',\n                                               'Dr', 'Dona', 'Jonkheer', \n                                                'Major','Rev','Sir'],'Rare') \ndf_data['Title'] = df_data['Title'].replace(['Mlle', 'Ms','Mme'],'Miss')\ndf_data['Title'] = df_data['Title'].replace(['Lady'],'Mrs')\ndf_data['Title'] = df_data['Title'].map({\"Mr\":0, \"Rare\" : 1, \"Master\" : 2,\"Miss\" : 3, \"Mrs\" : 4 })\nTi_pred = df_data.groupby('Title')['Age'].median().values\ndf_data['Ti_Age'] = df_data['Age']\n# Filling the missing age\nfor i in range(0,5):\n # 0 1 2 3 4 5\n    df_data.loc[(df_data.Age.isnull()) & (df_data.Title == i),'Ti_Age'] = Ti_pred[i]\ndf_data['Ti_Age'] = df_data['Ti_Age'].astype('int')\n\n# extract minor\ndf_data['Age_copy'] = df_data['Age'].fillna(-1)\ndf_data['Minor'] = (df_data['Age_copy'] < 14.0) & (df_data['Age_copy']>= 0)\ndf_data['Minor'] = df_data['Minor'] * 1\n# We could capture more 8 Master in Pclass = 3 by filling missing age \ndf_data['Ti_Minor'] = ((df_data['Ti_Age']) < 14.0) * 1\nprint('The # of masters we found in missing Age by Title : ', (df_data['Ti_Minor'] - df_data['Minor']).sum())","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"4cd73232076c36bc50bdc941b1d0501b80752096"},"cell_type":"markdown","source":"<a id='Modeling Adding Age'></a>"},{"metadata":{"_uuid":"68d4d74e47ee09a0bcb4d5197fad104854dd943c"},"cell_type":"markdown","source":"## Modeling"},{"metadata":{"trusted":true,"_uuid":"e0263396b0453ffce7486a64e23ab36cb482a863","collapsed":true},"cell_type":"code","source":"# splits again beacuse we just engineered new feature\ndf_train = df_data[:len(df_train)]\ndf_test = df_data[len(df_train):]\n# Training set and labels\nX = df_train.drop(labels=['Survived','PassengerId'],axis=1)\nY = df_train['Survived']\n# Show columns\nX.columns","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"d8c15d9d45d1bb5ce197b793471def9756210bd4","collapsed":true},"cell_type":"code","source":"minor = ['Sex_Code','Pclass','FareBin_Code_5','Connected_Survival','Ti_Minor']\nminor_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\nminor_Model.fit(X[minor], Y)\nprint('Minor oob score :%.5f' %(minor_Model.oob_score_),'   LB_Public : 0.82296')","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"956fc22fbe982efa4c112f228be066495a593d47"},"cell_type":"markdown","source":"> <a id='Checkpoint Adding Age'></a>"},{"metadata":{"_uuid":"0baf84315f8ba4ffacc1c386e621062adc6f87d0"},"cell_type":"markdown","source":"![](http://)\n### Checkpoint\nNow we get 0.82296 by adding Ti_Minor feature. I think the children survived more and there is an awesome interaction between Ti_Minor and Connect_Survival."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a4ca6ebee767fec7d4526bae74be213d50883a13"},"cell_type":"code","source":"X_Submit = df_test.drop(labels=['PassengerId'],axis=1)\n\nminor_pred = minor_Model.predict(X_Submit[minor])\n\nsubmit = pd.DataFrame({\"PassengerId\": df_test['PassengerId'],\n                      \"Survived\":minor_pred.astype(int)})\nsubmit.to_csv(\"submit_minor.csv\",index=False)","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"7203606f89f7b8ac2322bcd453a266b0f846e383"},"cell_type":"markdown","source":"<a id='Model Evaluation Adding Age'></a>"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cb3294e3b5c4fb9b528b3f5699d11f2c8206a5ce"},"cell_type":"markdown","source":"## Model Evaluation"},{"metadata":{"trusted":true,"_uuid":"c1028c0633a876792fcb25023cd07eacc453bc00","collapsed":true},"cell_type":"code","source":"# In-Sample correct\nminor_correct = Correct_classified_df(minor_Model, X[minor], Y)\n# Compare \ntem = [df_data, Base_correct, b5_correct,connect_correct,minor_correct]\ntem_factor_df = []\nfor i in tem:\n    tem_factor_df.append(pd.pivot_table( i, values='Survived',index='Sex_Code',columns='Pclass').round(3))\n# display\nkeys=['Data', 'Base','Adding_FareBin','Adding_Connected','Adding_Ti_Minor']\ndisplay(pd.concat([ tem_factor_df[0], tem_factor_df[1], tem_factor_df[2],tem_factor_df[3],tem_factor_df[4] ],keys=keys, axis = 1))","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"a733826473f588e3aadc5dafce923ca149fd1305"},"cell_type":"markdown","source":"We can see that minor male are well separated by Ti_Minor  and Connected_Survival. Also, the female in Pclass = 3 might be fully separated(more accuracy probably overfit)"},{"metadata":{"_uuid":"c317b7e802909ba8f8d2a76a336878f09d76c5fa"},"cell_type":"markdown","source":"[](http://)<a id='Conclusion'></a>"},{"metadata":{"_uuid":"38c26cf75333659a96332011aaa5e8d1cd7739cb"},"cell_type":"markdown","source":"# Conclusion\nThis kernel introduced more detail in how RandomForest works and the Pclass-Sex table to make sure the effect you trained your model. I think that we did well on the female prediction using these features in this kernel. If you dig deeper in Connected_Survival, you will get ~0.84  as shown in[Titantic Mega Model - [0.84210]](https://www.kaggle.com/cdeotte/titantic-mega-model-0-84210) by Chris Deotte. How am awesome work he had done!\n\nBut above 0.85, I think it's critical to capture how the adult survived in Pclass = 1,2,3. Is there a pattern exist or not? Or try to figure out what model predict adult survived better than RandomForest with the same feature. I tried some, the tree-based model basically performed similar which just make a more robust predictor on predicting female and children. I found out that LogReg seems to do well on male in Pclass=1 but probably overfit. However, It's a valuable direction to explore.\n\nThird, I filtered several common features by checking the LB score by myself. \nA noisy feature adds in, the more robust model is needed.\nI think the feature in this kernel makes several models work well.\n\n\nFinally, If you get something in this kernel or getting help in this kernel. Please upvote and let me know. Happy Coding!\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}