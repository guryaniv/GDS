{"nbformat_minor": 1, "nbformat": 4, "cells": [{"cell_type": "code", "metadata": {"_cell_guid": "deb207a5-50c4-40d7-8e06-fa13b4a8433b", "collapsed": true, "_uuid": "551d494eaa5a56e875ecdf67917a1de05fcaa70c"}, "outputs": [], "source": ["import pandas as pd"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "61bb4ed1-c025-409d-9e47-92c93954e1b5", "collapsed": true, "_uuid": "e53a773faba09fc6122311f5de6fba55d9aec04b"}, "outputs": [], "source": ["df=pd.read_csv('../input/winemag-data-130k-v2.csv',encoding='utf8')"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "ad5f32d3-ba99-4f2c-85ee-ff555a05645b", "collapsed": true, "_uuid": "815fe158a6117bd8102585329b47083ce37b52f7"}, "outputs": [], "source": ["df.dropna(axis=0, inplace=True, subset=['points'])\n", "df.drop('Unnamed: 0',axis=1,inplace=True)"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "6a1c8066-b75f-4e10-b56b-974b659de5f0", "collapsed": true, "_uuid": "6979ab5033f3bfde9c9ddde993b64ab61561324f"}, "outputs": [], "source": ["df.groupby('taster_name').count()"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "7644d127-be94-4d01-b940-5ecf701b0559", "collapsed": true, "_uuid": "67cee1e749a35cbcbb8131b5a439d2dd904a22c0"}, "outputs": [], "source": ["#see the how many reviews they contributed \n", "taster_count=df.groupby('taster_name').count()['points']\n", "taster_count.describe(percentiles=[.01,.05, .5, .95,.99])"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "4524d10c-aae8-4754-9843-26b7bb7799f6", "collapsed": true, "_uuid": "edfbe237cd0cb130d29584b6d8d321ab9eca5f19"}, "outputs": [], "source": ["# remove the bottom 5% tasters\n", "taster_count[taster_count>24.9].index"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "43f3b75f-e9ff-4c3a-bf8f-be63dda98737", "collapsed": true, "_uuid": "2641de787d5a005ec869943a3d5c0149e2ca6e7b"}, "outputs": [], "source": ["# remove the bottom 5% tasters\n", "newdf = df[df['taster_name'].isin(taster_count[taster_count>24.9].index)]"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "b9185286-029d-4b4d-a68f-31d4c2bad0c6", "collapsed": true, "_uuid": "966d069be445fdd71cafd132b01c4a9478b30257"}, "outputs": [], "source": ["newdf"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "ce99cb46-99ca-4678-97f1-1cec5edd2e39", "collapsed": true, "_uuid": "ae2268fe1d5eabeb48ffc840a5d607e1b128ff3d"}, "outputs": [], "source": ["%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "38ec243e-3e90-4f66-9293-58b996b7fded", "collapsed": true, "_uuid": "5605e8a3e319ed035a23f24745830dc98faae11d"}, "outputs": [], "source": ["import numpy as np\n", "country_c = df.groupby('country')"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "4c607052-843e-4d23-afbb-630c30aa0984", "collapsed": true, "_uuid": "0df1a924cc752102ad6c6de44b32048653d93fbd"}, "outputs": [], "source": ["country=country_c['points'].agg([np.sum, np.mean, np.std])"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "06531587-2a24-4be3-9943-618555ba15f0", "collapsed": true, "_uuid": "bbed60ec7ab3cedd800b9d9dd0a98da0690272c9"}, "outputs": [], "source": ["#rank the means points by country\n", "country.sort_values(by='mean',ascending=False)[:20]"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "3a397db7-2a7a-4bd1-879e-094bbc682206", "collapsed": true, "_uuid": "8b4f682939a5fb357b76b9efb0f847379c750dc9"}, "outputs": [], "source": ["#plot top 20 countries\n", "country.sort_values(by='mean',ascending=False)[:20]['mean'].plot.bar()"], "execution_count": null}, {"cell_type": "markdown", "metadata": {"_cell_guid": "cbd287c6-324f-4b6f-a264-c59e962e5c7b", "_uuid": "38a15d95f1ccf441fb740a71a9e0b978936dcd17"}, "source": ["# Group by country, it seems that English has the higest points"]}, {"cell_type": "code", "metadata": {"_cell_guid": "21d85b7d-e0a9-4475-b86e-b70c58fa5cb2", "collapsed": true, "_uuid": "b5de7b0e713bf39d8097bb9ad1a579c5c46373b1"}, "outputs": [], "source": ["#rank the means points by region\n", "region_1 = df.groupby('region_1')['points'].agg([np.sum, np.mean, np.std])"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "87f679e2-abbb-49b0-85f9-1ea3a9c742ea", "collapsed": true, "_uuid": "5a1e2bacc2304dcbe926babdf43ddb60c34f9f3d"}, "outputs": [], "source": ["topRegion=region_1.sort_values(by='mean',ascending=False)[:20]\n", "topRegion"], "execution_count": null}, {"cell_type": "markdown", "metadata": {"_cell_guid": "221a0372-3523-4483-a7a2-29069f0c3f38", "_uuid": "2d6a3051f7e54d169618330708f7d5487754563d"}, "source": ["# However when you group by region, you will see "]}, {"cell_type": "code", "metadata": {"_cell_guid": "bcc3f6af-e7fc-409e-8ddb-be3b8c065ee7", "collapsed": true, "_uuid": "81860640c4e8ecb47badafe9bcdf29eca138bdc4"}, "outputs": [], "source": ["for i in range(20):\n", "    print(newdf[newdf['region_1']==topRegion.index[i]]['country'].unique(),topRegion.index[i])"], "execution_count": null}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ad2a724c-65d2-490c-a684-b46c43c3fa54", "collapsed": true, "_uuid": "d4312e1eaaac86f68d6b550e8334679faad242dc"}, "source": ["**Now to use vord2vec for descrption**"]}, {"cell_type": "code", "metadata": {"_cell_guid": "4d4fb441-012c-40c3-9235-e59ed999ca39", "collapsed": true, "_uuid": "cb137673682c6c9f2b043914a41b798239bb722a"}, "outputs": [], "source": ["import gensim.models.word2vec as w2v\n", "import nltk\n", "from nltk.corpus import stopwords\n", "from nltk import FreqDist\n", "import time,re"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "1d29b37f-894e-4a71-88ea-afdb8e993185", "collapsed": true, "_uuid": "9eb5f5da741e5be7e30f6f43a7c82416f2d649b3"}, "outputs": [], "source": ["def sent_tokenizer(text):\n", "    \"\"\"\n", "    Function to tokenize sentences\n", "    \"\"\"\n", "    text = nltk.sent_tokenize(text)\n", "    return text\n", "\n", "def sentence_cleaner(text):\n", "    \"\"\"\n", "    Function to lower case remove all websites, emails and non alphabetical characters\n", "    \"\"\"\n", "    new_text = []\n", "    for sentence in text:\n", "        sentence = sentence.lower()\n", "        sentence = re.sub(\"((\\S+)?(http(s)?)(\\S+))|((\\S+)?(www)(\\S+))|((\\S+)?(\\@)(\\S+)?)\", \" \", sentence)\n", "        sentence = re.sub(\"[^a-z ]\", \"\", sentence)\n", "        sentence = nltk.word_tokenize(sentence)\n", "        sentence = [word for word in sentence if len(word)>1] # exclude 1 letter words\n", "        new_text.append(sentence)\n", "        #new_text = new_text+sentence\n", "    return new_text\n", "def apply_all(text):\n", "    return sentence_cleaner(sent_tokenizer(text))"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "a25fa82d-eeb8-49be-a5cc-68bb4f0d7ad4", "collapsed": true, "_uuid": "06c75d9b72aab1da9efdb4f6052017bce0d4d158"}, "outputs": [], "source": ["t1 = time.time()\n", "newdf['sent_tokenized_desc'] = newdf['description'].apply(apply_all)\n", "t2 = time.time()\n", "print(\"time cost %.1f , records:%d\"%((t2-t1)/60, len(newdf)))"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "ae1793db-2e52-4f26-bd75-336e04f8add7", "collapsed": true, "_uuid": "905087bfe7fc17cf6310e8c03d3d12f5d04dae39"}, "outputs": [], "source": ["newdf['sent_tokenized_desc'][0]"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "7224f750-cd62-4ef8-acd5-0931d969f3bd", "collapsed": true, "_uuid": "a9d2ef5f384636b625ecb5342a05c8236cd0fc0e"}, "outputs": [], "source": ["# create a list of all words using list comprehension\n", "all_sentences = [word for item in list(newdf['sent_tokenized_desc']) for word in item]\n", "all_words = [word for sent in all_sentences for word in sent]"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "d1ed6bee-9a76-43b5-9e62-4df67299a357", "collapsed": true, "_uuid": "2f62f185ae0a4609ecf1836b8dbdf105d8fb6ee6"}, "outputs": [], "source": ["all_words[:10]"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "8d5ea572-931d-4266-96d1-886633cb3ce4", "collapsed": true, "_uuid": "e682ec3d59cc3ca449e490895a7e48980d5592dd"}, "outputs": [], "source": ["fdist = FreqDist(all_words)\n", "len(fdist) # number of unique words"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "11f246af-9eaf-41d6-a5e6-5e7d391f4589", "collapsed": true, "_uuid": "98377a39398b99f6117019bc5ab89e8a35c3b289"}, "outputs": [], "source": ["# choose k and visually inspect the bottom 10 words of the top k\n", "k = 10000\n", "top_k_words = fdist.most_common(k)\n", "top_k_words[-10:]"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "bad865fa-ebdf-43a1-a387-05437268a5be", "collapsed": true, "_uuid": "d52f1918ba1f160763a3e73991e8bcb98b3f1824"}, "outputs": [], "source": ["import multiprocessing"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "88e98d52-8e69-40df-85a9-d2ae066ede2f", "collapsed": true, "_uuid": "827dbb4733c12cd2b83b958a61db6544728c0ad6"}, "outputs": [], "source": ["num_features = 300 # number of dimensions\n", "# if any words appear less than min_word_count amount of times, disregard it\n", "# recall we saw that the bottom 10 of the top 30,000 words appear only 7 times in the corpus, so lets choose 10 here\n", "min_word_count = 5\n", "num_workers = multiprocessing.cpu_count()\n", "context_size = 7 # window size around target word to analyse\n", "downsampling = 1e-3 # downsample frequent words\n", "seed = 1 # seed for RNG"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "3fc5cb89-5b6e-4639-b2a0-fdfec4842386", "collapsed": true, "_uuid": "b0184415f584276ccc92b2663df50423947ec575"}, "outputs": [], "source": ["# setting up model with parameters above\n", "desc2vec = w2v.Word2Vec(\n", "    sg=1,\n", "    seed=seed,\n", "    workers=num_workers,\n", "    size=num_features,\n", "    min_count=min_word_count,\n", "    window=context_size,\n", "    sample=downsampling\n", ")\n"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "dc4b0ad1-7b13-4ffd-a2d7-341a7244c227", "collapsed": true, "_uuid": "1358d5e7a9daac344a67c3825c5d6bae4d35ab65"}, "outputs": [], "source": ["desc2vec.build_vocab(all_sentences)"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "a32e0a6d-fc2c-4529-b62f-0af8889abd39", "collapsed": true, "_uuid": "696783cc0b67ae42d2dd1b6401de08d3e97d0117"}, "outputs": [], "source": ["print(\"Word2Vec vocabulary length:\", len(desc2vec.wv.vocab))"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "121f7066-9b72-4483-8fcb-a01723b16554", "collapsed": true, "_uuid": "49755658d0d240335acd769304e85768f017f856"}, "outputs": [], "source": ["# train word2vec - this may take a minute...\n", "desc2vec.train(all_sentences, total_examples=desc2vec.corpus_count, epochs=desc2vec.iter)"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "36a87df4-0ab9-483d-944d-c27ce6f88485", "collapsed": true, "_uuid": "9d6d8e7ac3a722049c8aeaa33e1535d853eb4a26"}, "outputs": [], "source": ["# dense 2D matrix of word vectors\n", "all_word_vectors_matrix = desc2vec.wv.syn0"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "24d250cd-c383-4829-99f9-7611d4f4623d", "collapsed": true, "_uuid": "57eb10581e00e4619114b96dd67214e3c82ee859"}, "outputs": [], "source": ["all_word_vectors_matrix.shape"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "b11556a2-92b1-40cc-96b9-98ef3a01f28f", "collapsed": true, "_uuid": "75b3c65e489bbfabe010d4e9f513ab5c25321f7d"}, "outputs": [], "source": ["all_word_vectors_matrix[desc2vec.wv.vocab['broom'].index]"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "65ddf341-139d-42d6-bb52-d0eeab5f4b56", "collapsed": true, "_uuid": "70ac9d73663fbd07a89da12ec25f12300d757ce8"}, "outputs": [], "source": ["desc2vec.wv.vocab['broom'].v"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "b3272fda-fe28-43d9-8346-f5075d80f31f", "collapsed": true, "_uuid": "5a36dfa12614ba6c9b45a54eb58c77de6f407988"}, "outputs": [], "source": ["#concate sentences to description\n", "tokenized_desc = []\n", "for desc in list(newdf['sent_tokenized_desc']):\n", "    text = []\n", "    for sent in desc:\n", "        text = text+sent\n", "    tokenized_desc.append(text)"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "3fb8fc54-01fa-48dd-b341-f810e5d98f2c", "collapsed": true, "_uuid": "99a415703f679fa4c652aabb7b4abf0dedf1d90e"}, "outputs": [], "source": ["assert len(tokenized_desc)==len(newdf['sent_tokenized_desc'])"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "c857eaf1-8776-4385-860b-6d5f74f0a868", "collapsed": true, "_uuid": "7c0c885fe67b051150d5333de7512ddc1b10556f"}, "outputs": [], "source": ["#vectorize the description\n", "word_embedding_matrix = np.zeros((len(fdist), 300), dtype=np.float32)"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "e9f0447d-b766-4102-8f07-91f7b85a9189", "collapsed": true, "_uuid": "62fbbe5b887bf93f600972d40515dd61c8dfaa4c"}, "outputs": [], "source": ["vocab_to_int = {} \n", "\n", "value = 0\n", "for word, count in fdist.items():\n", "    vocab_to_int[word] = value\n", "    value += 1\n", "        \n", "# Dictionary to convert integers to words\n", "int_to_vocab = {}\n", "for word, value in vocab_to_int.items():\n", "    int_to_vocab[value] = word"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "45b4116f-851c-48c8-b14e-7036a18b155a", "collapsed": true, "_uuid": "223fceb824fabee4d67891d4af5a55309aa656d8"}, "outputs": [], "source": ["embedding_dim = 300\n", "nb_words = len(vocab_to_int)\n", "\n", "# Create matrix with default values of zero\n", "word_embedding_matrix = np.zeros((nb_words, embedding_dim), dtype=np.float32)\n", "for word, i in vocab_to_int.items():\n", "    if desc2vec.wv.vocab.get(word,0) != 0:\n", "        word_embedding_matrix[i] = all_word_vectors_matrix[desc2vec.wv.vocab[word].index]\n", "    else:\n", "        # If word not in CN, create a random embedding for it\n", "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n", "        word_embedding_matrix[i] = new_embedding\n", "\n", "# Check if value matches len(vocab_to_int)\n", "print(len(word_embedding_matrix))"], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "97079785-b82f-4de7-908e-95bd052e0b0c", "collapsed": true, "_uuid": "9ba0abde774aa9bc0f139068f7d8087660dcad22"}, "outputs": [], "source": [], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "9bff4e8b-378c-4692-b64d-c274f69189c4", "collapsed": true, "_uuid": "4553f5bb8219fffa6ecdea32f1a3af521dede7ad"}, "outputs": [], "source": [], "execution_count": null}], "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.3", "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}}