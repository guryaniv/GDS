{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55d434c3eea150e1e61feaf5dea351aeadc4356f"},"cell_type":"markdown","source":"# Introduction\n\nI build this Generator for the TGS Dataset, but i am having problem in adding augmentation in it. As the batch size is fixed so how can i augment the images and even the batch size of the return data should also return to the specified batch size.\n\n# Help me add Augmentation in it"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport keras\nfrom skimage.transform import resize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11f073fb40eb031987870b32f1799f65f2e86142"},"cell_type":"code","source":"class Generator(keras.utils.Sequence):\n    def __init__(self, folder, files, batch_size=32, image_size=101, augment=False, mode='train'):\n        self.folder = folder\n        self.x_files = files\n        self.batch_size = batch_size\n        self.image_size = image_size\n        self.augment = augment\n        self.mode = mode\n        self.on_epoch_end()\n\n    def __load__(self, filename):\n        if self.mode == 'train':\n            image_path = self.folder + '/images/' + filename\n            mask_path  = self.folder + '/masks/' + filename\n\n            # Reading the image\n            image = cv2.imread(image_path, 1)\n            mask  = cv2.imread(mask_path, 0)\n            mask = np.reshape(mask, (mask.shape[0], mask.shape[1], 1))\n\n            # Normalizing the image\n            image = image/255.0\n            mask  = mask/255.0\n\n            # Resizing the image\n            if image.shape[0] != self.image_size:\n                image = resize(image, (self.image_size, self.image_size, 3), mode='constant', preserve_range=True)\n                mask  = resize(mask, (self.image_size, self.image_size, 1), mode='constant', preserve_range=True)\n            return image, mask\n            \n        elif self.mode == 'test':\n            image_path = self.folder + '/images/' + filename\n            image = cv2.imread(image_path, 1)\n            image = image/255.0\n            if image.shape[0] != self.image_size:\n                image = resize(image, (self.image_size, self.image_size, 3), mode='constant', preserve_range=True)\n            return image\n\n\n    def __getitem__(self, index):\n        # Select batch\n        if (index+1)*self.batch_size > len(self.x_files):\n            self.batch_size = len(self.x_files) - index*self.batch_size\n        files_batch = self.x_files[index*self.batch_size:(index+1)*self.batch_size]\n\n        if self.mode == 'train':\n            # Loading images and masks\n            image = []\n            mask  = []\n\n            for filename in files_batch:\n                tmp_img, tmp_mask = self.__load__(filename)\n                image.append(tmp_img)\n                mask.append(tmp_mask)\n\n            image = np.array(image)\n            mask  = np.array(mask)\n            return image, mask\n\n        elif self.mode == 'test':\n            image = []\n            for i, filename in enumerate(files_batch):\n                tmp_img = self.__load__(filename)\n                image.append(tmp_img)\n\n            image = np.array(image)\n            return image\n\n    def on_epoch_end(self):\n        pass\n\n    def __len__(self):\n        return int(np.ceil(len(self.x_files) / float(self.batch_size)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73d5d3ee0b382911be24f6cdf9da5459671b6d2c"},"cell_type":"code","source":"# Training\nfolder = '../input/train/'\nx_folder = '../input/train/images/'\ny_folder = '../input/train/masks/'\n\nx_files = os.listdir(x_folder)\ny_files = os.listdir(y_folder)\n\nn_valid_samples = 800\n\ntrain_x_files = x_files[n_valid_samples:]\ntrain_y_files = y_files[n_valid_samples:]\ntrain_files = train_x_files\n\nvalid_x_files = x_files[:n_valid_samples]\nvalid_y_files = y_files[:n_valid_samples]\nvalid_files = valid_x_files\n\nprint(\"Training Mode\")\ngen = Generator(folder, train_files)\nx, y = gen.__getitem__(0)\nprint(x.shape, y.shape)\nx, y = gen.__getitem__(1)\nprint(x.shape, y.shape)\nx, y = gen.__getitem__(2)\nprint(x.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cb60f3ea504d46091dba7319f2a7142c7c21819"},"cell_type":"code","source":"#Testing\nfolder = '../input/test/'\nx_folder = '../input/test/images/'\ntest_x_files = os.listdir(x_folder)\ntest_files = test_x_files\n\nprint(\"Test Mode\")\ngen = Generator(folder, test_files, mode='test')\nx = gen.__getitem__(0)\nprint(x.shape)\nx = gen.__getitem__(1)\nprint(x.shape)\nx = gen.__getitem__(2)\nprint(x.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6903c12391bda7ce4af9c3d7de00aa369d9d4b5c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}