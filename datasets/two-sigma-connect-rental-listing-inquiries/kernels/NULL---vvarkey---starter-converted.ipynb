{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "metadata": {
        "_cell_guid": "5fd3562c-2f0c-97e7-9367-221eedcee26f",
        "_active": false,
        "collapsed": false
      },
      "source": null,
      "execution_count": null,
      "cell_type": "markdown",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "3a0339ae-6660-105f-2328-d7ed1ba5fa39",
        "_active": false,
        "collapsed": false
      },
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport scipy\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss\nfrom sklearn import model_selection, preprocessing, ensemble\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom scipy import sparse\nimport xgboost as xgb\n\nimport os\nimport sys\nimport operator",
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "bd3f1dda-3349-4b4a-a2c0-0806c13859e0",
        "_active": false,
        "collapsed": false
      },
      "source": "df=pd.read_json(\"../input/train.json\")",
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "11eaccca-8cfb-b981-d94e-741b0e8d2165",
        "_active": false,
        "collapsed": false
      },
      "source": "df['priceperbed']=(df['price']/df['bedrooms'].clip(lower=1))\ndf['created']=df['created'].astype(np.datetime64)\ndf['created_date']=np.array(df.created.values, dtype='datetime64[D]').astype(np.float32)\ndf['created_day']=np.array(df.created.values, dtype='datetime64[D]').astype(np.float32)%7\ndf['created_week']=np.array(df.created.values, dtype='datetime64[W]').astype(np.float32)\ndf['created_month']=np.array(df.created.values, dtype='datetime64[M]').astype(np.float32)\ndf['created_hour']=np.array(df.created.values, dtype='datetime64[h]').astype(np.float32)%24\ndf['desc_count']=df.description.apply(lambda x: len(x.split()))\ndf['features_count']=df.features.apply(lambda x: len(x))\ndf['photos_count']=df.photos.apply(lambda x: len(x))\n",
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "5e9c7281-ed9e-4c18-741e-8bcad36cc13e",
        "_active": false,
        "collapsed": false
      },
      "source": "categorical = [\"display_address\", \"building_id\", \"street_address\", \"manager_id\"]\nfor f in categorical:\n        if df[f].dtype=='object':\n            lbl = preprocessing.LabelEncoder()\n            lbl.fit(list(df[f].values) + list(df[f].values))\n            df[f] = lbl.transform(list(df[f].values))",
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "b1bfb737-1178-fb7a-a2c9-c3721bf17b4b",
        "_active": false,
        "collapsed": false
      },
      "source": "df['features'] = df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\nprint(df[\"features\"].head())\ntfidf = CountVectorizer(stop_words='english', max_features=200)\nfeatures_sparse = tfidf.fit_transform(df[\"features\"])",
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "e6e45daa-73fc-e217-313f-9157f3c68aa6",
        "_active": false,
        "collapsed": false
      },
      "source": "train_ix, test_ix = train_test_split(range(df.shape[0]), random_state=0)\ntrain_ix, val_ix = train_test_split(train_ix, random_state=0)",
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "58ad657a-895f-33b8-2849-4553f77b9799",
        "_active": false,
        "collapsed": false
      },
      "source": "temp = pd.concat([df.iloc[train_ix].manager_id,pd.get_dummies(df.iloc[train_ix].interest_level)], \n                 axis = 1).groupby('manager_id').mean()\ntemp.columns = ['high_frac','low_frac', 'medium_frac']\ntemp['count'] = df.iloc[train_ix].groupby('manager_id').count().iloc[:,1]\n\ntemp['manager_skill'] = temp['high_frac']*2 + temp['medium_frac']\nunranked_managers_ixes = temp['count']<8\nranked_managers_ixes = ~unranked_managers_ixes\nmean_values = temp.loc[ranked_managers_ixes, [\n    'high_frac','low_frac', 'medium_frac','manager_skill']].mean()\ntemp.loc[unranked_managers_ixes,[\n    'high_frac','low_frac', 'medium_frac','manager_skill']] = mean_values.values\n\ndf = df.merge(temp.reset_index(),how='left', on='manager_id')\nnew_manager_ixes = df['high_frac'].isnull()\ndf.loc[new_manager_ixes,['high_frac','low_frac', 'medium_frac','manager_skill'\n                            ]] = mean_values.values",
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "f0faa73a-e4ae-766d-2bb7-258b1cd2b3e8",
        "_active": false,
        "collapsed": false
      },
      "source": "cols=['price', 'bathrooms', 'bedrooms', 'latitude', 'longitude', 'created_hour', 'created_day',\n      'created_month', 'created_date', 'desc_count', 'photos_count', 'features_count', \n      'priceperbed', 'manager_id']+categorical",
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "e1ee2c55-172a-d026-9517-33e4a64762d7",
        "_active": false,
        "collapsed": false
      },
      "source": "X = sparse.hstack([df[cols], features_sparse]).tocsr()\n\ntarget_num_map = {'high':0, 'medium':1, 'low':2}\ny = np.array(df['interest_level'].apply(lambda x: target_num_map[x]))\nprint(X.shape, y.shape)",
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "0d8bb7d4-a3ea-94a4-c6d2-086f7a14b95f",
        "_active": false,
        "collapsed": false
      },
      "source": "xgtrain = xgb.DMatrix(data=X[train_ix], label=y[train_ix])\nxgval = xgb.DMatrix(data=X[val_ix], label=y[val_ix])",
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "1fa4bddd-cf6f-d5f2-5fdb-8b7312aadec4",
        "_active": false,
        "collapsed": false
      },
      "source": "params = {\n    #'eta':.15,\n    'eta':.15,\n    'max_depth':6,\n    'min_child_weight':3,\n    #'min_child_weight':1,\n    'colsample_bytree':.8,\n    'subsample':.8,\n    #'colsample_bytree':.7,\n    #'subsample':.7,\n    'seed':0,\n    'nthread':16,\n    'objective':'multi:softprob',\n    'eval_metric':'mlogloss',\n    'num_class':3,\n}\n\nclf = xgb.train(params, xgtrain, 189,#1000, \n                #evals=[(xgtrain, 'train'), (xgval, 'val')], \n                #early_stopping_rounds=15, \n                verbose_eval=25)",
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "e0faefda-68af-4957-7ff5-21528b0100a9",
        "_active": true,
        "collapsed": false
      },
      "source": "y_pred = clf.predict(xgtrain)\nscore=log_loss(y[train_ix], y_pred)\nprint(score)\ny_pred = clf.predict(xgval)\nscore=log_loss(y[val_ix], y_pred)\nprint(score)",
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    }
  ]
}