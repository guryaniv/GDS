{"cells":[{"metadata":{"_uuid":"28428303865108e8fb1093337671e55e00214ee3"},"cell_type":"markdown","source":"This kernel is using chainer.\nmy first kernel!\n<h2>Import Library</h2>\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#!/usr/bin/env python3\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# my DNN Approach (using chainer)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n#import cupy as xp\nimport scipy\nimport time\nimport pickle \nimport chainer\nimport chainer.functions as F\nimport chainer.initializers as I\nimport chainer.links as L\nimport chainer.optimizers as O\nfrom chainer import reporter\nfrom chainer import training\nfrom chainer.training import extensions\nfrom chainer import cuda, Function, gradient_check, report, training, utils, Variable\nfrom chainer import datasets, iterators, optimizers, serializers\nfrom chainer import Link, Chain, ChainList\nimport matplotlib.pyplot as plt\nimport csv\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7381b2880ee38090891f12a4c3e64921897b3992"},"cell_type":"markdown","source":"![](http://)<h2>Setting using CPU</h2>"},{"metadata":{"trusted":true,"_uuid":"38b9c54189fcad73ca085d1bfe0f845be99cbc68"},"cell_type":"code","source":"gpu = -1 # use GPU(set 0)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"1dc02020a652d184be27b8681d751e91b1378a5a"},"cell_type":"markdown","source":"<h2> Model Define </h2>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"#model define\nclass standar_model(Chain):\n    \"\"\"Definition of standar Model\"\"\" \n    def __init__(self, X_len,Y_len):\n        super(standar_model, self).__init__()\n\n        with self.init_scope():\n            self.L1 = L.Linear(X_len, X_len *4 )\n            self.L2 = L.Linear(X_len *4 , X_len)\n            self.L3 = L.Linear(X_len , Y_len) \n            self.bn = L.BatchNormalization(X_len *4)\n    def forward(self, x,ys):\n        if gpu >= 0:\n            x = xp.array(x, dtype=xp.float32)\n        else:\n            x = np.array(x, dtype=np.float32)\n        h1 =self.L1(x)\n        h1 =self.bn(h1)\n        h2 = self.L2(h1)\n        y = self.L3(h2)\n        loss = F.softmax_cross_entropy(y, ys) \n        acc = F.accuracy(y, ys)\n        report({'accuracy': acc.data}, self)\n        report({'loss': loss.data}, self)\n        return loss  \n    def predict(self, x):\n        with chainer.no_backprop_mode(), chainer.using_config('train', False):\n            if gpu >=0:\n                x = xp.array(x, dtype=xp.float32)\n            else:\n                x = np.array(x, dtype=np.float32)  \n            h1 =self.L1(x)\n            h1 =self.bn(h1)\n            h2 =self.L2(h1)\n            y = self.L3(h2)\n            return y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ad5cfd44ab5f849a9c2e6ef41925e634fbd92ce"},"cell_type":"markdown","source":"<h2>Load Data and learning.</h2>"},{"metadata":{"trusted":true,"_uuid":"93359837db8ce096c8b3cc7237f0d3d27d5f044b"},"cell_type":"code","source":"def create_train_data(proc_data):\n    train = pd.DataFrame(proc_data, columns=[\"var_\" + str(i) for i in range(200)]) \n    x = train.values.tolist() \n    y = np.round(proc_data['target'])\n    x_y= list(zip(x,y))\n    x_y2 = []\n    for _ in range(5):\n        for item in x_y:\n            x_y2.append(item)\n    x = [item[0] for item in x_y2]\n    y = [item[1] for item in x_y2]\n    return  x ,y\n\ndef create_visualize_data(x,y):\n    x_y = []\n    x_y_1 = list(zip(x,y))\n    x0 =[]\n    x1 =[]\n    for item in x_y_1[:200000]:\n        if item[1] == 0:\n                x0.append(item[0]) #Label =0 data\n        else:\n                x1.append(item[0]) #Label =1 data\n    return x0,x1\nif __name__ =='__main__':\n    print(\"start training\")\n    proc_data = pd.read_csv(r\"../input/train.csv\") \n    x,y = create_train_data(proc_data) \n    print(len(x))\n    model =standar_model(200,2)\n    model.compute_accuracy = True\n    dir1 = 'standar/'\n    project_name = 'standar'\n    if gpu != -1:\n        model.to_gpu(gpu)\n    optimizer = optimizers.Adam() \n    optimizer.setup(model)\n    # Setup optimizer\n    train, test = datasets.split_dataset_random(datasets.TupleDataset(x, y),int(len(x) * 0.90))\n    train_iter = iterators.SerialIterator(train, batch_size=2048, shuffle=True)\n    test_iter = iterators.SerialIterator(test, batch_size=2048, repeat=False, shuffle=True) \n    updater = training.StandardUpdater(train_iter, optimizer, device=gpu)\n    trainer = training.Trainer(updater, (30, 'epoch'), out=dir1 +\"result\")\n    trainer.extend(extensions.Evaluator(test_iter, model, device=gpu))\n    trainer.extend(extensions.LogReport(log_name= project_name + 'log.txt'))\n    trainer.extend(extensions.PrintReport( ['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy']))\n    trainer.extend(extensions.ProgressBar()) \n   \n\n    # trainer.extend(extensions.snapshot(filename=project_name + 'snapshot_epoch-{.updater.epoch}'))\n    # trainer.extend(extensions.snapshot_object(model.predictor, filename='model_epoch-{.updater.epoch}'))\n    trainer.run() #Start Learning\n\n    model.to_cpu()\n    serializers.save_npz(dir1 +project_name + '.model', model) #Save Model\n    serializers.save_npz(dir1 +project_name + '.state', optimizer) #Save Optimizer\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a26eacbe10f24430ba7f72db59fe430c2281ed65"},"cell_type":"markdown","source":"<h2> Check distribution of training data.</h2>\nTry predict training data and see what kind of distribution it is.\n"},{"metadata":{"trusted":true,"_uuid":"5b10a9dcd21ad467285bd9a274123a9d5c970143"},"cell_type":"code","source":"    result1 = []\n    x0,x1 = create_visualize_data(x,y)\n    for i,item in enumerate(x0):\n\n        item = [item,item]\n        pred1 = model.predict(item).data[0]\n        result1.append(pred1) \n    for i,item in enumerate(x1): \n        item = [item,item] \n        pred2 = model.predict(item).data[0]\n        result1.append(pred2)\n    plt.title('distribution of training data')\n    plt.scatter([item[0] for item in result1[:len(x0)]],[item[1] for item in result1[:len(x0)]],c='red',Label=\"Label = 0\",alpha=0.7) #Red color is  Label 0\n    plt.scatter([item[0] for item in result1[len(x0):]],[item[1] for item in result1[len(x0):]],c='blue',Label=\"Label = 1\",alpha=0.7) #Blue color is Label 1\n    plt.show() #Show plot\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4da72256fa0a8fe3d846b68a9a233612ed66486"},"cell_type":"markdown","source":"<h2>make submission</h2>"},{"metadata":{"trusted":true,"_uuid":"3aa983df5cf2d6396362fc5ecd3015b9f0fdf022"},"cell_type":"code","source":"    print(\"predict test Data.\")\n    test_data = pd.read_csv(r\"../input/test.csv\") \n    x = []\n    y = [] \n    id1 = test_data['ID_code'].values.tolist()\n    test_x = pd.DataFrame(test_data, columns=[\"var_\" + str(i) for i in range(200)])\n    test_x = test_x.values.tolist()\n    \n\n    pred = model.predict(test_x).data\n\n    res = F.softmax(np.array(pred)).data.tolist()\n    result = []\n    result.append([\"ID_code\",\"target\"])\n    for i,item in enumerate(res): \n        result.append([id1[i],np.round(item[1],3)])\n         \n    import csv\n\n    with open('sample_submission.csv', 'w') as f:\n        writer = csv.writer(f, lineterminator='\\n') \n        writer.writerows(result) \n    print(\"saved csv.\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}