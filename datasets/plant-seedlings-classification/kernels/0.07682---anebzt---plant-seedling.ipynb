{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"78529c0a4fa98ed12dd6c75a84702a263d7fe0f7"},"cell_type":"code","source":"CLASS = {\n    'Black-grass': 0,\n    'Charlock': 1,\n    'Cleavers': 2,\n    'Common Chickweed': 3,\n    'Common wheat': 4,\n    'Fat Hen': 5,\n    'Loose Silky-bent': 6,\n    'Maize': 7,\n    'Scentless Mayweed': 8,\n    'Shepherds Purse': 9,\n    'Small-flowered Cranesbill': 10,\n    'Sugar beet': 11\n}\n\ndim = 64","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3e4db17fd63e8878e588883a34a166e082bafe2"},"cell_type":"code","source":"sample_sub.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ce0ae7b7d2f1fe7f9e831718fac512aa68224cc1"},"cell_type":"code","source":"import imageio\nfrom skimage.transform import resize as imresize\nfrom tqdm import tqdm\n\n# fill train and test dict\ndef fill_dict(paths, some_dict):\n    text = ''\n    if 'train' in paths[0]:\n        text = 'Start fill train_dict'\n    elif 'test' in paths[0]:\n        text = 'Start fill test_dict'\n\n    for p in tqdm(paths, ascii=True, ncols=85, desc=text):\n        img = imageio.imread(p)\n        img = img_reshape(img)\n        some_dict['image'].append(img)\n        some_dict['label'].append(img_label(p))\n        if 'train' in paths[0]:\n            some_dict['class'].append(img_class(p))\n\n    return some_dict\n\n\n# Resize all image to 51x51 \ndef img_reshape(img):\n    img = imresize(img, (dim, dim, 3)) # already normalizes? /255?\n    return img\n\n# get image tag\ndef img_label(path):\n    return str(str(path.split('/')[-1]))\n\n# get plant class on image\ndef img_class(path):\n    return str(path.split('/')[-2])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cfa958158fddad52e29bfd29ea3eecadd8407f2","scrolled":true},"cell_type":"code","source":"file_ext = []\ntrain_path = []\ntest_path = []\n\nfor root, dirs, files in os.walk('../input'):\n    if dirs != []:\n        print('Root: ' + str(root))\n        print('Dirs: ' + str(dirs))\n    else:\n        for f in files:\n            ext = os.path.splitext(str(f))[1][1:]\n\n            if ext not in file_ext:\n                file_ext.append(ext)\n\n            if 'train' in root:\n                path = os.path.join(root, f)\n                train_path.append(path)\n                \n            elif 'test' in root:\n                path = os.path.join(root, f)\n                test_path.append(path)\ntrain_dict = {\n    'image': [],\n    'label': [],\n    'class': []\n}\ntest_dict = {\n    'image': [],\n    'label': []\n}\n\ntrain_dict = fill_dict(train_path, train_dict)\ntest_dict = fill_dict(test_path, test_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f33f04b29e7b5512f8944f47fba36e5af1dc8e9f"},"cell_type":"code","source":"train_dict['image'][:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd4270e39c166b90a82d6b79b3c1cf91b13e53c1"},"cell_type":"code","source":"file_ext","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7272cc52c1f6763229a443d9f17156fbf62cf6f"},"cell_type":"code","source":"train_path[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92e2f12f8be4fc698322ba801304a56ec0c91d9f"},"cell_type":"code","source":"from keras.utils import to_categorical\n\nxtrain = np.array(train_dict['image'])\n_ytrain = np.array([CLASS[l] for l in train_dict['class']])\nytrain = to_categorical(np.array([CLASS[l] for l in train_dict['class']]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f0903292ba0fd37c19be9eb5649fb842fcd6ca7"},"cell_type":"code","source":"import seaborn as sns\nsns.set(style='white', context='notebook', palette='deep')\n\n# plot how many images there are in each class\nsns.countplot(_ytrain)\n\nprint(_ytrain.shape)\nprint(type(_ytrain))\n__ytrain = pd.Series(_ytrain)\n\n# array with each class and its number of images\nvals_class = __ytrain.value_counts()\nprint(vals_class)\n\n# mean and std\ncls_mean = np.mean(vals_class)\ncls_std = np.std(vals_class,ddof=1)\n\nprint(\"The mean amount of elements per class is\", cls_mean)\nprint(\"The standard deviation in the element per class distribution is\", cls_std)\n\n# 68% - 95% - 99% rule, the 68% of the data should be cls_std away from the mean and so on\n# https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule\nif cls_std > cls_mean * (0.6827 / 2):\n    print(\"The standard deviation is high\")\n    \n# if the data is skewed then we won't be able to use accurace as its results will be misleading and we may use F-beta score instead.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"897de9c57e7be06d06e1f3b941e049cdef061410"},"cell_type":"markdown","source":"quite a big balance mismatch, classes 4, 7, 9 have ~200 elements and classes 3, 6 have ~600"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5f265f0515c65c58047bd6cd4ddf364f649cb271"},"cell_type":"code","source":"xtest = np.array(test_dict['image'])\nlabel = test_dict['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da8717eed348e2af2a91a06db8cbd8f952e93709"},"cell_type":"code","source":"xtrain[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7eecfc70fd816d4febd774189e045f44ee7fbb1e"},"cell_type":"code","source":"xtrain.shape # 4750, 64, 64, 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f00a8688e9f0f949c69a75194d8fb0c80de70f6c"},"cell_type":"code","source":"xtrain[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b074c9b8709ababd9716b4ac56f12590c29fda51"},"cell_type":"code","source":"ytrain.shape # (4750, 12)\nnclasses = 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f12a4ce11ece4f2bd58de8443c4bf9550013a79a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdb62a21ba51e8036e26f525ea1926834d16b0c8"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# fix random seed for reproducibility\nseed = 42\nnp.random.seed(seed)\n\n# percentage of xtrain which will be xval\nsplit_pct = 0.05\n\n# Split the train and the validation set\nxtrain, xval, ytrain, yval = train_test_split(xtrain,\n                                              ytrain, \n                                              test_size=split_pct,\n                                              random_state=seed,\n                                              stratify=ytrain\n                                             )\n\nprint(xtrain.shape)\nprint(xval.shape)\nprint(ytrain.shape)\nprint(yval.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb576e6c759737a8c6f3b6ea564f7ea32d655e9c"},"cell_type":"markdown","source":"# CNN"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1f896554343b01e77f5de8e45a0d7d3ad8f97c58"},"cell_type":"code","source":"from keras import backend as K\n\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPool2D, AvgPool2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00bbf8b2b508650f1f835dda0c94ab8300a86676"},"cell_type":"code","source":"model = Sequential()\n\nksize = 5\n\nmodel.add(Conv2D(filters=32, kernel_size=(ksize,ksize), padding='same', activation='relu', input_shape=(dim,dim,3)))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(ksize,ksize), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(ksize,ksize), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(nclasses, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd0b61f0d65a539d9fe75216f6455db2cc9d16b9"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"61f656992e22dad374cb25b7f356ea867101485a"},"cell_type":"code","source":"# Compile the model\nopt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nmodel.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"983f1e1d9e2563e43288a323f33debe3d55be9a0"},"cell_type":"markdown","source":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"35c4d1ee3b6aae44b6704195365ed840141cb140"},"cell_type":"code","source":"# With data augmentation to prevent overfitting\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range=0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images\n\ndatagen.fit(xtrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e12913c4352e3f22a14f5b0466e3fe4f948eda25"},"cell_type":"code","source":"epochs = 35\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c48488f1a8d3f4080f80edd41b18ae82c3725f2c"},"cell_type":"code","source":"# Fit the model\nhistory = model.fit_generator(datagen.flow(xtrain,ytrain, batch_size=batch_size),\n                              epochs=epochs, validation_data=(xval,yval),\n                              verbose=1, steps_per_epoch=xtrain.shape[0]//batch_size, \n                              callbacks=[learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d528216512f40f553bd23675efcebb1c2315c0d9"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\n# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes=ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64b2fb25bf97106308a4b8c61cca3129da99dd7f"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport itertools\n\n# Confusion matrix\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nypred = model.predict(xval)\n# Convert predictions classes from one hot vectors to labels: [0 0 1 0 0 ...] --> 2\nypred_classes = np.argmax(ypred,axis=1)\n# Convert validation observations from one hot vectors to labels\nytrue = np.argmax(yval,axis=1)\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(ytrue, ypred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes=range(nclasses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6629fba972c856c831881eba3761084f51d357a9"},"cell_type":"code","source":"INV_CLASS = {\n    0: 'Black-grass',\n    1: 'Charlock',\n    2: 'Cleavers',\n    3: 'Common Chickweed',\n    4: 'Common wheat',\n    5: 'Fat Hen',\n    6: 'Loose Silky-bent',\n    7: 'Maize',\n    8: 'Scentless Mayweed',\n    9: 'Shepherds Purse',\n    10: 'Small-flowered Cranesbill',\n    11: 'Sugar beet'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8ec6673ee782a8d1bd8d1cc6303eb52bff2aa0d"},"cell_type":"code","source":"predictions = model.predict_classes(xtest, verbose=1)\nsub = pd.DataFrame({\"file\": label,\n                    \"species\": [INV_CLASS[p] for p in predictions]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c3c6734fa31c56956da7cccdd65a82cc78307b7"},"cell_type":"code","source":"sub.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"30088df6dbd8cf3d850b6260fa4f3d6a6859425f"},"cell_type":"code","source":"sub.to_csv(\"plant0708.csv\", index=False, header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1d3cbcefcd79376e952285504f84db8f0fd26297"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}