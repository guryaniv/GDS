{"nbformat_minor": 0, "nbformat": 4, "cells": [{"execution_count": null, "source": "Updates:\n\nThe stacking model:\nhttps://www.kaggle.com/schoolpal/nn-stacking-magic-no-magic-30409-private-31063\n\nhttps://www.kaggle.com/schoolpal/modifications-to-reynaldo-s-script/notebook\nI just added two XGB models, they were used together with in this one and one more DNN model in the stacking\n\n--------------------------------------------------------\n\nThis is a simple LightGBM script. It got two magic number, one took from Andy's script (proposed by Louis?). The second one actually down scale only the \"old\" investment properties, as the new ones are supported by the mortgage subsidy program? The LB score is at 0.3094. \n\n\nOne nice thing is that the classical BoxCox transformation can further improve the performance to 0.3093. It can also be verified by local skewness.  I wonder why no one bring this up in the kernel/forum.\n\nThis script (log version) serves as one of the basis model for the later stacking.", "cell_type": "markdown", "metadata": {"_execution_state": "idle", "collapsed": false, "_uuid": "dbdc01082aaef63472f3400e3d05c0124b5211ef", "_cell_guid": "a66cbc10-68f5-4de6-bc83-544ca09dd753"}, "outputs": []}, {"execution_count": null, "source": "from sklearn.model_selection import train_test_split,KFold,TimeSeriesSplit\nfrom sklearn import model_selection, preprocessing\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn import model_selection, preprocessing\nimport pdb\n\ndef process(train,test):\n    RS=1\n    np.random.seed(RS)\n    ROUNDS = 1500 # 1300,1400 all works fine\n    params = {\n        'objective': 'regression',\n            'metric': 'rmse',\n            'boosting': 'gbdt',\n            'learning_rate': 0.01 , #small learn rate, large number of iterations\n            'verbose': 0,\n            'num_leaves': 2 ** 5,\n            'bagging_fraction': 0.95,\n            'bagging_freq': 1,\n            'bagging_seed': RS,\n            'feature_fraction': 0.7,\n            'feature_fraction_seed': RS,\n            'max_bin': 100,\n            'max_depth': 7,\n            'num_rounds': ROUNDS,\n        }\n    #Remove the bad prices as suggested by Radar\n    train=train[(train.price_doc>1e6) & (train.price_doc!=2e6) & (train.price_doc!=3e6)]\n    train.loc[(train.product_type=='Investment') & (train.build_year<2000),'price_doc']*=0.9 \n    train.loc[train.product_type!='Investment','price_doc']*=0.969 #Louis/Andy's magic number\n    test = pd.read_csv('../input/test.csv',parse_dates=['timestamp'])\n\n  \n    id_test = test.id\n    times=pd.concat([train.timestamp,test.timestamp])\n    num_train=train.shape[0]\n    y_train = train[\"price_doc\"]\n    train.drop(['price_doc'],inplace=True,axis=1)\n    da=pd.concat([train,test])\n    da['na_count']=da.isnull().sum(axis=1)\n    df_cat=None\n    to_remove=[]\n    for c in da.columns:\n        if da[c].dtype=='object':\n            oh=pd.get_dummies(da[c],prefix=c)\n            if df_cat is None:\n                df_cat=oh\n            else:\n                df_cat=pd.concat([df_cat,oh],axis=1)\n            to_remove.append(c)\n    da.drop(to_remove,inplace=True,axis=1)\n\n    #Remove rare features,prevent overfitting\n    to_remove=[]\n    if df_cat is not None:\n        sums=df_cat.sum(axis=0)\n        to_remove=sums[sums<200].index.values\n        df_cat=df_cat.loc[:,df_cat.columns.difference(to_remove)]\n        da = pd.concat([da, df_cat], axis=1)\n    x_train=da[:num_train].drop(['timestamp','id'],axis=1)\n    x_test=da[num_train:].drop(['timestamp','id'],axis=1)\n    #Log transformation, boxcox works better.\n    y_train=np.log(y_train)\n    train_lgb=lgb.Dataset(x_train,y_train)\n    model=lgb.train(params,train_lgb,num_boost_round=ROUNDS)\n    predict=model.predict(x_test)\n    predict=np.exp(predict)\n    return predict,id_test\nif __name__=='__main__':\n    train = pd.read_csv('../input/train.csv',parse_dates=['timestamp'])\n    test = pd.read_csv('../input/test.csv',parse_dates=['timestamp'])\n    predict,id_test=process(train,test)\n    output=pd.DataFrame({'id':id_test,'price_doc':predict})\n    output.to_csv('lgb.csv',index=False)", "outputs": [], "metadata": {"trusted": false, "_uuid": "ec018d7eb8f7aaa8a8b2a1fd027a2dc67528106e", "_cell_guid": "190e9212-f25a-4ed6-b5eb-40818b6bfb42"}, "cell_type": "code"}], "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}}