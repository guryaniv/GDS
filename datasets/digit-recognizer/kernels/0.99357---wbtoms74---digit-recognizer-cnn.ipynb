{"cells":[{"metadata":{"_uuid":"ff2eedfeb716b4de07847349689228cfb80618c5"},"cell_type":"markdown","source":"# Introduction\nIn the following kernel, I will use CNN with Keras to address the problem of the digital recognizer."},{"metadata":{"_uuid":"fec90ac03386107958a223b9aca136bf301bc022"},"cell_type":"markdown","source":"# Import Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d97c40df1298c266dec8743efa231d8d973f3d3"},"cell_type":"markdown","source":"Load the training data into a data frame object and displays some statistics about its content:"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv')\ndf_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"574d6fdd853bd1ae9383286e8b2d11064afdcd78"},"cell_type":"markdown","source":"# Check, Clean and Prepocess Data"},{"metadata":{"_uuid":"5ccb4caeddc07e905762e39a71115894008c858e"},"cell_type":"markdown","source":"Here with check if the training data contains any NULL or NaN values, possibly missing data:"},{"metadata":{"trusted":true,"_uuid":"2b9c9452d2464bb5281e2d8ec95a210281c9852b"},"cell_type":"code","source":"df_train.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35e2553fa8f08ae50c490e009a4ee18195db4653"},"cell_type":"markdown","source":"# Extract Data"},{"metadata":{"_uuid":"5025772de0048ac3c4c3fd4d5e323b9c975db0ca"},"cell_type":"markdown","source":"Now we are extracting the data into NumPy array. This is because Keras methods needs array but also because all the preprocessing will be faster with array compare to data frame (indexing slower with data frame compare to array due to extra features provided bw the data frame)."},{"metadata":{"trusted":true,"_uuid":"a52e9f7734a9a0176e4727939076af88aee8747a"},"cell_type":"code","source":"data = df_train.values[:,:] \nprint(data[:5]) # display the first 5 elements\nprint(data.shape) # display the dimension of the array","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64c4f0f8366e14fd94b12e68837cf111c7469ab3"},"cell_type":"markdown","source":"# Create Training and Test Sets\nHere I made the choice to split the original training data into two set, a training set and test test. This is because I did not implemented CNN tuning. In case of CNN tuning, the best practice is to split the original training data at minimum in three sets, training set, validation set and test set, or even more subset depending on the fine tuning approach.\n\nHere the choice has been doen to:\n1. increase the original training data with new picture resulting from geometric transformation of the original data\n2. to shuffle the data\n3. to split the data 80% training and 20% test\n\nThis is performed in the following three sections."},{"metadata":{"_uuid":"9902d40839ce4af62c231fbcb28142639c145061"},"cell_type":"markdown","source":"## Data Augmentation\nCreate additional new data based on current ones, that is increase the original training data with new picture resulting from geometric transformation of the original data. Geometric transformation will be:\n\n1. Rotation, clockwise and counter clockwise\n2. Shift, up, down, left and right  \n(inspired from the following kernel: \"[Introduction to CNN Keras](https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6)\" section 3.3\n\nNote: For picture processing with neural networks, it is known that increasing the data using geometric transformation has a positive effect. On the contrary, it is known also that increasing data with noisy data does not improve the resutls.\n"},{"metadata":{"_uuid":"8c1a65b27264ceb12f4bd54243a916b18247e96b"},"cell_type":"markdown","source":"The coding approach is the following:\n*  The original data set is NOT increased on the fly. Rather a separate data set with new data is created and merged to the orignal data at the very end when all the new data have been generated.\n* The new data are flushed to different CSV files, one for each geometric transformation. This is to limit the file size and also to be able to process each transformation in parallel if needed.\n* The flush is done once a certain number of new data have been generated, this number being not too large to prevent too much overhead due to array indexing and due to array stacking with numpy.vstack, but also not too small to limit the file access overhead. A good number, found with experience is 100.\n* The data processing is implemented into a single method doWork, so that if needed we can easily parallelize it.\n\nThis approach has been guided by the performance and especially with the indexing overhead in mind. Experience showed that increasing the original data set on the fly would take many hours, the following approach on the same HW takes few minutes.\n"},{"metadata":{"trusted":true,"_uuid":"21f2810eb1f05f5fd71bfb6dce08ed7aee34598e"},"cell_type":"code","source":"from scipy import ndimage\nfrom enum import IntEnum\n\nclass ProcessAction(IntEnum):\n    RotateClockwise = 0\n    RotateCounterClockwise = 1\n    ShiftUp=2\n    ShiftDown=3\n    ShiftLeft=4\n    ShiftRight=5\n\nfile_name_ext=['RotateClockwise', 'RotateCounterClockwise', 'ShiftUp', 'ShiftDown', 'ShiftLeft', 'ShiftRight']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"572f143d95ea66d1fac9cecd6f299f9ccd140df4"},"cell_type":"code","source":"# Delete existing files if any\nimport os\nfor i in ProcessAction:\n    file_name = 'train_'+ file_name_ext[int(i)] + '.csv'\n    if os.path.isfile(file_name):\n        os.remove(file_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b1bba497029c7993038b9b6bcc11eb67cd787d1"},"cell_type":"code","source":"# Data processing methode\ndef doWork(data, action):\n    flush_limit=100\n    display_limit=1000\n    max=data.shape[0]\n    flush_count=0\n    for i in range(0,max):\n        # Create additional image for each signal image from the initial data set.\n        img=data[i,1:] # features    \n        lbl=data[i,0] # labels\n    \n        img=img.reshape((28, 28))\n        \n        if action == ProcessAction.RotateClockwise:\n            new_img= ndimage.rotate(img,-10,reshape=False)            \n\n        elif action == ProcessAction.RotateCounterClockwise:    \n            new_img= ndimage.rotate(img,10,reshape=False)\n\n        elif action == ProcessAction.ShiftUp:    \n            new_img= ndimage.shift(img,(0,28*0.1))\n\n        elif action == ProcessAction.ShiftDown:    \n            new_img= ndimage.shift(img,(0,-28*0.1))\n\n        elif action == ProcessAction.ShiftLeft:    \n            new_img= ndimage.shift(img,(28*0.1,0))\n\n        elif action == ProcessAction.ShiftRight:    \n            new_img= ndimage.shift(img,(-28*0.1,0))\n            \n        else:\n            print(\"Unkknow action \", action)\n            return;\n    \n        new_img_data=np.append([lbl],new_img.reshape((1,784))).reshape((1,785))\n\n        if (i % flush_limit == 0 and i != 0) or i == (max-1):\n\n            if i == (max-1):\n                # add the very last conversion\n                data_local = np.vstack((data_local,new_img_data))\n           \n            #-----------------------------------------------------\n            # Save data, flush every flush_limit images\n            #-----------------------------------------------------\n                        \n            df_new_train = pd.DataFrame(data_local, columns=df_train.columns)\n        \n            file_name='train_'+ file_name_ext[int(action)] + '.csv'\n                \n            if flush_count == 0:\n                df_new_train.to_csv(file_name, sep=',', mode='a', index=False)\n            else:\n                df_new_train.to_csv(file_name, sep=',', mode='a', index=False, header=False)\n\n            flush_count = flush_count+1\n\n\n        if i % flush_limit == 0:\n            data_local = new_img_data\n        else:\n            data_local = np.vstack((data_local,new_img_data))\n       \n        if i % display_limit == 0:\n            print(\"Iteration (\",action,\"): \",i,\"/\",max)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"338ed7d7a025df72d68a7a14da3a772012c1eda5"},"cell_type":"code","source":"# Perform the data processing for the different actions\nimport time\nstart = time.time()\ndoWork(data,ProcessAction.RotateClockwise)\ndoWork(data,ProcessAction.RotateCounterClockwise)\ndoWork(data,ProcessAction.ShiftUp)\ndoWork(data,ProcessAction.ShiftDown)\ndoWork(data,ProcessAction.ShiftLeft)\ndoWork(data,ProcessAction.ShiftRight)\nend = time.time()\nprint(\"Process time (s): \", end - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fdb4738be9fdc6198eea645c81b2569c567b50e"},"cell_type":"code","source":"# Merge the new data to the original data\nimport time\nstart = time.time()\nfor i in ProcessAction:\n    file_name = 'train_'+ file_name_ext[int(i)] + '.csv'\n    print(\"Add file to data:\", file_name)\n    df_tmp = pd.read_csv(file_name)\n    df_tmp.describe()\n    data_tmp = df_tmp.values[:,:] \n    print(data_tmp.shape)\n    data = np.vstack((data,data_tmp))\nprint(\"Final data set size: \",data.shape)\nend = time.time()\nprint(\"Process time (s): \", end - start)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b38e91220f0d6a6185753e797a26fb732b0f5c0c"},"cell_type":"markdown","source":"## Shuffle the data"},{"metadata":{"trusted":true,"_uuid":"098a25dc36f67927e73f949d60f4ac0686220f49"},"cell_type":"code","source":"np.random.seed(6)\nnp.random.shuffle(data)\nprint(data[:5])\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9184df76d4dedd8c83e4e05080180b9eaa52679"},"cell_type":"markdown","source":"## Split Data\nSplit the data into three sets: training (80%) and test (20%):"},{"metadata":{"trusted":true,"_uuid":"dfe7dd1782fb27217d1681711f682155e57336ee"},"cell_type":"code","source":"X=data[:,1:] # features\ny=data[:,0] # labels\nprint(\"X size: \", X.shape)\nprint(\"y size: \", y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e520c07fa9d62e567e056dae19f41ac9e1712241"},"cell_type":"code","source":"X_train, X_test = np.split(X, [int(.8*X.shape[0])])\ny_train, y_test = np.split(y, [int(.8*y.shape[0])])\nprint(\"X training set size: \", X_train.shape)\nprint(\"X test set size: \", X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3c7f1cc99a5a2e6f148cb5015c51beb4817e42a"},"cell_type":"markdown","source":"# Display Data Samples"},{"metadata":{"trusted":true,"_uuid":"379885491bf3ba671374cec5ed17084bfc0abe6b"},"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom scipy import ndimage\n\nfig = plt.figure()\n\nfor idx in range(0,9):\n    ax = fig.add_subplot(3,3,idx+1)\n    img_data=X[idx,:].reshape((28, 28))\n    plt.imshow(img_data, cmap=\"gray\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37e00baf4b81a5f684f1cfd403f57ce9ffaabdef"},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"_uuid":"4160a6560493c81c76783d873ee92734d80c4bfc"},"cell_type":"markdown","source":"## Input Standardization\nInputs of traning set and test set are standardized by removing the mean and scaling to unit variance:"},{"metadata":{"trusted":true,"_uuid":"c1e358f4eb822928a93491c37f142491ffef8d2a"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\n# Fit only to the training data\nscaler.fit(X_train)\nStandardScaler(copy=True, with_mean=True, with_std=True)\n\n# Now apply the transformations to the data:\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"588a7585510c59111e26f82c1dd9cc1acf50f406"},"cell_type":"markdown","source":"## Input Formatting for 2D Process\nAt the moment the input features of a training example is a 1D array of 784 features, being the pixels on one channel (grayscale).  \nFirst we need to reshape the input features so that they have the format of 2D image of 28x28 pixel on one channel. This necessary for the 2D convolution layer:"},{"metadata":{"trusted":true,"_uuid":"dfa86be881bbf15d8a9e05acae3ea95eed1224bb"},"cell_type":"code","source":"X_train_reshaped = X_train.reshape(X_train.shape[0],28, 28,1).astype( 'float32' )\nprint('Size of the input traning set: ',X_train_reshaped.shape)\nX_test_reshaped = X_test.reshape(X_test.shape[0],28, 28,1).astype( 'float32' )\nprint('Size of the input test set: ',X_test_reshaped.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"898847a07576dd7936597a1e3e260e504507bc2d"},"cell_type":"markdown","source":"## Output Label Transformation\nThe output labels of the training set and the test set have to be converted from a single class value (from 0 to 9) into 10 binary class values:"},{"metadata":{"trusted":true,"_uuid":"96cab8481ad25910353b1a6764d49adc46297f4b"},"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\n\nclass MyLabelBinarizer(LabelBinarizer):\n    def transform(self, y):\n        Y = super().transform(y)\n        if self.y_type_ == 'binary':\n            return np.hstack((Y, 1-Y))\n        else:\n            return Y\n\n    def inverse_transform(self, Y, threshold=None):\n        if self.y_type_ == 'binary':\n            return super().inverse_transform(Y[:, 0], threshold)\n        else:\n            return super().inverse_transform(Y, threshold)\n        \n\nlb = MyLabelBinarizer()\nprint(y_train.shape)\nprint(y_train[:5])\ny_train_bin = lb.fit_transform(y_train)\ny_test_bin = lb.fit_transform(y_test)\nprint(y_train_bin[0:5,:])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f3608106d43fa47d23fd5d7d6179d26aa2e93c9"},"cell_type":"markdown","source":"# Build and Train Model"},{"metadata":{"_uuid":"95ca1e51537fe233fd63d0b164c30a5c1375dca2"},"cell_type":"markdown","source":"Now we define the CNN model:"},{"metadata":{"trusted":true,"_uuid":"2bafd8f886e79b29079a42832a89d324fbc6cff9"},"cell_type":"code","source":"# Importing libraries\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n\n# Initialising the CNN\nclassifier = Sequential()\n\n# Adding a first convolutional layer\nclassifier.add(Conv2D(32, (5, 5), input_shape = (28,28,1), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a second convolutional layer\nclassifier.add(Conv2D(32, (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Step 3 - Flattening\nclassifier.add(Flatten())\n\n# Step 4 - Full connection\nclassifier.add(Dense(units = 128, activation = 'relu'))\nclassifier.add(Dense(units = 10, activation = 'softmax')) #softmax for classification","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14bf0c2e33549f540f6bc13b3db6971434f7c086"},"cell_type":"markdown","source":"Compile the model:"},{"metadata":{"trusted":true,"_uuid":"3e50096919ee27c6378c19afcefb6eb42b86806a"},"cell_type":"code","source":"# Compiling the CNN\nfrom keras import optimizers\nclassifier.compile(optimizer = 'adam', \n                   loss = 'categorical_crossentropy', \n                   metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4480d0e2a58c69a95c418e777b2c64485f108bb"},"cell_type":"markdown","source":"Train the model using the traning set:"},{"metadata":{"trusted":true,"_uuid":"f103a4ecbe2067b13ccf52d8f7ee317c5484617f"},"cell_type":"code","source":"classifier.fit(X_train_reshaped, y_train_bin,\n          epochs=70,\n          batch_size= 160)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb6c260fbf4fdd6a3ee0aecc202a3a793e375f0c"},"cell_type":"markdown","source":"# Predictions and Evaluation"},{"metadata":{"_uuid":"579747e9013bbf8a09996214353087ad96d01d55"},"cell_type":"markdown","source":"Evaluate the model on the test set:"},{"metadata":{"trusted":true,"_uuid":"e36bce8058aa9a137b05192ac7fae8816a127035"},"cell_type":"code","source":"score = classifier.evaluate(X_test_reshaped, y_test_bin, batch_size=128)\nprint('Score: ',score)\nprint('Metrics: ',classifier.metrics_names)\nclassifier.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a837f1fa7d57eadcfcf6b2ff02cb8fd58a129342"},"cell_type":"markdown","source":"Compute predictions for the test set:"},{"metadata":{"trusted":true,"_uuid":"19bf506325419f95159b7625286209dc2bb90085"},"cell_type":"code","source":"pred_test = classifier.predict(X_test_reshaped)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"478a9e6a9c03bde7434eedecd1df35f01c4cd403"},"cell_type":"markdown","source":"Transforme the 10 binary class prediction back to a single multi class value in order to be able to compute confusion matrix:"},{"metadata":{"trusted":true,"_uuid":"aa61fe0cf0959667585d15e3750c4b566000480b"},"cell_type":"code","source":"print(lb.classes_)\nprint(lb.y_type_)\npred_test = lb.inverse_transform(pred_test)\nprint(pred_test[:5])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1524969f59c0c93ea49ee225cbd50f2cd3c318a2"},"cell_type":"markdown","source":"Compute additional model prediction results:"},{"metadata":{"trusted":true,"_uuid":"b3e9d2178d8ccc1d30021a9125d439406198b8e5"},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\nprint(confusion_matrix(y_test,pred_test))\nprint(classification_report(y_test,pred_test))\nprint('>>>>>> Accuracy score: ',accuracy_score(y_test,pred_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a9cc74b92b4ccddbd79ae1f52c87dd37640744b"},"cell_type":"code","source":"print(pred_test[:5])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1634d00598a91c184da1bf00e347c8050d1aa527"},"cell_type":"markdown","source":"# Evaluate"},{"metadata":{"trusted":true,"_uuid":"4ede390cee3d725a6f5f39f10001e6a7babd588d"},"cell_type":"code","source":"def build_classifier(optimizer='adam'):\n    classifier = Sequential()\n    classifier.add(Conv2D(32, (3, 3), input_shape = (28,28,1), activation = 'relu'))\n    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n    classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n    classifier.add(Flatten())\n    classifier.add(Dense(units = 128, activation = 'relu'))\n    classifier.add(Dense(units = 128, activation = 'relu'))\n    classifier.add(Dense(units = 128, activation = 'relu'))\n    classifier.add(Dense(units = 10, activation = 'softmax'))\n    classifier.compile(optimizer = optimizer, \n                   loss = 'categorical_crossentropy', \n                   metrics = ['accuracy'])\n    return classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df7bf2de27cd63a9e2cfbe865478b64269deecea"},"cell_type":"code","source":"# Not used at the moment\nif 0:\n    # Evaluate\n    from keras.wrappers.scikit_learn import KerasClassifier\n    from sklearn.model_selection import cross_val_score\n    classifier = KerasClassifier(build_fn = build_classifier, batch_size = 160, epochs = 20)\n    accuracies = cross_val_score(estimator = classifier, X = X_train_reshaped, y = y_train_bin, cv = 10)\n    mean = accuracies.mean()\n    variance = accuracies.std()\n    print('Mean=',mean)\n    print('Variance=',variance)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93494266afb8f14be145b8dbddb501849457417c"},"cell_type":"markdown","source":"# Fine Tuning"},{"metadata":{"trusted":true,"_uuid":"e981429401929ef488ebe3752e549460c468cea5"},"cell_type":"code","source":"# Not used at the moment\nfrom sklearn.model_selection import GridSearchCV\nif 0:\n    classifier = KerasClassifier(build_fn = build_classifier)\n    parameters = {'batch_size': [150, 170],\n                  'epochs': [20, 30],\n                  'optimizer': ['adam', 'rmsprop']}\n    grid_search = GridSearchCV(estimator = classifier,\n                               param_grid = parameters,\n                               scoring = 'accuracy',\n                               cv = 10)\n    grid_search = grid_search.fit(X_train_reshaped, y_train_bin)\n    print('Best parameters: ',grid_search.best_params_)\n    print('Best score: ',grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d186d084e084614d7d9793b2e447343bd00a39d4"},"cell_type":"markdown","source":"# Create Submission on Challenge Test Set"},{"metadata":{"_uuid":"405f94480a35f860cd183b7124af5de37983767e"},"cell_type":"markdown","source":"## Import Data"},{"metadata":{"trusted":true,"_uuid":"e353d5ea539a3f8dc370efadb3e68304eebb306b"},"cell_type":"code","source":"df_test = pd.read_csv('../input/test.csv')\ndf_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72a3cfdaf34e3d3a44799ea3f58da9a00f939fc0"},"cell_type":"markdown","source":"## Check, Clean and Prepocess Data"},{"metadata":{"trusted":true,"_uuid":"647a1714b243aa7d7baa0eae0a49051cb47b2554"},"cell_type":"code","source":"df_test.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"473a0fc011eb43cedfa18c30659429f5e6c19811"},"cell_type":"markdown","source":"## Extract Data"},{"metadata":{"trusted":true,"_uuid":"fc8b2283169d57c3605da75e068413492a2cc0fe"},"cell_type":"code","source":"X_submission = df_test.values[:,:] \nprint(X_submission[:5]) # display the first 5 elements\nprint(X_submission.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff3b8a1c980f7735c842ab13430c452d9af71891"},"cell_type":"markdown","source":"## Display Data Samples"},{"metadata":{"trusted":true,"_uuid":"348af948117130c3367faab457babefb434c55b3"},"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pyplot as plt\n\nfig = plt.figure()\n\nfor idx in range(0,9):\n    ax = fig.add_subplot(3,3,idx+1)\n    img_data=X_submission[idx,:].reshape((28, 28))\n    plt.imshow(img_data, cmap=\"gray\")\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73056d1196d1b21e96da99bf3111c521f53750cc"},"cell_type":"markdown","source":"## Input Normalization"},{"metadata":{"trusted":true,"_uuid":"e8d24f3fd1ed6570bbdd952047887f6b0c10fbe6"},"cell_type":"code","source":"X_submission = scaler.transform(X_submission)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f54f418405b81df2ba5fcee10175b8140872ee7"},"cell_type":"markdown","source":"## Input Formatting for 2D Process"},{"metadata":{"trusted":true,"_uuid":"a6bc4615aad4e6040f283387701a929973c0f051"},"cell_type":"code","source":"X_submission_reshaped = X_submission.reshape(X_submission.shape[0],28, 28,1).astype( 'float32' )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac624713d3002fa128911fe80c73c890cf604718"},"cell_type":"markdown","source":"## Compute Predictions"},{"metadata":{"trusted":true,"_uuid":"d48d46aa36dd95f1822fb88dce9971e7028335e7"},"cell_type":"code","source":"pred_submission = classifier.predict(X_submission_reshaped)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db46b1af9114959df675d4721f23b0659279a4b3"},"cell_type":"markdown","source":"## Transforme 10 binary class prediction back to a single multi class value"},{"metadata":{"trusted":true,"_uuid":"139166e861ea741a79289ed498bbc24c92d88abb"},"cell_type":"code","source":"pred_submission = lb.inverse_transform(pred_submission)\nprint(pred_submission[:5])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80e590ebee33ff880f61159da3354962c2166796"},"cell_type":"markdown","source":"1. ## Create Submission Data Set"},{"metadata":{"trusted":true,"_uuid":"a21796f09976a7e66ef0acd39664fe336632aedd"},"cell_type":"code","source":"idx=np.arange(1,X_submission.shape[0]+1)\nsubmussion = np.column_stack((idx , pred_submission))\nprint(submussion[:5,:]) # display the first 5 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef1decffee2e984c47e404a3ced17d7499fdd6f5"},"cell_type":"code","source":"columns = ['ImageId', 'Label']\ndf_submission = pd.DataFrame(submussion, columns=columns)\nprint(df_submission.head(5)) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d4119594bda213d830990236b4d1085a35721ea"},"cell_type":"markdown","source":"## Write CSV Submission File"},{"metadata":{"trusted":true,"_uuid":"ff7837d3f1d104a063924417d2ffe68fd7fa1a94"},"cell_type":"code","source":"df_submission.to_csv('Digit Recognizer Submission 3.csv', sep=',' ,index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7df94fe4e7de415ad3583f11b09bb9a9d8eccab"},"cell_type":"markdown","source":"# Conclusion\nCNN performance is good but it could be better. Possible improvement ways:\n* Improve the data augmentation step with additional transformations\n* Implement a fine tuning strategy, on the hyperparameters or CNN architecture, but is the kernel the right place to execute it with the performance and time limitations?\n* Integrate in the CNN a Spatial Transformation Network (STN) module\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}