{"nbformat": 4, "cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "e81ee64d-e474-4662-9036-ce23df615199", "_uuid": "b6269c0e8f417f82daf093dda8fa0da6d2c57d86"}, "source": ["Sample of code below."]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "86b26423-563a-4fa1-a595-89e25ff93089", "_uuid": "1c728098629e1301643443b1341556a15c089b2b"}, "source": ["import pandas as pd\n", "\n", "main_file_path = '../input/train.csv'\n", "data = pd.read_csv(main_file_path)\n", "print('hello world')"], "execution_count": 29}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "ef3d495b-54a9-4151-80d1-bd6e0934b872", "_uuid": "502f939e50edaaaf35a2cf2f8da09f7d689f509d", "collapsed": true}, "source": ["import pandas as pd"], "execution_count": 30}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "1b703228-b2f0-49d5-98a0-18f0d943bdaf", "_uuid": "0ca7068b16ec31037654dd6b64774a4b89c68f19"}, "source": ["# Save filepath to variable for easier access\n", "melbourne_file_path = '../input/train.csv'\n", "# read the data and store in dataframe titled melbourne_data\n", "melbourne_data = pd.read_csv(melbourne_file_path)\n", "# Print a summary of the data\n", "print(melbourne_data.describe())"], "execution_count": 31}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "d9c0ed74-c344-474c-8c4a-8a5be3a03669", "_uuid": "b18886dd62006042d33cb8097a1e4d12db470d4e"}, "source": ["# See what is in this dataset\n", "print(melbourne_data.columns)"], "execution_count": 32}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "6b97229e-8542-493f-9c5a-72823fc1f9f3", "_uuid": "c930a832f73507fbe639d152f9d68d93ccdc5316"}, "source": ["## Subsetting data\n", "# Select a single column\n", "# Store prices separately\n", "melbourne_price_data = melbourne_data.SalePrice\n", "print(melbourne_price_data.head())"], "execution_count": 33}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "b3f8e31a-4acb-44db-85e3-add1131fca5a", "_uuid": "2612e961efdf70f783b115e30e1c960483cf9c4f"}, "source": ["# Selecting multiple columns\n", "columns_of_interest = ['YrSold', 'LotArea']\n", "two_columns_of_data = melbourne_data[columns_of_interest]\n", "two_columns_of_data.describe()"], "execution_count": 34}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "06550515-85fb-4446-9460-3e1a6e85431c", "_uuid": "717136c10e57fcd072613c1f33f8429195ac3a36"}, "source": ["## Build a model\n", "# step 1 - Choosing the prediction target\n", "# Specify the prediction target (column of data) and store it as y\n", "# We want to predict price of houses so use:\n", "y = melbourne_data.SalePrice\n", "\n", "# Choosing predictors\n", "# Select variables we want to use to predict price.\n", "# To start with we'll use:\n", "model_predictors = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n", "# Store predictors as x\n", "x = melbourne_data[model_predictors]\n", "\n", "# Build the model using scikit-learn library\n", "# Steps for building and using model:\n", "    # Define: What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.\n", "    # Fit: Capture patterns from provided data. This is the heart of modeling.\n", "    # Predict: Just what it sounds like\n", "    # Evaluate: Determine how accurate the model's predictions are.\n", "from sklearn.tree import DecisionTreeRegressor\n", "\n", "# Define model\n", "melbourne_model = DecisionTreeRegressor()\n", "# Fit model\n", "melbourne_model.fit(x,y)\n", "\n", "\n"], "execution_count": 35}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "5b3767d6-7e5b-4d4f-99e8-68a2eedd4a7a", "_uuid": "54514b4d30ed321894d0414fbe214cc6bafedd81", "scrolled": true}, "source": ["# Test how well the model works on the training data\n", "print(\"Making predictions for the following 5 houses:\")\n", "print(x.head())\n", "print(\"The predictions are\")\n", "print(melbourne_model.predict(x.head()))\n"], "execution_count": 36}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "d5948b06-c7d9-4b45-8166-c1453052a512", "_uuid": "85189fafd8a99e76aa353c399aec2bcb39fdd9b8"}, "source": ["# Model validation using mean absolute error\n", "# Check model MAE using data from the training set (bad idea)\n", "from sklearn.metrics import mean_absolute_error\n", "\n", "predicted_home_prices = melbourne_model.predict(x)\n", "mean_absolute_error(y, predicted_home_prices)"], "execution_count": 37}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "ef177c7a-fab8-47dc-a600-4db65e2c21c1", "_uuid": "c249cc177f3d86bce80ffacda0604a7ea9b93636"}, "source": ["# Need to test model accuracy using validation data\n", "# scikit-learn library has a function tran_test_split to break up the data into two pieces\n", "from sklearn.model_selection import train_test_split\n", "\n", "# The split is based on a random number generator. Supplying a numeric value to\n", "# the random_state argument guarantees we get the same split every time we\n", "# run this script.\n", "train_x, val_x, train_y, val_y = train_test_split(x, y, random_state = 0)\n", "# Define model\n", "melbourne_model = DecisionTreeRegressor()\n", "# Fit model\n", "melbourne_model.fit(train_x, train_y)\n", "\n", "# get predicted prices on validated data\n", "val_predictions = melbourne_model.predict(val_x)\n", "print(mean_absolute_error(val_y, val_predictions))"], "execution_count": 42}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "88ac3eaa-78d5-41de-9d2e-ab789a278805", "_uuid": "e2d2caae4a5493d0d699ce208d08d043d5fa6347", "collapsed": true}, "source": ["# Note the difference in error by using the flawed method (validating model data)\n", "# and the right method (splitting into train, validate datasets)"], "execution_count": 39}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "9e7aa067-dac2-4aa5-839b-5e27061ae201", "_uuid": "c57cf22600f86a08a145cea3a7573c52c8eb86ce", "collapsed": true}, "source": ["## Experimenting with different models\n", "# Avoid overfitting/underfitting the data using max_leaf_nodes\n", "\n", "from sklearn.metrics import mean_absolute_error\n", "from sklearn.tree import DecisionTreeRegressor\n", "\n", "def get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n", "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n", "    model.fit(predictors_train, targ_train)\n", "    preds_val = model.predict(predictors_val)\n", "    mae = mean_absolute_error(targ_val, preds_val)\n", "    return(mae)"], "execution_count": 44}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["# The data is loaded into train_x, val_x, train_y, val_y\n", "# We use a for-loop to compare accuracy of models built with different values for max_leaf_nodes\n", "# compare MAE with differing values of max_leaf_nodes\n", "for max_leaf_nodes in [5, 50, 500, 5000]:\n", "    my_mae = get_mae(max_leaf_nodes, train_x, val_x, train_y, val_y)\n", "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))\n"], "execution_count": 45}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["# Best model is with 50 leaf nodes (gives the lowest mean absolute error: 27825)"], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["# Decision trees are basic and have problems: too many leaves - overfitting, not enough leaves - underfitting\n", "# Random forest is more sophisticated decision tree method. Uses many trees and has better accuracy\n", "# Build a random forest based on the data:\n", "from sklearn.ensemble import RandomForestRegressor\n", "from sklearn.metrics import mean_absolute_error\n", "\n", "forest_model = RandomForestRegressor()\n", "forest_model.fit(train_x, train_y)\n", "melb_preds = forest_model.predict(val_x)\n", "print(mean_absolute_error(val_y, melb_preds))"], "execution_count": 46}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["# Note how much better random forest performed vs decision tree (24708 vs 27825)\n", "# There are parameters to make prediction more accurate but random forest works pretty well without tuning"], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["## Posting model to machine learning competition on kaggle\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn.ensemble import RandomForestRegressor\n", "\n", "# Read the data\n", "train = pd.read_csv('../input/train.csv')\n", "\n", "# Pull data into target (y) and predictors (X)\n", "train_y = train.SalePrice\n", "predictor_cols = ['1stFlrSF', '2ndFlrSF','LotArea','YearBuilt','TotRmsAbvGrd']\n", "\n", "# Create training predictors data\n", "train_X = train[predictor_cols]\n", "\n", "my_model = RandomForestRegressor()\n", "my_model.fit(train_X, train_y)"], "execution_count": 50}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["# Add test data\n", "test = pd.read_csv('../input/test.csv')\n", "# Treat the test data in the same way as the training data. In this case, pull same columns\n", "test_X = test[predictor_cols]\n", "# Use model to make predictions\n", "predicted_prices = my_model.predict(test_X)\n", "# Look at predicted prices to make sure they make sense\n", "print(predicted_prices)"], "execution_count": 51}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["# Prepare submission file\n", "my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\n", "# Can use any filename. Choose 'submission' for this\n", "my_submission.to_csv('submission.csv', index = False)"], "execution_count": 54}], "metadata": {"language_info": {"name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.6.4", "codemirror_mode": {"version": 3, "name": "ipython"}}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat_minor": 1}