{"nbformat": 4, "nbformat_minor": 1, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"version": "3.6.4", "codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python", "file_extension": ".py"}}, "cells": [{"source": ["<h1> Simple Tensorflow Prediction Pipeline </h1>\n", "The goal of this notebook is to serve as an example for a tensorflow model. I simplified many steps and ignored some other steps to create an understandable pipeline. This is also my first tensorflow model, so tips are welcome!\n", "\n", "<h3> A full pipeline would have the the following elements: </h3>\n", "1. Normalize colors of images -> Ignored for now. Could be an important performance booster in the future\n", "2. Resize images\n", "3. Prepare the X and Y matrices\n", "4. A. Define a tensorflow graph model for region proposal\n", "4. B. Define a tensorflow graph model for pixel segmentation\n", "4. C. Combine the output of models A and B\n", "5. Define the IOU metric. \n", "6. Run the model and evaluate the cost.\n", "\n", "<h3> The current version of this notebook covers te following elements </h3>\n", "1. Prepare X and Y matrices: 50 samples of  256x256x4 images, 40 for training, 10 for validation\n", "2. Define a tensorflow graph model (convolutional) to find the difference between nucleus (1) and background (0)\n", "3. Define an IOU metric\n", "4. Run the model and evaluate the cost\n", "\n", "But first: let's import the packages."], "metadata": {"_uuid": "7c62325d2814d60e4d4e4765ba08102bfb2e6832", "_cell_guid": "dd240ee9-8eb5-47c6-8a64-d9395c09eb6d"}, "cell_type": "markdown"}, {"source": ["\"\"\"IMPORT\"\"\"\n", "import numpy as np\n", "import pandas as pd\n", "import os\n", "from skimage.io import imread\n", "import matplotlib.pyplot as plt\n", "import gc\n", "import tensorflow as tf\n", "from PIL import Image\n", "from subprocess import check_output\n", "import time\n", "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "\"\"\"PREPARATION\"\"\"\n", "train_path = r\"../input/stage1_train/\"\n", "train_ids = os.listdir(train_path)\n", "subfolders = [\"images\",\"masks\"]\n", "train_list = []\n", "\n", "\n", "\"\"\"We want 50 256x256x4 images\"\"\"\n", "shape = 256, 256, 4\n", "m = 50"], "metadata": {"collapsed": true, "_uuid": "5bf1e2d215d974bb07eead9b6b675cbdee3c7b17", "_cell_guid": "43df8cce-9a48-4c2a-a80b-4d724131d663"}, "outputs": [], "cell_type": "code", "execution_count": null}, {"source": [" <h1> 1. Prepare X and Y matrices </h1>\n", " Constraints:\n", "* Only 256x256x4 pictures are used because we skip the resizing proces\n", "* We limit the amount of training examples to 50 to save processing time"], "metadata": {"_uuid": "487a5a66ec690aac6b540a8edbafa0c0c384e47d", "_cell_guid": "0aa00544-ebd9-49a7-9d08-a3968cbde3b3"}, "cell_type": "markdown"}, {"source": ["def get_XY(shape, m, train_path, train_ids):\n", "    \"\"\"\n", "    Description: \n", "        This function loops over the training ID's and masks to select m images and labels that match the \n", "        desired shape and return it. \n", "    Input: \n", "        - shape: dimensions of the picture (height x width x channels), a selection criterion\n", "        - m: number of samples, a selection criterion\n", "        - train_path: path of the train folder\n", "        - train_ids: list of training Ids.\n", "    Output: \n", "        - X: A stack of images. dimension is  (m x shape) where shape is (height x width x channels)\n", "        - Y: A stack of labels to predict. sum of all masks for that object\n", "    \"\"\"\n", "    i=0  # keep track of number of images retrieved\n", "    init_Y = False  # define whether Y is initialized\n", "    init_X = False  # define whether X is initialized\n", "    \n", "    #  Loop over the training id's.\n", "    for train_id in train_ids:\n", "        \n", "        # Load an image\n", "        x_path = train_path + train_id + \"/images/\" + train_id +  \".png\"\n", "        x = Image.open(x_path)\n", "        x = np.array(x)\n", "        \n", "        # Check if the size matches the expected size, else ignore \n", "        if shape != x.shape:\n", "            continue \n", "        \n", "        # Add an axis to stack the samples along. \n", "        x = np.expand_dims(x,0)\n", "        \n", "        # Stack the training examples\n", "        if not init_X:\n", "            X = x\n", "            init_X = True\n", "        else:\n", "            X = np.vstack([X,x])\n", "    \n", "        # Load a mask\n", "        y_path = train_path + train_id + \"/masks/\" \n", "        maskpaths = os.listdir(y_path)\n", "\n", "        # A single image id has multiple masks -> sum over the masks to create 1 label per image id.\n", "        init_y = False\n", "        for maskpath in maskpaths:\n", "            temppath = y_path + maskpath\n", "            if not init_y:\n", "                y = Image.open(temppath)\n", "                y = np.array(y)\n", "                init_y = True\n", "            else:\n", "                temp = Image.open(temppath)\n", "                temp = np.array(temp)\n", "                y = y + temp       \n", "\n", "        # Add an axis to stack the samples along.       \n", "        y = np.expand_dims(y,0)\n", "        print(y.shape)\n", "        if not init_Y:\n", "            Y = y\n", "            init_Y = True\n", "        else:\n", "            Y = np.vstack([Y,y])\n", "        i+=1\n", "        print(i)\n", "        if i >= m:\n", "            print(\"sampling limit reached.\")\n", "            Y = np.expand_dims(Y,3)\n", "            Y = Y/255\n", "            X = X/255\n", "            return X,Y"], "metadata": {"_kg_hide-output": true, "_uuid": "d4ad9713cb26069c2159f6d2096887cec65667e8", "collapsed": true, "_cell_guid": "3de3ad6a-4066-4521-ab82-cb2a536fdb5a"}, "outputs": [], "cell_type": "code", "execution_count": null}, {"source": ["X,Y = get_XY(shape, m, train_path, train_ids)"], "metadata": {"collapsed": true, "_uuid": "5992886d998134316e0c44ef538d0c8c127e5a9c", "_cell_guid": "0d1bd3fb-16b6-4912-b022-7a940743e6c0"}, "outputs": [], "cell_type": "code", "execution_count": null}, {"source": ["# check the shapes\n", "print(\"X.shape = \",X.shape)\n", "print(\"Y.shape = \",Y.shape)"], "metadata": {"collapsed": true, "_uuid": "9d81409caa85cc65cb365f7d140d8627acbba9fa", "_cell_guid": "59c4725c-bb6c-4534-9371-0a483f8983a9"}, "outputs": [], "cell_type": "code", "execution_count": null}, {"source": ["# check a sample \n", "plt.subplot(121)\n", "plt.imshow(X[0])\n", "plt.title(\"Image\")\n", "plt.subplot(122)\n", "plt.imshow(np.squeeze(Y[0]))\n", "plt.title(\"mask\")"], "metadata": {"collapsed": true, "_uuid": "3f2eb773c13ccfd72117b2c194ab7577d89771fb", "_cell_guid": "c24da1c3-41c3-430c-802e-d163b2581c94"}, "outputs": [], "cell_type": "code", "execution_count": null}, {"source": ["<h1> 2. Tensorflow graph model </h1>\n", "Here I'll build a convolutional neural network in tensorflow"], "metadata": {"_uuid": "af4e7ac748bbbc3e7a6555de6b480dcf45146650", "_cell_guid": "c2d36bb1-1bc7-4681-aa1e-bbc3d09b0ac2"}, "cell_type": "markdown"}, {"source": ["<h3> Placeholders </h3>"], "metadata": {"_uuid": "33816f224e6f4bd0c07b82a6826fcafd6a58cb00", "_cell_guid": "02a59406-32ea-4795-a3e2-2eab89fb32a6"}, "cell_type": "markdown"}, {"source": ["# Placeholders can be used to define the computations graph\n", "def get_placeholders(size):\n", "    Xtf = tf.placeholder(name=\"Xtf\",shape=[None,size[0],size[1],4],dtype=\"float\")\n", "    Ytf = tf.placeholder(name=\"Ytf\",shape=[None,size[0],size[1],1],dtype=\"float\")\n", "    return Xtf, Ytf"], "metadata": {"collapsed": true, "_uuid": "9db548400630e04c06ceb0101a1d27fdc6f21903", "_cell_guid": "66c4bdba-87e3-4747-aea5-f43f58a273f5"}, "outputs": [], "cell_type": "code", "execution_count": null}, {"source": ["<h3> The computation graph </h3>"], "metadata": {"_uuid": "8a5276771ac90becfed7be139f7ab8b95fc85b7b", "_cell_guid": "44953d85-3aaa-4daf-8d8c-8efa29829b34"}, "cell_type": "markdown"}, {"source": ["def go_forward(Xtf):\n", "    \n", "    # PARAMETERS\n", "    W1 = tf.get_variable(\"W1\",shape=[3,3,4,32],initializer=tf.contrib.layers.xavier_initializer(seed=0),dtype=\"float\")\n", "    W2 = tf.get_variable(\"W2\",shape=[3,3,32,64],initializer=tf.contrib.layers.xavier_initializer(seed=0),dtype=\"float\")\n", "    W3 = tf.get_variable(\"W3\",shape=[3,3,64,128],initializer=tf.contrib.layers.xavier_initializer(seed=0),dtype=\"float\")\n", "    W4 = tf.get_variable(\"W4\",shape=[3,3,128,1],initializer=tf.contrib.layers.xavier_initializer(seed=0),dtype=\"float\")\n", "\n", "    # LAYER 1\n", "    Z1 = tf.nn.conv2d(Xtf,W1,strides=[1,1,1,1],padding=\"SAME\")\n", "    A1 = tf.nn.relu(Z1)\n", "    \n", "    # LAYER 2\n", "    Z2 = tf.nn.conv2d(A1,W2,strides=[1,1,1,1],padding=\"SAME\")\n", "    A2 = tf.nn.relu(Z2)\n", "    \n", "    # LAYER 3\n", "    Z3 = tf.nn.conv2d(A2,W3,strides=[1,1,1,1],padding=\"SAME\")\n", "    A3 = tf.nn.relu(Z3)\n", "    \n", "    # LAYER 4\n", "    Z4 = tf.nn.conv2d(A3,W4,strides=[1,1,1,1],padding=\"SAME\")\n", "    A4 = tf.nn.sigmoid(Z4)\n", "    \n", "    return A4"], "metadata": {"collapsed": true, "_uuid": "7748ea0a62d435ff350f90c1a582a5d51c4bd8e5", "_cell_guid": "53845c22-2baf-45b7-b5b7-948df79a44e9"}, "outputs": [], "cell_type": "code", "execution_count": null}, {"source": ["<h1>3. The IOU metric</h1>"], "metadata": {"_uuid": "999d9fe1fdd130c3f3b88109ac07fa59de1c4b86", "_cell_guid": "2b3bca01-c4ca-459b-9914-1478832c0471"}, "cell_type": "markdown"}, {"source": ["def compute_cost(A4, Y):\n", "    print(\"A4 \",A4.shape)\n", "    Y_negatives = tf.subtract(1.,Y)\n", "    print(\"Y_neg \",Y_negatives)\n", "    tp = tf.reduce_sum(tf.reduce_sum(tf.multiply(A4,Y),1),1)  # True positives (i.e. the intersection)\n", "    print(\"true_pos \",tp)\n", "    fp = tf.reduce_sum(tf.reduce_sum(tf.multiply(A4,Y_negatives),1),1)  # False positives\n", "    fn = tf.reduce_sum(tf.reduce_sum(tf.multiply(tf.subtract(Y,A4),Y),1),1)  # False negatives\n", "    un_temp = tf.add(tp,fp)  # sum of true and false positvives\n", "    un = tf.add(un_temp,fn)  # The union\n", "    iou = tf.divide(tp,un)  # the intersection over union\n", "    cost = tf.subtract(1.,tf.reduce_mean(iou))  # the cost\n", "    return (cost, tp, fp, fn)"], "metadata": {"collapsed": true, "_uuid": "8d005b7776e1b8fb4fd4e6efcfb9df0fd89bb5ac", "_cell_guid": "d5e9534c-a386-4424-a990-32aa23beb7ac"}, "outputs": [], "cell_type": "code", "execution_count": null}, {"source": ["<h1>4. Running the model </h1>"], "metadata": {"_uuid": "204889af494d6d6c1ad0cba5db2eae91a31ecefe", "_cell_guid": "65ec9494-6bd8-415b-a954-15a54a5ed63f"}, "cell_type": "markdown"}, {"source": ["tf.reset_default_graph()\n", "best_score = 1.\n", "best_iter = 0\n", "start_time = time.time()\n", "max_duration = 900\n", "max_iterations = 80\n", "X_train = X[:-10]\n", "X_valid = X[-10:]\n", "Y_train = Y[:-10]\n", "Y_valid = Y[-10:]\n", "train_costs = [1] * max_iterations\n", "valid_costs = [1] * max_iterations\n", "with tf.Session() as sess:    \n", "    Xtf, Ytf = get_placeholders(shape)\n", "    A4 = go_forward(Xtf)\n", "    cost, tp, fp, fn = compute_cost(A4,Ytf)\n", "    optimizer = tf.train.AdamOptimizer(learning_rate=0.002).minimize(cost)\n", "    init = tf.global_variables_initializer()\n", "    sess.run(init)\n", "    for i in range(max_iterations):\n", "        pred, train_costs[i],tpo, fpo, fno = sess.run([optimizer,cost, tp, fp, fn],feed_dict={Xtf:X_train,Ytf:Y_train})\n", "        valid_costs[i] = sess.run(cost,feed_dict={Xtf:X_valid,Ytf:Y_valid})\n", "\n", "        print(\"\\n************************\")\n", "        print(\"iter:\",i)\n", "        print(\"training cost:\",train_costs[i])\n", "        print(\"valid cost:\",valid_costs[i])\n", "        print(\"************************\\n\")\n", "        \n", "        if train_costs[i] > best_score and best_iter <= i-10:\n", "            print(\"Converged\")\n", "            break\n", "        elif time.time() >= start_time + max_duration:\n", "            print(\"timed out\")\n", "            break\n", "        else:\n", "            best_score = train_costs[i]\n", "            best_iter = i\n", "    prediction, iou_pred = sess.run([A4,cost],{Xtf:X_valid,Ytf:Y_valid})\n", "    print(\"validation cost: \",iou_pred)\n", "#%%  CHECK OUTPUT"], "metadata": {"collapsed": true, "_uuid": "2011ba61119c505f1bdc0c40eca28d26c15e03e7", "_cell_guid": "e6c8786b-6124-4ffb-b211-bc0966f003f8"}, "outputs": [], "cell_type": "code", "execution_count": null}, {"source": ["<h3> The learning curve </h3>"], "metadata": {"_uuid": "dc6aa7dcd2cb206780683f887ce6952fea4adeed", "_cell_guid": "d6212c45-ab18-48a7-a6cb-ba6f5991d531"}, "cell_type": "markdown"}, {"source": ["plt.figure(figsize=(30,10))\n", "plt.plot(range(i),train_costs[:i],label=\"neg. training IOU\")\n", "plt.plot(range(i),valid_costs[:i],label=\"neg. validation IOU\",c='r')"], "metadata": {"collapsed": true, "_uuid": "4d16af5f6a83fc8bbc41442adf03f5b455288d2b", "_cell_guid": "140d47fb-fe24-4e35-a8c1-537bc29f8428"}, "outputs": [], "cell_type": "code", "execution_count": null}, {"source": [" <h3> Visualization </h3>"], "metadata": {"_uuid": "92b8bad6561aa4ee4dfc68642d88539a6a599de3", "_cell_guid": "81dae050-e0c2-4673-9c94-27d854c29fdb"}, "cell_type": "markdown"}, {"source": ["def show(out,Y,i=0):\n", "    fig = plt.figure(figsize=(10,15))\n", "        \n", "\n", "    ax_1 = fig.add_subplot(1,2,1)\n", "    ax_1.set_title(\"Predicted mask \" + str(i),fontsize=12)\n", "    ax_1.imshow(np.squeeze(out[i]),cmap=\"Greys\")\n", "    \n", "    ax_2 = fig.add_subplot(1,2,2)\n", "    ax_2.set_title(\"Actual mask \" + str(i),fontsize=12)\n", "    ax_2.imshow(np.squeeze(Y[i]),cmap=\"Greys\")\n", "\n", "    plt.show()\n", "\n", "for j in range(10):\n", "    show(prediction,Y_valid,i=j)"], "metadata": {"_uuid": "921193a16435459dc99298c592b3f03ec47a0ef3", "_kg_hide-input": true, "collapsed": true, "_cell_guid": "4de78ba5-9327-4f20-bcd6-741577257a18"}, "outputs": [], "cell_type": "code", "execution_count": null}]}