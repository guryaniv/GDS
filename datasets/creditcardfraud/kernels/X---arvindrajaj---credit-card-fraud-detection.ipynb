{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a2f95e51-eb96-c7e1-bba6-25620a75fd0c"
      },
      "source": [
        "**Credit card fraud detection**\n",
        "\n",
        "This notebook handles the skewed data and applies the dataset on multiple classifiers like the decision tree, random forest, logistic regression, SVM(both RBF and linear kernels),  k-Nearest Neighbors, Naive Bayes. We will pick the best model using cross-validation and pick the best values for the models using grid search. The model's accuracy is validated by K-fold cross validation and the confusion matrix is visualized.\n",
        "\n",
        "The handling of skewed data is taken from the below link\n",
        "https://www.kaggle.com/joparga3/in-depth-skewed-data-classif-93-recall-acc-now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c473ad0c-e62a-e9d4-04b0-eda2984bd7da"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "78a7fead-30c2-b922-db7e-30b4b769baef"
      },
      "outputs": [],
      "source": [
        "#importing the dataset\n",
        "dataset = pd.read_csv(\"../input/creditcard.csv\")\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b129e962-fb89-bfa5-1fb4-f0fdcd7a3c4c"
      },
      "outputs": [],
      "source": [
        "#Checking the target classes\n",
        "count_classes = pd.value_counts(dataset['Class'], sort = True).sort_index()\n",
        "count_classes.plot(kind = 'bar')\n",
        "plt.title(\"Fraud class histogram\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b53c96c1-6da7-3269-6aa0-b8b2cb739369"
      },
      "outputs": [],
      "source": [
        "#feature scaling is done on the values that have not been normalized \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "dataset['normAmount'] = StandardScaler().fit_transform(dataset['Amount'].reshape(-1, 1))\n",
        "#dropping copied and unneeded columns\n",
        "dataset = dataset.drop(['Time','Amount'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8301ed85-51aa-825c-b601-5ceea38ba694"
      },
      "outputs": [],
      "source": [
        "#assign x and y values\n",
        "x = np.array(dataset.iloc[:,:-1])\n",
        "y = np.array(dataset.iloc[:,-2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d8c84651-3af4-9b64-2a58-77b4aaad0251"
      },
      "outputs": [],
      "source": [
        "# Number of data points in the minority class\n",
        "number_records_fraud = len(dataset[dataset.Class == 1])\n",
        "fraud_indices = np.array(dataset[dataset.Class == 1].index)\n",
        "\n",
        "# Picking the indices of the normal classes\n",
        "normal_indices = dataset[dataset.Class == 0].index\n",
        "\n",
        "# Out of the indices we picked, randomly select \"x\" number (number_records_fraud)\n",
        "random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\n",
        "random_normal_indices = np.array(random_normal_indices)\n",
        "\n",
        "# Appending the 2 indices\n",
        "under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n",
        "\n",
        "# Under sample dataset\n",
        "under_sample_data = dataset.iloc[under_sample_indices,:]\n",
        "\n",
        "x_undersample = np.array(under_sample_data.ix[:, under_sample_data.columns != 'Class'])\n",
        "y_undersample = np.array(under_sample_data.ix[:, under_sample_data.columns == 'Class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a012b5cb-57df-5411-fe14-0fd04d828d36"
      },
      "outputs": [],
      "source": [
        "#splitting the sample data into trian and test set\n",
        "from sklearn.cross_validation import train_test_split\n",
        "\n",
        "# Undersampled dataset\n",
        "x_train_undersample, x_test_undersample, y_train_undersample, y_test_undersample = train_test_split(x_undersample,y_undersample,test_size = 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f77424a9-bd90-5121-3b5f-5c61329578da"
      },
      "outputs": [],
      "source": [
        "#checking the target class\n",
        "count_classes = pd.value_counts(np.ravel(y_train_undersample), sort = True).sort_index()\n",
        "count_classes.plot(kind = 'bar')\n",
        "plt.title(\"Fraud class histogram\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "991c43f8-5d4a-474c-5eb8-8b8e86ecd4de"
      },
      "outputs": [],
      "source": [
        "names = [\"Logistic Regression\",\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n",
        "         \"Decision Tree\", \"Random Forest\",\"Naive Bayes\" ]\n",
        "\n",
        "classifiers = [\n",
        "    LogisticRegression(),\n",
        "    KNeighborsClassifier(),\n",
        "    SVC(kernel=\"linear\"),\n",
        "    SVC(kernel=\"rbf\"),\n",
        "    DecisionTreeClassifier(criterion = 'entropy'),\n",
        "    RandomForestClassifier(criterion = 'entropy'),\n",
        "    GaussianNB(),\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ed820637-e20c-e0f1-12cc-f290645d2b73"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "results = {}\n",
        "for name, clf in zip(names, classifiers):\n",
        "    scores = cross_val_score(clf, x_train_undersample, np.ravel(y_train_undersample), cv=5)\n",
        "    results[name] = scores\n",
        "           \n",
        "for name, scores in results.items():\n",
        "    print(\"%20s | Accuracy: %0.2f%% (+/- %0.2f%%)\" % (name, 100*scores.mean(), 100*scores.std() * 2))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ad67b860-2911-353e-1aae-43aaffaa1894"
      },
      "outputs": [],
      "source": [
        "from sklearn.grid_search import GridSearchCV\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# prepare a range of values to test\n",
        "param_grid = [\n",
        "  {'n_estimators': [10,30,50,80,100,200], 'criterion': ['gini','entropy']},\n",
        " ]\n",
        "\n",
        "grid = GridSearchCV(estimator=clf, param_grid=param_grid)\n",
        "grid.fit(x_train_undersample, np.ravel(y_train_undersample))\n",
        "print(grid)\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(x_train_undersample, np.ravel(y_train_undersample))\n",
        "y_pred = clf.predict(x_test_undersample)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "00b839a0-e5ff-9e0a-350b-dfd94ab8ab48"
      },
      "outputs": [],
      "source": [
        "#creating the confusion matrix and checking the accuracy\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
        "cm = confusion_matrix(y_test_undersample,y_pred)\n",
        "acc = accuracy_score(y_test_undersample,y_pred)\n",
        "clr = classification_report(y_test_undersample,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cd2785eb-4b1f-e335-3541-865bde322cd5"
      },
      "outputs": [],
      "source": [
        "#visulaizing the confusion matirx\n",
        "import seaborn as sns\n",
        "print(acc)\n",
        "print(clr)\n",
        "label = [\"0\",\"1\"]\n",
        "sns.heatmap(cm, annot=True, xticklabels=label, yticklabels=label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "684f0e38-3cf0-0d00-e6cf-24ead27ea3c1"
      },
      "outputs": [],
      "source": [
        "# Applying k-Fold Cross Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = clf, X = x_train_undersample, y = np.ravel(y_train_undersample), cv = 10)\n",
        "accuracies.mean()\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}