{"metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"pygments_lexer": "ipython3", "name": "python", "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.3"}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"metadata": {"_cell_guid": "a038554a-50bc-4601-bcc3-e11f7bf6f735", "_uuid": "730886cde0f5348afa59734b1b089c013e4f5640"}, "source": ["## Welcome to my Spooky Author Identification Notebook\n", "\n", "The goal here is to use the provided dataset, which contains mappings of \"text\" to their authors, and use that data to build a model which can predict who the author is for any provided text.\n", "\n", "## Strategy\n", "\n", "In order to map text to an author, we're going to need to do some feature engineering to extract text into some useful features which will hopefully be correlated with author.  Here's some initial ideas I have:\n", "\n", "1. Words per sentence\n", "1. Vocabulary (unique words per N words)\n", "1. Punctuation usage rates\n", "1. Word frequency (maybe some authors like specific words)\n", "1. Sentiment analysis\n", "1. N-grams (analyze word groupings)\n", "\n", "I'm sure there are many other options, but I think those will be a good place to start.\n", "\n", "Let's begin by pulling in the training set and exploring the data a bit."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "89c795c8-4da5-4514-859a-636ddeb4df3e", "_uuid": "f912f1f4dcf7b9838d6f502af4f01f1b8963466f"}, "outputs": [], "source": ["import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import nltk # natural language toolkit - http://www.nltk.org/"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "4e465147-b476-4780-9fb6-89a390dc6a94", "_uuid": "023fe61ef94a0d1b7a8a302fea2c5008639943cf"}, "outputs": [], "source": ["# We have a train.csv and test.csv available\n", "df = pd.read_csv('../input/train.csv')\n", "\n", "df.head()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "7b5b052f-e5bd-4449-92e8-81af09256b7f", "_uuid": "a460b7e8ac57216637cb5d494ccb53c071eb4607"}, "source": ["To get a handle on this data, let's figure out some features that rely on individual word counts.\n", "\n", "We'll need nltk to tokenize the plain text into words, and then we'll do a count and assign it as a new column \"word_count\".  Then we'll store the number of characters per text sentence and then figure out the count of words per sentence."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "2b816096-4dbd-40c4-b048-47e594d8e9fd", "_uuid": "127e4a34813659b32b10fad3d854c6e5dcd63069"}, "outputs": [], "source": ["# I want to remove punctuation from the text for word counting purposes\n", "import string\n", "no_punct_translator=str.maketrans('','',string.punctuation)\n", "\n", "# tokenize each sentence and remove punctuation\n", "df['words'] = df['text'].apply(lambda t: nltk.word_tokenize(t.translate(no_punct_translator).lower()))"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_cell_guid": "8757d95c-c4f2-4723-afb3-6b18606cc1cc", "_uuid": "420b420f92aecd05e9a1a9e337a1f681a95efb9a"}, "outputs": [], "source": ["# create a new column with the count of all words\n", "df['word_count'] = df['words'].apply(lambda words: len(words))\n", "\n", "# for normalization, how many characters per sentence w/o punctuation\n", "df['sentence_length'] = df['words'].apply(lambda w: sum(map(len, w)))\n", "\n", "# for future calculations, let's keep around the full text length, including punctuation\n", "df['text_length'] = df['text'].apply(lambda t: len(t))"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "68edbb84-cde2-461f-bc12-11b338efccbf", "_uuid": "be1a1734009dc5d4beaf51bd4bc55ee139a9328b"}, "outputs": [], "source": ["df.head()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "59c8d138-386b-4970-87e2-bd6c14515d45", "_uuid": "fe39fbd4b7cc407870dee16c9210bb212322a18e"}, "source": ["Ok, now we have a list of words, and a count of words per sentence.  Let's do some graphing to see what the distribution of words looks like for each author."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "3c7d33e4-ea51-4608-b943-4268e78e5578", "_uuid": "4acbc9ba7f34a5bcb98a11f9b87031e91f0c684c"}, "outputs": [], "source": ["# import some graphing libraries\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "sns.set_style('whitegrid')"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "968e3b11-0fda-4269-96f2-d1e22088c936", "_uuid": "088642dbed1945c2d0fdf065b031d1bc61ba47fd"}, "outputs": [], "source": ["# Let's plot how many words per sentence each author uses\n", "sns.boxplot(x = \"author\", y = \"word_count\", data=df, color = \"red\")"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "a8a96c2d-4622-4361-a631-883d5491cb6c", "_uuid": "ffb74b8238d815caaf451b5f0ec4243d92aa0ada"}, "outputs": [], "source": ["# Here's the same thing in text form.  \n", "# Not a huge distinction but EAP seems to average less words per sentence\n", "df.groupby(['author'])['word_count'].describe()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "6a78d980-1671-46cc-9bb4-6a03b2079143", "_uuid": "9de7ae0cedddba8fc4fb2d3343a7688cefc07171"}, "outputs": [], "source": ["# here's the number of characters in each sentence, we do get a little separation here\n", "df.groupby(['author'])['sentence_length'].describe()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "86a1fd52-512c-4ca0-9c29-af558b5e1c90", "_uuid": "0483760ec36eda3ea8d77805c8e21db04dbef10c"}, "source": ["Well I was hoping we'd get more separation here, it doesn't seem like there is a huge difference in words per sentence or characters per sentence, but maybe there is enough destinction to make some decent guesses.\n", "\n", "Next up, let's do some simple punctuation counts.  We'll use a ratio of punctuation per character to see how often the author uses non word characters."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "7a15c01b-d802-411f-9565-6a3a26211958", "_uuid": "6ab12c5eae3e03b9657935ea07984ef34a245168"}, "outputs": [], "source": ["# the string library defines `string.punctuation` which is all the punctuation chars\n", "df['punctuation_count'] = df['text'].apply(lambda t: len(list(filter(lambda c: c in t, string.punctuation))))\n", "\n", "df['punctuation_per_char'] = df['punctuation_count'] / df['text_length'] "], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "1063f645-c9ab-4e7c-883d-454fcdc8b392", "_uuid": "41e7214a141636b342c8ce1c76a340fcb7deccdf"}, "outputs": [], "source": ["df.groupby(['author'])['punctuation_per_char'].describe()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_cell_guid": "c797aa45-8321-4781-8183-7b5444a65a7a", "_uuid": "0a994e7dc0692fa9c8062ae8abaaa2565a2b2b17"}, "source": ["Now let's start working on vocabulary by figuring out the ratio of unique words to all words in a sentence."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "e800ad9b-c3ae-4d2f-9d92-f4c6b30fac51", "_uuid": "b503acecc14b5881fbafdd6df7acef1556f44269"}, "outputs": [], "source": ["def unique_words(words):\n", "    word_count = len(words)\n", "    unique_count = len(set(words)) # creating a set from the list 'words' removes duplicates\n", "    return unique_count / word_count\n", "\n", "df['unique_ratio'] = df['words'].apply(unique_words)\n", "df.groupby(['author'])['unique_ratio'].describe()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "0496811a-9ffd-4c61-a08b-f6237f5c8d50", "_uuid": "c4973b0837e0f06fadff425397c0680a111519de"}, "source": ["Seems like the usage of unique words are about the same (90% of words are unique), though the distribution varies a bit.  Let's graph the distribution of unique words for each author."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "46481b45-b807-4356-9fd6-6bc2a5861bcf", "_uuid": "ea5cb8be05e9b34fa08443b72c1c7677eb59ce84"}, "outputs": [], "source": ["authors = ['MWS', 'HPL', 'EAP']\n", "\n", "for author in authors:\n", "    sns.distplot(df[df['author'] == author]['unique_ratio'], label = author, hist=False)\n", "\n", "plt.legend();"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "c238a91e-a73b-48da-895a-ac8f61a23d56", "_uuid": "dd037ca000e73c2c1148825f9fc6833b03d1bf35"}, "source": ["Pretty cool!\n", "\n", "Now let's take a look at the size of the actual words used, in case some authors like to use longer words."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "e158badb-7623-49a9-b5b5-24a2ff9b98dd", "_uuid": "b34dd6849f3e1a0ddb813bbc6aed6d8d5edd9f7b"}, "outputs": [], "source": ["# add up the length of each words and devide by the total number of words\n", "avg_length = lambda words: sum(map(len, words)) / len(words)\n", "\n", "df['avg_word_length'] = df['words'].apply(avg_length)\n", "df.groupby(['author'])['avg_word_length'].describe()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "f26b7cb8-b97f-4a34-8df1-d7bc8add96a8", "_uuid": "4d98d6524b9af5293fba142c00bb3d36b092d525"}, "outputs": [], "source": ["for author in authors:\n", "    sns.distplot(df[df['author'] == author]['avg_word_length'], label = author, hist=False)\n", "\n", "plt.legend();"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "5c294675-69f5-43b5-babb-93d4cb62bf87", "_uuid": "126a216372859dec4061df3321a712b854ff750d"}, "source": ["## Where we are now\n", "\n", "We have broken down the text into lots of different features, some which might be useful to feed into a machine learning algorithm.  Let's see what we have:\n", "\n", "1. word_count: number of words in the average sentence\n", "1. sentence_length: number of word characters in each sentence\n", "1. text_length: pure number of characters, including spaces and punctuation\n", "1. punctuation_per_char: how often an author uses punctuation marks per character written \n", "1. unique_ration: ratio of unique words to total words\n", "1. avg_word_length: how many characters is in the average word written "], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "1b20c9c9-4266-4669-bbce-935311d78cea", "_uuid": "dee23550046a9614f647c0fcf7959dfd6f8818bd"}, "outputs": [], "source": ["df.head(2)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "3d88b35c-35da-413c-b8e5-9cce35cafd59", "_uuid": "0c4a004695e1508b17a3dc06599cf6815da27453"}, "source": ["## Sentiment Analysis\n", "\n", "Now let's analyze the text itself for sentiment, hoping that some authors are more \"positive\", \"neutral\" or \"negative\" in their sentences than others.  NTLK makes this pretty easy with the VADER sentiment analyzer (http://www.nltk.org/api/nltk.sentiment.html#module-nltk.sentiment.vader)"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "019e1dad-3584-40f2-ae7f-ea37615f6640", "_uuid": "57b7fd4f69eac2bb4dde0526d7f96e4c00f64459"}, "outputs": [], "source": ["from nltk.sentiment.vader import SentimentIntensityAnalyzer\n", "sid = SentimentIntensityAnalyzer()\n", "\n", "# Let's test how this works\n", "print(sid.polarity_scores('Vader text analysis is my favorite thing ever'))\n", "print(sid.polarity_scores('I hate vader and everything it stands for'))"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "be0b2331-7fa5-403b-b38d-d82663b31be6", "_uuid": "98c24dd96faeab7e81850016e9a8ceeb423f5e32"}, "source": ["So for any piece of analyzed text, we get 4 outputs, all of which could be useful.  However there is a \"compound\" property which is normalized between -1 (most negative) and 1 (most positive) which we can use to give us a good overall classification.\n", "\n", "Let's update our data with sentiment scores and see how they differ for each author"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "78befe1f-5cd5-4bb6-9cbc-18aa9ac7d7c1", "_uuid": "42e612efa207602a97261952b1b3d8238887d77b"}, "outputs": [], "source": ["df['sentiment'] = df['text'].apply(lambda t: sid.polarity_scores(t)['compound'])\n", "df.groupby('author')['sentiment'].describe()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "f81688ab-b588-49a2-be15-1901575026bc", "_uuid": "c18a40ba5c5c33fd64f7ab889d443371c7cbd094"}, "outputs": [], "source": ["for author in authors:\n", "    sns.distplot(df[df['author'] == author]['sentiment'], label = author, hist=False)\n", "\n", "plt.legend();"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "448343b1-0d34-475a-b0a3-e7d920132a95", "_uuid": "ba3977f0158ac5eb5ee65d239e7f6e862742b12d"}, "source": ["Now this is really interesting, the is quite a bit of differentiation between the authors.  Everyone clusters around 0 (neutral sentence) but HP Lovecraft is significantly more negative and Mary Shelley is much more positive overall."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "90881d42-0ac9-4e1f-a0dd-b1a230cd79ca", "_uuid": "df096c2aaee8fe636e2d5038ff55f30e03106b66"}, "outputs": [], "source": ["sns.boxplot(x=\"author\", y=\"sentiment\", data=df);"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_cell_guid": "34a3d72f-d089-4dcf-a6de-1d5104ad2cd9", "_uuid": "2e6d0395f5025208977fd104efe02296fbf07452"}, "outputs": [], "source": ["# # TODO: do this later after we have more data\n", "\n", "# # let's create a correlation matrix\n", "# corr = df.corr()\n", "\n", "# # make \n", "# plt.subplots(figsize=(11, 9))\n", "\n", "# # Generate a custom diverging colormap\n", "# cmap = sns.diverging_palette(220, 10, as_cmap=True)\n", "\n", "# # Draw the heatmap with the mask and correct aspect ratio\n", "# sns.heatmap(corr, cmap=cmap, vmax=.3, center=0,\n", "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "2674bd4e-98e7-4a44-b18b-c98adaba37d4", "_uuid": "d748320cf9434e7d566d5a2bd90653641015a46f"}, "source": ["## Word Frequency\n", "\n", "I'd like to try to figure out if some authors have \"favorite\" words, which could help us determine which author wrote some specific piece of text.\n", "\n", "I'm not sure the best way to go about this, but I have a few ideas:\n", "\n", "1. Find the top N most commonly used words (for each author?), then score each text based on how frequently that word appears.\n", "   * issue: we would want to strip out common pronounds, conjunctions and other parts of speach\n", "   * issue: the ratio would probably be really close to zero so we'd want to normalize\n", "1. Pick a part of speach, say verbs or adverbs, and see how often certain authors utilize some array of top words\n", "   * issue: where would these words come from, should they just come from the whole training set?\n", "1. Instead of specific words, we could see how often authors use certain parts of speech using nltk\n", "\n"], "cell_type": "markdown"}, {"metadata": {"_kg_hide-output": false, "_cell_guid": "b7c115e6-c136-4c7e-8616-9beba7ce53ea", "_kg_hide-input": false, "_uuid": "d0e1ed4a3f3d267615ba250b79ba00c37050d7dc"}, "outputs": [], "source": ["# Let's start by figuring out the most common words in our word dataset\n", "\n", "# iterate all rows and create a new dataframe with author->word (single word)\n", "df_words = pd.concat([pd.DataFrame(data={'author': [row['author'] for _ in row['words']], 'word': row['words']})\n", "           for _, row in df.iterrows()], ignore_index=True)\n", "\n", "# use NLTK to remove all rows with simple stop words\n", "df_words = df_words[~df_words['word'].isin(nltk.corpus.stopwords.words('english'))]\n", "\n", "df_words.shape"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "5785b821-1532-4938-8096-4f19e89139fc", "_uuid": "2f1e9b95edd6bf95495c6c99e41095940b79f6bf"}, "outputs": [], "source": ["# let's use wordclouds to see which words each author likes to use\n", "from wordcloud import WordCloud, STOPWORDS\n", "\n", "def authorWordcloud(author):\n", "    # lower max_font_size\n", "    wordcloud = WordCloud(max_font_size=40,background_color=\"black\", max_words=10000).generate(\" \".join(df_words[df_words['author'] == author]['word'].values))\n", "    plt.figure(figsize=(11,13))\n", "    plt.title(author, fontsize=16)\n", "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n", "    plt.axis(\"off\")\n", "    plt.show()\n", "    \n", "authorWordcloud('HPL')\n", "authorWordcloud('EAP')\n", "authorWordcloud('MWS')"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "3ac0de7e-3ef7-441f-9888-6a18a1067f0a", "_uuid": "dbb4e4e5d79d992a5dcb9f8e98b9064a0298ea57"}, "source": ["### Now we have wordclouds for each author\n", "\n", "We can tell already that they tend to favor certain words, and they often intersect in interesting ways.  Now let's try to figure out the most commonly used words by each author"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "f16d40dc-4ae9-4297-b0a3-afb819e3fe86", "scrolled": false, "_uuid": "935e87a9e8d47397bf7d3791aa2ea58ee1879946"}, "outputs": [], "source": ["# function for a specific author to count occurances of each word\n", "def authorCommonWords(author, numWords):\n", "    authorWords = df_words[df_words['author'] == author].groupby('word').size().reset_index().rename(columns={0:'count'})\n", "    authorWords.sort_values('count', inplace=True)\n", "    return authorWords[-numWords:]\n", "\n", "# for example, here's how we get the 10 most common EAP words.\n", "authorCommonWords('EAP', 10)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_cell_guid": "d2cf5389-e5dd-4387-910f-ee1141c4ea87", "_uuid": "88830be4e6f3425ba1aa47b30575947f7262cca6"}, "source": ["## Utilizing An Author's Top Words\n", "\n", "Now we can get a list of an author's top words, and there are probably lots of ways to use them.  Our initial appoach will be make an indicator tensor (https://www.tensorflow.org/api_docs/python/tf/feature_column/indicator_column) for each possible top word and use it to indicate whether that example contains the given word.  Then we'll let our ML algorithm figure out the scoring relationship by treating that column as categorical data."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_cell_guid": "967cca1b-7aad-4ef8-a924-cb07e3da1002", "_uuid": "06e50a0c38ee42789ef90907a1158781e3ce6249"}, "outputs": [], "source": ["# get all top words from our authors.\n", "# this will represent our top words \"vocabulary list\"\n", "authors_top_words = []\n", "for author in authors:\n", "    authors_top_words.extend(authorCommonWords(author, 10)['word'].values)\n", "\n", "# use a set to remove duplicates\n", "authors_top_words = list(set(authors_top_words))"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "5cecfb01-07f9-481b-9e8a-4afd840052a6", "_uuid": "33cd2e2b8fc5c29a6e3290b063fa9f147dca6af6"}, "outputs": [], "source": ["# put all the top words used in each example into a new column    \n", "df['top_words'] = df['words'].apply(lambda w: list(set(filter(set(w).__contains__, authors_top_words))))\n", "df[['author','top_words', 'words']].head()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "e54d8f63-b698-4eff-9615-f9aaefae009a", "_uuid": "762d255eff0600a9cf7478cdd40ea823c85bb787"}, "source": ["## TODO: Create feature columns for each top word"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "dc45becf-1074-4124-b74b-19272f2ad651", "_uuid": "db58782056546ecdc7bbe5c49e7a96dfc19606ed"}, "source": ["## Making an ML Model\n", "Now that we have a lot of features, let's try to make our first ML model and see how it does.  I'm going to use Tensorflow to make a Logistic Regression model using the estimator API.\n", "\n", "## Defining our features for Tensorflow\n", "We have both continuous value columns, like words per sentence, and some categorical columns like top_words.  Let's figure out which columns we want to use from our dataframe and then define the feature columns.\n"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "89e11e6f-a52d-4288-9509-964fb458bff6", "_uuid": "e87044060dd448756229a83d3a404c3e1c3b9fd5"}, "outputs": [], "source": ["# First, let's just pull out the columns we need\n", "# feature_columns = ['author', 'word_count', 'text_length', 'punctuation_per_char', 'unique_ratio', 'avg_word_length', 'sentiment', 'top_words']\n", "# TODO: put back in top_words once we figure it out\n", "feature_columns = ['author', 'word_count', 'text_length', 'punctuation_per_char', 'unique_ratio', 'avg_word_length', 'sentiment']\n", "df_features = df[feature_columns]\n", "\n", "# Now let's split into a train and dev set\n", "# use random_state seed so we get the same split each time\n", "df_train=df_features.sample(frac=0.8,random_state=1)\n", "df_dev=df_features.drop(df_train.index)\n", "\n", "df_train.head()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "4f8a4524-00f7-4de8-9421-e613585c7bc9", "_uuid": "ae05fdfb8b618ddb5a0720e6f726620fa9b62637"}, "outputs": [], "source": ["import tensorflow as tf\n", "\n", "# continual numeric features\n", "feature_word_count = tf.feature_column.numeric_column(\"word_count\")\n", "feature_text_length = tf.feature_column.numeric_column(\"text_length\")\n", "feature_punctuation_per_char = tf.feature_column.numeric_column(\"punctuation_per_char\")\n", "feature_unique_ratio = tf.feature_column.numeric_column(\"unique_ratio\")\n", "feature_avg_word_length = tf.feature_column.numeric_column(\"avg_word_length\")\n", "feature_sentiment = tf.feature_column.numeric_column(\"sentiment\")\n", "\n", "# if we just used the single top word we could do it this way (single-hot)\n", "# feature_top_words = tf.feature_column.categorical_column_with_vocabulary_list(\n", "#    \"top_words\", vocabulary_list=authors_top_words)\n", "\n", "# feature_top_words = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(\n", "#     \"top_words_test\", vocabulary_list=authors_top_words))\n", "\n", "base_columns = [\n", "    feature_word_count, feature_text_length, feature_punctuation_per_char, feature_unique_ratio, feature_avg_word_length, feature_sentiment\n", "]"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "a1dadbe8-7b09-45c4-be8a-ddb8c91d3cb4", "_uuid": "23a8262c11d8b4b5e5308b3e6f980eb30cd46741"}, "outputs": [], "source": ["import tempfile\n", "\n", "model_dir = tempfile.mkdtemp() # base temp directory for running models\n", "\n", "# our Y value labels, i.e. the thing we are classifying\n", "labels_train = df_train['author']\n", "\n", "# let's make a training function we can use with our estimators\n", "train_fn = tf.estimator.inputs.pandas_input_fn(\n", "    x=df_train,\n", "    y=labels_train,\n", "    batch_size=100,\n", "    num_epochs=None, # unlimited\n", "    shuffle=True, # shuffle the training data around\n", "    num_threads=5)\n", "\n", "# let's try a simple linear classifier\n", "linear_model = tf.estimator.LinearClassifier(\n", "    model_dir=model_dir, \n", "    feature_columns=base_columns,\n", "    n_classes=len(authors),\n", "    label_vocabulary=authors)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "2bf0afa7-d7cc-4c09-8013-83d4982f37fa", "_uuid": "7272766e7c92399b54dd7a7b7f55606876f7ff16"}, "outputs": [], "source": ["train_steps = 5000\n", "\n", "# now let's train that model!\n", "linear_model.train(input_fn=train_fn, steps=train_steps)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "2cca82d0-7672-4bc3-8329-7f97127ab82e", "_uuid": "8c2a17a6582bfadbb30b404548341d4438927472"}, "outputs": [], "source": ["# let's see how well we did on our training set\n", "dev_test_fn = tf.estimator.inputs.pandas_input_fn(\n", "    x=df_dev,\n", "    y=df_dev['author'],\n", "    batch_size=100,\n", "    num_epochs=1, # just one run\n", "    shuffle=False, # don't shuffle test here\n", "    num_threads=5)\n", "\n", "linear_model.evaluate(input_fn=dev_test_fn)[\"accuracy\"]"], "execution_count": null, "cell_type": "code"}, {"metadata": {"collapsed": true, "_cell_guid": "b32d5e12-423f-4ea3-bd09-538ddcff7167", "_uuid": "669cd9a0e57381b14af319097bb1782ef105f2bf"}, "source": ["# Results so far\n", "\n", "Well no we have a model that can guess the right author about 43% of the time.  Better than the 33% of random chance, but really not so great :).  Though we were just using a simple logistic regression model (linear classifier) and we may be able to get more accurate preditictions with a different classifier since the data relationships are probably not linear anyway.  Also, we have yet to incorporate the author's top words yet.\n"], "cell_type": "markdown"}, {"metadata": {}, "source": ["# Work In Progress\n", "\n", "More to come soon, stay tuned"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "outputs": [], "source": [], "execution_count": null, "cell_type": "code"}]}