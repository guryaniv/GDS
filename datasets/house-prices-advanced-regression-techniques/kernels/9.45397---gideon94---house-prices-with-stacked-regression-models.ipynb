{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Compiled by HK\n\n#Data Loading\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\nsns.set_style('darkgrid')\nimport warnings\ndef ignore_warn(*args,**kwargs):\n    pass\nwarnings.warn = ignore_warn\n\npd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Limiting floats output to 3 decimal points","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9985c05b6aa5d10ef956c3511c253dbe76b420e5"},"cell_type":"code","source":"from scipy import stats\nfrom scipy.stats import norm, skew","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrain.head()\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92888c9a0e53846fbb39bb48bd524217a862093e"},"cell_type":"code","source":"print('Training dataset before any transformations: '+format(train.shape))\nprint('Testing dataset before any transformations: '+format(test.shape))\n\ntrain_ID = train.Id\ntest_ID = test.Id\n\ntrain.drop(\"Id\",axis=1, inplace=True)\ntest.drop(\"Id\",axis=1,inplace=True)\n\nprint('Training dataset before any transformations: '+format(train.shape))\nprint('Testing dataset before any transformations: '+format(test.shape))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6516a95409ded44be7b937b04ff890011d936f11"},"cell_type":"code","source":"#Data Processing\n\n#Outliers\nfig, ax = plt.subplots()\nax.scatter(x = train['GrLivArea'], y = train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea',fontsize=13)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1819f4cb0b434199692162561896a5e6e12a4c72"},"cell_type":"code","source":"#Deleting Outliers\ntrain =train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n\nfig,ax= plt.subplots()\nax.scatter(train['GrLivArea'],train['SalePrice'])\nplt.ylabel('SalePrice',fontsize=13)\nplt.xlabel('GrLivArea',fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e5abbd3ba4fb6a829501386776f830c2d85f7fa"},"cell_type":"code","source":"#Target Variable\n\nsns.distplot(train['SalePrice'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"621f92a15e4f8178019c1837642e2a3e3f1fced3"},"cell_type":"code","source":"#Log Transformat#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n\n#Check the new distribution \nsns.distplot(train['SalePrice'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)\nplt.show()\n\n#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n\n#Check the new distribution \nsns.distplot(train['SalePrice'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe9714dfdeb2eec31d7e1a08a314337717d35880"},"cell_type":"code","source":"#Feature Engineering\n\nntrain = train.shape[0]\nntest = test.shape[0]\ny_train = train.SalePrice.values\nall_data = pd.concat((train, test)).reset_index(drop=True)\nall_data.drop(['SalePrice'], axis=1, inplace=True)\nprint(\"all_data size is : {}\".format(all_data.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c34eabd7252e2e6d245e0ba76c6db0f6b91ffe0"},"cell_type":"code","source":"all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f037b506b141e4705e6351dde3b4101e8e0466ef"},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(15, 12))\nplt.xticks(rotation='90')\nsns.barplot(x=all_data_na.index, y=all_data_na)\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efa4c6aff32632c5668be3375e5c6e39108817c4"},"cell_type":"code","source":"#Data Correlation\n\ncorrmat = train.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, vmax=0.9, square=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"febf6e116a0a1d260742d0e734d47fe316fd120f"},"cell_type":"code","source":"#Imputing missing values\n#None for following columns\n\nall_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\nall_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\nall_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\nall_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\nall_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c63c86322171851e5696513071898dd28514e9bb"},"cell_type":"code","source":"#Median for LotFrontage grouped by Neighborhood\n    \nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"317237d032b059630f3eec595276482115b220d4"},"cell_type":"code","source":"#None for following columns\n\nfor col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col] = all_data[col].fillna('None')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d895599d14d4c6916061f85bd4590313b8083030"},"cell_type":"code","source":"#0 for following columns\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col] = all_data[col].fillna(0)\n    \nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col] = all_data[col].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24de0bb1c15236f3b28edcc9d5ce7b81f44e237f"},"cell_type":"code","source":"for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a76c9387ac49490e19fec2b405dcffa0ec942a83"},"cell_type":"code","source":"all_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7ec1c3b7a3af440f4b7c372b7083c6dc2adfed2"},"cell_type":"code","source":"#RL for MSZoning\nall_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cc2db359824deadf0005d593b402b712cbad913"},"cell_type":"code","source":"#Dropping Utilitie since it has no effect on Modelling\nall_data = all_data.drop(['Utilities'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e30661b52c3e00cf61da3755699ef0d33abfc9ec"},"cell_type":"code","source":"#Typical for Functional\nall_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39d40fc952b7983b407cb4fd7e70e12592af6d16"},"cell_type":"code","source":"#Filling most frequent data for all the columns\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"221f7186fb854d607f4667b9ce95417aed5e5ee7","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"all_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dde222b801e479d1c244914f4823ea3cc67bb1e"},"cell_type":"code","source":"#Check remaining missing values if any \nall_data_na = (all_data.isnull().sum() / len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ec95dee1c75f79375babe74db3863b4571debe6"},"cell_type":"code","source":"#Transforming some numerical variables that are really categorical\n\nall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"111aa0da29bc1d4fcf832ebf1090af264f70a26f"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(all_data[c].values)) \n    all_data[c] = lbl.transform(list(all_data[c].values))\n\n# shape        \nprint('Shape all_data: {}'.format(all_data.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"054a31a0ffa6ee5be1562346ea7326ab40fb3335"},"cell_type":"code","source":"all_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ef63583e7f96a35911ef193a5aa9e2ced0e4b23"},"cell_type":"code","source":"#Calculating total area which can be useful for Modelling\nall_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00075539dca09b0c0feac2abe86f4d267dae1cf2"},"cell_type":"code","source":"#Skewed Features\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bea134fe41c44129a61683b780d41f693018048"},"cell_type":"code","source":"#Box Cox Transformation of (highly) skewed features\n\nskewness = skewness[abs(skewness) > 0.75]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    #all_data[feat] += 1\n    all_data[feat] = boxcox1p(all_data[feat], lam)\n    \n#all_data[skewed_features] = np.log1p(all_data[skewed_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33b67d58843fa1a65995b3d3552d4da14814a01e"},"cell_type":"code","source":"#Getting dummies for Categorical data\nprint(all_data.shape)\nall_data =pd.get_dummies(all_data)\nprint(all_data.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f53acf650310ee7a5b74fb7020abd689c2d62178"},"cell_type":"code","source":"#Transforming all_data to train and test sets\ntrain = all_data[:ntrain]\ntest = all_data[ntrain:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a41bd2da00a0f7e4a55f88890c3259830f47a19"},"cell_type":"code","source":"#Modelling\n\n#Importing Libraries\n\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea34b1e6f6b46b6903575b98a74116626d30f366"},"cell_type":"code","source":"#Shuffling prior to cross validation\n\nn_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d43879f58efefda657cb9f3314444250f44f2f46"},"cell_type":"code","source":"#Lasso Regression\nlasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n#Elastic Net Regression\nENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n#Kernel Ridge Regression\nKRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n#Gradient Boosting\nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)\n#XGBoost\nmodel_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)\n#LightGBM\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31ecebfc31f267bb8ffaa10ec119bdd45e8ccba6"},"cell_type":"code","source":"#Base models scores\nscore = rmsle_cv(lasso)\nprint(\"LASSO SCORE: {:.4f} ({:.4f})\". format(score.mean(),score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb53727ef3fcc60fcf3b59c34b26ea38d2ade071"},"cell_type":"code","source":"score = rmsle_cv(ENet)\nprint(\"ECNET SCORE: {:.4f} ({:.4f})\".format(score.mean(),score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40bdee0db48bf318972c23fa91df24fdb8808692"},"cell_type":"code","source":"score = rmsle_cv(KRR)\nprint(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cd0e2d1b859c8cdbdbcff59d2f07d2e9f913dc6"},"cell_type":"code","source":"score = rmsle_cv(GBoost)\nprint(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11c8742bb2e79a85fff1299d30b0db5b421eddb3"},"cell_type":"code","source":"score = rmsle_cv(model_xgb)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2dcfe070c1c3e57249a2a7e1c7beef769055e493"},"cell_type":"code","source":"score = rmsle_cv(model_lgb)\nprint(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"829308c7799d6b1a485987771a321f7222194edc"},"cell_type":"code","source":"#Stacking Models : Averaging base models\nclass AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models):\n        self.models = models\n        \n    # we define clones of the original models to fit the data in\n    def fit(self, X, y):\n        self.models_ = [clone(x) for x in self.models]\n        \n        # Train cloned base models\n        for model in self.models_:\n            model.fit(X, y)\n\n        return self\n    \n    #Now we do the predictions for cloned models and average them\n    def predict(self, X):\n        predictions = np.column_stack([\n            model.predict(X) for model in self.models_\n        ])\n        return np.mean(predictions, axis=1)   \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae879534a2958b6ed003c34f3ae163be84624cc9"},"cell_type":"code","source":"#Score of Averaging base models\n\naveraged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))\n\nscore = rmsle_cv(averaged_models)\nprint(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81340fc13760bd110f36a7460264e2a9a66f7ecc"},"cell_type":"code","source":"#Stacking Models : Adding a Meta_model\n\nclass StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=5):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n    # We again fit the data on clones of the original models\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n        \n        # Train cloned base models then create out-of-fold predictions\n        # that are needed to train the cloned meta-model\n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X[train_index], y[train_index])\n                y_pred = instance.predict(X[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    #Do the predictions of all base models on the test data and use the averaged predictions as \n    #meta-features for the final prediction which is done by the meta-model\n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab4a8690bad2bde52cb5317fb3b3abf47d52e30b"},"cell_type":"code","source":"#Score of averaging meta_model\n\nstacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n                                                 meta_model = lasso)\n\nscore = rmsle_cv(stacked_averaged_models)\nprint(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5da0e2f3d6985817fbad77294b7fe5db1d160ec8"},"cell_type":"code","source":"#Ensembling StackedRegressor, XGBoost and LightGBM\n\n#rmsle evaluation function\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6fba4acffe8a84f72fe64bfd9aa564db5ab8ff8"},"cell_type":"code","source":"#StackedRegressor\n\nstacked_averaged_models.fit(train.values, y_train)\nstacked_train_pred = stacked_averaged_models.predict(train.values)\nstacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\nprint(rmsle(y_train, stacked_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"053c1d5c7ad2e5505611a7ba905e96a464f2d8c4"},"cell_type":"code","source":"#XGBoost\n\nmodel_xgb.fit(train, y_train)\nxgb_train_pred = model_xgb.predict(train)\nxgb_pred = np.expm1(model_xgb.predict(test))\nprint(rmsle(y_train, xgb_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73b258ec283cdce6d4c07cf46fecd6a3f2254bde"},"cell_type":"code","source":"#LightBGM\n\nmodel_lgb.fit(train, y_train)\nlgb_train_pred = model_lgb.predict(train)\nlgb_pred = np.expm1(model_lgb.predict(test.values))\nprint(rmsle(y_train, lgb_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"811e910fcb88f21d7473ef9bdb924076f49486aa"},"cell_type":"code","source":"#RMSE on the entire Train data when averaging\n\nprint('RMSLE score on train data:')\nprint(rmsle(y_train,stacked_train_pred*0.70 +\n               xgb_train_pred*0.15 + lgb_train_pred*0.15 ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"131b16d1588cc3bbcea76ae1e492449ff430a492"},"cell_type":"code","source":"#Ensemble prediction\nensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06d7cd20cef1667363a44ae997b3c568b7928b1f"},"cell_type":"code","source":"#Final Submission\nsub = pd.DataFrame()\nsub['Id'] = test_ID\nsub['SalePrice'] = ensemble\nsub.to_csv('submission1.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}