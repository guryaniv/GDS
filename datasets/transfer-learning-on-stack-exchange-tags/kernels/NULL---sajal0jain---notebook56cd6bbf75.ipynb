{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "81d94f5c-682b-e465-8c8c-f6c7d1e0ab65"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from subprocess import check_output\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2be4438b-3439-3ca0-09c9-bbd475d8cef9"
      },
      "outputs": [],
      "source": [
        "bio = pd.read_csv(\"../input/biology.csv\")\n",
        "cook = pd.read_csv(\"../input/cooking.csv\")\n",
        "crypto = pd.read_csv(\"../input/crypto.csv\")\n",
        "diy = pd.read_csv(\"../input/diy.csv\")\n",
        "robot = pd.read_csv(\"../input/robotics.csv\")\n",
        "travel = pd.read_csv(\"../input/travel.csv\")\n",
        "sample_sub = pd.read_csv(\"../input/sample_submission.csv\")\n",
        "test = pd.read_csv(\"../input/test.csv\")\n",
        "\n",
        "\n",
        "all_dat = [bio,cook,crypto,diy,robot,travel]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d0dd1cca-a5e0-b58c-c4d6-044761f97892"
      },
      "outputs": [],
      "source": [
        "swords1 = stopwords.words('english')\n",
        "\n",
        "punctuations = string.punctuation\n",
        "\n",
        "def title_clean(data):\n",
        "    title = data.title\n",
        "    title = title.apply(lambda x: x.lower())\n",
        "    print('Remove Punctuations')\n",
        "    # title = [' '.join(word.strip(punctuations) for word in i.split()) for i in title]\n",
        "    title = title.apply(lambda x: re.sub(r'^\\W+|\\W+$',' ',x))\n",
        "    title = title.apply(lambda i: ''.join(i.strip(punctuations))  )\n",
        "    print('tokenize')\n",
        "    title = title.apply(lambda x: word_tokenize(x))\n",
        "    print('Remove stopwords')\n",
        "    title = title.apply(lambda x: [i for i in x if i not in swords1 if len(i)>2])\n",
        "    print('minor clean some wors')\n",
        "    title = title.apply(lambda x: [i.split('/') for i in x] )\n",
        "    title = title.apply(lambda x: [i for y in x for i in y])\n",
        "    print('Lemmatizing')\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    title = title.apply(lambda x: [wordnet_lemmatizer.lemmatize(i,pos='v') for i in x])\n",
        "    title = title.apply(lambda x: [i for i in x if len(i)>2])\n",
        "    return(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d06427b6-a930-eb78-f40f-66e00a0b16aa"
      },
      "outputs": [],
      "source": [
        "test.title = title_clean(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b96d328a-dfba-a81f-8417-1a820d7cd947"
      },
      "outputs": [],
      "source": [
        "test.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5289758e-4e06-aa13-6fea-ce63f06417bb"
      },
      "outputs": [],
      "source": [
        "tags = test.title.apply(lambda x: nltk.pos_tag(x) )\n",
        "tags = tags.apply(lambda x: [i[0] for i in x if i[1][0] in \"N\" ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b3c30d9e-3ff4-0ceb-d323-247566ec7f88"
      },
      "outputs": [],
      "source": [
        "test[\"tags\"] = tags.apply(lambda x: \" \".join(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "339c9197-d703-f92f-ec4d-5c2ce7896adf"
      },
      "outputs": [],
      "source": [
        "sub_dat = test.loc[:,[\"id\",\"tags\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "875a70c3-cc01-1884-2774-817c074e507b"
      },
      "outputs": [],
      "source": [
        "sample_sub.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c2333624-24ba-9768-1fe4-d68e969a8da1"
      },
      "outputs": [],
      "source": [
        "sub_dat.to_csv(\"sub0.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fc11acbf-d6e9-e055-d8e1-01bfbb279b72"
      },
      "outputs": [],
      "source": [
        "sub_dat.head()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}