{"nbformat_minor": 0, "nbformat": 4, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "cells": [{"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "71cff0f6-5502-4c81-84b6-ded021dcf4f4", "_uuid": "5748e2f7223fc6738c6e4973fb9cb1eb5d28fd06", "_execution_state": "idle", "trusted": false}, "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport random as rnd\n%matplotlib inline\nimport pandas as pd\npd.options.display.max_columns = 100\nfrom matplotlib import pyplot as plt\nimport matplotlib\nmatplotlib.style.use('ggplot')\n\npd.options.display.max_rows = 100\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n#from subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\n\ndata = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\n\ndata.describe()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "ff3eb8d4abc64a842b54b4f3625e5aecb7c914db", "_cell_guid": "75f4b27b-a34e-4510-b526-7ae7ae56c588", "_execution_state": "idle", "trusted": false}, "source": "data['Age'].fillna(data['Age'].median(), inplace=True)\ndata.describe()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "f5b4372ba242a1abf68dfa6e3dc34a6f182bee15", "_cell_guid": "dd67cb96-06b7-465f-9634-6fe167aa0883", "_execution_state": "idle", "trusted": false}, "source": "survived_sex = data[data['Survived']==1]['Sex'].value_counts()\ndead_sex = data[data['Survived']==0]['Sex'].value_counts()\ndf = pd.DataFrame([survived_sex,dead_sex])\ndf.index = ['Survived','Dead']\ndf.plot(kind='bar',stacked=True, figsize=(15,8))", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "8ab976c36b34569b247538a4717b8d05d5383f6d", "_cell_guid": "806c1078-6787-456a-bfb5-77b62b9fabfb", "_execution_state": "idle", "trusted": false}, "source": "figure = plt.figure(figsize=(15,8))\nplt.hist([data[data['Survived']==1]['Age'], data[data['Survived']==0]['Age']], stacked=True, color = ['g','r'],\n         bins = 30,label = ['Survived','Dead'])\nplt.xlabel('Age')\nplt.ylabel('Number of passengers')\nplt.legend()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "8cb476f6c85036bb4f6f51c3f8d571dc20ebb983", "_cell_guid": "a8c431e2-7d8a-43c8-b63a-d4431ddd5e27", "_execution_state": "idle", "trusted": false}, "source": "survived_count = 0\nsurvived_fare = 0\nfor index, row in data.iterrows():\n    if row['Survived'] == 1:\n        survived_count += 1\n        survived_fare += row['Fare']\nprint(survived_fare/survived_count)\nprint(survived_count)\n\nfigure = plt.figure(figsize=(15,8))\nplt.hist([data[data['Survived']==1]['Fare'],data[data['Survived']==0]['Fare']], stacked=True, color = ['g','r'],\n         bins = 30,label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of passengers')\nplt.legend()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "499b45002ff2d730a40700aa43eb817fc3fe15f9", "_cell_guid": "0cf72634-7177-4fed-b2c8-1c57981caac9", "_execution_state": "idle", "trusted": false}, "source": "plt.figure(figsize=(15,8))\nax = plt.subplot()\nax.scatter(data[data['Survived']==1]['Age'],data[data['Survived']==1]['Fare'],c='green',s=40)\nax.scatter(data[data['Survived']==0]['Age'],data[data['Survived']==0]['Fare'],c='red',s=40)\nax.set_xlabel('Age')\nax.set_ylabel('Fare')\nax.legend(('survived','dead'),scatterpoints=1,loc='upper right',fontsize=15,)", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "ecaee36cdbbf3f0556dcc0e98898624558fb6e93", "_cell_guid": "1289e3ac-f7c5-400a-bdf5-b5c0d99f4734", "_execution_state": "idle", "trusted": false}, "source": "ax = plt.subplot()\nax.set_ylabel('Average fare')\ndata.groupby('Pclass').mean()['Fare'].plot(kind='bar',figsize=(15,8), ax = ax)", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "8c0d9150adb7cdc5d59610c23ef74f012f9cee6d", "_cell_guid": "6aec03dd-7caa-423a-8254-d06849be1fc5", "_execution_state": "idle", "trusted": false}, "source": "survived_embark = data[data['Survived']==1]['Embarked'].value_counts()\ndead_embark = data[data['Survived']==0]['Embarked'].value_counts()\ndf = pd.DataFrame([survived_embark,dead_embark])\ndf.index = ['Survived','Dead']\ndf.plot(kind='bar', stacked=True, figsize=(15,8))", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "d918295519f5ed5a4aa885c96d89c36e7bb7f9f9", "_cell_guid": "ec197cec-e5d5-4b6e-90b6-973420d7f110", "_execution_state": "idle", "trusted": false}, "source": "def get_combined_data():\n    # reading train data\n    train = pd.read_csv('../input/train.csv')\n    \n    # reading test data\n    test = pd.read_csv('../input/test.csv')\n\n    # extracting and then removing the targets from the training data \n    targets = train.Survived\n    train.drop('Survived', 1, inplace=True)\n    \n\n    # merging train data and test data for future feature engineering\n    combined = train.append(test)\n    combined.reset_index(inplace=True)\n    combined.drop('index', inplace=True, axis=1)\n    \n    return combined\n\ncombined = get_combined_data()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "563e72d557dbbb137f9dbd459bee81b534291eb2", "_cell_guid": "29515d65-913f-4c85-b1d7-1f81a39fef9f", "_execution_state": "idle", "trusted": false}, "source": "def get_titles():\n\n    global combined\n    \n    # we extract the title from each name\n    combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n    \n    # a map of more aggregated titles\n    Title_Dictionary = {\n                        \"Capt\":       \"Officer\",\n                        \"Col\":        \"Officer\",\n                        \"Major\":      \"Officer\",\n                        \"Jonkheer\":   \"Royalty\",\n                        \"Don\":        \"Royalty\",\n                        \"Sir\" :       \"Royalty\",\n                        \"Dr\":         \"Officer\",\n                        \"Rev\":        \"Officer\",\n                        \"the Countess\":\"Royalty\",\n                        \"Dona\":       \"Royalty\",\n                        \"Mme\":        \"Mrs\",\n                        \"Mlle\":       \"Miss\",\n                        \"Ms\":         \"Mrs\",\n                        \"Mr\" :        \"Mr\",\n                        \"Mrs\" :       \"Mrs\",\n                        \"Miss\" :      \"Miss\",\n                        \"Master\" :    \"Master\",\n                        \"Lady\" :      \"Royalty\"\n\n                        }\n    \n    # we map each title\n    combined['Title'] = combined.Title.map(Title_Dictionary)\n\nget_titles()\ncombined.head()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "e1894d5905c5a438e71cab478b3ec9e84b9de2ce", "_cell_guid": "12a62f47-e796-4660-a501-c5b3e0ed6f39", "_execution_state": "idle", "trusted": false}, "source": "grouped_train = combined.head(891).groupby(['Sex','Pclass','Title'])\ngrouped_median_train = grouped_train.median()\n\ngrouped_test = combined.iloc[891:].groupby(['Sex','Pclass','Title'])\ngrouped_median_test = grouped_test.median()\n\ngrouped_median_train", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "8453126a7e9275a8fcbd00d734c9ccebeabb37c2", "_cell_guid": "930a9577-05a2-4434-86a4-491683070683", "_execution_state": "idle", "trusted": false}, "source": "def process_age():\n    \n    global combined\n    \n    # a function that fills the missing values of the Age variable\n    \n    def fillAges(row, grouped_median):\n        if row['Sex']=='female' and row['Pclass'] == 1:\n            if row['Title'] == 'Miss':\n                return grouped_median.loc['female', 1, 'Miss']['Age']\n            elif row['Title'] == 'Mrs':\n                return grouped_median.loc['female', 1, 'Mrs']['Age']\n            elif row['Title'] == 'Officer':\n                return grouped_median.loc['female', 1, 'Officer']['Age']\n            elif row['Title'] == 'Royalty':\n                return grouped_median.loc['female', 1, 'Royalty']['Age']\n\n        elif row['Sex']=='female' and row['Pclass'] == 2:\n            if row['Title'] == 'Miss':\n                return grouped_median.loc['female', 2, 'Miss']['Age']\n            elif row['Title'] == 'Mrs':\n                return grouped_median.loc['female', 2, 'Mrs']['Age']\n\n        elif row['Sex']=='female' and row['Pclass'] == 3:\n            if row['Title'] == 'Miss':\n                return grouped_median.loc['female', 3, 'Miss']['Age']\n            elif row['Title'] == 'Mrs':\n                return grouped_median.loc['female', 3, 'Mrs']['Age']\n\n        elif row['Sex']=='male' and row['Pclass'] == 1:\n            if row['Title'] == 'Master':\n                return grouped_median.loc['male', 1, 'Master']['Age']\n            elif row['Title'] == 'Mr':\n                return grouped_median.loc['male', 1, 'Mr']['Age']\n            elif row['Title'] == 'Officer':\n                return grouped_median.loc['male', 1, 'Officer']['Age']\n            elif row['Title'] == 'Royalty':\n                return grouped_median.loc['male', 1, 'Royalty']['Age']\n\n        elif row['Sex']=='male' and row['Pclass'] == 2:\n            if row['Title'] == 'Master':\n                return grouped_median.loc['male', 2, 'Master']['Age']\n            elif row['Title'] == 'Mr':\n                return grouped_median.loc['male', 2, 'Mr']['Age']\n            elif row['Title'] == 'Officer':\n                return grouped_median.loc['male', 2, 'Officer']['Age']\n\n        elif row['Sex']=='male' and row['Pclass'] == 3:\n            if row['Title'] == 'Master':\n                return grouped_median.loc['male', 3, 'Master']['Age']\n            elif row['Title'] == 'Mr':\n                return grouped_median.loc['male', 3, 'Mr']['Age']\n    \n    combined.head(891).Age = combined.head(891).apply(lambda r : fillAges(r, grouped_median_train) if np.isnan(r['Age']) \n                                                      else r['Age'], axis=1)\n    \n    combined.iloc[891:].Age = combined.iloc[891:].apply(lambda r : fillAges(r, grouped_median_test) if np.isnan(r['Age']) \n                                                      else r['Age'], axis=1)\n\nprocess_age()\n\ncombined.info()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "c9331e2ed81f9152d0ef12c4265f517727814ae5", "_cell_guid": "d4eb6f55-78ab-41db-ab2f-a3904f9f8627", "_execution_state": "idle", "trusted": false}, "source": "def process_names():\n    \n    global combined\n    # we clean the Name variable\n    combined.drop('Name',axis=1,inplace=True)\n    \n    # encoding in dummy variable\n    titles_dummies = pd.get_dummies(combined['Title'],prefix='Title')\n    combined = pd.concat([combined,titles_dummies],axis=1)\n    \n    # removing the title variable\n    combined.drop('Title',axis=1,inplace=True)\n\nprocess_names()\ncombined.head()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "5f66b116b94f647f939642699718c1b405dd3c63", "_cell_guid": "d7858e67-ab9d-49db-ac53-902a2cafefb3", "_execution_state": "idle", "trusted": false}, "source": "def process_fares():\n    \n    global combined\n    # there's one missing fare value - replacing it with the mean.\n    combined.head(891).Fare.fillna(combined.head(891).Fare.mean(), inplace=True)\n    combined.iloc[891:].Fare.fillna(combined.iloc[891:].Fare.mean(), inplace=True)\n    \nprocess_fares()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "926e6fe056f8d9cba4a28b1bfbacd1e758ada43c", "_cell_guid": "9dbd565f-cc2f-4a2a-bb59-b04e697c0a7c", "_execution_state": "idle", "trusted": false}, "source": "def process_embarked():\n    \n    global combined\n    # two missing embarked values - filling them with the most frequent one (S)\n    combined.head(891).Embarked.fillna('S', inplace=True)\n    combined.iloc[891:].Embarked.fillna('S', inplace=True)\n    \n    \n    # dummy encoding \n    embarked_dummies = pd.get_dummies(combined['Embarked'],prefix='Embarked')\n    combined = pd.concat([combined,embarked_dummies],axis=1)\n    combined.drop('Embarked',axis=1,inplace=True)\n    \nprocess_embarked()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "ba474d872b812497ec8db2a3e47cb5b14e7100cc", "_cell_guid": "b624e64f-0b13-41fc-a832-c2e94802df9b", "_execution_state": "idle", "trusted": false}, "source": "def process_cabin():\n    \n    global combined\n    \n    # replacing missing cabins with U (for Uknown)\n    combined.Cabin.fillna('U', inplace=True)\n    \n    # mapping each Cabin value with the cabin letter\n    combined['Cabin'] = combined['Cabin'].map(lambda c : c[0])\n    \n    # dummy encoding ...\n    cabin_dummies = pd.get_dummies(combined['Cabin'], prefix='Cabin')\n    \n    combined = pd.concat([combined,cabin_dummies], axis=1)\n    \n    combined.drop('Cabin', axis=1, inplace=True)\n    \nprocess_cabin()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "5e041762529b70b618bd72b10bc14749ea84bc48", "_cell_guid": "45c57242-5fa2-43f5-9776-96c71d9ad477", "_execution_state": "idle", "trusted": false}, "source": "combined.info()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "bd82689fc1c2f959ceeb4a0556ee32ec86643baf", "_cell_guid": "8627844c-c65e-4c0d-9f40-f631de6a87a8", "_execution_state": "idle", "trusted": false}, "source": "def process_sex():\n    \n    global combined\n    # mapping string values to numerical one \n    combined['Sex'] = combined['Sex'].map({'male':1,'female':0})\n    \nprocess_sex()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "1cfb136b4934855ff221e405b09e160514db7f41", "_cell_guid": "21f67fdd-7ec3-4f00-bd69-7bde6f0f5032", "_execution_state": "idle", "trusted": false}, "source": "def process_pclass():\n    \n    global combined\n    # encoding into 3 categories:\n    pclass_dummies = pd.get_dummies(combined['Pclass'], prefix=\"Pclass\")\n    \n    # adding dummy variables\n    combined = pd.concat([combined,pclass_dummies],axis=1)\n    \n    # removing \"Pclass\"\n    \n    combined.drop('Pclass',axis=1,inplace=True)\n\nprocess_pclass()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "02ca07ef42924e8441002c285f0348ce1240d81b", "_cell_guid": "9f6a77f2-4a29-48f4-b6a2-1920f33ac911", "_execution_state": "idle", "trusted": false}, "source": "def process_ticket():\n    \n    global combined\n    \n    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n    def cleanTicket(ticket):\n        ticket = ticket.replace('.','')\n        ticket = ticket.replace('/','')\n        ticket = ticket.split()\n        ticket = map(lambda t : t.strip(), ticket)\n        ticket = list(filter(lambda t : not t.isdigit(), ticket))\n        if len(ticket) > 0:\n            return ticket[0]\n        else: \n            return 'XXX'\n    \n\n    # Extracting dummy variables from tickets:\n\n    combined['Ticket'] = combined['Ticket'].map(cleanTicket)\n    tickets_dummies = pd.get_dummies(combined['Ticket'], prefix='Ticket')\n    combined = pd.concat([combined, tickets_dummies], axis=1)\n    combined.drop('Ticket', inplace=True, axis=1)\n\nprocess_ticket()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "c589eacc17d4fc06241e8303ee88a066903e980c", "_cell_guid": "6d728cef-583b-4a19-9ba0-1e2ba8c8daf7", "_execution_state": "idle", "trusted": false}, "source": "def process_family():\n    \n    global combined\n    # introducing a new feature : the size of families (including the passenger)\n    combined['FamilySize'] = combined['Parch'] + combined['SibSp'] + 1\n    \n    # introducing other features based on the family size\n    combined['Singleton'] = combined['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n    combined['SmallFamily'] = combined['FamilySize'].map(lambda s: 1 if 2<=s<=4 else 0)\n    combined['LargeFamily'] = combined['FamilySize'].map(lambda s: 1 if 5<=s else 0)\n    \nprocess_family()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "91ef8d499c47eb3461c00494f00c37dbc6eb238c", "_cell_guid": "6ca272c0-0acd-479a-9e70-56d54a5d7291", "_execution_state": "idle", "trusted": false}, "source": "combined.drop('PassengerId', inplace=True, axis=1)", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "bd6ad5d6ad381147f80951c7c96ed497e218fef7", "_cell_guid": "e7370001-c63e-4a27-bbb9-479954aa58b5", "_execution_state": "idle", "trusted": false}, "source": "combined.head()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "88aff1714c1bc0d0b797f4b297ba5b09575870fb", "_cell_guid": "9a0ef679-ffce-409e-8e06-47f52e6f6d64", "_execution_state": "idle", "trusted": false}, "source": "from sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.cross_validation import StratifiedKFold\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\nfrom sklearn.cross_validation import cross_val_score", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "f75baeffc34fb0ae0fb8044cdc6ea8f3237bf4db", "_cell_guid": "bd4a7d4b-49f8-44b4-b586-bccdbbcc7d36", "_execution_state": "idle", "trusted": false}, "source": "def compute_score(clf, X, y, scoring='accuracy'):\n    xval = cross_val_score(clf, X, y, cv = 5, scoring=scoring)\n    return np.mean(xval)", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "0df4d92b5923d0647c727d67dafb6a4e4628e38d", "_cell_guid": "a1ca3941-408e-4d9e-a759-0da06e0ecd5d", "_execution_state": "idle", "trusted": false}, "source": "def recover_train_test_target():\n    global combined\n    \n    train0 = pd.read_csv('../input/train.csv')\n    \n    targets = train0.Survived\n    train = combined.head(891)\n    test = combined.iloc[891:]\n    \n    return train, test, targets", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "b0d6589397a1c5abbc35fa2eaff8ac5916f0c016", "_cell_guid": "03d7cf98-a46f-481e-bf69-813b73d78e46", "_execution_state": "idle", "trusted": false}, "source": "train, test, targets = recover_train_test_target()", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "b0cdf15bcf20d983329ed57a0bc6c2475a587e2c", "_cell_guid": "79bf1412-967e-49d6-9b12-b8194d4cb939", "_execution_state": "idle", "trusted": false}, "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel\nclf = RandomForestClassifier(n_estimators=100, max_features='sqrt')\nclf = clf.fit(train, targets)", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "3c8a3c40eb9262356767a5da863e28f0617b37d3", "_cell_guid": "c051c3c2-e23d-4350-95db-db9f0572efb9", "_execution_state": "idle", "trusted": false}, "source": "features = pd.DataFrame()\nfeatures['feature'] = train.columns\nfeatures['importance'] = clf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "1c43c955774f62eeedb3e559535428f147cb6c46", "_cell_guid": "ae03bc1b-613f-48b8-b549-02a6fb8904a3", "_execution_state": "idle", "trusted": false}, "source": "features.plot(kind='barh', figsize=(20, 20))", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "e2c25c81a99f7bdf6bd7264f025539f517a0073e", "_cell_guid": "65a953cc-6691-4676-92de-44c5acfec653", "_execution_state": "idle", "trusted": false}, "source": "model = SelectFromModel(clf, prefit=True)\ntrain_reduced = model.transform(train)\ntrain_reduced.shape", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "425336a01b38e31984e5c9b09ddc71fbbfcdad72", "_cell_guid": "9498ed6f-8f35-4193-a2db-b059096f35a8", "_execution_state": "idle", "trusted": false}, "source": "test_reduced = model.transform(test)\ntest_reduced.shape", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "76fe8e6010f513a6b43561b925daf0c03df30555", "_cell_guid": "f694a57a-a148-4c43-999b-fd9c46209d16", "_execution_state": "idle", "trusted": false}, "source": "run_gs = False\n\nif run_gs:\n    parameter_grid = {\n                 'max_depth' : [4, 6, 8],\n                 'n_estimators': [50, 10],\n                 'max_features': ['sqrt', 'auto', 'log2'],\n                 'min_samples_split': [1, 3, 10],\n                 'min_samples_leaf': [1, 3, 10],\n                 'bootstrap': [True, False],\n                 }\n    forest = RandomForestClassifier()\n    cross_validation = StratifiedKFold(targets, n_folds=5)\n\n    grid_search = GridSearchCV(forest,\n                               scoring='accuracy',\n                               param_grid=parameter_grid,\n                               cv=cross_validation)\n\n    grid_search.fit(train, targets)\n    model = grid_search\n    parameters = grid_search.best_params_\n\n    print('Best score: {}'.format(grid_search.best_score_))\n    print('Best parameters: {}'.format(grid_search.best_params_))\nelse: \n    parameters = {'bootstrap': False, 'min_samples_leaf': 3, 'n_estimators': 50, \n                  'min_samples_split': 10, 'max_features': 'sqrt', 'max_depth': 6}\n    \n    model = RandomForestClassifier(**parameters)\n    model.fit(train, targets)", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "894db5277f3689377d7de3fe8a74e25ee7516726", "_cell_guid": "3b77bcff-7a10-46ae-9946-473cd1f07c0f", "_execution_state": "idle", "trusted": false}, "source": "compute_score(model, train, targets, scoring='accuracy')", "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": false, "_uuid": "cf0648fb5f1a467ec6c09fb39d5751a1894c255d", "_cell_guid": "de839631-9e5e-4b6f-85db-f91b155e73d1", "_execution_state": "idle", "trusted": false}, "source": "output = model.predict(test).astype(int)\ndf_output = pd.DataFrame()\naux = pd.read_csv('../input/test.csv')\ndf_output['PassengerId'] = aux['PassengerId']\ndf_output['Survived'] = output\ndf_output[['PassengerId','Survived']].to_csv('output.csv',index=False)", "cell_type": "code"}]}