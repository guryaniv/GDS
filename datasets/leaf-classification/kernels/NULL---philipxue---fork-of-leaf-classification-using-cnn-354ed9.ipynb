{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "12482422-20f6-7dff-3ea7-2c291af8f6d9"
      },
      "source": [
        "This is my first try to train a CNN network. Planed to use an Alex net, but found that it takes too long to train it on CPU. So I gived up and change to a LeNet-like CNN to get result faster. I started working on this on Sunday morning(2.26), took a day to complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ef465dc7-56c8-d52b-a82d-23467d8d7775"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Activation, Convolution2D, MaxPooling2D, Flatten, Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "46f890e3-ce52-079f-ad85-477a495ae1f3"
      },
      "source": [
        "# Reading data\n",
        "Read data from data_folder, and transform it into form demanded by keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f51e8ce2-626e-c062-3cbf-37f8635096a3"
      },
      "outputs": [],
      "source": [
        "data_root = \"../input/\"\n",
        "img_folder = data_root + 'images/'\n",
        "train_data = pd.read_csv(data_root + 'train.csv')\n",
        "train_ID = train_data['id']\n",
        "train_Y = train_data['species']\n",
        "test_data = pd.read_csv(data_root + 'test.csv')\n",
        "test_ID = test_data['id']\n",
        "\n",
        "le = LabelEncoder()\n",
        "train_y = le.fit_transform(train_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "245c8906-fc70-658a-c142-46e522e6bb20"
      },
      "source": [
        "# Preprocess img\n",
        "Downsize the img and change it into grayscale binary format to save memory.\n",
        "Centrelized the image data on the input matrices. This part I took [kaggle notebook][1] as reference.\n",
        "\n",
        "\n",
        "  [1]: https://www.kaggle.com/abhmul/leaf-classification/keras-convnet-lb-0-0052-w-visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "20aa2e94-8134-102d-4da3-656b1096ffaa"
      },
      "outputs": [],
      "source": [
        "def resize_img(img, max_dim=96):\n",
        "    large_axis = max((0, 1), key=lambda x: img.size[x])\n",
        "    scalar = max_dim / float(img.size[large_axis])\n",
        "    resized = img.resize(\n",
        "        (int(img.size[0] * scalar), int(img.size[1] * scalar)))\n",
        "    return resized\n",
        "\n",
        "\n",
        "def load_image_data(id_list, max_dim=96, center=True):\n",
        "    X = np.empty((len(id_list), max_dim, max_dim, 1))\n",
        "    for i, idnum in enumerate(id_list):\n",
        "        x = image.load_img(\n",
        "            (img_folder + str(idnum) + '.jpg'), grayscale=True)\n",
        "        x = image.img_to_array(resize_img(x, max_dim=max_dim))\n",
        "        height = x.shape[0]\n",
        "        width = x.shape[1]\n",
        "        if center:\n",
        "            h1 = int((max_dim - height) / 2)\n",
        "            h2 = h1 + height\n",
        "            w1 = int((max_dim - width) / 2)\n",
        "            w2 = w1 + width\n",
        "        else:\n",
        "            h1, w1 = 0, 0\n",
        "            h2, w2 = (height, width)\n",
        "        X[i, h1:h2, w1:w2, :] = x\n",
        "    return np.around(X / 255.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e793a0db-1799-d448-60a6-3fa4f80b12f4"
      },
      "source": [
        "# Build the Alexnet\n",
        "Build the Alexnet model based on descrption in [This blog (In Chinese)][1]\n",
        "\n",
        "\n",
        "  [1]: http://blog.csdn.net/sunbaigui/article/details/39938097"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c35846a3-5205-cd16-0822-50382f27930e"
      },
      "outputs": [],
      "source": [
        "def AlexNex(input_layer):\n",
        "    conv_1 = Convolution2D(96, 11, 11, activation='relu', input_shape=(\n",
        "        96, 96, 1), border_mode='same', name='conv1')(input_layer)\n",
        "    max_pool_1 = MaxPooling2D((3, 3), strides=(2, 2))(conv_1)\n",
        "\n",
        "    conv_2 = Convolution2D(256, 5, 5, border_mode='same',\n",
        "                           activation='relu')(max_pool_1)\n",
        "    max_pool_2 = MaxPooling2D((3, 3), strides=(2, 2))(conv_2)\n",
        "\n",
        "    conv_3 = Convolution2D(384, 3, 3, border_mode='same',\n",
        "                           activation='relu')(max_pool_2)\n",
        "    conv_4 = Convolution2D(384, 3, 3, border_mode='same',\n",
        "                           activation='relu')(conv_3)\n",
        "\n",
        "    conv_5 = Convolution2D(256, 3, 3, border_mode='same',\n",
        "                           activation='relu')(conv_4)\n",
        "    max_pool_5 = MaxPooling2D((3, 3), strides=(2, 2))(conv_5)\n",
        "\n",
        "    flat = Flatten()(max_pool_5)\n",
        "    dense_1 = Dense(4096, init='glorot_normal', activation='relu')(flat)\n",
        "    drop_1 = Dropout(0.5)(dense_1)\n",
        "\n",
        "    dense_2 = Dense(4096, init='glorot_normal', activation='relu')(drop_1)\n",
        "    drop_2 = Dropout(0.5)(dense_2)\n",
        "\n",
        "    output_layer = Dense(99, activation='softmax')(drop_2)\n",
        "\n",
        "    model = Model(input_layer, output_layer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1ab04b09-2a7f-656c-d7a9-73ad92461a69"
      },
      "source": [
        "But the training process is to slow, I start this on Sunday afternoon, and it took about 500 sec to train a epoch.\n",
        "\n",
        "    990/990 [==============================] - 548s - loss: 0.8667 - acc: 0.6970    \n",
        "    Epoch 17/50\n",
        "    128/990 [==>...........................] - ETA: 480s - loss: 0.7794 - acc: 0.7656\n",
        "    256/990 [======>.......................] - ETA: 408s - loss: 0.7746 - acc: 0.7617\n",
        "    384/990 [==========>...................] - ETA: 336s - loss: 0.7541 - acc: 0.7682\n",
        "    512/990 [==============>...............] - ETA: 265s - loss: 0.7583 - acc: 0.7715\n",
        "    640/990 [==================>...........] - ETA: 193s - loss: 0.7449 - acc: 0.7781[Cancelled]\n",
        "\n",
        "And 50 epoch seems not enough to convergent, so I gived up halfway and build another LeNet-like model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2966c4ab-9cc3-1467-dfb4-4b78ed97868d"
      },
      "outputs": [],
      "source": [
        "def NaiveCovNet(input_layer):\n",
        "    x = Convolution2D(8, 5, 5, input_shape=(96, 96, 1),\n",
        "                      border_mode='same')(input_layer)\n",
        "    x = (Activation('relu'))(x)\n",
        "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
        "\n",
        "    # Now through the second convolutional layer\n",
        "    x = (Convolution2D(32, 5, 5, border_mode='same'))(x)\n",
        "    x = (Activation('relu'))(x)\n",
        "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
        "\n",
        "    # Flatten our array\n",
        "    x = Flatten()(x)\n",
        "    dense_1 = Dense(1024, init='glorot_normal', activation='relu')(x)\n",
        "    drop_1 = Dropout(0.5)(dense_1)\n",
        "\n",
        "    dense_2 = Dense(99, init='glorot_normal', activation='relu')(drop_1)\n",
        "    drop_2 = Dropout(0.5)(dense_2)\n",
        "\n",
        "    output_layer = Dense(99, activation='softmax')(drop_2)\n",
        "    model = Model(input_layer, output_layer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0b5e9a90-32ee-1e71-c480-ab08c418091a"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(96, 96, 1), name='image')\n",
        "model = NaiveCovNet(input_layer)\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "trian_X = load_image_data(train_ID)\n",
        "train_y = to_categorical(train_y)\n",
        "\n",
        "history = model.fit(trian_X, train_y, nb_epoch=10, batch_size=128)\n",
        "#f_model = './model'\n",
        "#json_string = model.to_json()\n",
        "#open(os.path.join(f_model, 'model.json'), 'w').write(json_string)\n",
        "#print('save weights')\n",
        "#model.save_weights(os.path.join(f_model, 'model_weights.hdf5'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e03656a2-1702-8c7b-b8f9-caa751504052"
      },
      "source": [
        "This model took about 20 min to trian for 100 epoch, and get such result:\n",
        "\n",
        "    Epoch 91/100\n",
        "    990/990 [==============================] - 16s - loss: 0.0933 - acc: 0.9727\n",
        "    Epoch 92/100\n",
        "    990/990 [==============================] - 17s - loss: 0.0869 - acc: 0.9768\n",
        "    Epoch 93/100\n",
        "    990/990 [==============================] - 16s - loss: 0.0849 - acc: 0.9737\n",
        "    Epoch 94/100\n",
        "    990/990 [==============================] - 17s - loss: 0.0925 - acc: 0.9727\n",
        "    Epoch 95/100\n",
        "    990/990 [==============================] - 17s - loss: 0.0859 - acc: 0.9747\n",
        "    Epoch 96/100\n",
        "    990/990 [==============================] - 17s - loss: 0.0858 - acc: 0.9758\n",
        "    Epoch 97/100\n",
        "    990/990 [==============================] - 17s - loss: 0.0662 - acc: 0.9798\n",
        "    Epoch 98/100\n",
        "    990/990 [==============================] - 17s - loss: 0.0896 - acc: 0.9758\n",
        "    Epoch 99/100\n",
        "    990/990 [==============================] - 16s - loss: 0.0763 - acc: 0.9737\n",
        "    Epoch 100/100\n",
        "    990/990 [==============================] - 17s - loss: 0.0725 - acc: 0.9778\n",
        "    save weights\n",
        "\n",
        "It did prety well on training set so I save the weight for further use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "37b87822-e9c1-8af7-1f3e-10cbc7887c01"
      },
      "source": [
        "Predict and save result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0ecce33b-cdd3-ea88-cbe9-d6ba126b4db7"
      },
      "outputs": [],
      "source": [
        "#from keras.models import model_from_json\n",
        "#f_model = './model'\n",
        "#model_filename = 'cnn_model.json'\n",
        "#weights_filename = 'cnn_model_weights.hdf5'\n",
        "#json_string = open(os.path.join(f_model, model_filename)).read()\n",
        "#model = model_from_json(json_string)\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "#model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#model.load_weights(os.path.join(f_model,weights_filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b19d0946-3adc-6916-c371-ce71e519ba7a"
      },
      "outputs": [],
      "source": [
        "X_test = load_image_data(test_ID)\n",
        "CNN_pred = model.predict(X_test)\n",
        "LABELS = sorted(pd.read_csv(os.path.join(data_root, 'train.csv')).species.unique())\n",
        "save_File = pd.DataFrame(CNN_pred,index=test_ID,columns=LABELS)\n",
        "save_File.to_csv(\"submission.csv\", index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a578f054-7df6-6bb9-df0d-d15fa3b53964"
      },
      "source": [
        "This is my first time try out CNN method, the result is not ideal, and I plan to improve it with the following method:\n",
        "\n",
        " - Apply data augment to training set. 990 examples is far from enough,\n",
        "   maybe I should try keras pre-built method ImageDataGenerator. \n",
        " - Use a machine with GPU and use model like VGG-16 net or Resnet. \n",
        " - I have found many pretrained model based on imagenet on Internet. Modify some top layers and fin-tuned them could have better output.\n",
        " - Use CNN to extract feathers and combined it with other manully selected feather in dataset.\n",
        "\n",
        "This is just a learning process of buliding and training CNN network so I didn't focus on getting better socre and utlizing avalible data."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}