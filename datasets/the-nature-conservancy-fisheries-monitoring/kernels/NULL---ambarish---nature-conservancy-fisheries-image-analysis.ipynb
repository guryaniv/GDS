{"cells":[{"metadata":{"_uuid":"27e18b498612bd35d5eb3ef43cdcbe2aefc801b4"},"cell_type":"markdown","source":"# Plan"},{"metadata":{"_uuid":"0d568f79be0d15d7b2e5c70f224aa628b9ce9fa2"},"cell_type":"markdown","source":"*  **Xplore the files**           \nExaminations of the files present in the Dataset is done in this section                \n*  **Labels analysis**\nLabels analysis of the labels found in the Train dataset            \n*  **Creating the One Hot Encoding of the labels**  \nThis is a `Multilabel Classification` problem , hence a One Hot Encoding of the labels need to be done          \n*   **Create the Data Generators**                   \nCreate the Train , Test Data Generators             \n* **Flow from DataFrame**     \nThis section defines the functions so that the paths \n* **Model Creation**\nThis is the section where the Actual Model is built\n* **Test Data Preparation**     \nThe Test Data is prepared so that it can be sent to the Model\n* **Map Predictions**\nThe predictions are mapped for the Submission File\n"},{"metadata":{"_uuid":"af8a76b1aacd7bb55efb9f50b2ef5a7cbb22ee91"},"cell_type":"markdown","source":"# Xplore the files"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"from os import listdir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af1501a985e9dbb82e708f72fc7656289bd57715"},"cell_type":"code","source":"train_path ='../input/train/'\nlistdir(train_path)[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fc850809443c5ffb5fd2331b8cce2cf8442de96"},"cell_type":"code","source":"len(listdir(train_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"701d9a298769fc3c21b089e767ea21dc47077643"},"cell_type":"code","source":"test_path = '../input/test_stg1/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1a97b00a46d82e22e24c5c12a8f21c0c2521a30"},"cell_type":"code","source":"listdir(test_path)[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea10f5beff406b57ba6b3eec0600430a246f41cb"},"cell_type":"code","source":"len(listdir(test_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4022986cebc17693fe04150540815123547f6e63"},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission_stg1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cbacb01d35641558b89f91a2a70a2893fdd5789"},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"211eb906eb0558e5f2a21686dcdb904167b97d60"},"cell_type":"markdown","source":"# Labels analysis"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"987eecaa6727b7dbf07de7014f2a3928dc76736e"},"cell_type":"code","source":"from tqdm import tqdm\ndef loadBatchImages(path):\n    catList = listdir(path)\n    loadedImages = []\n    loadedLabels = []\n    for cat in catList:\n        if not cat.startswith('.'):\n            deepPath = path+cat+\"/\"\n            imageList = listdir(deepPath)\n            for images in tqdm(imageList):\n                img = deepPath + images\n                loadedLabels.append(cat)\n                loadedImages.append(img)\n            \n    return loadedImages, loadedLabels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"912c64b798b695a2da8f3dac675cd7be96573345"},"cell_type":"code","source":"loadedImages, loadedLabels = loadBatchImages(train_path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2aaa9276cf69b3fbdc35363cb1f49f493edfcf1b"},"cell_type":"markdown","source":"# Creating the OHE vector for the labels"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"22e9890c26dc504e236030fde99371fd3c8d3832"},"cell_type":"code","source":"num_classes = len(np.unique(loadedLabels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"349355a7d7b0c4761063d2484cecd4ec7d6c0a40"},"cell_type":"code","source":"num_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"185c9871a088fc0f5db6cd9b7a79cba70b7dc6b5"},"cell_type":"code","source":"#Encode labels with value between 0 and n_classes-1.\nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nloadedLabels = np.asarray(loadedLabels)\nencoder.fit(loadedLabels)\nencoded_loadedLabels = encoder.transform(loadedLabels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f21507e19e689111b04ec8aa89955d91b8d19acb"},"cell_type":"code","source":"# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical\nlabels_Hot = to_categorical(encoded_loadedLabels, num_classes = num_classes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb1d45e6d1caead98165d4051834ab4da61a88d7"},"cell_type":"markdown","source":"# Create Data Generators"},{"metadata":{"trusted":true,"_uuid":"9da53fb8604edba62e83842fdd11a1983bb1e85b","collapsed":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (128, 128)\ncore_idg = ImageDataGenerator(samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.05, \n                              width_shift_range=0.1, \n                              rotation_range=5, \n                              shear_range = 0.1,\n                              fill_mode = 'reflect',\n                              zoom_range=0.15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbb6a97c4211dfae2d9bca44d5b25f121c7269f3","collapsed":true},"cell_type":"markdown","source":"# Create the Dataframe for the Datagenerators"},{"metadata":{"trusted":true,"_uuid":"094f0c1da9f7276f991b2eadf268980fda2f05e6"},"cell_type":"code","source":"df= pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"781e95e1492d9b5b2dcc1dc5c13fc1d0bb863af8"},"cell_type":"code","source":"df['path']=loadedImages\ndf['labels'] = list(labels_Hot)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"221520b0a344b653526ad347a8fb2a2fd1ed86fa"},"cell_type":"markdown","source":"# Flow from DataFrame"},{"metadata":{"trusted":true,"_uuid":"0de64213c0c9519a78044f87368018f8eeafeb30","collapsed":true},"cell_type":"code","source":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f13f3832c5ba8af743ac4cbaec3c6aafec95868"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(df, \n                                   test_size = 0.25, \n                                   random_state = 2018)\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccc19f3a4261b67f3dc99182d7eb2aa3a48d23a5"},"cell_type":"code","source":"train_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'labels', \n                            target_size = IMG_SIZE,\n                            batch_size = 128)\n\nvalid_gen = flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'labels', \n                            target_size = IMG_SIZE,\n                            batch_size = 256) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'labels', \n                            target_size = IMG_SIZE,\n                            batch_size = 1024)) # one big batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"049d9457989e9974da38497be9f166416c9e0a33","collapsed":true},"cell_type":"code","source":"t_x, t_y = next(train_gen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"610d0d5de448838d807fab7132519bdd2d807ef1"},"cell_type":"code","source":"t_x.shape[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d3dedadc8536ba321fb5be517112f80c8022e70f"},"cell_type":"code","source":"img_dim = t_x.shape[1:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc2e1461499a165aab6c16f4bb4534a4ae57292b"},"cell_type":"markdown","source":"# Vgg16"},{"metadata":{"trusted":true,"_uuid":"c4334a19c1d1a6712bd39ef45cb99ab2e916654d","collapsed":true},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, Flatten, Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom sklearn.metrics import fbeta_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b9c6c6c68b51f97ce37716ae829c3cea97f291a"},"cell_type":"code","source":"num_classes = len(labels_Hot[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"292d6e80fcea5658780ad318ef0f9726c027c6fa"},"cell_type":"code","source":"num_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02a0a1d8f782adcaa90d09a96a917d30bd692b2f"},"cell_type":"code","source":"input_tensor = Input(shape=img_dim)\nbase_model = VGG16(include_top=False,input_shape=img_dim)\n    \nbn = BatchNormalization()(input_tensor)\nx = base_model(bn)\nx = Flatten()(x)\noutput = Dense(num_classes, activation='softmax')(x)\nmodel = Model(input_tensor, output)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2288cec216db3e4e3e4f29f537ac12820b03c40","collapsed":true},"cell_type":"markdown","source":"# Finetune Vgg16"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6d1f9dd2946234f86317d631416483bca0232b1b"},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, History\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f8653b5e8b9d3929ff6bf5891e2307f73760ae2","collapsed":true},"cell_type":"code","source":"history = History()\ncallbacks = [history, \n             EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=0, min_lr=1e-7, verbose=1),\n             ModelCheckpoint(filepath='weights.best.hdf5', verbose=1, save_best_only=True, \n                             save_weights_only=True, mode='auto')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b7e4bc29dc45b3521acdd865d5c963eb89c7389","collapsed":true},"cell_type":"code","source":"model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d1fbedd68038da15701f72af6de2dc5d2c0babab"},"cell_type":"code","source":"batch_size = 128\nsteps_per_epoch = len(train_df)/batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ff39f5b189fc81dea8c00f44f3304a207362143"},"cell_type":"code","source":"steps_per_epoch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"747f5812a93f8ac0497ce28623aac1e24dffab9f"},"cell_type":"code","source":"model.fit_generator(train_gen,steps_per_epoch=steps_per_epoch,validation_data = (test_X, test_Y), \n                                  epochs = 25,callbacks = callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f965078a0702c61ec632642af2da0c0dcde0fa4d","collapsed":true},"cell_type":"code","source":"model.load_weights('weights.best.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3711a5a7c46d3e7e0b5179e69d3f1450f2e9cc8"},"cell_type":"markdown","source":"# Test Data Preparation"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"267fa338077b1d62f90e888abc23451ec3dfb03a"},"cell_type":"code","source":"import glob\nfrom glob import glob\ntest_image_paths = glob(test_path +'*.jpg', recursive=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7a556d8d0d28b4a4ce8071b727def1b8175312e"},"cell_type":"code","source":"test_image_paths[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"acd663c17035c43635753ea75636926c6e3e6294"},"cell_type":"code","source":"X_test = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"883088b6ad9931c95364c7b4d3d7acc278cfa11d"},"cell_type":"code","source":"X_test['path'] = test_image_paths","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ea3daec7ef14a12d983495ea03034e7302f5c22a"},"cell_type":"code","source":"X_test['image'] = X_test['path'].map(lambda x: os.path.splitext(os.path.basename(x))[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"246ea3244951b7dd38aa5f40279257b857d9e020"},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae4fd315e93c5ea531dd3dc665a734d3512d04f9"},"cell_type":"code","source":"test_gen = flow_from_dataframe(core_idg, X_test, \n                             path_col = 'path',\n                            y_col = 'image', \n                            target_size = IMG_SIZE,\n                            batch_size = 256) # we can use much larger batches for evaluation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7999676f07f524ac15a241c45a6c7fceef81d5d8"},"cell_type":"code","source":"pred_Y =  model.predict_generator(test_gen,verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f787b3e1b338509c1f8d0832cec4c7c6b58bf530"},"cell_type":"code","source":"len(pred_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed2e172ee676ce81bc1a6ed760b2c86b608919f7"},"cell_type":"code","source":"pred_Y[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"12c5fe97d389866137f0dab028c0521143af2576"},"cell_type":"code","source":"submission = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fbb4e0458005b57c1fb419647e0c00a3b7ed5d7"},"cell_type":"code","source":"X_test['image'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"28d35f33ddeb5cf19e212a2372029c31693b527f"},"cell_type":"code","source":"submission['image'] = X_test['image']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd6a104e1aa68436c4355c7545e5e0dc80f01e2d"},"cell_type":"code","source":"unique_labels = np.unique(loadedLabels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eea5f15d6b64b36bd840980259275fac9ec23617"},"cell_type":"code","source":"unique_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e2eeddc4aae0d553769fe37b5c4fdc1b3dce5f9"},"cell_type":"code","source":"encoder.fit(unique_labels)\nencoder.transform(unique_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49ee35df15a64cda982ab4f45a4ca66ca7b4bbfd"},"cell_type":"code","source":"for i,label in enumerate(list(unique_labels)):\n    print(i,label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"93669f30cace60afdf2a5a93748dd54fa5f550dd"},"cell_type":"code","source":"for i,label in enumerate(list(unique_labels)):\n    submission[label] = pred_Y[:,i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04ac45067e5d32f50c6d24057794771b3298eb37"},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1076f5767dcba818cec6e06e208592b7b9af2fa7"},"cell_type":"code","source":"submission.to_csv('predictions.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}