{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"trusted":false},"cell_type":"markdown","source":"# 1. Introduction\nSince there are not a lot of data in our trainset, let us create some more. The basic idea here is simple: a guitar + another guitar = still a guitar. What I will try is to add the audio signal and check the result.\n\nThis kernel is still a work in progress, so far I was lucky to have no values out of range of the 16bits audio file, but I will have to check for this in later versions."},{"metadata":{"_uuid":"ead7077c515079f451bdad63d886b8105543c21c"},"cell_type":"markdown","source":"# 2. Mixing Two Audio Files\n## 2.1 A First Try on Two Files\n\nLet us take two audio files and add there signal. Here, I take two different sounds (a trumpet and a cello).\n"},{"metadata":{"trusted":true,"_uuid":"7308b565e5f2addb2ed07d65261caa2a62992343"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nlabels = pd.read_csv('../input/train.csv')\nlabels[labels['label'] == 'Trumpet'].head()","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd2a55c329e47bd360fef973b22b7bea6f0e6ac2"},"cell_type":"code","source":"labels[labels['label'] == 'Cello'].head()","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"a9c210303a0949d671b6a80bb37e70705ce8e234"},"cell_type":"markdown","source":"Let us listen to this separately."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"361aa641265f1cfbf16f9bfe47e4f481b8daa986"},"cell_type":"code","source":"trumpet = '034e4ffa'\ncello = '00353774'","execution_count":19,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ea39f065476bb1c495f1efa8906fe6ab5b3a6ea"},"cell_type":"code","source":"import IPython.display as ipd  # To play sound in the notebook\nt_fname = '../input/audio_train/' + trumpet + '.wav'\nipd.Audio(t_fname)\n","execution_count":25,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9133e6d8b3890b3fcaa2d694ff4f2a4fa8544117"},"cell_type":"code","source":"import IPython.display as ipd  # To play sound in the notebook\nc_fname = '../input/audio_train/' + cello + '.wav'\nipd.Audio(c_fname)","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"c3bcce8bb0e07b7da3ebb24d982c1ef871ce052a"},"cell_type":"markdown","source":"It is now time to add signals."},{"metadata":{"trusted":true,"_uuid":"34a710f759595577974bf9f4cc7b6de7c5666d73"},"cell_type":"code","source":"from scipy.io import wavfile\nrate, t_signal = wavfile.read(t_fname)\nrate, c_signal = wavfile.read(c_fname)\n\nmin_len = min(len(t_signal),len(c_signal))\n\nt_signal = np.array([(e/2**16.0)*2 for e in t_signal]) #16 bits tracks, normalization\nc_signal = np.array([(e/2**16.0)*2 for e in c_signal])\n\nt_signal = t_signal[:min_len]\nc_signal = c_signal[:min_len]\n\nnew_sig = t_signal + c_signal\n\nnew_sig_16b = np.array([int((v*2**16.0)/2) for v in new_sig])\nplt.plot(new_sig_16b)\n\nipd.Audio(new_sig_16b,rate=44100)\n\n","execution_count":47,"outputs":[]},{"metadata":{"_uuid":"18578f38cd564860390289210bae97ecd62cc6ec"},"cell_type":"markdown","source":"I have heard more harmonious things in my life, but still we here distincly a cello and a trumpet. Let us try with two acoustic guitars.\n\n## 2.3 Same Example with Twice the Same Label"},{"metadata":{"trusted":true,"_uuid":"37bab433a459444c6af6919278f5dabfdf346158"},"cell_type":"code","source":"labels[labels['label'] == 'Acoustic_guitar'].head()","execution_count":52,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f24e32d619055d8ff20c7d3c535b3a532fc8b7b"},"cell_type":"code","source":"g1 = '0356dec7'\ng1_fname = '../input/audio_train/' + g1 + '.wav'\nipd.Audio(g1_fname)","execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6224ad2beffafd25cb862b8b40a19296b697609"},"cell_type":"code","source":"g2 = '0969b5c5'\ng2_fname = '../input/audio_train/' + g2 + '.wav'\nipd.Audio(g2_fname)","execution_count":59,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b9eaed26456dcb277da8c8e73f844b07cb9ffe8"},"cell_type":"code","source":"rate, g1_signal = wavfile.read(g1_fname)\nrate, g2_signal = wavfile.read(g2_fname)\n\nmin_len = min(len(g1_signal),len(g2_signal))\n\ng1_signal = np.array([(e/2**16.0)*2 for e in g1_signal]) #16 bits tracks, normalization\ng2_signal = np.array([(e/2**16.0)*2 for e in g2_signal])\n\ng1_signal = g1_signal[:min_len]\ng2_signal = g2_signal[:min_len]\n\nnew_sig = g1_signal + g2_signal\n\nnew_sig_16b = np.array([int((v*2**16.0)/2) for v in new_sig])\ng1_sig_16b = np.array([int((v*2**16.0)/2) for v in g1_signal])\ng2_sig_16b = np.array([int((v*2**16.0)/2) for v in g2_signal])\nplt.plot(new_sig_16b)\n\nipd.Audio(new_sig_16b,rate=44100)","execution_count":77,"outputs":[]},{"metadata":{"_uuid":"201dfe592bcba745604d3588d25a3b27106a43d7"},"cell_type":"markdown","source":"I won't speculate on the accord we got here, but to me, we clearly have two guitars. Let's check this on a spectrogram."},{"metadata":{"trusted":true,"_uuid":"5442cf14732a8b331f3c9fd381a8384326c393b3"},"cell_type":"code","source":"\n\nfrom scipy import signal\n#data\nfreqs, times, specs = signal.spectrogram(new_sig,\n                                         fs=44100,\n                                         window=\"boxcar\",\n                                        nperseg=13230,\n                                        noverlap=0,\n                                        detrend=False,\n                                        mode = 'complex')\nfreqs, times, specs1 = signal.spectrogram(g1_signal,\n                                         fs=44100,\n                                         window=\"boxcar\",\n                                        nperseg=13230,\n                                        noverlap=0,\n                                        detrend=False,\n                                        mode = 'complex')\nfreqs, times, specs2 = signal.spectrogram(g2_signal,\n                                         fs=44100,\n                                         window=\"boxcar\",\n                                        nperseg=13230,\n                                        noverlap=0,\n                                        detrend=False,\n                                        mode = 'complex')\n\nmax_freq = 1000\nplt.plot(freqs[:max_freq],np.absolute(specs[:max_freq,1]),'r')\nplt.plot(freqs[:max_freq],np.absolute(specs1[:max_freq,1]),'bo')\nplt.plot(freqs[:max_freq],np.absolute(specs2[:max_freq,1]),'gx')","execution_count":89,"outputs":[]},{"metadata":{"_uuid":"1319729155ec7678155b010e857d4062316ba549"},"cell_type":"markdown","source":"The spectrum of the two signals in red is clearly the mix of the individual signals (green and blue). It seems that we have a new datapoint here.\n\nNow, let us wrap a function to generate infinitely many new audio signals.\n\n# Wrapper\n\nWIP"}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}