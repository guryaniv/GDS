{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ac006717-5705-74b4-80a2-00bc36f7cb78"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "\n",
        "import kagglegym\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "daec93da-1ee2-6ce5-1cc0-23609d6da842"
      },
      "outputs": [],
      "source": [
        "# Here's an example of loading the CSV using Pandas's built-in HDF5 support:\n",
        "import pandas as pd\n",
        "\n",
        "with pd.HDFStore(\"../input/train.h5\", \"r\") as train:\n",
        "    # Note that the \"train\" dataframe is the only dataframe in the file\n",
        "    df = train.get(\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6eb23e87-7836-bec5-cf3a-3d3899cc2196"
      },
      "outputs": [],
      "source": [
        "# Create an environment\n",
        "env = kagglegym.make()\n",
        "\n",
        "# Get first observation\n",
        "observation = env.reset()\n",
        "\n",
        "# Get the train dataframe\n",
        "train = observation.train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c8ed09fc-c200-abea-d1bb-6f441375bb58"
      },
      "outputs": [],
      "source": [
        "def getidtraindata(instrument):\n",
        "    return train.loc[train.id==instrument,:]\n",
        "\n",
        "train10 = getidtraindata(11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "71827b07-b20e-d7cf-59f2-92ca31013ca1"
      },
      "outputs": [],
      "source": [
        "def scale(values):\n",
        "    new_values = []\n",
        "    for value in values:\n",
        "        new_value = (value - values.min())/(values.max()-values.min())\n",
        "        new_values.append(new_value)\n",
        "    return new_values\n",
        "\n",
        "def scale_all_features(data):\n",
        "    scaled_data = pd.DataFrame(data.timestamp)\n",
        "    for col, old_values in data.iteritems():\n",
        "        if col not in ['id','timestamp','y']:\n",
        "            scaled_data[str(col)] = scale(old_values)\n",
        "    return scaled_data\n",
        "\n",
        "scaled_train10 = scale_all_features(train10)\n",
        "scaled_train10.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d87474f4-af3c-0f90-379b-2bfb0ae21a8e"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "for col, values in scaled_train10.iteritems():\n",
        "    if col not in ['id','timestamp','y']:\n",
        "        plt.plot(scaled_train10.timestamp, values, '.')\n",
        "plt.xlabel('timestamp')\n",
        "plt.ylabel('scaled feature values')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "69b0ac3f-9695-68ac-e9d6-711c4c5f3ebe"
      },
      "outputs": [],
      "source": [
        "def find_groups(features, data, limit):\n",
        "    groups = []\n",
        "    singles = []\n",
        "    for col in features:\n",
        "        group = []\n",
        "        for feature in features:\n",
        "            coeff = np.corrcoef(data[col].values, data[feature].values)[0,1]\n",
        "            coeff = np.round(coeff, decimals=2)\n",
        "            if coeff >= limit:\n",
        "                group.append(feature)\n",
        "        for member in group:\n",
        "            while member in features:\n",
        "                features.remove(member)\n",
        "        if len(group) > 1:\n",
        "            groups.append(group)\n",
        "        elif len(group) == 1:\n",
        "            singles.append(col)\n",
        "    return groups, singles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f3236b9-9f1e-a078-6732-97d5a47a50c8"
      },
      "outputs": [],
      "source": [
        "features = [col for col in scaled_train10.columns if col not in ['id','timestamp','y']]\n",
        "groups, singles = find_groups(features, scaled_train10, 0.90)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "22aa39dd-1f91-f6e2-5519-9fde90771d8d"
      },
      "outputs": [],
      "source": [
        "softgroups, residuals = find_groups(singles, scaled_train10, 0.80)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0a6cd9fe-5fb1-7306-61b4-280dc53f7eb1"
      },
      "outputs": [],
      "source": [
        "def show_group_dynamic(group, data):\n",
        "    plt.figure()\n",
        "    for member in group:\n",
        "        values = data.loc[:, member]\n",
        "        plt.plot(data.timestamp, values, '.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0057b744-22b9-6e42-c87a-6a46362410fa"
      },
      "outputs": [],
      "source": [
        "show_group_dynamic(groups[0], scaled_train10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6f50f38c-88b8-350c-7289-664f88a41072"
      },
      "outputs": [],
      "source": [
        "groups[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "66ed9d23-4cff-14fd-7f77-38d6c9a609ba"
      },
      "outputs": [],
      "source": [
        "def get_group_mean_values(group, data):\n",
        "    member = group[0]\n",
        "    table = pd.DataFrame(data[member].values, columns=[member])\n",
        "    for index in range(1, len(group)):\n",
        "        member = group[index]\n",
        "        table[member] = pd.DataFrame(data[member].values, columns=[member])\n",
        "    mean_values = table.mean(axis=1).values\n",
        "    return mean_values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "222c578f-f0b5-75b9-46b5-146a11ee87e2"
      },
      "outputs": [],
      "source": [
        "def show_mean_feature_groups(groups, data, y_values):\n",
        "    plt.figure()\n",
        "    for index in range(0, len(groups)):\n",
        "        mean_values = get_group_mean_values(groups[index], data)\n",
        "        plt.plot(scaled_train10.timestamp, mean_values, '.-') \n",
        "    plt.plot(scaled_train10.timestamp, y_values)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "837b8da8-e294-d90d-81f7-1bc4fe148fe8"
      },
      "outputs": [],
      "source": [
        "y_scaled = scale(train10.y.values)\n",
        "show_mean_feature_groups(groups, train10, train10.y.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c2fec873-872b-6682-ec09-eeb78729b83d"
      },
      "outputs": [],
      "source": [
        "def get_y_groups_correlations(y, groups, data):\n",
        "    all_coeff = []\n",
        "    for index in range(0, len(groups)):\n",
        "        mean_values = get_group_mean_values(groups[index], data)\n",
        "        coeff = np.corrcoef(y, mean_values)[0,1]\n",
        "        all_coeff.append(coeff)\n",
        "    return all_coeff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f4de6514-feea-0be7-e5ce-8e0aa794d188"
      },
      "outputs": [],
      "source": [
        "y = train10.y.values\n",
        "corr_y_groups = get_y_groups_correlations(y, groups, train10)\n",
        "corr_y_groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "01ac7626-d9d6-bbfa-a608-830ad97f5f38"
      },
      "outputs": [],
      "source": [
        "groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aa6b1b80-c131-84d8-1d76-bc1a73eae5d8"
      },
      "outputs": [],
      "source": [
        "def prepare_features(groups, data):\n",
        "    nr_timestamps = len(data.timestamp)\n",
        "    X = np.zeros(shape=(nr_timestamps,len(groups)))\n",
        "    for index in range(0, len(groups)):\n",
        "        X[:, index] = get_group_mean_values(groups[index], data)\n",
        "    return X\n",
        "\n",
        "X = prepare_features(groups, train10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "89e227fa-1b7a-9189-3c8b-5f8a9ce0fdb5"
      },
      "outputs": [],
      "source": [
        "net = MLPRegressor(hidden_layer_sizes=(50,), solver=\"lbfgs\", activation=\"logistic\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "42bac1d4-f219-44d3-1012-f4629d91489a"
      },
      "outputs": [],
      "source": [
        "net.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a79a625-4c71-9956-0a7a-fba81967bf8d"
      },
      "outputs": [],
      "source": [
        "len(train10.timestamp.unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "19856986-3cc6-c4e9-0c5e-223f8db992cb"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bfa3af40-520a-2022-87c2-f1827f4ab45f"
      },
      "outputs": [],
      "source": [
        "df[ (df[\"id\"]==11) & (df[\"timestamp\"]==(len(scaled_train10.timestamp.unique()) + 1))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f6446689-704a-e366-bec8-e902c7c4d6bf"
      },
      "outputs": [],
      "source": [
        "def get_target_features(data, groups, instrument):\n",
        "    X = []\n",
        "    for group in groups:\n",
        "        group_values = np.zeros(len(group))\n",
        "        index = 0\n",
        "        for col in group:\n",
        "            group_values[index] = data.loc[data.id==instrument, col]\n",
        "            index += 1\n",
        "        group_values = np.array(group_values)\n",
        "        X.append(group_values.mean())\n",
        "    return np.array(X)\n",
        "            \n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dcdf434a-766e-ae31-7432-a57f3a10f0b2"
      },
      "outputs": [],
      "source": [
        "groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b4aa7d4e-c9f7-9bb5-e0b9-8fe473712cc1"
      },
      "outputs": [],
      "source": [
        "x_p = get_target_features(observation.features, groups, 11)\n",
        "x_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "28ffbd4f-cb95-8a18-d5aa-ce8a8223f16b"
      },
      "outputs": [],
      "source": [
        "x_p = x_p.reshape(1,-1)\n",
        "y_p = net.predict(x_p)\n",
        "y_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c21a9e42-bd38-9f55-6c43-72b7258a0bdd"
      },
      "outputs": [],
      "source": [
        "perfect_y = df[ (df[\"id\"]==11) & (df[\"timestamp\"]==(len(scaled_train10.timestamp.unique()) + 1))].y\n",
        "perfect_y"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}