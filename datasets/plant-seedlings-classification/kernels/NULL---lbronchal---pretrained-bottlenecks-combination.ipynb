{"cells":[{"metadata":{"_uuid":"e1f40911a481df3e28c2b226c7b4b72be4012a27"},"cell_type":"markdown","source":"## Summary\nWe have tried different pretrained models (Xception, Vgg16, Rest50) to obtain bottleneck features and build a new model. The best performance has been obtained combining the bottlenecks of all of these models. "},{"metadata":{"_uuid":"ca8e5ca8102ae39997c03f4fe1bb82f630357012"},"cell_type":"markdown","source":"## Data loading and fast analysis"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.simplefilter(\"ignore\", category=FutureWarning)\n\nimport os\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport random as rn\nfrom keras import backend as K\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, f1_score\n","execution_count":56,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"os.environ['PYTHONHASHSEED'] = '0'\n\nSEED = 1\nnp.random.seed(SEED)\nrn.seed(SEED)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"87c67db6467f059a90033925a170627b7c9982b3"},"cell_type":"code","source":"data_dir = \"../input/plant-seedlings-classification/\"\n\nimg_rows, img_cols, img_channel = 117, 117, 3\ntarget_size = (img_rows, img_cols)\ntarget_dims = (img_rows, img_cols, img_channel) # add channel for RGB\nn_classes = 12\nval_frac = 0.1\nbatch_size = 256\n\nLAYERS_TO_FREEZE = 18","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a5988f3d41c7f4b1d8edbc30393e7d2a56101f28"},"cell_type":"code","source":"import cv2\nfrom glob import glob\nfrom matplotlib import pyplot as plt\nfrom numpy import floor\nimport random","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bc492a3e7b62c9e33276dd84dd51d11cb798c81","collapsed":true},"cell_type":"code","source":"base_path = os.path.join(data_dir, \"train\")\nclasses = os.listdir(base_path)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7b9f99a874f3ca4863d01dd3bcee70d91786f20e"},"cell_type":"code","source":"sample_images = []\nplants = {}\nfor plant in classes:\n    img_path = os.path.join(base_path, plant, '**') \n    path_contents = glob(img_path)\n    total_plants = len(path_contents)\n    plants[plant] = total_plants\n    img = random.sample(path_contents, 1)\n    sample_images.append(img)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"bd2f9bc8315d9acb10c5c4a9e97e524a78b8e6d9"},"cell_type":"markdown","source":"Let's check some images:"},{"metadata":{"trusted":true,"_uuid":"2bbad2c59ee21ffcd5098ed80aa021bccfb7981b"},"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\nfor i in range(0, 12):\n    fig.add_subplot(4, 4, i+1)\n    fig.tight_layout()\n    img = cv2.imread(sample_images[i][0])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)     \n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(classes[i])    \nplt.show()","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"f8fe90a18e506137d251a9b5496e633642703f58"},"cell_type":"markdown","source":"The dataset is not full balanced:"},{"metadata":{"trusted":true,"_uuid":"471b99d473ecfe762018799874f6e1a2b2e63167"},"cell_type":"code","source":"plt.figure(figsize=(10, 8))\nplt.title(\"Number of cases per fruit (Training data)\")\nplt.bar(range(n_classes), list(plants.values()))\nplt.xticks(range(n_classes), classes, rotation=90)\nplt.show()","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d5fca1c793d162a2e1ced9594269f98d4e60663"},"cell_type":"code","source":"print(\"width: {} | length: {} | min value: {} | max value: {}\".format(img.shape[0], img.shape[1], img.min(), img.max()))","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"b593be61da0087c3dd35e974c98e73e750cc6e56"},"cell_type":"markdown","source":"## Models"},{"metadata":{"trusted":true,"_uuid":"eed915b0156502475584831d0607eaf9dd59b687","collapsed":true},"cell_type":"code","source":"from keras.layers import Conv2D, Dense, Dropout, Flatten, BatchNormalization\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras import applications\nfrom keras.models import Sequential, Model, load_model\nfrom keras import applications\nfrom keras import optimizers\nfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e3c378e60d83409937c86a83fcb5749b57096f02"},"cell_type":"code","source":"cache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\n\n# Create symbolic links for trained models.\nmodels_symlink = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_symlink):\n    os.symlink('/kaggle/input/keras-pretrained-models/', models_symlink)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b0d14fd06cc271116e95c9bf74c8c6f1ffa7530","collapsed":true},"cell_type":"code","source":"def create_generators(preprocess_input, data_path, target_size, batch_size, seed=1):\n    data_augmentor = ImageDataGenerator(preprocessing_function=preprocess_input,\n                                        validation_split=0.2)  \n    \n    train_generator = data_augmentor.flow_from_directory(data_path, \n                                                     target_size=target_size, \n                                                     batch_size=batch_size, \n                                                     subset=\"training\", \n                                                     shuffle=False, seed=seed)\n    val_generator = data_augmentor.flow_from_directory(data_path, \n                                                       target_size=target_size, \n                                                       batch_size=batch_size, \n                                                       subset=\"validation\", \n                                                       shuffle=False, \n                                                       seed=seed)\n    return train_generator, val_generator\n","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"78ff103cb8a43defa1c3d7454f80903e13bf20a1"},"cell_type":"code","source":"SEED_NN = 123456\nnp.random.seed(SEED_NN)\nrn.seed(SEED_NN)\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\ntf.set_random_seed(SEED_NN)\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\nK.set_session(sess)    ","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"e6c004f5a79321434166449a47b5b27fac17ec38"},"cell_type":"markdown","source":"## Xception bottleneck"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dff73da3c260d685315d39048ae72a4acd1fa652"},"cell_type":"code","source":"def get_bottleneck_xception(data_path, target_dims, batch_size, seed=SEED):\n    preprocess_input = applications.xception.preprocess_input    \n    img_rows, img_cols, img_channel = target_dims\n    target_size = (img_rows, img_cols)\n    target_dims = (img_rows, img_cols, img_channel) \n    train_generator, val_generator = create_generators(preprocess_input, data_path, target_size, batch_size, seed=SEED)\n    \n    model_xception = applications.Xception(weights='imagenet', \n                                           include_top=False, \n                                           pooling='avg',\n                                           input_shape=target_dims)\n    \n    x_train = model_xception.predict_generator(train_generator, verbose=0)\n    y_train = train_generator.classes\n    \n    x_val = model_xception.predict_generator(val_generator, verbose=0)\n    y_val = val_generator.classes\n\n    return x_train, x_val, y_train, y_val","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23e63a9287650c3724160fe65f60aa09da44dcbf"},"cell_type":"code","source":"data_path = data_dir + \"train\"","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b40471a54c491a0d32280191305ad3621a900dce"},"cell_type":"code","source":"x_xception_train, x_xception_val, y_xception_train, y_xception_val = \\\n    get_bottleneck_xception(data_path, (299, 299, 3), batch_size, seed=SEED)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d101decd1ccad9c4cc9ded317b9b398a329ee24"},"cell_type":"code","source":"lr = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\nlr.fit(x_xception_train, y_xception_train)\ny_xception_pred = lr.predict(x_xception_val)\naccuracy_score(y_xception_val, y_xception_pred)","execution_count":32,"outputs":[]},{"metadata":{"_uuid":"ed18439efb1d76797685aaf528f3e096e8ae272b"},"cell_type":"markdown","source":"## Vgg16 bottleneck"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fea85943da193b9ab46cf3dfed46422c87f7ecec"},"cell_type":"code","source":"def get_bottleneck_vgg16(data_path, target_dims, batch_size, seed=SEED):\n    preprocess_input = applications.vgg16.preprocess_input    \n    img_rows, img_cols, img_channel = target_dims\n    target_size = (img_rows, img_cols)\n    target_dims = (img_rows, img_cols, img_channel) \n    train_generator, val_generator = create_generators(preprocess_input, data_path, target_size, batch_size, seed=SEED)\n\n\n    model_xception = applications.VGG16(weights='imagenet', \n                                        include_top=False, \n                                        pooling='avg',\n                                        input_shape=target_dims)\n    \n    x_train = model_xception.predict_generator(train_generator, verbose=0)\n    y_train = train_generator.classes\n    \n    x_val = model_xception.predict_generator(val_generator, verbose=0)\n    y_val = val_generator.classes\n\n    return x_train, x_val, y_train, y_val","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fafab678e35e46713d08f1c29cbf15a58225e474"},"cell_type":"code","source":"x_vgg16_train, x_vgg16_val, y_vgg16_train, y_vgg16_val = get_bottleneck_vgg16(data_path, (224, 224, 3), batch_size, seed=SEED)","execution_count":34,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c0bdfbf1c261b2e771538031d530db45bd2ef24"},"cell_type":"code","source":"lr = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\nlr.fit(x_vgg16_train, y_vgg16_train)\ny_vgg16_pred = lr.predict(x_vgg16_val)\naccuracy_score(y_vgg16_val, y_vgg16_pred)","execution_count":35,"outputs":[]},{"metadata":{"_uuid":"8dadd4dbd87f3ea0cb0dc421e18badc249a16e44"},"cell_type":"markdown","source":"## Resnet50 bottleneck"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"edd6c3243cbe5b4c8d0022f999d9506b7489aaef"},"cell_type":"code","source":"def get_bottleneck_resnet50(data_path, target_dims, batch_size, seed=SEED):\n    preprocess_input = applications.resnet50.preprocess_input    \n    img_rows, img_cols, img_channel = target_dims\n    target_size = (img_rows, img_cols)\n    target_dims = (img_rows, img_cols, img_channel) \n    train_generator, val_generator = create_generators(preprocess_input, data_path, target_size, batch_size, seed=SEED)\n\n    model_xception = applications.ResNet50(weights='imagenet', \n                                           include_top=False, \n                                           pooling='avg',\n                                           input_shape=target_dims)\n    \n    x_train = model_xception.predict_generator(train_generator, verbose=0)\n    y_train = train_generator.classes\n    \n    x_val = model_xception.predict_generator(val_generator, verbose=0)\n    y_val = val_generator.classes\n\n    return x_train, x_val, y_train, y_val","execution_count":62,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3219d81aaad64a7a5a81f37543e2b1cd7408690"},"cell_type":"code","source":"x_resnet50_train, x_resnet50_val, y_resnet50_train, y_resnet50_val = \\\n    get_bottleneck_resnet50(data_path, (224, 224, 3), batch_size, seed=SEED)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff1317cf1051e0f7822752cea296432381c7cb04"},"cell_type":"code","source":"lr_resnet50 = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\nlr_resnet50.fit(x_resnet50_train, y_resnet50_train)\ny_resnet50_pred = lr_resnet50.predict(x_resnet50_val)\naccuracy_score(y_resnet50_val, y_resnet50_pred)","execution_count":38,"outputs":[]},{"metadata":{"_uuid":"1e0b6367cb0303138b40fb4bd00d986229ec78bd"},"cell_type":"markdown","source":"## Mix model\nwe are going to combine all the previous bottlenecks to build a new model"},{"metadata":{"trusted":true,"_uuid":"0a828b88b3af26f0770c9ce0a17cdeeadf99a6df","collapsed":true},"cell_type":"code","source":"x_train = np.hstack([x_vgg16_train, x_xception_train, x_resnet50_train])\nx_val = np.hstack([x_vgg16_val, x_xception_val, x_resnet50_val])","execution_count":39,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc9a69ebb8718bd9d391ea4d6df4dde041cfa025"},"cell_type":"code","source":"x_train.shape","execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5b89f92394c9a05886971e077011bb8b10032ec"},"cell_type":"code","source":"np.logical_and((y_xception_val==y_vgg16_val).all(), (y_vgg16_val==y_resnet50_val).all())","execution_count":41,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1b5ab02fb4cb1ee0f4af5c2f9750b0670e5d03b"},"cell_type":"code","source":"np.logical_and((y_xception_train==y_vgg16_train).all(), (y_vgg16_train==y_resnet50_train).all())","execution_count":42,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2a8d3832790c83887770a278e3918293bb8da663"},"cell_type":"code","source":"y_train = y_vgg16_train\ny_val = y_vgg16_val","execution_count":43,"outputs":[]},{"metadata":{"_uuid":"c9a9ce07f07135514526cc29dc169b5de7cdecf1"},"cell_type":"markdown","source":"### Logistic Regression\nWe are going to try Logistic Regression to combine all the bottlenecks:"},{"metadata":{"trusted":true,"_uuid":"2b9276a1ce09818985c6797c687918d1979124c1"},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nlr = LogisticRegression(multi_class='multinomial', class_weight=\"balanced\", solver='lbfgs', random_state=SEED)\npipeline = make_pipeline(StandardScaler(), lr)\n\npipeline.fit(x_train, y_train)\ny_pred = pipeline.predict(x_val)\naccuracy_score(y_val, y_pred)","execution_count":50,"outputs":[]},{"metadata":{"_uuid":"5ccb96957e369037682afeb77fe18ceb88895b19"},"cell_type":"markdown","source":"### SVM\nWe are going to try SVM to combine all the bottlenecks. We are going to have a better performance:"},{"metadata":{"trusted":true,"_uuid":"0fe61e2184393b270fee8d0abc6ea845d9648f3e"},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC(kernel=\"linear\", class_weight=\"balanced\", random_state=SEED)\npipeline_svc = make_pipeline(StandardScaler(), svc)\n\npipeline_svc.fit(x_train, y_train)\ny_svc_pred = pipeline_svc.predict(x_val)\naccuracy_score(y_val, y_svc_pred)","execution_count":51,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33e8381ba26c2374248b24e2582ab32c8e24071e"},"cell_type":"code","source":"print(classification_report(y_val, y_svc_pred))","execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72f3500eaf0f0448c96f2327d10e761fb6e4917f"},"cell_type":"code","source":"import scikitplot as skplt\nskplt.metrics.plot_confusion_matrix(y_val, y_svc_pred, normalize=False, figsize=(10, 10))\nplt.show()","execution_count":55,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}