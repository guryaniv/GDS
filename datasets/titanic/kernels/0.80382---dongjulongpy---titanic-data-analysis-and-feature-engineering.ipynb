{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d47e5052ffb2d84a6466434b8e4da107ebc0946"},"cell_type":"code","source":"# importing data analysis, graph libraries.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# to shuffle dataset.\nfrom sklearn.utils import shuffle\n\n# to ignore warning from sklearn.\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d64eec2f91924b71e23a6c739e6a9662336c154"},"cell_type":"code","source":"# Reading train and test data and concat them.\n# We are adding train and test data because a model can predict with same featues which we use train the model.\ntrain_df = pd.read_csv('../input/titanic/train.csv')\ntest_df = pd.read_csv('../input/titanic/test.csv')\n\n# After I got 0.78 score from kaggle I thought maybe\n# I can use test data which I predicted to train algorithms again.\n# In the second run I used test data and predictions to create a train data.\n\nsubmission_df = pd.read_csv('../input/submission080/submission.csv')\ntest_df['Survived'] = submission_df['Survived']\n\ntitanic_df = train_df.append(test_df, ignore_index=True, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d94a9843ac1425ed0f3a2a56badf56ba7255326f"},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f5a0609bda49d6dd43b2b3e11e641a2144b0d4d"},"cell_type":"markdown","source":"# 1 - Step: Feature Engineering and Data Analysis\n### We will analyze the data and try to generate some new features and clean some feature columns."},{"metadata":{"trusted":true,"_uuid":"184090424a5a1506e9f473c961b68cb4df75948e"},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ac47e69751f938a2164fdbbfaf38c2292e30169"},"cell_type":"markdown","source":"## 1 - PassengerId:"},{"metadata":{"trusted":true,"_uuid":"eebac9b8446dcac4a7cbf2c393ec1d770bb4d38e"},"cell_type":"code","source":"# PassengerId is a irrelevant column with our dataset so will remove this column.\ntitanic_df.drop('PassengerId', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"809137ea16d9433815a6d01f186ce1c9030fc75f"},"cell_type":"code","source":"titanic_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da1cefa266abbfc898ebe7f16504d0bbebd4a9ba"},"cell_type":"markdown","source":"## 2 - Pclass:"},{"metadata":{"trusted":true,"_uuid":"846123271f1a7e6ed75a122ee2f65072c700cf04"},"cell_type":"code","source":"# checking whether it has missing values or not.\ntitanic_df['Pclass'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9118247e9a5d1f261d7aa55b9ca8f32ea4a1a53"},"cell_type":"code","source":"plt.figure(figsize=(12, 6)) # setting figure size.\n\nsns.countplot(x='Pclass', data=titanic_df, hue='Survived')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"368f908299cf8e9a92e0d11c5826558d0892b3bd"},"cell_type":"code","source":"# For Pclass column we will leave same for now maybe with other columns we can create some new features.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7242e249316b8291feb29ccf8901f1987daaa33"},"cell_type":"markdown","source":"## 3 - Name:"},{"metadata":{"trusted":true,"_uuid":"f00e4c2bee38c80b6390b3c9bb2681b2413d90f4"},"cell_type":"code","source":"titanic_df['Name'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a70ef131446b29dd417b0144f82431d29705a801"},"cell_type":"code","source":"titanic_df['Name'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81793c1b4c6bc67ea41220da28231c5d0958aede"},"cell_type":"code","source":"# For name column we will split the names and look the name titles.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48d77ec2ebddd7c7b96baa3a86ac41d7b1250fe9"},"cell_type":"code","source":"def find_title(name):\n    \"\"\"\n    This method takes a full name \n    and return the title of name\n    \n    \"\"\"\n    \n    nameList = name.split()\n    \n    for i in nameList:\n        if '.' in i:\n            name = i[:-1]\n    \n    return name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b25c7584d981351377b5e1ce5375800afe5710c"},"cell_type":"code","source":"# creating a new title column in titanic_df\ntitanic_df['Title'] = titanic_df['Name'].apply(find_title) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96ab8cc4a9ec884ac28afc03225211315f2d9325"},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"600ae065b60b337c907bee8528a4f595edebb233"},"cell_type":"code","source":"plt.figure(figsize=(16, 6)) # setting figure size.\n\nsns.countplot(x='Title', data=titanic_df, hue='Survived')\n\nplt.ylim(0, 500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14c336fb7847015ebc8be28a49e9010e08b0d00e"},"cell_type":"code","source":"# In the graph we see that ['Mme', 'Ms', 'L', 'Lady', 'Sir', 'Mlle', 'Countess'] all survived.\n# Also ['Don', 'Rev', 'Capt', 'Jonkheer'] all died.\n# ['Mrs', 'Miss'] have similar ratio.\n# So we will create 6 class for title:\n\n# 1 - ['Mme', 'Ms', 'L', 'Lady', 'Sir', 'Mlle', 'Countess']\n# 2 - ['Don', 'Rev', 'Capt', 'Jonkheer']\n# 3 - ['Mrs', 'Miss']\n# 4 - Master\n# 5 - Mr\n# 6 - Others","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5041e89ef8096ab8a92021066cfce6646ede2311"},"cell_type":"code","source":"def title_class(title):\n    \n    if title in ['L', 'Lady', 'Sir', 'Countess', 'Mme', 'Mlle', 'Ms']:\n        return 0\n    elif title in ['Don', 'Rev', 'Capt', 'Jonkheer']:\n        return 1\n    elif title in ['Mrs', 'Miss']:\n        return 2\n    elif title in ['Master']:\n        return 3\n    elif title in ['Mr']:\n        return 5\n    else:\n        return 6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1a41e245eef43f6661711bea45ed190418c9f0d"},"cell_type":"code","source":"titanic_df['Title'] = titanic_df['Title'].apply(title_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a6a127813385152bc581de655be4f3ff39578d9"},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"307c06f1f2de9d849d631d973b1fca9dbcedf87e"},"cell_type":"code","source":"# Now we don't need the name column anymore.\ntitanic_df.drop('Name', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9b8de5d32367479d22b815ceea20a35012d3e60"},"cell_type":"markdown","source":"## 4 - Sex:"},{"metadata":{"trusted":true,"_uuid":"45ddd3f5df68091af8996085e5ffd3b71e123dca"},"cell_type":"code","source":"titanic_df['Sex'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c357208b048b1807b3150139916d9ad7d68ae650"},"cell_type":"code","source":"def sex_column(sex):\n    \n    if sex == 'male':\n        return 0\n    else:\n        return 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1dfef01ea21baf087a8b12c4ae52a42cba897731"},"cell_type":"code","source":"titanic_df['Sex'] = titanic_df['Sex'].apply(sex_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1cf33383db7352f0c993f1326201125541bbfaa"},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04aace1b33a4a00d9f034c7a5dd09faffbc35560"},"cell_type":"markdown","source":"## 5 - Age:"},{"metadata":{"trusted":true,"_uuid":"d3f654a73daae3ba0c4a80c07b93a19bc4e25376"},"cell_type":"code","source":"titanic_df['Age'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6a59dc10e879204a6c07b64f6f83ebe6d6fe3f6"},"cell_type":"code","source":"# We have a lot of missing values. So first we have to fill these missing values.\n# We can find relevant feature columns in age column and give some random age values for missing ages.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"867dd665491fac9df9f7558459a4c3e663745913"},"cell_type":"code","source":"plt.figure(figsize=(16, 6)) # setting figure size.\n\nsns.barplot(x='Pclass', y='Age', data=titanic_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"620e5d4b5d824dbd77f10812de1e5a7f5ea0e6de"},"cell_type":"code","source":"titanic_df['Age'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9eedb407163181db35c2d4366518aecfdafff84"},"cell_type":"code","source":"titanic_df[titanic_df['Pclass'] == 1]['Age'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ecc2ff6b305817d1b4b90692fabe9a08c613fd1"},"cell_type":"code","source":"titanic_df[titanic_df['Pclass'] == 2]['Age'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0892ea89977328ac549e6f9365fd77abcab6d62"},"cell_type":"code","source":"titanic_df[titanic_df['Pclass'] == 3]['Age'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c26d38f3f7d6b8da1d6ac45808b58c5f315f49d8"},"cell_type":"code","source":"# Pclass is a option for predicting Age Column.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f9c369303d0e24269cf471fae0d5de5d559fa56"},"cell_type":"code","source":"# We can scale the fare column and analyze relationship with age.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cecf89ff665d4c42ecf0eb4deea57c2833a82cd9"},"cell_type":"code","source":"def fare_class(fare):\n    return fare // 200","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"549f973c5cdf1876c19631f9843e86fb57534123"},"cell_type":"code","source":"titanic_df['FareClass'] = titanic_df['Fare'].apply(fare_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03703e7685c0e29031816db18eb3b3589c221443"},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8cfa29a9e66526c807c77d8773d8a37aedd196e"},"cell_type":"code","source":"plt.figure(figsize=(16, 6)) # setting figure size.\n\nsns.barplot(x='FareClass', y='Age', data=titanic_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f102bad6b312700873654274a5ba9dc58f944b1a"},"cell_type":"code","source":"# We can use both FareClass and Pclass to fill missing age values.\n# FareClass 2 means Pclass 1 \n# FareClass 1 means Pclass 2 \n# FareClass 0 means Pclass 3 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"450508712b3e07636cde987dd2d524ef94fae6a6"},"cell_type":"code","source":"import random\n\ndef fill_age(columns):\n    \n    age = columns[0]\n    pclass = columns[1]\n    fareclass = columns[2]\n        \n    if pd.isnull(age):\n        pclass_mean = int(round(titanic_df[titanic_df['Pclass'] == pclass]['Age'].mean()))\n        fareclass_mean = int(round(titanic_df[titanic_df['FareClass'] == fareclass]['Age'].mean()))\n\n        pclass_std = int(round(titanic_df[titanic_df['Pclass'] == pclass]['Age'].std()))\n        fareclass_std = int(round(titanic_df[titanic_df['FareClass'] == fareclass]['Age'].std()))\n\n        age_max = int(round(((pclass_mean + fareclass_mean) + (pclass_std + fareclass_std))/2))\n        age_min = int(round(((pclass_mean + fareclass_mean) - (pclass_std + fareclass_std))/2))\n\n        random_age = random.randint(age_min, age_max)\n        return random_age\n    else:\n        return age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"773ace3aada6fa2466e2b84a68e5e08095b6a475"},"cell_type":"code","source":"titanic_df['Age'] = titanic_df[['Age', 'Pclass', 'FareClass']].apply(fill_age, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a2ce13592d41cab04343586630ca1b931808bf3"},"cell_type":"code","source":"titanic_df['Age'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09e46f2a81ca279eea783aecacdc089f7c1f1fcf"},"cell_type":"code","source":"titanic_df['Age'] = titanic_df['Age'].apply(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a366e5c608404c22f8ce131cc56fc9653dcd7e3"},"cell_type":"code","source":"# We may create an age_class like 0-20, 21-40, 40-others","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd39407d19fb42b13d306c41937de193e2a0d439"},"cell_type":"code","source":"def age_class(age):\n    \n    if 0 <= age <= 20:\n        return 0\n    elif 20 < age <= 40:\n        return 1\n    elif 40 < age <= 60:\n        return 2\n    else:\n        return 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"187edbafb42496c9122d2bd12970797ddf581564"},"cell_type":"code","source":"titanic_df['AgeClass'] = titanic_df['Age'].apply(age_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfe65bbcf9f4f5fbc6ec2298e671357f95323dbe"},"cell_type":"code","source":"plt.figure(figsize=(16, 6)) # setting figure size.\n\nsns.countplot(x='AgeClass', data=titanic_df, hue='Survived')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7af54b7908b81864022b64de1cf32e5ce4a8f302"},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db6bcd9407f305824a51a17607510dce642619a2"},"cell_type":"markdown","source":"## 6 - SibSp and Parch:"},{"metadata":{"trusted":true,"_uuid":"63dca3054d8adb8fb46bb9efe5d15c342547ecff"},"cell_type":"code","source":"titanic_df['SibSp'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f860ff1accb85d14c14af69107aa63070ccfd2d2"},"cell_type":"code","source":"titanic_df['Parch'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b452190a64f07f6f8eaf42989a3d546558edc19"},"cell_type":"code","source":"# We can use these columns to create family size column.\n# We can create a column which is passenger alone or not.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10021f341c9cd43328941cc402800b5b768a9543"},"cell_type":"code","source":"# We have to add 1 because we have to include passenger too.\ntitanic_df['FamilySize'] = titanic_df['SibSp'] + titanic_df['Parch'] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36de4676472e4ff7b18bb767767c572509069d3c"},"cell_type":"code","source":"def alone(familysize):\n    \n    if familysize == 1:\n        return 1\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a623a3cc5f6dcb470b941c04963660b6fb651db"},"cell_type":"code","source":"titanic_df['Alone'] = titanic_df['FamilySize'].apply(alone)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfb83dd5ce92442a4021889cfac99ff215d60ba9"},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ef90b370a090bca2140553429fae83cd9ff857f"},"cell_type":"code","source":"sizes = titanic_df['FamilySize'].unique() # unique familysize values.\nsizes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f13f16ab94df6713c6516ba0b653193a7918957f"},"cell_type":"code","source":"# We can classify the familysize as small medium and big.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a53929165c644fd935ea0a5b68aa9cef2a8e3305"},"cell_type":"code","source":"(max(sizes) - min(sizes)) / 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36341a91807e35c977d1c38dee6e97e2a9dd8a14"},"cell_type":"code","source":"def family_class(familysize):\n    \n    if familysize <= 3:\n        return 0\n    elif 3 < familysize <= 7:\n        return 1\n    else:\n        return 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef4d3e9413188804c75951f942c378f5b1c800a8"},"cell_type":"code","source":"titanic_df['FamilyClass'] = titanic_df['FamilySize'].apply(family_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"467dc162221877efe00a15b3fc26fd8980754a27"},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bcdd4c57bdca69c6a55f9140ea3fc6df3bdde69d"},"cell_type":"markdown","source":"## 7 - Ticket:"},{"metadata":{"trusted":true,"_uuid":"b5fbdcb1c80d271f341d2ef96862bfdd5a3f85f2"},"cell_type":"code","source":"titanic_df['Ticket'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ebbe808c69240eb24fbee15cefa4fe102637460"},"cell_type":"code","source":"tickets = titanic_df['Ticket'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cc252dc2ada891f1e36e1d789b4e832a755a5ee"},"cell_type":"code","source":"# We can split ticket as digit and non digit tickets.\n# We may use the first letter inside tickets.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efe902c66dfc6c5c9391b60c1c6b8e2097ac9dd7"},"cell_type":"code","source":"tickets_int = list()\ntickets_str = list()\n\nfor i in range(len(tickets)):\n    try:\n        tickets_int.append(int(tickets[i]))\n    except:\n        tickets_str.append(tickets[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b86b3c3b0f9b2799d54c999a1607204f37f0cd96"},"cell_type":"code","source":"def ticket_class(ticket):\n    \n    try:\n        int(ticket)\n        return 0\n    except:\n        return 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b974038634d34d5733b105156f9fd6293ac8f435"},"cell_type":"code","source":"titanic_df['TicketClass'] = titanic_df['Ticket'].apply(ticket_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fe063f1c2ec2427e94bfa5d9f3bddcc207794de"},"cell_type":"code","source":"plt.figure(figsize=(16, 6)) # setting figure size.\n\nsns.countplot(x='TicketClass', data=titanic_df, hue='Survived')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"943d723606253ac96b5880edf215dfe4b98ab4da"},"cell_type":"code","source":"titanic_df.drop('Ticket', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b6c7db01cefc0794631f76dac64e84c54d3d5ac"},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aecfd0f28050d67a95f65d22117691e8dfef757e"},"cell_type":"markdown","source":"## 8 - Fare:"},{"metadata":{"trusted":true,"_uuid":"64934daaf960226ad2ef45e6b967bb700d97c2de"},"cell_type":"code","source":"# We have already created fareclass just we can make them integer values\ntitanic_df['Fare'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a0bf57a66968273c5575c9a9c6a02cc38ac089b"},"cell_type":"code","source":"titanic_df[titanic_df['Fare'].isnull() == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"661bb6147055e2e34cb10a9d717fb1deef7769b5"},"cell_type":"code","source":"pclass_mean = int(round(titanic_df[titanic_df['Pclass'] == 3]['Fare'].mean()))\npclass_std = int(round(titanic_df[titanic_df['Pclass'] == 3]['Fare'].std()))\n\nfare_min = pclass_mean - pclass_std\nfare_max = pclass_mean + pclass_std\n\nrandom_fare = random.randint(fare_min, fare_max)\n\ntitanic_df.loc[titanic_df['Fare'].isnull() == True, 'Fare'] = random_fare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8437fc8ce5e03567bb9edd399573ab6ba9c12b78"},"cell_type":"code","source":"titanic_df['Fare'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24e9b3b7819a7aa263458b1b875f935638fa7533"},"cell_type":"code","source":"titanic_df['FareClass'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a030bdabeb6f63f090edb52001fc03977467b46b"},"cell_type":"code","source":"titanic_df.loc[titanic_df['FareClass'].isnull() == True, 'FareClass'] = random_fare // 200","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d551fe882b5e1795ecc177b42947c44198f063a"},"cell_type":"code","source":"titanic_df['FareClass'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f1bc0f355471653cbeeb5a62fdfe41c1b9f0c09"},"cell_type":"code","source":"titanic_df['FareClass'] = titanic_df['FareClass'].apply(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dceb166c55d42b46fd2eff4ebd9bfbe15a96b34e"},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de1053057970a9755c9e5b70d580f11dd1e65923"},"cell_type":"markdown","source":"## 9 - Cabin:"},{"metadata":{"trusted":true,"_uuid":"ea5c880aa001f75f9569d2d5585ea000915c7769"},"cell_type":"code","source":"titanic_df['Cabin'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9a5ee2410eb941c0d34d747a9a69ac31e6f008b"},"cell_type":"code","source":"cabins = list(titanic_df['Cabin'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"429a5288dc602d2b988d80e83ed7996cc4953a84"},"cell_type":"code","source":"cabins.remove(np.nan)\ncabins = sorted(cabins)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26cedc979c6e5da7a53c81e8c0ac4247ac02e742"},"cell_type":"code","source":"def cabins(cabin):\n    \n    cabin_allocations = {'A' : 0, 'B' : 1, 'C' : 2, 'D' : 3, 'E' : 4, 'F' : 5, 'G' : 6, 'T' : 7}\n    \n    if pd.isnull(cabin):\n        return 8\n    else:\n        return cabin_allocations[cabin[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48858d5f47fecad4b13400d7fc8fcb1fcaeff962"},"cell_type":"code","source":"titanic_df['Cabin'] = titanic_df['Cabin'].apply(cabins)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"006eb76427bc9fde9878b66fb6c86920d4d6b9e1"},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab0e9df2893cfc70f8ec5bf778c4ba7f37fbb42a"},"cell_type":"markdown","source":"## 10 - Embarked:"},{"metadata":{"trusted":true,"_uuid":"41193b53381b397c9642d1c42bcd8cda872d6de2"},"cell_type":"code","source":"titanic_df['Embarked'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41da5768c926b98683127a4d6c221af24f59720d"},"cell_type":"code","source":"titanic_df[titanic_df['Embarked'].isnull() == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3783c59c973c9f12077746c0301a44654bd987b1"},"cell_type":"code","source":"# I will give S for missing embarked values because the highest probility is 'S'.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5899b83ba8ca5ab218cbdaef4f1f0735f865aee6"},"cell_type":"code","source":"titanic_df.loc[titanic_df['Embarked'].isnull() == True, 'Embarked'] = 'S'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4eb12c25c354194daae04598b67759e0c9cdf844"},"cell_type":"code","source":"def embarked(embarked):\n    \n    embarked_dict = {'S' : 0, 'C' : 1, 'Q' : 2}\n    return embarked_dict[embarked]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a4dc8389626006461eb991489ce9fcb5f30187e"},"cell_type":"code","source":"titanic_df['Embarked'] = titanic_df['Embarked'].apply(embarked)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6541a550ef4ac6f64d87ad7c1bef88d8d123b447"},"cell_type":"code","source":"titanic_df['Embarked'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9610be81b63842f4531bb29fd724574926642c0b"},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fb3f71b9b619b39bff34afbdbaa2aa6d3c2aae3"},"cell_type":"code","source":"# Now, We have a featured data set which occured from train and test dataset.\n# We will separete train and test dataset and then we will train our algorithms.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"003e7940f3dcfd9dee664414d789b285960b8e0c"},"cell_type":"code","source":"train_featured = titanic_df.iloc[:891]\ntest_featued = titanic_df.iloc[891:]\n\ntrain_featured_copy = titanic_df\ntrain_featured_copy = shuffle(train_featured_copy)\ntest_featued_copy = test_featued","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75f7d6f55f0a22d449e6d34e927c7fb2536ba229"},"cell_type":"markdown","source":"# 2 - Step: Train Test Algorithm and Predict:"},{"metadata":{"trusted":true,"_uuid":"867fec693e2524bd35b2b540a3e7fb874d848823"},"cell_type":"code","source":"# First split our train data as train and test data to see accuract values.\n# Sklearn has train_split for dividing dataset and shuffle it.\nfrom sklearn.model_selection import train_test_split\n\ntrain_df = train_featured_copy\n\nX = train_df.drop(['Survived'], axis=1)\ny = train_df['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9a6aebb5d3939703f23d37d6e82f3a9ad3c05e4"},"cell_type":"code","source":"# Some algorithms from sklearn to classification. \n# Actually, I didn't use many algorithms because they are almost all will give similar result.\n# Because, the important thing is create a good featured dataset. If we have a good classifiable dataset\n# mostly all algorithm will give similar result.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5bbb9bfb937296b2e76c16314016a479adcc189"},"cell_type":"code","source":"logmodel = LogisticRegression()\nlogmodel.fit(X_train, y_train)\nlog_predictions = logmodel.predict(X_test)\nprint(classification_report(y_test, log_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6462176064fb0102a024c7a5e2a5fb4bd3300221"},"cell_type":"code","source":"svm_model = SVC()\nsvm_model.fit(X_train, y_train)\nsvm_predictions = svm_model.predict(X_test)\nprint(classification_report(y_test, svm_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74ac4472bceaf08a4a38831312d565517de141c1"},"cell_type":"code","source":"rdm = RandomForestClassifier()\nrdm.fit(X_train, y_train)\nrdm_predictions = rdm.predict(X_test)\nprint(classification_report(y_test, rdm_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"574c147249fd924b073b097389f8dda510dc5feb"},"cell_type":"code","source":"param_grid = {'C' : [1, 10, 100, 1000, 10000], 'gamma' : [1, 0.1, 0.01, 0.001, 0.0001]}\ngrid = GridSearchCV(SVC(), param_grid, refit=True)\ngrid.fit(X_train, y_train)\ngrid_predictions = grid.predict(X_test)\nprint(classification_report(y_test, grid_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e820aca1205c5310385215185fa8ee3fe9b372a"},"cell_type":"code","source":"gbc = GradientBoostingClassifier()\ngbc.fit(X_train, y_train)\ngbc_pred = gbc.predict(X_test)\nprint(classification_report(y_test, gbc_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca9a1906b02d2139a7d6e5c2e1895851edb41bb5"},"cell_type":"code","source":"import itertools\nimport time\n\nstart = time.time()\n\ny = train_df['Survived']\ncolumns = list(train_df.columns)\ncolumns.remove('Survived')\n\ntotal_score = [0, 0, 0]\n\nfor k in range(0, len(columns)-8):\n    \n    start_1 = time.time()\n    \n    features = list(itertools.combinations(columns, k))\n\n    score_index = [0, 0]\n    score_max = score_index[0]\n\n    for i in range(len(features)):\n\n        features_extra = list(features[i])\n        features_extra.append('Survived')\n        \n        X = train_df.drop(features_extra, axis=1)\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n        #logmodel = LogisticRegression()\n        #logmodel.fit(X_train, y_train)\n        #log_predictions = logmodel.predict(X_test)\n\n        #svm_model = SVC()\n        #svm_model.fit(X_train, y_train)\n        #svm_predictions = svm_model.predict(X_test)\n\n        #rdm = RandomForestClassifier()\n        #rdm.fit(X_train, y_train)\n        #rdm_predictions = rdm.predict(X_test)\n\n        gbc = GradientBoostingClassifier()\n        gbc.fit(X_train, y_train)\n        gbc_predictions = gbc.predict(X_test)\n\n        scores = dict()\n\n        #scores[accuracy_score(y_test, log_predictions)] = \"Logistic Regression: \"\n        #scores[accuracy_score(y_test, svm_predictions)] = \"SVM: \"\n        #scores[accuracy_score(y_test, rdm_predictions)] = \"Random Forest Classifier: \"\n        scores[accuracy_score(y_test, gbc_predictions)] = \"GradientBoosting Classifier: \"\n\n        sorted_scores = sorted(scores, reverse=True)\n\n        if score_max < max(sorted_scores):\n            score_index[0] = max(sorted_scores)\n            score_index[1] = i\n            score_max = max(sorted_scores)\n            \n        if total_score[1] < max(sorted_scores):\n            total_score[0] = k\n            total_score[1] = max(sorted_scores)\n            total_score[2] = i\n            \n\n        #print(\"------------------------------------Test\", i, '---------------------------------')    \n        #print()\n\n        #for j in sorted_scores:\n        #    print(scores[j], j)\n\n        #print()\n    end_1 = time.time()\n    print(\"------------------------------------ Extra Feature\", k, '---------------------------------')\n    print(\"Extra Feature Count:\",  k, \"\\nMax Score:\", score_index[0], \"\\nFeatue Index:\", score_index[1])\n    print(\"Extra Feature\", k, \": ...done\", end_1 - start_1)\n    \nend = time.time()\ntime_comb = end - start\nprint(\"-----------------------------------------------------------------------------------------------\")\nprint(\"Time for Combinations of Features: \", time_comb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e31cc98f27884ef1d1c8d0699abc6f1405b3bb25"},"cell_type":"code","source":"# After I got some scores around 79-80 from algorithms. I thought, maybe I have some extra features \n# and I used bruce force to try exery combinations of extra features. \n# Because it takes long time I didn't use some algorithms above.\n# The best score 0.8507462686567164 with 3 extra feature. Lets find these extra features.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fa066eecd6e0d05233591b02e88248dbcd774d8"},"cell_type":"code","source":"print(\"Max Score:\", total_score[1], \"Extra Feature Count:\", total_score[0], \"Featue Index:\", total_score[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce29b2be84b4b20238828d7b447da6983fec64f5"},"cell_type":"code","source":"features = list(itertools.combinations(columns, total_score[0]))\nextra_features = list(features[total_score[2]])\nextra_features.append('Survived')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6cd73869236414755e6c5871e8b1888ad894db7"},"cell_type":"code","source":"# Now, to be sure I will remove these features and get some scores again from algorithms.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a491204a2a15e6cf3676de03e76a55c1c259ff4"},"cell_type":"code","source":"train_df = train_df\n\nX = train_df.drop(extra_features, axis=1)\ny = train_df['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea4285b0d483767f7783e7947498cf2411468a8e"},"cell_type":"code","source":"logmodel = LogisticRegression()\nlogmodel.fit(X_train, y_train)\nlog_predictions = logmodel.predict(X_test)\nprint(classification_report(y_test, log_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79273ed19d65b59b9ff231df6daaa1b139cf0d79"},"cell_type":"code","source":"svm_model = SVC()\nsvm_model.fit(X_train, y_train)\nsvm_predictions = svm_model.predict(X_test)\nprint(classification_report(y_test, svm_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed21bf9072f69fad7b9e8ce0c34f771bd16425e5"},"cell_type":"code","source":"rdm = RandomForestClassifier()\nrdm.fit(X_train, y_train)\nrdm_predictions = rdm.predict(X_test)\nprint(classification_report(y_test, rdm_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36b93124417e685139bbb5f4466da216723c0952"},"cell_type":"code","source":"param_grid = {'C' : [1, 10, 100, 1000, 10000], 'gamma' : [1, 0.1, 0.01, 0.001, 0.0001]}\ngrid = GridSearchCV(SVC(), param_grid, refit=True)\ngrid.fit(X_train, y_train)\ngrid_predictions = grid.predict(X_test)\nprint(classification_report(y_test, grid_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f69de91543457c627ed42a899c347b367a0a6def"},"cell_type":"code","source":"gbc = GradientBoostingClassifier()\ngbc.fit(X_train, y_train)\ngbc_pred = gbc.predict(X_test)\nprint(classification_report(y_test, gbc_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3dc944cb7d5d13ec9e8c974f4812b4e0b3379931"},"cell_type":"markdown","source":"# Final Step:"},{"metadata":{"trusted":true,"_uuid":"853cd0368032d9836e831684763238d0a469b412"},"cell_type":"code","source":"train_df = train_df\n\nX = train_df.drop(extra_features, axis=1)\ny = train_df['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf059267b3b1ebfde2fcafde7382d0e78e05bf83"},"cell_type":"code","source":"gbc.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5368606be147983fd60e402e3f281c0cd79e678c"},"cell_type":"code","source":"X_test = test_featued.drop(extra_features, axis=1)\n\ngbc_predictions = gbc.predict(X_test)\ngbc_predictions = pd.DataFrame(gbc_predictions, columns=['Survived'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c89e89b9e231276efa7433d611bed25e8880a89c"},"cell_type":"code","source":"gbc_predictions['Survived'] = gbc_predictions['Survived'].apply(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6db7fca31c2339d331afa9a7ab3ade651ba147a3"},"cell_type":"code","source":"gbc_predictions.set_index(test_df['PassengerId'], inplace=True)\ngbc_predictions.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3096b80499c21994fcfb4990d250565eb35608b1"},"cell_type":"code","source":"data_df = pd.read_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}