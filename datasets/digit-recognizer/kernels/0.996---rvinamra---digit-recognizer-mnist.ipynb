{"cells":[{"metadata":{"trusted":true,"_uuid":"b88c1f2df09446519111049ed937e9ae13815da4"},"cell_type":"markdown","source":"# Introduction\n\nUsing *Yassine Ghouzam's* kernel as a reference, a **five-layered Sequential CNN** has been used for digits recognition from **MNIST dataset**. It is built with *Keras API* (Tensorflow backend). Firstly, I started with importing relevant libraries and then moved on to getting a quick description of the data. \n\n**After  lot of trial and error, the number of steps (epochs) has been set to 48, for better accuracy.** Initially for testing purposes epochs was set as 2 which gave an accuracy of ~85% and it crossed the 99% mark at epochs approximately equal to 25. On increasing the number of epochs beyond 50, the accuracy when down due to probable overfitting of the model. \n\n**Kaggle's GPU was used for getting more computational power.**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(5)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # for ohe\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nsns.set(style='white', context='notebook', palette='deep')\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Loading the data\n\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d78b050ae816e7e56b781bf98006425b8f1e4b71"},"cell_type":"markdown","source":"# Breaking up train.csv\n\nThe **label** column of the training dataset consists of the actual number denoted by the handwritten digit image. In the next step, the training data is separated into two dataframes *X_train* and *Y_train*, wherein *Y_train* represents the label column and *X_train* has a structure similar to the test dataset."},{"metadata":{"trusted":true,"_uuid":"1cbd590f8cc2f643bd8a8acbedd49d4816cdfe79"},"cell_type":"code","source":"# preparation for a descriptive plot of the training data\n\nY_train = train['label']\n\n# dropping the label column\nX_train = train.drop(labels = ['label'], axis = 1)\n\ndel train\n\ng = sns.countplot(Y_train)\n\nY_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f4a7a8e278465a4d644eb0b0766ca9b90b12324"},"cell_type":"markdown","source":"# Data check and Normalisation\n\nBoth the training and test data is checked for any null values so that appropriate measures could be taken to deal with it. In this case, luckily, there were no missing values. \nAfter that **Grayscale Normalisation** was done to both the datasets to reduce the effect of illumination differences. Moreover, CNNs converge faster on [0..1] data than on [0..255]. "},{"metadata":{"trusted":true,"_uuid":"fe73a0a0a3b4ffc8cc86180cbfed5573a3e6dff9"},"cell_type":"code","source":"# checking the data\nX_train.isnull().any().describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"000294bb91c6f989e9ba49edcb6112dffec40b19"},"cell_type":"code","source":"# checking for missing values in the test data\ntest.isnull().any().describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c60fe5acc938edf9cd748b22db395cd4ef577da0"},"cell_type":"code","source":"# no missing values in both train and test data \n\nX_train = X_train/255.0\ntest = test/255.0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"570b7357463c00b689539763a276fef103e2744e"},"cell_type":"markdown","source":"# Reshaping and One-hot encoding\n\nTrain and test images of dimension 28px x 28px has been stock into pandas as dataframe of 1D vectors of 784 values. Reshaping all data to 28x28x1 3D matrices.\nKeras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, and for that it would have reshaped 784px vectors to 28x28x3 3D matrices. \n\nThe major advantage here of using **One-hot encoding** is that it speeds up the model considerably. "},{"metadata":{"trusted":true,"_uuid":"f0e4fd28f5613e5b7c34474e57249d04d21d7724"},"cell_type":"code","source":"# reshaping image in 3D (height = width = 28px; canal = 1)\n# since it is a grayscale image, therefore channel is 1. For RGB image channel = 3\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d4141abb60765ac8f27e76a29bad5a7246dbb00"},"cell_type":"code","source":"# one hot encoding of the labels\nY_train = to_categorical(Y_train, num_classes = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"196a0d659154a7468567bee7f095d7141d9ab645"},"cell_type":"code","source":"# splitting training and validation set\nrandom_seed = 2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4581cd88832c9add72adca654ddd8299f31fd42e"},"cell_type":"markdown","source":"# Internal splitting of data for Cross Validation\n\nUsing 10% of the dataset as a validation set for cross-validation. A random split is done using the train_test_split function because the dataset contains all the numbers in almost an equal proportion as can be seen in the plot generated above. .\n"},{"metadata":{"trusted":true,"_uuid":"58b9e00e55ce03014fd54be61fef82fb493e4913"},"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state = random_seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2c754623e37c4611180548107ba0fd164e7b144"},"cell_type":"code","source":"# 10% of the training data has been used as a validation set and the rest is used to train the model\n# some examples\ng = plt.imshow(X_train[1][:,:,0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4479f08580e17923ba1b31a99425940c15ab192b"},"cell_type":"markdown","source":"# CNN Architechture\n\nAs mentioned in the introduction cell, Keras Sequential API has been used to build the model which allows us to add one layer at a time. \nThe first layer is convolutional *(Conv2D)* layer.  32 filters for the two firsts conv2D layers and 64 filters for the two last ones were set. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter.  Therefore, in short, filters can be seen as a transformation of the image.\nThe second important layer in CNN is the pooling *(MaxPool2D)* layer. These are used to reduce computational cost, and to some extent also reduce overfitting.\nAs a result of combination of convolutional and pooling layers, CNNs are able to combine local features and learn more global features of the image.\n\nFor regularization, **Dropout** method was used. Dropout is implemented by only keeping a neuron active with some probability p (a hyperparameter), or setting it to zero otherwise. This forces the network to be accurate even in the absence of certain information. It prevents overfitting by providing a way of approximately combining exponentially many different neural network architectures efficiently.\n\n**'relu'** is the rectifier (activation function max(0,x) which is used to add non linearity to the network. \n\nAfter that, Flatten layer is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that fully connected layers can be used after some convolutional/maxpool layers. It combines all the found local features of the previous convolutional layers.\n"},{"metadata":{"trusted":true,"_uuid":"ef52e1e56cb5fdd0c5c972fe1251dd9aa4d3ef24"},"cell_type":"code","source":"# USING THE KERAS SEQUENTIAL API\n# SETTING THE CNN MODEL\n# CNN architechture -> [[Conv2D->relu]]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same',\n                activation = 'relu', input_shape =(28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same',\n                activation = 'relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = 'softmax'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed9fc432c81686cb3a0636e2690b4f134ccc430d"},"cell_type":"markdown","source":"# Optimisation Algorithm and Loss Function\n\nA loss function is defined to measure how poorly our model performs on images with known labels. It is the error rate between the oberved labels and the predicted ones. A specific form for categorical classifications (>2 classes) called the \"categorical_crossentropy\" has been used.\nThe optimisation algorithm will iteratively improve parameters (filters kernel values, weights and bias of neurons, etc.) in order to minimise the loss. \nRMSprop is preferred as a optimizer over Stochastic Gradient Descent because SGD is generally slower. \nThe Learning Rate is the step by which the optimizer walks through the 'loss landscape'. Higher LR leads to quicker convergence at the same time causing poor sampling.\nReferring to Yassine's notebook, it's better to have a decreasing learning rate during the training to reach efficiently the global minimum of the loss function. \nTo keep the advantage of the fast computation time with a high LR, ReduceLROnPlateau function from Keras.callbacks was used. A choice of reducing LR by half if the accuracy was not improved after three steps (epochs) was made."},{"metadata":{"trusted":true,"_uuid":"db6619dbb77e6afd35a2c959d3506aaaf4bc6960"},"cell_type":"code","source":"# setting the optimizer and annealer\n# setting up a score function, loss function, optimisation algorithm\n# defining the optimizer\n\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3666e05d415cfd7919e3fcf88a0dc23dd8234879"},"cell_type":"code","source":"# compiling the model\nmodel.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9897d3092d9394fc746a411c0cfa3d52713f049c"},"cell_type":"code","source":"# setting a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca06a30cb06f792b7363cf7e260e68cdf2284d95"},"cell_type":"code","source":"epochs = 200\nbatch_size = 86","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f433dd0b95bafb791e411d5460cb671f6d89c81"},"cell_type":"markdown","source":"# Data Augmentation\n\nTo avoid overfitting, small variations are introduced in the training dataset to create new images. Methods of augmenting data used here:\n1. Rotating images by 10 degrees\n2. Randomly zooming by 10%\n3. Randomly shift images horizontally or vertically by 10%"},{"metadata":{"trusted":true,"_uuid":"8f0f4cc5e0f1e7f316b12e83edbb777807b1c303"},"cell_type":"code","source":"# avoiding overfitting\n# data augmentation\n\n# With data augmentation to prevent overfitting \n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31814582078b34d4f03a97ba8b91e929874c0b13"},"cell_type":"code","source":"# fittng the model\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n                              , callbacks=[learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"439a8187c323df242dd3add91f11e213733def02"},"cell_type":"code","source":"# confusion matrix helps in checking the drawbacks of the models\n\n# looking at confusion matrix \n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9af8c777ea8c1cae48ea0ce5593519b90efbd451"},"cell_type":"code","source":"# investigating for the errors\n\n# Displaying some error results \n\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad99f1a891fd39c2da87ab4f0954a0890a48270c"},"cell_type":"code","source":"# we can see that the errors committed by the model makes sense\n# some of them could be even committed by humans\n\n# prediction of results\nresults = model.predict(test)\n\n# selecting the index with max prob.\nresults = np.argmax(results, axis=1)\n\nresults = pd.Series(results, name ='Label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98ca2ef173251ea2d0778729928f491b1ea3c8e6"},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001), name = 'ImageId'), results], axis =1)\n\nsubmission.to_csv('submission_five.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}