{"cells": [{"cell_type": "code", "execution_count": null, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"-ltrh\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "\n", "\n", "# coding: utf-8\n", "\n", "# In[8]:\n", "\n", "\n", "from numpy import loadtxt\n", "from xgboost import XGBClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import accuracy_score, average_precision_score\n", "\n", "\n", "# In[9]:\n", "\n", "\n", "# load data\n", "lines = open('../input/creditcard.csv').readlines()[1:]\n", "\n", "lines2 = []\n", "for l in lines:\n", "    lines2.append( l.replace('\"', '') )\n", "\n", "print( lines2[0] )\n", "dataset = np.loadtxt(lines2, delimiter=',')\n", "\n", "# In[10]:\n", "\n", "\n", "# split data into X and y\n", "X = dataset[:,0:-1]\n", "Y = dataset[:,-1]\n", "\n", "\n", "# In[11]:\n", "\n", "\n", "X[0:5]\n", "\n", "\n", "# In[12]:\n", "\n", "\n", "# split data into train and test sets\n", "seed = 10\n", "test_size = 0.33\n", "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n", "\n", "\n", "# In[13]:\n", "\n", "\n", "# fit model no training data\n", "model = XGBClassifier()\n", "model.fit(X_train, y_train)\n", "\n", "\n", "# In[34]:\n", "\n", "\n", "X_test_new = []\n", "\n", "for i,val in enumerate(y_test):\n", "    if val == 1.0:\n", "        X_test_new.append( X_test[i])\n", "\n", "y_test_new = [1.0]*len(X_test_new)\n", "\n", "\n", "# In[35]:\n", "\n", "\n", "# make predictions for test data \n", "y_pred = model.predict(X_test)\n", "predictions = [round(value) for value in y_pred]\n", "\n", "y_pred_new = model.predict(X_test_new)\n", "predictions_new = [round(value) for value in y_pred_new]\n", "\n", "\n", "# In[36]:\n", "\n", "# y_pred_new\n", "\n", "# In[37]:\n", "file = open(\"submission.csv\",\"w\")\n", "for pred,x in zip(y_pred,X_test):\n", "    file.write(\",\".join([str(int(x[0])),str(pred)]))\n", "    file.write(\"\\n\")\n", "    \n", "\n", "\n", "# In[38]:\n", "\n", "\n", "# evaluate predictions\n", "accuracy = accuracy_score(y_test, predictions)\n", "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n", "\n", "accuracy = accuracy_score(y_test_new, predictions_new)\n", "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n", "\n", "# In[19]:\n", "auprc = average_precision_score(y_test,predictions)\n", "print(\"AU precision-recall curve: \",auprc)\n", "\n", "auprc = average_precision_score(y_test_new,predictions_new)\n", "print(\"AU precision-recall curve: \",auprc)\n", "\n", "# In[20]:\n", "\n", "sum(y_test)/len(y_test)\n", "\n", "\n"], "metadata": {"_cell_guid": "d41fd33f-49c6-4675-aa8d-7822b1a1ef97", "_uuid": "d83c47b0c2e0179ecc57104e213c90f864e962a1"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": [], "metadata": {"_cell_guid": "e67f7c74-b483-4628-8240-cf4dfdb640aa", "_uuid": "86ba436a52a089f4f1b917ffa33a0b4318b62c10", "collapsed": true}}], "metadata": {"language_info": {"mimetype": "text/x-python", "file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "version": "3.6.4", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 1, "nbformat": 4}