{"cells":[{"metadata":{"_cell_guid":"590a18e9-b66c-4480-bd75-5b6dafc4fb6b","_uuid":"afe6d03087dc1a6a51f64c3f56ec56ad984ae642"},"cell_type":"markdown","source":"[Research Paper of Stock Prediction of NYSE](http://cs229.stanford.edu/proj2012/BernalFokPidaparthi-FinancialMarketTimeSeriesPredictionwithRecurrentNeural.pdf)  \nLearn More Technique for this project [Click on Here](https://github.com/BenjiKCF/Neural-Network-with-Financial-Time-Series-Data)\n\nThis dataset is a playground for fundamental and technical analysis. It is said that **30% of traffic on stocks** is already generated by **machines**, can trading be fully automated? If not, there is still a lot to learn from historical data."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom pandas import datetime\nimport math, time\nimport itertools\nfrom sklearn import preprocessing\nimport datetime\nfrom operator import itemgetter\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import load_model\nimport keras\nimport h5py\nimport requests\nimport os\nimport seaborn as sns\nsns.set()","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"**Read data and transform them to pandas dataframe**"},{"metadata":{"_cell_guid":"98463e30-4c1b-4c31-a220-06031791fb9f","_uuid":"8f87962ce6f722f6bf59efc882d3a55e42be3223","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/prices-split-adjusted.csv\", index_col = 0)\ndf[\"adj close\"] = df.close # Moving close to the last column\ndf.drop(['close'], 1, inplace=True) # Moving close to the last column\ndf.head()","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"b7d93887-d02c-40f6-b44b-ab51ee464351","_uuid":"d5ac916f35cedc1cb6d8285d84a4ad2b738b8290","trusted":true},"cell_type":"code","source":"df2 = pd.read_csv(\"../input/fundamentals.csv\")\ndf2.head()","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"e9ef6e7d-bdf1-49bc-b410-7ce23ea94363","_uuid":"e62f8d1640f622ed28eb9b6414ae80716347ecac"},"cell_type":"markdown","source":"**Extract all symbols from the list**"},{"metadata":{"_cell_guid":"5bcb7190-f04b-4d9b-b326-78ec0b04c85c","_uuid":"53cb26feb9de5ec569acd9205ae6540d5421c380","trusted":true},"cell_type":"code","source":"symbols = list(set(df.symbol))\nlen(symbols)","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"f2794d85-8805-43e8-bff1-2ba9f0b9bcb8","_uuid":"c33aa99b40f86a45476d8ae4a9043464baac8e05","trusted":true},"cell_type":"code","source":"symbols[:11]","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"49e30b05-8198-4b48-badd-e7dc87e87a29","_uuid":"8ffedca5e373f998976474533a9b537592aa7717","trusted":true},"cell_type":"code","source":"df = df[df.symbol == 'GOOG']\ndf.drop(['symbol'],1,inplace=True)\ndf.head()","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"ba1e7e86-37c9-4db4-91ea-b0fea4c473b3","_uuid":"c9e00e4497abcd967935a3bace2c3c3197644445","trusted":true},"cell_type":"code","source":"df.plot(figsize=(23,8))","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"f27b7f54-92e8-4121-99c4-17f62da8a130","_uuid":"1338c7184d5f99ed69403abac24362828ddd8243","collapsed":true},"cell_type":"markdown","source":"**Normalize the data**"},{"metadata":{"_cell_guid":"6cab3827-de37-4d6e-8e21-403fddaad691","_uuid":"8fa92c6314a354bd5cf003ba97a23f6aa0647555","trusted":true},"cell_type":"code","source":"def normalize_data(df):\n    min_max_scaler = preprocessing.MinMaxScaler()\n    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n    df['volume'] = min_max_scaler.fit_transform(df.volume.values.reshape(-1,1))\n    df['adj close'] = min_max_scaler.fit_transform(df['adj close'].values.reshape(-1,1))\n    return df\ndf = normalize_data(df)\ndf.plot(figsize=(23,10))","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"1da9b53b-d848-44cf-bc56-8b33e0afefca","_uuid":"4e68fcd2a87ba5c22cbbec094025a563e03ca4be"},"cell_type":"markdown","source":"**Create Training Set and Testing Set**"},{"metadata":{"_cell_guid":"2523c504-733b-4e9c-ba5a-5d037ec3ccb7","_uuid":"3ecc510822acb3b0cbe70106f54346b7d2949cc0","collapsed":true,"trusted":true},"cell_type":"code","source":"def load_data(stock, seq_len):\n    amount_of_features = len(stock.columns) # 5\n    data = stock.as_matrix() \n    sequence_length = seq_len + 1 # index starting from 0\n    result = []\n    \n    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n        result.append(data[index: index + sequence_length]) # index : index + 22days\n    \n    result = np.array(result)\n    row = round(0.9 * result.shape[0]) # 90% split\n    train = result[:int(row), :] # 90% date, all features \n    \n    x_train = train[:, :-1] \n    y_train = train[:, -1][:,-1]\n    \n    x_test = result[int(row):, :-1] \n    y_test = result[int(row):, -1][:,-1]\n\n    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n\n    return [x_train, y_train, x_test, y_test]","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"a206ecf1-72b6-40c4-9a03-7320ff9a761d","_uuid":"d8199f82ef42fc69341d03e619d0cb3d404a3a0f"},"cell_type":"markdown","source":"**Build the structure of model**  \n\n* **dropout** = 0.3  \n* **epochs** = 90  \n* **LSTM** 256  \n* LSTM 256 > Relu 32 > Linear 1"},{"metadata":{"_cell_guid":"df699287-2f50-477e-8399-3fe93805c422","_uuid":"363271255d3f8f7dde5dbec777d0be57aa25125f","collapsed":true,"trusted":true},"cell_type":"code","source":"def build_model(layers):\n    d = 0.3\n    model = Sequential()\n    \n    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=True))\n    model.add(Dropout(d))\n        \n    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=False))\n    model.add(Dropout(d))\n        \n    model.add(Dense(32,kernel_initializer=\"uniform\",activation='relu'))        \n    model.add(Dense(1,kernel_initializer=\"uniform\",activation='linear'))\n    \n    # adam = keras.optimizers.Adam(decay=0.2)\n        \n    start = time.time()\n    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n    print(\"Compilation Time : \", time.time() - start)\n    return model","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"6e1f6fe7-0f3d-4c98-9ee5-f5d64f068d50","_uuid":"5e634c11f8faf94ae1f49fbb940e697ca6265f54"},"cell_type":"markdown","source":"### Train Model"},{"metadata":{"_cell_guid":"ba2b547e-431a-4fe5-ace2-d9c9c567620d","_uuid":"2c54c56c39ea64bf1bc06bd48a492b2c9c64f72c","trusted":true},"cell_type":"code","source":"window = 22\nX_train, y_train, X_test, y_test = load_data(df, window)\nprint (X_train[0], y_train[0])","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"d121666f-205e-4109-9ecd-cb3d21f706ba","_uuid":"4b96559f83a39c99e422d746d0ae446dd5061628","trusted":true},"cell_type":"code","source":"model = build_model([5,window,1])","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"08b6fedd-ad5f-4a0a-a36b-a80f895039ee","_uuid":"4dea43a6b0b096a2a6f291cc5eecd43ecfb569e7","trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train,batch_size=1024,epochs=90,validation_split=0.1,verbose=1)","execution_count":38,"outputs":[]},{"metadata":{"_cell_guid":"d4e60751-c051-4ad9-b630-5a6e71788fb9","_uuid":"e2282017b0de8385531cdac58be7dd35c2da6f26","trusted":true},"cell_type":"code","source":"# print(X_test[-1])\ndiff=[]\nratio=[]\np = model.predict(X_test)\nprint (p.shape)\n# for each data index in test data\nfor u in range(len(y_test)):\n    # pr = prediction day u\n    pr = p[u][0]\n    # (y_test day u / pr) - 1\n    ratio.append((y_test[u]/pr)-1)\n    diff.append(abs(y_test[u]- pr))\n    # print(u, y_test[u], pr, (y_test[u]/pr)-1, abs(y_test[u]- pr))\n    # Last day prediction\n    # print(p[-1]) ","execution_count":39,"outputs":[]},{"metadata":{"_cell_guid":"6f7d9647-769f-46e5-ab0e-0c4771e37243","_uuid":"3dcfd2edee6290235f689935c635b158c1983fbc"},"cell_type":"markdown","source":"**Denormalize the data**"},{"metadata":{"_cell_guid":"8d18d99e-ac45-410c-a6be-a40bd6e69021","_uuid":"d67872b1cd7e98a57069f2e4ee679394083f21ad","collapsed":true,"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/prices-split-adjusted.csv\", index_col = 0)\ndf[\"adj close\"] = df.close # Moving close to the last column\ndf.drop(['close'], 1, inplace=True) # Moving close to the last column\ndf = df[df.symbol == 'GOOG']\ndf.drop(['symbol'],1,inplace=True)\n\n# Bug fixed at here, please update the denormalize function to this one\ndef denormalize(df, normalized_value): \n    df = df['adj close'].values.reshape(-1,1)\n    normalized_value = normalized_value.reshape(-1,1)\n    \n    #return df.shape, p.shape\n    min_max_scaler = preprocessing.MinMaxScaler()\n    a = min_max_scaler.fit_transform(df)\n    new = min_max_scaler.inverse_transform(normalized_value)\n    return new\n\nnewp = denormalize(df, p)\nnewy_test = denormalize(df, y_test)","execution_count":40,"outputs":[]},{"metadata":{"_cell_guid":"dc49b4a7-c197-4fe6-8ce9-c05297274b63","_uuid":"ab2d0d4029d844c19c00f3ce96457c4d0d6cad7f","trusted":true},"cell_type":"code","source":"def model_score(model, X_train, y_train, X_test, y_test):\n    trainScore = model.evaluate(X_train, y_train, verbose=0)\n    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n\n    testScore = model.evaluate(X_test, y_test, verbose=0)\n    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n    return trainScore[0], testScore[0]\n\n\nmodel_score(model, X_train, y_train, X_test, y_test)","execution_count":41,"outputs":[]},{"metadata":{"_cell_guid":"1d50b5fd-8627-4642-afa2-318aa21e43cb","_uuid":"d0aa3418ca60c0b1c0d3573ac2a6b57a36598f2a","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt2\nplt.figure(figsize=(25,8))\nplt2.plot(newp,color='red', label='Prediction')\nplt2.plot(newy_test,color='blue', label='Actual')\nplt2.legend(loc='best')\nplt2.show()","execution_count":42,"outputs":[]},{"metadata":{"_cell_guid":"33ece2dc-4442-4e83-a8f1-d18e9bbf4765","_uuid":"7d5bac41883755dee05c8f1db1580c5bd1402982","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}