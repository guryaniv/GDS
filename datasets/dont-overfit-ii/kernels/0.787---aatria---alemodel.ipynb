{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport keras as keras\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.\n\n#from sklearn.model_selection import KFold\n#from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, roc_auc_score\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport random\n\nfrom sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv', index_col='id')\ntest = pd.read_csv('../input/test.csv', index_col='id')\nsample_sub = pd.read_csv('../input/sample_submission.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60bb874ca0e00d2bcc146dc85343ce6c07bb4554","trusted":true},"cell_type":"code","source":"# split train in features and labels\nX_train = train.iloc[:, 1:]\ny_train = train.iloc[:, 0]\n\nX_test = test.iloc[:, :]\ny_test = sample_sub.iloc[:, 0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cde74912bd0a18eed3c7eaf843e1ef2cade1c7f0","trusted":true},"cell_type":"code","source":"# Number of labels per classes\ny_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67b8bccd686caefd3f2c3a6d599a90348ddcbdd4","trusted":true},"cell_type":"code","source":"# Number of labels per classes\nmax_samples = np.max(y_train.value_counts())\nclass_weight = y_train.value_counts()/max_samples\nclass_weight = class_weight.to_dict()\nclass_weight","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75f00e6d8989686e5c4f27a11b5730076ebe0d62","trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nimport time\n\ndef train_model(model, X, y, X_test, \\\n                folds=None, \\\n                averaging='usual', \\\n                model_type='sklearn', \\\n                tf_session=None, \\\n                epochs=10, \\\n                class_weight=None):\n    n_fold = 10\n    if(folds is None):\n        folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n    \n    oof = np.zeros(len(X))\n    prediction = np.zeros(len(X_test))\n    scores = []\n    feature_importance = pd.DataFrame()\n    \n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        #print('Fold', fold_n, 'started at', time.ctime())\n        #print(train_index, valid_index)\n        X_train, X_valid = X[train_index], X[valid_index]\n        y_train, y_valid = y[train_index], y[valid_index]\n        \n        if(model_type == 'sklearn'):\n            model.fit(X_train, y_train)\n            y_pred_valid = model.predict(X_valid)\n            y_pred_valid = y_pred_valid.reshape(-1,)\n        elif(model_type == 'tensorflow'):\n            model.fit(X_train, y_train, epochs=epochs, class_weight=class_weight)\n            y_pred_valid = model.predict(X_valid)\n            y_pred_valid = y_pred_valid.eval(session=tf_session)\n            y_pred_valid = np.reshape(y_pred_valid, (-1,))\n        \n        score = roc_auc_score(y_valid, y_pred_valid)\n        #print(type(y_valid), type(y_pred_valid) )\n        print(f'Fold {fold_n}. AUC: {score:.4f}.')\n        #print('')\n\n        oof[valid_index] = y_pred_valid.reshape(-1,)\n        scores.append(score)\n        \n        if(model_type == 'sklearn'):\n            y_pred_test = model.predict_proba(X_test)[:, 1]\n            if averaging == 'usual':\n                prediction += y_pred_test/n_fold\n            elif averaging == 'rank':\n                prediction += pd.Series(y_pred_test).rank().values  \n        elif(model_type == 'tensorflow'):\n            y_pred_test = model.predict(X_test)\n            y_pred_test = y_pred_test.eval(session=tf_session)\n            y_pred_test = np.reshape(y_pred_test, (-1,))\n            \n            prediction += (y_pred_test/n_fold)\n        else:\n            prediction = 0\n    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n    return oof, prediction, scores","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49534c87662e299f546da58f31489e48d7ab2648","trusted":true},"cell_type":"code","source":"# Benchmark score\n# CV mean score: 0.7635, std: 0.0469.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34a8da6c11b7448b18953e19f48804db922725c7","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\nminMaxScaler= MinMaxScaler()\nscaler = StandardScaler()\n\nX_train = train.iloc[:, 1:]\ny_train = train.iloc[:, 0]\n\nX_test = test.iloc[:, :]\ny_test = sample_sub.iloc[:, 0]\n\nX_train_scl = scaler.fit_transform(X_train)\nX_test_scl = scaler.transform(X_test)\n\n#X_train_scl = minMaxScaler.fit_transform(X_train_scl)\n#X_test_scl = minMaxScaler.transform(X_test_scl)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b817eea1fd957a5fdef9fc1e8cf1b6f36b583064","trusted":true},"cell_type":"code","source":"class C3POModel:\n    def __init__(self, input_dim=300, debug=False, autoencoder=True):\n        #initializer = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n        #initializer = keras.initializers.RandomUniform()\n        \n        ##### Autoencoder block to get peculiar features in unsupervised manner ####\n        X = keras.layers.Input(shape=(input_dim, ), name='Input')\n        if(autoencoder):\n            Y = keras.layers.Dense(input_dim, input_dim=input_dim, name='encoder_layer_1', \n                                   #kernel_regularizer=keras.regularizers.l1(0.01),\n                                   activation='tanh')(X)\n            Y = keras.layers.Dense(int(input_dim/3), name='encoder_layer_2', \n                                   #kernel_regularizer=keras.regularizers.l1(0.01),\n                                   activation='tanh')(Y)\n            #Y = keras.layers.Dense(input_dim, name='encoder_layer_3', \n            #                       activation='tanh')(Y)\n            #Y = keras.layers.Dense(150, name='encoder_layer_4', \n            #                       activation='tanh')(Y)\n            Y = keras.layers.Dense(input_dim, name='encoder_layer_5', \n                                   #kernel_regularizer=keras.regularizers.l1(0.01),\n                                   activation='tanh')(Y)\n\n            #### Average encoded and raw data\n            Y = keras.layers.Average()([X, Y])\n        else:\n            Y = X\n        Y = keras.layers.Dense(input_dim, name='layer_1',\n                               kernel_regularizer=keras.regularizers.l1_l2(0.01),\n                               activation='tanh')(Y)\n        #Y = keras.layers.Dropout(0.5)(Y)\n        Y = keras.layers.Dense(input_dim*2, name='layer_2', \n                               kernel_regularizer=keras.regularizers.l1_l2(0.01),\n                               activation='sigmoid')(Y)\n        #Y = keras.layers.Dropout(0.5)(Y)\n        Y = keras.layers.Dense(1, name='layer_4', \n                               activation='sigmoid')(Y)\n        self.net = keras.Model(X, Y)\n        \n        self.net.compile(optimizer='adadelta',\n              loss=keras.losses.MSE,\n              metrics=['accuracy'])\n        if(debug):\n            print(self.net.summary())\n        pass\n    \n    def fit(self, X, y, epochs=5, verbose=0, validation_split=0.1, class_weight=None):\n        callback = None # [\n            #keras.callbacks.EarlyStopping(patience=5),\n            #keras.callbacks.ReduceLROnPlateau(patience=5, verbose=1)\n            #keras.callbacks.ModelCheckpoint(filepath=\"C3POModel_weights.hdf5\", verbose=0, save_best_only=True)\n        #]\n        history = self.net.fit(X, \n                               y, \n                               epochs=epochs, \n                               verbose=verbose, \n                               validation_split=validation_split,\n                               callbacks=callback,\n                               class_weight=class_weight\n                              )\n        return history\n    \n    def evaluate(self, X, y):\n        return self.net.evaluate(X, y)\n    \n    def predict(self, X):\n        #print('called predict()')\n        return self.net.call(tf.convert_to_tensor(X, dtype=tf.float32))\n    \n    def load_weights(self, filepath):\n        self.net.load_weights(filepath)\n        pass\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f2f2dda882cc5f10cd971590677121aedda3dbe","scrolled":false,"trusted":true},"cell_type":"code","source":"from keras import backend\nbackend.clear_session()\n\nwith tf.Session() as sess:\n    init_op = tf.global_variables_initializer()\n    sess.run(init_op)\n    model = C3POModel(input_dim=X_train.shape[1], autoencoder=True)\n    oof, prediction, scores = train_model(model, \\\n                                          X_train_scl, \\\n                                          y_train, \\\n                                          X_test_scl, \\\n                                          model_type='tensorflow', \\\n                                          tf_session=sess, \\\n                                          class_weight=class_weight)\n    \n    y_pred = model.predict(X_test_scl)\n    y_pred = y_pred.eval(session=sess)\n    y_pred = np.reshape(y_pred, (-1,))\n    \n    prediction = y_pred #(prediction+y_pred)/2\n    auc_score = roc_auc_score(y_true=np.append(y_test, (1, 0)), y_score=np.append(np.where(prediction < 0.5, 0, 1), (1, 0)))\n    acc_score = accuracy_score(y_true=np.append(y_test, (1, 0)), y_pred=np.append(np.where(prediction < 0.5, 0, 1), (1, 0)))\n    \n    print(auc_score, acc_score)\n    submit = pd.read_csv('../input/sample_submission.csv')\n    submit[\"target\"] = prediction\n    submit.to_csv(\"submission.csv\", index=False)\n    #print(submit.head(30))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e054715863a36def7e45f1174e80e6c88f22c285","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41f98bccf0468ee06109a753cce0b06b296ab4b2","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}