{"nbformat_minor": 1, "nbformat": 4, "cells": [{"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "import matplotlib.pyplot as plt\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "metadata": {"_cell_guid": "bd526fb1-6242-4b43-a030-744662cf2ff3", "_uuid": "ca74ddacb04cc363742b6cb2420c74d7c16a5b36"}, "execution_count": null, "cell_type": "code"}, {"source": ["train = pd.read_csv(\"../input/train.csv\",parse_dates=[\"date\"],index_col='date')\n", "train[\"onpromotion\"].fillna(0, inplace=True)\n", "train['id'] = train['id'].astype(np.uint32)\n", "train['store_nbr'] = train['store_nbr'].astype(np.uint8)\n", "train['item_nbr'] = train['item_nbr'].astype(np.uint32)\n", "train['unit_sales'] = train['unit_sales'].astype(np.uint32)\n", "train[\"onpromotion\"]=train[\"onpromotion\"].astype(np.int8)"], "outputs": [], "metadata": {"_cell_guid": "8ea5dc53-b0ee-4ad1-a6d4-34e432e408d4", "_uuid": "b6a965848c098405616129605bba94d3bf74cd36"}, "execution_count": null, "cell_type": "code"}, {"source": ["test = pd.read_csv(\"../input/test.csv\",parse_dates=[\"date\"],index_col='date')\n", "test[\"onpromotion\"].fillna(0, inplace=True)\n", "test['id'] = test['id'].astype(np.uint32)\n", "test['store_nbr'] = test['store_nbr'].astype(np.uint8)\n", "test['item_nbr'] = test['item_nbr'].astype(np.uint32)\n", "test[\"onpromotion\"]=test[\"onpromotion\"].astype(np.int8)"], "outputs": [], "metadata": {"_cell_guid": "94574838-1850-46b1-bb43-f177dc015e17", "collapsed": true, "_uuid": "03f89b40096abd645132c50f634737a9cbd3319f"}, "execution_count": null, "cell_type": "code"}, {"source": ["items = pd.read_csv('../input/items.csv')\n", "transaction = pd.read_csv('../input/transactions.csv')\n", "stores = pd.read_csv('../input/stores.csv')"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["print(\"Total Obsevations before sampling\",len(train))\n", "strain = train.sample(frac=0.01,replace=True)\n", "#print(\"Total Obsevations after sampling\",len(test))\n", "print(\"Total Obsevations after sampling\",len(strain))"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["df = strain.merge(right = items, on='item_nbr', right_index  = True)\n", "df = df.merge(right=stores,on='store_nbr', right_index  = True)"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["dft = test.merge(right = items, on='item_nbr', right_index  = True)\n", "dft = dft.merge(right=stores,on='store_nbr', right_index  = True)"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["from sklearn.model_selection import GridSearchCV\n", "df.drop(['city','state','id'], axis=1,inplace=True)\n", "dft.drop(['city','state','id'], axis=1,inplace=True)\n", "ohe_df = pd.get_dummies(df, columns=['onpromotion','family','type'])    \n", "ohe_dft = pd.get_dummies(dft, columns=['onpromotion','family','type'])  "], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["from sklearn.model_selection   import train_test_split\n", "\n", "unitSales = ohe_df['unit_sales']\n", "features = ohe_df.drop('unit_sales', axis = 1)\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(features, unitSales, test_size=0.2, random_state=42)\n", "print(X_test.shape[0], X_train.shape[0],ohe_df.shape[0])"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["import time\n", "from sklearn.neural_network import MLPRegressor\n", "\n", "stime=time.time()\n", "mlpc = MLPRegressor(hidden_layer_sizes=(100, 300, 100), activation='relu', \n", "                         solver='adam', alpha=0.005, learning_rate_init = 0.001, shuffle=False)\n", "\n", "mlpc.fit(X_train, y_train)\n", "etime=time.time()"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["print(etime-stime)\n", "prediction = mlpc.predict(X_test)\n"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["prediction = pd.DataFrame(prediction, index=X_test.index,columns=['PedictedSale'])\n", "sub =  pd.concat([prediction, y_test.to_frame()], axis=1)\n", "sub =  pd.concat([sub, X_test['perishable'].to_frame()], axis=1)"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["sub['newPS'] = sub.apply(lambda row: 0 if(row['PedictedSale']<0) else row['PedictedSale'] , axis=1)\n", "sub['newUS'] = sub.apply(lambda row: 0 if(row['unit_sales']<0) else row['unit_sales'] , axis=1)"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["sub['newPS'] = np.log(sub.newPS + 1 )\n", "sub['newUS'] = np.log(sub.newPS + 1 )\n", "sub['yhatminusy'] = (sub['newPS']-sub['newUS'])**2\n", "sub['perishable'] = sub.perishable>0\n", "sub['perishableW'] = sub.apply(lambda row: 1.5 if(row['perishable']) else 1, axis=1)\n", "sub['comp1'] = sub.yhatminusy*sub.perishableW\n", "\n", "sub.head()"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["ax = sub['PedictedSale'].resample('m').mean().plot(figsize = (15, 6), color='red')\n", "fig = sub['unit_sales'].resample('m').mean().plot(ax=ax).get_figure()\n", "plt.legend(['Predicted Sale', 'actual'], loc='upper right')\n", "plt.show()"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["(sub.comp1.sum()/sub.perishableW.sum())**0.5"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["Following are results **without considering** 'city','state','id' while training model\n", "\n", "**Test Dataset** | **Train Dataset Size**  | **NWRMSLE **\n", "\n", "X_test  | 0.0001 | 0.68249025011606335\n", "\n", "X_test  | 0.001  | 1.094370399919558\n", "\n", "X_test  | 0.01    | 1.1043093902342433 \n", "\n", "____________________________________________\n", "\n", "Following are results **with considering** 'city','state','id' while training model\n", "\n", "**Test Dataset** | **Train Dataset Size**  | **NWRMSLE **\n", "\n", "X_test  | 0.0001 | 1.0789754618301821\n", "\n", "X_test  | 0.001  | 1.0688842227424471\n", "\n", "X_test  | 0.01    | 1.1023627733144485 \n", "\n", "\n", "\n", "test  | 0.001 | \n", "\n", "X_test  | 0.01 | 1.094370399919558\n", "\n"], "metadata": {}, "cell_type": "markdown"}], "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "file_extension": ".py", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3"}}}