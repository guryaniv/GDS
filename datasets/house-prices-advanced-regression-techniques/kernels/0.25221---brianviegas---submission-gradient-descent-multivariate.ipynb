{"cells":[{"metadata":{"_uuid":"15f48498b478753feb1edfa61d47cc16c6bf0251"},"cell_type":"markdown","source":"Based on the poor initial results of Gradient Descent algorithm using all variables without log transformation and outliers removal, this submission was performed considering the use of these techniques.\n\n* Learning rate (alpha) = 0.00000003\n* Number of iterations = 1000\n* Random initial theta values \n* Score = 0.25221"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom scipy.stats import skew\npd.options.mode.chained_assignment = None  # default='warn'\n\n\n#######################  LINEAR REGRESSION ###########################\ndef predict(theta, x_test):\n    if len(x_test.shape) < 2:\n        x_test = x_test.reshape(-1,1)\n        x_test = np.insert(x_test, 0, 1, 1)\n    return np.dot(x_test, theta) \n\n######################### GRADIENT DESCENT ALGORITHM ####################\ndef compute_cost(features, values, theta):\n    m = len(values)\n    sum_of_square_errors = np.square(np.dot(features, theta) - values).sum()\n    cost = sum_of_square_errors / (2*m)\n    return cost\n\ndef gradient_descent(features, values, alpha, num_iterations):\n    if len(features.shape) < 2:\n        features = features.reshape(-1,1)\n        features = np.insert(features, 0, 1, 1)    \n    theta = abs(np.random.normal(0,0.00002, size = features[0].shape))\n    m = len(values)\n    cost_history = []\n    for i in range(num_iterations):\n        predict_values = np.dot(features, theta)\n        theta = theta - (alpha / m * np.dot((predict_values - values), features))\n        cost_theta = compute_cost(features, values, theta)\n        cost_history.append(cost_theta)\n    return theta, pd.Series(cost_history)\n\n########################## END OF GRADIENT DESCENT ALGORITHM #######################\n########################## MISSING VALUES #########################################\ndef handle_missing_values(data):\n    for col in ('PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', \n            'GarageCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType'):\n        train_data[col] = train_data[col].fillna('None')\n        test_data[col] = test_data[col].fillna('None')\n    for col in ('GarageYrBlt', 'GarageArea', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', \n            'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea'):\n        train_data[col] = train_data[col].fillna(0)\n        test_data[col] = test_data[col].fillna(0)\n    train_data[\"LotFrontage\"] = train_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\n    test_data[\"LotFrontage\"] = test_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\n    \n##########################\n# Input train data\nfile_path = '../input/train.csv' \ntrain_data = pd.read_csv(file_path)\n# Input test data\ntest_data = pd.read_csv('../input/test.csv')\n\n# Handle the missing values\nhandle_missing_values(train_data)\nhandle_missing_values(test_data)\n\n# Removing GrLivArea > 4000 square feet area and eletrical input from train data\ntrain_data = train_data.drop(train_data.loc[train_data['Electrical'].isnull()].index)\ntrain_data = train_data[train_data.GrLivArea < 4000]\n\n# Log Transformation of GrLivArea and SalePrice\ntrain_data['GrLivArea'] = np.log(train_data['GrLivArea'])\ntest_data['GrLivArea'] = np.log(test_data['GrLivArea'])\ntrain_data['SalePrice'] = np.log(train_data['SalePrice'])\n\n# Spliting features and values from train data\ntrain_test_data = train_data['SalePrice']\ntrain_data = train_data.drop(['SalePrice'], axis = 1)\n\n# One-hot enconding for both train and test data. The data sets are concatenated, encoded and splited again\ntrain_objs_num = len(train_data)\ndataset = pd.concat(objs=[train_data, test_data], axis=0, sort=False)\ndataset_preprocessed = pd.get_dummies(dataset)\ntrain_data = dataset_preprocessed[:train_objs_num]\ntest_data = dataset_preprocessed[train_objs_num:]\n\n# Log Transformation of all numerical variables with skewness > 0.5\ncategorical_features = train_data.select_dtypes(include = [\"object\"]).columns\ntrain_data_categorical = train_data[categorical_features]\nnumerical_features = train_data.select_dtypes(exclude = [\"object\"]).columns\ntrain_data_numerical = train_data[numerical_features]\nskewness = train_data_numerical.apply(lambda x: skew(x))\nskewness = skewness[abs(skewness) > 0.5]\nskewed_features = skewness.index\ntrain_data_numerical[skewed_features] = np.log1p(train_data_numerical[skewed_features])\n# Test data transformation \ntest_data[skewed_features] = np.log1p(test_data[skewed_features])\n\n# Join categorical and numerical variables\ntrain_data = pd.concat([train_data_numerical, train_data_categorical], axis = 1)\n\n# Formats train_x and test_x\ntrain_x = np.array(train_data)\ntest_x = np.array(test_data)\n\n# Process the gradient descent\nprint(\"Starting regression\")\ntheta_gradient_descent, cost_history = gradient_descent(train_x, train_test_data, 0.00000003, 1000)\npredictions = predict(theta_gradient_descent, test_data)\n#Transform the preditions back\npredictions = np.exp(predictions)\nsubmission = pd.DataFrame({'Id': test_data.Id, 'SalePrice': predictions})\nsubmission.to_csv('submission_multi_gradient_final2.csv', index=False)\nprint(\"Done\")\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}