{"cells":[{"metadata":{"_cell_guid":"22f37db7-757c-46cd-a39f-02cce86c5aa5","_uuid":"2af61b09b65dae48f6fd306b218a4df690a318dd"},"cell_type":"markdown","source":"Loads the ETF data, computes a bunch of ad-hoc features for each day, and then builds an xgboost classifier to predict whether an ETF will close higher tomorrow.\n\nAccuracy is ~53%, which is hardly better than chance.\n\nThis is my first kaggle kernel and my first time using XGBoost.\n\n![I have no idea what I'm doing](https://i.imgur.com/AfgkjCf.jpg)"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n\nPATH = '../input/Data/ETFs'\netfs = dict()\nfor filename in os.listdir(PATH):\n    if not filename.endswith('.txt'):\n        print('Skipping', filename)\n        continue\n    etfs[filename[:-4]] = pd.read_csv(PATH + '/' + filename)\nprint('Loaded', len(etfs), 'ETFs')","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"a81bf5c8-e6b8-466d-8895-10dbc0f69002","_uuid":"c0d9ebba2d0aabf48072ec2aa8976fce723f508d","trusted":true,"collapsed":true},"cell_type":"code","source":"def prepare_samples(etf):\n    # Delete rows where opening or closing prices is 0,\n    # since we can't compute pct_change for those.\n    etf = etf[(etf['Open'] != 0) & (etf['Close'] != 0)]\n    \n    samples = pd.DataFrame()\n    # Target\n    samples['target'] = (etf['Close'].pct_change() > 0).shift(-1)\n    \n    # Features\n    samples['Open_chg'] = etf['Open'].pct_change()\n    for days in range(1, 6):\n        samples['Open_chg_' + str(days) + 'days_ago'] = samples['Open_chg'].shift(days)\n    \n    samples['Open_return'] = 1.0 + samples['Open_chg']\n\n    samples['Open_above_30day_avg'] = (etf['Open'] > etf['Open'].rolling(30).mean()).astype(np.float)\n\n    samples['Open_5day_return'] = samples['Open_return'].rolling(5).apply(np.prod)\n    samples['Open_10day_return'] = samples['Open_return'].rolling(10).apply(np.prod)\n\n    chg_functions = {'std': np.std, 'mean': np.mean, 'max': np.max}\n    for name, function in chg_functions.items():\n        samples['Open_chg_5day_' + name] = samples['Open_chg'].rolling(5).apply(function)\n        samples['Open_chg_10day_' + name] = samples['Open_chg'].rolling(10).apply(function)\n\n    del samples['Open_return']\n    \n    return samples.iloc[30:-1]\n\nsamples = pd.concat([prepare_samples(etfs[symbol]) for symbol in etfs.keys()])","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"525a6505-a544-4dae-aed3-a6a69568d252","_uuid":"136c87040e69b3e7bb9a70c97e8951370e348e6f","trusted":true},"cell_type":"code","source":"print('Prepared', len(samples), 'samples.')","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"7eb314e9-f423-4b44-9f0f-ddb4850c0620","_uuid":"a178d23969b29d9c3f4f71de72a8903be2e89d80","trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import Imputer, StandardScaler\nfrom sklearn.utils import shuffle\n\nshuffled_samples = shuffle(samples, random_state=2610)\ny = shuffled_samples['target']\nX = shuffled_samples.drop(['target'], axis=1)\ntrain_X, test_X, train_y, test_y = train_test_split(X.as_matrix(), y.as_matrix(), test_size=0.25)\nscaler = StandardScaler().fit(train_X)\ntrain_X = scaler.transform(train_X)\ntest_X = scaler.transform(test_X)","execution_count":43,"outputs":[]},{"metadata":{"_cell_guid":"1c76a098-75f1-4411-870c-5f0161eb01c1","_uuid":"bf3ca77cfee2f700dfb30e2ea6cd58c87a2cda12","scrolled":true,"trusted":true},"cell_type":"code","source":"train_X.shape","execution_count":44,"outputs":[]},{"metadata":{"_cell_guid":"720d29f6-e840-4d7e-8943-ea4bd3fb4c81","_uuid":"c7cee20b79185b8ed34f7645569e25414925e1e9","trusted":true,"scrolled":true},"cell_type":"code","source":"import xgboost\n\nmodel = xgboost.XGBClassifier(n_estimators=130, learning_rate=1.0)\nmodel.fit(train_X, train_y)","execution_count":56,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e0f5353122c7c935fcbeada1e6517b60b5e2090"},"cell_type":"code","source":"model.best_score","execution_count":57,"outputs":[]},{"metadata":{"_cell_guid":"535fa58f-e50d-4084-8ba3-66ed773c5c9d","_uuid":"8cbcf2a4438c28f75d5d7a438abd0c0cbe122f27","trusted":true},"cell_type":"code","source":"print('Accuracy', (model.predict(test_X) == test_y).mean())","execution_count":58,"outputs":[]},{"metadata":{"_cell_guid":"9a4eb2db-cfde-48f7-a18c-441609a690b3","_uuid":"cce2bf15655e86263d6b490e7831dd55b98c5c8d","trusted":true},"cell_type":"code","source":"print('Random model accuracy', ((np.random.rand(len(test_y)) < 0.5) == test_y).mean())\nprint('Constant True model accuracy', (True == test_y).mean())\nprint('Constant False model accuracy', (False == test_y).mean())","execution_count":59,"outputs":[]},{"metadata":{"_uuid":"a25486314a72fb764a7c6f68c8db8d912828dcb9","_cell_guid":"8464ec9b-0b81-4c79-9bb9-704125e9d634","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimportances = sorted(zip(X.columns, model.feature_importances_), key=lambda i: -i[1])\nplt.figure(figsize=(10, 5))\nplt.bar(range(len(importances)), [i[1] for i in importances])\nplt.xticks(range(len(importances)), [i[0] for i in importances], rotation=90);","execution_count":60,"outputs":[]},{"metadata":{"_uuid":"b1a60e2e2d5eb079e3f5cd3097a2d40e4ebc0c7a","_cell_guid":"2471c7d9-a1b5-4877-9a56-a07bc320e063","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}