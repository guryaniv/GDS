{"cells":[{"metadata":{"trusted":true,"_uuid":"e3b90ba4a9f096a2d6a5d27499aa87a1b34ed28a"},"cell_type":"markdown","source":"import os\nos.environ['KMP_DUPLICATE_LIB_OK']='True'"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.linear_model import HuberRegressor, LinearRegression\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nfrom tqdm import tnrange,tqdm_notebook\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import NuSVR, SVR\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import ShuffleSplit, KFold\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.svm import SVR\n\nfrom scipy.signal import hilbert\nfrom scipy.signal import hann\nfrom scipy.signal import convolve\nfrom scipy import stats\n\nimport matplotlib.pyplot as plt\nimport gc\n\nimport xgboost as xgb\nimport seaborn as sns\nfrom xgboost import XGBRegressor\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"markdown","source":"%%time\ntrain = pd.read_csv('../input/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n#print(\"train shape\", train.shape)\n#pd.set_option(\"display.precision\", 15)  # show more decimals\n#train.head()"},{"metadata":{"_uuid":"94c878e444b076ed778305b3e75ae763f18ee7dd","trusted":true},"cell_type":"code","source":"print(\"train shape\", train.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36511a7f6d48c5e8c0a88ec54cdefd8a2bdf2f72","trusted":true},"cell_type":"code","source":"pd.set_option(\"display.precision\", 15)  # show more decimals","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"384a566455e0d27c0ac679fe01c64cd35ef3a349"},"cell_type":"code","source":"def featurize(x):\n    X = pd.Series()\n    \n    X['mean'] = x.mean()\n    X['std'] = x.std()\n    X['max'] = x.max()\n    X['min'] = x.min()\n\n\n    X['mean_change_abs'] = np.mean(np.diff(x))\n    X['mean_change_rate'] = np.mean(np.nonzero((np.diff(x) / x[:-1]))[0])\n\n    X['max_to_min'] = x.max() / np.abs(x.min())\n    X['max_to_min_diff'] = x.max() - np.abs(x.min())\n    X['count_big'] = len(x[np.abs(x) > 500])\n    X['sum'] = x.sum()\n\n    X['q95'] = np.quantile(x, 0.95)\n    X['q99'] = np.quantile(x, 0.99)\n    X['q05'] = np.quantile(x, 0.05)\n    X['q01'] = np.quantile(x, 0.01)\n\n    X['mad'] = x.mad()\n    X['kurt'] = x.kurtosis()\n    X['skew'] = x.skew()\n    X['med'] = x.median()\n\n    X['iqr'] = np.subtract(*np.percentile(x, [75, 25]))\n    X['q999'] = np.quantile(x,0.999)\n    X['q001'] = np.quantile(x,0.001)\n    X['ave10'] = stats.trim_mean(x, 0.1)\n\n    '''for windows in [10, 100, 1000]:\n        if len(x) < windows:\n            continue\n        x_roll_std = x.rolling(windows).std().dropna().values\n        x_roll_mean = x.rolling(windows).mean().dropna().values\n\n        X['ave_roll_std_' + str(windows)] = x_roll_std.mean()\n        X['std_roll_std_' + str(windows)] = x_roll_std.std()\n        X['max_roll_std_' + str(windows)] = x_roll_std.max()\n        X['min_roll_std_' + str(windows)] = x_roll_std.min()\n        X['q01_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.01)\n        X['q05_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.05)\n        X['q95_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.95)\n        X['q99_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.99)\n        X['av_change_abs_roll_std_' + str(windows)] = np.mean(np.diff(x_roll_std))\n        X['av_change_rate_roll_std_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_std) / x_roll_std[:-1]))[0])\n        X['abs_max_roll_std_' + str(windows)] = np.abs(x_roll_std).max()\n\n        X['ave_roll_mean_' + str(windows)] = x_roll_mean.mean()\n        X['std_roll_mean_' + str(windows)] = x_roll_mean.std()\n        X['max_roll_mean_' + str(windows)] = x_roll_mean.max()\n        X['min_roll_mean_' + str(windows)] = x_roll_mean.min()\n        X['q01_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.01)\n        X['q05_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.05)\n        X['q95_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.95)\n        X['q99_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.99)\n        X['av_change_abs_roll_mean_' + str(windows)] = np.mean(np.diff(x_roll_mean))\n        X['av_change_rate_roll_mean_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_mean) / x_roll_mean[:-1]))[0])\n        X['abs_max_roll_mean_' + str(windows)] = np.abs(x_roll_mean).max()'''\n    #print(X.shape)\n    return X.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ae199b0c62ef99ae3eedc61584c5028a36030a2"},"cell_type":"code","source":"def featurize_ts(x, n_steps=150):\n    res = []\n    for i in range(x.shape[0]):\n        series = pd.Series(x[i, :])\n        #print(series.shape)\n        res.append(featurize(series))\n    arr = np.array(res)\n    #print(arr.shape)\n    return arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a18e7d8a8f753cd91ff7880b15c2157da02e7f6"},"cell_type":"code","source":"def create_X(x, last_index=None, n_steps=150, step_length=1000):\n    if last_index == None:\n        last_index=len(x)\n       \n    assert last_index - n_steps * step_length >= 0\n\n    # Reshaping and approximate standardization with mean 5 and std 3.\n    # ORIGINAL: I changed this becuase I got an No OpKernel was registered to support Op 'CudnnRNN' error\n    #temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1) - 5 ) / 3\n    # MY CHANGE: This doesn't fix things, I get the same errors\n    temp = (x[(last_index - n_steps * step_length):last_index].values.reshape(n_steps, -1))#.astype(np.float32) - 5 ) / 3\n    #print(temp.shape)\n    \n    # Extracts features of sequences of full length 1000, of the last 100 values and finally also \n    # of the last 10 observations. \n    return np.c_[featurize_ts(temp),\n                 featurize_ts(temp[:, -step_length // 10:]),\n                 featurize_ts(temp[:, -step_length // 100:])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a77932a5082c4776da646784a9c621945e8bedc"},"cell_type":"code","source":"float_data = train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7d0dce6c329779a0f0776668bc6d5240a9afabc"},"cell_type":"code","source":"#https://gist.github.com/platdrag/e755f3947552804c42633a99ffd325d4\nimport threading\n'''\n    A generic iterator and generator that takes any iterator and wrap it to make it thread safe.\n    This method was introducted by Anand Chitipothu in http://anandology.com/blog/using-iterators-and-generators/\n    but was not compatible with python 3. This modified version is now compatible and works both in python 2.8 and 3.0 \n'''\nclass threadsafe_iter:\n    \"\"\"Takes an iterator/generator and makes it thread-safe by\n    serializing call to the `next` method of given iterator/generator.\n    \"\"\"\n    def __init__(self, it):\n        self.it = it\n        self.lock = threading.Lock()\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        with self.lock:\n            return self.it.__next__()\n\ndef threadsafe_generator(f):\n    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n    \"\"\"\n    def g(*a, **kw):\n        return threadsafe_iter(f(*a, **kw))\n    return g","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"611732de53ffa4f3865f89209173959135e611a8"},"cell_type":"code","source":"# Query \"create_X\" to figure out the number of features\nn_features = create_X(float_data.loc[0:150000, :]).shape[1]\nprint(\"Our RNN is based on %i features\"% n_features)\n\n# The generator endlessly selects \"batch_size\" ending positions of sub-time series. For each ending position,\n# the \"time_to_failure\" serves as target, while the features are created by the function \"create_X\".\n@threadsafe_generator\ndef generator(data, min_index=0, max_index=None, batch_size=16, n_steps=150, step_length=1000):\n    if max_index is None:\n        max_index = len(data) - 1\n     \n    while True:\n        # Pick indices of ending positions\n        rows = np.random.randint(min_index + n_steps * step_length, max_index, size=batch_size)\n         \n        # Initialize feature matrices and targets\n        samples = np.zeros((batch_size, n_steps, n_features))\n        targets = np.zeros(batch_size, )\n        \n        for j, row in enumerate(rows):\n            samples[j] = create_X(data.iloc[:, 0], last_index=row, n_steps=n_steps, step_length=step_length)\n            targets[j] = data.iloc[row - 1, 1]\n        yield samples, targets\n        \nbatch_size = 32\n\n# Position of second (of 16) earthquake. Used to have a clean split\n# between train and validation\nsecond_earthquake = 50085877\nfloat_data.iloc[second_earthquake, 1]\n\n# Initialize generators\n# train_gen = generator(float_data, batch_size=batch_size) # Use this for better score\ntrain_gen = generator(float_data, batch_size=batch_size, min_index=second_earthquake + 1)\nvalid_gen = generator(float_data, batch_size=batch_size, max_index=second_earthquake)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8daa7f1955ecaecc6dca128df981809acaae01fa"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, GRU\nfrom keras.optimizers import adam\nfrom keras.callbacks import ModelCheckpoint\n\ncb = [ModelCheckpoint(\"model.hdf5\", save_best_only=True, period=3)]\n\nmodel = Sequential()\nmodel.add(GRU(48, input_shape=(None, n_features)))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(1))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5650ac1458357a5362e91c615eb611bd8e627ff"},"cell_type":"code","source":"model.compile(optimizer=adam(lr=0.0005), loss=\"mae\")\n\nhistory = model.fit_generator(train_gen,\n                              steps_per_epoch=1000,\n                              epochs=30,\n                              verbose=0,\n                              callbacks=cb,\n                              validation_data=valid_gen,\n                              validation_steps=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8640a951f6580bee4dca2201ab3348b40898117"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef perf_plot(history, what = 'loss'):\n    x = history.history[what]\n    val_x = history.history['val_' + what]\n    epochs = np.asarray(history.epoch) + 1\n    \n    plt.plot(epochs, x, 'bo', label = \"Training \" + what)\n    plt.plot(epochs, val_x, 'b', label = \"Validation \" + what)\n    plt.title(\"Training and validation \" + what)\n    plt.xlabel(\"Epochs\")\n    plt.legend()\n    plt.show()\n    return None\n\nperf_plot(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"acb857aa2dd4beec0adfa68db8bd2828a0a0644b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}