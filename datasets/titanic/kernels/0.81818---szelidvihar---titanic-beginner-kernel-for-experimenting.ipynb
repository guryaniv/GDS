{"cells":[{"metadata":{"_uuid":"a3f644072dacb262d679425cfd13d90544d58a76"},"cell_type":"markdown","source":"# Introduction\nI have created this kernel for beginners. However I am also a beginner, so it has been a way of learning for me. I would really appreciate any expert comments. Many features are defined (most based on other kernels I studied), but not all of them are used. I tried to keep explanations concise.\n\nSome kernels I studied: \n- [Erik Bruin's kernel](https://www.kaggle.com/erikbruin/titanic-2nd-degree-families-and-majority-voting)\n- [Konstantin's kernel](https://www.kaggle.com/konstantinmasich/titanic-0-82-0-83)\n- [Manav Sehgal's kernel](https://www.kaggle.com/startupsci/titanic-data-science-solutions)"},{"metadata":{"_uuid":"c5dd6a94c5723b5981121207e940b2d065769b4d","trusted":false},"cell_type":"code","source":"# Settings\nshow_graphs = True\nadd_interactions = False\nmodel_tuning = False\nfeature_selection = False ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"fd35c3952537fa5cc3f37b0ca251b3a8503127b2"},"cell_type":"code","source":"# The features with 1 will be used as predictors directly in the models.  \n\nused_features = {\n    'PassengerId': 0,\n    'Pclass': 1,\n    'Name': 0,\n    'LastName': 0,\n    'Title': 0,                 \n    'Sex': 1,\n    'Sex-female x Pclass-1-2': 1,\n    'Sex-male x Pclass-3': 0,\n    'SibSp': 0, \n    'Parch': 0,\n    'FamilySize': 0,\n    'FamilySizeBin': 0,\n    'IsAloneF': 0,\n    'Age': 0,\n    'AgeBin': 1,\n    'IsChild': 0,\n    'IsChild x Pclass-1-2': 1,\n    'Cabin': 0, \n    'HasCabin': 0,\n    'CabinType': 0,\n    'Embarked': 0,\n    'Ticket': 0,\n    'TicketSize': 1,\n    'TicketSizeBin': 0,\n    'IsAloneT': 1,\n    'Fare': 0,\n    'FareOrig': 0,\n    'FareBin': 1,\n    'NameFareSize': 0,\n    'Group': 0,\n    'GroupSurvived': 1,\n    'GroupSize': 0\n}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# ML models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom xgboost import XGBClassifier\n\n# Utils\nimport os\nimport scipy\nfrom itertools import compress\nfrom sklearn.preprocessing import PolynomialFeatures, LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_validate, GridSearchCV, RandomizedSearchCV\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2793eb85b40d2f9a3c6660c16cf866f4920ab6ab","trusted":false},"cell_type":"code","source":"# Functions\ndef gridgraph(df, x, col=None, row=None, hue=None, fun=sns.distplot, **fun_kwargs):\n    grid = sns.FacetGrid(df, col=col, row=row, hue=hue, size=4)\n    grid = grid.map(fun, x, **fun_kwargs)\n    grid.add_legend()\n    if fun_kwargs['kde']:\n        for ax in grid.axes.flat:\n            drawmedian(ax)\n    \ndef catgroup(df, catcol, target, fun=\"mean\"):\n    print(df.groupby(catcol, as_index=False)[target].agg(fun))\n    \ndef drawmedian(ax):\n    for line in ax.get_lines():\n        x, y = line.get_data()\n        cdf = scipy.integrate.cumtrapz(y, x, initial=0)\n        middle = np.abs(cdf-0.5).argmin()\n\n        median_x = x[middle]\n        median_y = y[middle]\n\n        ax.vlines(median_x, 0, median_y)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"# Read data\nHere we read the input files, and concatenate them to have the full data in one dataframe. This will make data cleaning tasks easier. If we need to use the target, we will filter to the training part."},{"metadata":{"_uuid":"6853c53177ca8b29b1727f70e02e45d3c2b884c5","trusted":false},"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv')\ndf_valid = pd.read_csv('../input/test.csv')\nyt = df_train['Survived']\n\n# Create unified data\ndf_train['Data'] = 'T'\ndf_valid['Data'] = 'V'\ndf_full = pd.concat([df_train, df_valid], sort=False, ignore_index=True) \nmask_train = df_full['Data'] == 'T' \nmask_valid = df_full['Data'] == 'V' ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b048a306934537b4f13f01d3a55a1b70f0b993a"},"cell_type":"markdown","source":"# Data cleaning and EDA\nHere I will look at each feature individually, and do the following:\n- Analyze: Check stats, correlate to target, visualize, etc.\n- Correct: Fix data errors, outliers, check if values are reasonable, handle missing values. \n- Derive: Do feature engineering. \n- Convert: Use correct datatypes, data format (e. g. dummies), do necessary transformations (e. g. scaling)."},{"metadata":{"_uuid":"7c68be8f2d515f298a1c775edb1e6aa4013fe1ab"},"cell_type":"markdown","source":"### Overall stats\nHere we look at overall statistics as a starting point."},{"metadata":{"_uuid":"41f178aa5de22a701ab9c53d64225b92c9e8f887","scrolled":true,"trusted":false},"cell_type":"code","source":"# Check datatypes, missing values\ndf_full.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"91300bf35b2332b64a19c9d641b8614e71d4e920"},"cell_type":"code","source":"# Check stats of the columns.\ndf_full.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fb56dce27a27fb522f17e2708f46e7393b45d58"},"cell_type":"markdown","source":"We have seen that\n- Age, Fare, Embarked, and Cabin have missing values.\n- There are 0 values in Fare, which is strange."},{"metadata":{"_uuid":"886c7bb0064bb1b867f530c3ee890df4a27fcde3"},"cell_type":"markdown","source":"### PassengerId\nNot really useful as predictor, because it is just an ID."},{"metadata":{"_uuid":"76f26dcbb32bc72cadd9a3b8fd119def6536cb2a"},"cell_type":"markdown","source":"### Pclass\nWe check the average rate of survival in each class."},{"metadata":{"trusted":false,"_uuid":"c6c1a4678f76a5b3fd5f46836fd61cc51b1f4af0"},"cell_type":"code","source":"catgroup(df_full.loc[mask_train], 'Pclass', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"pixiedust":{"displayParams":{}},"scrolled":true,"trusted":false,"_uuid":"749c955047714e88933814bdb6c1ad15260ec9db"},"cell_type":"code","source":"if show_graphs:\n    sns.barplot(x='Pclass', y='Survived', order=[1,2,3], data=df_full[mask_train], palette='colorblind')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"159bb0a79c22d26a3dd1a8be008c510e5d20cc10"},"cell_type":"markdown","source":"We see that the survival rate is much higher if class value is lower. This feature can be useful in the model. "},{"metadata":{"_uuid":"6b30912ad27dfe79b53dced28bc053f5b85a1687"},"cell_type":"markdown","source":"### Name\nName contains many information. We can extract titles and last names, and form groups based on them. So we will use Name to derive new features."},{"metadata":{"_uuid":"94846f045635e8637900d9d01472fea5788eff7d"},"cell_type":"markdown","source":"### LastName (derived from Name)\nWe might be able to find families based on last name, provided we can differentiate between families with the same name. We will go deeper into this later. "},{"metadata":{"trusted":false,"_uuid":"4d298a472371925f20f214ac5e0301318d2ec74c"},"cell_type":"code","source":"df_full['LastName'] = df_full['Name'].str.extract('^([^,]+),', expand=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"274e70e233b07ee4931d5c5bfc4ed8a7afc18151"},"cell_type":"markdown","source":"### Title (derived from Name)\nTitle can tell us about sex (Mr./Mrs.), age (Master is child, Miss is young), class (Countess, Lady, etc. probably have 1st class ticket), so it can be useful.\n\nThere is some noise in this feature, in the form of rare titles. We group these first."},{"metadata":{"_uuid":"e8fced7ba02de74d1a74fae1ebf023ba366dc04e","trusted":false},"cell_type":"code","source":"df_full['Title'] = df_full['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n# Change rare titles to more common categories\ndict_replace = {\n    \"Capt\": \"Officer\",\n    \"Col\": \"Officer\",\n    \"Countess\": \"Noble\",\n    \"Don\": \"Noble\",\n    \"Dona\": \"Noble\",\n    \"Dr\": \"Noble\",\n    \"Jonkheer\": \"Noble\",\n    \"Lady\": \"Noble\",\n    \"Major\": \"Officer\",\n    \"Mlle\": \"Miss\",\n    \"Mme\": \"Mrs\",\n    \"Ms\": \"Miss\",\n    \"Rev\": \"Noble\",\n    \"Sir\": \"Noble\",\n}\n\ndf_full['Title'] = df_full['Title'].replace(dict_replace)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53a547a3b09cabc4f72ba3f257f8e6f172fee52b"},"cell_type":"markdown","source":"Title may not be that useful as predictor, because We already have the information it would give in columns Age, Sex, and Pclass."},{"metadata":{"_uuid":"cfa8cd8f78e366b773f6818129b6102802114fbf"},"cell_type":"markdown","source":"### Sex\nSex is probably the most useful feature, see below."},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"1d1bdc095953fef9dc581283bbc9f9ec33094a2a"},"cell_type":"code","source":"catgroup(df_full.loc[mask_train], 'Sex', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51b9e2fdf0928687400d56b7a048c464c81b96bf"},"cell_type":"markdown","source":"We convert this to integers."},{"metadata":{"trusted":false,"_uuid":"8b492ea476c3e286a7ad6c00f0b321dd80b5920f"},"cell_type":"code","source":"df_full['Sex'] = df_full['Sex'].map({'male': 0, 'female': 1})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19fa1fa7b70028e99f9af35f8e622e0148b77459"},"cell_type":"markdown","source":"We see that females have a lot more chance to survive, so Sex is very predictive."},{"metadata":{"_uuid":"caddcabc598280e0f05f7f01f15bc81a6590cf00"},"cell_type":"markdown","source":"### Sex-female x Pclass-1-2 (derived from Sex and Pclass)\nWe can check the rate of survival in groups formed by Pclass and Sex categories."},{"metadata":{"pixiedust":{"displayParams":{}},"scrolled":true,"trusted":false,"_uuid":"681e97bed0f91674b1fb8398d428ca26d94c0755"},"cell_type":"code","source":"if show_graphs:\n    gridgraph(df_full[mask_train], 'Survived', col='Pclass', row='Sex', bins=2, kde=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d9597349e288c5b4b15ef877c0db561eca41988"},"cell_type":"markdown","source":"We see that in 1st and 2nd class, Sex is much more predictive, so we create an interaction feature."},{"metadata":{"trusted":false,"_uuid":"d587e4206584c608249eae8ab6c6f2dfbcac4be6"},"cell_type":"code","source":"mask_female = df_full['Sex'] == 1\nmask_class12 = df_full['Pclass'].isin([1, 2])\ndf_full['Sex-female x Pclass-1-2'] = (mask_female & mask_class12).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f0b55ae9804257df031214786a4139df7ab3e98"},"cell_type":"markdown","source":"Check how predictive it is."},{"metadata":{"trusted":false,"_uuid":"b67f78f3a5ca13cd552b9099b2bc9054585500be"},"cell_type":"code","source":"catgroup(df_full.loc[mask_train], 'Sex-female x Pclass-1-2', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68b430ebdda2cdbae8decabedd15cce3a4a2945d"},"cell_type":"markdown","source":"It predicts female survival very accurately in 1st and 2nd class."},{"metadata":{"_uuid":"749dd89242a4bfa72dda521f67dd4e85487d04f0"},"cell_type":"markdown","source":"### Sex-male x Pclass-3 (derived from Sex and Pclass)\nIn 3rd class, Sex is also much more predictive, so we create another interaction feature."},{"metadata":{"trusted":false,"_uuid":"9cc9abda9e3cbc53b91954d37810d71a5bf5c765"},"cell_type":"code","source":"mask_male = df_full['Sex'] == 0\nmask_class3 = df_full['Pclass'] == 3\ndf_full['Sex-male x Pclass-3'] = (mask_male & mask_class3).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7ce93d402c1da5a1370853f3a7008d0a79699803"},"cell_type":"code","source":"catgroup(df_full.loc[mask_train], 'Sex-male x Pclass-3', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0224aa1005e333aa353f6c318efb235dce1c78d8"},"cell_type":"markdown","source":"This feature predicts male perishing very accurately in 3rd class."},{"metadata":{"_uuid":"e1074a296d3c26db7ea9e53b1b5289212838f55a"},"cell_type":"markdown","source":"### SibSp and Parch \nThese features are not that useful in their initial form, but we can use them to derive other features."},{"metadata":{"_uuid":"9552eaf7696489954dd7c3969da109a9df44efcd"},"cell_type":"markdown","source":"### FamilySize (derived from SibSp and Parch)\nWe can check how predictive this feature is."},{"metadata":{"trusted":false,"_uuid":"62e92514db57c2e88afae0fe57489333028b9a08"},"cell_type":"code","source":"df_full['FamilySize'] = df_full['SibSp'] + df_full['Parch'] + 1","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"8ab805fb02205f76166bf34f4d561f378b9c056e"},"cell_type":"code","source":"catgroup(df_full[mask_train], 'FamilySize', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"ebf5ec5613f114c7d4729fd46fe74bee1e978968"},"cell_type":"code","source":"if show_graphs:\n    sns.barplot(x='FamilySize', y='Survived', data=df_full[mask_train], palette='colorblind')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c431c33de0f40f22575694fb1755c931ad6e67b"},"cell_type":"markdown","source":"It seems that having a family size of 2-4 is best. We can create bins that reflect this more."},{"metadata":{"_uuid":"8f1aaf6a2c0c573093eefe0905b589f1490e4a17"},"cell_type":"markdown","source":"### FamilySizeBin (derived from FamilySize)\nWe will use three categories here."},{"metadata":{"_uuid":"b45fc182f1b0c5fe4bb391f980307a693bd1dea6","trusted":false},"cell_type":"code","source":"# Create categories for FamilySize\ndf_full['FamilySizeBin'] = pd.cut(df_full['FamilySize'], [0, 1, 4, 20], labels=[\"alone\", \"normal\", \"big\"])\ncatgroup(df_full.loc[mask_train], 'FamilySizeBin', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66cbf6caf8327ceaf5e54ef766d9e1b88e0b865e"},"cell_type":"markdown","source":"We encode this feature as integers."},{"metadata":{"trusted":false,"_uuid":"a2a94fd6785ed4367be1a9192c4baa34fd98ae2d"},"cell_type":"code","source":"df_full['FamilySizeBin'] = df_full['FamilySizeBin'].map({'alone': 0, 'normal': 1, 'big': 2})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35c7945ca0a661287f296930cc5ca706b3409877"},"cell_type":"markdown","source":"###  IsAloneF (derived from FamilySizeBin)\nWe will create a separate variable for being alone, it may help in some models. "},{"metadata":{"_uuid":"937b82ec9ce63b331e2756bcf69868ea6c77593a","trusted":false},"cell_type":"code","source":"df_full['IsAloneF'] = (df_full['FamilySizeBin'] == 0).astype(int)\ncatgroup(df_full.loc[mask_train], 'IsAloneF', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d57e44a07758b1990c770023e8b06b2d5b05a75"},"cell_type":"markdown","source":"### Age\nThere are a lot of missing values here, so first we check who has missing age. It is important to get ages right. My experience is that it can add a lot to performance, but it is easy to overfit."},{"metadata":{"_uuid":"6f5141a88314dfce419056bcac649649d0d40880","trusted":false},"cell_type":"code","source":"# Check who has missing age.\nmask_noage = df_full['Age'].isnull()\ndf_noage = df_full.loc[mask_noage]\n\ndf_noage.groupby(['Title', 'Pclass'], as_index=False)['Name'].count()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"136c51420bdffb36e4603c89d2b27c748a2406c7"},"cell_type":"markdown","source":"Mostly men from 3rd class have missing age. Children with missing age are also almost exclusively from 3rd class.\n\nNow let us check the Age distributions in each Pclass value, for survived and perished passengers."},{"metadata":{"trusted":false,"_uuid":"09e1779980cd2d9fb8a8f80cd8d2e7b0116be673"},"cell_type":"code","source":"# Check Age distributions.\nif show_graphs:\n    bins = np.linspace(0, 100, 20)\n    gridgraph(df_full.loc[mask_train], 'Age', col='Pclass', hue='Survived', kde=False, bins=bins)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"945d0e7d730c051309791ef96ff342161ba43a3d"},"cell_type":"markdown","source":"We see that children have a better survival rate in 1st and 2nd class. In 3rd class, there is not much difference. This means that it is not so important to impute accurate ages for 3rd class children. If we still wanted to do that, then for female children, the title \"Miss\" and Parch > 0 could be a good age predictor, because most young passengers are with parents, and while Parch > 0 can also indicate a child for an older passenger, their title is more likely Mrs, not Miss.\n\nWe expect that the median age is different in each Pclass, and for each Sex. Title is also a good proxy for Age, and it contains also sex information (Master is male child, Mr is male adult, Miss is young female, Mrs is older female).\n\nTherefore we could use the median ages of (Pclass, Title) groups, however my experience is that using only Title medians gives better performance."},{"metadata":{"_uuid":"af07c9661eea7d3fe18a4cdaece594df6dd1d3e7"},"cell_type":"markdown","source":"Fixing missing values: \n\n- For the rest of theall of the passengers, we will group by Pclass and Title, and impute with the group median age."},{"metadata":{"_uuid":"e6b1406d397651639b3541811ae0c551ade7a48d","scrolled":true,"trusted":false},"cell_type":"code","source":"# Check Age distributions.\nif show_graphs:\n    bins = np.linspace(0, 100, 20)\n    gridgraph(df_full, 'Age', row='Title', kde=True, bins=bins)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6aa12d4c16990af884dee7b101dc8e21c78a7a0f","trusted":false},"cell_type":"code","source":"# Impute Age\ndf_medians = df_full.groupby('Title')['Age'].median()\nfor idx, median in df_medians.iteritems():\n    mask_group = df_full['Title'] == idx\n    df_full.loc[mask_group & mask_noage, 'Age'] = median","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e71ad8cfc82b58a1b422da31ba1660845e07f37"},"cell_type":"markdown","source":"### AgeBin (derived from Age)\nWe create categorical feature from Age here."},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"b917b7858bc79ea8aa26c78392e4e1e9e5f779f1"},"cell_type":"code","source":"df_full['AgeBin'] = pd.qcut(df_full['Age'], 4, labels=False).astype(int)\nif show_graphs:\n    sns.barplot(x='AgeBin', y='Survived', data=df_full[mask_train], palette='colorblind')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"498762962b14db59f3d231db74818c28150a9e73"},"cell_type":"markdown","source":"### IsChild (derived from Age and Pclass)\nThis feature represents the fact that children have better survival rates."},{"metadata":{"_uuid":"c445ca058e35fb136f94a3285eee205f52f86fc1","scrolled":true,"trusted":false},"cell_type":"code","source":"df_full['IsChild'] = (df_full['Age'] < 16).astype(int)\ncatgroup(df_full.loc[mask_train], 'IsChild', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"457d1378eac4580772b664320bd457a3d13f59ee"},"cell_type":"markdown","source":"### IsChild x Pclass-1-2 (derived from IsChild and Pclass)\nWe have seen that children have better chances only in 1st and 2nd classes. Thus we create an interaction feature representing this."},{"metadata":{"_uuid":"4f19a23828a824cb7037ce4032ddbe5c3c476388","trusted":false},"cell_type":"code","source":"mask_class12 = df_full['Pclass'].isin([1, 2])\ndf_full['IsChild x Pclass-1-2'] = df_full['IsChild'] * mask_class12.astype(int)\ncatgroup(df_full.loc[mask_train], 'IsChild x Pclass-1-2', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b62364e81421225ca5f4a29f709134b8b5e24735"},"cell_type":"markdown","source":"### Cabin\nCabin information was found mostly for 1st class passengers only, so most of it is missing. We can still check whether having cabin information or the type of cabin gives any advantage."},{"metadata":{"_uuid":"aa4295730452ab9c95e0931628cd73894ecff4cd"},"cell_type":"markdown","source":"### HasCabin\nWe look at the effect of having cabin information. It is expected to correlate with being in 1st class."},{"metadata":{"_uuid":"6c27e69827453d768bf231faa0d899be56992f76","scrolled":true,"trusted":false},"cell_type":"code","source":"df_full['HasCabin'] = df_full['Cabin'].notnull().astype(int)\nmask_class1 = (df_full['Pclass'] == 1).astype(int)\n\nprint(\"Correlation with 1st class: \", df_full['HasCabin'].corr(mask_class1))\ncatgroup(df_full.loc[mask_train], 'HasCabin', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17ba2e6a4fce40e7648d8fab53af1fc9060e3106"},"cell_type":"markdown","source":"The group that has cabin information truly correlates with 1st class.  "},{"metadata":{"_uuid":"d9347cd6319759a4149ecd66d340cff0ba017a8a"},"cell_type":"markdown","source":"### CabinType\nWe check if the type of cabin adds any advantage."},{"metadata":{"_uuid":"6c27e69827453d768bf231faa0d899be56992f76","scrolled":true,"trusted":false},"cell_type":"code","source":"df_full['CabinType'] = df_full['Cabin'].str[0]\ncatgroup(df_full.loc[mask_train], 'CabinType', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d224ae4ed0ea70e1fba19f0db9f1be3ce630cf62"},"cell_type":"markdown","source":"In the group that has cabin info, there is no predictive power in having any cabin type. (There is only one passenger with type T, so that does not count.)"},{"metadata":{"_uuid":"5334ff14b95c0881eae3183a5599387fae449c84"},"cell_type":"markdown","source":"### Embarked\nWe can check for any correlation between survival chance and town of boarding. It is hard to imagine any strong causality in the background though, so we do not expect too much useful result.\n\nFirst, we fill the missing values."},{"metadata":{"_uuid":"0899be4b1a88ae4fec3c0d8687df9426baa15200","trusted":false},"cell_type":"code","source":"# See who is missing Embarked\nmask_noembarked = df_full['Embarked'].isnull()\ndf_full[mask_noembarked]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd845c7ec33c4edfb0e2452708bf13a835f2ad63"},"cell_type":"markdown","source":"Their Ticket number does not unambiguously identify Embarked, but some internet search reveals that it is Southampton, which is also the most frequent value."},{"metadata":{"_uuid":"b74ae3a6112190c46e40954a3a3bb863ac4fd62a","trusted":false},"cell_type":"code","source":"# Impute missing Embarked with most frequent value ('S')\ndf_full['Embarked'].fillna(df_full['Embarked'].mode()[0], inplace=True)\nif show_graphs:\n    sns.barplot(x='Embarked', y='Survived', data=df_full[mask_train], palette='colorblind')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"426bac3ce1cc6a9e26c51faddfbf2a252bb1ef4a"},"cell_type":"markdown","source":"We see that passengers from Cherbourg have the highest chance to survive, but it could be just noise."},{"metadata":{"_uuid":"3080b817a7d0acb44b5fa024b398f3fec39fc896"},"cell_type":"markdown","source":"### Ticket\nWe can observe that sometimes multiple people have the same ticket number. This suggests that they are a group traveling together. We can use this information to create a feature similar to FamilySize."},{"metadata":{"_uuid":"58bcb0dae4a7c41f14bd279fe746c6a032467b72"},"cell_type":"markdown","source":"### TicketSize (derived from Ticket)\nThis feature also captures the dependence of survival chance on the size of the traveling group, just like FamilySize. "},{"metadata":{"_uuid":"c57b97786ba63c2211a04132b185334aa06c176e","scrolled":true,"trusted":false},"cell_type":"code","source":"# Check survival rate in function of group size.\ndf_ticket = df_full.loc[mask_train].groupby('Ticket', as_index=False)['Survived', 'Name'].agg({'Survived': 'mean', 'Name': 'count'})\ndf_ticket = df_ticket.groupby('Name', as_index=False)['Survived'].mean()\ndf_ticket = df_ticket.sort_values(by='Survived')\ndf_ticket","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"782fdbcb6826a9c5c11e9549f38ee13639c74746"},"cell_type":"markdown","source":"We see that similarly to FamilySize, groups of 2-4 seem to be ideal. "},{"metadata":{"_uuid":"c57b97786ba63c2211a04132b185334aa06c176e","trusted":false},"cell_type":"code","source":"df_ticket = df_full.groupby('Ticket')['Name'].count()\ndf_full['TicketSize'] = df_full['Ticket'].map(df_ticket)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ed1f22554f5605cf97cc9d9d807cccafa90f2d1"},"cell_type":"markdown","source":"Check the correlation between TicketSize and FamilySize."},{"metadata":{"_uuid":"d4635b9665ed4ac70d000fecd58d74b8aa15bb37","trusted":false},"cell_type":"code","source":"print('Correlation: ', df_full[['TicketSize', 'FamilySize']].corr().values[0, 1])\n(df_full['TicketSize'] - df_full['FamilySize']).hist(bins=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d089be8c21ab78ac80e9ffcb699f010a720ebb87"},"cell_type":"markdown","source":"TicketSize and FamilySize are strongly correlated."},{"metadata":{"_uuid":"2c1d564154beee4f8bc5937b50c96b2d60e29cb0"},"cell_type":"markdown","source":"### TicketSizeBin (derived from TicketSize)\nWe will assign Ticket based group sizes into categories, like we did with FamilySize."},{"metadata":{"_uuid":"b45fc182f1b0c5fe4bb391f980307a693bd1dea6","trusted":false},"cell_type":"code","source":"df_full['TicketSizeBin'] = pd.cut(df_full['TicketSize'], [0, 1, 4, 20], labels=[\"alone\", \"normal\", \"big\"])\ncatgroup(df_full.loc[mask_train], 'TicketSizeBin', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4427ef991607e61e1c03f925735eafb7bf76063"},"cell_type":"markdown","source":"We encode this feature as integers."},{"metadata":{"trusted":false,"_uuid":"4aded74fcf5ae9561fd73bf8c4d400e3188a906e"},"cell_type":"code","source":"df_full['TicketSizeBin'] = df_full['TicketSizeBin'].map({'alone': 0, 'normal': 1, 'big': 2})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e967710a59c2ac81a718552272d6758b6b287d6"},"cell_type":"markdown","source":"###  IsAloneT (derived from TicketSizeBin)\nWe will create the \"traveling alone\" indicator from the TicketSizeBin feature too."},{"metadata":{"_uuid":"937b82ec9ce63b331e2756bcf69868ea6c77593a","trusted":false},"cell_type":"code","source":"df_full['IsAloneT'] = (df_full['TicketSizeBin'] == 0).astype(int)\ncatgroup(df_full.loc[mask_train], 'IsAloneT', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5f47930fab11afd50b927d575aac77aa6754177"},"cell_type":"markdown","source":"It seems that IsAloneT is slightly better predictor than IsAloneF (though the difference can be just noise)."},{"metadata":{"_uuid":"92e401295a4e535beb7436b7423be655efc1adb1"},"cell_type":"markdown","source":"### Fare\nWe can observe in the data that Fare is given for the ticket, not for the individual passenger. Therefore we divide fare values with TicketSize. (We could also try FamilySize though.)"},{"metadata":{"_uuid":"85c476856375be317bd6a86667bb883beb2672a3","trusted":false},"cell_type":"code","source":"fare_scaler = 'TicketSize'\ndf_full['Fare'] = df_full['Fare'] / df_full[fare_scaler]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bafeaf1676a6d4071ff5e1dbc54b438232456fd"},"cell_type":"markdown","source":"We have seen that there are passengers with zero fare. They are either members of the Titanic \"guarantee group\", or their tickets were bought by their company, or they worked on the Philadelphia, that was canceled due to the coal strike (LINE tickets). \n\nWe could think that\n- these are data errors, and we do not expect similar records in real data, therefore we have to fix them using e. g. some group medians. \n- these are special kind of passengers, and similar ones can appear in real data too, so we do not touch them. \n\nHere we go with the second assumption."},{"metadata":{"_uuid":"8f242a7f78da90f36e0c715a9b02bcbc00136cde","scrolled":true,"trusted":false},"cell_type":"code","source":"mask_zerofare = df_full['Fare'] == 0\ndf_full.loc[mask_zerofare]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04938bb94e48491903ec21baa3568d0ead4affdf"},"cell_type":"markdown","source":"These are all adult (aged 20-50) males embarked at Southampton and traveling alone. We could assign a median fare for them based on this group, if we wanted. "},{"metadata":{"_uuid":"8f242a7f78da90f36e0c715a9b02bcbc00136cde","scrolled":true},"cell_type":"markdown","source":"There is also a 1st class passenger with a fare of 5 (Carlsson, Mr. Frans Olof), which is an outlier. (He bought this for the St Louis, which was canceled because of the coal strike, so his company bought him a 1st class ticket for Titanic.) \n\nWe could fix this too, but we will not. (In fact, there could be many more such deviations in the data, it is not our goal to look for these here...)"},{"metadata":{"_uuid":"6995e81c41435dda8a21acbf8597415fb5e252eb"},"cell_type":"markdown","source":"Now, we impute missing values with the median fare. Only one value is missing, so it does not matter too much in this case."},{"metadata":{"_uuid":"c07ba461a980bdebf18f1f04dc0c05ed9f946b16","trusted":false},"cell_type":"code","source":"df_full['Fare'].fillna(df_full['Fare'].median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fdf7b7d1220b9a18a5718ed4e02fc7f800e9f89b"},"cell_type":"markdown","source":"We would like to keep the original fare values too, in case we need them."},{"metadata":{"trusted":false,"_uuid":"a3b767a8153a2f4d9430275494f7b873421b154e"},"cell_type":"code","source":"df_full['FareOrig'] = df_full['Fare'] * df_full[fare_scaler] ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5977cd3f737c0b9f85434545379b26c2d2e2d5ac"},"cell_type":"markdown","source":"### FareBin (derived from Fare)\nHere we create a feature that is a categorized version of Fare."},{"metadata":{"_uuid":"8a06ad709c47b6a63e23a6d224b92a05b7472406","trusted":false},"cell_type":"code","source":"df_full['FareBin'] = pd.qcut(df_full['Fare'], 4, labels=False).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e402aecbb6a8fa6511571c2649b4fea00ab0635"},"cell_type":"markdown","source":"### NameFareSize (derived from LastName and FareOrig)\nThis feature is a third way of grouping. We can observe that fares are sometimes the same for people even if they are not on the same ticket. So we can make groups based on this."},{"metadata":{"_uuid":"c57b97786ba63c2211a04132b185334aa06c176e","scrolled":false,"trusted":false},"cell_type":"code","source":"# Check survival rate in function of group size.\ndf_familygroup = df_full.loc[mask_train].groupby(['LastName', 'FareOrig'], as_index=False)['Survived', 'Name'].agg({'Survived': 'mean', 'Name': 'count'})\ndf_familygroup = df_familygroup.groupby('Name', as_index=False)['Survived'].mean()\ndf_familygroup = df_familygroup.sort_values(by='Survived')\ndf_familygroup","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"894ec6a0e1685f2f81b63d9f90cea42ac0eab10f"},"cell_type":"markdown","source":"We see that this feature is similar to FamilySize and TicketSize, groups of 2-4 seem to be ideal. "},{"metadata":{"_uuid":"c57b97786ba63c2211a04132b185334aa06c176e","trusted":false},"cell_type":"code","source":"df_familygroup = df_full.groupby(['LastName', 'FareOrig'])['Name'].count()\ndf_full['NameFareSize'] = df_full[['LastName', 'FareOrig']].apply(lambda row: df_familygroup[(row[0], row[1])], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c39f85d41bb953bd331c5707f9ea5ba08f861539"},"cell_type":"markdown","source":"Check the correlation between NameFareSize, TicketSize and FamilySize."},{"metadata":{"_uuid":"d4635b9665ed4ac70d000fecd58d74b8aa15bb37","scrolled":true,"trusted":false},"cell_type":"code","source":"df_corr = df_full[['NameFareSize', 'TicketSize', 'FamilySize']].corr()\nprint(\"Correlation Familysize - NameFaresize = \", df_corr.loc['FamilySize', 'NameFareSize'])\nprint(\"Correlation Ticketsize - NameFaresize = \", df_corr.loc['TicketSize', 'NameFareSize'])\n(df_full['NameFareSize'] - df_full['FamilySize']).hist(bins=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b30f84e970b892bcc31b2002e94d44677a12b89c"},"cell_type":"markdown","source":"We see that NameFareSize correlates more with FamilySize, so we can use just FamilySize instead. This also suggests that using FamilySize in the model and for scaling Fares could be better."},{"metadata":{"_uuid":"dc47a0769a694e73130468143de31203b1056ba3"},"cell_type":"markdown","source":"### GroupSurvived (derived from LastName, FareOrig, and Ticket)\nNot only the size of groups can be important, but also whether any group members survived. The assumption here is that a passenger has better chance to survive if somebody survived in their group.\n\nWe will construct the groups here from both LastName, Fare, and Ticket information. First we use LastName and Fare."},{"metadata":{"trusted":false,"_uuid":"ac8cae1ff1070c4e732c99f6723616b1fa652e5c"},"cell_type":"code","source":"df_full['Group'] = ''\ndf_groups = df_full.groupby(['LastName', 'FareOrig'])\n\nfor group, df_group in df_groups:    \n    for idx, row in df_group.iterrows():\n        group_members = df_group.drop(idx)['PassengerId'].tolist()\n        df_full.at[idx, 'Group'] = group_members","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51fcf2a266327a4b732bef8cbd187fdb3490d30b"},"cell_type":"markdown","source":"Second, we construct groups based on Ticket."},{"metadata":{"trusted":false,"_uuid":"e97ea4b4f50264feee3e9792cb9c37a4e3128087"},"cell_type":"code","source":"df_groups = df_full.groupby('Ticket')\n\nfor group, df_group in df_groups:    \n    for idx, row in df_group.iterrows():\n        group_members = df_group.drop(idx)['PassengerId'].tolist()\n        df_full.at[idx, 'Group'].extend(group_members)\ndf_full['Group'] = df_full['Group'].map(set)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7e6c2f8faaf521a3585fda0bff8261ffc2a8654"},"cell_type":"markdown","source":"Last, we merge the two kind of groups for each passenger."},{"metadata":{"trusted":false,"_uuid":"cc3175ad75e82e361a9b71d858b29cad115b7797"},"cell_type":"code","source":"def group_survived(group):\n    mask_group = df_full['PassengerId'].isin(group)\n    s = df_full.loc[mask_group, 'Survived'].max()\n    return s if pd.notnull(s) else 0.5 \n\ndf_full['GroupSurvived'] = df_full['Group'].apply(group_survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a29f3330d4e0d5d842a201d86dec40c51c0c76ed"},"cell_type":"markdown","source":"We could construct another GroupSize type feature based on these groups, and check its performance, but we will skip this for now."},{"metadata":{"_uuid":"63a1eaddfa927f14d0e8e580c2b70bb4a8badaaf"},"cell_type":"markdown","source":"### GroupSize (derived from Group)\nThis is the fourth type of traveling group size feature."},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"2ff45b0a1e7ed12312b2299654022d7e559eb5a0"},"cell_type":"code","source":"df_full['GroupSize'] = df_full['Group'].str.len() + 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0eb10c51a02ab6cc33d0163fa878f7c18c064e3c"},"cell_type":"markdown","source":"Check how it performs."},{"metadata":{"_uuid":"c57b97786ba63c2211a04132b185334aa06c176e","scrolled":false,"trusted":false},"cell_type":"code","source":"# Check survival rate in function of group size.\ndf_fullgroup = df_full.loc[mask_train].groupby('GroupSize', as_index=False)['Survived'].mean()\ndf_fullgroup = df_fullgroup.sort_values(by='Survived')\ndf_fullgroup","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a4a5a737c7eb24ea3d80db55341af1d1eea102d"},"cell_type":"markdown","source":"Being in a 3-4 sized group is the best here. We can check how similar it is to previous group size features."},{"metadata":{"_uuid":"d4635b9665ed4ac70d000fecd58d74b8aa15bb37","scrolled":true,"trusted":false},"cell_type":"code","source":"df_corr = df_full[['NameFareSize', 'TicketSize', 'FamilySize', 'GroupSize']].corr()\nprint(\"Correlation Familysize - GroupSize = \", df_corr.loc['FamilySize', 'GroupSize'])\nprint(\"Correlation Ticketsize - Groupsize = \", df_corr.loc['TicketSize', 'GroupSize'])\nprint(\"Correlation NameFareSize - Groupsize = \", df_corr.loc['NameFareSize', 'GroupSize'])\n(df_full['GroupSize'] - df_full['TicketSize']).hist(bins=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1d1ca348c6e84e6bcfccacb46e0f14d4da94cd2"},"cell_type":"markdown","source":"We see that GroupSize correlates more with TicketSize, so we can use just TicketSize instead."},{"metadata":{"_uuid":"291bac0f1a458aea2056b3583966ff68f63f74ee"},"cell_type":"markdown","source":"### Used features\nWe are done with feature engineering, it is time to drop features, which we will not use for modeling."},{"metadata":{"_uuid":"60dd253e589516774329ff3b69a4beff3cfe10e0","scrolled":true,"trusted":false},"cell_type":"code","source":"list_drop_features = [name for name, include in used_features.items() if not include]\n\ndf_full.drop(columns=list_drop_features, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0a2480ddcb82b96f07d68171ceddd1c47b90269"},"cell_type":"markdown","source":"Check the correlation between remaining features."},{"metadata":{"_uuid":"4a7db033c581fc578ebb7ff9bda1405eb174e426","scrolled":true,"trusted":false},"cell_type":"code","source":"df_full.loc[mask_train].corr()\n#sns.heatmap(df_full[mask_train], annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba991fc7d169fc31ff733ae2cfa0a832daa765f6"},"cell_type":"markdown","source":"# Feature transformations"},{"metadata":{"_uuid":"785281b29113bb3d46bed920f2c0ddc8f88e5058"},"cell_type":"markdown","source":"### Scaling\nHere we apply scaling on the feature set. It might not be necessary for all of them, but it does not hurt."},{"metadata":{"trusted":false,"_uuid":"5fdd8caa9ae3b14226071797cff68dc42e5ca1ad"},"cell_type":"code","source":"base_columns = ['Survived', 'Data']\ndata_columns = [col for col in df_full.columns if col not in base_columns]\n\nscaler = StandardScaler()\ndf_full.loc[mask_train, data_columns] = scaler.fit_transform(df_full.loc[mask_train, data_columns])\ndf_full.loc[mask_valid, data_columns] = scaler.transform(df_full.loc[mask_valid, data_columns])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c011076bc61f96ab4f1f523da28b11f91ffd5309"},"cell_type":"markdown","source":"We separate the full dataset to training and validation parts."},{"metadata":{"_uuid":"abecfc7558a8db9bcb4adba5c192a3f2ef56e4ef","trusted":false},"cell_type":"code","source":"Xt = df_full.loc[mask_train].drop(columns=base_columns)\nXv = df_full.loc[mask_valid].drop(columns=base_columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba991fc7d169fc31ff733ae2cfa0a832daa765f6"},"cell_type":"markdown","source":"# Feature selection\nHere is a check that shows feature importances using LASSO."},{"metadata":{"_uuid":"9eda6173db16ceae9de03a65bd9f5234ec535ebe","scrolled":true,"trusted":false},"cell_type":"code","source":"# Logistic Regression LASSO\nif feature_selection:\n    threshold_pct = 0.1\n    lasso = LogisticRegression(penalty='l1', C=10, random_state=0, solver='saga', max_iter=200)\n    lasso.fit(Xt, yt)\n    print(\"Lasso accuracy on training data: \", lasso.score(Xt, yt))\n    \n    # Select features\n    coefs = np.absolute(lasso.coef_.flatten())\n    plt.hist(coefs, bins=20)\n    mask_features = coefs > (np.max(coefs) * threshold_pct)\n    new_columns = Xt.columns[mask_features]\n    df_features = pd.DataFrame({'Features': new_columns, 'Strength': coefs[mask_features]}).sort_values(by='Strength', ascending=False)\n    print(df_features)\n    \n    # Drop features with low importance\n    Xt = Xt[new_columns]\n    Xv = Xv[new_columns]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1877de5daed23066b068eba935381ba7f4e4ef0"},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"_uuid":"f61d58e533459398323090b08f15d16bfe389a25","scrolled":true},"cell_type":"markdown","source":"### Model evaluation\nHere we evaluate some simple models using cross validation."},{"metadata":{"_uuid":"bae6eb8638c66eac358a73dbecb2b8d7ce00c13b","trusted":false},"cell_type":"code","source":"# Models\nmodels = {}\nmodels['Logistic Regression'] = LogisticRegression(penalty='l2', C=1.0, random_state=0, solver='saga', max_iter=300)\nmodels['SVC_rbf'] = SVC(probability=True, kernel='rbf', gamma='scale', random_state=0)\nmodels['SVC_lin'] = SVC(probability=True, kernel='linear', random_state=0)\nmodels['KNN'] = KNeighborsClassifier(algorithm='auto', leaf_size=20, metric='minkowski', metric_params=None, \n                                     n_jobs=1, n_neighbors=10, p=3, weights='uniform')\ndtree_params = {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'min_impurity_decrease': 0.0, \n              'min_samples_leaf': 0.01, 'min_samples_split': 0.01, 'min_weight_fraction_leaf': 0.0, 'splitter': 'best'}\nmodels['Decision Tree'] = DecisionTreeClassifier(**dtree_params)\nmodels['Random Forest'] = RandomForestClassifier(criterion='entropy', n_estimators=200, oob_score=True)\nxgb_params = {'subsample': 0.5, 'reg_lambda': 5, 'reg_alpha': 0, 'n_estimators': 200, 'min_child_weight': 0, 'max_depth': 6, \n              'max_delta_step': 1, 'learning_rate': 1.0, 'gamma': 2, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.5}\nmodels['XGBoost'] = XGBClassifier(objective='binary:logistic', **xgb_params)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bae6eb8638c66eac358a73dbecb2b8d7ce00c13b","trusted":false},"cell_type":"code","source":"# Run CV using randomized folds (these can overlap).\nscoring = ['accuracy']  # We can give multiple metrics here \ncv = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n\nfor mname, model in models.items():\n    result = cross_validate(model, Xt, yt, scoring=scoring, cv=cv, return_train_score=False)\n    print(\"CV results for model {}: mean {:2.4f}, std {:2.4f}\".format(mname, np.mean(result['test_accuracy']), np.std(result['test_accuracy'])))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e38b5e8eb22c04ae309edbba2d10bcd464a8d29e"},"cell_type":"markdown","source":"### Model tuning\nHere we can do hyperparameter optimization."},{"metadata":{"_uuid":"df4590530b93121762fc8ce866dbdd901feaeba7","trusted":false},"cell_type":"code","source":"if model_tuning:\n    param_grid_XGBoost = {\n        'colsample_bytree': [0.1, 0.5, 1],\n        'colsample_bylevel': [0.1, 0.5, 1],\n        'subsample': [0.1, 0.5, 1], \n        'learning_rate': [0.05, 0.1, 0.3, 1.0],\n        'max_depth': [0, 3, 6, 10], \n        'reg_alpha': [0, 0.1, 1, 5],\n        'reg_lambda': [0, 0.1, 1, 5],\n        'gamma': [0, 1, 2, 5], \n        'n_estimators': [100, 200, 300, 500],\n        'min_child_weight': [0, 1, 2, 5],\n        'max_delta_step': [0, 1, 2, 5],\n    }\n\n    param_grid_DTC = {\n        'criterion': ['gini', 'entropy'], \n        'splitter': ['best', 'random'], \n        'max_depth': [None, 3, 5, 7, 10], \n        'min_samples_split': [2, 0.01, 0.05, 0.1],\n        'min_samples_leaf': [1, 0.01, 0.05, 0.1],\n        'min_weight_fraction_leaf': [0.0, 0.1, 0.2],\n        'max_features': [None, 'auto'], \n        'min_impurity_decrease': [0.0, 0.2, 0.4, 0.7],\n    }\n    #tune_model = RandomizedSearchCV(models['XGBoost'], param_distributions=param_grid_XGBoost, scoring='roc_auc', cv=cv, n_iter=1000)\n    tune_model = GridSearchCV(models['Decision Tree'], param_grid=param_grid_DTC, scoring='roc_auc', cv=cv)\n    tune_model.fit(Xt, yt)\n    print('Best parameters:\\n', tune_model.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24527e6ca6f4b541b8aee96b312bbda0cd795324"},"cell_type":"markdown","source":"# Prediction\nNow we use the validation data and create the predictions, and the submission files. \n\nNOTE: If we predicted based on Sex only, we could reach 74% accuracy. So we expect much better results from more complex models."},{"metadata":{"_uuid":"5d36453828a5603892c7ff6c8e0685f8b32a96ff","scrolled":false,"trusted":false},"cell_type":"code","source":"list_submit = models.keys()\ndict_submissions = {}\n\n# Loop over models\nfor mname in list_submit:\n    model = models[mname]\n    model.fit(Xt, yt)\n\n    # Check train data score\n    ytp = model.predict(Xt)\n    acc = model.score(Xt, yt)\n    #print(\"Accuracy of model \", mname, \" on train data: \", acc)\n\n    # Generate validation data score\n    yvp = model.predict(Xv)\n    dict_submissions[mname] = yvp\n    submission = pd.DataFrame({\"PassengerId\": df_valid[\"PassengerId\"], \"Survived\": yvp})\n    submission.to_csv('submission_{}.csv'.format(mname), index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f331fe341ae25bd93aeffbb43eeb0e06f98a45b"},"cell_type":"markdown","source":"Performances:\n- KNN: 0.8181\n- Decision Tree: 0.8086\n- SVC: 0.8086\n- Logistic Regression: 0.7894 "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}