{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import neighbors\nfrom sklearn.neighbors import KNeighborsRegressor\n\ncolor= sns.color_palette()\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"31ed556e-6ea4-4d04-9b99-be4c61fc1274","_uuid":"1999b22f3f47c7bde7db4446ed9e7aef316eca0c","trusted":false,"collapsed":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"67052aeb-2765-42a1-81f2-cd2731c3ba3e","_uuid":"f1e811b7eda192dd108181501689e0c0f74bd8fe","trusted":false,"collapsed":true},"cell_type":"code","source":"train_df=pd.read_csv(\"../input/train_2016_v2.csv\")\ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fb4d5c45-135a-47fb-8656-14d12b5271b5","_uuid":"f1905530324301d86155c6eed73c8e5a76fcbb10","trusted":false,"collapsed":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"61e6b423-4adc-48ba-a7f7-c46fd0e69cfa","_uuid":"a1006936dc44a2db89da5cd4a0553db05e939b44","trusted":false,"collapsed":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"78b3ff40-5d4f-4e91-a1f0-65220c00d8fb","_uuid":"b4012989c4a61dda26db43cba593c0e2b7d41d50"},"cell_type":"markdown","source":"**logerror**"},{"metadata":{"_cell_guid":"283cd9ed-68e0-4fea-bbf1-d2df61a0ecee","_uuid":"1ece95642bfca46f7475c4d6377ebd7658c50c64","trusted":false,"collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.logerror.values))\nplt.xlabel('index',fontsize=12)\nplt.ylabel('logerror',fontsize=12)\nplt.show()           ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"43e36def-c2e1-4c6f-949d-1fb0c5815459","_uuid":"f9a85ea75ef068bc7cd847af3669aae27601195b","trusted":false,"collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.distplot(train_df.logerror.values,bins=500,kde=False)\nplt.xlabel('logerror',fontsize=12)\nplt.xlim([-0.4,0.4])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3d30d766-bf77-4614-9b56-74406c883602","_uuid":"c150742c601687b80f5274e52423b0ae702e13e9"},"cell_type":"markdown","source":"**transaction date**"},{"metadata":{"_cell_guid":"cfd384f5-48b2-457c-a92b-ca88faa837c8","_uuid":"5c70350683ba2b7e32465f20f2f382814c68c901","trusted":false,"collapsed":true},"cell_type":"code","source":"train_df['transactiondate']=pd.to_datetime(train_df['transactiondate'])\ntrain_df['transaction_month']=train_df['transactiondate'].dt.month\n\nmonth_count=train_df['transaction_month'].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(month_count.index, month_count.values)\nplt.xlabel('Month of transaction',fontsize=12)\nplt.ylabel('Number of Occurrences',fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"03d5a1e2-8458-4141-8a2c-896db7e8ecb9","_uuid":"20851c19e0b2969c584bf5876097ee7dc0e83094"},"cell_type":"markdown","source":"**parcel id**"},{"metadata":{"_cell_guid":"d4f80277-efd4-4736-9108-48146e3a3f4e","_uuid":"aee0334cf3f292b738cfd06f90ca6a199ea99723","trusted":false,"collapsed":true},"cell_type":"code","source":"(train_df['parcelid'].value_counts()).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"00f44375-ad81-4646-954e-b069c7528e00","_uuid":"8e768e0cd609876c1deb6b0424c9fcb982412ca4"},"cell_type":"markdown","source":"**properties 2016 dataframe**"},{"metadata":{"_cell_guid":"93ff694e-fd10-487b-abb0-f28bd739db1f","_uuid":"fc09d62c4454d629dacf8b1adefee5292a835df2","trusted":false,"collapsed":true},"cell_type":"code","source":"prop_df=pd.read_csv(\"../input/properties_2016.csv\")\nprop_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b01fe01f-ce81-4a1c-bbc4-eea5f2738cc1","_uuid":"c5aea5f5b10b543ed2a24ffbec4ae6fbe558dbc6","trusted":false,"collapsed":true},"cell_type":"code","source":"prop_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a1ae3448-72f1-42f4-9c38-fead47efcc1b","_uuid":"761e43c5b1f16df12bb9dbb15cfdbe314da7a072","trusted":false,"collapsed":true},"cell_type":"code","source":"prop_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eb92d2bf-6bc4-4550-ab54-8c70121c6f88","_uuid":"d36d237d693a81528bc4310b93ec048187325933"},"cell_type":"markdown","source":"**missing values**"},{"metadata":{"_cell_guid":"10f6127a-3418-4d7f-9efb-cceefcfc3d1b","_uuid":"ffb1c5b0f5164010618023834fba97f97783986e","trusted":false,"collapsed":true},"cell_type":"code","source":"missing_df=prop_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns=['column_name', 'missing_count']\nmissing_df=missing_df.sort_values(by='missing_count')\nmissing_df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9259c0bd-cfe4-4abf-ae5a-da7a2011b42d","_uuid":"162f8c55a8a50f27aebd98a171160433368a097f","trusted":false,"collapsed":true},"cell_type":"code","source":"ind= np.arange(missing_df.shape[0])\nfig, ax =plt.subplots(figsize=(12,18))\nrects=ax.barh(ind, missing_df.missing_count.values)\nax.set_yticklabels(missing_df.column_name.values,rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_title(\"Number of missing values in each column\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ebefaedc-5a7e-4858-9e3f-3cf4bad10582","_uuid":"50984d39adc8e9824deb0f7e986d843dcbf6ab0f"},"cell_type":"markdown","source":"**merge train with properties**"},{"metadata":{"_cell_guid":"32a1e0eb-eed1-4690-b69c-642c2effeeda","_uuid":"88f89927419775c76db619ae886d50e2c98cc63a","trusted":false,"collapsed":true},"cell_type":"code","source":"train_df=pd.merge(train_df, prop_df, on='parcelid', how='left')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"71c4cf68-1519-422b-b82d-a8df10a0e64b","_uuid":"b043f873d323d67f09653db371885ec938f764e6","trusted":false,"collapsed":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b73f284e-5b9d-4a19-bf02-b62ae648c72f","_uuid":"ba3a02ed82dadb683cd6dd0c0f0843c7192cd102"},"cell_type":"markdown","source":"explore variables"},{"metadata":{"_cell_guid":"f0007587-9e89-4052-b3aa-653e06097ad9","_uuid":"351cdcd41649c62a2ee57ddf93f08834daa36718","trusted":false,"collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\nsns.jointplot(x=train_df.longitude.values, y=train_df.latitude.values, size=10)\nplt.ylabel('Latitude',fontsize=12)\nplt.xlabel('Longitude',fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1518239c-2a80-4f50-8c73-15856a121ddc","_uuid":"a0ae8eda9df9258dc6ae54f2ed29d70a25e7f90d","trusted":false,"collapsed":true},"cell_type":"code","source":"#plot heatmap to find correlations between variables\nplt.figure(figsize = (12,8))\nsns.heatmap(data=train_df.corr())\nplt.show()\nplt.gcf().clear()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4b1ef1b6-14f7-4829-9e2e-72683f39276a","_uuid":"4a7426b3dc2509be73a9b6411176ef4cfa68b4f7"},"cell_type":"markdown","source":"**missing values**"},{"metadata":{"_cell_guid":"e4dbe5bd-f586-4190-9f3d-78f5b46868b4","_uuid":"3d8e6f392ac36c33379b4f7e3c4039fcbd726cad","collapsed":true,"trusted":false},"cell_type":"code","source":"#missing_df=train_df.isnull().sum(axis=0).reset_index()\n#missing_df.columns=['column_name','missing_count']\n#missing_df['missing_ratio']=(missing_df['missing_count'])/train_df.shape[0]\n#missing_df.ix[missing_df['missing_ratio']>0.5]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8acb9449-da08-43cc-812c-21b1f31447f3","_uuid":"c473809abf39727be9ab0ab9a50bb74396bb5a49","collapsed":true,"trusted":false},"cell_type":"code","source":"#reduntant features\ndropcols = ['finishedsquarefeet12','finishedsquarefeet13', 'finishedsquarefeet15','finishedsquarefeet6','finishedsquarefeet50']\n#identical to bathroomcnt\ndropcols.append('calculatedbathnbr')\ndropcols.append('fullbathcnt')\n#if there is no data for hot tub, most likely there is no hot tub\nindex = train_df.hashottuborspa.isnull()\ntrain_df.loc[index,'hashottuborspa'] = \"None\"\n#too many missing values\ndropcols.append('pooltypeid10')\n#if pooltype id is null, most likely the pool doesnt exist\nindex = train_df.pooltypeid2.isnull()\ntrain_df.loc[index,'pooltypeid2'] = 0\n\nindex = train_df.pooltypeid7.isnull()\ntrain_df.loc[index,'pooltypeid7'] = 0\n\nindex = train_df.poolcnt.isnull()\ntrain_df.loc[index,'poolcnt'] = 0","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"94948284-0b4d-4e32-ab40-c166ebb7d6ab","_uuid":"0420b043586ee033a9a11cbac984c462c65f17d8","collapsed":true,"trusted":false},"cell_type":"code","source":"#for poolsizesum, fill in with median only for properties that have a pool\npoolsizesum_median = train_df.loc[train_df['poolcnt'] > 0, 'poolsizesum'].median()\ntrain_df.loc[(train_df['poolcnt'] > 0) & (train_df['poolsizesum'].isnull()), 'poolsizesum'] = poolsizesum_median\n#If property doesn't have a pool then poolsizesum is 0 \ntrain_df.loc[(train_df['poolcnt'] == 0), 'poolsizesum'] = 0","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b98f6be7-3c72-46d8-8904-ce4666b91019","_uuid":"35706e516fb7e0ec47efce5771545d80e3cedd54","collapsed":true,"trusted":false},"cell_type":"code","source":"#fireplaceflag and fireplacecnt\ntrain_df['fireplaceflag']= \"No\"\ntrain_df.loc[train_df['fireplacecnt']>0,'fireplaceflag']= \"Yes\"\n\nindex = train_df.fireplacecnt.isnull()\ntrain_df.loc[index,'fireplacecnt'] = 0\n\n#Tax deliquency flag - if it is null, most likely it doesn't exist\nindex = train_df.taxdelinquencyflag.isnull()\ntrain_df.loc[index,'taxdelinquencyflag'] = \"None\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ba97af8a-db3c-407e-bcaa-da5d27c13a2e","_uuid":"529b0f7d71aeccd48839737d8237523e7c78189b","collapsed":true,"trusted":false},"cell_type":"code","source":"#garagecarcnt and garagetotalsqft\n#if garage count is null, most likely there are no garages\nindex = train_df.garagecarcnt.isnull()\ntrain_df.loc[index,'garagecarcnt'] = 0\n#if no garage, garage size is 0\n#Likewise no garage means the size is 0 by default\nindex = train_df.garagetotalsqft.isnull()\ntrain_df.loc[index,'garagetotalsqft'] = 0\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e422f982-5fcf-4898-a1fa-7fac9824f936","_uuid":"298d2114fbe146f9a6710fbf0fa973503a250d88","trusted":false,"collapsed":true},"cell_type":"code","source":"#fill in missing values with most reasonable/common value\n#airconditioningtypeid\ntrain_df['airconditioningtypeid'].value_counts()\nindex = train_df.airconditioningtypeid.isnull()\ntrain_df.loc[index,'airconditioningtypeid'] = 1\n\n#heatingorsystemtypeid\nprint(train_df['heatingorsystemtypeid'].value_counts())\nindex = train_df.heatingorsystemtypeid.isnull()\ntrain_df.loc[index,'heatingorsystemtypeid'] = 2\n\n#threequarterbathnbr\nprint(train_df['threequarterbathnbr'].value_counts())\nindex = train_df.threequarterbathnbr.isnull()\ntrain_df.loc[index,'threequarterbathnbr'] = 1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bcef5b44-28db-44a2-a26f-bf71176abd05","_uuid":"d2a22b8893d0157ca6e1ed545c7d6b4be29cc020","trusted":false,"collapsed":true},"cell_type":"code","source":"#drop variables with more than 97% of values missing\nmissingvalues_prop = (train_df.isnull().sum()/len(train_df)).reset_index()\nmissingvalues_prop.columns = ['field','proportion']\nmissingvalues_prop = missingvalues_prop.sort_values(by = 'proportion', ascending = False)\nprint(missingvalues_prop)\nmissingvaluescols = missingvalues_prop[missingvalues_prop['proportion'] > 0.97].field.tolist()\ndropcols = dropcols + missingvaluescols\ntrain_df = train_df.drop(dropcols, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a5a57d3b-1d53-4590-9161-75db0cc4ee54","_uuid":"868988b51d7ecf268a0e9cf9e38a8db6cb84ae0a","collapsed":true,"trusted":false},"cell_type":"code","source":"def fillna_knn( df, base, target, fraction = 1, threshold = 10, n_neighbors = 5 ):\n    assert isinstance( base , list ) or isinstance( base , np.ndarray ) and isinstance( target, str ) \n    whole = [ target ] + base\n    \n    miss = df[target].isnull()\n    notmiss = ~miss \n    nummiss = miss.sum()\n    \n    enc = OneHotEncoder()\n    X_target = df.loc[ notmiss, whole ].sample( frac = fraction )\n    \n    enc.fit( X_target[ target ].unique().reshape( (-1,1) ) )\n    \n    Y = enc.transform( X_target[ target ].values.reshape((-1,1)) ).toarray()\n    X = X_target[ base  ]\n    \n    print( 'fitting' )\n    n_neighbors = n_neighbors\n    clf = neighbors.KNeighborsClassifier( n_neighbors, weights = 'uniform' )\n    clf.fit( X, Y )\n    \n    print( 'the shape of active features: ' ,enc.active_features_.shape )\n    \n    print( 'predicting' )\n    Z = clf.predict(df.loc[miss, base])\n    \n    numunperdicted = Z[:,0].sum()\n    if numunperdicted / nummiss *100 < threshold :\n        print( 'writing result to df' )    \n        df.loc[ miss, target ]  = np.dot( Z , enc.active_features_ )\n        print( 'num of unperdictable data: ', numunperdicted )\n        return enc\n    else:\n        print( 'out of threshold: {}% > {}%'.format( numunperdicted / nummiss *100 , threshold ) )\n\n#function to deal with variables that are actually string/categories\ndef zoningcode2int( df, target ):\n    storenull = df[ target ].isnull()\n    enc = LabelEncoder( )\n    df[ target ] = df[ target ].astype( str )\n\n    print('fit and transform')\n    df[ target ]= enc.fit_transform( df[ target ].values )\n    print( 'num of categories: ', enc.classes_.shape  )\n    df.loc[ storenull, target ] = np.nan\n    print('recover the nan value')\n    return enc\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b65d099d-3fa4-4f54-a557-1239cab1de56","_uuid":"93a6b65d62cd5b734e39d668f942916d7fbe506e","trusted":false,"collapsed":true},"cell_type":"code","source":"#fill in features that depend on location  \nfillna_knn( df = train_df,\n                  base = [ 'latitude', 'longitude' ] ,\n                  target = 'buildingqualitytypeid', fraction = 0.15, n_neighbors = 1 )\n\n\nzoningcode2int( df = train_df,\n                            target = 'propertycountylandusecode' )\nfillna_knn( df = train_df,\n                  base = [ 'latitude', 'longitude' ] ,\n                  target = 'propertycountylandusecode', fraction = 0.15, n_neighbors = 1 )\n\nzoningcode2int( df = train_df,\n                            target = 'propertyzoningdesc' )\n\nfillna_knn( df = train_df,\n                  base = [ 'latitude', 'longitude' ] ,\n                  target = 'propertyzoningdesc', fraction = 0.15, n_neighbors = 1 )\n\n#regionidcity, regionidneighborhood & regionidzip - assume it is the same as the nereast property. \n#As mentioned above, this is ok if there's a property very nearby to the one with missing values (I leave it up to the reader to check if this is the case!)\nfillna_knn( df = train_df,\n                  base = [ 'latitude', 'longitude' ] ,\n                  target = 'regionidcity', fraction = 0.15, n_neighbors = 1 )\n\nfillna_knn( df = train_df,\n                  base = [ 'latitude', 'longitude' ] ,\n                  target = 'regionidneighborhood', fraction = 0.15, n_neighbors = 1 )\n\nfillna_knn( df = train_df,\n                  base = [ 'latitude', 'longitude' ] ,\n                  target = 'regionidzip', fraction = 0.15, n_neighbors = 1 )\n\n#unitcnt - the number of structures the unit is built into. Assume it is the same as the nearest properties. If the property with missing values is in a block of flats or in a terrace street then this is probably ok - but again I leave it up to the reader to check if this is the case!\nfillna_knn( df = train_df,\n                  base = [ 'latitude', 'longitude' ] ,\n                  target = 'unitcnt', fraction = 0.15, n_neighbors = 1 )\n\n#yearbuilt - assume it is the same as the nearest property. This assumes properties all near to each other were built around the same time\nfillna_knn( df = train_df,\n                  base = [ 'latitude', 'longitude' ] ,\n                  target = 'yearbuilt', fraction = 0.15, n_neighbors = 1 )\n\n#lot size square feet - not sure what to do about this one. Lets use nearest neighbours. Assume it has same lot size as property closest to it\nfillna_knn( df = train_df,\n                  base = [ 'latitude', 'longitude' ] ,\n                  target = 'lotsizesquarefeet', fraction = 0.15, n_neighbors = 1 )\n\nfillna_knn( df = train_df,\n                  base = [ 'latitude', 'longitude' ] ,\n                  target = 'numberofstories', fraction = 0.15, n_neighbors = 1 )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b12c003d-9494-43fe-b2e5-0bcaa465921c","_uuid":"3071bbb4799391687c31c7403305db8adae56762","trusted":false,"collapsed":true},"cell_type":"code","source":"#finishedfloor1squarefeet\nplt.figure(figsize=(12,12))\nsns.jointplot(x=train_df.finishedfloor1squarefeet.values, y=train_df.calculatedfinishedsquarefeet.values)\nplt.ylabel('calculatedfinishedsquarefeet', fontsize=12)\nplt.xlabel('finishedfloor1squarefeet', fontsize=12)\nplt.title(\"finishedfloor1squarefeet Vs calculatedfinishedsquarefeet\", fontsize=15)\nplt.show()\n\n#There are some properties where finishedfloor1squarefeet and calculatedfinishedsquarefeetare are both exactly the same - probably because its a studio flat of some sort so that the area on the first floor is equivalent to the total area, lets see how many there are\n#For now assume if the number of stories is 1 then the finishedfloor1squarefeet is the same as calculatedfinishedsquarefeet\ntrain_df.loc[(train_df['finishedfloor1squarefeet'].isnull()) & (train_df['numberofstories']==1),'finishedfloor1squarefeet'] = train_df.loc[(train_df['finishedfloor1squarefeet'].isnull()) & (train_df['numberofstories']==1),'calculatedfinishedsquarefeet']\n\n#I also discovered that there seems to be two properties that have finishedfloor1squarefeet greater than calculated finishedsquarefeet. Notice also that they have big logerrors aswell - my guess is that the Zillow House price model found it difficult to predict these points due to the fact that they probably had potentially 'incorrect' data input values?\n#Discussion point - should we be removing these points or leave them in as they are or 'fix' them? I think it really depends on whether the test data has similar points which may be wrong as we'll want to predict big log errors for these incorrect points aswell I guess...\n#For now just remove them.\nprint(train_df.loc[train_df['calculatedfinishedsquarefeet']<train_df['finishedfloor1squarefeet']])\ndroprows = train_df.loc[train_df['calculatedfinishedsquarefeet']<train_df['finishedfloor1squarefeet']].index\ntrain_df = train_df.drop(droprows)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"878d23cc-ef62-4b3b-b55d-140c8de50f14","_uuid":"1eb2fd730a9ba7100b324e6acd715cb41d10003b","trusted":false,"collapsed":true},"cell_type":"code","source":"print(train_df.isnull().sum())\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a4f267e9-f258-47fd-8b1e-cc461eca0003","_uuid":"fafe79adf5b4959cd79e9bed100978982ab9cde4","trusted":false,"collapsed":true},"cell_type":"code","source":"#taxvaluedollarcnt & landtaxvaluedollarcnt - set it equal to the tax amount (most correlated value). Single story property so assume they are all the same\ntrain_df.loc[train_df.taxvaluedollarcnt.isnull(),'taxvaluedollarcnt'] = train_df.loc[train_df.taxvaluedollarcnt.isnull(),'taxamount']\ntrain_df.loc[train_df.landtaxvaluedollarcnt.isnull(),'landtaxvaluedollarcnt'] = train_df.loc[train_df.landtaxvaluedollarcnt.isnull(),'taxamount']\n\n#structure tax value dollar - fill this in using its most correlated variable\nx =  train_df.corr()\nprint(x.structuretaxvaluedollarcnt.sort_values(ascending = False))\n\n#taxvaluedollarcnt is most correlated variable, let's see how they are related \nplt.figure(figsize=(12,12))\nsns.jointplot(x=train_df.structuretaxvaluedollarcnt.values, y=train_df.taxvaluedollarcnt.values)\nplt.ylabel('taxvaluedollarcnt', fontsize=12)\nplt.xlabel('structuretaxvaluedollarcnt', fontsize=12)\nplt.title(\"structuretaxvaluedollarcnt Vs taxvaluedollarcnt\", fontsize=15)\nplt.show()\n\n#Lets look at the distribution of taxvaluedollar cnt where structuretaxvaluedollarcnt is missing just to make sure we are predicting missing values in the body of the taxvaluedollarcnt distribution\nprint(train_df.loc[train_df['structuretaxvaluedollarcnt'].isnull(),'taxvaluedollarcnt'].describe())\nprint(train_df['taxvaluedollarcnt'].describe())\n\n#Slightly amend the k nearest neighbour function so it works on regression\ndef fillna_knn_reg( df, base, target, n_neighbors = 5 ):\n    cols = base + [target]\n    X_train = df[cols]\n    scaler = StandardScaler(with_mean=True, with_std=True).fit(X_train[base].values.reshape(-1, 1))\n    rescaledX = scaler.transform(X_train[base].values.reshape(-1, 1))\n\n    X_train = rescaledX[df[target].notnull()]\n    Y_train = df.loc[df[target].notnull(),target].values.reshape(-1, 1)\n\n    knn = KNeighborsRegressor(n_neighbors, n_jobs = -1)    \n    # fitting the model\n    knn.fit(X_train, Y_train)\n    # predict the response\n    X_test = rescaledX[df[target].isnull()]\n    pred = knn.predict(X_test)\n    df.loc[train_df[target].isnull(),target] = pred\n    return\n\n#fill in structuretaxvaluedollarcnt using taxvaluedollarcnt as per the above\nfillna_knn_reg(df = train_df, base = ['taxvaluedollarcnt'], target = 'structuretaxvaluedollarcnt')\n\n#Do the same thing for tax amount, as taxvaluedollarcnt is its most correlated variable\nfillna_knn_reg(df = train_df, base = ['taxvaluedollarcnt'], target = 'taxamount')\nprint(train_df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"40ce31a9-ff32-4b0d-b6c0-d784e2c32697","_uuid":"ee2d29de4fe82d5c0a997f8a25a520db2141cfb7","collapsed":true,"trusted":false},"cell_type":"code","source":"#fill in total square feet based on number of bedrooms (assumed to be proportional)\nfillna_knn_reg(df = train_df, base = ['bedroomcnt'], target = 'calculatedfinishedsquarefeet')\n#fill in unit count based on total square feet (assumed to be proprtional)\nfillna_knn_reg(df = train_df, base = ['calculatedfinishedsquarefeet'], target = 'unitcnt')\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a79d2da3-858c-445d-b9f0-8beecd5048d8","_uuid":"07e0d40e2d52ce9a4a50b35fd1541da3adaf33e9","collapsed":true,"trusted":false},"cell_type":"code","source":"train_df=train_df.drop(['numberofstories','finishedfloor1squarefeet'],axis=1)\ntrain_df['censustractandblock']=train_df['censustractandblock'].fillna(train_df['censustractandblock'].mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7f09c973-e8bf-45d4-b7c9-6100362b6479","_uuid":"a49ffb9633febc896fe4f80f692d79f5c9ce9bd9","trusted":false,"collapsed":true},"cell_type":"code","source":"print(train_df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"67c7b795-5bbb-45df-b6ef-1e1f2d5f6049","_uuid":"e601db64036714cc79d38865e0769fa4d6bbbae3","collapsed":true},"cell_type":"markdown","source":"impute missing float values;\ncorrelation analysis"},{"metadata":{"_cell_guid":"1fcb3450-e99b-426c-b661-e176fcf20ef0","_uuid":"e7565ae0386f805e34c45b14cd74cae4bfd97fcf","collapsed":true},"cell_type":"markdown","source":"#mean_values=train_df.mean(axis=0)\n#train_df_new=pd.DataFrame()\n#train_df_new=train_df[col for col in train_df.columns if train_df[col].dtype=='float64'].fillna(train_df[col].mean(axis=0),inplace=True)\n#train_df_new = train_df.groupby(train_df.columns, axis = 1).transform(lambda x: x.fillna(x.mean()))\n\nx_cols= [col for col in train_df.columns if col not in ['logerror'] if train_df[col].dtype=='float64']\n\nlabels=[]\nvalues=[]\nfor col in x_cols:\n    labels.append(col)\n    values.append(np.corrcoef(train_df[col].values,train_df.logerror.values)[0,1])\ncorr_df=pd.DataFrame({'col_labels':labels,'corr_values':values})\ncorr_df=corr_df.sort_values(by='corr_values')\n\nind=np.arange(len(labels))\nwidth=0.9\nfig,ax=plt.subplots(figsize=(12,20))\nrects=ax.barh(ind,np.array(corr_df.corr_values.values),color='y')\nax.set_yticks(ind)\nax.set_yticklabels(corr_df.col_labels.values,rotation='horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation coefficient of the variables\")\nplt.show()"},{"metadata":{"_cell_guid":"9e838efd-0384-43cd-a670-9f6a19c39706","_uuid":"b0b99ffe44dfded9c9e27b52b3fa0340bb27019f"},"cell_type":"markdown","source":"some columns only have one possible value, therefore no correlation"},{"metadata":{"_cell_guid":"9f9b0e3a-3337-4721-8a9d-e4028bc83a13","_uuid":"1613dad5465998b53c89c49d2f4299a24dabae01","collapsed":true},"cell_type":"markdown","source":"corr_zero_cols=['assessmentyear', 'storytypeid', 'pooltypeid2', 'pooltypeid7', 'pooltypeid10', 'poolcnt', 'decktypeid', 'buildingclasstypeid']\nfor col in corr_zero_cols:\n    print(col, len(train_df_new[col].unique()))"},{"metadata":{"_cell_guid":"d1bb4779-89fd-45ea-8331-a1e2e7ba66a3","_uuid":"0329fe6cd77ea2061a27db88e448a357fcf245d9"},"cell_type":"markdown","source":"**apply ExtraTreesRegressor to find feature importances**"},{"metadata":{"_cell_guid":"64ffa0fa-2242-426e-bc63-f90c9c05605b","_uuid":"c0d50ec44b43cd659001805355c785202b7df7fb","collapsed":true,"trusted":false},"cell_type":"code","source":"train_y=train_df['logerror'].values\ncat_cols=[\"hashottuborspa\", \"propertycountylandusecode\", \"propertyzoningdesc\", \"fireplaceflag\", \"taxdelinquencyflag\"]\ntrain_x=train_df_new.drop(['parcelid', 'logerror', 'transactiondate','airconditioningtypeid']+cat_cols,axis=1)\ntrain_x=train_x.groupby(train_x.columns, axis = 1).transform(lambda x: x.fillna(x.mean()))\nfeat_names=train_df.columns.values\n\nfrom sklearn import ensemble\nmodel=ensemble.ExtraTreesRegressor(n_estimators=25,max_depth=30,max_features=0.3,n_jobs=-1,random_state=0)\nmodel.fit(train_x,train_y)\n\n#plot variable importances\nimportances=model.feature_importances_\n#std=np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n#indices=np.argsort(importances)[::-1][:20]\nindices=range(len(model.feature_importances_))\nplt.figure(figsize=(12,12))\nplt.title(\"Feature importances\")\nplt.bar(indices,importances[indices],color='b')\nplt.xticks(indices,feat_names[indices],rotation='vertical')\nplt.xlim([-1,len(indices)])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"734178c8-b8c3-4ae3-b71b-dc9c0b0499da","_uuid":"db4217ca9ece71667d0a9e6928fca6e278f07fa0"},"cell_type":"markdown","source":"**apply RandomForestRegressor to find feature importances**"},{"metadata":{"_cell_guid":"c03f96c5-24e1-4b5f-a1a5-7ae5c8f51016","_uuid":"22a900aad1aa5a7432590ac567bb2be4c90db7a0","collapsed":true,"trusted":false},"cell_type":"code","source":"parameters = {'n_estimators':[5,10,15],'n_jobs':[-1],'oob_score':[False]}  # this can be extended\nmodel = ensemble.RandomForestRegressor()\nfrom sklearn import model_selection\ngrid = model_selection.GridSearchCV(model,param_grid=parameters,scoring='neg_mean_absolute_error',cv=3)  \ngrid.fit(train_x,train_y)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1065c353-a7a5-4ff9-852e-1028c5f7abab","_uuid":"f360e8a3b3f6c5322456469995ffa7dddd4a1579","collapsed":true,"trusted":false},"cell_type":"code","source":"cv_results = pd.DataFrame(grid.cv_results_)\nprint(cv_results[[\"param_n_estimators\",\"mean_test_score\",\"std_test_score\"]])\n\nfeat_imps = grid.best_estimator_.feature_importances_\nfi = pd.DataFrame.from_dict({'feat':train_x.columns,'imp':feat_imps})\nfi.set_index('feat',inplace=True,drop=True)\nfi = fi.sort_values('imp',ascending=False)\nfi.head(20).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"98a50513-38f0-40f9-9ac8-ee4a72b9e0ee","_uuid":"9d818082a520f510d01ccd6626566f99a1f7d420"},"cell_type":"markdown","source":"**use RandomForestRegressor to predict for the test set**"},{"metadata":{"_cell_guid":"e446b0bb-c86f-425e-ab76-49973ac3d445","_uuid":"a1622b58f52170d60b317861dc4850bfcea2fbb3","collapsed":true,"trusted":false},"cell_type":"code","source":"samp = pd.read_csv(r\"../input/sample_submission.csv\")  #The parcelid's for the testset\n#impute all numerical missing values in the properties dataframe\nprop_df_new = prop_df.groupby(prop_df.columns, axis = 1).transform(lambda x: x.fillna(x.mean()))\ntest = samp.loc[:,['ParcelId']].merge(prop_df_new,how='left',left_on='ParcelId',right_on='parcelid')\ntest_x = test.drop(['ParcelId','parcelid']+cat_cols,axis=1,inplace=False)\n#,'airconditioningtypeid','architecturalstyletypeid','assessmentyear','basementsqft','bathroomcnt','bedroomcnt','buildingclasstypeid'\ntest_x=test_x.groupby(test_x.columns, axis = 1).transform(lambda x: x.fillna(x.mean()))\n\ntest_y = grid.predict(test_x)\ntest_y = pd.DataFrame(test_y)\ntest_y[1] = test_y[0]\ntest_y[2] = test_y[0]\ntest_y[3] = test_y[0]\ntest_y[4] = test_y[0]\ntest_y[5] = test_y[0]  #For simplicity make identical predictions for all months\ntest_y.columns = [\"201610\",\"201611\",\"201612\",\"201710\",\"201711\",\"201712\"]\nsubmission = test_y.copy()\nsubmission[\"parcelid\"] = samp[\"ParcelId\"].copy()\ncols = [\"parcelid\",\"201610\",\"201611\",\"201612\",\"201710\",\"201711\",\"201712\"]\nsubmission = submission[cols]\nfilename = \"Prediction_\" + str(submission.columns[0]) + re.sub(\"[^0-9]\", \"\",str(datetime.datetime.now())) + '.csv'\nprint(filename)\nsubmission.to_csv(filename,index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"167d29d5-6f0c-406c-b3a6-82172ed73805","_uuid":"fb0d9b61ad524f0fa8a291ec66746606d1ccc51f","collapsed":true,"trusted":false},"cell_type":"code","source":"y=train_df.logerror\nx=train_df.drop(['parcelid','logerror','transactiondate',],axis=1)\nfrom sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.3,random_state=148)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3643335a-d3ea-41da-bde8-8e6b1f615a13","_uuid":"6acd4c801f4130013af7ac972a9814dd75783600","collapsed":true,"trusted":false},"cell_type":"code","source":"# Consider the following models\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import Lasso, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\n\ngb = XGBRegressor(n_jobs=1, random_state=148)\nls = Lasso(alpha=1e-6, normalize=True)\nel = ElasticNet(alpha=1e-6, normalize=True)\nrf = RandomForestRegressor(random_state=148)\n\nbase_learners = [\n    ('ls', ls), ('el', el), ('rf', rf), ('gb', gb)\n]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c3ed7e00-29c4-4cc9-80d3-7f5cfb3dea5e","_uuid":"ee3976f4c4263b51bd3e4b76e76038d8d62181b0","trusted":false,"collapsed":true},"cell_type":"code","source":"P = np.zeros((xtest.shape[0], len(base_learners)))\nP = pd.DataFrame(P, columns=[e for e, _ in base_learners])\n\nfrom sklearn.metrics import mean_absolute_error\n\nfor est_name, est in base_learners:\n    est.fit(xtrain, ytrain)\n    p = est.predict(xtest)\n    P.loc[:, est_name] = p\n    print(\"%3s : %.4f\" % (est_name, mean_absolute_error(ytest, p)))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"93437e63-604d-4a7e-8d83-93dac0d50b4f","_uuid":"96a3a963a44837c45d04264196a1f9f62e384bf4"},"cell_type":"markdown","source":"onehotencode categ variables!!!!!"},{"metadata":{"_cell_guid":"7a0647e2-4b27-40da-b755-1f5f3d7968e2","_uuid":"936591afed564bc33b6fabcee2afb8abf5f68232","trusted":false,"collapsed":true},"cell_type":"code","source":"xtrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"259d0003-ba73-4142-8cfe-3d6993d23070","_uuid":"43b2afce0f998f6ab52c22922dc410307582aeb9","trusted":false,"collapsed":true},"cell_type":"code","source":"train_df.loc[train_df['taxdelinquencyflag']=='None','taxdelinquencyflag']=0\ntrain_df.loc[train_df['taxdelinquencyflag']=='Y','taxdelinquencyflag']=1\ntrain_df.loc[train_df['hashottuborspa']=='None','hashottuborspa']=0\ntrain_df.loc[train_df['hashottuborspa']=='True','hashottuborspa']=1\ntrain_df.loc[train_df['fireplaceflag']=='No','fireplaceflag']=0\ntrain_df.loc[train_df['fireplaceflag']=='Yes','fireplaceflag']=1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"76d5cb5f-f134-48ef-8bcb-2e0e198179d6","_uuid":"a0a0db50c0fdc020fe955cce009e5708016a08dc","trusted":false,"collapsed":true},"cell_type":"code","source":"xtrain.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bc143d0b-6efd-48a6-8573-926e94c7396e","_uuid":"c3d36fdd7c9e20f9a813ede83e53f08eb3f81082","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}