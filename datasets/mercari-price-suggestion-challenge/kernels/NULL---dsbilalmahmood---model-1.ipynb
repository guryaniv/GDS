{"nbformat_minor": 1, "nbformat": 4, "cells": [{"cell_type": "code", "metadata": {"_cell_guid": "194e0cb9-9f2d-4c45-90ae-9dd83521af5e", "_uuid": "328691ddba1b47bbf34306fdb83c65d610f5f3d5"}, "outputs": [], "execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from sklearn.externals import joblib # load trained model\n", "import scipy\n", "from sklearn.feature_extraction.text import  TfidfVectorizer\n", "from sklearn.base import TransformerMixin, BaseEstimator\n", "from sklearn.preprocessing import OneHotEncoder\n", "from sklearn.preprocessing import LabelEncoder\n", "\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "metadata": {"_cell_guid": "d22ccd73-4cd4-486d-95fa-9baae5e954f2", "collapsed": true, "_uuid": "e55d759a3da6f259bd5feca51f43c7edcab414df"}, "outputs": [], "execution_count": null, "source": ["## Reading test data\n", "df_test = pd.read_csv(\"../input/mercari-price-suggestion-challenge/test.tsv\",sep = \"\\t\")\n", "\n", "## Dealing with missing values\n", "df_test = df_test.fillna('unavailable')\n"]}, {"cell_type": "code", "metadata": {"_cell_guid": "ce8d0ef7-9afd-49c7-85ea-ee7e8f8ca7cf", "collapsed": true, "_uuid": "7641f7470165014711d5c845e6ff91278140b402"}, "outputs": [], "execution_count": null, "source": ["class CustomVectorizer(BaseEstimator, TransformerMixin):\n", "    \"\"\" This is a custom transformer that joins text(product name + description) \n", "        with non text variables(product category, brand, condition & shipment)\n", "        and is used in pipeline to tune and make predictions.\n", "        \n", "        name + description ---> DTM \n", "        category_name --->  OneHotEncoding\n", "        brand name --->  OneHotEncoding\n", "        item_condition --> Number\n", "        shipping ---> Number\n", "       \n", "        \n", "    Parameters\n", "    ----------\n", "    min_df = look at sklearn's tfidf vectorizer for its meaning,\n", "    ngram_range = look at sklearn's tfidf vectorizer for its meaning\n", "    stop_words = list of english words that do not convey vital information\n", "    \n", "    \"\"\"\n", "    def __init__(self, min_df = 10, ngram_range = (1,1), stop_words = None):\n", "        ## Hyper parameters for the text part \n", "        self.min_df = min_df\n", "        self.ngram_range = ngram_range\n", "        self.stop_words = stop_words\n", "        \n", "        \n", "    def fit(self, df, y=None):\n", "        \"\"\"Fits separate transformers on text and categorical data.\n", "        Parameters\n", "        ----------\n", "        df : dataframe with text and non text variables\n", "        y : None\n", "            There is no need of a target in a transformer, yet the pipeline API\n", "            requires this parameter, thus it is there\n", "        Returns\n", "        -------\n", "        self : object\n", "            Returns self.\n", "        \"\"\"\n", "\n", "        ## Fitting Text\n", "        self.text_vect_  = TfidfVectorizer(stop_words = self.stop_words, \n", "                                          ngram_range = self.ngram_range,\n", "                                          min_df = self.min_df)\n", "        text = (df[\"name\"] + \" | \" + df[\"item_description\"]).values        \n", "        self.text_vect_.fit(text)\n", "        \n", "        ## Fitting Categories\n", "        self.label_cat_enc_  = LabelEncoder()\n", "        self.hot_cat_enc_  = OneHotEncoder()\n", "        categories = df[\"category_name\"].values\n", "        self.hot_cat_enc_.fit(self.label_cat_enc_.fit_transform(categories).reshape(-1, 1))\n", "        \n", "        self.cat_classes_dict = {i:0 for i in self.label_cat_enc_.classes_}\n", "        print(\"Number of categories {}\".format(len(self.cat_classes_dict)))\n", "        \n", "        ## Fitting Brand names\n", "        self.label_brand_enc_  = LabelEncoder()\n", "        self.hot_brand_enc_  = OneHotEncoder()\n", "        brands = df[\"brand_name\"].values\n", "        self.hot_brand_enc_.fit(self.label_brand_enc_.fit_transform(brands).reshape(-1, 1))\n", "        \n", "        self.brand_classes_dict = {i:0 for i in  self.label_brand_enc_.classes_}\n", "        print(\"Number of brands {}\".format(len(self.brand_classes_dict)))\n", "        \n", "        # Return the transformer\n", "        return self\n", "\n", "    def transform(self, df, y = None):\n", "        \"\"\" Using the fitted individual transformers, transform the data and \n", "        concatenate them into a special DTM\n", "        \n", "        Parameters\n", "        ----------\n", "        df : dataframe containing the required column names\n", "            The input samples.\n", "        Returns\n", "        -------\n", "        X_transformed : Custom Matrix with DTM + encoded non text data\n", "        \"\"\"\n", "        \n", "        ## Transforming text \n", "        text = (df[\"name\"] + \" | \" + df[\"item_description\"]).values         \n", "        text_dtm = self.text_vect_.transform(text)\n", "        \n", "        ## Transforming brands\n", "        \"\"\"\n", "        new_brands = df[\"brand_name\"].values\n", "        new_brands[np.isin(new_brands, self.label_brand_enc_.classes_, \n", "                           invert = True)] = \"unavailable\"\n", "        \"\"\"\n", "        new_brands = df[\"brand_name\"]\n", "        new_brands[~new_brands.isin(self.brand_classes_dict)] = \"unavailable\"\n", "        \n", "    \n", "        trans_brands = self.hot_brand_enc_.transform(self.label_brand_enc_.transform(new_brands).reshape(-1, 1))\n", "        \n", "        ## Transforming categories\n", "        \"\"\"\n", "        new_categories = df[\"category_name\"].values\n", "        new_categories[np.isin(new_categories, self.label_cat_enc_.classes_, \n", "                           invert = True)] = \"unavailable\"\n", "        \"\"\"\n", "        new_categories = df[\"category_name\"]\n", "        new_categories[~new_categories.isin(self.cat_classes_dict)] = \"unavailable\"\n", "        \n", "        \n", "        trans_categories = self.hot_cat_enc_.transform(self.label_cat_enc_.transform(new_categories).reshape(-1, 1))\n", "         \n", "        \n", "        ## Item Condition and Shipping\n", "        trans_item_condition = df[\"item_condition_id\"].values.reshape(-1, 1)\n", "        trans_shipping = df[\"shipping\"].values.reshape(-1, 1)\n", "        \n", "        \n", "        ## Sparse Vectors\n", "        sparse_trans_categories =  scipy.sparse.csr.csr_matrix(trans_categories)   \n", "        sparse_trans_brands =  scipy.sparse.csr.csr_matrix(trans_brands)   \n", "        sparse_trans_item_condition = scipy.sparse.csr.csr_matrix(trans_item_condition)\n", "        sparse_trans_shipping = scipy.sparse.csr.csr_matrix(trans_shipping)\n", "        \n", "        ## Stacked Sparse dataframe\n", "        return scipy.sparse.hstack([sparse_trans_categories, sparse_trans_brands, \n", "                                    sparse_trans_item_condition, sparse_trans_shipping, text_dtm])\n", "        \n", "       \n", "\n", "\n", "\n"]}, {"cell_type": "code", "metadata": {"_cell_guid": "221fc03c-9fc2-4075-9110-ddc729c05749", "_uuid": "d7e44ab497027ef6857ffe2a8b468978f9abca38"}, "outputs": [], "execution_count": null, "source": ["## Loading Model\n", "trans  = joblib.load('../input/mercari-model/trained_transformer.pkl') \n", "reg_model  = joblib.load('../input/mercari-model/NN_100_relu_linear_output.pkl') "]}, {"cell_type": "code", "metadata": {"_cell_guid": "a50898eb-849b-4b25-ab00-00e5dbc6fc34", "_uuid": "e6e5380509ad4b6369b25da31e67b9a5cc3ef5be"}, "outputs": [], "execution_count": null, "source": ["## Transforming the features\n", "X_test =  df_test[[\"category_name\",\"brand_name\",\"item_condition_id\",\"shipping\",\"name\",\"item_description\"]]\n", "X_test_vector = trans.transform(X_test)\n", "\n", "## Making predictions using NN\n", "y_pred = reg_model.predict(X_test_vector)\n", "\n", "## Predicted dataframe\n", "df_prediction = df_test[[\"test_id\"]]\n", "df_prediction[\"price\"] = y_pred \n", "\n"]}, {"cell_type": "code", "metadata": {"_cell_guid": "58122671-f49b-4130-8a55-488ff1e74a6c", "collapsed": true, "_uuid": "ab85aae879579b967ec7030f41456243bbd107b0"}, "outputs": [], "execution_count": null, "source": ["## Saving the predictions\n", "df_prediction.to_csv(\"sample_submission.csv\",\n", "                     index = False)\n"]}, {"cell_type": "code", "metadata": {"_cell_guid": "dd7a9a4a-e5f2-45f3-a618-65a8ce06fa07", "collapsed": true, "_uuid": "e638a59ed7b1dda1a2b2dd7a4373851b8320e843"}, "outputs": [], "execution_count": null, "source": []}], "metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3", "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}}