{"cells":[{"metadata":{"_uuid":"d4dd1e2a939fe1480ba91a042ab34cb38c9049f8"},"cell_type":"markdown","source":"In this notebook, I made a simple lightgbm code. \nThis code takes **less than 15min** to finish all process. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pyarrow.parquet as pq\nimport random\nrandom.seed(1)\n\nimport os\nimport sys\nimport gc\nprint(os.listdir(\"../input\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\nimport lightgbm as lgb\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%%time\n# 1min in Kernel\nmeta_train = pd.read_csv('../input/metadata_train.csv')\nsubset_train = pq.read_pandas('../input/train.parquet', columns=[str(i) for i in range(8712)]).to_pandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04562222e8b9227b73a81578d09dace4a6657af6"},"cell_type":"code","source":"%%time\n# 20s in Kernel\ntrain_length = 8712 #max 8712\npositive_length = len(meta_train[meta_train['target']==1])\ntrain_df = pd.DataFrame()\nrow_index = 0\nfor i in range(train_length):\n    # downsampling\n    if meta_train.loc[i,'target'] == 1 or random.random() < positive_length / train_length:\n        subset_train_row = subset_train[str(i)]\n        train_df.loc[row_index, 'signal_min'] = subset_train_row.min()\n        train_df.loc[row_index, 'signal_max'] = subset_train_row.max()\n        train_df.loc[row_index, 'signal_mean'] = subset_train_row.mean()\n        # *** Add your feature here ***\n        train_df.loc[row_index, 'signal_id'] = i\n        row_index += 1\nprint(\"positive length: \" + str(positive_length))\n# positive length 525\nprint(\"train length: \" + str(len(train_df)))\n# train length 1038  example\n# This will be about 1050","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b35f06a6ec040b62388b0e2795edf214c81964a1"},"cell_type":"code","source":"train_df = pd.merge(train_df, meta_train, on='signal_id')\ntrain_df.to_csv(\"train.csv\", index=False)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5b73d89159a46f327011b163bed121a38a2d546"},"cell_type":"code","source":"# From https://www.kaggle.com/delayedkarma/lightgbm-cv-matthews-correlation-coeff\n# Thank you!!\n# If you have preprocessed data, input here and delete process method.\n# x_train = pd.read_csv('../input/***/train.csv')\nx_train = train_df\ntarget = x_train['target']\ninput_target = x_train['target']\nx_train.drop('target', axis=1, inplace=True)\nx_train.drop('signal_id', axis=1, inplace=True)\nfeatures = x_train.columns\nparam = {'num_leaves': 80,\n         'min_data_in_leaf': 60, \n         'objective':'binary',\n         'max_depth': -1,\n         'learning_rate': 0.1,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.8,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.8 ,\n         \"bagging_seed\": 11,\n         \"metric\": 'auc',\n         \"lambda_l1\": 0.1,\n         \"random_state\": 133,\n         \"verbosity\": -1}\nmax_iter=5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"064dfe1805f86331125cdb406c9ea4886723f1b1"},"cell_type":"code","source":"folds = KFold(n_splits=5, shuffle=True, random_state=15)\noof = np.zeros(len(x_train))\nfeature_importance_df = pd.DataFrame()\nscore = [0 for _ in range(folds.n_splits)]\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train.values, target.values)):\n    print(\"Fold No.{}\".format(fold_+1))\n    trn_data = lgb.Dataset(x_train.iloc[trn_idx][features],\n                           label=target.iloc[trn_idx])\n    val_data = lgb.Dataset(x_train.iloc[val_idx][features],\n                           label=target.iloc[val_idx])\n    num_round = 10000\n    clf = lgb.train(param,\n                    trn_data,\n                    num_round,\n                    valid_sets = [trn_data, val_data],\n                    verbose_eval=100,\n                    early_stopping_rounds = 100)\n    \n    oof[val_idx] = clf.predict(x_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    score[fold_] = metrics.roc_auc_score(target.iloc[val_idx], oof[val_idx])\n    if fold_ == max_iter - 1: break\nif (folds.n_splits == max_iter):\n    print(\"CV score: {:<8.5f}\".format(metrics.roc_auc_score(target, oof)))\nelse:\n     print(\"CV score: {:<8.5f}\".format(sum(score) / max_iter))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5033f0af87be235f27c05633752eb3a3bd41ed36"},"cell_type":"code","source":"cols = (feature_importance_df[[\"feature\", \"importance\"]]\n        .groupby(\"feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:1000].index)\nbest_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n\nplt.figure(figsize=(10,10))\nsns.barplot(x=\"importance\",\n            y=\"feature\",\n            data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6250ea1ed50f3908434404b7636012847bc724b8"},"cell_type":"markdown","source":"Check your CV carefully because\n> You may submit a maximum of 2 entries per day."},{"metadata":{"trusted":true,"_uuid":"650b5d071bad7ee976080954f3e95295a7285fd1"},"cell_type":"code","source":" gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97ab65cb3e6c27059a6f88ce137ed0ac77ef7226"},"cell_type":"code","source":"%%time\n# 25ms in Kernel\nmeta_test = pd.read_csv('../input/metadata_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc4c75449c1d2bddcfab7d0e9037949ab3f05004","_kg_hide-output":false},"cell_type":"code","source":"%%time\n# About 10min in Kernel\ntest_df = pd.DataFrame()\nrow_index = 0\nfor i in range(10):\n    subset_test = pq.read_pandas('../input/test.parquet', columns=[str(i*2000 + j + 8712) for j in range(2000)]).to_pandas()\n    for j in range(2000):\n        subset_test_row = subset_test[str(i*2000 + j + 8712)]\n        test_df.loc[row_index, 'signal_min'] = subset_test_row.min()\n        test_df.loc[row_index, 'signal_max'] = subset_test_row.max()\n        test_df.loc[row_index, 'signal_mean'] = subset_test_row.mean()\n        # *** Add your feature here ***\n        test_df.loc[row_index, 'signal_id'] = i*2000 + j + 8712\n        row_index += 1\nsubset_test = pq.read_pandas('../input/test.parquet', columns=[str(i + 28712) for i in range(337)]).to_pandas()\nfor i in tqdm(range(337)):\n    subset_test_row = subset_test[str(i + 28712)]\n    test_df.loc[row_index, 'signal_min'] = subset_test_row.min()\n    test_df.loc[row_index, 'signal_max'] = subset_test_row.max()\n    test_df.loc[row_index, 'signal_mean'] = subset_test_row.mean()\n    # *** Add your feature here ***\n    test_df.loc[row_index, 'signal_id'] = i + 28712\n    row_index += 1\ntest_df = pd.merge(test_df, meta_test, on='signal_id')\ntest_df.to_csv(\"test.csv\", index=False)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"771482d457a74a093db5b4f9d6c6c207bc9cada6"},"cell_type":"code","source":"# If you have preprocessed data, input here and delete process method.\n# x_test = pd.read_csv('../input/***/test.csv')\nx_test = test_df\nx_filename = x_test['signal_id']\nx_test = x_test.drop('signal_id', axis=1)\n\npredictions = clf.predict(x_test, num_iteration=clf.best_iteration)\n\nsub_df = pd.DataFrame({\"signal_id\":x_filename.values})\nsub_df[\"target\"] = pd.Series(predictions).round()\nsub_df['signal_id'] = sub_df['signal_id'].astype(np.int64)\nsub_df['target'] = sub_df['target'].astype(np.int64)\nsub_df.to_csv(\"submission.csv\", index=False)\nsub_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df6087ae19a9c1edb9a5d80f8e01a301148509a7"},"cell_type":"code","source":"positive = len(sub_df[sub_df[\"target\"] == 1])\nprint(positive)\nprint(str(positive/len(sub_df)*100) + \"%\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c654dac14d4fa94f4984a846b8339116f45600d"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}