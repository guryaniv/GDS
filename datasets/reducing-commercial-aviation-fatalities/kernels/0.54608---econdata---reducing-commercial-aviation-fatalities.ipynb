{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))\n#del train,test\n#train=pd.read_csv(\"../input/train.csv\")\n#test=pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5d381e70cde421b381b2dbc574c8e2c0eb0fe1d"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n\n\ndef kodeer(dfdir):\n    \n    mtrain=pd.read_csv(dfdir).reset_index()\n    if 'experiment' in mtrain.columns:\n        print('train experiment /n',mtrain.groupby('experiment').count())\n    else:\n        print('event',mtrain.groupby('event').count())\n    \n                \n    features_n = [\"eeg_fp1\", \"eeg_f7\", \"eeg_f8\", \"eeg_t4\", \"eeg_t6\", \"eeg_t5\", \"eeg_t3\", \"eeg_fp2\", \"eeg_o1\", \"eeg_p3\", \"eeg_pz\", \"eeg_f3\", \"eeg_fz\", \"eeg_f4\", \"eeg_c4\", \"eeg_p4\", \"eeg_poz\", \"eeg_c3\", \"eeg_cz\", \"eeg_o2\", \"ecg\", \"r\", \"gsr\"]\n\n    mtrain['pilot'] = 100 * mtrain['seat'] + mtrain['crew']\n    print(\"Number of pilots : \", len(mtrain['pilot'].unique()))\n    \n    pilots=mtrain['pilot'].unique()\n    for pilot in pilots:\n        ids = mtrain[mtrain[\"pilot\"] == pilot].index\n        scaler = MinMaxScaler()\n        mtrain.loc[ids, features_n] = scaler.fit_transform(mtrain.loc[ids, features_n])    \n    \n    mtrain=mtrain.drop('experiment',axis=1)\n    \n    if 'event' in mtrain.columns:\n        lbl = LabelEncoder()\n        mtrain['event']=lbl.fit_transform(list(mtrain['event'].values))\n        lblevent=lbl\n        print( list(lblevent.classes_) )\n    else:\n        lblevent=[]\n\n    mtrain['groep']=np.round( mtrain.index.values/256,0 )  # 256 measurements per second = grouping per second !\n    trainSD=mtrain.groupby(['groep','crew']).std()  #,'seat'\n    trainMA=mtrain.groupby(['groep','crew']).mean() #,'seat'\n    trainSD=trainSD.reset_index().sort_values(['crew','index']) #,'seat'\n    trainMA=trainMA.reset_index().sort_values(['crew','index']) #,'seat'\n\n    return trainSD,trainMA,lblevent,mtrain[['groep','crew']] #,'seat'\n\ntestsd,testma,lbl_event,test=kodeer(\"../input/test.csv\")\ntrainsd,trainma,lbl_event,train=kodeer(\"../input/train.csv\")\n\n\nprint(trainsd.shape,testsd.shape,test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82b884949c387eded0284fed20191368e4b9726e"},"cell_type":"code","source":"def SVD_tree_predict(e_,mtrain,mtest,veld,idvld):\n    velden=[v for v in e_.columns if v not in [veld,idvld]]\n    label = mtrain[veld].astype('int')\n    mtrain[veld]=label\n    print(e_.shape,velden)\n    e_=e_.loc[:,velden]\n\n    print(e_.shape)\n    ncomp=e_.shape[1]-3\n    # SVD\n    from sklearn.decomposition import TruncatedSVD\n    svd = TruncatedSVD(n_components=ncomp, n_iter=7, random_state=42)\n    e_=svd.fit_transform(e_.fillna(0))\n    print(e_[:len(mtrain)].shape,mtrain[veld].values.shape)\n    \n    xtrain=pd.DataFrame(e_[:len(mtrain)])\n    xtrain[veld]=label\n    xtest=pd.DataFrame(e_[len(mtrain):])\n    #New_features=e_[:len(mtrain)]\n    #Test_features=e_[len(mtrain):]\n    pd.DataFrame(e_[:len(mtrain)]).plot.scatter(x=0,y=1,c=label,colormap='winter')\n    from sklearn.ensemble import RandomForestClassifier, VotingClassifier,ExtraTreesClassifier,GradientBoostingRegressor, AdaBoostClassifier\n    from sklearn.multiclass import OneVsRestClassifier\n    clf=OneVsRestClassifier(ExtraTreesClassifier(n_estimators=10))\n    \n    fit=clf.fit(e_[:len(mtrain)],label)\n    pred=fit.predict(e_[:len(mtrain)])\n    from sklearn.metrics import accuracy_score\n    print('accuracy',accuracy_score(mtrain[veld].astype('int'),pred)*100)\n    #predict\n    sub = pd.DataFrame(fit.predict_proba(e_[len(mtrain):]))\n    for ci in mtest.columns:\n        sub[ci]=mtest[ci]\n    \n    sub.to_csv('submission.csv', index=False)\n    # prepare second method\n    import lightgbm as lgb\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import confusion_matrix, log_loss\n\n    train_df, val_df = train_test_split(mtrain, test_size=0.2, random_state=420)\n    print(f\"Training on {train_df.shape[0]} samples.\")    \n    features_n = [\"eeg_fp1\", \"eeg_f7\", \"eeg_f8\", \"eeg_t4\", \"eeg_t6\", \"eeg_t5\", \"eeg_t3\", \"eeg_fp2\", \"eeg_o1\", \"eeg_p3\", \"eeg_pz\", \"eeg_f3\", \"eeg_fz\", \"eeg_f4\", \"eeg_c4\", \"eeg_p4\", \"eeg_poz\", \"eeg_c3\", \"eeg_cz\", \"eeg_o2\", \"ecg\", \"r\", \"gsr\"]\n    features = [\"crew\", \"seat\"] + features_n\n    features =[x for x in mtrain.columns if x !=veld]  \n    def run_lgb(df_train, df_test):\n    \n        params = {\"objective\" : \"multiclass\",\n                  \"num_class\": 4,\n                  \"metric\" : \"multi_error\",\n                  \"num_leaves\" : 30,\n                  \"min_child_weight\" : 50,\n                  \"learning_rate\" : 0.1,\n                  \"bagging_fraction\" : 0.7,\n                  \"feature_fraction\" : 0.7,\n                  \"bagging_seed\" : 420,\n                  \"verbosity\" : -1\n                 }\n    \n        lg_train = lgb.Dataset(df_train[features], label=(df_train[veld]))\n        lg_test = lgb.Dataset(df_test[features], label=(df_test[veld]))\n        model = lgb.train(params, lg_train, 1000, valid_sets=[lg_test], early_stopping_rounds=50, verbose_eval=100)\n    \n        return model\n    \n    model = run_lgb(train_df, val_df)\n    pred_val = model.predict(val_df[features], num_iteration=model.best_iteration)\n    print( confusion_matrix(np.argmax(pred_val, axis=1), val_df[veld].values) )\n    pred_test = model.predict(mtest[features], num_iteration=model.best_iteration) #mtest[features]\n    submission = pd.DataFrame(np.concatenate((np.arange(len(mtest))[:, np.newaxis], pred_test), axis=1), columns=['id', 'A', 'B', 'C', 'D'])\n    submission['id'] = submission['id'].astype(int)\n    \n    return sub,submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66b985a6d18a12d49f3b647e6c21dfd4d61d207f"},"cell_type":"code","source":"trainMS=trainma.merge(trainsd,left_index=True,right_index=True)\ntestMS=testma.merge(testsd,left_index=True,right_index=True)\ntrainma['event']=trainma['event']+0.249 #*2\ntrainma['event']=trainma['event'].map(round)\n\ntrainma.groupby('event').count(),trainma.shape,testma.shape,trainMS.shape,testMS.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc0a7e9913172ecb364e44ec80590c39e9687195"},"cell_type":"code","source":"trainMS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"314327cc6c235ede5e1bc9809febdf9b9f1c7102"},"cell_type":"code","source":"#subx=SVD_tree_predict(trainMS.append(testMS).drop(['index_x','index_y','id_x','id_y','pilot_x','pilot_y','time_x','time_y','event_y','groep_y','event_x','crew_x','crew_y','seat_x','seat_y'],axis=1), trainma,testma,'event','groep')\ndropveld=['index_x','index_y','id_x','id_y','pilot_x','pilot_y','time_x','time_y','event_y','groep_x','groep_y','event_x','crew_x','crew_y','seat_x','seat_y']\ndropveld1=['index_x','index_y','pilot_x','pilot_y','time_x','time_y','groep_x','groep_y','crew_x','crew_y','seat_x','seat_y','event_y']\n\ndropveld2=['index_x','index_y','pilot_x','pilot_y','time_x','time_y','groep_x','groep_y','crew_x','crew_y','seat_x','seat_y']\n\n#subx,subg=SVD_tree_predict(trainma.append(testma).drop(['index','id','pilot','time','groep','event','crew','seat'],axis=1), trainma,testma,'event','groep')\nsubx,subg=SVD_tree_predict(trainMS.append(testMS).drop(dropveld,axis=1), trainMS.drop(dropveld1,axis=1),testMS.drop(dropveld2,axis=1),'event_x','groep')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ec4dc990b2a7a8a023ce1710b66afe1eab142ce"},"cell_type":"code","source":"subx #[['groep','crew','seat']]\nsubg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"843b8fa831e368a4ce96badb0b621ea0247a0024"},"cell_type":"code","source":"sub2=subx.iloc[:,:7]\nsub2.columns=['A','B','C','D','groep','crew','seat']\nsub2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00f64612346cf8a297c7ac4cea0b7dcb383edfc9"},"cell_type":"code","source":"#sub2=subx.groupby('groep').median()\n#sub2=subx[:int(len(subx)/2)]\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36f386a1c7f5d478f31963f619d28802190ecd7e"},"cell_type":"code","source":"#testSD=testSD.merge(subx,left_on='groep',right_on='groep')\n#testSD['event']=lblevent.inverse_transform(testSD['event_x'])\n\n\n#test=pd.read_csv(\"../input/test.csv\")\n#test['groep']=np.round( test.index.values/200,0 )\n#test2=test.merge(sub2,how='left',left_on=['groep','crew'],right_on=['groep','crew']) #','seat'\ntest2=test.merge(subg,how='left',left_on=['groep'],right_on=['id']) #','seat'\n#test2.groupby('event_x').count()\n#test2=test2.drop(['groep','crew','seat'],axis=1)  #,'seat'\ntest2=test2.drop(['groep','id','crew'],axis=1)  #,'seat'\ntest2.index.names = ['id']\ntest2=test2.reset_index()\n\ntest2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92244c9fc5179b834746573fc65343c618c1b791"},"cell_type":"code","source":"test2.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ca2b9b8861e1f9442160c9cec6d78dd1fea0726"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}