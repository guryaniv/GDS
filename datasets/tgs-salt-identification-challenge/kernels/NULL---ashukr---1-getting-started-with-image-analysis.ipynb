{"cells":[{"metadata":{"_uuid":"129b8c07548abc3cc7a166449f7d174e6880ecd4"},"cell_type":"markdown","source":"Author: ashukr\nDate: (6 September 2018)\n>Still working..in progress\n\n>[Reference notebook](https://www.kaggle.com/stkbailey/teaching-notebook-for-total-imaging-newbies)\n\n> suggestions to learn and improve always welcome"},{"metadata":{"_uuid":"af27abfbfd8f5e8816198d20e2e10ab07a38cd38","_cell_guid":"5917d988-a42f-4761-91f8-303595dd3c4d","_execution_state":"idle"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"ebce62cdc6497ceb8a6462307f5599bffce7cd4b","trusted":true,"_cell_guid":"00aa24f1-3983-42f2-834b-4a5a2dcc735a","_execution_state":"idle"},"cell_type":"code","source":"import pathlib\n# this module has class for file-system with semantics appropiate for different operating system\nimport imageio\n# this module provides an easy interface to read volumes of image data\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"863ebc5029e2abe645c212f3e36b588882b370fc"},"cell_type":"code","source":"train_path = pathlib.Path('../input/train/images').glob('*.png')\n# train_path is a generator which can be iterated only once, the result will \n# be empty if we wish to iterate twice over the generator train_path\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e1a5cdafcbe8f54967d0d75e8acf9cfc5c3eca2"},"cell_type":"code","source":"# for x in train_path:\n#     print(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b448ad26cf2ef89312a6db5dd51734749632a71d"},"cell_type":"code","source":"# for x in train_path:\n#     print(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"215edbcc72b654d5677fd961ebb6c7136d64a9eb"},"cell_type":"code","source":"train_path_sorted = sorted([x for x in train_path])\n# the piece of code sorts the concerned path of images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78476aca9c78a7db5ba8d8997a92972619348cf7"},"cell_type":"code","source":"im_path = train_path_sorted[41]\n# we access an image with the help of its index\n# we may get out of bound error if we iterate over the train_path second time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67fe8f667e7ddb0c5a30bf6fb80f568e56dfae84"},"cell_type":"code","source":"#print(im_path.parts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81ac1debc824aa683cb2a6c4cdd7f00a49f4249e"},"cell_type":"code","source":"#print(im_path.parts[-1][0:-4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77f550e48400ef41c52a80493f2db4def48d5c9a"},"cell_type":"code","source":"type(im_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4525659b1bc23a3a954c485ff4dee978a0e690d"},"cell_type":"code","source":"im = imageio.imread(str(im_path))\n# the im_path which is a posixPath is first converted to string and then the corresponding image is read","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62fb19eba8f9599607c97f50af9f04ae90cbeeb1"},"cell_type":"code","source":"im.shape\n# the presence of three dimensions suggests that the colour scale is RGB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9e65c7b84abc5df54ec027923fca7fdf313b4c4"},"cell_type":"code","source":"print(\"image original shape :{}\".format(im.shape))\n# helps to print the shape of the image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c736e1f5071c6d7ad8d3235c6e5c463b7093bfa"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5de87c07558c257154c7b25b784d46d63e73537"},"cell_type":"code","source":"from skimage.color import rgb2gray\n# the rgb2gray compute the illuminance of an RGB image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"806e0a49c4e3cdcc7034de4dd050a37dfd0ce4f9"},"cell_type":"code","source":"im_gray = rgb2gray(im)\n# calculating the illuminance apparantly gives us the gray scale of the image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c088f838c60010ad2184ca4409eef53c29383c8"},"cell_type":"code","source":"print(\"the shape of the image in the grayScale :{}\".format(im_gray.shape))\n# here we get two dimensional image matrix, significant for grayScale images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d09878efad416b3036df5e1b3f85ab7cb54e0f9"},"cell_type":"code","source":"#import matplotlib.pyplot as plt\n# plot a line, implicitly creating a subplot(111)\n#plt.plot([1,2,3])\n# now create a subplot which represents the top plot of a grid\n# with 2 rows and 1 column. Since this subplot will overlap the\n# first, the plot (and its axes) previously created, will be removed\n# plt.subplot(2,1,1)\n# plt.plot(range(12))\n# plt.subplot(212, facecolor='y') # creates 2nd subplot with yellow background","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfda06e979e007d314ac6915a4fce96041cc81ee"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n# the module to visualize the image\nplt.figure(figsize = (10,4))\n# we  decide the display size of the visualisation\nplt.subplot(1,2,1)\n# In the current figure, create and return an Axes, at position index of a (virtual) grid of nrows by ncols axes. Indexes go from 1 to nrows * ncols, incrementing in row-major order.\n# If nrows, ncols and index are all less than 10, they can also be given as a single, concatenated, three-digit number.\nplt.imshow(im)\n#displays the image on the axis\nplt.axis('off')\n#turns off the axis and the labels\nplt.title(\"the original image\")\n\nplt.subplot(122)\n#if the value of parameters in the arguements are less than 10 then they can be written in the sequence\nplt.imshow(im_gray,cmap = 'gray')\n#for gray scale image a corresponding parameter for Cmap is passed\nplt.axis('off')\nplt.title(\"grayScaleImage\")\n# the display of the grayScale image\nplt.tight_layout()\n# tight_layout automatically adjusts subplot params so that the subplot(s) fits in to the figure area.\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8ab61073c993c5b40698d600837ed3292230ddc"},"cell_type":"code","source":"# to remove the image and the background, there is method of seperation (i am not very sure if this approach of seperation will help in any way..\n# ..i am doing it cause the tutorial does it :-) ).\n\n# the eaisest way is to find the simple descriptive statistics like mean median and mode, the other approach is to \"otsu\" method, which finds the bimodal \n# distribution and finds the optimal seperation value\n\n\n#otsu method named after Noboyuki Otsu is a method in which the gray scale image are converted to binary image or clustering based image thresholding\n#to find the optimal seperation between the image and its background","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee141f5abd8ae81236ffc9d193a918f6385bc48f"},"cell_type":"code","source":"from skimage.filters import threshold_otsu\nthres_val = threshold_otsu(im_gray)\n# thres_val contains the threshold value for the separation of image and its background as per the otsu's algorithm\n# for that particular image\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7187ed7b2d70085c8a8aa8ddbc5e2b9a931a7ce"},"cell_type":"code","source":"mask = np.where(im_gray > thres_val,1,0)\n#the np.where(,[1,0]) returns the value 1 for true and the value 0 for false","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95cdd012f1d61ae38f348a49dba6ae247a21d9a8"},"cell_type":"code","source":"# we are considering the larger portion of he mask as the background\nif np.sum(mask==0) < np.sum(mask==1):\n    mask = np.where(mask,0,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"248752d3fc27bc84062fc05a1d523825c34b032f"},"cell_type":"code","source":"plt.figure(figsize=(10,4))\n\nplt.subplot(1,2,1)\nim_pixels = im_gray.flatten()\n#numpy flatten returns the array collapsed in one dimension\nplt.hist(im_pixels,bins=50)\nplt.vlines(thres_val, 0, 100000, linestyle='--')\n#the plt.vlines draws a vertical line at every X from y_min to y_max\nplt.ylim([0,50000])\nplt.title('Grayscale Histogram')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35bc52f0fa6cc61edc465d0c673612dd4d9155c5"},"cell_type":"code","source":"plt.subplot(1,2,2)\nmask_for_display = np.where(mask, mask, np.nan)\n# the np.nan substitutes the nan in place of all the zeros\nplt.imshow(im_gray, cmap='gray')\nplt.imshow(mask_for_display, cmap='rainbow', alpha=0.5)\nplt.axis('off')\nplt.title('Image w/ Mask')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"643e01b41d30a5d74c33824dc773ae5ba07eb9e4"},"cell_type":"code","source":"#we assign a label to each component in the mask and add each label to \n#an iterable such as list\n\nfrom scipy import ndimage\n#the package for multi dimensional image processing\nlabels, nlabels = ndimage.label(mask)\n#the ndimage label returns the number of features and every feature marked \n#with the labels \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f59cdfa16dfd13136b48c57ff2589aa533753cde"},"cell_type":"code","source":"label_arrays = []\nfor label_num in range(1, nlabels+1):\n    label_mask = np.where(labels == label_num, 1, 0)\n    label_arrays.append(label_mask)\nprint('There are {} seperate components/objects/features detected.'.format(nlabels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88d02cd29765a3e479d0240b5ea88234ea39f126"},"cell_type":"code","source":"#listedColourMap maps a color from a list of color, after creating an object of colourMap\nfrom matplotlib.colors import ListedColormap\nrand_cmap = ListedColormap(np.random.rand(256,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09074608da05ad77f10b430bbf72681d887e84ed"},"cell_type":"code","source":"type(rand_cmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac737b06e82cea7c236223e77ecc4db3303f624a"},"cell_type":"code","source":"labels_for_display = np.where(labels > 0, labels, np.nan)\nplt.imshow(im_gray, cmap='gray')\n#plt.imshow(labels_for_display, cmap=rand_cmap)\nplt.axis('off')\nplt.title('Labeled Objects ({} Objects)'.format(nlabels))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d2672ab976dba29a5881c324d9d7871f8321c9e"},"cell_type":"code","source":"labels_for_display = np.where(labels > 0, labels, np.nan)\nplt.imshow(im_gray, cmap='gray')\n#we have added the colourMap to visualize the different components\nplt.imshow(labels_for_display, cmap=rand_cmap)\nplt.axis('off')\nplt.title('Labeled Objects ({} Objects)'.format(nlabels))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc9f867e9c05db1ce01d5a5d870c4197e61085ad","scrolled":true},"cell_type":"code","source":"#now we can use the ndimage.find_objects to iterate over \n#the different objects in the image and process them individually\nfor label_ind, label_coords in enumerate(ndimage.find_objects(labels)):\n   # print(label_ind)\n    #print(label_coords)\n    cell = im_gray[label_coords]\n    \n    # Check if the label size is too small\n    #prefer np.prod over np.product as the later uses the former and may be depricated in future release\n    #np.prod multiplies the elements of an array, either all of them together or the multiplication along the specefied axis\n    if np.product(cell.shape) < 10: \n        print('Label {} is too small! Setting to 0.'.format(label_ind))\n        mask = np.where(labels==label_ind+1, 0, mask)\n\n# Regenerate the labels\nlabels, nlabels = ndimage.label(mask)\nprint('There are now {} separate components / objects detected.'.format(nlabels))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8487a238f080e14be02c341d07300a5aa1770586","trusted":true},"cell_type":"code","source":"ig, axes = plt.subplots(1,6, figsize=(10,6))\n#this block of code is getting out every component of the given image and is visualizing them \nfor ii, obj_indices in enumerate(ndimage.find_objects(labels)[0:6]):\n    cell = im_gray[obj_indices]\n    axes[ii].imshow(cell, cmap='gray')\n    axes[ii].axis('off')\n    axes[ii].set_title('Label #{}\\nSize: {}'.format(ii+1, cell.shape))\n\nplt.tight_layout()\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d43503f5a34698891d74eb025e127e22299d3be"},"cell_type":"code","source":"#shrinking the mask so as to get the components more confidently is called mask erosion\n#we can re-dilate the mask so as to retrieve the original components\n#now we get an image and perform the binary opening procedure\ntwo_cell_indices = ndimage.find_objects(labels)[1]\ncell_mask = mask[two_cell_indices]\ncell_mask_opened = ndimage.binary_opening(cell_mask, iterations=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d767eed57757197fee4e63cf3a7da0fab6bdac92"},"cell_type":"code","source":" dots = np.where(label_mask.T.flatten()==1)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae4e07c6ed3af8ebe92d0c8add42b1541c2920d1"},"cell_type":"code","source":"dots","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f8724b098903d5ac7b23fd22a042d824598dde4"},"cell_type":"code","source":"# run_lengths = []\n# prev = -2\n# for b in dots:\n#     print(b)\n#     if (b>prev+1): \n#         print(b)\n#         run_lengths.extend((b+1, 0))\n#         print(run_lengths)\n#     run_lengths[-1] += 1\n#     prev = b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7afaf78771a525da7ec71a133ff38806a2844c91"},"cell_type":"code","source":"def rle_encoding(x):\n    '''\n    x: numpy array of shape (height, width), 1 - mask, 0 - background\n    Returns run length as list\n    '''\n    dots = np.where(x.T.flatten()==1)[0] # .T sets Fortran order down-then-right\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b+1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return \" \".join([str(i) for i in run_lengths])\n\nprint('RLE Encoding for the current mask is: {}'.format(rle_encoding(label_mask)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09c6d1cdcdd94a20c4e16c054128dc6af124a6fa"},"cell_type":"code","source":"from skimage.color import rgb2gray\nim_gray = rgb2gray(im)\nthres_val = threshold_otsu(im_gray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3736ade998a993860aa33d66d646d923ae28acd0"},"cell_type":"code","source":"# now we combine together all of the function that we have created above and then process all of the images for a submission\nimport pandas as pd\ni=0\ndef analyze_image(im_path):\n    '''\n    Take an image_path (pathlib.Path object), preprocess and label it, extract the RLE strings \n    and dump it into a Pandas DataFrame.\n    '''\n    print()\n    # Read in data and convert to grayscale\n    im_id = im_path.parts[-1][0:-4]\n    im = imageio.imread(str(im_path))\n    im_gray = rgb2gray(im)\n    \n    # Mask out background and extract connected objects\n    thresh_val = threshold_otsu(im_gray)\n    mask = np.where(im_gray > thresh_val, 1, 0)\n    if np.sum(mask==0) < np.sum(mask==1):\n        mask = np.where(mask, 0, 1)    \n        labels, nlabels = ndimage.label(mask)\n    labels, nlabels = ndimage.label(mask)\n    \n    # Loop through labels and add each to a DataFrame\n    im_df = pd.DataFrame()\n    for label_num in range(1, nlabels+1):\n        label_mask = np.where(labels == label_num, 1, 0)\n        if label_mask.flatten().sum() > 10:\n            rle = rle_encoding(label_mask)\n            s = pd.Series({'id': im_id, 'rle_mask': rle})\n            im_df = im_df.append(s, ignore_index=True)\n    \n    return im_df\n\n\ndef analyze_list_of_images(im_path_list):\n    '''\n    Takes a list of image paths (pathlib.Path objects), analyzes each,\n    and returns a submission-ready DataFrame.'''\n    all_df = pd.DataFrame()\n    \n    for im_path in im_path_list:\n        im_df = analyze_image(im_path)\n        all_df = all_df.append(im_df, ignore_index=True)\n    \n    return all_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50eaae31a72d9fcb98e581ffc9963a6ba18239cd"},"cell_type":"code","source":"testing = pathlib.Path('../input/train/images').glob('*.png')\ndf = analyze_list_of_images(list(testing))\ndf.to_csv('submission.csv', index=None)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4bd2aedf8a7ccd9108cfed04bd8cc4cd74ce7f38"},"cell_type":"markdown","source":"## the method of separating the background image with the rel image components and then extracting their encodings did not work for this task, as there are some images which have only one colour, and for suc images the otsu_separation do not work."},{"metadata":{"trusted":true,"_uuid":"278d8c3fa2f522a1972d8725df794365f5defd37"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}