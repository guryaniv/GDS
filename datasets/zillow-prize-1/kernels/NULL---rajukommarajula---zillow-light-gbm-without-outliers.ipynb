{"metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"pygments_lexer": "ipython3", "mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.6.1", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "name": "python"}}, "cells": [{"metadata": {"_uuid": "292a5acbaae2317b091771c2cca106821a328fb4", "_cell_guid": "717d4d47-a82d-474b-bcc1-4011aa264d69", "collapsed": true}, "cell_type": "code", "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "import os\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "color = sns.color_palette()\n", "%matplotlib inline\n", "\n", "pd.options.mode.chained_assignment = None\n", "pd.options.display.max_columns = 999\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "#------------------------------------------------------------------------------\n", "\n", "\n", "train = pd.read_csv('../input/train_2016_v2.csv', parse_dates=[\"transactiondate\"])\n", "prop = pd.read_csv('../input/properties_2016.csv')\n", "sample = pd.read_csv('../input/sample_submission.csv')\n", "\n", "##### PROCESS DATA FOR REGRESSION\n", "\n", "print( \"\\nProcessing data for REGRESSION ...\" )\n", "for c, dtype in zip(prop.columns, prop.dtypes):\t\n", "    if dtype == np.float64:\t\t\n", "        prop[c] = prop[c].astype(np.float32)\n", "\n", "df_train = train.merge(prop, how='left', on='parcelid')\n", "\n", "\n", "# drop out ouliers\n", "ax = sns.boxplot(y=df_train[\"logerror\"])\n", "\n", "\n", "def IQR(x):\n", "    return np.percentile(x, 75) - np.percentile(x, 25)\n", "\n", "upper = np.percentile(df_train.logerror.values, 75)+1.5*IQR(df_train.logerror)\n", "lower = np.percentile(df_train.logerror.values, 25)-1.5*IQR(df_train.logerror)\n", "\n", "print (\"upper,lower\" ,upper, lower)\n", "\n", "\n", "#Subset the data after removing the outliers\n", "df_train=df_train[(df_train['logerror'] < upper) & (df_train['logerror'] > lower)]\n", "df_train.shape\n", "\n", "#------------------------------------------------------------------------------\n", "#Feature Engineering\n", "#------------------------------------------------------------------------------\n", "###Property age in years\n", "df_train['D_Prop_Age'] = 2018 - df_train['yearbuilt']   \n", "\n", "\n", "#Total number of rooms\n", "df_train['D_TotalRooms'] = df_train['bathroomcnt']*df_train['bedroomcnt']\n", "\n", "#Missing Count\n", "df_train['D_miss_count']=df_train.apply(lambda x: sum(x.isnull().values), axis = 1) # For rows\n", "#------------------------------------------------------------------------------\n", "\n", "\n", "count = 0\n", "for col in list(df_train):\n", "    if (len(df_train[col].unique())==1):\n", "        print(col)\n", "        count=count+1\n", "print(count)        \n", "\n", "\n", "\n", "df_train['assessmentyear'].value_counts()\n", "\n", "#Find out the missing values by columnwise\n", "df_train.apply(lambda x: sum(x.isnull().values), axis = 0) # For columns\n", "\n", "df_train['D_miss_count']=df_train.apply(lambda x: sum(x.isnull().values), axis = 1) # For rows\n", "\n", "df_train=df_train[df_train['D_miss_count']<30]\n", "df_train.shape\n", "\n", "\n", "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode','assessmentyear'], axis=1)\n", "\n", "y_train = df_train['logerror'].values\n", "print(x_train.shape, y_train.shape)\n", "\n", "x_train = x_train.apply(lambda x:x.fillna(x.value_counts().index[0]))\n", "\n", "x_train.describe()\n", "#x_train=np.nan_to_num(x_train)\n", "#from sklearn.model_selection import train_test_split\n", "#X_train,X_valid,Y_train,Y_valid=train_test_split(x_train,y_train,test_size=0.2,random_state=42)\n", "\n", "\n", "\n", "from sklearn.preprocessing import LabelEncoder\n", "import lightgbm as lgb\n", "import gc\n", "from sklearn.linear_model import LinearRegression\n", "import random\n", "import datetime as dt\n", "\n", "\n", "#------------------------------------------------------------------------------\n", "train_columns = x_train.columns\n", "\n", "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n", "    x_train[c] = (x_train[c] == True)\n", "\n", "del df_train; gc.collect()\n", "\n", "split = 90000\n", "x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n", "x_train = x_train.values.astype(np.float32, copy=False)\n", "x_valid = x_valid.values.astype(np.float32, copy=False)\n", "\n", "d_train = lgb.Dataset(x_train, label=y_train)\n", "d_valid = lgb.Dataset(x_valid, label=y_valid)\n", "\n", "params = {}\n", "params['learning_rate'] = 0.002\n", "params['boosting_type'] = 'gbdt'\n", "params['objective'] = 'regression'\n", "params['metric'] = 'mae'\n", "params['sub_feature'] = 0.5\n", "params['num_leaves'] = 60\n", "params['min_data'] = 500\n", "params['min_hessian'] = 1\n", "\n", "watchlist = [d_valid]\n", "clf = lgb.train(params, d_train, 500, watchlist)\n", "\n", "del d_train, d_valid; gc.collect()\n", "del x_train, x_valid; gc.collect()\n", "\n", "print(\"Prepare for the prediction ...\")\n", "sample = pd.read_csv('../input/sample_submission.csv')\n", "sample['parcelid'] = sample['ParcelId']\n", "df_test = sample.merge(prop, on='parcelid', how='left')\n", "del sample, prop; gc.collect()\n", "\n", "#------------------------------------------------------------------------------\n", "###Property age in years\n", "df_test['D_Prop_Age'] = 2018 - df_test['yearbuilt']   \n", "\n", "\n", "#Total number of rooms\n", "df_test['D_TotalRooms'] = df_test['bathroomcnt']*df_test['bedroomcnt']\n", "\n", "#Missing Count\n", "df_test['D_miss_count']=df_test.apply(lambda x: sum(x.isnull().values), axis = 1) # For rows\n", "#------------------------------------------------------------------------------\n", "x_test = df_test[train_columns]\n", "del df_test; gc.collect()\n", "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n", "    x_test[c] = (x_test[c] == True)\n", "x_test = x_test.values.astype(np.float32, copy=False)\n", "\n", "print(\"Start prediction ...\")\n", "# num_threads > 1 will predict very slow in kernal\n", "clf.reset_parameter({\"num_threads\":1})\n", "p_test = clf.predict(x_test)\n", "\n", "del x_test; gc.collect()\n", "\n", "print(\"Start write result ...\")\n", "sub = pd.read_csv('sample_submission.csv')\n", "for c in sub.columns[sub.columns != 'ParcelId']:\n", "    sub[c] = p_test\n", "\n", "sub.to_csv('lgb_starter.csv', index=False, float_format='%.4f')\n", "\n", "\n", "# Any results you write to the current directory are saved as output.\n", "\n"], "execution_count": null}], "nbformat": 4, "nbformat_minor": 1}