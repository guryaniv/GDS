{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"# Playing with linear regression\nAs my first model I wanted to try a simple linear regression, just to see how that would fare. "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import scipy\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\n\nfrom sklearn.preprocessing import scale\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.decomposition import FastICA\nfrom sklearn.decomposition import PCA\nfrom sklearn.random_projection import GaussianRandomProjection\nfrom sklearn.random_projection import SparseRandomProjection\n\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import make_scorer\n\nfrom skopt import BayesSearchCV\n\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\n\nimport scikitplot as skplt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b0260454ea0076e57392ff5c55d403522660251"},"cell_type":"markdown","source":"# 1. Data Processing\n## 1.1. Loading data and Scaling\nI'll be log-transforming the features with outliers prior to mean-variance scaling them. Same procedure as I've used in [previous notebook](https://www.kaggle.com/nanomathias/distribution-of-test-vs-training-data) where I looked at differences between train and test dataset."},{"metadata":{"trusted":true,"_uuid":"54b8156ed9b55cbd05ede7b6de8d4f633e2142d9","collapsed":true},"cell_type":"code","source":"# Read train and test files\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\n\n# Get the combined data\ntotal_df = pd.concat([train_df.drop('target', axis=1), test_df], axis=0).drop('ID', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49d764c6cbfa306e03757713d3c36de7e8df505c"},"cell_type":"code","source":"# Columns to drop because there is no variation in training set\nzero_std_cols = train_df.drop(\"ID\", axis=1).columns[train_df.std() == 0]\ntotal_df.drop(zero_std_cols, axis=1, inplace=True)\nprint(f\">> Removed {len(zero_std_cols)} constant columns\")\n\n# Removing duplicates\n# Taken from: https://www.kaggle.com/scirpus/santander-poor-mans-tsne\ncolsToRemove = []\ncolsScaned = []\ndupList = {}\ncolumns = total_df.columns\nfor i in tqdm(range(len(columns)-1)):\n    v = train_df[columns[i]].values\n    dupCols = []\n    for j in range(i+1,len(columns)):\n        if np.array_equal(v, train_df[columns[j]].values):\n            colsToRemove.append(columns[j])\n            if columns[j] not in colsScaned:\n                dupCols.append(columns[j]) \n                colsScaned.append(columns[j])\n                dupList[columns[i]] = dupCols\ncolsToRemove = list(set(colsToRemove))\ntotal_df.drop(colsToRemove, axis=1, inplace=True)\nprint(f\">> Dropped {len(colsToRemove)} columns\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60c1e535d5953cb9c3f1318b80dee9b0b7338e16"},"cell_type":"code","source":"# Go through the columns one at a time (can't do it all at once for this dataset)\nfor col in tqdm(total_df.columns):\n    \n    # Detect outliers in this column\n    data = total_df[col].values\n    data_mean, data_std = np.mean(data), np.std(data)\n    cut_off = data_std * 3\n    lower, upper = data_mean - cut_off, data_mean + cut_off\n    outliers = [x for x in data if x < lower or x > upper]\n    \n    # If there are crazy high values, do a log-transform\n    if len(outliers) > 0:\n        non_zero_idx = data != 0\n        total_df.loc[non_zero_idx, col] = np.log(data[non_zero_idx])\n    \n    # Scale non-zero column values\n    nonzero_rows = total_df[col] != 0\n    total_df.loc[nonzero_rows, col] = scale(total_df.loc[nonzero_rows, col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"54d6283c131bc91b0700b113d41410e81d75971b"},"cell_type":"markdown","source":"## 1.2. Decomposition\nI'll try to sync these to the progress I'm making in [this notebook](https://www.kaggle.com/nanomathias/feature-engineering-benchmarks)"},{"metadata":{"trusted":true,"_uuid":"ac4d5dec32820a393c5e4b33d15fd7f0429616bd"},"cell_type":"code","source":"COMPONENTS = 10\n\n# List of decomposition methods to use\nmethods = [\n    TruncatedSVD(n_components=COMPONENTS),\n    PCA(n_components=COMPONENTS),\n    FastICA(n_components=COMPONENTS),\n    GaussianRandomProjection(n_components=COMPONENTS, eps=0.1),\n    SparseRandomProjection(n_components=COMPONENTS, dense_output=True)    \n]\n\n# Run all the methods\nembeddings = []\nfor method in methods:\n    name = method.__class__.__name__    \n    embeddings.append(\n        pd.DataFrame(method.fit_transform(total_df), columns=[f\"{name}_{i}\" for i in range(COMPONENTS)])\n    )\n    print(f\">> Ran {name}\")\n    \n# Put all components into one dataframe\ncomponents_df = pd.concat(embeddings, axis=1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1dd7cdd252ad5721aa821fcfd6d592a3f17ae62b"},"cell_type":"markdown","source":"## 1.3. Feature Engineering\nI'll try to sync these to the progress I'm making in [this notebook](https://www.kaggle.com/nanomathias/feature-engineering-benchmarks)"},{"metadata":{"trusted":true,"_uuid":"f22b158d8f230db660d250835b4fb4351c0fba0c"},"cell_type":"code","source":"aggregate_df = pd.DataFrame()\n\n# V1 Features\naggregate_df['mean'] = total_df.mean(axis=1)\naggregate_df['median'] = total_df.median(axis=1)\naggregate_df['std'] = total_df.std(axis=1)\naggregate_df['min'] = total_df.min(axis=1)\naggregate_df['max'] = total_df.max(axis=1)\naggregate_df['number_of_different'] = total_df.nunique(axis=1)\naggregate_df['non_zero_count'] = total_df.astype(bool).sum(axis=1) \naggregate_df['sum_zeros'] = (total_df == 0).astype(int).sum(axis=1)\naggregate_df['geometric_mean'] = total_df.apply(\n    lambda x: np.exp(np.log(x[x>0]).mean()), axis=1\n)\naggregate_df.reset_index(drop=True, inplace=True)\nprint(\">> Created features for; mean, median, std, min, max, number_of_different, non_zero_count, sum_zeros, geometric_mean\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b520802dac88cd33f641b2e47341e22eb3ba525"},"cell_type":"markdown","source":"## 1.4. Splitting data into train and test"},{"metadata":{"trusted":true,"_uuid":"81052a2c1ca3cb35bf7ff5572a47bf88fd736124","collapsed":true},"cell_type":"code","source":"# Concate and split dataset\nX = pd.concat([components_df, aggregate_df], axis=1).fillna(0)\nX_train = X.iloc[0:len(train_df)]\nX_test = X.iloc[len(train_df):]\ny = train_df['target']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f58d3c15b94daac9e1125c632c78eaa788a606fa"},"cell_type":"markdown","source":"## 1.5. Forward Feature Selection\nIt's unlikely that we'll want to fit a linear model with all the features in case, so to reduce the number of features I'll run a simple floating forward feature selection algorithm to pick out the ones that add the most towards the target. I use the [SequentialFeatureSelector](https://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/) from mlxtend, which has a nice implementation for this."},{"metadata":{"trusted":true,"_uuid":"1df2cc8b16e71c2a724b47cbf6c48266cbd50305"},"cell_type":"code","source":"# Create forward feature selector\nselector = SFS(\n    ElasticNet(alpha=1, l1_ratio=0.5),\n    k_features=(10,20),\n    forward=True,\n    floating=True,\n    scoring='neg_mean_squared_error',\n    cv=10,\n    n_jobs=-1, \n    verbose=1\n)\n\n# Fit model and get best features\nselector.fit(X_train.values, np.log1p(y))\n\n# Let the user know which features were selected and how many\nprint(f\">> Selected the following {len(selector.k_feature_idx_)} features: {X_train.columns[list(selector.k_feature_idx_)]}\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"413771e909fbfa6a80c7921dd5c1fcfee95b62ad"},"cell_type":"markdown","source":"# 2. Model Tuning\nFor tuning the model I'll use bayesian optimization, as detailed in [this notebook](https://www.kaggle.com/nanomathias/bayesian-optimization-of-xgboost-lb-0-9769) I posted in another competition. I've uncommented here the last line since I do not want to run it when submitting the notebook."},{"metadata":{"trusted":true,"_uuid":"519604adf86a900c15084d75035b57a6b2627deb","_kg_hide-output":true},"cell_type":"code","source":"# Classifier\nbayes_cv_tuner = BayesSearchCV(\n    estimator = ElasticNet(),\n    search_spaces = {\n        'alpha': (0.5, 500, 'log-uniform'),\n        'l1_ratio': (0.25, 0.75),\n        'fit_intercept': [True, False]\n    },    \n    scoring = 'neg_mean_squared_error',\n    cv = KFold(\n        n_splits=10,\n        shuffle=True,\n        random_state=42\n    ),\n    n_jobs = 1,\n    n_iter = 40,   \n    verbose = 0,\n    refit = True,\n    random_state = 42\n)\n\ndef status_print(optim_result):\n    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n    \n    # Get all the models tested so far in DataFrame format\n    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n    \n    # Get current parameters and the best parameters    \n    best_params = pd.Series(bayes_cv_tuner.best_params_)\n    print('Model #{}\\nBest mean_squared_error: {}\\nBest params: {}\\n'.format(\n        len(all_models),\n        np.round(bayes_cv_tuner.best_score_, 4),\n        bayes_cv_tuner.best_params_\n    ))\n    \n    # Save all model results\n    clf_name = bayes_cv_tuner.estimator.__class__.__name__\n    all_models.to_csv(clf_name+\"_cv_results.csv\")\n\n# Fit the model - uncomment to run\nresult = bayes_cv_tuner.fit(\n    X_train.values[:, selector.k_feature_idx_], \n    np.log1p(y), \n    callback=status_print\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f417e2ebe453224206d8f0d52dc6f7f9bcd3b85b"},"cell_type":"markdown","source":"We could let this run for a long time, although I'm not sure it'll make much sense for this very simple model.\n\n# Model Fitting & Submission"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a164e47caeca2ac9cbb3a88d8a21b45433f7b06a"},"cell_type":"code","source":"# Fit model on full training set\nprint(\">> Fitting with parameters: \", bayes_cv_tuner.best_params_)\nregr = ElasticNet(**bayes_cv_tuner.best_params_)\nregr.fit(X_train.values[:, selector.k_feature_idx_], np.log(y))\n\n# Get submission file\nsubmission_file = pd.read_csv('../input/sample_submission.csv')\nsubmission_file.target = np.exp(\n    regr.predict(X_test.values[:, selector.k_feature_idx_])\n)\n\nprint(\">> Saving submission file\")\nsubmission_file.to_csv('submission_baseline_elasticnet.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de0619d4922f992a98ccfb1b7e1ad60f98322990"},"cell_type":"markdown","source":"I got a 1.56 score, which I think overall is pretty good for this extremely simple model and only using 10 features"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}