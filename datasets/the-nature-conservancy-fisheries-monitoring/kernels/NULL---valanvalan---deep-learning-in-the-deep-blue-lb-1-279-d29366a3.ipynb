{"cells": [{"metadata": {"_uuid": "b75a179fa06838e3988542888410589dfbf170be", "_cell_guid": "17a737e2-ff67-6170-1229-bb95dbb2f65a"}, "outputs": [], "cell_type": "markdown", "execution_count": null, "source": "# Start-to-Finish Solution in Keras\n\nHere is my basic method for getting a LB submission churned out. No parameter tuning or data augmentation has been attempted, which should increase the score significantly. "}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "8c1bb2d7d0cdf1b47e051a8a5daa3756c1edbcb0", "trusted": false, "_cell_guid": "e6a4aad9-f09f-8f20-a9d0-159f5ef6c922"}, "source": "import os, cv2, random\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker\nimport seaborn as sns\n%matplotlib inline \n\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D, Dense, Activation\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import np_utils\nfrom keras import backend as K\n\nTRAIN_DIR = '../input/train/'\nTEST_DIR = '../input/test_stg1/'\nFISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\nROWS = 90  #720\nCOLS = 160 #1280\nCHANNELS = 3"}, {"metadata": {"_uuid": "b602cbe8f7d9c931871681a957d59d4948176a29", "_cell_guid": "dec4ed7b-f0b8-0c30-5431-3bd652c190da"}, "outputs": [], "cell_type": "markdown", "execution_count": null, "source": "# Loading and Preprocessing Data\n\nNot much processing, other than resizing to 90x160, but you will probably want to run larger images on a GPU for a higher score. I am also keeping track of the labels as I loop through each image folder.  "}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "a3996b525c9ff1308925f159ff59b8b5190a5a66", "trusted": false, "_cell_guid": "d8f4e77d-ce91-48f7-c04a-ba225f893f0c"}, "source": "def get_images(fish):\n    \"\"\"Load files from train folder\"\"\"\n    fish_dir = TRAIN_DIR+'{}'.format(fish)\n    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n    return images\n\ndef read_image(src):\n    \"\"\"Read and resize individual images\"\"\"\n    im = cv2.imread(src, cv2.IMREAD_COLOR)\n    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n    return im\n\n\nfiles = []\ny_all = []\n\nfor fish in FISH_CLASSES:\n    fish_files = get_images(fish)\n    files.extend(fish_files)\n    \n    y_fish = np.tile(fish, len(fish_files))\n    y_all.extend(y_fish)\n    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n    \ny_all = np.array(y_all)"}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "45c15aeffabdd43ae0b5ebec04f8ce9880e7d4d1", "trusted": false, "_cell_guid": "7547d288-1ca9-c45e-0efb-75ea832cb318"}, "source": "X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n\nfor i, im in enumerate(files): \n    X_all[i] = read_image(TRAIN_DIR+im)\n    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n\nprint(X_all.shape)"}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "02f4b277913cd7b35204ad509c33fe5dfcb6fbbb", "trusted": false, "_cell_guid": "18a6f374-8c0e-b332-3e46-46a732b96930"}, "source": "## Uncomment to check out a fish from each class\n#uniq = np.unique(y_all, return_index=True)\n# for f, i in zip(uniq[0], uniq[1]):\n    #plt.imshow(X_all[i])\n    #plt.title(f)\n    #plt.show()"}, {"metadata": {"_uuid": "9845d1bca2b6857ceaf063d6762d9414375245b2", "_cell_guid": "25a3b3b2-a00e-d618-9d2c-4dc18ad14744"}, "outputs": [], "cell_type": "markdown", "execution_count": null, "source": "# Splitting the Training Data\n\nOne-Hot-Encode the labels, then create a stratified train/validation split. "}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "1b9a10c80d19c11727945fffd408a3fbd5975b68", "trusted": false, "_cell_guid": "0537e039-ae27-ea4e-82a6-23603d9aa007"}, "source": "# One Hot Encoding Labels\ny_all = LabelEncoder().fit_transform(y_all)\ny_all = np_utils.to_categorical(y_all)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, \n                                                    test_size=0.2, random_state=23, \n                                                    stratify=y_all)"}, {"metadata": {"_uuid": "5ac06e6d1253778ecc85030ba91ff958ca7d131d", "_cell_guid": "e2256352-79ff-78eb-24d8-f1874d32cbf4"}, "outputs": [], "cell_type": "markdown", "execution_count": null, "source": "## The Model\n\nPretty typical CNN in Keras with a plenty of dropout regularization between the fully connected layers. Note: I set the epochs to 1 to avoid timing out - change it to around 20. "}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "dce72389d999f8ea16601602f72f3e9dbcf366d3", "trusted": false, "_cell_guid": "6e2396d3-d295-9616-d327-99cbe76b8851"}, "source": "optimizer = RMSprop(lr=1e-4)\nobjective = 'categorical_crossentropy'\n\ndef center_normalize(x):\n    return (x - K.mean(x)) / K.std(x)\n\nmodel = Sequential()\n\nmodel.add(Activation(activation=center_normalize, input_shape=(ROWS, COLS, CHANNELS)))\n\nmodel.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n\nmodel.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n\nmodel.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n\nmodel.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(len(FISH_CLASSES)))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss=objective, optimizer=optimizer)"}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "d75bd28c5b371697a36ccf66660e59e765bf3753", "trusted": false, "_cell_guid": "461ff410-5bca-f26d-5b4b-722fb2681e33"}, "source": "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')        \n        \nmodel.fit(X_train, y_train, batch_size=64, nb_epoch=1,\n              validation_split=0.2, verbose=1, shuffle=True, callbacks=[early_stopping])"}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "e7c9f5e491f0e692c096f752addfd88774098a1c", "trusted": false, "_cell_guid": "6c3c125c-e273-99a5-8360-8b717b9b9e58"}, "source": "preds = model.predict(X_valid, verbose=1)\nprint(\"Validation Log Loss: {}\".format(log_loss(y_valid, preds)))"}, {"metadata": {"_uuid": "48a1dae02db0a7c2f79286a4682dbb134cc5f83d", "_cell_guid": "6020ea37-c78f-a6f3-0877-2196833f8790"}, "outputs": [], "cell_type": "markdown", "execution_count": null, "source": "# Predicting the Test Set\n\nFinishing off with predictions on the test set. Scored LB 1.279 "}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "b1615ce770de655f82f08833934a59fd0ec4acec", "trusted": false, "_cell_guid": "c4769ce7-367c-5240-b615-714972d8e596"}, "source": "test_files = [im for im in os.listdir(TEST_DIR)]\ntest = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n\nfor i, im in enumerate(test_files): \n    test[i] = read_image(TEST_DIR+im)\n    \ntest_preds = model.predict(test, verbose=1)"}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "bbf279ea5b71e2199878b46192fd2023355113f8", "trusted": false, "_cell_guid": "dfe3630b-9944-e91e-102d-d26efdcaa90f"}, "source": "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\nsubmission.insert(0, 'image', test_files)\nsubmission.head()"}], "nbformat_minor": 0, "nbformat": 4, "metadata": {"_change_revision": 0, "_is_fork": false, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1", "name": "python", "file_extension": ".py", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}}}}