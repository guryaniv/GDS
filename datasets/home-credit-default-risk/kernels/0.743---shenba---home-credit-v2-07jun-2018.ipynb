{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Objective of the competition is to \"predict their clients' repayment abilities.\" There are quite a number of files provided. For this notebook, let's start with the main file and explore the variables in that\nSummary of this notebook:\n\n1. In the V1 file (EDA 23 May 2018), we had done a baseline model with only a few features\n2. In this notebook, we will bring in all features\n3. Build a model with all features - convert categorical to numeric, include all numeric\n4. do cross validation and get output as average of multiple models\n5, check if a feature is not useful - i.e., all input vals has same output val; we can remove them\n6. we will still use only one file for this notebook\n7. \n"},{"metadata":{"_uuid":"658f7bc3c693fcb43933e0e070be2b7b0ad87683"},"cell_type":"markdown","source":"# 1. Load the main data (train) file"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"056d41f967e6c921ca96f875ae82ec673665aa6b"},"cell_type":"code","source":"train_df = pd.read_csv('../input/application_train.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f65c2692d005f01f8c2767b795ecf15e0a47e40"},"cell_type":"code","source":"train_df.shape","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fbfaa83068b11eb2a9c61923bc437aebb4c8ff8e"},"cell_type":"code","source":"#there are 307K rows and 122 columns; the number of cols is very high","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"049afba770266f25ef2d9c601303e8dc4d3af7ec"},"cell_type":"code","source":"train_df.head()","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"968b64c5617b2cefc90e891b2cdc73847750f32e"},"cell_type":"code","source":"# we see that TARGET is the output variable and also that we have a number of demographic variables","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6d3319bd6fc091e3058b015c69028b1c431d2470"},"cell_type":"code","source":"#let's explore the output variable","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"bff14c0dc6795816249d02f16bc4859e3cd882e6"},"cell_type":"code","source":"train_df.TARGET.value_counts()","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4000a1a9f1688bae57f0274114c3ce53f7935347"},"cell_type":"code","source":"# low event rate (as we would expect)\nprint(\"event rate is : {} %\".format(round((train_df.TARGET.value_counts()[1]/train_df.shape[0]) * 100)))","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"03c87e93bd1d99ab7ac291fe608393f831b14376"},"cell_type":"code","source":"#the file homecredit_columns_description has details ","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9fc4d47cf9c82b3e2fd639635eb8655d1d84047d"},"cell_type":"code","source":"#load the test set","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"041bec5f590fa460753e27cf60fcd4fef89af66b"},"cell_type":"code","source":"test_df =  pd.read_csv('../input/application_test.csv')","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ed5b1d0d235342ed34e97451c32654cd2fef318d"},"cell_type":"code","source":"#create flag in train and test df to identify them\ntrain_df['is_train'] = 1\ntest_df['is_train'] = 0","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6e7dba66ecc8851056b27649847fc71b3928a73e"},"cell_type":"code","source":"#take the train output variable out from the train df so that we can merge train and test for processing\nY_train = train_df['TARGET']\ntrain_X = train_df.drop(['TARGET'], axis = 1)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ef1ec9c89da2c503edb9fa124caa82068eb6d449"},"cell_type":"code","source":"# test ID\ntest_id = test_df['SK_ID_CURR']\ntest_X = test_df\n\n# merge train and test datasets for preprocessing\ndata = pd.concat([train_X, test_X], axis=0)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"23e9d7af422b4a033a29e9ecabea563d071eac84"},"cell_type":"code","source":"#write functions to get the categorical features in the overall dataset","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2100e787eb3f0f06c555a35f881450d15080f46f"},"cell_type":"code","source":"# function to obtain Categorical Features\ndef get_categorical_features(df):\n    cat_feats = [col for col in list(df.columns) if df[col].dtype == 'object']\n    return cat_feats","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4ffdb0fe1ec91c4f8b10c5f845a7436864b46c53"},"cell_type":"code","source":"#function to encode categorical values; we use pd.get_dummies;\n#refer to https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-0-772; this nb has used both factorize and get dummies while I feel that just\n#get dummies should do","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1dc58fc0c6f150df362a1a9162f483687d95fda8"},"cell_type":"code","source":"def get_dummies(df, cat_feats):\n    for cat_col in cat_feats:\n        df = pd.concat([df, pd.get_dummies(df[cat_col], prefix=cat_col)], axis=1)\n    return df","execution_count":19,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c9588f666455d478ba02c6233591e865c8b8109b"},"cell_type":"code","source":"# get categorical features\ndata_cat_feats = get_categorical_features(data)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"66634525d0be056743b529a5891cf4a9d9cdaeb3"},"cell_type":"code","source":"# create additional dummy features - \ndata = get_dummies(data,data_cat_feats)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8aa3003e48f359202b45c3c89fa228ff9a3b43e6"},"cell_type":"code","source":"data.head()","execution_count":22,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"001956b587ba63d1d6b33ec18df7184029f3f907"},"cell_type":"code","source":"#get numeric cols\nnumeric_cols = [col_name for col_name in list(data.columns) if data[col_name].dtype != 'object']","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce84d8943420f8e68585384b7c1ba83bad5407d0"},"cell_type":"code","source":"len(numeric_cols)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9aa53de7aa31c3245352be4895a01ef813bd272"},"cell_type":"code","source":"'is_train' in numeric_cols","execution_count":29,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a46f05175bd741ccd3ebf923c2a0c9aef0857cf"},"cell_type":"code","source":"numeric_cols = [col for col in numeric_cols if col !='is_train']","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f6c25c5696cc4f3a7ba72d1b9adf34ba66b9a55"},"cell_type":"code","source":"len(numeric_cols)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8b75879bd1e4d7023deb43b11446bd98fa23c556"},"cell_type":"code","source":"# remove the ID from list\nnumeric_cols = [col for col in numeric_cols if col !='SK_ID_CURR']","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a4e67e56bcb4c27748322fe5c18e2786f2974de"},"cell_type":"code","source":"#split the data back in to train and test\ntrain_X = data[data['is_train'] == 1][numeric_cols]\ntest_X = data[data['is_train'] == 0][numeric_cols]","execution_count":36,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"215eb28eb70c437250a9f885fc08bbe6eb68c3ba"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split ","execution_count":37,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fded3b5e3a5942739a1a3d8164597d566ec0c14f"},"cell_type":"code","source":"random_seed = 144","execution_count":38,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49f99858cbb3920c269a77bf5f6b3eff6e3fbc79"},"cell_type":"code","source":"#create validation sets to be used while training the model\nX_train, X_val, y_train, y_val = train_test_split(train_X, Y_train, test_size=0.2, random_state=random_seed)","execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"99b9c4ff9522a077b0a46f0b80254f34d6128ab7"},"cell_type":"code","source":"#build a simple light gbm model","execution_count":41,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a04e0212953a4baf3a19715c98457f7e78873c90"},"cell_type":"code","source":"import lightgbm as lgb","execution_count":42,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"adad35279aaafbefeb7020a40e81ccc84f81ead3"},"cell_type":"code","source":"#prepare the train and eval data to fit to model\nlgb_train = lgb.Dataset(data=X_train, label=y_train)\nlgb_eval = lgb.Dataset(data=X_val, label=y_val)","execution_count":43,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ab33a4369f3035b08384863e1ae22468ec334388"},"cell_type":"code","source":"#define the params for the model\nparams = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', \n          'learning_rate': 0.01, 'num_leaves': 48, 'num_iteration': 5000, 'verbose': 0 ,\n          'colsample_bytree':.8, 'subsample':.9, 'max_depth':7, 'reg_alpha':.1, 'reg_lambda':.1, \n          'min_split_gain':.01, 'min_child_weight':1}\n#used same params as here: https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-0-772","execution_count":44,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd2036a2a7f728f29eb4d4987b182cee16086153"},"cell_type":"code","source":"model = lgb.train(params, lgb_train, valid_sets=lgb_eval, early_stopping_rounds=150, verbose_eval=200)","execution_count":45,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b07eb2c6a92599bb4c995a0629611944c1b8084c"},"cell_type":"code","source":"#preds\npreds = model.predict(test_X)\nsub_lgb = pd.DataFrame()\nsub_lgb['SK_ID_CURR'] = test_id\nsub_lgb['TARGET'] = preds\nsub_lgb.to_csv(\"lgb_baseline.csv\", index=False)\nsub_lgb.head()","execution_count":46,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"17a5082dc29e94cf8eaec173f66d7c178bc6d281"},"cell_type":"code","source":"#there are a number of numeric and categorical features; for the baseline model in this notebook, let's take only a few\n#also, for the categorical features, we will try to do mean encoding instead of the regular one hot encoding / label encoding","execution_count":37,"outputs":[]},{"metadata":{"_uuid":"15d09157746d5ccd74a75da22418d6cbc411e937"},"cell_type":"markdown","source":"#numeric features we are interested in:\nAMT_INCOME_TOTAL\nAMT_CREDIT\nAMT_ANNUITY\nAMT_GOODS_PRICE\nDAYS_EMPLOYED\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d15f03e28dd266cee7352b98de418f54ee6600ae"},"cell_type":"code","source":"num_features_list = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_EMPLOYED']","execution_count":38,"outputs":[]},{"metadata":{"_uuid":"80cd3726f958d46435de4df7808c409024b341e9"},"cell_type":"markdown","source":"# categorical features:\nNAME_CONTRACT_TYPE\nCODE_GENDER\nFLAG_OWN_CAR\nFLAG_OWN_REALTY\nNAME_INCOME_TYPE\nNAME_EDUCATION_TYPE\nNAME_FAMILY_STATUS\nOCCUPATION_TYPE\n\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"193ec1a294f908cdc7f3257c3f0f63f8d47be886"},"cell_type":"code","source":"cat_features_list = ['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', \n                     'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'OCCUPATION_TYPE']","execution_count":39,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"98c0b47a959bee82bb418e02b6eeeb49d90681cf"},"cell_type":"code","source":"#mean encoding for cat features","execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4d5a91c7a78e0ee4d9c8758d82d4e2f71945a9f6"},"cell_type":"code","source":"num_rows = train_df.shape[0] #get number of records in train\n\nfor cat_feature in cat_features_list: #iterate over all the cat features\n        encoder_series = train_df[cat_feature].value_counts() / num_rows #create a series that would have the mean for each value in the cat feature\n        train_df[cat_feature+'_mean_enc'] = train_df[cat_feature].map(encoder_series) #map that to the specific cat feature and create a new col","execution_count":41,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"96dbe550f77e828b2230aad883cf677f190f4115"},"cell_type":"code","source":"# we have created a set of cols that are mean encoded from categorical cols\n#lets move on to create a baseline model with the selected numeric features and the mean encoded cols","execution_count":43,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"485ce4f964eb4433a29ce91ad9f6b27ba7c27f04"},"cell_type":"code","source":"#create a list with numeric cols","execution_count":44,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44e7ba9c8fd3eb9fee9a5152f25441a3c9053b7e","collapsed":true},"cell_type":"code","source":"train_df.columns","execution_count":45,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44a99d8886f6fc5047a161abeab6a6ac755d9120","collapsed":true},"cell_type":"code","source":"features = num_features_list + ['NAME_CONTRACT_TYPE_mean_enc', 'CODE_GENDER_mean_enc', 'FLAG_OWN_CAR_mean_enc', 'FLAG_OWN_REALTY_mean_enc',\n                               'NAME_INCOME_TYPE_mean_enc', 'NAME_EDUCATION_TYPE_mean_enc',\n                               'NAME_FAMILY_STATUS_mean_enc', 'OCCUPATION_TYPE_mean_enc']","execution_count":47,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c4518d06f430e4c3510f3f902fe803818809a80e"},"cell_type":"code","source":"X_train = train_df[features]","execution_count":48,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6b1c0e31f5338ebfe5d71503d60461d8c6af9c09"},"cell_type":"code","source":"y_train = train_df.TARGET","execution_count":50,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0267ac487ba872321eddaca710d48ba93b90e959"},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":51,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bcc7c3e0e27e4f79b70d85f4301345f06be9b310"},"cell_type":"code","source":"seed = 111","execution_count":52,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ca33ea3a254e5e7a4453b780c2b58e9589ae4010"},"cell_type":"code","source":"#without scale pos weight, we had no 1 preds; with scale pos weight as 12, we had a 127K 1s with accuracy of 60%","execution_count":69,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"889c27560835bf9f5706c85064e6bab88e817097"},"cell_type":"code","source":"model_xgb = XGBClassifier(scale_pos_weight=6)","execution_count":70,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfed14b375ab2de72d37785cf46d90a63e856671","collapsed":true},"cell_type":"code","source":"model_xgb.fit(X=X_train, y=y_train)","execution_count":71,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b35ff60eb434528048f5b4bc5cd4fd329d31873","collapsed":true},"cell_type":"code","source":"np.sum(model_xgb.predict(X_train))","execution_count":72,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"31a1127ec482bea476141030f7a7224f4c2c962d"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":55,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aef4bcd462215e0f1719c74ba36193b6618eeabb","collapsed":true},"cell_type":"code","source":"accuracy_score(y_true=y_train, y_pred=model_xgb.predict(data=X_train))","execution_count":73,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8badf7a2d063a4001b7bf6fd2ed338ce463d3241"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","execution_count":74,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e85a59c95f9060349a8eac7d97485e0091c0c3fb","collapsed":true},"cell_type":"code","source":"confusion_matrix(y_true=y_train, y_pred=model_xgb.predict(data=X_train))","execution_count":75,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bc8c8ffe52bb48e2f0c06dbaceeca759b956137e"},"cell_type":"code","source":"#now to make predictions on the test set\n#first, we need to do the mean encoding for the test data as well","execution_count":57,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2767ae3dafb165a52663fb922278bc65e7ef9504"},"cell_type":"code","source":"test_df = pd.read_csv('../input/application_test.csv')","execution_count":58,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c0d23d005ba86510eb5e015b2c398ff56960ae8e"},"cell_type":"code","source":"for cat_feature in cat_features_list: #iterate over all the cat features\n        test_df[cat_feature+'_mean_enc'] = test_df[cat_feature].map(encoder_series) #map that to the specific cat feature and create a new col","execution_count":59,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fb13ccc9b12f329197d74371b3fbf5c24bf8b4e9"},"cell_type":"code","source":"X_test = test_df[features]","execution_count":60,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"178c1ef45552342e8d40b07a7b9427e5e4b1d8e2"},"cell_type":"code","source":"y_pred_test = model_xgb.predict(X_test)","execution_count":76,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"914d7edc356abc81c5b6a08d76eb032c6d9966c1","collapsed":true},"cell_type":"code","source":"np.sum(y_pred_test)","execution_count":77,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8b3130c77ee0b15e8ace1fbc3084442bea5d066e"},"cell_type":"code","source":"#no 1s are predicted; FAIL","execution_count":78,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f29421d046a5395391c95e23eb9bfd1dd7938ae9"},"cell_type":"code","source":"#do submission","execution_count":79,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3ca6577a584591ef6723d840f15e68dce5d973dc"},"cell_type":"code","source":"y_pred_test_prob = model_xgb.predict_proba(X_test)[:, 1]\n\n\nSubmission = pd.DataFrame({ 'SK_ID_CURR': test_df.SK_ID_CURR,'TARGET': y_pred_test_prob })\nSubmission.to_csv(\"sample_submission_baseline_23May18.csv\", index=False)","execution_count":80,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0830bd52db0e9199374f7473600cbf50c4e749a7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}