{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"training_data = pd.read_json(\"../input/train.json\")\nsplit_point = 0.9\ntraining_data = training_data[:int(len(training_data)*split_point)].copy()\nvalidation_data = training_data[int(len(training_data)*split_point):].copy()\n\ntest_data = pd.read_json(\"../input/test.json\")\n\nprint(\"Num Training Data Rows: \", len(training_data))\nprint(\"Num Validation Data Rows: \", len(validation_data))\ntraining_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4dd91a0219488ff944cd69cacf7ff89cc06b18f6","collapsed":true},"cell_type":"code","source":"training_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7ccf418b4253f00d889b7c443c417b6208e6d13","collapsed":true},"cell_type":"code","source":"from functools import reduce\ndef flatten_into_ingredients(df):\n    return reduce(lambda x,y: x+y, df.ingredients.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3648ae6baa5c0cb6ed244feb822b65c7a03bc1fe"},"cell_type":"code","source":"all_ingredients = flatten_into_ingredients(training_data)\nunique_ingredients = np.unique(all_ingredients)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6f52c9fc6aab07e6a2a98e006838e71f423cd3f","collapsed":true},"cell_type":"code","source":"cuisines = training_data.cuisine.unique()\ningredients_by_cuisine = {}\nfor cuisine in cuisines:\n    ingredients_by_cuisine[cuisine] = flatten_into_ingredients(training_data[training_data.cuisine == cuisine])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"c29df0f6dc0cba4dcdce6c602787fb13fd9a0a7d","collapsed":true},"cell_type":"code","source":"print(\"Total Ingredients: \", len(all_ingredients))\nprint(\"Unique Ingredients: \", len(unique_ingredients))\nprint(\"% Duplicate: \", (1 - (float(len(unique_ingredients)) / float(len(all_ingredients)))) * 100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ea472414c3fd311565494859ff9967715f2d370"},"cell_type":"markdown","source":"# TF-IDF Prediction"},{"metadata":{"trusted":true,"_uuid":"528f65656571790e491b80a7664e60792b249254","collapsed":true},"cell_type":"code","source":"import math\n\ntotal_number_documents = len(training_data)\n\ndef tfidf(ingredient):\n    num_docs_with_ingredient_in = sum(training_data.ingredients.map(lambda x: (ingredient.name in x)))\n    idf = math.log(total_number_documents / num_docs_with_ingredient_in)\n    for cuisine in ingredient.index.values:\n        num_ingredients_in_cuisine = len(ingredients_by_cuisine[cuisine])\n        num_this_ingredient_in_cuisine = ingredients_by_cuisine[cuisine].count(ingredient.name)\n        tf = num_this_ingredient_in_cuisine / num_ingredients_in_cuisine\n        ingredient[cuisine] = tf * idf\n    return ingredient\n\ningredient_frequencies = pd.DataFrame(index=unique_ingredients, columns=training_data.cuisine.unique())\ningredient_frequencies = ingredient_frequencies.apply(tfidf, axis=1)\ningredient_frequencies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1102ac236217f00725de55dadd44ca6dab6e51d2","collapsed":true},"cell_type":"code","source":"print(ingredient_frequencies.greek.sort_values(ascending=False).head())\nprint(ingredient_frequencies.italian.sort_values(ascending=False).head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd1f5239d72b097f5f408e50042c2faa8c8174a0","collapsed":true},"cell_type":"code","source":"import operator\n\ndef dict_argmax(dictionary):\n    return max(dictionary.items(), key=operator.itemgetter(1))[0]\n\ndef predict(row):\n    scores = {}\n    for cuisine in cuisines:\n        total = 0\n        for ingredient in row.ingredients:\n            if ingredient in ingredient_frequencies.index:\n                total = total + ingredient_frequencies.loc[ingredient, cuisine]\n        scores[cuisine] = total\n    # print(row.ingredients, row.cuisine, dict_argmax(scores))\n    return dict_argmax(scores)\n\nvalidation_data[\"prediction\"] = validation_data.apply(predict, axis=1)\naccuracy = sum(validation_data.cuisine == validation_data.prediction) / len(validation_data)\nprint(\"Accuracy: %\", (accuracy * 100))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"975d04dcf9df650477a9ac89260018d008eeb488"},"cell_type":"markdown","source":"# Wrong Predictions Analysis"},{"metadata":{"trusted":true,"_uuid":"db5b03a85f2d0934cdfefa5aac557cea3cb92660","collapsed":true},"cell_type":"code","source":"false_predictions = validation_data[validation_data.cuisine != validation_data.prediction].groupby(by=\"cuisine\").id.count()\ntrue_predictions = validation_data[validation_data.cuisine == validation_data.prediction].groupby(by=\"cuisine\").id.count()\n\naccuracy_breakdown = pd.DataFrame({ \"right\": true_predictions, \"wrong\": false_predictions, \"accuracy\": (true_predictions / (true_predictions + false_predictions)) * 100 })\naccuracy_breakdown.sort_values('accuracy', inplace=True, ascending=False)\n\naxes = accuracy_breakdown.accuracy.plot.bar()\n_ = axes.set_ylabel(\"Accuracy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f790078392b4f68b8206765a50078285cee10d8","collapsed":true},"cell_type":"code","source":"wrongly_predicted_rows = validation_data[validation_data.cuisine != validation_data.prediction].copy()\nwrongly_predicted_rows[\"tuple\"] = (wrongly_predicted_rows[\"cuisine\"].str.cat(wrongly_predicted_rows[\"prediction\"], sep=\"-\"))\nwrongly_predicted_rows.groupby('tuple').id.count().sort_values(ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c62a37e5fd7ddd59ad72321c3bba56481d25f66a","collapsed":true},"cell_type":"code","source":"validation_data[validation_data.cuisine == \"italian\"][validation_data.cuisine != validation_data.prediction].groupby('prediction').id.count().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed86850b984fc851eb7818e67ac51a555fd639b0","scrolled":false,"collapsed":true},"cell_type":"code","source":"# validation_data[(validation_data.cuisine == \"italian\") & (validation_data.prediction == \"greek\")].ingredients.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8181b82a88ea367d4973367028ac7cd6038c9b2f"},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true,"_uuid":"019e80c17bee368d0cd2cde8a21a6860592ebe30","collapsed":true},"cell_type":"code","source":"test_data[\"cuisine\"] = test_data.apply(predict, axis=1)\ntest_data.drop(columns=['ingredients'], inplace=True)\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5dce2be9af51ecab12e11e5da60ed441c725ff87"},"cell_type":"code","source":"test_data.to_csv(\"logistic_sub.csv\", index=False, header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2a2ef218afc6401cceaa64249ad6169ff16c79b8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}