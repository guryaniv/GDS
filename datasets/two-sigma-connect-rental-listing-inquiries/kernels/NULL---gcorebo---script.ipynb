{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e33d8dc9-2e0f-d586-574d-1e75f1bed159"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "pd.options.display.max_columns = 100\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.style.use('ggplot')\n",
        "import numpy as np\n",
        "pd.options.display.max_rows = 100\n",
        "data = pd.read_json('../input/train.json')\n",
        "print(\"\\nFirst 8\")\n",
        "data.head(5)\n",
        "def status(feature):\n",
        "\n",
        "    print ('Processing '+feature+': ok')\n",
        "def get_combined_data():\n",
        "    # reading train data\n",
        "    train = pd.read_json('../input/train.json')\n",
        "    \n",
        "    # reading test data\n",
        "    test = pd.read_json('../input/test.json')\n",
        "\n",
        "    # extracting and then removing the targets from the training data \n",
        "    targets = train.interest_level\n",
        "    train.drop('interest_level',1,inplace=True)\n",
        "    \n",
        "\n",
        "    # merging train data and test data for future feature engineering\n",
        "    combined = train.append(test)\n",
        "    combined.reset_index(inplace=True)\n",
        "    combined.drop('index',inplace=True,axis=1)\n",
        "    \n",
        "    return combined\n",
        "\n",
        "combined = get_combined_data()\n",
        "def get_address():\n",
        "    global combined\n",
        "    \n",
        "    #extract street type from each address\n",
        "    combined['address_type'] = combined['street_address'].map(lambda type: \n",
        "                                                              type.split()[-1] if len(type)>1 else \"Other\")\n",
        "    \n",
        "    #map street types to general ones\n",
        "    street_dict = {\n",
        "        \"Street\": \"Street\",\n",
        "        \"St\": \"Street\",\n",
        "        \"St.\": \"Street\",\n",
        "        \"St..\": \"Street\",\n",
        "        \"St,\": \"Street\",\n",
        "        \"St...\": \"Street\",\n",
        "        \"Avenue\": \"Avenue\",\n",
        "        \"Ave\": \"Avenue\",\n",
        "        \"Ave.\": \"Avenue\",\n",
        "        \"Terrace\": \"Terrace\",\n",
        "    }\n",
        "    combined[\"address_type\"] = combined['address_type'].map(street_dict)\n",
        "get_address()\n",
        "combined.head(50)\n",
        "def process_streets():\n",
        "    \n",
        "    global combined\n",
        "    # we clean the street variable\n",
        "    combined.drop('street_address',axis=1,inplace=True)\n",
        "    combined.drop('display_address', axis=1, inplace=True)\n",
        "\n",
        "    # encoding in dummy variable\n",
        "    street_dummies = pd.get_dummies(combined['address_type'],prefix='address_type')\n",
        "    combined = pd.concat([combined,street_dummies],axis=1)\n",
        "    \n",
        "    # removing the title variable\n",
        "    combined.drop('address_type',axis=1,inplace=True)\n",
        "    \n",
        "    status('streets')\n",
        "process_streets()\n",
        "combined.head(50)\n",
        "def process_features():\n",
        "    global combined\n",
        "    \n",
        "    #replace with len\n",
        "    combined['features'] = combined['features'].map(lambda d: len(d))\n",
        "process_features()\n",
        "combined.head()\n",
        "def process_description():\n",
        "    global combined\n",
        "    \n",
        "    #replace\n",
        "    combined['description'] = combined['description'].map(lambda d: len(d.split()))\n",
        "process_description()\n",
        "combined = combined.drop(\"listing_id\", 1)\n",
        "combined = combined.drop(\"manager_id\", 1)\n",
        "combined = combined.drop(\"building_id\", 1)\n",
        "from datetime import datetime\n",
        "from dateutil.parser import parse\n",
        "combined['created'] = combined['created'].map(\n",
        "    lambda x: ((datetime.now() - parse(x)).days )\n",
        ")\n",
        "combined = combined.drop(\"photos\", 1)\n",
        "def scale_all_features():\n",
        "    \n",
        "    global combined\n",
        "    combined[combined['longitude']==0] = combined.longitude.median()\n",
        "    combined[combined.latitude == 0] = combined.latitude.median()\n",
        "    the_features = list(combined.columns)\n",
        "    combined[the_features] = combined[the_features].apply(lambda x: x/x.max(), axis=0)\n",
        "    \n",
        "    print ('Features scaled successfully !')\n",
        "scale_all_features()\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.cross_validation import StratifiedKFold\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
        "from sklearn.cross_validation import cross_val_score\n",
        "def compute_score(clf, X, y,scoring='accuracy'):\n",
        "    xval = cross_val_score(clf, X, y, cv = 5,scoring=scoring)\n",
        "    return np.mean(xval)\n",
        "def recover_train_test_target():\n",
        "    global combined\n",
        "    \n",
        "    train0 = pd.read_json('../input/train.json')\n",
        "    \n",
        "    targets = train0.interest_level\n",
        "    targets = targets.map({\n",
        "        \"low\": -1,\n",
        "        \"medium\": 0,\n",
        "        \"high\": 1\n",
        "    })\n",
        "    train = combined.ix[0:49351]\n",
        "    test = combined.ix[49352:]\n",
        "    \n",
        "    return train,test,targets\n",
        "train,test,targets = recover_train_test_target()\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "clf = ExtraTreesClassifier(n_estimators=200)\n",
        "clf = clf.fit(train, targets)\n",
        "features = pd.DataFrame()\n",
        "features['feature'] = train.columns\n",
        "features['importance'] = clf.feature_importances_\n",
        "features.sort(['importance'],ascending=False)\n",
        "model = SelectFromModel(clf, prefit=True)\n",
        "train_new = model.transform(train)\n",
        "train_new.shape\n",
        "test_new = model.transform(test)\n",
        "test_new.shape\n",
        "forest = RandomForestClassifier(max_features='sqrt')\n",
        "\n",
        "parameter_grid = {\n",
        "                 'max_depth' : [4,5,6,7,8],\n",
        "                 'n_estimators': list(range(200,300,10)),\n",
        "                 'criterion': ['gini','entropy']\n",
        "                 }\n",
        "\n",
        "cross_validation = StratifiedKFold(targets, n_folds=3)\n",
        "\n",
        "grid_search = GridSearchCV(forest,\n",
        "                           param_grid=parameter_grid,\n",
        "                           cv=cross_validation)\n",
        "\n",
        "grid_search.fit(train_new, targets)\n",
        "\n",
        "print('Best score: {}'.format(grid_search.best_score_))\n",
        "print('Best parameters: {}'.format(grid_search.best_params_))"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}