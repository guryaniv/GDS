{"nbformat_minor": 0, "cells": [{"metadata": {"_uuid": "0b1e1ed37134bce1ef3e2a29f7526d33199b0b01", "collapsed": false, "_cell_guid": "cfaec94a-71f9-4205-adaa-5a7f2121a460", "_execution_state": "idle"}, "outputs": [], "source": "##This Kernel will follow the next steps:##\n##1st- Preprocess data##\n##2nd- Find correlations##\n##3rd- Linnear regression##", "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "fac2a1062fdb1cdc49307244f9ef2efed4bc7bf8", "trusted": false, "_cell_guid": "2796d8a0-129b-478b-908f-8a08e716c706", "_execution_state": "idle"}, "outputs": [], "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.", "cell_type": "code", "execution_count": 33}, {"metadata": {"_uuid": "f840218338b7864c73290156caa03d8719603b11", "collapsed": false, "_cell_guid": "03e634bd-4229-4328-b864-b712a51cc2d8", "_execution_state": "idle"}, "outputs": [], "source": "##1st- Preprocess data##\n\n", "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "83493c13d3df0efb63f13e892a86623267f25f42", "collapsed": false, "_cell_guid": "f57aa5bf-591c-48d4-9628-6d19c9c71958", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "#As the data has a date column let's parse the dates for later analisys\ndf = pd.read_csv('../input/kc_house_data.csv', parse_dates = ['date'])\ndf.head()\n", "cell_type": "code", "execution_count": 34}, {"metadata": {"_uuid": "86c8c8456e8a3a2c817128c9011324a457253124", "collapsed": false, "_cell_guid": "90cbdb6f-8b44-4ac4-90d7-911b723041b6", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "#Kind of data we are working\ndf.info()", "cell_type": "code", "execution_count": 35}, {"metadata": {"_uuid": "14549c811fb826c14e27edbc7e706e488af8dcde", "collapsed": false, "_cell_guid": "82f42245-caf6-4ad3-b8c2-3fb16c138f0b", "_execution_state": "idle"}, "outputs": [], "source": "There is no needed to use dummy varibales. ", "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "3875ad6bc62c8d36f86054fd259825877bf7d2ec", "collapsed": false, "_cell_guid": "ea7d0404-f9cf-4e41-9489-bb7b66648419", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "#Find null values\ndf.isnull().sum()", "cell_type": "code", "execution_count": 36}, {"metadata": {"_uuid": "21a89024dc72dd7b49e9ad44de21bf6eb329d262", "collapsed": false, "_cell_guid": "d1943019-3214-45c8-8573-a9a2bdd34837", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "No null variables", "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "c6a22f544b7e99c2df475423b158fd03898e30fd", "collapsed": false, "_cell_guid": "5883c594-e1cf-4188-8cbb-61718bff805b", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "#Extract from 'date of sale' and create two new columns with month an year to find relations with price\ndf['month'] = df['date'].dt.month\ndf['year'] = df['date'].dt.year\n", "cell_type": "code", "execution_count": 37}, {"metadata": {"_uuid": "624ed431b2392139c8d984e4b7b22ca4683d28c9", "collapsed": false, "_cell_guid": "9eda792d-ccc7-41f9-ae06-b8609b8e8f0c", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "df.head()", "cell_type": "code", "execution_count": 38}, {"metadata": {"_uuid": "187791f5d87634320c674fba89d231348af3e32d", "collapsed": false, "_cell_guid": "2c34e7f0-4b1b-47be-b9d5-e5bf2a99160d", "_execution_state": "idle"}, "outputs": [], "source": "##2nd- Find Correlations##", "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "01c2d5beaf00c5902848063f9c91e12204b74ec1", "collapsed": false, "_cell_guid": "37d4e9dc-f179-44bb-9a92-a1a6327c10dd", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "#Correlation\ncorr = df.corr()\n\n#Listed correlation with the price. 23 is the number of columns of the df\ncorr.nlargest(23, 'price')['price']\n", "cell_type": "code", "execution_count": 39}, {"metadata": {"_uuid": "ca396ba11c66f5a35ccc5ec7f5237c69f2026d84", "collapsed": false, "_cell_guid": "85d9ac17-71c6-4503-a9fc-b66df134669d", "_execution_state": "idle"}, "outputs": [], "source": "Closer to 1 or -1 more correlated the values.  Closer to 0 the less correlated, in this case the year is the less correlated with the price. Reading those values there is nothing strange with them.", "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "3e07cfa0bd2f2f9ac243475fa7f8270eb32310cd", "collapsed": false, "_cell_guid": "ac656670-737f-482a-a1f7-f198425a5b4e", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "\n#Mybe there is not correlation between dates and price but the prices can be stationary\n#I will also check if the prices had increase from 2014 to 2015\n\n#Price increase between 2014 adn 2015\npriceYear =  df['price'].groupby(df['year']).mean()\npriceYear.plot(kind = 'bar')\n\n", "cell_type": "code", "execution_count": 40}, {"metadata": {"_uuid": "4c45c28cc54b2d0deba98c5dc0f1c9667d518f62", "collapsed": false, "_cell_guid": "51769a93-384f-426d-af1a-90af47cfda73", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "#% value of the icrease\nlist_priceYear = list(priceYear)\npriceIncrease = ((list_priceYear[0]/list_priceYear[1])-1)*(-100)\nprint ('Form 2014 to 2015 there is a price increase in % of: ', priceIncrease)", "cell_type": "code", "execution_count": 41}, {"metadata": {"_uuid": "8b08d0190ee386e074004f076141e841b4a08614", "collapsed": false, "_cell_guid": "888c2432-7716-417d-9d8e-1fcd24ffaad7", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "#Find if the prices are stationary between months\npriceMonth = df['price'].groupby(df['month']).mean()\npriceMonth.plot(kind = 'line')\n", "cell_type": "code", "execution_count": 42}, {"metadata": {"_uuid": "dd93f5c73fe583ee185c528ee05895e9e6ab55c8", "collapsed": false, "_cell_guid": "f783244a-261d-438d-9b2a-73f854302649", "_execution_state": "idle"}, "outputs": [], "source": "**If you buy a house the best month is February with the lower average prices!!!** ", "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "3e939cbb173430bab244cf1cb5685cef27527812", "collapsed": false, "_cell_guid": "df00edd2-c991-493e-802b-9954f35be4b0", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "#The difference in the average price between February and May\nprint('The average price diference in $ buying a house in Feb or in May is: ', priceMonth.max()-priceMonth.min())", "cell_type": "code", "execution_count": 43}, {"metadata": {"_uuid": "36888dc87560ac1127312fc1283dae05ed4d5099", "collapsed": false, "_cell_guid": "f8e8a983-3550-4e79-a97a-c69af72880ab", "_execution_state": "idle"}, "outputs": [], "source": "Seems  that in King Country they like he sun. Nearly 54000$ At least when they buy houses.", "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "dcaa1fbda3e8e58cbb3e6f90c6ca483fee3c8a53", "collapsed": false, "_cell_guid": "b54f7ca6-84cb-4c06-8e21-2255c5a0e4a1", "_execution_state": "idle"}, "outputs": [], "source": "##3rd- Linear regression##", "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "36ba0dbe7f3ebda2b8a310f0dd4af36ab5195525", "collapsed": false, "_cell_guid": "ecd569c9-a54e-47b0-b861-ee63a3210bc8", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "#Create the data to train.\ny = df['price']\ndf = df.drop(['price', 'id', 'date'], axis = 1)\nx_train,x_test,y_train,y_test=train_test_split(df,y,train_size=0.8,random_state=42)\n\n", "cell_type": "code", "execution_count": 44}, {"metadata": {"_uuid": "8e0236ea9418ee9760fbe6c76e468f01609b486e", "collapsed": false, "_cell_guid": "4e12fe9e-64f1-4c69-b132-367d3f6ead52", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "#Linnear regression\nreg=LinearRegression()\nreg.fit(x_train,y_train)\nreg.score(x_test,y_test)\n", "cell_type": "code", "execution_count": 45}, {"metadata": {"_uuid": "307c00b2809addfee264e7f883566e4598ec81a8", "collapsed": false, "_cell_guid": "5bef3018-1d24-4eff-b8cd-d0a448bff4e0", "_execution_state": "idle"}, "outputs": [], "source": "70% is not a bad result for starting. There are much more powerful algorithms to  make this prediction.", "cell_type": "markdown", "execution_count": null}], "metadata": {"language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4}