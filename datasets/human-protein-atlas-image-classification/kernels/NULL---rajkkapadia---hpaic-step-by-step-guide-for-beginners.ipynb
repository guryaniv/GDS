{"cells":[{"metadata":{"_uuid":"2626d1f0cac958fcddafca3a3a7754af89464d05"},"cell_type":"markdown","source":"**Hello friends,**\n\n**This is my first informative post here on Kaggle.**\n\n**I have been learning Neural Network for about 1 year now, and I have learnt so much from the fello Kagglers, so I thought to give it back to the community.**\n\n**I hope this will help.**"},{"metadata":{"_uuid":"199f41850ddf5b878aa501d9b4ec2b729089f585"},"cell_type":"markdown","source":"**First Things First - What is our input**\n\n1. We have **train.csv** which contains id of each image and label for respective image.\n2. We have **train.zip** this contains four images of each sample, they are **red, green, blue, yellow**.\n3. We have **test.zip** contains images for testing and submitting your work, ids for test images are given in **sample_submission.csv**\n4. Images are of two different size and type,\n    512x512 PNG files\n    2048x2048 and 3072x3072 TIFF files\n    we will work with 512x512 images.\n    \n5. We have everything above mentioned in **../input/** directory.    "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Some basic libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# PIL library to read images\n# PIL library is the fastest as per my knowledge\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e6e5c292b282397f52a14e65df6ced23c527d79"},"cell_type":"code","source":"# Read the train.csv fiel\ntrain_csv = pd.read_csv(\"../input/train.csv\")\n\n# Training images path\nTRAIN_PATH = \"../input/train/\"\n# Testing images path\nTEST_PATH = \"../input/test/\"\n\n# Four colours for images\ncolours = [\"red\", \"green\", \"blue\", \"yellow\"]\n\n# Training image ids\nids = train_csv[\"Id\"]\n# Training image labels\ntargets = train_csv[\"Target\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8070310d2ae2a642911abf10106113a5c91175e"},"cell_type":"code","source":"train_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d9089f529a83d9abdf9d303cd9529be1731a7ea"},"cell_type":"markdown","source":"**Let's see the images**"},{"metadata":{"trusted":true,"_uuid":"704c69825420c2c06f591eae00d866748176d4af"},"cell_type":"code","source":"ids[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40be853979f62d3eb6b8262a49d58a6b00320395"},"cell_type":"code","source":"# The whole set of images for one sample is as follows\nprint(TRAIN_PATH+ids[0]+\"_\"+colours[0]+\".png\")\nprint(TRAIN_PATH+ids[0]+\"_\"+colours[1]+\".png\")\nprint(TRAIN_PATH+ids[0]+\"_\"+colours[2]+\".png\")\nprint(TRAIN_PATH+ids[0]+\"_\"+colours[3]+\".png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d060e3cf0e8692d49311ccf781421f24fc3869b"},"cell_type":"markdown","source":"As mentioned in the data of the competition ,in this tutorial we will work with **Green** image."},{"metadata":{"trusted":true,"_uuid":"fa9d2bb1ad4b2b38a3c3ae07ff90d37a947abd5b"},"cell_type":"code","source":"green = np.asarray(Image.open(TRAIN_PATH+ids[0]+\"_\"+colours[1]+\".png\"))\n\nplt.imshow(green)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00594a3b4fb216588890e9263357686ff4baac6f"},"cell_type":"code","source":"target = targets[1].split(\" \")\nprint(target)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92020d1c31faac3511b5a1b93faa4a5ef96cf99b"},"cell_type":"markdown","source":"**Now the labels**\n\nWe have different 28 labels for one sample, we convert them into\n[0, 0, 0, ... ,0, 0, 0]\n\nfor example sample 0 [16, 0] **Protein** present in them\nwe will convert them into\n\n[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n\nThis is a **Multi Lable Classification Problem**"},{"metadata":{"trusted":true,"_uuid":"9d5f9c3f4f9ac2ec945a07f3a85730fe2ca68ed2"},"cell_type":"code","source":"# First create empty array and then fill 1 where needed\nlabel = np.zeros((1, 28))\nprint(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72dfc8a097203e4be8f84918412b5a00e443c816"},"cell_type":"code","source":"for value in target:\n    label[0, int(value)] = 1\n\nprint(label)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ac3862ce095c9eb54ea8d983b9754061bbca8f0"},"cell_type":"markdown","source":"So now we understand how to read the image and convert label into required form let's create a CNN."},{"metadata":{"trusted":true,"_uuid":"a30ab140b649251193c210b03e214bcca91c2a82"},"cell_type":"markdown","source":"**Create you own model here.**"},{"metadata":{"trusted":true,"_uuid":"d309fdd6a1c98ae765e641c567cff72dad1aa502"},"cell_type":"code","source":"# Create your own batches here\nbatches = [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n           1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n           1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n           1071]\nnumb_labels = 28","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5b58bb1a4be15804d87e0ee8e99f041f20053b5"},"cell_type":"code","source":"# Model fitting parameters\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001, verbose=1)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n\nbatch_id = 1\nindex = 0\n\nfor batch in batches:\n    print(\"Processing batch number \" + str(batch_id))\n    # Create empty images and labels for batch\n    images = np.zeros((batch, 512, 512, 1), dtype=np.float)\n    labels = np.zeros((batch, numb_labels), dtype=np.float)\n    \n    for i in range(batch):\n        \n        # Get the image\n        green = np.asarray(Image.open(TRAIN_PATH+ids[index]+\"_\"+colours[1]+\".png\"))\n        index += 1\n        # Add to images\n        images[i] = green.reshape(512, 512, 1)/255\n        \n        # Same for labels\n        target = targets[i].split(\" \")\n        \n        for value in target:\n            labels[i, int(value)] = 1\n        \n    print(\"Fitting the data to the model.\")\n    # Train the model\n    # --> Youer model here\n    batch_id += 1\n    index += 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c66a34099e4e3d0f7ae68548b8ac3b5918da5a6"},"cell_type":"markdown","source":"Now let's test our model."},{"metadata":{"trusted":true,"_uuid":"3637ae49edf45d0ecdbe6662425bbabc9d3aa570"},"cell_type":"code","source":"test_csv = pd.read_csv(\"../input/sample_submission.csv\")\ntest_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be39986ba71821b6a9dabfb79b93686ca4b4df4c"},"cell_type":"code","source":"ids_test = test_csv[\"Id\"]\nids_test[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1adfade245cda5054ae61e5591b53f7ab52a0f6"},"cell_type":"code","source":"y_pred = np.zeros((len(ids_test), numb_labels), dtype=np.float)\nimages = np.zeros((1, 512, 512, 3), dtype=np.float)\n\nfor i in range(len(ids_test)):\n    red = np.asarray(Image.open(TEST_PATH+ids_test[i]+\"_\"+colours[0]+\".png\"))\n    green = np.asarray(Image.open(TEST_PATH+ids_test[i]+\"_\"+colours[1]+\".png\"))\n    blue = np.asarray(Image.open(TEST_PATH+ids_test[i]+\"_\"+colours[2]+\".png\"))\n    \n    img_rgb = np.stack((red, green, blue), axis=-1)\n    img_rgb = img_rgb/255\n    \n    images[0] = img_rgb\n    \n    # Your model\n    # y_pred[i] = model.predict(images, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40a95117e75c6ff739592475e479b9a9d2afa8b7"},"cell_type":"code","source":"y_pred = (y_pred > 0.4).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcf2ad5d1ad4df0668cf810960946d22e00c85ae"},"cell_type":"code","source":"# Convert 1 and 0 into 0 to 27 digits for our labels\ny_sub = []\nfor label_set in y_pred:\n    index = 0\n    l = \"\"\n    for label in label_set:\n        if label == 1:\n            l += str(index)\n            l += \" \"\n            index += 1\n        else:\n            index += 1\n    y_sub.append(l[0:-1])\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2eff21f51b5bf30526b9723c83d0d87bcae560e8"},"cell_type":"code","source":"# Prepare submission file\nsubmission = pd.DataFrame({\"Predicted\":y_sub}, index=ids_test)\nsubmission.to_csv(\"submission_one.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6a22854f32fb7fb2ee39aa7c0b2f94186c853e9"},"cell_type":"markdown","source":"If you like my work consider up voting it.\nThank you.\n\n\n\n**Enjoy The Life, Feel The Music**"},{"metadata":{"trusted":true,"_uuid":"66578f9c9506bbe53bd2b1c45374dc8b79e6176f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}