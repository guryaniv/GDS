{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib as plt\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Activation,Dropout,Conv2D,MaxPooling2D,Flatten,Input,BatchNormalization,AveragePooling2D,LeakyReLU\nfrom keras.metrics import top_k_categorical_accuracy\nfrom keras.utils import plot_model\nfrom keras import optimizers\nfrom keras.models import Model\nfrom tqdm import tqdm\nfrom keras.applications.resnet50 import ResNet50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79c5f9e626a027296a18b1c2b7f3265a408a07b7"},"cell_type":"code","source":"trainFilePath = '../input/train.csv'\nrawTrainData = pd.read_csv(trainFilePath)\nprint(rawTrainData.head(15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d753bb32a5e2775be03924167161f671f88cd131"},"cell_type":"code","source":"trainLabel = rawTrainData['Id']\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(trainLabel)\ntrainLabel_transform = le.transform(trainLabel)\nprint('The number of unique whale classes are : ',len(np.unique(trainLabel_transform)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91b3c9245082b5700b109276434ea052b43978d4","scrolled":false},"cell_type":"code","source":"import matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nuniqueWhaleNames = np.unique(trainLabel)\ntmpUniqueWhaleNames = uniqueWhaleNames[0:9]\nfor id in tmpUniqueWhaleNames:\n    tempDF = rawTrainData.loc[rawTrainData['Id'] == id]\n    fileName = tempDF.iloc[0]['Image']\n    imgdata = mpimg.imread('../input/train/' + fileName)\n    plt.imshow(imgdata)\n    plt.show()\n    print('The size of image is: ',np.shape(imgdata))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"a7bd7310f4b676c4edb5fc3e569e6365b6cc4e5b"},"cell_type":"code","source":"import cv2\n\ntrain_df,val_df = train_test_split(rawTrainData,test_size = 0.03, random_state = 42)\nbatch_size = 64\n\ndef prepareImageData(fileName):    \n    gray_image = cv2.imread('../input/train/' + fileName)    \n    gray_image = cv2.resize(gray_image, (64, 64), interpolation = cv2.INTER_AREA)    \n    return np.array(gray_image)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ac9a2da18a80b2625d006fbd7b0ca22c633c576"},"cell_type":"code","source":"def top_5_accuracy(y_true,y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4185a88ad204108e96459d79df7d4ea9e75dd3ca"},"cell_type":"code","source":"new_whale_df = rawTrainData[rawTrainData.Id == \"new_whale\"] \ntrainData = rawTrainData[~(rawTrainData.Id == \"new_whale\")] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10e945e5cbb261e2b340463ee6a88b368c5fefa7"},"cell_type":"code","source":"trainLabel = trainData['Id']\nle = LabelEncoder()\nle.fit(trainLabel)\ntrainLabel_transform = le.transform(trainLabel)\nprint('The number of unique whale classes are : ',len(np.unique(trainLabel_transform)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b53a2e0c8adf8cfc296a3ab9bd1b83ad0275975","scrolled":false},"cell_type":"code","source":"train_df,val_df = train_test_split(trainData,test_size = 0.03, random_state = 42)\nX_train = np.array([prepareImageData(fileName) for fileName in tqdm(train_df['Image'])])\nY_train = np.array([targetVal for targetVal in tqdm(train_df['Id'])])\nY_train = keras.utils.to_categorical(le.transform(Y_train),num_classes = len(np.unique(trainLabel_transform)))\n\nX_val = np.array([prepareImageData(fileName) for fileName in tqdm(val_df['Image'])])\nY_val = np.array([targetVal for targetVal in tqdm(val_df['Id'])])\nY_val = keras.utils.to_categorical(le.transform(Y_val),num_classes = len(np.unique(trainLabel_transform)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20894eb984e1d28b0b95e93371a6d2a9ca581426"},"cell_type":"code","source":"input_img = Input(shape=(64,64,3))\nlayer_1 = Conv2D(filters = 6,kernel_size = (5,5),strides = 1,padding = 'same')(input_img)\nlayer_1 = BatchNormalization(axis=3, momentum=0.99, epsilon=0.001)(layer_1)\nlayer_1 = Activation('relu')(layer_1)\nlayer_1 = MaxPooling2D(pool_size = (2,2),padding = 'same')(layer_1)\nlayer_2 = Conv2D(filters = 16,kernel_size = (5,5),strides = 1,padding = 'same')(layer_1)\nlayer_2 = Activation('relu')(layer_2)\nlayer_2 = MaxPooling2D(pool_size = (2,2),padding = 'same')(layer_2)\nlayer_3 = Conv2D(filters = 16,kernel_size = (5,5),strides = 1,padding = 'same')(layer_2)\nlayer_3 = Activation('relu')(layer_3)\nlayer_3 = MaxPooling2D(pool_size = (2,2),padding = 'same')(layer_3)\nlayer_4 = Flatten()(layer_3)\nlayer_4 = Dense(512,activation='relu')(layer_4)\nlayer_4 = Dropout(0.5)(layer_4)\noutput = Dense(len(np.unique(trainLabel_transform)),activation='softmax')(layer_4)\nmodel_conv = Model(inputs = input_img, outputs = output)\nmodel_conv.compile(optimizer='Adam',loss = 'categorical_crossentropy',metrics=['accuracy',top_5_accuracy])\nmodel_conv.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f98aa93a0fac86fe6c62d721c5bed8c3e43a9d09","scrolled":false},"cell_type":"code","source":"model_conv.fit(X_train, Y_train, batch_size=256,validation_data = (X_val,Y_val),epochs = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93c6ba4f3252771eaba01ec6cdf7c2e849ca1961"},"cell_type":"code","source":"X_newWhale = np.array([prepareImageData(fileName) for fileName in tqdm(new_whale_df['Image'])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10c55b1424c61f6a5c51871c403682c2d3f4b1c0"},"cell_type":"code","source":"Y_newwhale_predict = model_conv.predict(X_newWhale, batch_size=256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5a159c72d72cbe1d3bb917eaaaf462d6f097e42"},"cell_type":"code","source":"whaleThresh = np.mean(np.max(Y_newwhale_predict,axis=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c334c90d325def38501c05393434f0caeeda7a5"},"cell_type":"code","source":"def getLabel(classes,le):\n    result = []\n    _class = le.inverse_transform(classes)\n    for i in range(0, len(classes)):              \n        result.append(_class[i])\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2a4ee146a7684af76c161e3dfef61c79cd6e0af"},"cell_type":"code","source":"TEST = '../input/test/'\ntest_names = [f for f in os.listdir(TEST)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cf02482b9b1e56959a173bc6bae9daf1f2ea3b3","scrolled":false},"cell_type":"code","source":"SAMPLE_SUBMISSION_FILE=\"submission_64.csv\"\n\nwith open(SAMPLE_SUBMISSION_FILE,\"w\") as f:\n    f.write(\"Image,Id\\n\")\n    for fileName in tqdm(test_names):        \n        gray_image = cv2.imread('../input/test/' + fileName)\n        gray_image = cv2.resize(gray_image,(64,64),interpolation = cv2.INTER_AREA)         \n        X_test = np.array(np.reshape(gray_image,(1,64,64,3)))\n        Y_test = model_conv.predict(X_test,batch_size=1)        \n        temp_best_predict_5 = np.argsort(Y_test)[0][::-1][:5]            \n        temp_pre = getLabel(temp_best_predict_5,le)\n        best_Y_test = Y_test[0,temp_best_predict_5]        \n        for i in range(0,len(best_Y_test)):\n            print(best_Y_test[i])\n            if best_Y_test[i] < whaleThresh:\n                breakId = i\n                break\n        if breakId <4:\n            pre = []\n            for i in range(0,breakId):\n                pre.append(temp_pre[i])\n            pre.append(\"new_whale\")        \n            for i in range(breakId+1,4):\n                pre.append(temp_pre[i])\n        else:\n            pre = temp_pre\n            \n        #print(image, \" \".join( pre))\n        print(pre)\n        f.write(\"%s,%s\\n\" %(os.path.basename(fileName), \" \".join( pre)))\nprint(\"csv created\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}