{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea84a100ccb1383856f05440d1bf108144c94b84"},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"cd ../input/daguan-cups-dataset/new_data/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca47ae5fc3f060422bb024af39f94f0293b61319","collapsed":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"943ec9797c640924e96c87abadd315ed28d592b0"},"cell_type":"code","source":"cd new_data/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9049d2b6c718a3df454ab921cf80fd22ad3f1e66"},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cc525100128fedaaeb79b27afb58968d5391af9d"},"cell_type":"code","source":"import os\n\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,TfidfVectorizer\n\n\n# to splite dataset into train and test data.\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\n\n# importing Machine learning Algorithm from sklearn\nfrom sklearn.linear_model import LogisticRegression #Logistic Regression\nfrom sklearn.linear_model import LinearRegression #Linear Regression\nfrom sklearn.neighbors.nearest_centroid import NearestCentroid # Centroid Based Classifier\nfrom sklearn.neighbors import KNeighborsClassifier #KNN Classifier\nfrom sklearn.svm import SVC # Support Vector Machine\nfrom sklearn.naive_bayes import BernoulliNB # Naive Bayes Classifier\nfrom sklearn.tree import DecisionTreeClassifier # Decission Tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcff3cd7d445c221403db01d8426127ccff9193a","collapsed":true},"cell_type":"code","source":"\nimport pandas as pd, numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn import svm\nimport pickle\ncolumn = \"word_seg\"\ntrain = pd.read_csv('train_set.csv')\ntest = pd.read_csv('test_set.csv')\ntest_id = test[\"id\"].copy()\nvec = TfidfVectorizer(ngram_range=(1,2),min_df=3, max_df=0.9,use_idf=1,smooth_idf=1, sublinear_tf=1)\nfeature=vec.fit_transform(train['word_seg']+train['word_seg'])\ntest_feature=vec.transform(test['word_seg']+train['word_seg'])\nwith open(\"vec.pic\",\"w\") as fw:\n    vec_pic=pickle.dumps(vec)\n    f.write(vec_pic)\n    del vec_pic\nwith open(\"fea.pic\",\"w\") as fw:\n    fea_pic=pickle.dumps(feature)\n    f.write(fea_pic)\n    del fea_pic\nwith open(\"test_fea.pic\",\"w\") as fw:\n    test_fea_pic=pickle.dumps(test_feature)\n    f.write(test_fea_pic)\n    del test_fea_pic\n    \nlabel=(train['class']-1).astype(int)\nlabel, feature = shuffle(label, feature, random_state=1)\nx_train, x_test, y_train, y_test = train_test_split(feature, label, test_size=0.20, random_state=0)\nprint(\"data over\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"956444aaf36e5da873a6270958b28a3045fa4672"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"93eb61a277c6e7746bc1032bcc7d24e5a115826b"},"cell_type":"code","source":"linearRegr = LinearRegression().fit(x_train, y_train)\n# logisticRegr = LogisticRegression().fit(x_train, y_train)\n# model_centroid = NearestCentroid().fit(x_train, y_train)\n# model_knn = KNeighborsClassifier(19).fit(x_train, y_train)\n# model_svm = SVC().fit(x_train, y_train)\n# model_nb = BernoulliNB().fit(x_train, y_train)\n# model_dtree = DecisionTreeClassifier(criterion = \"entropy\",random_state = 100, max_depth=3, min_samples_leaf=5).fit(x_train, y_train)\n# model_rfc = RandomForestClassifier(n_estimators=300, max_depth=150,n_jobs=1).fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26048ef5bb8c66bb04ca142744ad4daefb363ea2","collapsed":true},"cell_type":"code","source":"# Find the accuracy of each model\nphrase = \"The accuracy of %s is %0.2f\"\n# accu_lir = linearRegr.score(x_test, y_test)\n# print(phrase % (\"Linear Regression\", 100*accu_lir))\naccu_lr = logisticRegr.score(x_test, y_test)\nprint(phrase % (\"Logistic Regression\", 100*accu_lr))\n# accu_centroid = model_centroid.score(x_test, y_test)\n# print(phrase % (\"Centroid Based Classifier\", 100*accu_centroid))\n# accu_knn = model_knn.score(x_test, y_test)\n# print(phrase % (\"KNN\", 100*accu_knn))\n# accu_svm = model_svm.score(x_test, y_test)\n# print(phrase % (\"SVM\", 100*accu_svm))\n# accu_nb = model_nb.score(x_test, y_test)\n# print(phrase % (\"Naive Bayes\", 100*accu_nb))\n# accu_dtree = model_dtree.score(x_test, y_test)\n# print(phrase % (\"Decission Tree\", 100*accu_dtree))\n# accu_rfc = model_rfc.score(x_test, y_test)\n# print(phrase % (\"RandomForest Classifier\", 100*accu_rfc))\n# y_pred = model_centroid.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ffee19eadbb166c5c091d622a81e758042670bb"},"cell_type":"markdown","source":"- lr : The accuracy of Logistic Regression is 76.73"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"59bd339ae91fdb903333636f989e132b9ebbf671"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}