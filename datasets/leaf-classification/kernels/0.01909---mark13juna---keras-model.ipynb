{"nbformat_minor": 1, "cells": [{"execution_count": null, "source": ["%pylab inline\n", "\n", "import numpy as np\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from sklearn import preprocessing\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.cross_validation import train_test_split\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.model_selection import StratifiedShuffleSplit\n", "from keras.models import Sequential\n", "from keras.layers import Merge\n", "from keras.layers import Dense, Dropout, Activation, Flatten\n", "from keras.layers.advanced_activations import PReLU\n", "from keras.layers import Convolution2D, MaxPooling2D\n", "from keras.utils.np_utils import to_categorical\n", "from keras.callbacks import EarlyStopping\n", "\n", "## Read data from the CSV file\n", "data = pd.read_csv('../input/train.csv')\n", "parent_data = data.copy()    ## Always a good idea to keep a copy of original data\n", "__id__ = data.pop('id')\n", "\n", "data.shape\n", "data.describe()\n", "\n", "## Need to encode labels as they're strings\n", "y = data.pop('species')\n", "y = LabelEncoder().fit(y).transform(y)\n", "print(y.shape)\n", "\n", "## Normalizing data, zero mean\n", "X = preprocessing.MinMaxScaler().fit(data).transform(data)\n", "X = StandardScaler().fit(data).transform(data)\n", "print(X.shape)\n", "X\n", "\n", "## We will be working with categorical crossentropy function\n", "## It is required to further convert the labels into \"one-hot\" representation\n", "y_cat = to_categorical(y)\n", "print(y_cat.shape)\n", "\n", "## retain class balances \n", "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1,random_state=12345)\n", "train_id, value_id = next(iter(sss.split(X, y)))\n", "x_train, x_val = X[train_id], X[value_id]\n", "y_train, y_val = y_cat[train_id], y_cat[value_id]\n", "print(\"x_train dim: \",x_train.shape)\n", "print(\"x_val dim:   \",x_val.shape)\n", "print()\n", "# ----------------\n", "## Developing a layered model for Neural Networks No/4/\n", "## Input dimensions should be equal to the number of features\n", "## We used softmax layer to predict a uniform probabilistic distribution of outcomes\n", "Model = Sequential()\n", "Model.add(Dense(900,input_dim=192,  init='uniform', activation='relu'))\n", "Model.add(Dropout(0.25))\n", "Model.add(Dense(450, activation='sigmoid'))\n", "Model.add(Dropout(0.25))\n", "Model.add(Dense(99, activation='softmax'))\n", "\n", "\n", "Model.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics = [\"accuracy\"])\n", "early_stopping = EarlyStopping(monitor='val_loss', patience=600)\n", "history = Model.fit(x_train, y_train,batch_size=192,nb_epoch=2500 ,verbose=0,validation_data=(x_val, y_val),callbacks=[early_stopping])\n", "                    \n", "print('val_acc: ',max(history.history['val_acc']))\n", "print('val_loss: ',min(history.history['val_loss']))\n", "print('train_acc: ',max(history.history['acc']))\n", "print('train_loss: ',min(history.history['loss']))\n", "print(\"train/val loss ratio: \", min(history.history['loss'])/min(history.history['val_loss']))\n", "\n", "\n", "\n", "\n", "## read test file\n", "test = pd.read_csv('../input/test.csv')\n", "index = test.pop('id')\n", "\n", "## we need to perform the same transformations from the training set to the test set\n", "test = preprocessing.MinMaxScaler().fit(test).transform(test)\n", "test = StandardScaler().fit(test).transform(test)\n", "\n", "\n", "yPred =  Model.predict_proba(test)\n", "\n", "yPred = pd.DataFrame(yPred,index=index,columns=sort(parent_data.species.unique()))\n", "\n", "\n", "\n", "fp = open('submission_nn_kernel.csv','w')\n", "fp.write(yPred.to_csv())\n", "\n"], "cell_type": "code", "metadata": {"_uuid": "017b05d747517b59240d14c07db73474240816a6", "_cell_guid": "ae537d1a-e285-4836-a9cf-f7317234de28"}, "outputs": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.4", "file_extension": ".py", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4}