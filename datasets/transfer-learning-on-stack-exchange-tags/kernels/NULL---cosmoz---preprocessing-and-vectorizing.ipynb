{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "992f36de-d4d9-4bec-daab-d4520629f8a7"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "from pandas import Series,DataFrame\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# machine learning\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# preprocessing\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "57f6d04e-86f6-17b8-6fc1-101a18852bde"
      },
      "outputs": [],
      "source": [
        "dataframes = {\n",
        "    \"cooking\": pd.read_csv(\"../input/cooking.csv\"),\n",
        "    \"crypto\": pd.read_csv(\"../input/crypto.csv\"),\n",
        "    \"robotics\": pd.read_csv(\"../input/robotics.csv\"),\n",
        "    \"biology\": pd.read_csv(\"../input/biology.csv\"),\n",
        "    \"travel\": pd.read_csv(\"../input/travel.csv\"),\n",
        "    \"diy\": pd.read_csv(\"../input/diy.csv\"),\n",
        "}\n",
        "\n",
        "test = pd.read_csv(\"../input/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "308a12a1-e6b1-16e1-f046-4a6380560ef2"
      },
      "outputs": [],
      "source": [
        "# remove html tags and uris from contents\n",
        "\n",
        "uri_re = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?\u00ab\u00bb\u201c\u201d\u2018\u2019]))'\n",
        "\n",
        "def stripTagsAndUris(x):\n",
        "    if x:\n",
        "        # BeautifulSoup on content\n",
        "        soup = BeautifulSoup(x, \"html.parser\")\n",
        "        # Stripping all <code> tags with their content if any\n",
        "        if soup.code:\n",
        "            soup.code.decompose()\n",
        "        # Get all the text out of the html\n",
        "        text =  soup.get_text()\n",
        "        # Returning text stripping out all uris\n",
        "        return re.sub(uri_re, \"\", text)\n",
        "    else:\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bd9fc15a-8b09-80a6-395b-b9f119e904b6"
      },
      "outputs": [],
      "source": [
        "for df in dataframes.values():\n",
        "    df[\"content\"] = df[\"content\"].map(stripTagsAndUris)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0307a53a-5c88-7b7e-a4cd-dffae1a1da45"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "vectorizer = CountVectorizer(min_df=1)\n",
        "for df in dataframes.values():\n",
        "    for title in df['title']:\n",
        "        corpus.append(title)\n",
        "    for content in df['content']:\n",
        "        corpus.append(content)\n",
        "X = vectorizer.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7f965448-287c-ca71-3336-917f05613f93"
      },
      "outputs": [],
      "source": [
        "analyzer = vectorizer.build_analyzer()\n",
        "tokenizer = vectorizer.build_tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "980a1e01-c152-3050-0ec4-568bf08ed0b2"
      },
      "outputs": [],
      "source": [
        "for df in dataframes.values():\n",
        "    df[\"title\"] = df[\"title\"].map(analyzer)\n",
        "    df[\"content\"] = df[\"content\"].map(analyzer)\n",
        "    df[\"tags\"] = df[\"tags\"].map(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "27a26a49-0797-db71-efd3-14f2b2101db5"
      },
      "outputs": [],
      "source": [
        "dataframes['cooking'].head()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}