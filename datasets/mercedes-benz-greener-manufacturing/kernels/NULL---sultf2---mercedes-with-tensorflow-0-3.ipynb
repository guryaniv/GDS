{"metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython2", "name": "python", "file_extension": ".py", "version": "2.7.12"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"metadata": {"_uuid": "89cc62c604aae65bc474f8f49fb36f52627c7d4b", "_cell_guid": "2207021e-3f3e-487f-837a-40c01fffbfe2"}, "source": "Would be really interested if people have ideas on how to improve this!", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "d93c05d6952802af17e43b4699419e5795e03f40", "collapsed": false, "_cell_guid": "bf38a08a-6123-4c08-a2d6-14800aeeef75"}, "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import ShuffleSplit\nimport numpy as np\nimport tensorflow as tf\nimport tflearn", "outputs": [], "cell_type": "code", "execution_count": 51}, {"metadata": {"_uuid": "9592a5a67c09c37d8b1164e0f9a7a4be876dccf6", "collapsed": false, "_cell_guid": "8863ea18-206d-4dbc-8aff-1152fabc9bd7"}, "source": "train_df = pd.read_csv(\"../input/train.csv\")\ntrain_df.drop('ID', axis=1, inplace=True)\ntest_df = pd.read_csv(\"../input/test.csv\")\ntest_df.drop('ID', axis=1, inplace=True)\nprint(\"Train shape : \", train_df.shape)\nprint(\"Test shape : \", test_df.shape)", "outputs": [], "cell_type": "code", "execution_count": 52}, {"metadata": {"_uuid": "265ef6d16d444460dc71046bf6782611cd9bbc06", "collapsed": false, "_cell_guid": "f15bb60c-1a67-432b-ac30-505df8fced63"}, "source": ["dtype_df = train_df.dtypes.reset_index()\n", "dtype_df.columns = ['name','type']\n", "dtype_df.groupby('type').aggregate('count').reset_index()"], "outputs": [], "cell_type": "code", "execution_count": 53}, {"metadata": {"_uuid": "1f208e4615482e38b243392d53c49898a53fc0df", "collapsed": true, "_cell_guid": "9619c44a-e89a-457a-9847-7cffd4c04221"}, "source": ["def get_dummy_values(dummy_fields, base_df):\n", "    # This will create dummy values for all categorical features\n", "    # and remove the original features from the dataset\n", "    for each in dummy_fields:\n", "        dummies = pd.get_dummies(base_df[each], prefix=each, drop_first=False)\n", "        base_df = pd.concat([base_df, dummies], axis=1)\n", "    data = base_df.drop(dummy_fields, axis=1)\n", "    return data\n", "\n", "def get_scaled_values(quant_features, data):\n", "    # Store scalings in a dictionary so we can convert back later\n", "    scaled_features = {}\n", "    for each in quant_features:\n", "        mean, std = data[each].mean(), data[each].std()\n", "        scaled_features[each] = [mean, std]\n", "        data.loc[:, each] = (data[each] - mean)/std\n", "    return scaled_features, data"], "outputs": [], "cell_type": "code", "execution_count": 54}, {"metadata": {"_uuid": "2dcacd602b6c73c6291e3fd87e7ba18c3edcfdc9", "collapsed": false, "_cell_guid": "c7db35b2-0417-46bb-bd04-49830364bf92"}, "source": ["# ID all the categoical and numerical features\n", "cat_vars = dtype_df.name[dtype_df.type=='object'].tolist()\n", "print(cat_vars)\n", "num_vars = dtype_df.name[dtype_df.type=='float64'].tolist()\n", "print(num_vars)"], "outputs": [], "cell_type": "code", "execution_count": 55}, {"metadata": {"_uuid": "f96f79284fd4d5eaca21bcceff5b0ee709539e9b", "collapsed": false, "_cell_guid": "f58188f8-bafb-4929-8a47-238838321e8a"}, "source": ["# We want to create dummy variables for all categorical features\n", "data = get_dummy_values(cat_vars, train_df)\n", "# We only need to scale the target variable. All other numerical features \n", "# are binary categories so no need to scale them\n", "scaled_features, data = get_scaled_values(num_vars, data)\n", "\n", "# just need to get the categorical variables for the test data\n", "test_data = get_dummy_values(cat_vars, test_df)\n", "\n", "print(data.shape, test_data.shape)\n", "data.head()"], "outputs": [], "cell_type": "code", "execution_count": 56}, {"metadata": {"_uuid": "021fbefa2dc2a356f93da09b73a31a577bf2f871", "collapsed": false, "_cell_guid": "2c1a0b6b-6ea3-411e-a2f2-5a966d1df6e7"}, "source": ["# Create train and test sets. In this case we'll set the test size to 0 as we want to use all the data for training\n", "ss = ShuffleSplit(n_splits=1, test_size=0.0)\n", "target_fields = ['y']\n", "features, targets = data.drop(target_fields, axis=1), data[target_fields]\n", "for train_index, test_index in ss.split(features, targets):\n", "    train_x, test_x = features.values[train_index], features.values[test_index]\n", "    train_y, test_y = targets.values[train_index], targets.values[test_index]"], "outputs": [], "cell_type": "code", "execution_count": 57}, {"metadata": {"_uuid": "c4c0c915a1eda7740f3d62af851f435c4d5c5e5a", "collapsed": false, "_cell_guid": "fb27f08c-e51e-4943-a6f1-faa3e7872f0d"}, "source": ["print(\"Train shapes (x, y):\", train_x.shape, train_y.shape)\n", "print(\"Test shapes (x, y):\", test_x.shape, test_y.shape)"], "outputs": [], "cell_type": "code", "execution_count": 58}, {"metadata": {"_uuid": "4518e174d6d110072916407635d16da8d38cb25c", "collapsed": true, "_cell_guid": "949569dc-1afc-4240-8c87-e22977ab69a8"}, "source": ["# Define the neural network\n", "def build_model():\n", "    # This resets all parameters and variables, leave this here\n", "    tf.reset_default_graph()\n", "    \n", "    # Inputs\n", "    net = tflearn.input_data([None, train_x.shape[1]])\n", "\n", "    # Hidden layer(s)\n", "    net = tflearn.fully_connected(net, 100, activation='ReLU')\n", "    net = tflearn.fully_connected(net, 100, activation='ReLU')\n", "    net = tflearn.fully_connected(net, 100, activation='ReLU')\n", "    \n", "    # Output layer and training model\n", "    net = tflearn.fully_connected(net, 1, activation='linear')\n", "    \n", "    # The regression layer is used in TFLearn to apply a regression (linear or logistic) to the provided input. \n", "    # It requires to specify a TensorFlow gradient descent optimizer 'optimizer' that will minimize the provided \n", "    # loss function 'loss' (which calculate the errors). A metric can also be provided, to evaluate the model performance.\n", "    net = tflearn.regression(net, optimizer='adam', learning_rate=0.001, loss='mean_square', metric='R2')\n", "    \n", "    model = tflearn.DNN(net, tensorboard_verbose=3)\n", "    return model"], "outputs": [], "cell_type": "code", "execution_count": 59}, {"metadata": {"_uuid": "3747fcb66b679071f9b04f24beff8fae814d8f1c", "collapsed": true, "_cell_guid": "05964d59-1bd1-4c8c-9cae-360dc2e9ea10"}, "source": ["model = build_model()"], "outputs": [], "cell_type": "code", "execution_count": 60}, {"metadata": {"_uuid": "8ac6c27ec24594ffcc42e34027bf19e3d1c9b76c", "collapsed": false, "_cell_guid": "486ed41c-5f83-4614-98b9-6ad23ad1e660"}, "source": ["# Training\n", "model.fit(train_x, train_y, validation_set=0.1, show_metric=True, batch_size=None, n_epoch=100)"], "outputs": [], "cell_type": "code", "execution_count": 61}, {"metadata": {"_uuid": "f194ed90a8d259c4ae643fbf42ea143aeb8d04bf", "collapsed": false, "_cell_guid": "8ba38052-b375-4aae-98fd-9c8a834ec576"}, "source": ["# There are differences between the trainging and test sets provided\n", "dlist = data.columns.tolist()\n", "tlist = test_data.columns.tolist()\n", "# This tells us which features are in training and not in test\n", "buffer_list_one = list(set(dlist)-set(tlist))\n", "# Add these to test with 0 value\n", "buffer_list_one.remove('y')\n", "for each in buffer_list_one:\n", "    test_data[each] = 0"], "outputs": [], "cell_type": "code", "execution_count": 62}, {"metadata": {"_uuid": "eb31246a0605272ead66b74db94eb9be12fe1b83", "collapsed": false, "_cell_guid": "698e5a63-5ee9-4968-9d1f-b1df717077e8"}, "source": ["# This tells us which features are in test and not in training\n", "buffer_list_two = list(set(tlist)-set(dlist))\n", "# drop these columns from the test data set\n", "test_data.drop(buffer_list_two, axis=1, inplace=True)"], "outputs": [], "cell_type": "code", "execution_count": 63}, {"metadata": {"_uuid": "9b6b950cf02166b58df0eff9b09c8cebb67ceb89", "collapsed": false, "_cell_guid": "d36c7a07-9063-44b9-a9d1-0c3113dd67de"}, "source": ["test_data.shape"], "outputs": [], "cell_type": "code", "execution_count": 64}, {"metadata": {"_uuid": "34ffd3cbe75156cb85ff0a46b721354375f782ee", "collapsed": true, "_cell_guid": "2c20e0e5-7b4f-49b3-9aa9-e53930c65a20"}, "source": ["mean, std = scaled_features['y']\n", "predictions = np.array(model.predict(test_data))*std + mean"], "outputs": [], "cell_type": "code", "execution_count": 65}, {"metadata": {"_uuid": "a0fc18b04b03b7c31d8b5c36e0084cfb783361fb", "collapsed": false, "_cell_guid": "9ec7c622-37f1-437a-86c5-3d701b514e27"}, "source": ["predictions"], "outputs": [], "cell_type": "code", "execution_count": 66}, {"metadata": {"_uuid": "3143605e6e72a052037280536ecb26c790d90508", "collapsed": true, "_cell_guid": "f1dc3347-02f3-4dab-81c9-760fc67099f2"}, "source": "submission_data = pd.read_csv('../input/test.csv')\nsubmission_data['y'] = np.absolute(predictions)\nsubmission_data.to_csv('submission.csv',columns=['ID','y'],header=['ID','y'],index=False)", "outputs": [], "cell_type": "code", "execution_count": 67}, {"metadata": {"_uuid": "cacbe5375f4c50aecb5f44014b5db94f7d237626", "collapsed": true, "_cell_guid": "db34efca-6c01-441c-9604-577edfe70b74"}, "source": [], "outputs": [], "cell_type": "code", "execution_count": null}]}