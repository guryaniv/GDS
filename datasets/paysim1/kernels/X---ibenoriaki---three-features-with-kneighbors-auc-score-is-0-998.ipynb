{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "931a1cf1-4e0f-d870-728f-d3d256ff77c3"
      },
      "source": [
        "Three Features with KNeighbors: AUC score is 0.998"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1cb2f2f-3547-466e-0c60-fc09b46b1b2d"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4d6d0ea5-6a7c-06cb-885b-0b89ebdd2143"
      },
      "outputs": [],
      "source": [
        "# Checking data\n",
        "df = pd.read_csv('../input/PS_20174392719_1491204439457_log.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "df00bb92-de60-e07e-2fdb-855513ddb9c6"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "F = df['type']\n",
        "print('Total {}'.format(Counter(F)))\n",
        "F = df[df['type'] == 'PAYMENT']['isFraud']\n",
        "print('PAYMENT {}'.format(Counter(F)))\n",
        "F = df[df['type'] == 'TRANSFER']['isFraud']\n",
        "print('TRANSFER {}'.format(Counter(F)))\n",
        "F = df[df['type'] == 'CASH_OUT']['isFraud']\n",
        "print('CASH_OUT {}'.format(Counter(F)))\n",
        "F = df[df['type'] == 'DEBIT']['isFraud']\n",
        "print('DEBIT {}'.format(Counter(F)))\n",
        "F = df[df['type'] == 'CASH_IN']['isFraud']\n",
        "print('CASH_IN {}'.format(Counter(F)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5195e0cf-180f-df3b-5b10-0e175f2c3806"
      },
      "outputs": [],
      "source": [
        "# Benchmark and Evaluation\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from numpy.random import *\n",
        "y_true = df['isFraud']\n",
        "y_scoresR =np.random.randint(0, 2, df.shape[0])\n",
        "y_scores1 = np.ones(df.shape[0])\n",
        "y_scores0 = np.zeros(df.shape[0])\n",
        "\n",
        "print(('Random prediction        : Accuracy {}'.format(accuracy_score(y_true, y_scoresR))), ('AUC Score {}'.format(roc_auc_score(y_true, y_scoresR))))\n",
        "print(('Predict all as Fraud     : Accuracy {}'.format(accuracy_score(y_true, y_scores1))), ('AUC Score {}'.format(roc_auc_score(y_true, y_scores1))))\n",
        "print(('Predict all as Not Fraud : Accuracy {}'.format(accuracy_score(y_true, y_scores0))), ('AUC Score {}'.format(roc_auc_score(y_true, y_scores0))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "188a3f13-c16c-cfa3-894d-fb1782c06dcb"
      },
      "outputs": [],
      "source": [
        "df_TRANSFER = df[df['type'] ==  'TRANSFER']\n",
        "\n",
        "X_TRANSFER = np.array(pd.DataFrame(df_TRANSFER, columns=['amount','oldbalanceOrg', 'oldbalanceDest']))\n",
        "y_TRANSFER = df_TRANSFER['isFraud']\n",
        "y_TRANSFER = np.array(y_TRANSFER.reshape(len(y_TRANSFER), ))\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_TRANSFER = StandardScaler()\n",
        "sc_TRANSFER.fit(X_TRANSFER)\n",
        "X_TRANSFER_sc = sc_TRANSFER.transform(X_TRANSFER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eea405fe-c7d8-a748-1484-202f098bd8d6"
      },
      "outputs": [],
      "source": [
        "# data processing for imbalanced data\n",
        "from imblearn.over_sampling import SMOTE \n",
        "\n",
        "print('Original dataset shape {}'.format(Counter(y_TRANSFER)))\n",
        "sm = SMOTE(random_state=42)\n",
        "X_TRANSFER_sm, y__TRANSFER_sm = sm.fit_sample(X_TRANSFER_sc, y_TRANSFER)\n",
        "print('Resampled dataset shape {}'.format(Counter(y__TRANSFER_sm)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1b929139-d5f8-674d-564d-3d477ecd0956"
      },
      "outputs": [],
      "source": [
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_TRANSFER_sm, y__TRANSFER_sm, test_size=0.7, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4a2a508b-7955-b2ad-3237-4f4bcad8e4e5"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "scores = ['roc_auc']\n",
        "# scores = ['roc_auc', 'accuracy'] < please use if you want to run with 'accuracy' basis too.\n",
        "k = np.arange(10)+40\n",
        "tuned_parameters1 = {'n_neighbors': k}\n",
        "knn = sklearn.neighbors.KNeighborsClassifier()\n",
        "for score in scores:\n",
        "    print('\\n' + '='*50)\n",
        "    print(score)\n",
        "    print('='*50)\n",
        "\n",
        "    clf1 = GridSearchCV(knn, tuned_parameters1, cv=5, scoring=score, n_jobs=-1)\n",
        "    clf1.fit(X_train, y_train)\n",
        "\n",
        "    print (\"\\n+ best parameters :\\n\")\n",
        "    print (clf1.best_estimator_)\n",
        "\n",
        "    print(\"\\n+ Average score with Training data :\\n\")\n",
        "    for params, mean_score, all_scores in clf1.grid_scores_:\n",
        "        print (\"{:.3f} (+/- {:.3f}) for {}\".format(mean_score, all_scores.std() / 2, params))\n",
        "\n",
        "    print(\"\\n+ Reference:\\n\")\n",
        "    y_true1, y_pred1 = y_test, clf1.predict(X_test)\n",
        "    print(classification_report(y_true1, y_pred1))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "75c4a95b-b2f9-20c8-2ede-76c302ce9ece"
      },
      "outputs": [],
      "source": [
        "df_CASH_OUT = df[df['type'] ==  'CASH_OUT']\n",
        "\n",
        "X_CASH_OUT = np.array(pd.DataFrame(df_CASH_OUT, columns=['amount','oldbalanceOrg', 'oldbalanceDest']))\n",
        "y_CASH_OUT = df_CASH_OUT['isFraud']\n",
        "y_CASH_OUT = np.array(y_CASH_OUT.reshape(len(y_CASH_OUT), ))\n",
        "\n",
        "sc_CASH_OUT = StandardScaler()\n",
        "sc_CASH_OUT.fit(X_CASH_OUT)\n",
        "X_CASH_OUT_sc = sc_CASH_OUT.transform(X_CASH_OUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e5e717f3-5d6e-6d64-9796-1ca310fe04db"
      },
      "outputs": [],
      "source": [
        "# data processing for imbalanced data\n",
        "print('Original dataset shape {}'.format(Counter(y_CASH_OUT)))\n",
        "sm = SMOTE(random_state=41)\n",
        "X_CASH_OUT_sm, y__CASH_OUT_sm = sm.fit_sample(X_CASH_OUT_sc, y_CASH_OUT)\n",
        "print('Resampled dataset shape {}'.format(Counter(y__CASH_OUT_sm)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ad99d352-7746-d7a0-4ff0-41f0fdc6b3e3"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_CASH_OUT_sm, y__CASH_OUT_sm, test_size=0.85, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0229f69d-0d7a-bbb2-45dc-74293b72a9c9"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "scores = ['roc_auc']\n",
        "# scores = ['roc_auc', 'accuracy'] < please use if you want to run with 'accuracy' basis too.\n",
        "k = np.arange(20)+40\n",
        "tuned_parameters1 = {'n_neighbors': k}\n",
        "knn = sklearn.neighbors.KNeighborsClassifier()\n",
        "for score in scores:\n",
        "    print('\\n' + '='*50)\n",
        "    print(score)\n",
        "    print('='*50)\n",
        "\n",
        "    clf2 = GridSearchCV(knn, tuned_parameters1, cv=5, scoring=score, n_jobs=-1)\n",
        "    clf2.fit(X_train, y_train)\n",
        "\n",
        "    print (\"\\n+ best parameters :\\n\")\n",
        "    print (clf2.best_estimator_)\n",
        "\n",
        "    print(\"\\n+ Average score with Training data :\\n\")\n",
        "    for params, mean_score, all_scores in clf2.grid_scores_:\n",
        "        print (\"{:.3f} (+/- {:.3f}) for {}\".format(mean_score, all_scores.std() / 2, params))\n",
        "    \n",
        "    # commentout due to \"The kernel was killed for trying to exceed the memory limit of 8589934592;\"\n",
        "    # print(\"\\n+ Reference:\\n\")\n",
        "    # y_true2, y_pred2 = y_test, clf2.predict(X_test)\n",
        "    # print(classification_report(y_true2, y_pred2))\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}