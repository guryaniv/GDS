{"nbformat_minor": 1, "metadata": {"language_info": {"version": "3.6.1", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "nbconvert_exporter": "python", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "cells": [{"metadata": {"_uuid": "a2b7cb2e62a998c69be07fa46f3ad13abe5b57b6", "_cell_guid": "fa4d4816-f425-4035-aa66-44f3cab68541"}, "cell_type": "markdown", "source": ["This is version 2 where I used the GradientBoostingRegressor (gbr) with default parameters  and I added a few new features in addition to Day, Month and Season (from the previous version) such as the tax per square foot etc. I removed some of the features with large number of missing values and changed the dtypes to keep the properties frame under 0.7GB and the number of features at 64. On its own this gave LB 0.06445 but when combined (simply averaged) with some of the other public kernels that have similar score on their own the result was 0.06426 (top 5%).  Suprisingly both lgbm and xgb gave worse score with the extra features.  The rest of the notebook compares the feature importances between gbr  and lgbm and xgb and looks at the impact of each feature. The test set score seems to converge at about 30 features but keeping all 64 gave a better LB score.\n"]}, {"metadata": {"_uuid": "7c5670caa7a3faf992fcda8a7064d682eb90b3b7", "_cell_guid": "ac9bfcc6-529e-424e-afd5-4ac80e9c3850"}, "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.ensemble import  GradientBoostingRegressor\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.cluster import MiniBatchKMeans\n", "import lightgbm as lgb\n", "import xgboost as xgb\n", "import datetime as dt\n", "import gc\n", "\n", "print('loading files...')\n", "prop = pd.read_csv('../input/properties_2016.csv',low_memory=False)\n", "prop.rename(columns={'parcelid': 'ParcelId'}, inplace=True)   # make it the same as sample_submission\n", "train = pd.read_csv('../input/train_2016_v2.csv')\n", "train.rename(columns={'parcelid': 'ParcelId'},inplace=True)\n", "sample = pd.read_csv('../input/sample_submission.csv')\n", "print(train.shape, prop.shape, sample.shape)"], "cell_type": "code", "outputs": [], "execution_count": 1}, {"metadata": {"_uuid": "c348da19d950905ef4c02a2147be7e7221d6e48e", "_cell_guid": "a7d9a3a5-0024-4f63-9f78-a384cef8e0b2"}, "source": ["print('preprocessing, fillna, outliters, dtypes ...')\n", "\n", "prop['longitude']=prop['longitude'].fillna(prop['longitude'].median()) / 1e6   #  convert to float32 later\n", "prop['latitude'].fillna(prop['latitude'].median()) / 1e6\n", "prop['censustractandblock'].fillna(prop['censustractandblock'].median()) / 1e12\n", "train = train[train['logerror'] <  train['logerror'].quantile(0.9975)]  # exclude 0.5% of outliers\n", "train = train[train['logerror'] >  train['logerror'].quantile(0.0025)]\n", "\n", "print('qualitative ...')\n", "qualitative = [f for f in prop.columns if prop.dtypes[f] == object]\n", "prop[qualitative] = prop[qualitative].fillna('Missing')\n", "for c in qualitative:  prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values)).astype(int)\n", "\n", "print('smallval ...')\n", "smallval = [f for f in prop.columns if np.abs(prop[f].max())<100]\n", "prop[smallval] = prop[smallval].fillna('Missing')\n", "for c in smallval:  prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values)).astype(np.int8)\n", "\n", "print('other ...')\n", "other=['regionidcounty','fips','propertycountylandusecode','propertyzoningdesc','propertylandusetypeid']\n", "prop[other] = prop[other].fillna('Missing')\n", "for c in other:  prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values)).astype(int)\n", "\n", "randomyears=pd.Series(np.random.choice(prop['yearbuilt'].dropna().values,len(prop)))\n", "prop['yearbuilt']=prop['yearbuilt'].fillna(randomyears).astype(int)\n", "med_yr=prop['yearbuilt'].quantile(0.5)\n", "prop['New']=prop['yearbuilt'].apply(lambda x: 1 if x > med_yr else 0).astype(np.int8)  # adding a new feature\n", "\n", "randomyears=pd.Series(np.random.choice(prop['assessmentyear'].dropna().values,len(prop)))\n", "prop['assessmentyear']=prop['assessmentyear'].fillna(randomyears).astype(int)\n", "\n", "prop['unitcnt'] = prop['unitcnt'].fillna(1).astype(int)    \n", "    \n", "feat_to_drop=[ 'finishedsquarefeet50', 'finishedfloor1squarefeet', 'finishedsquarefeet15', 'finishedsquarefeet13']\n", "prop.drop(feat_to_drop,axis=1,inplace=True)   # drop because too many missing values\n", "prop['lotsizesquarefeet'].fillna(prop['lotsizesquarefeet'].quantile(0.001),inplace=True)\n", "prop['finishedsquarefeet12'].fillna(prop['finishedsquarefeet12'].quantile(0.001),inplace=True)\n", "prop['calculatedfinishedsquarefeet'].fillna(prop['finishedsquarefeet12'],inplace=True)\n", "prop['taxamount'].fillna(prop['taxamount'].quantile(0.001),inplace=True)\n", "prop['landtaxvaluedollarcnt'].fillna(prop['landtaxvaluedollarcnt'].quantile(0.001),inplace=True)\n", "prop.fillna(0,inplace=True)\n", "    \n", "print('quantitative ...')   \n", "quantitative = [f for f in prop.columns if prop.dtypes[f] == np.float64]\n", "prop[quantitative] = prop[quantitative].astype(np.float32) \n", "\n", "cfeatures = list(prop.select_dtypes(include = ['int64', 'int32', 'uint8', 'int8']).columns)\n", "for c in qualitative:  prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values))\n", "\n", "# some quantitative features have a limited number of values (eg ZIP code)    \n", "for c in ['rawcensustractandblock',  'regionidcity',  'regionidneighborhood',  'regionidzip',  'censustractandblock'] :\n", "    prop[c] = LabelEncoder().fit(list(prop[c].values)).transform(list(prop[c].values))\n", "\n", "# other quantitative features were probably transformed when Zillow first calculate prices because of the skew\n", "for c in ['calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'lotsizesquarefeet', \n", "    'structuretaxvaluedollarcnt',  'taxvaluedollarcnt',  'landtaxvaluedollarcnt',  'taxamount'] :\n", "    prop[c] = np.log1p(prop[c].values)\n", "    \n", "gc.collect()"], "cell_type": "code", "outputs": [], "execution_count": 2}, {"metadata": {"_uuid": "2d262aef018faedcb7af3387a63d60849085222f", "_cell_guid": "3c64ec3b-1021-4399-b3a7-5930c47dd06f"}, "source": ["print('create new features and the final dataframes frames ...')\n", "\n", "#replace latitudes and longitudes with 500 clusters  (similar to ZIP codes)\n", "coords = np.vstack(prop[['latitude', 'longitude']].values)\n", "sample_ind = np.random.permutation(len(coords))[:1000000]\n", "kmeans = MiniBatchKMeans(n_clusters=500, batch_size=100000).fit(coords[sample_ind])\n", "prop['Cluster'] = kmeans.predict(prop[['latitude', 'longitude']])\n", "\n", "prop['Living_area_prop'] = prop['calculatedfinishedsquarefeet'] / prop['lotsizesquarefeet']\n", "prop['Value_ratio'] = prop['taxvaluedollarcnt'] / prop['taxamount']\n", "prop['Value_prop'] = prop['structuretaxvaluedollarcnt'] / prop['landtaxvaluedollarcnt']\n", "prop['Taxpersqrtfoot']=prop['finishedsquarefeet12']/prop['taxamount']\n", "\n", "train['transactiondate'] = pd.to_datetime(train.transactiondate)\n", "train['Month'] = train['transactiondate'].dt.month.astype(np.int8)\n", "train['Day'] = train['transactiondate'].dt.day.astype(np.int8)\n", "train['Season'] = train['Month'].apply(lambda x: 1 if x in [1,2,9,10,11,12] else 0).astype(np.int8)\n", "\n", "month_err=(train.groupby('Month').aggregate({'logerror': lambda x: np.mean(x)})- train['logerror'].mean()).values\n", "train['Meanerror']=train['Month'].apply(lambda x: month_err[x-1]).astype(np.float)\n", "\n", "train['abserror']=train['logerror'].abs()\n", "month_abs_err=(train.groupby('Month').aggregate({'abserror': lambda x: np.mean(x)})- train['abserror'].mean()).values\n", "train['Meanabserror']=train['Month'].apply(lambda x: month_abs_err[x-1]).astype(np.float)\n", "train.drop(['abserror'], axis=1,inplace=True)\n", "\n", "X = train.merge(prop, how='left', on='ParcelId')\n", "y = X['logerror']\n", "X.drop(['ParcelId', 'logerror', 'transactiondate'], axis=1,inplace=True)\n", "features=list(X.columns)\n", "\n", "print(X.shape, y.shape)\n", "gc.collect()"], "cell_type": "code", "outputs": [], "execution_count": 3}, {"metadata": {"_uuid": "eba33b0faa3bfa65f6d0516e92e6614434d601c5", "_cell_guid": "81268377-8fc4-4f4e-a417-922c55d98086"}, "source": ["print(' Training GB ...')\n", "X_train=X\n", "y_train=y\n", "n_estimators=800\n", "clf = GradientBoostingRegressor(loss='lad',   n_estimators=n_estimators,  verbose=1)\n", "clf.fit(X_train, y_train)\n", "print('MAE train  {:.4f}'.format(np.mean(np.abs(y_train-clf.predict(X_train)) )))\n", "gc.collect()\n", "\n", "submit=False     # change to create the submission file\n", "features=X_train.columns\n", "if submit:\n", "    print('predict and submit ...')\n", "    X_test = (sample.merge(prop, on='ParcelId', how='left')).loc[:,features]\n", "    \n", "    if 'Season' in features: X_test['Season']=np.int8(1)\n", "    if 'Day' in features: X_test['Day']=np.int8(15)\n", "\n", "    for month in [10, 11, 12]:\n", "        print('month ',month)\n", "        if 'Month' in features: X_test['Month']=np.int8(month) \n", "        if 'Meanerror' in features: X_test['Meanerror']=np.float(month_err[month-1])\n", "        if 'Meanabserror' in features: X_test['Meanabserror']=np.float(month_abs_err[month-1])\n", "        sample['2016' + str(month)] = clf.predict(X_test)\n", "        print(' MAE {}  {:.4f}'.format(month,np.mean(np.abs(sample['2016' + str(month)]-0) )))\n", "\n", "    sample.to_csv('submission_GBR6445.csv', index = False, float_format = '%.5f')\n", "\n", "FeatImp=pd.DataFrame(clf.feature_importances_, index=X_train.columns, columns=['Importance'])\n", "FeatImp=FeatImp.sort_values('Importance')\n", "FeatImp.plot(kind='barh', figsize=(8,14))\n", "plt.show()\n"], "cell_type": "code", "outputs": [], "execution_count": 4}, {"metadata": {"_uuid": "7586979b49d350f9276bc9ca28243c0c6af056f6", "_cell_guid": "2ef18d6f-e354-4d5a-9f79-cc08407187d4"}, "source": ["# Plot training deviance - 600 iteration seems enough\n", "plt.plot(np.arange(n_estimators)+1, clf.train_score_)\n", "plt.xlabel('Boosting Iterations')\n", "plt.ylabel('Deviance')\n", "plt.show()"], "cell_type": "code", "outputs": [], "execution_count": 8}, {"metadata": {"_uuid": "4bcd0282e646b64f104f649fcd996364c34b6778", "_cell_guid": "45119564-5430-4fe0-a9b7-8b38ce5c6c0e"}, "source": ["# starting with 10 most important features I gradually add more features to see their impact\n", "# there are 64 features but after the first 30 the gain is quite small\n", "print('feature impact ...')\n", "\n", "X_train, X_eval, y_train, y_eval = train_test_split(X,y, test_size=0.5, random_state=1)\n", "clf = GradientBoostingRegressor(loss='lad',   n_estimators=600,  verbose=0)\n", "clf.fit(X_train, y_train)\n", "FeatImp=pd.DataFrame(clf.feature_importances_, index=X_train.columns, columns=['Importance'])\n", "FeatImp=FeatImp.sort_values('Importance', ascending = False)\n", "print( FeatImp.iloc[0:10].index.values )\n", "Errors_train = []\n", "Errors_eval = []\n", "\n", "istart=10\n", "iend=len(FeatImp)+1\n", "iend = 30  # remove if time is no constraint and let run to the end (ie 64)\n", "for i in range(istart,iend):\n", "    X_train_temp = X_train[FeatImp.iloc[0:i].index.values]\n", "    X_eval_temp = X_eval[FeatImp.iloc[0:i].index.values]\n", "    clf.fit(X_train_temp, y_train)\n", "    Err_eval = np.mean(np.abs(y_eval-clf.predict(X_eval_temp) ) )\n", "    Err_train=np.mean(np.abs(y_train-clf.predict(X_train_temp) ) )\n", "    print('{:<30} train {:.3f} eval {:.3f} '.format(FeatImp.index[i-1],1000*Err_train, 1000*Err_eval))\n", "    Errors_train = Errors_train+[Err_train]\n", "    Errors_eval = Errors_eval+[Err_eval]\n", "\n", "plt.figure(figsize=(20,10))\n", "plt.plot(range(istart,iend),Errors_train,label='train')\n", "plt.plot(range(istart,iend),Errors_eval,label='eval')\n", "plt.xticks(range(istart,iend), features[10:],rotation=90)\n", "plt.ylabel('Errors')\n", "plt.legend()\n", "plt.show()   "], "cell_type": "code", "outputs": [], "execution_count": 10}, {"metadata": {"_uuid": "64f087bcfabc6af44472ee3780ab575054fccc47", "_cell_guid": "811a632c-ef64-4c60-9ca6-f1e52c35175a"}, "source": ["print('Training lgbm ...')\n", "features=list(X.columns)\n", "cfeatures = list(X.select_dtypes(include = ['int64', 'int32', 'uint8', 'int8']).columns)\n", "\n", "params = {'metric': 'mae', 'learning_rate' : 0.005, 'max_depth':10, 'max_bin':10,\n", "         'feature_fraction': 0.95,'bagging_fraction':0.95,'bagging_freq':10,'min_data': 500}\n", "\n", "# using eval or not (set CV to True or False)\n", "CV=False\n", "if CV:\n", "    \n", "    X_train, X_eval, y_train, y_eval = train_test_split(X,y, test_size=0.5, random_state=5)\n", "    lgb_train = lgb.Dataset(X_train.values, y_train.values)\n", "    lgb_eval = lgb.Dataset(X_eval.values, y_eval.values, reference = lgb_train)\n", "    lgb_model = lgb.train(params, lgb_train, num_boost_round = 3000, valid_sets = lgb_eval, \n", "             feature_name=features, early_stopping_rounds=100, verbose_eval = 100)\n", "    pred1 = lgb_model.predict(X_train.values, num_iteration = lgb_model.best_iteration)\n", "    pred2 = lgb_model.predict(X_eval.values, num_iteration = lgb_model.best_iteration)\n", "    print(' MAE train  {:.4f}'.format(np.mean(np.abs(y_train.values-pred1) )))\n", "    print(' MAE eval   {:.4f}'.format(np.mean(np.abs(y_eval.values-pred2) )))\n", "    del lgb_train,pred1,lgb_eval, pred2\n", "    \n", "else:\n", "\n", "    X_train=X\n", "    y_train=y\n", "    lgb_train = lgb.Dataset(X_train.values, y_train.values)\n", "    lgb_model = lgb.train(params, lgb_train, num_boost_round = 3000, feature_name=features)\n", "    pred1 = lgb_model.predict(X_train.values, num_iteration = lgb_model.best_iteration)\n", "    print(' MAE train  {:.4f}'.format(np.mean(np.abs(y_train.values-pred1) )))\n", "    del lgb_train, pred1\n", "    \n", "    \n", "lgb_model.save_model('model.txt')\n", "#bst = lgb.Booster(model_file='model.txt')    \n", "gc.collect()"], "cell_type": "code", "outputs": [], "execution_count": 15}, {"metadata": {"_uuid": "18a7859408be0cfbf6602eb920b1e33adf472bb9", "_cell_guid": "8e2cca88-a916-4b2d-adc9-12578616ff46"}, "source": ["#check feature importance\n", "lgb.plot_importance(lgb_model,  figsize=(10,20))\n", "plt.show()\n", "gc.collect()"], "cell_type": "code", "outputs": [], "execution_count": 32}, {"metadata": {"_uuid": "194bb5846bae18c98f4b4f28f42cd6c1aa2c04b0", "_cell_guid": "56d88ee9-7d60-4335-90b6-8c1df31e7442"}, "source": ["# I do not know if there is a more pythonic way to get the lgbm feature importances but the best I \n", "# could do is by parsing the model file\n", "ind=[]\n", "data=[]\n", "with open('model.txt') as f: FI = list(f)[-100:-2]\n", "FI=FI[FI.index('feature importances:\\n') +1:]    \n", "for i in range(len(FI)): \n", "    FI[i]=FI[i][:-1]\n", "    ind=ind+[FI[i].split('=')[0]]\n", "    data=data+[int(FI[i].split('=')[1])]\n", "FeatImp=pd.DataFrame(data, index=ind, columns=['Importance'])\n", "del f,ind,data\n", "FeatImp.head()"], "cell_type": "code", "outputs": [], "execution_count": 17}, {"metadata": {"_uuid": "aad019cfee7c3bd65da4e995cc9c2348198cdd2a", "_cell_guid": "43d2d029-7bf7-4324-84f4-fc81d59c3ddf"}, "cell_type": "markdown", "source": ["Obviously the feature importances depend on the choice of the parameters but still the first attempt to compare gbr and lgbm leads to quite large differences and so it makes sense to combine the different methods. Finally, let us compare with xgb. "]}, {"metadata": {"_uuid": "414cc2037ba248b554233296cbc951e8cb3e6960", "_cell_guid": "aaf9fd2b-e0ad-45d4-9c10-c121eced7793"}, "source": ["print('training xgboost ...')\n", "X_train=X\n", "y_train=y\n", "y_mean = np.mean(y_train)\n", "xgb_params = {'eta': 0.037, 'max_depth': 5, 'subsample': 0.80,  'eval_metric': 'mae', \n", "              'lambda': 0.8,   'alpha': 0.4, 'base_score': y_mean, 'silent': 1 }\n", "dtrain = xgb.DMatrix(X_train, y_train)\n", "model = xgb.train(xgb_params, dtrain, num_boost_round=250)\n", "pred1 = model.predict(dtrain)\n", "print(' xgb MAE train  {:.4f}'.format(np.mean(np.abs(y_train.values-pred1) )))\n", "del dtrain, pred1\n", "gc.collect()"], "cell_type": "code", "outputs": [], "execution_count": 25}, {"metadata": {"_uuid": "ec70cc56e00cff55b6ec4a4493bac424cba5eb6c", "_cell_guid": "90157eff-6a9d-4f2f-a7b4-075dc997d908"}, "source": ["fig, ax = plt.subplots(figsize=(20, 20))\n", "xgb.plot_importance(model, ax=ax)\n", "plt.show()\n", "gc.collect()"], "cell_type": "code", "outputs": [], "execution_count": 29}, {"metadata": {"_uuid": "5a83ec74ae8fa22832f922fc4858aaab6e66a974", "_cell_guid": "4554da72-4a75-47ab-bc92-d88506dc56c9"}, "cell_type": "markdown", "source": ["Work in progress ...\n"]}, {"metadata": {"_uuid": "6891fc6a265e40ef161fd43d24b65d3fd6f6b6b7", "_cell_guid": "078f83d4-5247-429f-9a64-b2d80349d8d9"}, "cell_type": "markdown", "source": []}], "nbformat": 4}