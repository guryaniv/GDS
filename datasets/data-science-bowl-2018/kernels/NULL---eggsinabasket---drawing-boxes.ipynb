{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":false,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\nimport scipy.signal\nfrom astropy.visualization import MinMaxInterval\nimport itertools as it\n%matplotlib inline  \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\n\nprint(os.listdir(\"../input\"))\nTRAIN_PATH = '../input/stage1_train/'\nTEST_PATH = '../input/stage1_test/'\n\ntrain_ids = os.listdir(TRAIN_PATH)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false,"collapsed":true},"cell_type":"code","source":"# Loading \n\nimgs = []\nmasks = []\n\nfor i in train_ids:\n    img = cv2.cvtColor(cv2.imread((TRAIN_PATH + i + '/images/' + i +'.png'), -1), cv2.COLOR_BGR2RGB) #bgr \n    imgs.append(img) \n\n    \n## plotting all images    \nplt.figure(figsize=(25,50))    \n#for i in range(0,100):\n    #plt.subplot(20,5,i+1)\n    #plt.imshow(imgs[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a84cc4b230ab68e0a20a7af1fc721fd42faeec7e","_cell_guid":"bac97e7a-f339-462e-8e7c-1425597dcd52","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"## Combining masks\n\ndef imgMerge(imgPath):\n    #getting all the png files\n    png_files= [f for f in os.listdir(imgPath) if f.endswith('.png')]\n    \n    #loading in the first image as greyscale\n    img = cv2.imread(imgPath+'/'+png_files[0],0)\n    for i in png_files[1:]:\n        temp_img = cv2.imread(imgPath+'/'+i,0)\n        img=img+temp_img\n    \n    return img\n\n#merging all masks and storing inside an array\nfor i in range(0,len(imgs)):\n    path = TRAIN_PATH + train_ids[i] + '/masks/'\n    a = imgMerge(path)\n    masks.append(a)\n    \n## checking a few side by side\nplt.figure(figsize=(10, 10), dpi=100)\nplt.subplot(1,2,1)\nplt.imshow(masks[45])\nplt.axis('off')\nplt.subplot(1,2,2)\nplt.imshow(imgs[45])\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c155d049ccd76c363e8364243b493062604c5f7","collapsed":true,"_cell_guid":"ce3c322a-e976-4835-960f-70128cdde33c","trusted":false},"cell_type":"code","source":"## Copying image array to perform countouring\nj = [np.copy(f) for f in imgs ]\nmask_dup = [np.copy(f) for f in masks ]\nidx = 0  ## trying out sample index\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"910501fc44d3c9acbe1498a8a000de8866708b9a","_cell_guid":"fbf18442-4f94-44e2-a4bf-3ba20539e632","trusted":false,"collapsed":true},"cell_type":"code","source":"# Normalizing all images\nk = [np.copy(f) for f in imgs ]\n\nintensities = {}\nfor i in range(0,len(imgs)):\n    img_min = np.min(imgs[i])\n    img_max = np.max(imgs[i])\n    k[i] = np.round(((imgs[i] - img_min)/(img_max - img_min))*255)\n    k[i] = k[i].astype(np.uint8)\n    d = {'Min':img_min,'Max':img_max, 'ID':i}\n    intensities.update({i:d})\n    \nplt.imshow(k[idx])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aedf3aec9e4f3f440d2985d33cfba7c5745717f1","collapsed":true,"_cell_guid":"3f18bb6d-1972-4d22-9c74-0a7063078c48","trusted":false},"cell_type":"code","source":"## Trying auto canny\n\ndef auto_canny(image, sigma=0.33):\n    # compute the median of the single channel pixel intensities\n    v = np.median(image)\n \n    # apply automatic Canny edge detection using the computed median\n    lower = int(max(0, (1.0 - sigma) * v))\n    upper = int(min(255, (1.0 + sigma) * v))\n    edged = cv2.Canny(image, lower, upper)\n \n    # return the edged image\n    return edged\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a589968c13b04ee2cd3e97ed12cc1839a1e50cb4","_cell_guid":"da97c475-ec93-4429-873f-1fe9a8459c81","trusted":false,"collapsed":true},"cell_type":"code","source":"# apply Canny edge detection using a wide threshold, tight\n# threshold, and automatically determined threshold\ngray = cv2.cvtColor(j[0], cv2.COLOR_RGB2GRAY)\nblurred = cv2.GaussianBlur(gray, (3, 3), 0)\n\n\nwide = cv2.Canny(blurred, 10, 200)\ntight = cv2.Canny(blurred, 225, 250)\nauto = auto_canny(blurred)\n \n# show the images\nplt.imshow(imgs[0])\nplt.imshow(wide)\nplt.imshow(tight)\nplt.imshow(auto)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b558eae048ab8168d23be8657e4ec7d4abede0b","collapsed":true,"_cell_guid":"47664b4a-7450-411a-a5df-1d0cced2eaa1","trusted":false},"cell_type":"code","source":"## setting manual index\nidx = 0\n\nplt.imshow(imgs[idx])\n## runing canny edge detector\nthresh = cv2.Canny(cv2.cvtColor(k[idx],cv2.COLOR_RGB2GRAY) ,75,75)\n## runing canny edge detector\nim2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n# drawing contours\n#plt.imshow(cv2.drawContours(j[100], contours, -1, (0,255,0), 2)   )\n\n# with each contour, draw boundingRect in green\n# a minAreaRect in red and\n# a minEnclosingCircle in blue\nfor c in contours:\n    # get the bounding rect\n    x, y, w, h = cv2.boundingRect(c)\n    # draw a green rectangle to visualize the bounding rect\n    cv2.rectangle(j[idx], (x, y), (x+w, y+h), (0, 255, 0), 2)\n \n    # get the min area rect\n    rect = cv2.minAreaRect(c)\n    box = cv2.boxPoints(rect)\n    # convert all coordinates floating point values to int\n    box = np.int0(box)\n   \nplt.imshow(j[idx]) \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7d696336ba3ccbf5e92e22605710327be18bdba","collapsed":true,"_cell_guid":"95edeaa8-630a-48bf-b4f7-c0fe29fa45e7","trusted":false},"cell_type":"code","source":"## creating edge convolutor to extract mask contours\n\ne_con = np.array([[0,-1,0],[-1,4,-1],[0,-1,0]])\n\nimg_con = cv2.filter2D(mask_dup[idx],-1, e_con)\nimg_con2 = scipy.signal.convolve(mask_dup[idx], e_con, mode = 'same')\n\nthresh1 = cv2.Canny(mask_dup[idx],50,55)\n## runing canny edge detector\nim2, contours, hierarchy = cv2.findContours(mask_dup[idx], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\nfor c in contours:\n    # get the bounding rect\n    x, y, w, h = cv2.boundingRect(c)\n    # draw a green rectangle to visualize the bounding rect\n    cv2.rectangle(mask_dup[idx], (x, y), (x+w, y+h), (0, 255, 0), 2)\n \n    # get the min area rect\n    rect = cv2.minAreaRect(c)\n    box = cv2.boxPoints(rect)\n    # convert all coordinates floating point values to int\n    box = np.int0(box)\n   \nplt.imshow(mask_dup[idx]) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8faae2c2991e5c365d711a4b4e67d2426007c002","collapsed":true,"_cell_guid":"f4da9312-2fb4-49d2-a875-4b8bc16c2b53","scrolled":false,"trusted":false},"cell_type":"code","source":"### Creating box files for all images\n\nboxes = {}\ncont = {}\nfor i in range(0,len(k)):\n    thresh = cv2.Canny(cv2.GaussianBlur(cv2.cvtColor(k[i],cv2.COLOR_RGB2GRAY), (3, 3), 0),75,250)\n    ## runing canny edge detector\n    im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    d = []\n    cont.update({i:contours})\n    for c in contours:\n        # get the bounding rect\n        x, y, w, h = cv2.boundingRect(c)\n        l1 = [x,y,w,h]\n        d.append(l1)\n        # draw a green rectangle to visualize the bounding rect\n        cv2.rectangle(j[i], (x, y), (x+w, y+h), (0, 255, 0), 2)\n        \n    boxes.update({i:d})\n\n    \n    \n## checking a few side by side\nplt.figure(figsize=(10, 10), dpi=100)\nplt.subplot(2,2,1)\nplt.imshow(k[idx]) \nplt.axis('off')\nplt.subplot(2,2,2)\nplt.imshow(j[idx]) \nplt.axis('off')\nplt.subplot(2,2,3)\nplt.imshow(masks[idx]) \nplt.axis('off')\nplt.subplot(2,2,4)\nplt.imshow(mask_dup[idx]) \nplt.axis('off')\nplt.tight_layout()\n   \n#plt.hist(masks[idx].ravel(),256,[0,256]); plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bc9333b6a561d5423276b7cdcb086e85f0dbeaf","_cell_guid":"2620a3da-70d5-402c-98a7-5ca0f5c29fd5"},"cell_type":"markdown","source":"Given that there are multiple boxes inside larger bounding boxes, the pixels need to be selected only once for use in the image classifier. All points within a bounding box needs to be captured and filtered from the original image. "},{"metadata":{"_uuid":"20fccc710d1f1e32521f119b17170e9aa836fa36","collapsed":true,"_cell_guid":"7af185f9-ed6e-4e9a-be73-216e16af6493","trusted":false},"cell_type":"code","source":"\n## finding all pixel addresses in a bounding box for 1 image\nidx = 0\n#key = 0\nbox_local = boxes.get(idx)\nx = box_local\n## get all pixel values for first object in x\nx[0]\nl = []\nfor ele in x:\n    for i in range(0,ele[2]+1):\n        for id in range(0,ele[3]+1):\n            a1 = (ele[0]+i,ele[1]+id)\n            if a1 in l:\n                continue\n            else:\n                l.append(a1)\n\n## check\n\nchk = []\nfor t in l:\n      x = t[1]\n      y = t[0]\n      chk.append(masks[0][x,y])\n   \n\n\np = [np.copy(f) for f in masks ]\n\nfor i in range(0,len(l)):\n        cv2.circle(p[0], (l[i][0], l[i][1]), 1, 255, 1)\n\nplt.hist(k[0].ravel(),256,[0,256])\n\nplt.subplot(1,2,1)\nplt.imshow(p[0])\n\nplt.subplot(1,2,2)\nplt.imshow(masks[0])\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4fc2e2274d7ed6133f7c028bc45f44460bfbc0b","collapsed":true,"_cell_guid":"dbf933ec-83b6-4b2b-92cc-5db5190a607d","trusted":false},"cell_type":"code","source":"## Finding bounding box pixel values for all images\n\nbb_pixels = {}\n\nfor counter in range(0,len(boxes)):\n    l = []\n    x = boxes[counter]\n    for ele in x:\n        for i in range(0,ele[2]+1):\n            for id in range(0,ele[3]+1):\n                a1 = (ele[0]+i,ele[1]+id)\n                if a1 in l:\n                    continue\n                else:\n                    l.append(a1)\n        \n    bb_pixels.update({counter:l})\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2cf55825c98f553dfd413f4cef103037051875c","collapsed":true,"_cell_guid":"89580f88-1a07-4dcb-9114-c8f8ed30505f","trusted":false},"cell_type":"code","source":"## Finding bounding box pixel values for all images\n\nbb_pixels = {}\n\nfor counter in range(0,len(boxes)):\n    p = []\n    x = boxes[counter]\n    for ele in x:\n        a1 = list(it.product(range(ele[0],ele[0]+ele[2]), range(ele[1],ele[1]+ele[3])))\n        p.append(a1)\n    p = list(it.chain.from_iterable(p))\n    p = list(set(p))    \n    bb_pixels.update({counter:p})\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84222b0d6fa8946691f479d9a84fa3263a1af0b3","collapsed":true,"_cell_guid":"9998e7bb-2165-4842-862a-37a9d2730e32","trusted":false},"cell_type":"code","source":"## Now that we have the pixel values , compare against the masks to see how much we have captured and plot a histogram of capture rate\nmask_pixels = {}\nfor key in bb_pixels.keys():\n    chk = []\n    x = bb_pixels[key]\n    for t in x:\n      x = t[1]\n      y = t[0]\n      chk.append(masks[key][x,y])\n    mask_pixels.update({key:chk})\n    \nacc = []\nfor i in range(0,len(masks)):\n        acc.append(np.sum(mask_pixels[i])/np.sum(masks[i]))\n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"239a2e90f23d92e0863da6c9be691183689d39ad","collapsed":true,"_cell_guid":"90aa087d-76a4-46c4-a4c0-737d5e8fdc1d","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.4","pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py","name":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}