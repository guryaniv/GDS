{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5bc3af10f7c9efa808c8ec0ec44b605d97d5128"},"cell_type":"markdown","source":"## Import Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np \nimport pandas as pd \n\ntrain = pd.read_csv('../input/train.tsv',sep = '\\t')\ntest = pd.read_csv('../input/test.tsv', sep = '\\t')\nprint(\"Train set: {0}\".format(train.shape))\nprint(\"Test set: {0}\".format(test.shape))\n\ndf = pd.concat([train, test])\nprint(\"All df set: {0}\".format(df.shape))\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c8d27c48b039456ae2c5ec898b202f0f2703acc"},"cell_type":"code","source":"sub = pd.read_csv('../input/sampleSubmission.csv', sep = ',')\nprint(\"Submission: {0}\".format(sub.shape))\n\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9332763b5b6a5c58bbe8578755f3ab21dd52db38"},"cell_type":"markdown","source":"Let's see the distribution of the each group"},{"metadata":{"trusted":true,"_uuid":"fcd458d59b1a615c4655458d69539c805c0e0655"},"cell_type":"code","source":"x = train.groupby(['Sentiment'])['PhraseId'].count()\nx.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07a35d8014c22ca96dafe70329d7ce0227549c05"},"cell_type":"code","source":"print(\"Training set distribution: \", train.groupby(['Sentiment']).size()/train.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e41bb107d7bbd5232037a27d944da07cb310c11b"},"cell_type":"markdown","source":"## Clean data"},{"metadata":{"trusted":true,"_uuid":"8b290b2cebc9ea3da4696875490a75022f252e15","collapsed":true},"cell_type":"code","source":"import re\nfrom nltk.stem import PorterStemmer\nstemmer = PorterStemmer()\n\nfrom nltk.stem import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4a4760a2056c9ec8784a3d430f2851b6d0c8959","collapsed":true},"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"[-()\\\"#/@;:<>{}+=~|.?,]\", \"\", text)\n    review_lemma=[]\n    for word in text.split():\n        word_lemma = wordnet_lemmatizer.lemmatize(word)\n        review_lemma.append(word_lemma)\n    review_lemma=' '.join(review_lemma)\n    return review_lemma","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38523abee3928202711095a83cb0fa93f4ed4026","collapsed":true},"cell_type":"code","source":"train['clean_phrase'] = train['Phrase'].apply(clean_text)\ntest['clean_phrase'] = test['Phrase'].apply(clean_text)\ndf['clean_phrase'] = df['Phrase'].apply(clean_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f315d7237fddc43b7c856e3ec3479851eb7049c"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eca2137da437d88cd0e926ed91e3bb706ccbfef0"},"cell_type":"markdown","source":"## Count Features"},{"metadata":{"trusted":true,"_uuid":"32bd7b8480a1b7382c16d8d57890ce778a4fc9fb"},"cell_type":"code","source":"from keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import word_tokenize\nfrom nltk import FreqDist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ecdb1034656281fd128956aab9bfc29bf8ba753"},"cell_type":"code","source":"train_text=train.clean_phrase.values\ntest_text=test.clean_phrase.values\ntarget=train.Sentiment.values\ny=to_categorical(target)\nprint(train_text.shape,target.shape,y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71dd92113c4ad41d7f94dbd3c166a8df638c4c0f"},"cell_type":"code","source":"X_train_text,X_val_text,y_train,y_val=train_test_split(train_text,y,test_size=0.2,stratify=y,random_state=123)\nprint(X_train_text.shape,y_train.shape)\nprint(X_val_text.shape,y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6049035d44f7c40508567df01b813e9ad444952b"},"cell_type":"code","source":"all_words = ' '.join(X_train_text)\nword2count = {}\nfor word in all_words.split():\n    if word not in word2count:\n        word2count[word] = 1\n    else:\n        word2count[word] += 1\nprint(\"Number of unique words: \", len(word2count.keys()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc42a1b6e1b2c0b49744c1e985a53ae862e4ffb3"},"cell_type":"code","source":"df['length_review'] = df['clean_phrase'].apply(lambda x: len(x.split()))\nprint(\"Max phrase length: \", max(df['length_review']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d665e4fc0e7176fbc0a5ba5311dd36a600da6320"},"cell_type":"markdown","source":"## Feature Engineering: tf-idf"},{"metadata":{"trusted":true,"_uuid":"9ea6f7666703c82aed8f995525607be9748fcbe5"},"cell_type":"code","source":"d = pd.DataFrame(list(word2count.items()), columns=['word', 'count'])\nd.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e89bab53b4c71339417242392258725686a9905f"},"cell_type":"code","source":"all_phrases = [X_train_text]\nall_phrases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06349eb59d3fcc581dbb98edb8cc4e0c334b48e5"},"cell_type":"code","source":"# from sklearn.feature_extraction.text import TfidfTransformer\n\n# sklearn_tfidf = TfidfTransformer()\n# sklearn_representation = sklearn_tfidf.fit_transform(all_phrases)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba9ab7c2798ec710890a4751b61d5b27fa762209"},"cell_type":"markdown","source":"## Tokenizer and Sequence padding"},{"metadata":{"trusted":true,"_uuid":"fc3ec4c5036fdd33373c39be7f1cec7b91c9da2b","collapsed":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5601923ab9492e39a82d8f3ad19e4b41cf133ba4","collapsed":true},"cell_type":"code","source":"MAX_REVIEW_LENGTH = 49\nFEATURE_LENGTH = 12011\nBATCH_SIZE = 1000\nEPOCHS = 100\nNUM_CLASSES = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37d83dbb1cb2e6ee4c7a2b3ebfd752aa4ff97d74","collapsed":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words = FEATURE_LENGTH)\ntokenizer.fit_on_texts(list(np.concatenate((train_text, test_text), axis=0)))\nX_train = tokenizer.texts_to_sequences(X_train_text)\nX_val = tokenizer.texts_to_sequences(X_val_text)\nX_test = tokenizer.texts_to_sequences(test_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4004d45dbb31c8fe4b2341d1eed5c477fee5e8a","collapsed":true},"cell_type":"code","source":"X_train = pad_sequences(X_train, maxlen=MAX_REVIEW_LENGTH)\nX_val = pad_sequences(X_val, maxlen=MAX_REVIEW_LENGTH)\nX_test= pad_sequences(X_test, maxlen=MAX_REVIEW_LENGTH)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33c71e90aad41816e32999f38a84d8afba604d92"},"cell_type":"markdown","source":"## Random Forest (baseline)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a1a678634f4d3a935986a459d506176e44ca9e6d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f958a89b9d93bd8165db7d89c592bf7baffe9470"},"cell_type":"markdown","source":"## LSTM Model"},{"metadata":{"trusted":true,"_uuid":"87ce8fc09f859a11374eca89cd66fadca3b2418c","collapsed":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Embedding,LSTM,Conv1D,GlobalMaxPooling1D\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90aa8f562065a3883846b0a09d363bc2144ee9f3"},"cell_type":"code","source":"model=Sequential()\nmodel.add(Embedding(FEATURE_LENGTH,250,mask_zero=True))\nmodel.add(LSTM(128,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\nmodel.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\nmodel.add(Dense(NUM_CLASSES,activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1103e573da750412fda5e5c7171579f771a452a2"},"cell_type":"code","source":"history = model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0da54cf2baafcb0da58eeccd19049844b9ff4459"},"cell_type":"code","source":"y_pred = model.predict_classes(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d500f2f0a68ff070c29b0693b7b444913e107b2f"},"cell_type":"code","source":"test[\"Sentiment\"] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"549e3d037557c400f346b55ff422a657ae7873e6"},"cell_type":"code","source":"test[['PhraseId', 'Sentiment']].to_csv('submission_lstm.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9d0d427c8c2bb8937bfe25d5183037956d00ef61"},"cell_type":"markdown","source":"## ANN"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0cec5794c3546c698a4100dfee564cad7e848297"},"cell_type":"code","source":"from keras.layers import Flatten","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1f9c4c31225704041d91782f6adf7346b0aca7d"},"cell_type":"code","source":"ann_model = Sequential()\nann_model.add(Embedding(FEATURE_LENGTH,250, input_length=MAX_REVIEW_LENGTH))\nann_model.add(Dense(output_dim = 100, init = 'uniform', activation = 'relu'))\nann_model.add(Flatten())\nann_model.add(Dense(output_dim = 50, activation='tanh'))\nann_model.add(Dense(output_dim = 10, activation = 'relu'))\nann_model.add(Dense(NUM_CLASSES,activation='softmax'))\nann_model.compile(optimizer=Adam(lr=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\nann_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92459ec0494a100f66e31a20f62fd17ed77ff6d9","scrolled":true},"cell_type":"code","source":"ann_history = ann_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size = BATCH_SIZE, epochs = EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bab4e515495ddfe43f2a40858bfb66e801c36297"},"cell_type":"code","source":"y_pred = ann_model.predict_classes(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c481b58ef1affb024995401d4aec85d32a3ab38","collapsed":true},"cell_type":"code","source":"test[\"Sentiment\"] = y_pred\ntest[['PhraseId', 'Sentiment']].to_csv('submission_ann.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"77d212103c96a46074c3c0dcfecf30bf68134ff9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}