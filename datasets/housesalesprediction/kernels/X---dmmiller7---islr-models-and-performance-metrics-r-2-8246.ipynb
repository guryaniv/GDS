{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"# King County, Washington home prices...\n\nThis kernel is the result of a class project where we were asked to apply a set of models covered in class to a dataset of our choosing. The class was loosely based on the Introduction to Statistical Learning with applications in R text found [here in hardcopy](https://amzn.to/2KgQJPY) or [here in soft copy form for free](https://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf). I wanted to reproduce some of those models in Python, because that's what I'm familiar with. I make no claim that these are the best models to use for this dataset--this is only meant as a demo.\n### Skip to the AdaBoost model if you want to see the best performing model. There is a chart at the end that shows the error in terms of actual sale price. I think this is the best measure of performance for a ML model in this context, because it allows you to see the error across the entire market. This model performs more predictably the more expensive a property is."},{"metadata":{"_uuid":"edc757faeec90243415fc3eddf7fdd6fda3b21fb"},"cell_type":"markdown","source":"# Table of Contents:\n## --------- [Data Wrangling](#Data-Wrangling:) -----------------\n## --------- Model Building: ------------------\n## 0. [A Baseline Model](#0.-Baseline-Model:)\n## 1. [Multiple Linear Regression](#1.-Multiple-Linear-Regression:)\n## 2. [Best Subset Regression](#2.-Best-Subset-Regression:)\n## 3. [Ridge Regression](#3.-Ridge-Regression:)\n## 4. [Lasso Regression](#4.-Lasso-Regression:)\n## 5. [SVM for Regression](#5.-Support-Vector-Machine-for-Regression:)\n## 6. [K Nearest Neighbors](#6.-K-Nearest-Neighbors:)\n## 7. [Classification and Regression Tree](#7.-CART:)\n## 8. [Random Forest](#8.-Random-Forest:)\n## 9. [AdaBoost](#9.-AdaBoost:)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a489e8a9838a3306148c73ce43a112426a2159e","scrolled":true,"collapsed":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/kc_house_data.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c85e15a31768d1823801ca43ba8f0624c55694ea","_kg_hide-output":false,"_kg_hide-input":false,"collapsed":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6925b31b6cb6ef4b7b84f6ff3981a559402029e9","collapsed":true},"cell_type":"code","source":"## Look at useful stats for each variable:\nprint('There are',len(df.columns.tolist()),'columns, including the response variable \"price\".')\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"357a99af8f2cabbd9c474c0e68dfc942db68d8fe"},"cell_type":"markdown","source":"# Data Wrangling:\n### Before we begin building models with these data, we should do several things to make the data more meaningful:\n\n1. Convert **'date'** to python datetime objects.\n1. Check for empty (NaN) values\n2. Figure out which predictors should be categorical, and transform them to that data type (so Pandas will play nicer with them)\n3. Transform the dependent variable, **`price`**, to a log scale, as is common with widely varying financial data (e.g. **`hitters`** from ISLR) \n4. Transform **`yr_built`** to a more apt **`yrs_old`** (at sale)\n5. Plot the values of all variables against **`logPrice`** to see what anomalies we may have\n6. Remove remaining meaningless or superfluous data (such as **`id`**)\n\n### 1. Convert date column to datetime64 dtype:"},{"metadata":{"trusted":true,"_uuid":"35ae9a9e236863133d9f7b7f438191a721dea81d","collapsed":true},"cell_type":"code","source":"df['date'] = df['date'].astype('datetime64') #pd.to_datetime(df['date'])\ndf['date'].describe()\n# The desrcibe method still tells me that the dtype is \"object\", but if you index to a specific value such as (type(df.loc[0,'date'])), it says \"pandas._libs.tslibs.timestamps.Timestamp\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19561a580bef1f9a44b4416aa32e39194d67baed"},"cell_type":"markdown","source":"### 2. Check for empty (NaN) values (there are none!)"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"77c8ddfb62c7fc7a0ae02ba8215e485c243740a1","collapsed":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb6967bfb997db750b6e45581c31f3782ffec18f"},"cell_type":"markdown","source":"### 3. Figure out which predictors should be categorical\nNotice when we called `df.info()` above, all of the columns are read in from the csv as either `int64`, `float64`, or `object`.  Pandas has more datatypes that may be of use to us, particularly the categorical data type: http://pbpython.com/pandas_dtypes.html"},{"metadata":{"trusted":true,"_uuid":"512b257b60e78bb4b35a7f2177e0a5dc45114440","collapsed":true},"cell_type":"code","source":"# Which are categorical? Let's check all non-float values, screening for features with fewer than 50 unique values\n## (50 is arbitrary, but I checked several other values, like 500, to make sure this result is reasonable)\npredNames = ['waterfront','bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',  'view', 'condition', 'grade',\n            'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'sqft_living15','sqft_lot15']\n\nuniqueValsList = []\nseriesNames = [] # Keep only the columns that have fewer than 50 unique values.\nfor each in predNames:\n    if str(df[each].dtype) == \"int64\":\n        uniqueVals = list(df[each].unique())\n        if len(uniqueVals) < 50:\n            uniqueValsList.append(pd.Series(data=uniqueVals,name=each))\n            seriesNames.append(each)\n\nlistOfLists = []\nfor i in range(len(uniqueValsList)):\n    thisList = []\n    thisList.append(seriesNames[i])\n    for each in uniqueValsList[i].tolist():\n        thisList.append(each)\n    listOfLists.append(thisList)\n\nfrom IPython.display import HTML, display\nimport tabulate\ndisplay(HTML(tabulate.tabulate(listOfLists, tablefmt='html')))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"334657378b60918a3d9fdf06579f692deb6af2c3"},"cell_type":"markdown","source":"### Based on this, it looks like `bedrooms`, `waterfront`, `view`, `condition`, and `grade` are the only candidates for categorical variables. Addressing each of them on their own:\n\n- **`bedrooms`**: this should be kept as an integer, since order matters, and simple math applies\n- **`waterfront`**: this is basically binary; it either is on the water or it isn't. I will translate this to a categorical variable\n- **`view`**: this appears to contain more than binary information, maybe based on how many sides of the property have a view? There is no useful detail in the data documentation. I'll map this to a binary categorical variable--either it has a view or it doesn't.\n- **`condition`**: Appears to be a 1-5 scale, so order matters. We will leave it as an `int`\n- **`grade`**: There doesn't seem to be an obvious range to the scale here. Plotting will help.\n\nThe last two in particular warrant further examination. Should we not include both condition and grade, as they seem to contain similar information? I'll take the low hanging fruit first (converting **`waterfront`** and **`view`** to categorical variables), and then do some basic plotting to look more closely at **`condition`** and **`grade`**."},{"metadata":{"trusted":true,"_uuid":"d47b125e2a4a99bf4475e5306dc378d9ce359c27","collapsed":true},"cell_type":"code","source":"df['waterfront']= pd.Series(pd.Categorical(df['waterfront'], \n                                           categories=[0,1],\n                                           ordered=True))\ndf['waterfront'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54ffbe502c3c3fcd9e139d6a7b8fe117929f66c1","collapsed":true},"cell_type":"code","source":"## Map all non-zero values in \"view\" to 1\ny = pd.Series([0,1,1,1,1], index=[0,1,2,3,4])\ndf['view'] = df['view'].map(y)\ndf['view'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df05278c3a54e7a507964dfb0beab2003978fa7c","collapsed":true},"cell_type":"code","source":"df['view']= pd.Series(pd.Categorical(df['view'], \n                                        categories=[0,1],\n                                        ordered=True))\ndf['view'].describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9c70a94406a9830f901c86d233f8d22c3391bbe"},"cell_type":"markdown","source":"### Now for some plotting:"},{"metadata":{"trusted":true,"_uuid":"c4985c3c2a6119dc62f30a35fc8357261a274f5c","collapsed":true},"cell_type":"code","source":"plotColNames = ['condition','grade']\n\nplt.figure(1,figsize = (5,6))\n    \nfor i in range(len(plotColNames)):\n    plt.subplot(100*len(plotColNames)+10+1+i)\n    sns.distplot(df[plotColNames[i]],kde=0,label=plotColNames[i],color='blue')\n    \nplt.subplots_adjust(hspace = 0.8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b81cca5d70c0ef6d1b197bfd94ef42c230e2ba3"},"cell_type":"markdown","source":"### My assessment:\n- **`condition`**: Looks like no-one gives below a 3.0. Has less variation than `grade`, so I may only keep grade.\n- **`grade`**: Yep, this looks like more information, so I'm going to drop `condition` and keep `grade`."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"08f20f206f34a79c316334958ad496bede5fc681"},"cell_type":"code","source":"## Remove \"condition\"\ndf = df.drop(columns=['condition'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33eb962df7303800019f2cbb42b5f1f138142008"},"cell_type":"markdown","source":"### 4. Transform the dependent variable, **`price`**, to a log scale, as is common with widely varying financial data (e.g. **`hitters`** from ISLR)"},{"metadata":{"trusted":true,"_uuid":"763f1d7df6815ed373cf667611d02f4f5120ff91","collapsed":true},"cell_type":"code","source":"## First, plot it as it is:\nsns.distplot(df['price'],kde=1,color='darkblue',hist_kws={'alpha':0.8})\nplt.title('Sale Price (USD)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9383a1250aabf2569d3e4d2f4fadcc87012a0418","collapsed":true},"cell_type":"code","source":"# Now transform it, but don't overwrite it:\nlogPrice = df['price'].apply(np.log)\nsns.distplot(logPrice,kde=1,color='darkblue',hist_kws={'alpha':0.8})\nplt.title('Log Transform of Sale Price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b26e83cfa75077e6ee9b1ad9d8780b356255c42"},"cell_type":"markdown","source":"### The log transform definitely looks better, but I'll keep them both in case I want to try different models with different version of the dependent variable."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2739efcc06d555ccc76e45a8af5961e58bb74abe"},"cell_type":"code","source":"df['logPrice'] = logPrice","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e2e4e6707955f8ff414cd005302d494f41f5a41"},"cell_type":"markdown","source":"### 5. Transform year-related data \nIt could be useful to transform the `yr_built` to something that gives us a better sense of how old the house is. It may be that there will be no difference in the resulting models, but it seems to make more sense to me. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"575f0fd4dabcb5fb8917386e2d49a5eb799d0ad5"},"cell_type":"code","source":"df[\"yrs_old\"] = pd.to_datetime(df['date']).dt.year - df['yr_built']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc3153e40289af42e07de8d49d6c471493703651"},"cell_type":"markdown","source":"### 5.1 Because `yr_renovated` includes values of `0` for houses that have never been renovated, a similar transformation would not be useful. I think it will be best to look at this variable as binary--either it has or has not been renovated. I'll map all the non-zero numbers to 1, then make it categorical."},{"metadata":{"trusted":true,"_uuid":"741f6763f8915ebd6faffeef8c6ff01cf91df5b6","collapsed":true},"cell_type":"code","source":"plt.figure()\n#Let's make sure we ignor the '0' values.\nrenovations = df['yr_renovated'][df['yr_renovated']>100]\nsns.distplot(renovations,kde=0,color='blue')\n    \nplt.subplots_adjust(hspace = 0.8)\nprint('There have been only:',len(renovations),'renovations.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e838aa2b8a9966433a901e4291ce1e03847e194","collapsed":true},"cell_type":"code","source":"## Map all non-zero values in \"yr_renovated\" to 1\ndf['yr_renovated'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3cd7ce0358a9a87b7d3a6c2a61aebe6251b86a6c","collapsed":true},"cell_type":"code","source":"df['yr_renovated'][df['yr_renovated']>100] = 1\ndf['yr_renovated']= pd.Series(pd.Categorical(df['yr_renovated'], \n                                        categories=[0,1],\n                                        ordered=True))\ndf['yr_renovated'].describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b14203750f6c7b976a2570a68a044252a0453f9d"},"cell_type":"markdown","source":"### 6. Plot the explanatory variables against price\n\nDouble click on a graph to enlarge them all."},{"metadata":{"trusted":true,"_uuid":"0024d1e1e10d3b37ae3717e9a3dff74747e13812","collapsed":true},"cell_type":"code","source":"colNames = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view','grade','sqft_above',\n            'sqft_basement','yr_renovated','sqft_living15','sqft_lot15','logPrice','yrs_old']\n\nsns.pairplot(df,x_vars=colNames,y_vars=\"logPrice\",size=10,aspect=1.0,kind = 'reg')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60d1967c8ef7d8e579210a4b0f2525b0d7673cc8","collapsed":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(df, alpha=0.2, figsize=(20, 20), diagonal='kde');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"260fb87775a0c08295bb2c92ef54a015f6536752"},"cell_type":"markdown","source":"### 7. Remove remaining meaningless or superfluous data (such as **`id`**)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a7eeef99218e63b06e60042052a8ef80b5862d51"},"cell_type":"code","source":"# There two variables that we don't care about:\n#  id\n#  date (all are within about a year of each other, making it difficult to establish seasonality)\n#  lat/long (this should be captured in zip code, and I'm not sure how to deal with it otherwise)\ndf = df.drop(columns=['id', 'date', 'lat','long','yr_built'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28ef2271ee627beee923abfa25be26f8dd9f1945"},"cell_type":"markdown","source":"### 8. Check for collinearity"},{"metadata":{"trusted":true,"_uuid":"ebafad673cb054498f43cdd2f107d4cbd225b33c","collapsed":true},"cell_type":"code","source":"#Source: https://stackoverflow.com/questions/39409866/correlation-heatmap?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa\ncmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)\ncorr = df.corr()\ncorr.style.background_gradient(cmap, axis=1)\\\n    .set_properties(**{'max-width': '50px', 'font-size': '9pt'})\\\n    .set_precision(2)\\","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b05f94ab29d3d96ecaca9da437650c1a819a7739"},"cell_type":"markdown","source":"### Interestingly, `sqft_*15` variables seem to be sufficiently different from their counterparts that I will keep them."},{"metadata":{"_uuid":"a82fb39651efed2d384e7c9c1c049cb57f5fa4a4"},"cell_type":"markdown","source":"## Before we do model-building, it will be useful to split the data into training/test data.\n\nThere is a lot of data, so I'm going to do an 80/20 split. I have no idea if this is optimal!"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9c859ad10e879f936c7868ac3452f724ca585bc3"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# All the data:\ny = pd.Series(df['logPrice'])\nX = df.drop(columns=['logPrice','price'])\n\n# How many observations are there?\nnumObs = df.shape[0]\nnumTrain = int(round(numObs*0.8,0))\n# numTrain = 17290 in this case\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=numObs-numTrain, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4e49c8bbce0713d248883466eb654f6469ecc7a","collapsed":true},"cell_type":"code","source":"# Store column names for later:\ncolumnHeaders = X.columns.tolist()\n\nprint(X_train.shape,' ',X_test.shape)\nprint(y_train.shape,' ',y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62fddf16741094af2164545bd0bc83ce3e5bef6d"},"cell_type":"markdown","source":"### And set up a dataframe to store performance data:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f6f5f5cc53e032f58c71be767901cf50f7f5f5e4"},"cell_type":"code","source":"perfDFColumns = ['Model Name','Test MSE','Test R^2']\nperfDF = pd.DataFrame(columns=perfDFColumns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac8a7e3b14d159095bdacc0dedb67f411c474b2a"},"cell_type":"markdown","source":"# 0. Baseline Model:\n## How does a naive average work? We'll use its performance metrics as a \"floor\" to compare everything else against."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8367ae8f94de2dcd47b27e023f6a1a804aea0c4e"},"cell_type":"code","source":"from sklearn.dummy import DummyRegressor\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd141256d2c73d10a334e1f4b1bc63b23615a257","collapsed":true},"cell_type":"code","source":"dummy = DummyRegressor(strategy='mean')\ndummy.fit(X_train,y_train)\ndummy_MSE = mean_squared_error(y_test,dummy.predict(X_test))\ndummy_R2  = dummy.score(X_test,y_test)\nprint(dummy_MSE,dummy_R2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fa7472d3d7a8f0733eaf88683f22c72d38f719d","collapsed":true},"cell_type":"code","source":"newRow = [('Naive Mean Model',round(dummy_MSE,3),round(dummy_R2*100,2))]\nperfDF = perfDF.append(pd.DataFrame(data=newRow,columns=perfDFColumns),ignore_index=True)\nperfDF.drop_duplicates(inplace=True) # So we don't accidentally append multiple times.\nperfDF","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4525cddf17abcc30d5233e82d9c9033114e02b8"},"cell_type":"markdown","source":"# 1. Multiple Linear Regression:\n## This will also be used as a baseline of sorts, because it is the most simple statistical learning model we have. If other ML models don't beat linear regression, then use linear regression!"},{"metadata":{"trusted":true,"_uuid":"c2e51ca98ef2a62baba71f1a814263c5a465f402","collapsed":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlinRegr = LinearRegression()\nlinRegr.fit(X_train, y_train)\nr2 = linRegr.score(X_test, y_test)\n\nlinRegr_MSE = mean_squared_error(y_test, linRegr.predict(X_test))\nprint('Linear Regression Test MSE: {}'.format(round(linRegr_MSE,3)))\nprint('Linear Regression model Test R^2 is: {}%'.format(round(r2*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ead5e224354db47c0b1cc6f6bb39b2fb83ac4bf","collapsed":true},"cell_type":"code","source":"newRow = [('Linear Regression',round(linRegr_MSE,3),round(r2*100,3))]\nperfDF = perfDF.append(pd.DataFrame(data=newRow,columns=perfDFColumns),ignore_index=True)\nperfDF.drop_duplicates(inplace=True) # So we don't accidentally append multiple times.\nperfDF","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af2bb58f5f466e0037e7957234a5108dfb3b5a37"},"cell_type":"markdown","source":"# 2. Best Subset Regression:\n\n### Best Subset. Scikit-learn implements feature selection using a univariate statistical test (f_regression in this case) to choose the k-best of p predictors.\nBest subset is a dimension-reducing methodology. Since there aren't that many predictors in this data set, I'm not expecting it to be that useful."},{"metadata":{"trusted":true,"_uuid":"9f573a7da23d026f42cd71a7459ea413bd9b9058","collapsed":true},"cell_type":"code","source":"#SYNTAX: X_train, X_test, y_train, y_test\nfrom sklearn.feature_selection import SelectKBest, f_regression\n# X_train.shape[1] = 15; There are 15 possible predictors.\nsubSetter = SelectKBest(f_regression, k=5).fit(X_train, y_train)\nX_bestSubset = subSetter.transform(X_train)\nscores = subSetter.scores_\nX_bestSubsetScoresDF = pd.DataFrame(data=scores,columns=['scores'],index=X_train.columns.tolist())\nX_bestSubsetScoresDF.sort_values(by='scores',ascending=False,inplace=True)\nX_bestSubsetScoresDF.astype(float).round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e119ebaaade1e9361bb53cdb0fa08ba3a97bbe6d"},"cell_type":"code","source":"linRegrSubsetPerfDF = pd.DataFrame(columns=perfDFColumns,index=range(1,16))\nlinRegrSubsetPerfDF['#Var'] = range(1,16)\nlinRegrSubsetPerfDF.set_index('#Var',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5925dbaafcc12ebdd7c9b52fc7421b45d9de75f4","collapsed":true},"cell_type":"code","source":"# Get the R^2 of a model with 1 through all 15 predictors, in order of their score:\nlinRegrSubsetPerfDF = pd.DataFrame(columns=['R-squared'],index=range(1,16))\n\nfor k in range(1,16):\n    linRegr = LinearRegression().fit(X_train[X_bestSubsetScoresDF.index[0:k].values], y_train)\n    #linRegr.fit(X_train[X_bestSubsetScoresDF.index[0:k].values], y_train)\n    linRegrSubsetPerfDF.loc[k,'R-squared'] = linRegr.score(X_test[X_bestSubsetScoresDF.index[0:k].values], y_test)\n    linRegrSubsetPerfDF.loc[k,'test MSE'] = mean_squared_error(y_test, linRegr.predict(X_test[X_bestSubsetScoresDF.index[0:k].values]))\n    \n# Example of stringing methods together in Python:\n# Show the whole DataFrame, after rounding it to two decimal places, after transposing it.\nlinRegrSubsetPerfDF.astype(float).round(2).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6c165410e3822ae3fc4406e514c77bf22b5e8d4e"},"cell_type":"code","source":"## Creating a function because we'll graph MSE and R^2 for each candidate model:\n\ndef plotPerformance(x,mse,r2,title='Title Goes Here',xlabel='x label goes here'):\n    # Informed by: https://matplotlib.org/gallery/api/two_scales.html\n    fig, ax1 = plt.subplots()\n\n    # plot R^2 with scale on left hand side of plot\n    xaxis = x\n    ax1.plot(x, r2,'b.-')\n    ax1.set_xlabel(xlabel)\n    ax1.set_ylabel('R-Squared', color='b')\n    ax1.tick_params(axis='y',labelcolor='b')\n\n    # plot test MSE with scale on right hand side of plot\n    ax2 = ax1.twinx()\n    ax2.plot(x, mse,'r.-')\n    ax2.set_ylabel('test MSE', color='r')\n    ax2.tick_params(labelcolor='r')\n\n    plt.title(title)  \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a35a183a4197476119ab990217ff03cf889bbc97","collapsed":true},"cell_type":"code","source":"plotPerformance(x=linRegrSubsetPerfDF.index.values, \n               mse=linRegrSubsetPerfDF['test MSE'],\n               r2=linRegrSubsetPerfDF['R-squared'],\n               title='Performance based on # features included',\n               xlabel='# features')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b846bbbcd0de494d284b6cf314aa5ac717ee33a","collapsed":true},"cell_type":"code","source":"newRow = [('Best Subset Regression',round(linRegrSubsetPerfDF.loc[14]['test MSE'],3),round(linRegrSubsetPerfDF.loc[14]['R-squared']*100,3))]\nperfDF = perfDF.append(pd.DataFrame(data=newRow,columns=perfDFColumns),ignore_index=True)\nperfDF.drop_duplicates(inplace=True) # So we don't accidentally append multiple times.\nperfDF","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1472d5f8507e70c597b0438e3e14f49d447d1f5b"},"cell_type":"markdown","source":"### Note that the highest accuracy is with 14 predictors. 15 predictors gives us the same test accuracy as the naive linear regression model, because they are the same! As expected, best subset, which is a dimensionality reduction tool, is not useful with this dataset.\n\n# 3. Ridge Regression:\n\n### Ridge and Lasso Regression: setting up the $\\lambda$ and finding the best $\\lambda$ by cross-validation."},{"metadata":{"trusted":true,"_uuid":"076d201d810a83c96ab82a900b0742b3748449e5","collapsed":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n# Generate a range of alpha values:\nalphas = 10**np.linspace(10,-4,100)\nridge = Ridge(normalize = True)\ncoefs = []\n\nfor a in alphas:\n    ridge.set_params(alpha = a)\n    ridge.fit(X_train, y_train)\n    coefs.append(ridge.coef_)\n    \nnp.shape(coefs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a68157e8ebbc5fa8570f25b3cd91736a9bb1f165","collapsed":true},"cell_type":"code","source":"# This chart is similar to Figure 6.4 in ISLR (p 216)\nax = plt.gca()\nax.plot(alphas, coefs);\nax.set_xscale('log')\nplt.xlabel('alpha')\nplt.ylabel('Standardized Coefficients');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36e8052f407ca78d35be228fa0d92436daf29588","collapsed":true},"cell_type":"code","source":"# Use cross-validation to find the alpha value with the lowest error:\nridgecv = RidgeCV(alphas=alphas, scoring = 'neg_mean_squared_error',normalize=True)\nridgecv.fit(X_train, y_train)\nridgecv.alpha_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19af68400474bc239784a7874bf6651b99c2a9c6","collapsed":true},"cell_type":"code","source":"# Find the test MSE associated with the best alpha:\nridge = Ridge(alpha = ridgecv.alpha_, normalize = True)\nridge.fit(X_train, y_train)\nridge_MSE = mean_squared_error(y_test, ridge.predict(X_test))\nridge_accuracy = ridge.score(X_test, y_test)\nprint('Ridge Regression MSE: {}'.format(round(ridge_MSE,3)))\nprint('Ridge Regression model accuracy is: {}%'.format(round(ridge_accuracy*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fdc10c01dd920735a2f45587d01c1b3b13a81c3","collapsed":true},"cell_type":"code","source":"ridgePerfDF = pd.DataFrame(columns=['R-squared','test MSE'])\nridgePerfDF['alpha'] = ridgecv.alphas\nridgePerfDF.set_index('alpha',inplace=True)\n\nfor a in ridgecv.alphas:\n    ridge = Ridge(alpha = a, normalize = True)\n    ridge.fit(X_train, y_train)\n    testMSE = mean_squared_error(y_test, ridge.predict(X_test))\n    testR2 = ridge.score(X_test, y_test)\n    ridgePerfDF.loc[a,'test MSE']  = mean_squared_error(y_test, ridge.predict(X_test))\n    ridgePerfDF.loc[a,'R-squared'] = ridge.score(X_test, y_test)\n\nridgePerfDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98733bc50fcd9839beb276bfe3ce33bdf3847790","collapsed":true},"cell_type":"code","source":"# Plot performance based on alpha value. Does it match the autmated ridgeCV alpha?\n# Note: the highest alpha values skew the graph, so we zoom in with indexing\nplotPerformance(x=ridgePerfDF.index.values[60:101], \n               mse=ridgePerfDF['test MSE'].values[60:101],\n               r2=ridgePerfDF['R-squared'].values[60:101],\n               title='Performance based on alpha value',\n               xlabel='alpha')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cb0ed53ba2537afc92effa93569cb790e798923","collapsed":true},"cell_type":"code","source":"newRow = [('Ridge Regression',round(ridge_MSE,3),round(ridge_accuracy*100,2))]\nperfDF = perfDF.append(pd.DataFrame(data=newRow,columns=perfDFColumns),ignore_index=True)\nperfDF.drop_duplicates(inplace=True) # So we don't accidentally append multiple times.\nperfDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afd2645d108b7c3a44ace3270480ec72b7468b7d","collapsed":true},"cell_type":"code","source":"ridgeCoefDF = pd.DataFrame(data=ridgecv.coef_,columns=['Coeff Val'],index=columnHeaders)\nprint('Best Alpha: ',ridgecv.alpha_)\nridgeCoefDF","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6dd067a3741fe07e248cbda89bd1578f70f93c1"},"cell_type":"markdown","source":"### Scikit-Learn's Ridge Regression CV feature finds that an $\\lambda$ = 0.000977, which is the smallest $\\lambda$ I have tried. This checks out with the manual CV I conducted above. Not sure if it's appropriate to continue looking at lower $\\lambda$ values. (I already lowered it once, where previously the lowest $\\lambda$ was 0.01.\n### It does not appear that ridge regression produces any zero coefficients, so it's not actually doing any variable selection. Furthermore, the Ridge Regression model doesn't even out perform the baseline Linear Regression. \n# 4. Lasso Regression:"},{"metadata":{"trusted":true,"_uuid":"03960e751672c0d5af982336246d7467e5076e9b","collapsed":true},"cell_type":"code","source":"## Thanks to: http://www.science.smith.edu/~jcrouser/SDS293/labs/lab10-py.html\n\n# Basic model: (no cross-validation)\nlasso = Lasso(max_iter = 100000, normalize = True)\ncoefs = []\n\nfor a in alphas:\n    lasso.set_params(alpha=a)\n    lasso.fit(X_train, y_train)\n    coefs.append(lasso.coef_)\n    \nax = plt.gca()\nax.plot(alphas*2, coefs)\nax.set_xscale('log')\nplt.axis('tight')\nplt.xlabel('alpha')\nplt.ylabel('weights')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43071a483b63967433a88c8fbac945ff65269dbc","collapsed":true},"cell_type":"code","source":"# Cross-validated model:\nlassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\nlassocv.fit(X_train, y_train)\n\n# Get MSE\nlasso.set_params(alpha=lassocv.alpha_)\nlasso.fit(X_train, y_train)\nlassoCV_MSE = mean_squared_error(y_test, lasso.predict(X_test))\n\n# Get model accuracy\nlassoCV_accuracy = lasso.score(X_test, y_test)\n\nlassocvCoefDF = pd.DataFrame(data=lasso.coef_,columns=['Coeff Val'],index=columnHeaders)\nprint('lassoCV_MSE',lassoCV_MSE)\nprint('lassoCV_accuracy',lassoCV_accuracy)\nlassocvCoefDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"739c3156c443903a20e30e5351aa673f21f997cf","collapsed":true},"cell_type":"code","source":"lassoPerfDF = pd.DataFrame(columns=['R-squared','test MSE'])\nlassoPerfDF['alpha'] = ridgecv.alphas\nlassoPerfDF.set_index('alpha',inplace=True)\n#lassoPerfDF\n\nfor a in ridgecv.alphas:\n    lasso = Lasso(alpha = a, normalize = True)\n    lasso.fit(X_train, y_train)\n    testMSE = mean_squared_error(y_test, lasso.predict(X_test))\n    testR2 = lasso.score(X_test, y_test)\n    lassoPerfDF.loc[a,'test MSE']  = mean_squared_error(y_test, lasso.predict(X_test))\n    lassoPerfDF.loc[a,'R-squared'] = lasso.score(X_test, y_test)\n\nprint(\"Note: Best performance is with lowest alphas\")\nlassoPerfDF.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b91f75d1787a293a5bc7a62bc067c9a42c1d739","collapsed":true},"cell_type":"code","source":"print(min(lassoPerfDF['test MSE']))\nprint(max(lassoPerfDF['R-squared']))\nlassoPerfDF[lassoPerfDF['R-squared']>0.6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"69d75ef11d196c29a600ba501f61682f03478dae"},"cell_type":"code","source":"lasso_MSE = lassoPerfDF.loc[0.0001,'test MSE']\nlasso_R2 = lassoPerfDF.loc[0.0001,'R-squared']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d86fd0ed3d203542d77cd4663eaebcd1ae2ef0ab","collapsed":true},"cell_type":"code","source":"# Plot performance based on alpha value. Does it match the autmated ridgeCV alpha?\n# Note: the highest alpha values skew the graph, so we zoom in with indexing\nplotPerformance(x=lassoPerfDF.index.values[85:101], \n               mse=lassoPerfDF['test MSE'].values[85:101],\n               r2=lassoPerfDF['R-squared'].values[85:101],\n               title='Lasso performance based on alpha value',\n               xlabel='alpha')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa01565aab25c1b2f71c3748653382af260c92c7","collapsed":true},"cell_type":"code","source":"newRow = [('Lasso Regression',round(lasso_MSE,3),round(lasso_R2*100,2))]\nperfDF = perfDF.append(pd.DataFrame(data=newRow,columns=perfDFColumns),ignore_index=True)\nperfDF.drop_duplicates(inplace=True) # So we don't accidentally append multiple times.\nperfDF","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3152f0b74adde08ece753552ef30f56fa49df448"},"cell_type":"markdown","source":"### Although a lot of the coefficients are close to zero, probably due to the log scale of the dependent variable, only one variable is left out. Strangely, the variable that's left out is **`sqft_above`**.\n\n### Most importantly, the Lasso model does not improve upon linear regression with this data set.\n\n# 5. Support Vector Machine for Regression:\n\n### In class, we've used SVM's for binary classification (default or not, survive or not), but it is possible to use it for numerical regression of a continuous response variable. Scikit-Learn uses the `SVR` model object instead of the `SVC`, which is used for classification. It will be interesting to see how it performs against models that are typically better suited for Regression with continuous response variables."},{"metadata":{"trusted":true,"_uuid":"9b85c3d59515312db2911eb2fc4ccefb0cef7237","collapsed":true},"cell_type":"code","source":"from sklearn.svm import SVR\nsvr = SVR()\nsvr.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d13e69071775303c5cdbf3ba7ac20a81096817b1","collapsed":true},"cell_type":"code","source":"# Get MSE\nsvr_MSE = mean_squared_error(y_test, svr.predict(X_test))\n# Get model accuracy\nsvr_accuracy = svr.score(X_test, y_test)\nprint('Test MSE:',svr_MSE,' & Accuracy:',svr_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03bb224649d4bd6ab90203be18ded0c9ce1b56b3","collapsed":true},"cell_type":"code","source":"## Grid search cross-validation isn't supported for continuous variables,\n##  so I'll do  manually:\n\nfor c in [0.001, 0.01, 0.1, 1, 5, 10, 100]:\n    svr = SVR(C=c,kernel='rbf') # radial basis function kernel is highly flexible\n    svr.fit(X_train,y_train)\n    svr_MSE = mean_squared_error(y_test, svr.predict(X_test))\n    svr_accuracy = svr.score(X_test, y_test)\n    print('For c=',c,'Test MSE:',svr_MSE,' & Accuracy:',svr_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4957002194d8713a3485284e7c2005cb5954832e","collapsed":true},"cell_type":"code","source":"## Refit with best C:\nsvr = SVR(C=1)\nsvr.fit(X_train,y_train)\nsvr_MSE = mean_squared_error(y_test, svr.predict(X_test))\nsvr_accuracy = svr.score(X_test, y_test)\nprint('Test MSE:',svr_MSE,' & Accuracy:',svr_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf8ea381d9e487cf50a898492ecaf0d35d2adb6b","collapsed":true},"cell_type":"code","source":"newRow = [('SVM Regression',round(svr_MSE,3),round(svr_accuracy*100,2))]\nperfDF = perfDF.append(pd.DataFrame(data=newRow,columns=perfDFColumns),ignore_index=True)\nperfDF.drop_duplicates(inplace=True) # So we don't accidentally append multiple times.\nperfDF","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3de1c48c65c634930f9603416a7ba36301e7e919"},"cell_type":"markdown","source":"### Even the best SVM model does quite poorly with this data, barely achieving over 1% accuracy.\n\n# 6. K Nearest Neighbors:\nTesting for k = 1,2,3,...38,39,40, as in our lab.\n\nWe will use the Scikit-Learn scale feature, which standardizes all predictor variables to have a mean of zero and standard deviation of one. This way, we don't have problems with different scales across different variables. **This was already accomplished with the Lasso and Ridge Regression algorithms with the `normalize=True` parameter**"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a481d58ccb4467ebf2e76a7818951dd4b69827de"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import scale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bea61e8a4d53f8173256476addb6b48a2a909888"},"cell_type":"code","source":"knnDF = pd.DataFrame(columns=['k','test MSE','R-squared'],index=range(1,41))\nknnDF['k'] = range(1,41)\nknnDF['test MSE'] = range(1,41)\nknnDF.set_index('k',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9bf6e4f1357e72187627df7dcf880b527b29838a"},"cell_type":"code","source":"for k in range(1,41):\n    knn = KNeighborsRegressor(n_neighbors=k)\n    knn.fit(scale(X_train), y_train) \n    knnDF.loc[k,'test MSE'] = mean_squared_error(y_test, knn.predict(scale(X_test)))\n    knnDF.loc[k,'R-squared'] = knn.score(scale(X_test), y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f82a35fccbc5a7b28f8c81fd83333284a3e0d9b8","collapsed":true},"cell_type":"code","source":"# Plot performance based on k value. \nplotPerformance(x=knnDF.index.values,#[85:101], \n               mse=knnDF['test MSE'].values,#[85:101],\n               r2=knnDF['R-squared'].values,#[85:101],\n               title='KNN Performance',\n               xlabel='k neighbors')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc82569b03b412528813d778a3b28bb3d4c87f60","collapsed":true},"cell_type":"code","source":"newRow = [('KNN Regression',round(knnDF.loc[20,'test MSE'],3),round(knnDF.loc[20,'R-squared']*100,2))]\nperfDF = perfDF.append(pd.DataFrame(data=newRow,columns=perfDFColumns),ignore_index=True)\nperfDF.drop_duplicates(inplace=True) # So we don't accidentally append multiple times.\nperfDF","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1f025b73c71991bbee436f1d82d3335f04483d2"},"cell_type":"markdown","source":"## The KNN model increases from k=1 and plateaus at about k = 20. Since referencing more neighbors at runtime will slow down processing of future predictions, I would use k=20 over k=40, even though they have about the same performance.\n\n## So far, KNN is the best model.\n\n# 7. CART:\nBuilding a decision tree using the **`sklearn.tree.DecisionTreeRegressor()`** model, and plot it with **`graphviz`** (spoiler, I couldn't get graphviz to work)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"08496914343d2b43f589530df39e14278891dce3"},"cell_type":"code","source":"from sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83062a165ea65fd8cdece414a76de274fca41a63","collapsed":true},"cell_type":"code","source":"cart = tree.DecisionTreeRegressor()\ncart = cart.fit(X_train,y_train)\n\ncart_MSE = mean_squared_error(y_test, cart.predict(X_test))\ncart_R2 = cart.score(X_test, y_test)\nprint(cart_MSE,cart_R2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2acccf279bbfee585194d601405aab4c3c4bfdb4","collapsed":true},"cell_type":"code","source":"newRow = [('CART Regression',round(cart_MSE,3),round(cart_R2*100,2))]\nperfDF = perfDF.append(pd.DataFrame(data=newRow,columns=perfDFColumns),ignore_index=True)\nperfDF.drop_duplicates(inplace=True) # So we don't accidentally append multiple times.\nperfDF","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a64cc85053cca0cfd1ef6afb60477ae1589364c"},"cell_type":"markdown","source":"# 8. Random Forest:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"780d509362022a94cb23d88efd5e94635d80cebc"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9af3a9e0b932b78be0a6e7f6079a6ce59d977cf","collapsed":true},"cell_type":"code","source":"%%time\nrandFor = RandomForestRegressor(max_depth=500,random_state=2)\nrandFor.fit(X_train,y_train)\nRF_MSE = mean_squared_error(y_test, randFor.predict(X_test))\nRF_R2 = randFor.score(X_test,y_test)\nprint(RF_MSE,RF_R2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfd844a96670b5f5d772737e76a20a39715967d3","collapsed":true},"cell_type":"code","source":"newRow = [('Random Forest Regression',round(RF_MSE,3),round(RF_R2*100,2))]\nperfDF = perfDF.append(pd.DataFrame(data=newRow,columns=perfDFColumns),ignore_index=True)\nperfDF.drop_duplicates(inplace=True) # So we don't accidentally append multiple times.\nperfDF","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"986d2d80e994f76b3c6279777cc913bb2be6050e"},"cell_type":"markdown","source":"# 9. AdaBoost:\n## Using the CART and boosting it."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ebed2eb08df7895269d9e4d3f84bedb497bfadcd"},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5099673722bbe0a04fc9bdd664f0891a754e32e","collapsed":true},"cell_type":"code","source":"adaBoost = AdaBoostRegressor(cart,n_estimators=300,random_state=np.random.RandomState(1))\nadaBoost.fit(X_train,y_train)\nadaPredict = adaBoost.predict(X_test)\nadaBoost_MSE = mean_squared_error(y_test,adaPredict)\nadaBoost_R2  = adaBoost.score(X_test,y_test)\nprint(adaBoost_MSE,adaBoost_R2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a35e9a1e65c5e7d9595d29c343153b20b3e959f9","collapsed":true},"cell_type":"code","source":"newRow = [('AdaBoost Regression',round(adaBoost_MSE,3),round(adaBoost_R2*100,2))]\nperfDF = perfDF.append(pd.DataFrame(data=newRow,columns=perfDFColumns),ignore_index=True)\nperfDF.drop_duplicates(inplace=True) # So we don't accidentally append multiple times.\nperfDF","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"290f87aa7e4a48948e0f7c57376d92544f79d6d8"},"cell_type":"markdown","source":"## But who cares if we can predict on a log scale... potential investors would want to know how accurate the model is in real terms.\n\nSo let's map the predicted and true (test) response values back onto the normal scale:"},{"metadata":{"trusted":true,"_uuid":"abe7b758039b7c19f6a7342ef743ffac5538a594","collapsed":true},"cell_type":"code","source":"yNoLog=np.exp(y_test)\nyNoLog.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"806d57ee6e1cc7c02985d8fb5507e13fc94ef618","collapsed":true},"cell_type":"code","source":"percError = ((yNoLog - np.exp(adaPredict)) / yNoLog) * 100\npercError.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c5d71cf61715e723fe941768a54d5a36c1d29c6","collapsed":true},"cell_type":"code","source":"fig, ax1 = plt.subplots()\nsns.regplot(x=yNoLog,y=percError,fit_reg=False);\n\nlinex = np.linspace(0, max(yNoLog+100000), 5)\nline1 = ax1.plot(linex, 0*linex, '--', linewidth=1,color='black')\n\nfig.set_size_inches(10,6)\nax1.set_xlabel('Sale Price')\nax1.set_ylabel('Estimator % Error')\nplt.title('% Error By Sale Price');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70ce389e65b294b85d5b84cf9097c9a0bcf87fc5"},"cell_type":"markdown","source":"In the chart above, points above the line were **underestimated**, and points below the line were **overestimated** by the model. \n\n# Conclusion\nThe AdaBoost model seems to work the best with this test/training split. In order to improve my model further, I would spend more time on feature engineering, specifically with the lat/long values. I assume it's possible to deduce school ratings, import census data, etc... with this location information.\n\nI did look at an outlier in the bottom left of the chart, `df.iloc[18332]`, which was predicted to be sold for \\$390k when in fact it sold for \\$130k, a 300% error. I tried to resolve the lat/long to an address, but it appears as though the data have been generalized so as to not allow that. I could place the neighborhood, but not the address. So I don't think it would be possible to gather adress information \n\n# Future Work\nI think the most interesting measure of performance is the chart showing errors in terms of the actual sale price. I'm wondering if some models that didn't perform as well as AdaBoost, when judged by Test MSE and Test R-squared, may perform better in *certain segments* of the market. It could be that different models perform better in a noisy segment of the data, such as the lower end of the sale price spectrum, even though AdaBoost performs better overall. **I'd be interested to know how real estate analysts would typically split up a market**, and I would re-run these models, segmenting the test data to only those that apply. I may have to increase my percentage of data allocated to the test data so that my test set for each segment is sufficient."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c33abd1a1f2ba0098797e3a456fc48aeebd1609b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}