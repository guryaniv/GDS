{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"626a0af60cd86c7fbc9b4c852c05ba135678caf9"},"cell_type":"code","source":"#Processing\nimport pandas as pd\nimport numpy as np\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA, TruncatedSVD, FastICA\nfrom sklearn.model_selection import KFold\nfrom sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\nfrom sklearn.preprocessing import normalize\nfrom sklearn.manifold import TSNE\nimport gc\n#Plotting\nimport seaborn as sns\n\n#Models\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"660eddcbd4e1a2d57136b7023086890c1e0bb2bd"},"cell_type":"markdown","source":"## Load the files and get a brief overview\n"},{"metadata":{"trusted":true,"_uuid":"de4e270e1c277cc96508aa0595c79c5d8ef2dfc3","collapsed":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9c79a158d5bf52352200b50eb933cd42c0662d7"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcf10858e996e58f4fb282558c8c59cf932ea3e9"},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d55aecff54c8aa6bdd163167f058d49cf33df10c"},"cell_type":"markdown","source":"### Set up train and test X,Y"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0686ab850c7b0d29135f6d897966ee29f72d21ab"},"cell_type":"code","source":"X_train = train_df.drop([\"ID\", \"target\"], axis=1)\ny_train = np.log1p(train_df[\"target\"].values)\n\nX_test = test_df.drop([\"ID\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2aa4b37baf6d628b9a450de45f3928d0a6f01627"},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95178959a699263a89ca0a86a6fd4a8bda5db57d"},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f7876a1bce352394beb8ddd7cfac0e475cf92c2"},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"_uuid":"35c7d9836c1757f90d8977e4034e651cae19f634"},"cell_type":"markdown","source":"## Prepare data"},{"metadata":{"_uuid":"8ef2f5162ad83fadb3cacad2ac4c05452a3617b4"},"cell_type":"markdown","source":"### Checking for NaN values and removing constant features in the training data"},{"metadata":{"trusted":true,"_uuid":"c7eb68cd08ae67704af52cbe2a14193b58fe3b35"},"cell_type":"code","source":"print(\"Total Train Features with NaN Values = \" + str(train_df.columns[train_df.isnull().sum() != 0].size))\nif (train_df.columns[train_df.isnull().sum() != 0].size):\n    print(\"Features with NaN => {}\".format(list(train_df.columns[train_df.isnull().sum() != 0])))\n    train_df[train_df.columns[train_df.isnull().sum() != 0]].isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1641ac15e5b2adb5a177f844bae0c50fa73348a8"},"cell_type":"code","source":"zero_count = []\nfor col in X_train.columns[2:]:\n    zero_count.append([i[1] for i in list(X_train[col].value_counts().items()) if i[0] == 0][0])\n    \nprint('{0} features of 4491 have zeroes in 99% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.99])))\nprint('{0} features of 4491 have zeroes in 98% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.98])))\nprint('{0} features of 4491 have zeroes in 97% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.97])))\nprint('{0} features of 4491 have zeroes in 96% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.96])))\nprint('{0} features of 4491 have zeroes in 95% or more samples.'.format(len([i for i in zero_count if i >= 4459 * 0.95])))\n\ncols_to_drop = [col for col in X_train.columns[2:] if [i[1] for i in list(X_train[col].value_counts().items()) if i[0] == 0][0] >= 4459 * 0.98]\n\nX_train.drop(cols_to_drop, axis=1, inplace=True)\nX_test.drop(cols_to_drop, axis=1, inplace=True)\n\nprint('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"7e1cc0ebdb1fcc4f025d859d098a34b4870abe03"},"cell_type":"code","source":"colsToRemove = []\nfor col in X_train.columns:\n    if X_train[col].std() == 0: \n        colsToRemove.append(col)\n        \n# remove constant columns in the training set\ntrain_df.drop(colsToRemove, axis=1, inplace=True)\n\n# remove constant columns in the test set\ntest_df.drop(colsToRemove, axis=1, inplace=True) \n\nprint(\"Removed `{}` Constant Columns\\n\".format(len(colsToRemove)))\nprint(colsToRemove)\nprint('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30f852b466b6adf961052d8262ea18c8c38787aa"},"cell_type":"markdown","source":"### Removing duplicated columns"},{"metadata":{"trusted":true,"_uuid":"a0d384841b2278b7fe65b9445f05603312890a32"},"cell_type":"code","source":"colsToRemove = []\ncolsScaned = []\ndupList = {}\n\ncolumns = X_train.columns\n\nfor i in range(len(columns)-1):\n    v = X_train[columns[i]].values\n    dupCols = []\n    for j in range(i+1,len(columns)):\n        if np.array_equal(v, X_train[columns[j]].values):\n            colsToRemove.append(columns[j])\n            if columns[j] not in colsScaned:\n                dupCols.append(columns[j]) \n                colsScaned.append(columns[j])\n                dupList[columns[i]] = dupCols\n                \n# remove duplicate columns in the training set\nX_train.drop(colsToRemove, axis=1, inplace=True) \n\n# remove duplicate columns in the testing set\nX_test.drop(colsToRemove, axis=1, inplace=True)\n\nprint(\"Removed `{}` Duplicate Columns\\n\".format(len(dupList)))\nprint(dupList)\n\nprint('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"152531ef2c22aaebaf2ec5e32e949a8e5cedf856"},"cell_type":"markdown","source":"### Drop Sparse Data"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e6b1279706c84fd8c08b0a2a35ab539663d22c25"},"cell_type":"code","source":"def drop_sparse(train, test):\n    flist = [x for x in train.columns if not x in ['ID','target']]\n    for f in flist:\n        if len(np.unique(train[f]))<2:\n            train.drop(f, axis=1, inplace=True)\n            test.drop(f, axis=1, inplace=True)\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e41ab5ad0b7eb71997386de546ee89dea3fd608a"},"cell_type":"code","source":"X_train, X_test = drop_sparse(X_train, X_test)\n\nprint('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56f23ae2316833c604de8e34b3e82037fe5ab531"},"cell_type":"markdown","source":"## Add Features"},{"metadata":{"_uuid":"d61c58344dc4c567701f59dffc3f7993036f01fa"},"cell_type":"markdown","source":"### Sumzeros and Sumvalues"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6ea858f4ab2a63b3c6459c79b3dd5c3c9c810429"},"cell_type":"code","source":"def add_SumZeros(train, test, features):\n    flist = [x for x in train.columns if not x in ['ID','target']]\n    if 'SumZeros' in features:\n        train.insert(1, 'SumZeros', (train[flist] == 0).astype(int).sum(axis=1))\n        test.insert(1, 'SumZeros', (test[flist] == 0).astype(int).sum(axis=1))\n    flist = [x for x in train.columns if not x in ['ID','target']]\n\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71fb6a45b144ca5f2eae337167ef32648b57e8be","collapsed":true},"cell_type":"code","source":"# X_train, X_test = add_SumZeros(X_train, X_test, ['SumZeros'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"efbb17e97cddc97fec763becb6a3caf0ef3063e2"},"cell_type":"code","source":"def add_SumValues(train, test, features):\n    flist = [x for x in train.columns if not x in ['ID','target']]\n    if 'SumValues' in features:\n        train.insert(1, 'SumValues', (train[flist] != 0).astype(int).sum(axis=1))\n        test.insert(1, 'SumValues', (test[flist] != 0).astype(int).sum(axis=1))\n    flist = [x for x in train.columns if not x in ['ID','target']]\n\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e55ef947b6cfcc6444f4ee98e1c166309d54a31d"},"cell_type":"code","source":"# X_train, X_test = add_SumValues(X_train, X_test, ['SumValues'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30233b9a85317dadb9d69da629b42b0f019ea6af"},"cell_type":"markdown","source":"### Other Aggregates"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"000ed2bdc20e9de1bf0d7c43571262203f801683"},"cell_type":"code","source":"def add_OtherAgg(train, test, features):\n    flist = [x for x in train.columns if not x in ['ID','target','SumZeros','SumValues']]\n    if 'OtherAgg' in features:\n        train['Mean'] = train.mean(axis=1)\n        train['Median'] = train.median(axis=1)\n        train['Mode'] = train.mode(axis=1)\n        train['Max'] = train.max(axis=1)\n        train['Var'] = train.var(axis=1)\n        train['Std'] = train.std(axis=1)\n        \n        test['Mean'] = test.mean(axis=1)\n        test['Median'] = test.median(axis=1)\n        test['Mode'] = test.mode(axis=1)\n        test['Max'] = test.max(axis=1)\n        test['Var'] = test.var(axis=1)\n        test['Std'] = test.std(axis=1)\n    flist = [x for x in train.columns if not x in ['ID','target','SumZeros','SumValues']]\n\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5cf1e7c6244a8a219673179a7d68cc9aa605004"},"cell_type":"markdown","source":"### K-Means"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a14b2e04eb3133ec411db7d71bf90505badd0a21"},"cell_type":"code","source":"def kmeans(X_Tr,Xte):\n    flist = [x for x in X_Tr.columns if not x in ['ID','target']]\n    flist_kmeans = []\n    for ncl in range(2,11):\n        cls = KMeans(n_clusters=ncl)\n        cls.fit_predict(X_train[flist].values)\n        X_Tr['kmeans_cluster_'+str(ncl)] = cls.predict(X_Tr[flist].values)\n        Xte['kmeans_cluster_'+str(ncl)] = cls.predict(Xte[flist].values)\n        flist_kmeans.append('kmeans_cluster_'+str(ncl))\n    print(flist_kmeans)\n    \n    return X_Tr,Xte","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bba2ea791874effd662d169b63682f5ef05d912"},"cell_type":"markdown","source":"### PCA"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fe761a131a937410a81894afca3fb0a63950ba1e"},"cell_type":"code","source":"def pca(X_Tr,Xte):\n    flist = [x for x in X_Tr.columns if not x in ['ID','target']]\n    n_components = 20\n    flist_pca = []\n    pca = PCA(n_components=n_components)\n    x_train_projected = pca.fit_transform(StandardScaler(X_Tr[flist], axis=0))\n    x_test_projected = pca.transform(StandardScaler(X_test[flist], axis=0))\n    for npca in range(0, n_components):\n        X_Tr.insert(1, 'PCA_'+str(npca+1), x_train_projected[:, npca])\n        Xte.insert(1, 'PCA_'+str(npca+1), x_test_projected[:, npca])\n        flist_pca.append('PCA_'+str(npca+1))\n    print(flist_pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa166293adb8196a46a6b6700d7e3ec7857f84d9"},"cell_type":"code","source":"print('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b39a986df78d2ed2f9127400511c3a02234b9da7"},"cell_type":"code","source":"PERC_TRESHOLD = 0.98   ### Percentage of zeros in each feature ###\nN_COMP = 97            ### Number of decomposition components ###\n\nprint(\"\\nStart decomposition process...\")\nprint(\"PCA\")\npca = PCA(n_components=N_COMP, random_state=17)\npca_results_train = pca.fit_transform(X_train)\npca_results_test = pca.transform(X_test)\nprint(pca.explained_variance_ratio_)\n\nprint(\"tSVD\")\ntsvd = TruncatedSVD(n_components=N_COMP, random_state=17)\ntsvd_results_train = tsvd.fit_transform(X_train)\ntsvd_results_test = tsvd.transform(X_test)\n\nprint(\"ICA\")\nica = FastICA(n_components=N_COMP, random_state=17)\nica_results_train = ica.fit_transform(X_train)\nica_results_test = ica.transform(X_test)\n\nprint(\"GRP\")\ngrp = GaussianRandomProjection(n_components=N_COMP, eps=0.1, random_state=17)\ngrp_results_train = grp.fit_transform(X_train)\ngrp_results_test = grp.transform(X_test)\n\nprint(\"SRP\")\nsrp = SparseRandomProjection(n_components=N_COMP, dense_output=True, random_state=17)\nsrp_results_train = srp.fit_transform(X_train)\nsrp_results_test = srp.transform(X_test)\n\nprint(\"Append decomposition components to datasets...\")\nfor i in range(1, N_COMP + 1):\n    X_train['pca_' + str(i)] = pca_results_train[:, i - 1]\n    X_test['pca_' + str(i)] = pca_results_test[:, i - 1]\n    \n    X_train['ica_' + str(i)] = ica_results_train[:, i - 1]\n    X_test['ica_' + str(i)] = ica_results_test[:, i - 1]\n\n    X_train['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n    X_test['tsvd_' + str(i)] = tsvd_results_test[:, i - 1]\n\n    X_train['grp_' + str(i)] = grp_results_train[:, i - 1]\n    X_test['grp_' + str(i)] = grp_results_test[:, i - 1]\n\n    X_train['srp_' + str(i)] = srp_results_train[:, i - 1]\n    X_test['srp_' + str(i)] = srp_results_test[:, i - 1]\nprint('\\nTrain shape: {}\\nTest shape: {}'.format(X_train.shape, X_test.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64a1ade7100a9b401d60e1cc6ac0a4c6092187e3"},"cell_type":"code","source":"print(tsvd.explained_variance_ratio_)\nsum1 = 0\nfor i in range(len(tsvd.explained_variance_ratio_)):\n    sum1 = sum1 + tsvd.explained_variance_ratio_[i]\n\nprint(sum1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93ed0e5d83964102334f821160bd4b165115364e"},"cell_type":"code","source":"sum = 0\nfor i in range(len(pca.explained_variance_ratio_)):\n    sum = sum + pca.explained_variance_ratio_[i]\n\nprint(sum)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eba058002a23a7798abe7523ba5a1735904bb600"},"cell_type":"markdown","source":"## Build models"},{"metadata":{"_uuid":"f4623ebaa4b34c407125b2d3144c1591903d0bf8"},"cell_type":"markdown","source":"### LightGBM"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2ca46bf1983658d14912188e6aa4e60b8c8d682b"},"cell_type":"code","source":"def run_lgb(train_X, train_y, val_X, val_y, test_X):\n    params = {\n    'task': 'train',\n    'boosting_type': 'dart',\n    'objective': 'regression',\n    'metric': 'rmse',\n    \"learning_rate\": 0.01,\n    \"num_leaves\": 200,\n    \"feature_fraction\": 0.50,\n    \"bagging_fraction\": 0.50,\n    'bagging_freq': 4,\n    \"max_depth\": -1,\n    \"reg_alpha\": 0.3,\n    \"reg_lambda\": 0.1,\n    #\"min_split_gain\":0.2,\n    \"min_child_weight\":10,\n    'zero_as_missing':True\n}\n    \n#     {'learning_rate':0.008,\n#         'boosting_type':'gbdt',\n#         'objective':'regression',\n#         'metric':'rmse',\n#         'sub_feature':0.5,\n#         'num_leaves':180,\n#         'feature_fraction': 0.5,\n#         'bagging_fraction': 0.5,\n#         'min_data':50,\n#         'max_depth':-1,\n#         'reg_alpha': 0.3, \n#         'reg_lambda': 0.1, \n#         'min_child_weight': 10, \n#         'verbose': 1,\n#         'nthread':5,\n#         'max_bin':512,\n#         'subsample_for_bin':200,\n#         'min_split_gain':0.0001,\n#         'min_child_samples':5\n#        }\n\n\n#     {\n#         \"objective\" : \"regression\",\n#         \"metric\" : \"rmse\",\n#         \"num_leaves\" : 40,\n#         \"learning_rate\" : 0.005,\n#         \"bagging_fraction\" : 0.7,\n#         \"feature_fraction\" : 0.5,\n#         \"bagging_frequency\" : 5,\n#         \"bagging_seed\" : 42,\n#         \"verbosity\" : -1,\n#         \"random_seed\": 42\n#     }\n#     {\n#     'task': 'train',\n#     'boosting_type': 'dart',\n#     'objective': 'regression',\n#     'metric': 'rmse',\n#     \"learning_rate\": 0.01, # Try 0.05\n#     \"num_leaves\": 200, # 24\n#     \"feature_fraction\": 0.50, \n#     \"bagging_fraction\": 0.90,\n#     'bagging_freq': 4,\n#     \"max_depth\": -1,\n#     \"reg_alpha\": 0.3,\n#     \"reg_lambda\": 0.1,\n#     #\"min_split_gain\":0.2,\n#     \"min_child_weight\":10,\n#     'zero_as_missing':True\n#     'nthread': 32,\n#     'lambda_l1':0.1, \n#     'lambda_l2':0.1,\n    \n    \n# }\n    \n    lgtrain = lgb.Dataset(train_X, label=train_y)\n    lgval = lgb.Dataset(val_X, label=val_y)\n    evals_result = {}\n    model = lgb.train(params, lgtrain, 5000, \n                      valid_sets=[lgval], \n                      early_stopping_rounds=100, \n                      verbose_eval=50, \n                      evals_result=evals_result)\n    \n    pred_test_y = np.expm1(model.predict(test_X, num_iteration=model.best_iteration))\n    return pred_test_y, model, evals_result","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0042ea666373d552a73f8a53515976111cff41e4"},"cell_type":"markdown","source":"### XGboost"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"99b3fdc0f20054c055453817d0f086b3445a87bc"},"cell_type":"code","source":"def run_xgb(train_X, train_y, val_X, val_y, test_X):\n    params = {'objective': 'reg:linear', 'eval_metric': 'rmse', 'eta': 0.005, 'max_depth': 10, 'subsample': 0.7, 'colsample_bytree': 0.5, 'alpha':0, 'silent': True, 'random_state':5}\n# {'objective': 'reg:linear','eval_metric': 'rmse','eta': 0.005,'max_depth': 15,'subsample': 0.7,'colsample_bytree': 0.5,'alpha':0,'random_state':42,'silent': True}\n    \n    tr_data = xgb.DMatrix(train_X, train_y)\n    va_data = xgb.DMatrix(val_X, val_y)\n    \n    watchlist = [(tr_data, 'train'), (va_data, 'valid')]\n    \n    model_xgb = xgb.train(params, tr_data, 2000, watchlist, maximize=False, early_stopping_rounds = 30, verbose_eval=100)\n    \n    dtest = xgb.DMatrix(test_X)\n    xgb_pred_y = np.expm1(model_xgb.predict(dtest, ntree_limit=model_xgb.best_ntree_limit))\n    \n    return xgb_pred_y, model_xgb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2c97a10f22ee74de966f77fed20aec5898da30a"},"cell_type":"markdown","source":"### Training "},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"7464fe72d2d16fdbe531f8db9ec8cc059339782e"},"cell_type":"code","source":"#Split data\ndev_X, val_X, dev_y, val_y = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)\n\n\n# Training LGB\npred_test, model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y, X_test)\nprint(\"LightGBM Training Completed...\")\n\nprint(\"Features Importance...\")\ngain = model.feature_importance('gain')\nfeatureimp = pd.DataFrame({'feature':model.feature_name(), \n                   'split':model.feature_importance('split'), \n                   'gain':100 * gain / gain.sum()}).sort_values('gain', ascending=False)\nprint(featureimp[:15])\n\n# Training XGB\npred_test_xgb, model_xgb = run_xgb(dev_X, dev_y, val_X, val_y, X_test)\nprint(\"XGB Training Completed...\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74fed90476b39616c6c0a31b7da4092319b9b657"},"cell_type":"markdown","source":"### Create file with submissions"},{"metadata":{"trusted":true,"_uuid":"5067817cb22853c8493fa52acd6caabdafb7d7d1"},"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')\n\nsub_lgb = pd.DataFrame()\nsub_lgb[\"target\"] = pred_test\nsub_lgb[\"ID\"] = sub[\"ID\"]\nsub_lgb.to_csv(\"sub_lgb.csv\", index=False)\n\nsub_xgb = pd.DataFrame()\nsub_xgb[\"target\"] = pred_test_xgb\nsub_xgb[\"ID\"] = sub[\"ID\"]\nsub_lgb.to_csv(\"sub_xgb.csv\", index=False)\n\n\nsub[\"target\"] = (sub_lgb[\"target\"] + sub_xgb[\"target\"] )/2\n\nprint(sub.head())\nsub.to_csv('sub_lgb_xgb.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d721c23b194f32f7057f4c88b01d1930f29575b4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"03f72468e253921dc9c277482e52d1413b7b2e39"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}