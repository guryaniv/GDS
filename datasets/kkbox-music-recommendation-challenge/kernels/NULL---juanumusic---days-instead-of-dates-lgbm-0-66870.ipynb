{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.1", "pygments_lexer": "ipython3", "name": "python", "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python"}}, "cells": [{"metadata": {}, "cell_type": "markdown", "source": ["# Days instead of Dates\n", "On this notebook I will show you how I improve the score by replacing date data, and converting it into number of days.\n", "In this case specifically I will use ALL the fields on the datasets, but only replace the **expiration_date** and **registration_init_time** fields by calculating the difference in days between the two dates.\n", "\n", "$$ expiration\\_date - registration\\_init\\_time = membership\\_days$$\n", "\n", "## Acknowledgements:\n", "This notebook is primarily based on the grate [TalySacc's Script](https://www.kaggle.com/talysacc/simple-lgbm-starter-with-3-fold-cv-lb-0-65249). The modifications are mainly for make understanding easier. I also tried to comment the code as much as I could."]}, {"metadata": {}, "cell_type": "markdown", "source": ["# Settings\n", "This cell contains the main settings for the notebook."]}, {"execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# This value stores the path where all the input data is stored. \n", "# This is in case you run the notebook on your local computer.\n", "INPUT_DATA_PATH = '../input/'"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["#  Libraries Import\n", "First, we will import the required libraries."]}, {"execution_count": null, "metadata": {"_cell_guid": "2889c032-26b8-4fcb-9e85-820dec22e389", "_uuid": "5a05c399dce033e4fc3d6e4cc46d18e32e14bc22", "collapsed": true}, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# SKLEARN\n", "from sklearn.model_selection import KFold\n", "from sklearn.metrics import log_loss\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["# Read datasets\n", "Next we read all the datasets into dataframes."]}, {"execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": ["\n", "df_test = pd.read_csv(INPUT_DATA_PATH + 'test.csv',dtype={'msno' : 'category',\n", "                                                'source_system_tab' : 'category',\n", "                                                'source_screen_name' : 'category',\n", "                                                'source_type' : 'category',\n", "                                                'song_id' : 'category'})\n", "\n", "df_train = pd.read_csv(INPUT_DATA_PATH + 'train.csv',dtype={'msno' : 'category',\n", "                                                 'source_system_tab' : 'category',\n", "                                                  'source_screen_name' : 'category',\n", "                                                  'source_type' : 'category',\n", "                                                  'target' : np.uint8,\n", "                                                  'song_id' : 'category'})\n", "\n", "df_members = pd.read_csv(INPUT_DATA_PATH + 'members.csv',dtype={'city' : 'category',\n", "                                                      'bd' : np.uint8,\n", "                                                      'gender' : 'category',\n", "                                                      'registered_via' : 'category'},\n", "                                                      parse_dates=['registration_init_time','expiration_date'])\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["# Convert dates to number of days\n", "### $ expiration\\_date - registration\\_init\\_time = membership\\_days$\n", "This is the part where we will convert the dates into days, by calculating the total membership days."]}, {"execution_count": null, "metadata": {"_cell_guid": "d677d32e-ffe6-46f0-837d-6f812187a9ca", "_uuid": "4eacd12508233d07a8a278595f677f36e021c409", "collapsed": true}, "cell_type": "code", "source": ["# Convert date to number of days\n", "df_members['membership_days'] = (df_members['expiration_date'] - df_members['registration_init_time']).dt.days.astype(int)\n", "\n", "# Remove both date fieldsa since we already have the number of days between them\n", "df_members = df_members.drop(['registration_init_time','expiration_date'], axis=1)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["# Merge Dataframes\n", "Let's merge all the data into the test and train dataframes"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Members\n", "We will now merge the test and train dataframes with the members dataframe."]}, {"execution_count": null, "metadata": {"_cell_guid": "8d2cf342-5688-42e9-b697-164c4127e0a2", "_uuid": "d0222f14fb9a32596d640e130e87a2fe83f9a685", "collapsed": true}, "cell_type": "code", "source": ["# Merge the members dataframe into the test dataframe\n", "df_test = pd.merge(left = df_test,right = df_members,how='left',on='msno')\n", "df_test.msno = df_test.msno.astype('category')\n", "\n", "# Merge the member dataframe into the train dataframe\n", "df_train = pd.merge(left = df_train,right = df_members,how='left',on='msno')\n", "df_train.msno = df_train.msno.astype('category')\n", "\n", "# Release memory\n", "del df_members"], "outputs": []}, {"metadata": {"collapsed": true}, "cell_type": "markdown", "source": ["## Songs\n", "Now we will merge the songs dataframe into the test and train dataframes."]}, {"execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# Load the songs dataframe\n", "df_songs = pd.read_csv(INPUT_DATA_PATH + 'songs.csv',dtype={'genre_ids': 'category',\n", "                                                  'language' : 'category',\n", "                                                  'artist_name' : 'category',\n", "                                                  'composer' : 'category',\n", "                                                  'lyricist' : 'category',\n", "                                                  'song_id' : 'category'})\n", "\n", "# Merge the Test Dataframe with the SONGS dataframe\n", "df_test = pd.merge(left = df_test,right = df_songs,how = 'left',on='song_id')\n", "df_test.song_length.fillna(200000,inplace=True)\n", "df_test.song_length = df_test.song_length.astype(np.uint32)\n", "df_test.song_id = df_test.song_id.astype('category')\n", "\n", "# Merge the Train dataframe with the SONGS dataframe\n", "df_train = pd.merge(left = df_train,right = df_songs,how = 'left',on='song_id')\n", "df_train.song_length.fillna(200000,inplace=True)\n", "df_train.song_length = df_train.song_length.astype(np.uint32)\n", "df_train.song_id = df_train.song_id.astype('category')\n", "\n", "# Release memory\n", "del df_songs"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["# LightGBM\n", "Finally, we create the model, train it, and make the final predictions."]}, {"execution_count": null, "metadata": {}, "cell_type": "code", "source": ["import lightgbm as lgb\n", "\n", "# Create a Cross Validation with 3 splits\n", "kf = KFold(n_splits=3)\n", "\n", "# This array will store the predictions made.\n", "predictions = np.zeros(shape=[len(df_test)])\n", "\n", "# For each KFold\n", "for train_indices ,validate_indices in kf.split(df_train) : \n", "    train_data = lgb.Dataset(df_train.drop(['target'],axis=1).loc[train_indices,:],label=df_train.loc[train_indices,'target'])\n", "    val_data = lgb.Dataset(df_train.drop(['target'],axis=1).loc[validate_indices,:],label=df_train.loc[validate_indices,'target'])\n", "    \n", "    # Create the parameters for LGBM\n", "    params = {\n", "        'objective': 'binary',\n", "        'metric': 'binary_logloss',\n", "        'boosting': 'gbdt',\n", "        'learning_rate': 0.1 ,\n", "        'verbose': 0,\n", "        'num_leaves': 108,\n", "        'bagging_fraction': 0.95,\n", "        'bagging_freq': 1,\n", "        'bagging_seed': 1,\n", "        'feature_fraction': 0.9,\n", "        'feature_fraction_seed': 1,\n", "        'max_bin': 128,\n", "        'max_depth': 10,\n", "        'num_rounds': 200,\n", "        'metric' : 'auc',\n", "        } \n", "    \n", "    # Train the model\n", "    bst = lgb.train(params, train_data, 100, valid_sets=[val_data])\n", "    \n", "    # Make the predictions storing them on the predictions array\n", "    predictions += bst.predict(df_test.drop(['id'],axis=1))\n", "    \n", "    # Release the model from memory for the next iteration\n", "    del bst\n", "\n", "print('Training process finished. Generating Output...')\n", "\n", "# We get the ammount of predictions from the prediction list, by dividing the predictions by the number of Kfolds.\n", "predictions = predictions/3\n", "\n", "# Read the sample_submission CSV\n", "submission = pd.read_csv(INPUT_DATA_PATH + '/sample_submission.csv')\n", "# Set the target to our predictions\n", "submission.target=predictions\n", "# Save the submission file\n", "submission.to_csv('submission.csv',index=False)\n", "\n", "print('Output created.')"], "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": [], "outputs": []}], "nbformat": 4, "nbformat_minor": 1}