{"cells":[{"metadata":{"_uuid":"c6405a9ba97dc7bfae5437fea9ae4943ccd0cb55"},"cell_type":"raw","source":""},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport os; \nos.environ['OMP_NUM_THREADS'] = '4'\nos.environ['TF_CPP_MIN_LOG_LEVEL']='2'  ## To deactivate  Warnings\nimport sys\nimport tensorflow as tf\nimport numpy as np\nimport shutil\nimport pandas as pd\n\nprint(tf.__version__)\nassert tf.__version__ >= \"1.8\" or tf.__version__ >= \"1.10\"\ntf.logging.set_verbosity(tf.logging.INFO)\n\n# List the CSV columns\nCSV_COLUMNS = ['fare_amount', 'pickup_datetime','pickup_longitude','pickup_latitude',\n               'dropoff_longitude','dropoff_latitude', 'passenger_count', 'key']\n\n#Choose which column is your label\nLABEL_COLUMN = 'fare_amount'\nTRAIN_LINES = 55423856\n#import os\n#print(os.listdir(\"../input\"))\nDEBUG=False\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41690bb0b2e4fe9a2429efd13f517c194d1641e2"},"cell_type":"code","source":"from contextlib import contextmanager\nimport time\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    yield\n    print(f'[{name}] done in {time.time() - t0:.0f} s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d316db9def3e86baeb1830b6dd70a47e843aa5c"},"cell_type":"code","source":"#This is just to have a look at the data\nPATH = '../input'\ntrain_df = pd.read_csv(f'{PATH}/train.csv', nrows=10000)\ntrain_df['distance'] = np.sqrt(np.abs(train_df['pickup_longitude']-train_df['dropoff_longitude'])**2 +\n                        np.abs(train_df['pickup_latitude']-train_df['dropoff_latitude'])**2)\ntrain_df.head()\ntrain_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"973ceacc4cd789f6ad067e6b2842e7b7898828a1"},"cell_type":"code","source":"BATCH_SIZE=1 #Filtering works only with size 1 batches!!\ndataset = tf.contrib.data.make_csv_dataset(\n    file_pattern=f'{PATH}/train.csv',\n    batch_size=BATCH_SIZE,\n    column_names=None,\n    column_defaults=None,\n    label_name='fare_amount',\n    select_columns=[1, 2, 3, 4, 5, 6, 7],\n    field_delim=',',\n    use_quote_delim=True,\n    na_value='',\n    header=True,\n    num_epochs=None,\n    shuffle=True,\n    shuffle_buffer_size=10000,\n    shuffle_seed=None,\n    prefetch_buffer_size=1,\n    num_parallel_reads=1,\n    sloppy=False,\n    num_rows_for_inference=100\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9a4c231b1f84135c399539731e2f0f349aabc13"},"cell_type":"code","source":"def filter_data(features, label=None):\n#    label = tf.Print(label, [label], \"Filtering...\", first_n=1,)\n    val = tf.greater(label , tf.constant(20.0, tf.float32))\n    return True\nif DEBUG:\n    dataset = dataset.filter(filter_data)\n    next_element = dataset.make_one_shot_iterator().get_next()\n    with tf.Session() as sess:\n        features, label = sess.run(next_element)\n        print(\"Features:\\n\", features, \"\\n\\nLabel:\\n\", label)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"227a11c9cb10a34d769700835e9aaf1450e356f0"},"cell_type":"code","source":"def pd_weekDay(year, month, day):\n    df = pd.DataFrame({'year': year,\n                       'month': month,\n                       'day': day})\n    date_df = pd.to_datetime(df)\n    return date_df.dt.weekday.astype(np.int32)\n\ndef pd_dayofYear(year, month, day):\n    df = pd.DataFrame({'year': year,\n                       'month': month,\n                       'day': day})\n    date_df = pd.to_datetime(df)\n    return date_df.dt.dayofyear.astype(np.int32)\n\nif DEBUG:\n    years=np.array([2018, 2018, 2018])\n    months=np.array([8, 11, 1])\n    days=np.array([20, 6, 8])\n    print(pd_dayofYear(years, months, days))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b5861b03d73807440be8ce218f748208c199476"},"cell_type":"code","source":"nyccenter = tf.constant([-74.0063889, 40.7141667])\n\n# county\nNassau = (-73.5594, 40.6546)\nSuffolk = (-72.6151, 40.9849)\nWestchester = (-73.7949, 41.1220)\nRockland = (-73.9830, 41.1489)\nDutchess = (-73.7478, 41.7784)\nOrange = (-74.3118, 41.3912)\nPutnam = (-73.7949, 41.4351) \n\ndef outer_product(x, y, x1, y1, x2, y2):\n#    x = tf.Print(x, [x, y, x1, y1, x2, y2])\n    outer_product = (x-x1)*(y2-y1)-(y-y1)*(x2-x1)\n    return outer_product\n\ndef river_side(x, y, river_name='EAS'):\n    if river_name=='EAS': # East River\n        river_line = tf.constant([-74.07, 40.6, -73.84, 40.9])\n    elif river_name=='HUD': # East River\n        river_line = tf.constant([-74.0356, 40.6868, -73.9338, 40.8823])\n    else:\n        raise ValueError( f'Unknown NYC River {river_name}' )\n    tf.reshape(river_line, [1,4])\n    if DEBUG:\n        print(x,y, river_line)\n    side = tf.sign(outer_product(x, y, river_line[0], river_line[1], river_line[2], river_line[3]))\n    return side\n\ndef distance_from_loc(x, y, x1, y1):\n    '''Euclidean Distance between location (x,y) and Tensor of locations (x1,y1)'''\n    return ( tf.sqrt(tf.abs(x1-x)**2 + tf.abs(y1-y)**2) )\n\ndef angle_from_nyc(x, y):\n    x1 = x - nyccenter[0]\n    y1 = y - nyccenter[1]\n    angle = tf.atan2(y1, x1)\n    return angle\n    \nif DEBUG:\n    long=np.array([-73.94, -73.95, -73.96])\n    lat=np.array([40.7613, 40.7613, 40.7613])\n    side = river_side(long, lat, river_name='EAS')\n    with tf.Session() as sess:\n        result = sess.run(side)\n        print(\"Side:\\n\", result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6951ccbd7cb40912a67a66b0ef1aa3043fcc399c"},"cell_type":"code","source":"def tf_isAirport(latitude,longitude,airport_name='JFK'):\n    jfkcoord = tf.constant([-73.8352, -73.7401, 40.6195, 40.6659])\n    ewrcoord = tf.constant([-74.1925, -74.1531, 40.6700, 40.7081])\n    lgucoord = tf.constant([-73.8895, -73.8550, 40.7664, 40.7931])\n    if airport_name=='JFK':\n        coord = jfkcoord\n    elif airport_name=='EWR':\n        coord = ewrcoord\n    elif airport_name=='LGU':\n        coord = lgucoord\n    else:\n        raise ValueError( f'Unknown NYC Airport {airport_name}' )\n        \n    is_airport = \\\n    tf.logical_and(\n        tf.logical_and(\n            tf.greater(longitude, coord[0]), tf.less(longitude, coord[1])\n        ),\n        tf.logical_and(\n            tf.greater(latitude, coord[2]), tf.less(latitude, coord[3])\n        )\n    )\n    return is_airport\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"930d90d91583479c0613eb91f8150e02ddf525ec"},"cell_type":"code","source":"def feat_eng_func(features, label=None):\n    print(\"Feature Engineered Label:\", label)\n    #New features based on pickup datetime\n    features['pickup_year'] = tf.string_to_number(tf.substr(features['pickup_datetime'], 0, 4), tf.int32)\n    features['pickup_month'] = tf.string_to_number(tf.substr(features['pickup_datetime'], 5, 2), tf.int32)\n    features['pickup_day'] = tf.string_to_number(tf.substr(features['pickup_datetime'], 8, 2), tf.int32)\n    features['pickup_hour'] = tf.string_to_number(tf.substr(features['pickup_datetime'], 11, 2), tf.int32)\n    #TODO is there an easy way to perform below functions using TF APIs?\n    features['pickup_weekday'] = tf.py_func(pd_weekDay,\n                                            [features['pickup_year'], features['pickup_month'], features['pickup_day']],\n                                            tf.int32,\n                                            stateful=False,\n                                            name='Weekday'\n                                           )\n    #no advantage features['pickup_dayofyear'] = tf.cast(features['pickup_month'] * 31 + features['pickup_day'], tf.int32 ) #not precise, but good enough\n    #Normalize year and add decimals for months. This is because fares increase with time\n    features['pickup_dense_year'] = (\n                tf.cast(features['pickup_year'], tf.float32) + \\\n                tf.cast(features['pickup_month'], tf.float32) / tf.constant(12.0, tf.float32) -  \\\n                 tf.constant(2009.0, tf.float32) ) /  \\\n                 tf.constant(6.0, tf.float32) \n    features['night'] = tf.cast(\n        tf.logical_or( tf.greater(features['pickup_hour'], 19),  tf.less(features['pickup_hour'], 7)),\n        tf.float32)\n    #Clip latitudes and longitudes\n    minlat = tf.constant(38.0)\n    maxlat = tf.constant(42.0)\n    minlon = tf.constant(-76.0)\n    maxlon = tf.constant(-72.0)\n    features['pickup_longitude'] = tf.clip_by_value(features['pickup_longitude'], minlon, maxlon)\n    features['pickup_latitude'] = tf.clip_by_value(features['pickup_latitude'], minlat, maxlat)\n    features['dropoff_longitude'] = tf.clip_by_value(features['dropoff_longitude'], minlon, maxlon)\n    features['dropoff_latitude'] = tf.clip_by_value(features['dropoff_latitude'], minlat, maxlat)\n    #Clip (normalize passengers didn't work?)\n    minpass = tf.constant(1.0)\n    maxpass = tf.constant(6.0)\n    features['passenger_count'] = tf.clip_by_value(tf.cast(features['passenger_count'], tf.float32), minpass, maxpass)\n    #Clip fare_amount\n    #TODO normalize or tf.log the fare_amount\n    if label != None:\n        minfare = tf.constant(3.0)\n        maxfare = tf.constant(300.0)\n        label = tf.clip_by_value(label,  minfare, maxfare) \n    #TODO feature for bridge passing\n    #TODO new feature for distance and angle from city center\n    #New features based on pickup and dropoff position\n    features['longitude_dist'] = tf.abs(features['pickup_longitude'] - features['dropoff_longitude'])\n    features['latitude_dist'] = tf.abs(features['pickup_latitude'] - features['dropoff_latitude'])\n    #compute euclidean distance of the trip (multiply by 10 to slightly normalize)\n    features['distance'] = tf.sqrt(features['longitude_dist']**2 + features['latitude_dist']**2)\n    features['pick_dist_center'] = distance_from_loc(nyccenter[0], nyccenter[1], \n                                                     features['pickup_longitude'], features['pickup_latitude'])\n    features['drop_dist_center'] = distance_from_loc(nyccenter[0], nyccenter[1], \n                                                     features['dropoff_longitude'], features['dropoff_latitude'])\n    features['pick_angle'] = angle_from_nyc(features['pickup_longitude'],features['pickup_latitude'])\n    features['drop_angle'] = angle_from_nyc(features['dropoff_longitude'],features['dropoff_latitude'])\n    features['angle'] = features['pick_angle'] - features['drop_angle']\n#    features['ortdistance'] = features['longitude_dist'] + features['latitude_dist']\n#    long_distance = tf.constant(0.7)\n#    features['is_long_distance'] = tf.less(long_distance, features['distance'])\n#    features['is_JFK_pickup'] = tf_isAirport(features['pickup_latitude'], \n#                                             features['pickup_longitude'],\n#                                             airport_name='JFK')\n#    features['is_JFK_dropoff'] = tf_isAirport(features['dropoff_latitude'], \n#                                             features['dropoff_longitude'],\n#                                             airport_name='JFK')\n#    features['is_EWR_pickup'] = tf_isAirport(features['pickup_latitude'], \n#                                             features['pickup_longitude'],\n#                                             airport_name='EWR')\n#    features['is_EWR_dropoff'] = tf_isAirport(features['dropoff_latitude'], \n#                                             features['dropoff_longitude'],\n#                                             airport_name='EWR')\n#    features['is_LGU_pickup'] = tf_isAirport(features['pickup_latitude'], \n#                                             features['pickup_longitude'],\n#                                             airport_name='LGU')\n#    features['is_LGU_dropoff'] = tf_isAirport(features['dropoff_latitude'], \n#                                             features['dropoff_longitude'],\n#                                             airport_name='LGU')\n#    features['is_NYC_airport'] = tf.logical_or(\n#        tf.logical_or(\n#            tf.logical_or(features['is_JFK_pickup'], features['is_JFK_dropoff']),\n#            tf.logical_or(features['is_EWR_pickup'], features['is_EWR_dropoff'])),\n#        tf.logical_or(features['is_LGU_pickup'], features['is_LGU_dropoff'])\n#    )\n#    BOOL_COLUMNS = ['is_JFK_pickup', 'is_JFK_dropoff', 'is_EWR_pickup', 'is_EWR_dropoff',\n#                   'is_LGU_pickup', 'is_LGU_dropoff', 'is_NYC_airport' ]\n#    for key in BOOL_COLUMNS:\n#        features[key] = tf.cast(features[key], tf.int32)\n#\n#    features['same_side_EAS'] = tf.equal(river_side(features['pickup_longitude'], features['pickup_latitude'], river_name='EAS'),\n#                                         river_side(features['dropoff_longitude'], features['dropoff_latitude'], river_name='EAS'))\n#    features['same_side_HUD'] = tf.equal(river_side(features['pickup_longitude'], features['pickup_latitude'], river_name='HUD'),\n#                                         river_side(features['dropoff_longitude'], features['dropoff_latitude'], river_name='HUD'))\n#\n\n#    features['pickup_minute'] = tf.substr(features['pickup_datetime'], 14, 2)\n#TODO normalize long and lat\n#TODO remove outliers on passenger_count and fare_amount\n#    print(features)\n    if label == None:\n        return features\n    return (features, label)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Create an input function that stores your data into a dataset\ndef read_dataset(filename, mode, batch_size = 512):\n    def _input_fn():    \n        if mode == tf.estimator.ModeKeys.TRAIN:\n            num_epochs = None # indefinitely\n            shuffle = False\n        else:\n            num_epochs = 1 # end-of-input after this\n            shuffle = False\n\n        if mode == tf.estimator.ModeKeys.PREDICT:\n            label_name=None\n            select_columns=[1, 2, 3, 4, 5, 6]\n        else:\n            label_name ='fare_amount'\n            select_columns = [1, 2, 3, 4, 5, 6, 7]\n\n        # Create list of files that match pattern\n        file_list = tf.gfile.Glob(filename)\n        # Create Dataset from the CSV files\n        dataset = tf.contrib.data.make_csv_dataset(\n            file_pattern=file_list,\n            batch_size=batch_size, #for filtering\n            column_names=None,\n            column_defaults=None,\n            label_name=label_name,\n            select_columns=select_columns,\n            field_delim=',',\n            use_quote_delim=True,\n            na_value='',\n            header=True,\n            num_epochs=num_epochs,\n            shuffle=shuffle,\n            shuffle_buffer_size=128*batch_size,\n            shuffle_seed=None,\n            prefetch_buffer_size=1,\n            num_parallel_reads=1,\n            sloppy=False,\n            num_rows_for_inference=100\n        )\n#This is necessary to split train and eval\n        skip_train_lines = TRAIN_LINES // batch_size // 100 * 10 #skip first 10% lines of train data set\n        if mode == tf.estimator.ModeKeys.TRAIN:\n#        dataset = dataset.filter(filter_data)\n            dataset = dataset.skip(skip_train_lines)\n        elif mode == tf.estimator.ModeKeys.EVAL:\n            dataset = dataset.take(skip_train_lines) \n\n        dataset = dataset.map(feat_eng_func)\n#        dataset = dataset.repeat(3)\n#        dataset = dataset.batch(batch_size)\n        return dataset.make_one_shot_iterator().get_next()\n    return _input_fn\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d06e3f13a201c8dbcb80a8069abbf5f6b8930776"},"cell_type":"code","source":"train_input_fn = read_dataset(f'{PATH}/train.csv', tf.estimator.ModeKeys.EVAL, batch_size = 8)\n#next_element = train_input_fn()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1995703313676a2b5bf642fa2a8874017f260a8","scrolled":true},"cell_type":"code","source":"with timer('Evaluating'):\n    with tf.Session() as sess:\n        features, label = sess.run(train_input_fn())\n        print(\"Features:\\n\", features, \"\\n\\nLabel:\\n\", label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35fc0403cde57b11b4fa0a00879b842ca634e328"},"cell_type":"code","source":"NUMERIC_COLUMNS = ['passenger_count', 'pickup_dense_year', \n                   'longitude_dist', 'latitude_dist',\n                   'distance', 'pick_dist_center', 'drop_dist_center', 'angle',\n                   'pick_angle','drop_angle',\n#                   , 'night'\n                  ]\nBOOL_COLUMNS = ['is_JFK_pickup', 'is_JFK_dropoff', 'is_EWR_pickup', 'is_EWR_dropoff',\n                   'is_LGU_pickup', 'is_LGU_dropoff', 'is_NYC_airport'\n                  ]\n# Define your feature columns\ndef create_feature_cols():\n    hour_cat = tf.feature_column.categorical_column_with_identity('pickup_hour', 24 )\n    weekday_cat = tf.feature_column.categorical_column_with_identity('pickup_weekday', 7)\n    hour_X_weekday = tf.feature_column.crossed_column([hour_cat, weekday_cat], 500)\n    #days_list = range(367)\n    #yearday = tf.feature_column.categorical_column_with_vocabulary_list('pickup_dayofyear', days_list)\n    NUM_BUCKETS = 27\n    long_list = list(np.linspace(-74.2, -73.7, NUM_BUCKETS))\n    lat_list = list(np.linspace(40.55, 41.0, NUM_BUCKETS))\n    p_lon = tf.feature_column.numeric_column('pickup_longitude')\n    p_lat = tf.feature_column.numeric_column('pickup_latitude')\n    d_lon = tf.feature_column.numeric_column('dropoff_longitude')\n    d_lat = tf.feature_column.numeric_column('dropoff_latitude')\n    buck_p_lon = tf.feature_column.bucketized_column(p_lon, long_list)\n    buck_p_lat = tf.feature_column.bucketized_column(p_lat, lat_list)\n    buck_d_lon = tf.feature_column.bucketized_column(d_lon, long_list)\n    buck_d_lat = tf.feature_column.bucketized_column(d_lat, lat_list)\n    X_p = tf.feature_column.crossed_column([buck_p_lon, buck_p_lat], 3*NUM_BUCKETS**2)\n    X_d = tf.feature_column.crossed_column([buck_d_lon, buck_d_lat], 3*NUM_BUCKETS**2)\n    X_loc = tf.feature_column.crossed_column([X_p, X_d], (3*NUM_BUCKETS**2)**2 )\n########################################################################    \n    numeric_columns = [ tf.feature_column.numeric_column(key)\n                       for key in NUMERIC_COLUMNS]\n    other_columns = [tf.feature_column.indicator_column(hour_cat),\n                     tf.feature_column.embedding_column(hour_X_weekday, 2),\n                     tf.feature_column.embedding_column(\n                        tf.feature_column.categorical_column_with_vocabulary_list('pickup_month', (0, 1, 2, 3, 4, 5, 6, \n                                                                                   7, 8, 9, 10, 11, 12)),\n                        2),\n                     tf.feature_column.embedding_column(X_loc, NUM_BUCKETS)\n                    ]\n    return numeric_columns + other_columns\n#[\n#    tf.feature_column.indicator_column(hour_cat),\n#    tf.feature_column.numeric_column('pickup_longitude'),\n#    tf.feature_column.numeric_column('pickup_latitude'),\n#    tf.feature_column.numeric_column('dropoff_longitude'),\n#    tf.feature_column.numeric_column('dropoff_latitude'),\n\n#    tf.feature_column.numeric_column('passenger_count'),\n#    tf.feature_column.numeric_column('pickup_dense_year'),\n#TODO    tf.feature_column.numeric_column('pickup_dayofyear'),\n#    tf.feature_column.embedding_column(yearday, 2),\n#    tf.feature_column.numeric_column('pickup_year'),\n#    tf.feature_column.numeric_column('pickup_month'),\n#    tf.feature_column.numeric_column('pickup_day'),\n    #TODO use embeddings for the hour\n    #tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('pickup_hour', (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n    #                                                                        11, 12, 13, 14, 15, 16, 17, 18,\n    #                                                                         19, 20, 21, 22, 23) )\n    #                                  ),\n    #tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('pickup_weekday', (0, 1, 2, 3, 4, 5, 6)\n    #                                                                                            )),\n#    tf.feature_column.embedding_column(hour_X_weekday, 2),\n#    tf.feature_column.embedding_column(\n#        tf.feature_column.categorical_column_with_vocabulary_list('pickup_month', (0, 1, 2, 3, 4, 5, 6, \n#                                                                                   7, 8, 9, 10, 11, 12)),\n#        2),\n#    tf.feature_column.embedding_column(X_loc, 27), #NUM_BUCKETS\n#    tf.feature_column.numeric_column('longitude_dist'),\n#    tf.feature_column.numeric_column('latitude_dist'),\n#    tf.feature_column.numeric_column('distance'),\n#    tf.feature_column.numeric_column('pick_dist_center'),\n#    tf.feature_column.numeric_column('drop_dist_center'),\n#    tf.feature_column.numeric_column('angle'),\n#    tf.feature_column.numeric_column('pick_angle'),\n#    tf.feature_column.numeric_column('drop_angle'),\n#    tf.feature_column.numeric_column('ortdistance'),\n#    tf.feature_column.numeric_column('same_side_EAS'),\n#    tf.feature_column.numeric_column('same_side_HUD'),\n#    tf.feature_column.numeric_column('is_JFK_pickup'),\n#    tf.feature_column.numeric_column('is_JFK_dropoff'),\n#    tf.feature_column.numeric_column('is_EWR_pickup'),\n#    tf.feature_column.numeric_column('is_EWR_dropoff'),\n#    tf.feature_column.numeric_column('is_LGU_pickup'),\n#    tf.feature_column.numeric_column('is_LGU_dropoff'),\n#    tf.feature_column.numeric_column('is_NYC_airport'),\n#    tf.feature_column.numeric_column('is_long_distance')\n#  ]\n\n# Define your feature columns\ndef create_sparse_feature_cols():\n    bool_columns = [ tf.feature_column.indicator_column(\n                        tf.feature_column.categorical_column_with_identity(key, 2) )\n                    for key in BOOL_COLUMNS]\n    return bool_columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb62dd25e57f512826cead8ad31ec7dd6012a7cd"},"cell_type":"code","source":"feat = create_feature_cols()\nprint(\"Number of features=\", len(feat))\nfeat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5607f77fb81893225f8e731f04d90919d00d2fd9","scrolled":false},"cell_type":"code","source":"BATCH_SIZE = 512\ntrain_input_fn = read_dataset(f'{PATH}/train.csv', tf.estimator.ModeKeys.TRAIN, batch_size = BATCH_SIZE)\neval_input_fn = read_dataset(f'{PATH}/train.csv', tf.estimator.ModeKeys.EVAL, batch_size = BATCH_SIZE)\n# Create estimator train and evaluate function\ndef train_and_evaluate(output_dir, num_train_steps):\n#    estimator = tf.estimator.LinearRegressor(model_dir = output_dir, feature_columns = create_feature_cols())\n    runconfig = tf.estimator.RunConfig(model_dir = OUTDIR, keep_checkpoint_max=1, \n                                   save_summary_steps=25000, log_step_count_steps=25000,\n                                   save_checkpoints_steps=50000,\n                                   tf_random_seed = 42\n                                  )\n    optimizer = tf.contrib.opt.LazyAdamOptimizer(\n    )\n    estimator = tf.estimator.DNNRegressor(model_dir = output_dir, feature_columns = create_feature_cols(),\n                                         hidden_units=[128, 128, 128],\n                                         optimizer=optimizer,\n                                         config=runconfig,\n                                         batch_norm=True,\n                                         loss_reduction = tf.losses.Reduction.SUM_OVER_BATCH_SIZE)\n    train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn, \n                                      max_steps = num_train_steps)\n    eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn, \n                                    steps = None, \n                                    start_delay_secs = 0, # start evaluating after N seconds, \n                                    throttle_secs = 60)  # evaluate every N seconds\n    evaluation, result = tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n    return estimator, evaluation, result\n    \n\nOUTDIR = './trained_model'\nshutil.rmtree(OUTDIR, ignore_errors = True)\nestimator, evaluation, result = train_and_evaluate(OUTDIR, 180000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7394b8ab69057c7131c3761c08e82f923bb8c5ee","scrolled":false,"collapsed":true},"cell_type":"code","source":"if False:\n    BATCH_SIZE = 512\n    OUTDIR = './trained_model'\n    train_input_fn = read_dataset(f'{PATH}/train.csv', tf.estimator.ModeKeys.TRAIN, batch_size = BATCH_SIZE)\n    eval_input_fn = read_dataset(f'{PATH}/train.csv', tf.estimator.ModeKeys.EVAL, batch_size = BATCH_SIZE)\n    shutil.rmtree(OUTDIR, ignore_errors = True)\n    runconfig = tf.estimator.RunConfig(model_dir = OUTDIR, keep_checkpoint_max=1, \n                                   save_summary_steps=2500, log_step_count_steps=2500,\n                                   save_checkpoints_steps=500000,\n                                   tf_random_seed = 42\n                                  )\n    #estimator = tf.estimator.LinearRegressor(model_dir = OUTDIR, feature_columns = create_feature_cols())\n    optimizer = tf.train.FtrlOptimizer(learning_rate=0.05, #default is 0.05\n                                   learning_rate_power=-0.5,\n                                   initial_accumulator_value=0.1,\n                                   l1_regularization_strength=0.0,\n                                   l2_regularization_strength=0.0\n                                  )\n    estimator = tf.estimator.DNNRegressor(model_dir = OUTDIR, feature_columns = create_feature_cols(),\n                                     hidden_units=[128, 128, 128], # 32 OK (43,37, 29: KO)\n#                                     optimizer=optimizer, #'Ftrl', \n                                     batch_norm=True, \n                                     config=runconfig,\n                                     dropout=0.0) \n                                     \n#estimator = tf.estimator.DNNLinearCombinedRegressor(model_dir = OUTDIR, \n#                                                    linear_feature_columns=create_sparse_feature_cols(),\n#                                                    dnn_feature_columns=create_dense_feature_cols(),\n#                                                    dnn_hidden_units=[128, 64, 32, 16],\n#                                                    dnn_dropout=None\n#                                                   )\n    with timer('Training...'):\n        estimator.train(train_input_fn, max_steps=130000)\n    with timer('Evaluating'):\n        evaluation = estimator.evaluate(eval_input_fn, name='train_eval')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0f0b1b2aa59ecaca8479a212fb3bb6859d0a7b1","_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"print(evaluation)\navg_loss = evaluation['average_loss']\npredict_input_fn = read_dataset(f'{PATH}/test.csv', tf.estimator.ModeKeys.PREDICT, batch_size=1)\npredictions = estimator.predict(predict_input_fn)\n\ntest_df = pd.read_csv(f'{PATH}/test.csv', nrows=10000)\n#test_df.head()\n\ns = pd.Series()\nfor i, p in enumerate(predictions):\n    if i < 9915:\n        s.at[i] = p['predictions'][0]\n    else:\n        break\ntest_df['fare_amount'] = s\nsub = test_df[['key', 'fare_amount']]\nsub.to_csv(f'DNNregr-{avg_loss:4.4}.csv', index=False, float_format='%.1f')\n#    print(\"Prediction %s: %s\" % (i + 1, p))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"424ec19726fd2aff6f4da3d3d5f2621bc3220869","collapsed":true},"cell_type":"code","source":"s.describe()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f36f10de598f7e56e65c0fd168f9eabf052a41d0","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}