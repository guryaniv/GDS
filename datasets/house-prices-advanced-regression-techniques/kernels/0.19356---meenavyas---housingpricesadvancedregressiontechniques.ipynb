{"cells":[{"metadata":{"_cell_guid":"8090186a-90c8-471e-8f82-c6e623007dcf","_uuid":"dc85f521eb944e31481bb44359739874708af8af","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom subprocess import check_output\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom scipy.stats import spearmanr, pearsonr\n\n# print list of input files\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# read train.csv\ndfTrainVal=pd.read_csv(\"../input/train.csv\")\nprint(dfTrainVal.head(1))\nprint(\"Train data shape is\",dfTrainVal.shape) # 1460, 81\nprint(\"In training data ID ranges from\", dfTrainVal['Id'].describe()) # min 1 max 1460\n\n# read test.csv\ndfTest=pd.read_csv(\"../input/test.csv\")\nprint(dfTest.head(1))\nprint(\"Test data shape is\",dfTest.shape) # 1459, 80 (there is no 'SalesPrice')\nprint(\"In training data ID ranges from\", dfTest['Id'].describe()) # min 1461, 2919\n\n# We will need this later to split data back\nnumTrainValRecords = dfTrainVal.shape[0]\nnumTestRecords = dfTest.shape[0]\n# save list of IDs in Test data\nidList = dfTest['Id']\n# save Y of train data\nY = dfTrainVal['SalePrice'] # type int64\n# now dfTrainVal contains only X values doesn't contain SalePrice\ndfTrainVal = dfTrainVal.loc[:, dfTrainVal.columns != 'SalePrice']","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"2d6d0de6-6d5b-408f-99bf-fdd0e0d0f33e","scrolled":true,"_uuid":"1ce85973f4f43ec00466c4dc8f3e83e44b73fabb","trusted":true},"cell_type":"code","source":"#### Inspection to find Categorical Data\ndfTrainVal.describe()\nprint(dfTrainVal.describe(exclude=[np.number]))\nprint(dfTrainVal.dtypes)\n# Above comamnds shows that the following are 43 categorical variables :\ncategoricalColumns = [ \"MSZoning\", \"Street\", \"Alley\", \"LotShape\", \"LandContour\", \\\n    \"Utilities\",  \"LotConfig\", \"LandSlope\",   \"Neighborhood\", \"Condition1\", \\\n    \"Condition2\", \"BldgType\", \"HouseStyle\",  \"RoofStyle\", \"RoofMatl\", \\\n    \"Exterior1st\", \"Exterior2nd\", \"MasVnrType\", \"ExterQual\", \"ExterCond\", \\\n    'Foundation', \"KitchenQual\",  'BsmtQual',  'BsmtCond',\"BsmtExposure\", \\\n    \"BsmtFinType1\", \"BsmtFinType2\", \"Heating\", \"HeatingQC\", \"CentralAir\",\\\n    \"Electrical\",  \"Functional\",\"FireplaceQu\",\"GarageType\", \"GarageFinish\",\\\n    \"GarageQual\",\"GarageCond\", \"PavedDrive\",\"PoolQC\", \"Fence\",\\\n    \"MiscFeature\",\"SaleType\", \"SaleCondition\"]\n# there are 2 columns of type float64\ncolumnsOfTypefloat64 = ['LotFrontage', 'MasVnrArea'] \n# there are 29 columns of type int64\ncolumnsOfTypeint64 = [ 'PoolArea', 'GarageArea', 'GrLivArea', 'LotArea',\\\n    'MSSubClass', 'OverallQual', 'OverallCond',  'GarageCars', \\\n    'MiscVal', '3SsnPorch', 'ScreenPorch', 'EnclosedPorch',\\\n    'WoodDeckSF', 'OpenPorchSF', 'Fireplaces',\\\n    'BsmtFullBath', 'BsmtHalfBath',  'FullBath', 'HalfBath', \\\n    'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', \\\n    'BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \\\n    '1stFlrSF', '2ndFlrSF','LowQualFinSF']\n\n# Date related columns: all other are int64 GarageYrBlt is float64\ncolumnsRelatedToDate = [ 'MoSold', 'YrSold', 'YearBuilt', 'YearRemodAdd',  'GarageYrBlt']","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"edb719e9-a731-4477-8f00-90d187edb074","_uuid":"e3d8d803c669d0328cf0764a8f5273c8a896e844","trusted":true},"cell_type":"code","source":"# convert categorical values using one hot encoding\n# refer http://pbpython.com/categorical-encoding.html\ndfCombined = pd.concat([dfTrainVal, dfTest]) \n# now take actions you want to run on both test and train data\n# Do not put in model : \"Id\" column of type int64\ndfCombined.drop(\"Id\", axis=1, inplace=True)\ndfCombined = pd.get_dummies(dfCombined, columns=categoricalColumns, prefix=categoricalColumns)\n# handle missing values\n# refer https://www.kaggle.com/dansbecker/handling-missing-values\nmy_imputer = Imputer()\ndfCombined = my_imputer.fit_transform(dfCombined)\ntargetNames = list(dfCombined)\n#print(target_names)\n# Scaling \nscaler = StandardScaler().fit(dfCombined)\ndfCombined = pd.DataFrame(scaler.transform(dfCombined))\n\n# Split Back test and train data\nX = dfCombined.loc[0:numTrainValRecords-1,]\nprint(\"numTrainValRecords\", numTrainValRecords,\"X has records\", X.shape[0])\nXTest = dfCombined.loc[numTrainValRecords:numTrainValRecords+numTestRecords-1,]\nprint(\"numTestRecords\", numTestRecords,\"XTest has records\", XTest.shape[0])","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"f48ebe9a-ba34-421a-864d-3cb03615e78b","_uuid":"04e0d21d6e412da995d235e389160e71e8fbf45c","trusted":true},"cell_type":"code","source":"# http://www.blopig.com/blog/2017/07/using-random-forests-in-python-with-scikit-learn/\n# simple Random forest\nXtrain, Xval, Ytrain, Yval = train_test_split(X, Y, train_size=0.75, test_size=0.25, \\\n                                              random_state=10)\n\ndef runRF(numEstimators, leaf_size):\n    rf = RandomForestClassifier(n_estimators=numEstimators, oob_score=True, \\\n         n_jobs = -1, max_features = \"auto\", min_samples_leaf = leaf_size, random_state=10)\n    rf.fit(Xtrain, Ytrain)\n    predictedTrain = rf.predict(Xtrain)\n    predictedVal = rf.predict(Xval)\n    accuracy = accuracy_score(Yval, predictedVal)\n    print(\"----------------------------\")\n    print(\"Random Forest with estimators\", numEstimators, \"leaf size\", leaf_size)\n    print(\"----------------------------\")\n    print(f'Mean accuracy score: {accuracy:.3}')\n    test_score = r2_score(Yval, predictedVal)\n    spearman = spearmanr(Yval, predictedVal)\n    pearson = pearsonr(Yval, predictedVal)\n    print(f'Test data R-2 score: {test_score:>5.3} Spearman correlation: {spearman[0]:.3} Pearson correlation: {pearson[0]:.3}')\n    print(f'Out-of-bag score estimate: {rf.oob_score_:.3}') #>5.3\n    predictedTest = rf.predict(XTest)\n    return predictedTest\n\n#sample_leaf_options = [1,5,10,50,100,200,250] # 500\n#estimator_options = [50,100,200,250,500]\n#for leaf_size in sample_leaf_options:\n#    for n_estimator in estimator_options:\n#        predictedTest = runRF(n_estimator, leaf_size)\n# best oob score was with 50 and 50\npredictedTestBest = runRF(50, 50)\n\n#pca_scaled = PCA() #pca = PCA(n_components=20)\n#train_features = pca_scaled.fit_transform(Xtrain, YTrain)\n#test_features = pca.transform(Xval, Yval)\n#x_axis = np.arange(1, pca.n_components_+1)\n#predictedTestPCA = runRF(50, 50)\n","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"09518def-0069-4416-adea-f3ea1994d355","_uuid":"7ab6a52ec40a5f09e6b3083d44af3155bbbe3c96","trusted":true},"cell_type":"code","source":"# Write output to file\nimport csv\nwith open('output.csv', 'w', newline='') as csvfile:\n    fieldnames = ['Id', 'SalePrice']    \n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n    writer.writeheader()\n    for index in range(len(idList)):\n        writer.writerow({'Id': idList[index], 'SalePrice': predictedTestBest[index]})\nprint(\"End\")","execution_count":15,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}