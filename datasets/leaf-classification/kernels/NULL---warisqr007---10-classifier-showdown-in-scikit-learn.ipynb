{"cells":[{"metadata":{"_cell_guid":"3bb42045-03bc-0ca3-36c9-9379444c88b1","_uuid":"c462835a6751b6f9e113c8ecfa208c1e1d8b8594"},"cell_type":"markdown","source":"# Which Classifier Should I Choose? \n\nThis is one of the most import questions to ask when approaching a machine learning problem. I find it easier to just test them all at once. Here's 10 of your favorite Scikit-Learn algorithms applied to the leaf data. ","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"e86aec01-dbc6-4696-e066-6da72fedd092","_uuid":"6cfacfa27461e43bdd2ace6986ae0ed6b7332f13","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef warn(*args, **kwargs): pass\nimport warnings\nwarnings.warn = warn\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cross_validation import StratifiedShuffleSplit\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5de1ab5b-9b22-2375-4705-f6d12e9d3046","_uuid":"2447a8c94d29d023d3a90ff1b0b6e22d3aa596e1"},"cell_type":"markdown","source":"## Data Preparation\n","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"361c2695-95c0-745a-0336-a49f6dec97b2","_uuid":"d4cfb821919c28ccdcaff6072ed358714aaeec5a","trusted":true},"cell_type":"code","source":"# Swiss army knife function to organize the data\n\ndef encode(train, test):\n    le = LabelEncoder().fit(train.species) \n    labels = le.transform(train.species)           # encode species strings\n    classes = list(le.classes_)                    # save column names for submission\n    test_ids = test.id                             # save test ids for submission\n    \n    train = train.drop(['species', 'id'], axis=1)  \n    test = test.drop(['id'], axis=1)\n    \n    return train, labels, test, test_ids, classes\n\ntrain, labels, test, test_ids, classes = encode(train, test)\ntrain.head(1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3222a1a2-6df6-e5a6-2c4d-65383fc9ee66","_uuid":"298142976f95e1b8b86b6bc028a99741f1cbe385"},"cell_type":"markdown","source":"## Stratified Train/Test Split\n\nStratification is necessary for this dataset because there is a relatively large number of classes (100 classes for 990 samples). This will ensure we have all classes represented in both the train and test indices. ","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"7c91b9c9-3b4d-73ac-92d8-db0792f60a3e","_uuid":"1989d05cd0e2a8f2d23642d67f9c4e94c6a08166","trusted":true},"cell_type":"code","source":"sss = StratifiedShuffleSplit(labels, 10, test_size=0.2, random_state=23)\n\nfor train_index, test_index in sss:\n    X_train, X_test = train.values[train_index], train.values[test_index]\n    y_train, y_test = labels[train_index], labels[test_index]\n    \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e1172a79-cdc8-6544-2580-4a58ee9fb434","_uuid":"4a67286a857751c6543b31334e0871ff211988a5"},"cell_type":"markdown","source":"## Sklearn Classifier Showdown\n\nSimply looping through 10 out-of-the box classifiers and printing the results. Obviously, these will perform much better after tuning their hyperparameters, but this gives you a decent ballpark idea. ","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"fb7913b9-e36d-ef8b-a012-cc708b583ab4","_uuid":"a7199df26509ff07c3586b2aeec65c7b5b93cc4f","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    NuSVC(probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis()]\n\n# Logging for Visual Comparison\nlog_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\nlog = pd.DataFrame(columns=log_cols)\n\nfor clf in classifiers:\n    clf.fit(X_train, y_train)\n    name = clf.__class__.__name__\n    \n    print(\"=\"*30)\n    print(name)\n    \n    print('****Results****')\n    train_predictions = clf.predict(X_test)\n    acc = accuracy_score(y_test, train_predictions)\n    print(\"Accuracy: {:.4%}\".format(acc))\n    \n    train_predictions = clf.predict_proba(X_test)\n    ll = log_loss(y_test, train_predictions)\n    print(\"Log Loss: {}\".format(ll))\n    \n    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n    log = log.append(log_entry)\n    \nprint(\"=\"*30)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5d972faa-01b5-f354-155b-9ab11cb9ab63","_uuid":"2e212628c667ca4b395035104cde4da7ae22ce1a","trusted":true},"cell_type":"code","source":"sns.set_color_codes(\"muted\")\nsns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n\nplt.xlabel('Accuracy %')\nplt.title('Classifier Accuracy')\nplt.show()\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x='Log Loss', y='Classifier', data=log, color=\"g\")\n\nplt.xlabel('Log Loss')\nplt.title('Classifier Log Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0f97c983-69ac-486d-b454-f3385f4c9803","_uuid":"b1070c322100f752d7dafdd655bff5e7f54fd6d1"},"cell_type":"markdown","source":"**##Random search for optimal hyperparameters of the SVM classifier**","outputs":[],"execution_count":null},{"metadata":{"scrolled":true,"_cell_guid":"caaedf52-b839-48e3-a0ad-46f4b0e993fe","_uuid":"b92796e4d96eed78a24e8d97a7950cf1a3df0740","trusted":true},"cell_type":"code","source":"import scipy\nfrom sklearn.grid_search import RandomizedSearchCV\nclf = SVC(probability=True, random_state=1)\nparam_grid = {'C': scipy.stats.expon(scale=100), 'gamma': scipy.stats.expon(scale=.1),\n  'kernel': ['rbf'], 'class_weight':['balanced', None]}\nrand_search = RandomizedSearchCV(clf, param_distributions = param_grid, n_iter = 20) \nrand_search.fit(X_train,y_train) \nrand_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"e36053d6-0dff-4072-b2a2-04550cc2fc48","_uuid":"d11e33d8f26d808adb50860c857998f3670c36c0","trusted":true},"cell_type":"code","source":"predr = rand_search.predict(X_test)\nprint(\"Accuracy: {:.4%}\".format(accuracy_score(y_test,predr)))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bbab4ca8-1050-4a40-a17f-6fdbbb58ba12","_uuid":"187349e5636f1072f1c5667ac639d23d9cfecd67"},"cell_type":"markdown","source":"Hyperparameter tuning gives us an accuracy boost of over 1%!!!","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"d6948e0b-fa3f-151d-baf4-a5e12f6fd1ec","_uuid":"94de4774ee06a396e3d9b3ee23e43788376c6da4"},"cell_type":"markdown","source":"## Submission\n\nAfter choosing your favorite classifier, format the output for a leaderboard submission. ","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"e8370e61-ea98-94a6-2b46-99ca7e401e9f","_uuid":"ebb36516c99c92135dfbdb50b32c40cd36329448","trusted":true},"cell_type":"code","source":"# Predict Test Set\nfavorite_clf = SVC(C=13.450385695977566, class_weight='balanced', gamma=0.0043155380191205834,\n kernel='rbf',probability = True, random_state=1)\nfavorite_clf.fit(X_train, y_train)\ntest_predictions = favorite_clf.predict_proba(test)\n\n# Format DataFrame\nsubmission = pd.DataFrame(test_predictions, columns=classes)\nsubmission.insert(0, 'id', test_ids)\nsubmission.reset_index()\n\n# Export Submission\n#submission.to_csv('submission.csv', index = False)\nsubmission.tail()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"_is_fork":false,"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"_change_revision":0},"nbformat":4,"nbformat_minor":1}