{"cells":[{"metadata":{"_uuid":"a9140efecd361c712794bd784d60b413b513b01f"},"cell_type":"markdown","source":"![forest](https://i.imgur.com/3tGpAwL.jpg)\n<h1 align=\"center\">Exploring Roosevelt Natl. Forest Cover Types</h1><br>\nHere's my exploration of this dataset for predicting leaf cover varieties in the Colorado mountains. It's a bit exhaustive as a way of gathering all the information in one place and attempting to consolidate it in a more human-readable fashion. Much of this first section is most likely a reversal of changes previously made to the data set, such as returning dummies to categorical types.\n<h2>Project setup</h2>"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\npd.set_option('display.max_columns', 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dca445c1c29c81e0ee04d3d8e34ca952882f5dd4"},"cell_type":"code","source":"# Set up labels \ncover_types = {\n    1: \"Spruce/Fir\",\n    2: \"Lodgepole Pine\",\n    3: \"Ponderosa Pine\",\n    4: \"Cottonwood/Willow\",\n    5: \"Aspen\",\n    6: \"Douglas-fir\",\n    7: \"Krummholz\"}\nwild_areas = {\n    1: \"Rawah Wilderness Area\",\n    2: \"Neota Wilderness Area\",\n    3: \"Comanche Peak Wilderness Area\",\n    4: \"Cache la Poudre Wilderness Area\"}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3978975a0c8ca3eb703306255bc29c12981453fe"},"cell_type":"markdown","source":"<h2>Read input data files into Pandas dataframes</h2>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"train_raw = pd.read_csv(\"../input/train.csv\")\ntest_raw = pd.read_csv(\"../input/test.csv\")\nsample_submission = pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9a5be86f43758200989ac7a6179746987131da89"},"cell_type":"code","source":"train_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"797150b113836a402890bd2dcdcc3f779b9d4420"},"cell_type":"markdown","source":"<h2>Relabel data for interpretation</h2><br>\nSince the raw dataframe is a little extensive, I'll clean it up for plotting and readability."},{"metadata":{"trusted":false,"_uuid":"d9b59c504993af4a4d15b864018363754614b1c8"},"cell_type":"code","source":"train = train_raw.copy()\ntest = test_raw.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b22add8f64dafd44eae1af1aff333a661966cf33"},"cell_type":"markdown","source":"<h3>Relabel cover types with descriptive values</h3>"},{"metadata":{"trusted":false,"_uuid":"a478fae19abf39ac0d04077597d6215788ead566"},"cell_type":"code","source":"train['Cover_Type'] = train['Cover_Type'].apply(lambda x: cover_types[x])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2dd47e0c042c34c5f9c9ade8ea67391ea956f28c"},"cell_type":"markdown","source":"<h3>Relabel wilderness areas with true names</h3>"},{"metadata":{"trusted":false,"_uuid":"ab793eefdc0090cf3ee6962f5ed04e9506000c23"},"cell_type":"code","source":"df = train[[\"Wilderness_Area1\",\"Wilderness_Area2\",\"Wilderness_Area3\",\"Wilderness_Area4\"]]\ndf = df.idxmax(axis=1)\ntrain[\"Wilderness_Area1\"] = df.apply(lambda x: wild_areas[int(x.split(\"Wilderness_Area\")[1])])\ntrain = train.rename(columns = {\"Wilderness_Area1\": \"Wilderness_Area\"})\ntrain.drop([\"Wilderness_Area2\", \"Wilderness_Area3\", \"Wilderness_Area4\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ce9c8ffc90df550304bd9d1fd2c627be099afc3"},"cell_type":"markdown","source":"<h3>Restructure soil types as categorical column</h3>"},{"metadata":{"trusted":false,"_uuid":"de444513b48b4c82c52766e5d5a0582ca11bd8fc"},"cell_type":"code","source":"train['Soil_Type1'] = train[train.columns[12:52]].idxmax(axis=1)\ntrain = train.rename(columns = {\"Soil_Type1\": \"Soil_Type\"})\ntrain.drop(train.columns[13:52], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f749d7b767bc3449c0b8a943880191e79b12659b"},"cell_type":"code","source":"train.columns = train.columns.str.replace(\"_\", \" \")\ntrain.drop(\"Id\", inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a314c5199163c6caa098c01f956fb9777b3ba9ff"},"cell_type":"markdown","source":"<h2>Inspect newly labeled and organized data</h2>"},{"metadata":{"_uuid":"0e5b39cb4969600771fb256b1209b45353664b28","trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80c51bf0caad5ace3c3f137c99943d657ac7f7db","trusted":false},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"558af74962a8a4a3e0d643b46dfc85b581e88197"},"cell_type":"markdown","source":"<h2>Relabel Test Data</h2> <br>\nHere's all the same (relavant) relabeling done to the test dataframe for later comparison purposes."},{"metadata":{"trusted":false,"_uuid":"7bd41383808d15f0c349fc70d6446b436c76c027"},"cell_type":"code","source":"# Relabel wilderness areas with true names\ndf = test[[\"Wilderness_Area1\",\"Wilderness_Area2\",\"Wilderness_Area3\",\"Wilderness_Area4\"]]\ndf = df.idxmax(axis=1)\ntest[\"Wilderness_Area1\"] = df.apply(lambda x: wild_areas[int(x.split(\"Wilderness_Area\")[1])])\ntest = test.rename(columns = {\"Wilderness_Area1\": \"Wilderness_Area\"})\ntest.drop([\"Wilderness_Area2\", \"Wilderness_Area3\", \"Wilderness_Area4\"], axis=1, inplace=True)\n# Restructure soil types as categorical column\ntest['Soil_Type1'] = test[test.columns[12:52]].idxmax(axis=1)\ntest = test.rename(columns = {\"Soil_Type1\": \"Soil_Type\"})\ntest.drop(test.columns[13:52], inplace=True, axis=1)\ntest.columns = test.columns.str.replace(\"_\", \" \")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"383ba0d7fbbe1852d6eadd4e1ef73e8318ff067a"},"cell_type":"markdown","source":"<h2>Data Visualisation</h2>\n<br>\nLet's look at some plots of the dataset. For some of these we'll have to actually go back to the raw data in order to get the columns in a form that can be graphed properly. "},{"metadata":{"_uuid":"d88d17008dd6a490b342e3c66cd7eba3d59582c2","trusted":false},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"40053b3b8f128a5c7927b7d6ffedebfb7f7691bc"},"cell_type":"code","source":"plt.figure(figsize=(9,4.5))\nsns.countplot(x=\"Cover Type\", data=train)\nplt.xticks(rotation=65)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6062df001fe67d9a816bd2aa87d8d0dfce9b06d"},"cell_type":"markdown","source":"We can see that each cover type is equally represented in the set. Let's look at how they're distributed relative to some of the other variables."},{"metadata":{"trusted":false,"_uuid":"09aaec14ab9b7f567151183dd09635fcb955fbff"},"cell_type":"code","source":"plt.figure(figsize=(9,4.5))\nsns.countplot(x='Cover Type', hue='Wilderness Area', data=train)\nplt.xticks(rotation=65)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41dfd7094500f329247b226c86a235c6cf5ba98c"},"cell_type":"markdown","source":"This plot shows us that there seems to be significant correlation between cover type and wilderness area, and that the Neota Area has a much smaller representation than the others. Let's do one more visualization using the soil types."},{"metadata":{"trusted":false,"_uuid":"775dff3e83441505dfa317e99a90183feba35451"},"cell_type":"code","source":"df = pd.DataFrame(train['Soil Type'].value_counts())   \ndf.reset_index(inplace=True)\ndf.columns = ['Soil Type', 'Soil Count']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"68ce56a83cb4393961415e7105718c5adf615530"},"cell_type":"code","source":"plt.figure(figsize=(25, 7))\nsns.barplot(x='Soil Type', y='Soil Count', data=df)\nplt.xticks(rotation=80)\nsns.set_context(\"notebook\", font_scale=1.5)\nplt.title('Train Soil Types')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52a5c7ab90d353cdc886835af8a57d612b61006d"},"cell_type":"markdown","source":"Now we can see that the most common soil type by far is Soil_Type10, and the least common types are barely represented, if at all. Let's check on those rarer types to see if they have any entries at all."},{"metadata":{"trusted":false,"_uuid":"f13d437dff1db8348dc15d9983c7690d7b00674d"},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"350cf479e14d65f2cd4a0c200e3dd59181b87af3"},"cell_type":"markdown","source":"Ok, there's at least one entry for all soil types, but we should be aware that some of them have very low representation. In order to have good predictions, we'd hope our test data to have similar trends to our training set, so let's take a look at the test set to see the distibution. "},{"metadata":{"trusted":false,"_uuid":"d0df81885e2eed0dcd8dc280c3b57027eb923e78"},"cell_type":"code","source":"df = pd.DataFrame(test['Soil Type'].value_counts())   \ndf.reset_index(inplace=True)\ndf.columns = ['Soil Type', 'Soil Count']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"d120e116a346f3ccae0a0e957bcca1ccbbf5681a"},"cell_type":"code","source":"plt.figure(figsize=(25, 7))\nsns.barplot(x='Soil Type', y='Soil Count', data=df)\nplt.xticks(rotation=80)\nsns.set_context(\"notebook\", font_scale=1.5)\nplt.title('Test Soil Types')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8c42b97d16d32e721606b8163b04fff3b030b2c9"},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a0b06cbc843c7493b27a393bceb9fcd831e00b2"},"cell_type":"markdown","source":"The test data has a very similar distibution of soil types to training. Although the ranking differs for individual types, the similarity seems enough for meaninful usage. In combination with the other features, we'll see how the model overcomes these descrepancies.\n<br>"},{"metadata":{"trusted":false,"_uuid":"32c5dc8dbcb5b569acb3e41c00c2ced789191b5e"},"cell_type":"code","source":"# Save altered data\ntrain1 = train\ntest1 = test\n\n# Reset train and test sets to original states\ntrain = train_raw.copy()\ntest = test_raw.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70859ce231382c90af2e0e93fd90eaec1f14e6eb"},"cell_type":"markdown","source":"## Feature Building\n\nThe data set shows multiple columns of location in relation to certain geographical amenities. By combining these variables we can create new features as a function of distance from these amenities. These new features are likely to have higher importance in our prediction model because they are more specific descriptions than the isolated indicators of location. [Lathwal](https://www.kaggle.com/codename007) has already done this engineering well in [his notebook](https://www.kaggle.com/codename007/forest-cover-type-eda-baseline-model), so I will borrow his new features for use in this model. The next cell is his code."},{"metadata":{"trusted":false,"_uuid":"990eb7136f3a3b2177f13492a4709a6f4439c323"},"cell_type":"code","source":"####################### Train data #############################################\ntrain['HF1'] = train['Horizontal_Distance_To_Hydrology']+train['Horizontal_Distance_To_Fire_Points']\ntrain['HF2'] = abs(train['Horizontal_Distance_To_Hydrology']-train['Horizontal_Distance_To_Fire_Points'])\ntrain['HR1'] = abs(train['Horizontal_Distance_To_Hydrology']+train['Horizontal_Distance_To_Roadways'])\ntrain['HR2'] = abs(train['Horizontal_Distance_To_Hydrology']-train['Horizontal_Distance_To_Roadways'])\ntrain['FR1'] = abs(train['Horizontal_Distance_To_Fire_Points']+train['Horizontal_Distance_To_Roadways'])\ntrain['FR2'] = abs(train['Horizontal_Distance_To_Fire_Points']-train['Horizontal_Distance_To_Roadways'])\ntrain['ele_vert'] = train.Elevation-train.Vertical_Distance_To_Hydrology\n\ntrain['slope_hyd'] = (train['Horizontal_Distance_To_Hydrology']**2+train['Vertical_Distance_To_Hydrology']**2)**0.5\ntrain.slope_hyd=train.slope_hyd.map(lambda x: 0 if np.isinf(x) else x) # remove infinite value if any\n\n#Mean distance to Amenities \ntrain['Mean_Amenities']=(train.Horizontal_Distance_To_Fire_Points + train.Horizontal_Distance_To_Hydrology + train.Horizontal_Distance_To_Roadways) / 3 \n#Mean Distance to Fire and Water \ntrain['Mean_Fire_Hyd']=(train.Horizontal_Distance_To_Fire_Points + train.Horizontal_Distance_To_Hydrology) / 2 \n\n####################### Test data #############################################\ntest['HF1'] = test['Horizontal_Distance_To_Hydrology']+test['Horizontal_Distance_To_Fire_Points']\ntest['HF2'] = abs(test['Horizontal_Distance_To_Hydrology']-test['Horizontal_Distance_To_Fire_Points'])\ntest['HR1'] = abs(test['Horizontal_Distance_To_Hydrology']+test['Horizontal_Distance_To_Roadways'])\ntest['HR2'] = abs(test['Horizontal_Distance_To_Hydrology']-test['Horizontal_Distance_To_Roadways'])\ntest['FR1'] = abs(test['Horizontal_Distance_To_Fire_Points']+test['Horizontal_Distance_To_Roadways'])\ntest['FR2'] = abs(test['Horizontal_Distance_To_Fire_Points']-test['Horizontal_Distance_To_Roadways'])\ntest['ele_vert'] = test.Elevation-test.Vertical_Distance_To_Hydrology\n\ntest['slope_hyd'] = (test['Horizontal_Distance_To_Hydrology']**2+test['Vertical_Distance_To_Hydrology']**2)**0.5\ntest.slope_hyd=test.slope_hyd.map(lambda x: 0 if np.isinf(x) else x) # remove infinite value if any\n\n#Mean distance to Amenities \ntest['Mean_Amenities']=(test.Horizontal_Distance_To_Fire_Points + test.Horizontal_Distance_To_Hydrology + test.Horizontal_Distance_To_Roadways) / 3 \n#Mean Distance to Fire and Water \ntest['Mean_Fire_Hyd']=(test.Horizontal_Distance_To_Fire_Points + test.Horizontal_Distance_To_Hydrology) / 2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"912fee2d390c8bcfff2c54e160a048dcce7ed20e","trusted":false},"cell_type":"code","source":"features = [col for col in train.columns if col not in ['Cover_Type','Id']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df82b2de193a0f8cfb965e922903199d33694c41"},"cell_type":"markdown","source":"## Run Classifier Models"},{"metadata":{"trusted":false,"_uuid":"af966c64e1728119b0e85eb29ff25d976187d8a6"},"cell_type":"code","source":"# Set up test values from the already classified data so that I can test model accuracy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nX_train, X_test, y_train, y_test = train_test_split(train[features], train['Cover_Type'], test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5f655c60af39b9e0a1a75b8e289b31eef15bde09"},"cell_type":"code","source":"predictions = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abfe74c638ef2421c9c05b80f78493714380cc94"},"cell_type":"markdown","source":"### Random Forests\n\nConsidering the source data, Random Forests of decision trees seems like a poetically appropriate model to apply, although it may not be the most functional. Let's see how well it predicts."},{"metadata":{"_uuid":"de6c701772d483c62579ae4fa6bcd5d3675a77d6","trusted":false},"cell_type":"code","source":"# Benefit from n_estimators seems to level out around 1000\n# with n_estimators=500, accuracy=0.78643 (119th place)\n# with n_estimators=750, accuracy=0.78699 (114th place)\n\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=750)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58e85a12261d3669214a02c0f707613ca6189e51","trusted":false},"cell_type":"code","source":"%%time\nrfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57e590e07099b467bbcee55af2295d6464747213","trusted":false},"cell_type":"code","source":"%%time\npredictions['Random Forest'] = rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"efbad53a0494228bc1d3aa72ed6dbffdf98c7a93"},"cell_type":"code","source":"print(classification_report(y_test, predictions['Random Forest']))\nprint(confusion_matrix(y_test, predictions['Random Forest']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abfe74c638ef2421c9c05b80f78493714380cc94"},"cell_type":"markdown","source":"### Extra Trees\n\nAdding in the extra trees classifier will give another model to check against. "},{"metadata":{"_uuid":"de6c701772d483c62579ae4fa6bcd5d3675a77d6","trusted":false},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\netc = RandomForestClassifier(n_estimators=750)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58e85a12261d3669214a02c0f707613ca6189e51","trusted":false},"cell_type":"code","source":"%%time\netc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ad222d756e6aa2f1326e5c7eb022c19a07c14c33"},"cell_type":"code","source":"%%time\npredictions['Extra Trees'] = etc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ed5c6db51f3911ed14d645bf09b16342e7608271"},"cell_type":"code","source":"print(classification_report(y_test, predictions['Extra Trees']))\nprint(confusion_matrix(y_test, predictions['Extra Trees']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abfe74c638ef2421c9c05b80f78493714380cc94"},"cell_type":"markdown","source":"### Gradient Boosting \n\nGradient boosting classifier will give me another model for a vote consensus. "},{"metadata":{"_uuid":"de6c701772d483c62579ae4fa6bcd5d3675a77d6","trusted":false},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\ngbc = AdaBoostClassifier(GradientBoostingClassifier(n_estimators=100), n_estimators=10, learning_rate=.1, algorithm='SAMME')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58e85a12261d3669214a02c0f707613ca6189e51","trusted":false},"cell_type":"code","source":"%%time\ngbc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4f7efb304d3515b4571d427f9fac7e75a740eb14"},"cell_type":"code","source":"%%time\npredictions['Gradient Boosting'] = gbc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e7b8b54d098684e44d97aa982dc3cdf3c7a021e1"},"cell_type":"code","source":"print(classification_report(y_test, predictions['Gradient Boosting']))\nprint(confusion_matrix(y_test, predictions['Gradient Boosting']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abfe74c638ef2421c9c05b80f78493714380cc94"},"cell_type":"markdown","source":"### Ada Boost\n\nI'll also do an Ada boosting classifier on the Extra Trees model, and play with the parameters to squeeze better accuracy out of it."},{"metadata":{"_uuid":"de6c701772d483c62579ae4fa6bcd5d3675a77d6","trusted":false},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nabc = AdaBoostClassifier(ExtraTreesClassifier(n_estimators=500), n_estimators=500, learning_rate=.1, algorithm='SAMME')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58e85a12261d3669214a02c0f707613ca6189e51","trusted":false},"cell_type":"code","source":"%%time\nabc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"738784285015d9853f3bd64fd687de3e323b481d"},"cell_type":"code","source":"%%time\npredictions['Ada Boost'] = abc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9627f62a8ae1779c25718e5bca18b8f6f42a81d2"},"cell_type":"code","source":"print(classification_report(y_test, predictions['Ada Boost']))\nprint(confusion_matrix(y_test, predictions['Ada Boost']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab8bf88c387c1839a8b468761d15ea94aec6179a"},"cell_type":"markdown","source":"## Tally up Votes\n"},{"metadata":{"trusted":false,"_uuid":"45152181c482d668298dfb0eff86cdefada0f186"},"cell_type":"code","source":"predictions.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6487fa8a5480bbd4a6dd493d63c209d9c3a5a15b"},"cell_type":"code","source":"%%time\npred = predictions.mode(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9dbb6a7f6c7a1f6d744f1177ed8f7e2fcbd6f31a"},"cell_type":"code","source":"predictions.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7d2dd2865515cf995d904c0b4c9bf101e05b84fb"},"cell_type":"code","source":"pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5b518ba2297fad1ba1cd7bd01c2be6c1bcd98e2c"},"cell_type":"code","source":"print(classification_report(y_test, pred[0]))\nprint(confusion_matrix(y_test, pred[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cef8a904cf968890bd04cc39ee9edb8460ae1a5"},"cell_type":"markdown","source":"## Get Predictions from Best Model\n\nWhile Random Forests and Extra Trees did pretty well around 89% accuracy, using AdaBoost with Extra Trees was the highest around 90%. Since the voting mechanism detracts from this accuracy, I'll submit my predictions from just the AdaBoost with Extra Trees model. The cells below run the model on the real test data."},{"metadata":{"trusted":false,"_uuid":"e3ad9774e12b2aebfae8112e87e0edef2bccbc37"},"cell_type":"code","source":"X_train = train[features]\ny_train = train['Cover_Type']\nX_test = test[features]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de6c701772d483c62579ae4fa6bcd5d3675a77d6","trusted":false},"cell_type":"code","source":"abc2 = AdaBoostClassifier(ExtraTreesClassifier(n_estimators=500), n_estimators=500, learning_rate=.1, algorithm='SAMME')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58e85a12261d3669214a02c0f707613ca6189e51","trusted":false},"cell_type":"code","source":"%%time\nabc2.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d2dcfcb2f2510a61266ee3c367b6c162773f483c"},"cell_type":"code","source":"%%time\npred = abc2.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae0d0df71c0112b1ef81570c5e6d8ccf402612ec"},"cell_type":"markdown","source":"<h1>Print submission file</h1>"},{"metadata":{"trusted":false,"_uuid":"6b32472d54e868433cabe82d9cd5e609b84e6578"},"cell_type":"code","source":"sub = pd.DataFrame({\"Id\": test[\"Id\"], \"Cover_Type\": pred.astype('int')})\nsub.reindex().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8234c836086a3752d5352dc86c57930be9fbb769"},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6761c2eb45887a32e6d170d0f9808a72a848a03d"},"cell_type":"markdown","source":"This notebook is an example of what is possible with a simple analysis + prediction, without going much into tweaking parameters of the models. If you'd like to leave a commment, please do. I welcome any feedback to further my own learning process. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}