{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e7093727-e671-c080-d45f-a7697b2cd742"
      },
      "source": [
        "The goal of this notebook is to show you how to build a feature that is ***very*** close to the value of the response, y, at the previous timestep.\n",
        "\n",
        "This notebook builds chiefly upon the work in these two notebooks:\n",
        "\n",
        "[https://www.kaggle.com/chenjx1005/two-sigma-financial-modeling/physical-meanings-of-technical-20-30/discussion][1]\n",
        "\n",
        "\n",
        "[https://www.kaggle.com/luckylwk/two-sigma-financial-modeling/moving-average-macd-analysis][2]\n",
        "\n",
        "\n",
        "  [1]: https://www.kaggle.com/chenjx1005/two-sigma-financial-modeling/physical-meanings-of-technical-20-30/discussion\n",
        "  [2]: https://www.kaggle.com/luckylwk/two-sigma-financial-modeling/moving-average-macd-analysis\n",
        "\n",
        "\n",
        "We can make two conclusions from these:\n",
        "\n",
        "1) The feature set is shifted. IE the features actually are derived from y(t-1)\n",
        "\n",
        "2) Many of the features are strongly related to the moving average of of y (or y(t-1) )\n",
        "\n",
        "To re-iterate these points, in the following code block I load the data set and build some derived quantities from y. In particular I look at the moving averages of y and the moving averages of y(t-1).\n",
        "\n",
        "I then examine their correlations with the feature set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a7fe110e-4409-fb3d-623c-b2ce9b7dd8fb"
      },
      "outputs": [],
      "source": [
        "###################################################################\n",
        "# Import libraries\n",
        "###################################################################\n",
        "\n",
        "import kagglegym\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns\n",
        "import sklearn as sk\n",
        "from sklearn import preprocessing\n",
        "from sklearn import cluster\n",
        "from sklearn import linear_model\n",
        "from sklearn import ensemble\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# The \"environment\" is our interface for code competitions\n",
        "env = kagglegym.make()\n",
        "\n",
        "# We get our initial observation by calling \"reset\"\n",
        "observation = env.reset()\n",
        "data_df = observation.train\n",
        "\n",
        "    \n",
        "###################################################################\n",
        "# Get train data frame, do some pre-processing\n",
        "###################################################################\n",
        "\n",
        "data = data_df[data_df['timestamp'] < 906]\n",
        "\n",
        "mean_values = data.mean(axis=0)\n",
        "data.fillna(mean_values, inplace=True)\n",
        "\n",
        "train = data[data['timestamp'] < 906/2]\n",
        "test  = data[data['timestamp'] > 906/2]\n",
        "\n",
        "# Fill na values\n",
        "mean_values = test.mean(axis=0)\n",
        "test.fillna(mean_values, inplace=True)\n",
        "mean_values = test.mean(axis=0)\n",
        "train.fillna(mean_values, inplace=True)\n",
        "\n",
        "def ewm_mean(x,span_in):\n",
        "    return(x.ewm(span=span_in).mean())\n",
        "\n",
        "#Build EWM parameters\n",
        "train['EWM_9_mean']   = train.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=9))\n",
        "train['EWM_12_mean']  = train.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=12))\n",
        "train['EWM_26_mean']  = train.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=26))\n",
        "train['EWM_40_mean']  = train.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=40))\n",
        "\n",
        "test['EWM_9_mean']   = test.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=9))\n",
        "test['EWM_12_mean']  = test.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=12))\n",
        "test['EWM_26_mean']  = test.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=26))\n",
        "test['EWM_40_mean']  = test.groupby('id')['y'].apply(lambda x: ewm_mean(x,span_in=40))\n",
        "\n",
        "# Build shifted parameters\n",
        "train['y_shifted']      = train.groupby('id')['y'].shift(1).fillna(0)\n",
        "train['EWM_9_mean_s']   = train.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=9))\n",
        "train['EWM_12_mean_s']  = train.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=12))\n",
        "train['EWM_26_mean_s']  = train.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=26))\n",
        "train['EWM_40_mean_s']  = train.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=40))\n",
        "\n",
        "test['y_shifted']      = test.groupby('id')['y'].shift(1).fillna(0)\n",
        "test['EWM_9_mean_s']   = test.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=9))\n",
        "test['EWM_12_mean_s']  = test.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=12))\n",
        "test['EWM_26_mean_s']  = test.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=26))\n",
        "test['EWM_40_mean_s']  = test.groupby('id')['y_shifted'].apply(lambda x: ewm_mean(x,span_in=40))\n",
        "\n",
        "\n",
        "# Plot corrilation matrix\n",
        "cols = [x for x in train.columns if x not in ['id','timestamp']]\n",
        "\n",
        "main_cols = ['y','EWM_9_mean','EWM_12_mean','EWM_26_mean','EWM_40_mean',\n",
        "            'EWM_9_mean_s','EWM_12_mean_s','EWM_26_mean_s','EWM_40_mean_s']\n",
        "main_ix =  train[cols].columns.get_indexer(main_cols)\n",
        "\n",
        "cor_mat = np.corrcoef(train[cols], rowvar=0)[:,main_ix]\n",
        "\n",
        "corr_df = pd.DataFrame(cor_mat,columns=main_cols,index=[cols])\n",
        "\n",
        "plt.figure(figsize=(20,40))\n",
        "sns.heatmap(corr_df, vmin=-1.0, vmax=1.0, linewidths=.5, annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "01310fa8-58fc-dda8-a51c-3c2dec0bc8e9"
      },
      "source": [
        "Again we see our friends technical_30 and technical_20. In addition some other features appear to also be related to the moving averages. In addition the shifted moving averages are, in general, more strongly correlated to the feature set. \n",
        "\n",
        "\n",
        "Now, to \"rebuild\" y(t-1) I will employ the following strategy.\n",
        "\n",
        "1) We transform y(t-1) via an exponentially weighted average\n",
        "\n",
        "2) We build a model to predict the transformed quantity (EWM_26_mean_s) from the feature set, called say EWM_26s_pred\n",
        "\n",
        "3) We perform an inverse transformation on EWM_26s_pred. We utilize the fact that exponential weighted averages can be computed in an iterative fashion.\n",
        "\n",
        "That is, S_t = alpha*Y_t +(1-alpha)*S_(t-1)\n",
        "\n",
        "where S_t is the exponentially weighted average at time t, Y_t is the response at time t, and S_t-1 is the EWA for time t-1\n",
        "\n",
        "Clearly this equation can be re-arranged to yield\n",
        "\n",
        "Y_t = (S_t - (1-alpha)*S_(t-1))/alpha\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ef287320-e92b-76f4-137e-b12f9c84a39d"
      },
      "outputs": [],
      "source": [
        "ewm_features = ['technical_30','technical_20','technical_21','technical_19','technical_17','technical_11','technical_2']\n",
        "my_model = sk.ensemble.GradientBoostingRegressor(loss='ls', max_depth=5, learning_rate=0.05)\n",
        "my_model.fit(X=train[ewm_features],y=train['EWM_26_mean_s'])\n",
        "train['EWM_26s_pred'] = my_model.predict(X=train[ewm_features]) \n",
        "test['EWM_26s_pred'] = my_model.predict(X=test[ewm_features])\n",
        "\n",
        "def ewm_reverse(data,span=26):\n",
        "    alpha = 2/(span+1)\n",
        "    return (data-(1-alpha)*data.shift(1).fillna(0))/alpha\n",
        "\n",
        "# Inverse transform\n",
        "train['yEWM_26'] = train.groupby('id')['EWM_26s_pred'].apply(lambda x: ewm_reverse(x, span=26))\n",
        "test['yEWM_26'] = test.groupby('id')['EWM_26s_pred'].apply(lambda x: ewm_reverse(x, span=26))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "aa851760-72a2-ec00-62b7-1828e6ca2afd"
      },
      "source": [
        "If all went well yEWM_26 should corrispond quite strongly to y(t-1). Lets test it out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "75ede8fa-ccc6-b653-2d9a-971b06cf8d63"
      },
      "outputs": [],
      "source": [
        "def find_R_value(y_predict,y_actual):\n",
        "    mean = np.mean(y_actual)\n",
        "    Rrr = 1 - sum((y_predict-y_actual)**2)/sum((y_actual-mean)**2)\n",
        "    return np.sign(Rrr)*np.sqrt(np.abs(Rrr))  \n",
        "\n",
        "find_R_value(test['yEWM_26'],test.groupby('id')['y'].shift(1).fillna(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9f2ac90b-2c9a-975e-21b9-4c4a8892e51c"
      },
      "source": [
        "Not bad! Granted it is not perfect as there is some noise in the features, but this might be a decent feature for determining y(t).\n",
        "\n",
        "For fun, lets look at the plots for a few IDs to see how they match up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "96d7e997-8c62-26ea-d89f-fd01bd9ea6e1"
      },
      "outputs": [],
      "source": [
        "tmp_df = test[(test['timestamp'] < 500) & (test['id'] == test['id'].iloc[10])]\n",
        "tmp_df.plot(x='timestamp',y=['yEWM_26','y_shifted'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c65185c3-9a3f-dab6-1a63-4132074c7d70"
      },
      "outputs": [],
      "source": [
        "tmp_df = test[(test['timestamp'] < 500) & (test['id'] == test['id'].iloc[1])]\n",
        "tmp_df.plot(x='timestamp',y=['yEWM_26','y_shifted'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8ab90242-7176-3318-8fd1-38f654efd72e"
      },
      "source": [
        "There is some slight distortion at the start due to how yEWM_26 is calculated, but generally it seems to match quite well.\n",
        "\n",
        "I think this can prove useful as a feature than can perhaps enable the use of some more conventional time series techniques.\n",
        "\n",
        "Now, I know what you might be thinking. Why not try this procedure on y(t) instead of y(t-1). Well I have tried this, and surprisingly you get back something that looks more like y(t-1) than y(t)."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}