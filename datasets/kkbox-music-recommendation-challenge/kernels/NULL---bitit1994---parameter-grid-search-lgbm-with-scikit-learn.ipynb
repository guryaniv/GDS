{"cells": [{"cell_type": "markdown", "source": ["I'm here to make friends to work on this interesting challenge together. Skype me: sarazxy\n", "\n", "Welcome your comments."], "metadata": {"_uuid": "85cb9739ea0476d4531d697c87a71d7a0887c470", "_cell_guid": "bb65b899-a334-4269-9439-f449727362ab"}}, {"source": ["import numpy as np\n", "import pandas as pd\n", "from time import gmtime, strftime\n", "import gc\n", "\n", "from sklearn.model_selection import (train_test_split, GridSearchCV)\n", "from sklearn.preprocessing import LabelEncoder\n", "import lightgbm as lgb\n", "from tqdm import tqdm\n", "from sklearn.metrics import (roc_curve, auc, accuracy_score)"], "cell_type": "code", "metadata": {"_uuid": "98b1b738c4285aa51d184cf109d76874aededec4", "_cell_guid": "07eb4438-192b-4587-ae85-88ac2cd09600", "collapsed": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["## 1. Load data"], "metadata": {"_uuid": "c59349538fbb10ac7894f3f0a096709dec819fa7", "_cell_guid": "3e612e55-fd10-4f24-b0fe-57b74dcf1967"}}, {"source": ["# read the first 99 rows for demo\n", "train = pd.read_csv('../input/train.csv', nrows=99)\n", "test = pd.read_csv('../input/test.csv',nrows=99)\n", "songs = pd.read_csv('../input/songs.csv')\n", "members = pd.read_csv('../input/members.csv')\n", "\n", "# Merge datasets with song attributes\n", "song_cols = ['song_id', 'artist_name', 'genre_ids', 'song_length', 'language']\n", "train = train.merge(songs[song_cols], on='song_id', how='left')\n", "test = test.merge(songs[song_cols], on='song_id', how='left')\n", "\n", "# Merge datasets with member features\n", "members['registration_year'] = members['registration_init_time'].apply(lambda x: int(str(x)[0:4]))\n", "members['registration_month'] = members['registration_init_time'].apply(lambda x: int(str(x)[4:6]))\n", "members['registration_date'] = members['registration_init_time'].apply(lambda x: int(str(x)[6:8]))\n", "\n", "members['expiration_year'] = members['expiration_date'].apply(lambda x: int(str(x)[0:4]))\n", "members['expiration_month'] = members['expiration_date'].apply(lambda x: int(str(x)[4:6]))\n", "members['expiration_date'] = members['expiration_date'].apply(lambda x: int(str(x)[6:8]))\n", "members = members.drop(['registration_init_time'], axis=1)\n", "\n", "members_cols = members.columns\n", "train = train.merge(members[members_cols], on='msno', how='left')\n", "test = test.merge(members[members_cols], on='msno', how='left')\n", "\n", "train = train.fillna(-1)\n", "test = test.fillna(-1)\n", "\n", "del members, songs; gc.collect();\n", "\n", "cols = list(train.columns)\n", "cols.remove('target')\n", "\n", "for col in tqdm(cols):\n", "    if train[col].dtype == 'object':\n", "        train[col] = train[col].apply(str)\n", "        test[col] = test[col].apply(str)\n", "\n", "        le = LabelEncoder()\n", "        train_vals = list(train[col].unique())\n", "        test_vals = list(test[col].unique())\n", "        le.fit(train_vals + test_vals)\n", "        train[col] = le.transform(train[col])\n", "        test[col] = le.transform(test[col])\n", "\n"], "cell_type": "code", "metadata": {"_uuid": "5107cf9bc022a686194503e3ba9ca53282fc6cbf", "_cell_guid": "0e032b61-0cd5-4eca-926a-66ea753b25e7"}, "execution_count": null, "outputs": []}, {"source": ["X = np.array(train.drop(['target'], axis=1))\n", "y = train['target'].values"], "cell_type": "code", "metadata": {"_uuid": "f0bbac632567137937fffc77f01f2476d02c9e22", "_cell_guid": "9f4e2140-3f34-402c-987b-1f26d849e530", "collapsed": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["## 2. Initiate a model"], "metadata": {"_uuid": "28574180eb2fab50b26d80ad457c50d7a5c74087", "_cell_guid": "ee32b3e7-a9af-47d3-8d3d-23c05cba2df5"}}, {"source": ["params = {\n", "    'application': 'binary', # for binary classification\n", "#     'num_class' : 1, # used for multi-classes\n", "    'boosting': 'gbdt', # traditional gradient boosting decision tree\n", "    'num_iterations': 100, \n", "    'learning_rate': 0.05,\n", "    'num_leaves': 62,\n", "    'device': 'cpu', # you can use GPU to achieve faster learning\n", "    'max_depth': -1, # <0 means no limit\n", "    'max_bin': 510, # Small number of bins may reduce training accuracy but can deal with over-fitting\n", "    'lambda_l1': 5, # L1 regularization\n", "    'lambda_l2': 10, # L2 regularization\n", "    'metric' : 'binary_error',\n", "    'subsample_for_bin': 200, # number of samples for constructing bins\n", "    'subsample': 1, # subsample ratio of the training instance\n", "    'colsample_bytree': 0.8, # subsample ratio of columns when constructing the tree\n", "    'min_split_gain': 0.5, # minimum loss reduction required to make further partition on a leaf node of the tree\n", "    'min_child_weight': 1, # minimum sum of instance weight (hessian) needed in a leaf\n", "    'min_child_samples': 5# minimum number of data needed in a leaf\n", "}\n", "\n", "# Initiate classifier to use\n", "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', \n", "          objective = 'binary', \n", "          n_jobs = 5, \n", "          silent = True,\n", "          max_depth = params['max_depth'],\n", "          max_bin = params['max_bin'], \n", "          subsample_for_bin = params['subsample_for_bin'],\n", "          subsample = params['subsample'], \n", "          min_split_gain = params['min_split_gain'], \n", "          min_child_weight = params['min_child_weight'], \n", "          min_child_samples = params['min_child_samples'])\n", "\n", "# To view the default model parameters:\n", "mdl.get_params().keys()\n", "\n"], "cell_type": "code", "metadata": {"_uuid": "c802408e8464cd4e89d5d5036c872ebcea16f58d", "_cell_guid": "f9857e93-e3db-4458-b50b-f6d7576561cd"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["## 3. Grid search"], "metadata": {"_uuid": "c80ab7d33a1ba3158dc204b96498542d36fd44e0", "_cell_guid": "837e4025-aaa5-4756-95b0-4c5bfab1ba45"}}, {"source": ["gridParams = {\n", "    'learning_rate': [0.005, 0.01],\n", "    'n_estimators': [8,16,24],\n", "    'num_leaves': [6,8,12,16], # large num_leaves helps improve accuracy but might lead to over-fitting\n", "    'boosting_type' : ['gbdt', 'dart'], # for better accuracy -> try dart\n", "    'objective' : ['binary'],\n", "    'max_bin':[255, 510], # large max_bin helps improve accuracy but might slow down training progress\n", "    'random_state' : [500],\n", "    'colsample_bytree' : [0.64, 0.65, 0.66],\n", "    'subsample' : [0.7,0.75],\n", "    'reg_alpha' : [1,1.2],\n", "    'reg_lambda' : [1,1.2,1.4],\n", "    }\n", "\n", "grid = GridSearchCV(mdl, gridParams, verbose=1, cv=4, n_jobs=-1)\n", "# Run the grid\n", "grid.fit(X, y)\n", "\n", "# Print the best parameters found\n", "print(grid.best_params_)\n", "print(grid.best_score_)\n", "\n"], "cell_type": "code", "metadata": {"_uuid": "b1795cff61b6c664ffd3abf627f3fc6d81a76f1b", "_cell_guid": "70f58452-119b-4922-ada6-2bf76a02955b"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["## 4. Use the best model"], "metadata": {"_uuid": "e3d4faa1bc298ced1adc8f0c15e2ae6045a5958f", "_cell_guid": "a5246d75-8725-40d8-90f3-a0cea9362f77"}}, {"source": ["params['colsample_bytree'] = grid.best_params_['colsample_bytree']\n", "params['learning_rate'] = grid.best_params_['learning_rate'] \n", "params['max_bin'] = grid.best_params_['max_bin']\n", "params['num_leaves'] = grid.best_params_['num_leaves']\n", "params['reg_alpha'] = grid.best_params_['reg_alpha']\n", "params['reg_lambda'] = grid.best_params_['reg_lambda']\n", "params['subsample'] = grid.best_params_['subsample']\n", "\n", "\n", "X_test = np.array(test.drop(['id'], axis=1))\n", "ids = test['id'].values\n", "\n", "\n", "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state = 12)\n", "    \n", "del X, y; gc.collect();\n", "\n", "d_train = lgb.Dataset(X_train, label=y_train)\n", "d_valid = lgb.Dataset(X_valid, label=y_valid) \n", "\n", "watchlist = [d_train, d_valid]\n", "\n", "\n", "model = lgb.train(params, train_set=d_train, num_boost_round=1000, valid_sets=watchlist, early_stopping_rounds=50, verbose_eval=4)\n", "\n", "p_test = model.predict(X_test)\n", "\n", "subm = pd.DataFrame()\n", "subm['id'] = ids\n", "subm['target'] = p_test\n", "submName = strftime(\"%Y%m%d%H%M%S\", gmtime()) + '_submission.csv.gz'\n", "subm.to_csv(submName, compression = 'gzip', index=False, float_format = '%.5f')"], "cell_type": "code", "metadata": {"_uuid": "3b539ca753600af5e819790d228d1eb4f5564fcd", "_cell_guid": "1fefcf44-600b-4428-bea5-e3aab6f259b8", "collapsed": true}, "execution_count": null, "outputs": []}], "nbformat": 4, "nbformat_minor": 1, "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"mimetype": "text/x-python", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "file_extension": ".py", "version": "3.6.3", "nbconvert_exporter": "python"}}}