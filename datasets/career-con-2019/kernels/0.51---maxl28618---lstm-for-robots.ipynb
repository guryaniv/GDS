{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport os\n\nbase_dir = \"../input\"\n\nprint(os.listdir(base_dir))","execution_count":265,"outputs":[{"output_type":"stream","text":"['y_train.csv', 'sample_submission.csv', 'X_test.csv', 'X_train.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"X_train = pd.read_csv(f'{base_dir}/X_train.csv')\ny_train = pd.read_csv(f'{base_dir}/y_train.csv')","execution_count":266,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a390ee840121f27496c0356b8cbec25efb8e3c3"},"cell_type":"code","source":"USE_CUDA = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n#device = torch.device(\"cpu\")\ndevice","execution_count":267,"outputs":[{"output_type":"execute_result","execution_count":267,"data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"metadata":{"_uuid":"b862b7471b51ab6382c00e480c99f887efd81d91"},"cell_type":"markdown","source":"**Prepare the training data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nfrom sklearn.model_selection import train_test_split\n\ntrain_val_split = int(n_examples * 0.9)\ndataset_IDs = {}\ndataset_IDs['train'], dataset_IDs['eval'] = train_test_split(X_train['series_id'].unique(), test_size=0.0)","execution_count":291,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(dataset_IDs['train'])","execution_count":292,"outputs":[{"output_type":"execute_result","execution_count":292,"data":{"text/plain":"3810"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"bfbfef0678dd39a40b3b605b0f35ea118405c366"},"cell_type":"code","source":"series_id_to_surface = {}\nsurface_to_series_id = {}\nsurface_to_surface_tensor = {}\nseries_id_to_tensor = {}\n\nfor row in y_train.iterrows():\n    surface_to_series_id.setdefault(row[1].surface, []).append(row[1].series_id)\n    series_id_to_surface[row[1].series_id] = row[1].surface\nall_surfaces = list(surface_to_series_id.keys())\n\nfor i in range(len(all_surfaces)):\n    surface_to_surface_tensor[all_surfaces[i]] = torch.tensor([i], dtype=torch.long).to(device)\n\ndef tensor_from_series_id(series_id, df):\n    series = df[df['series_id'] == series_id].drop(['row_id', 'series_id', 'measurement_number'], axis=1)\n    series_tensor = torch.from_numpy(series.values).view(series.shape[0], 1, -1).float().to(device)\n    return series_tensor\n    \nfor series_id in X_train['series_id'].unique():\n    series_id_to_tensor[series_id] = tensor_from_series_id(series_id, X_train)\n    \ndef random_training_example(phase):\n    series_id = random.choice(dataset_IDs[phase])\n    surface = series_id_to_surface[series_id]\n    surface_tensor = surface_to_surface_tensor[surface]\n    series_tensor = series_id_to_tensor[series_id]\n    return series_id, surface, series_tensor, surface_tensor\n\nn_features = X_train.drop(['row_id', 'series_id', 'measurement_number'], axis=1).shape[1]\nn_surfaces = len(all_surfaces)\nn_hidden = 32\nn_examples = len(X_train['series_id'].unique())\nn_sequence = len(X_train['measurement_number'].unique())","execution_count":293,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_targets = {}\ndataset_targets['train'] = [series_id_to_surface[series_id] for series_id in dataset_IDs['train']]\ndataset_targets['eval'] = [series_id_to_surface[series_id] for series_id in dataset_IDs['eval']]","execution_count":294,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b8562ecffe41d0e292d20145b192bdb6e973198"},"cell_type":"code","source":"class LSTMSurface(nn.Module):\n    def __init__(self, series_dim, hidden_dim, surface_dim):\n        super(LSTMSurface, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.lstm = nn.LSTM(series_dim, hidden_dim)\n        self.hidden2surface = nn.Linear(hidden_dim, surface_dim)\n\n    def forward(self, series):\n        lstm_out, _ = self.lstm(series)\n        surface_space = self.hidden2surface(lstm_out)\n        surface_scores = F.log_softmax(surface_space, dim=2)\n        return surface_scores[-1]","execution_count":295,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00ace27a7ce597dede939a55b3da2a4eaad1f207"},"cell_type":"code","source":"def surface_from_output(output):\n    top_n, top_i = output.topk(1)\n    surface_i = top_i[0].item()\n    return all_surfaces[surface_i], surface_i","execution_count":296,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fef4ba777b3171429f910eea11c7775cec7ab8db"},"cell_type":"code","source":"model = LSTMSurface(n_features, n_hidden, n_surfaces).to(device)\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters())","execution_count":297,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a9be8af85578d7261790186a6883b35e085ac95"},"cell_type":"code","source":"%matplotlib inline\nfrom IPython import display\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport statistics\nimport copy\n\nn_epochs = 200000\nsave_loss_every = 10\nprint_every = 1000\nplot_every = 5000\nlosses = {'train': [], 'eval': []}\naccs = {'train': [], 'eval': []}\n\nall_losses = {'train': [], 'eval': []}\n\nbest_model_wts = copy.deepcopy(model.state_dict())\nbest_acc = 0.0\n        \nfig = plt.figure()\n\nfor epoch in range(1, n_epochs + 1):\n    for phase in ['train']:\n        optimizer.zero_grad()\n\n        if phase == 'train':\n            model.train()\n        else:\n            model.eval()\n        \n        _, _, inputs, targets = random_training_example(phase)\n        \n        with torch.set_grad_enabled(phase == 'train'):\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n            _, preds = torch.max(outputs, 1)\n\n            if phase == 'train':\n                loss.backward()\n                optimizer.step()\n        \n        if epoch % save_loss_every == 0:\n            running_loss = loss.item() * inputs.size(1)\n            running_corrects = torch.sum(preds == targets.data)\n            epoch_loss = running_loss / len(targets)\n            epoch_acc = running_corrects.double() / len(targets)\n            losses[phase].append(epoch_loss)\n            accs[phase].append(epoch_acc.item())\n        \n        if phase == 'eval' and epoch % print_every == 0:\n            training_loss = statistics.mean(losses['train'])\n            validation_loss = statistics.mean(losses['eval'])\n            all_losses['train'].append(training_loss)\n            all_losses['eval'].append(validation_loss)\n            training_acc = statistics.mean(accs['train'])\n            validation_acc = statistics.mean(accs['eval'])\n            if validation_acc > best_acc:\n                best_acc = validation_acc\n                print(f'Best accuracy so far! Acc = {best_acc}')\n                best_model_wts = copy.deepcopy(model.state_dict())\n            print(f'{epoch} {epoch / n_epochs:.2%} / Train Loss: {training_loss:.4}, Validation Loss: {validation_loss:.4} / Train Accuracy: {training_acc:.2%}, Validation Accuracy: {validation_acc:.2%}')\n            losses = {'train': [], 'eval': []}\n            accs = {'train': [], 'eval': []}\n        \n        if phase == 'eval' and epoch % plot_every == 0:\n            plt.plot(all_losses['train'], label='Train loss')\n            plt.plot(all_losses['eval'], label='Validation loss')\n            display.display(plt.gcf())\n            display.clear_output(wait=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"996b7a3c94abcb5f4bb95598bc5cbff07b66e4b4"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nplt.figure()\nplt.plot(all_losses['train'], label='Train loss')\nplt.plot(all_losses['eval'], label='Validation loss')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d25b3b7f362821d67824656d270fa9c61397096"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nmodel.load_state_dict(best_model_wts)\n\nconfusion = torch.zeros(n_surfaces, n_surfaces)\nn_confusion = 1000\n\ndef evaluate(series_tensor):\n    with torch.no_grad():\n        scores = model(series_tensor)\n        return scores\n\nall_guesses = []\nhits = 0\nfor i in range(n_confusion):\n    series_id, surface, series_tensor, surface_tensor = random_training_example('eval')\n    output = evaluate(series_tensor)\n    guess, guess_i = surface_from_output(output)\n    all_guesses.append(guess)\n    surface_i = all_surfaces.index(surface)\n    confusion[surface_i][guess_i] += 1\n    if surface_i == guess_i:\n        hits += 1\n\naccuracy = hits / n_confusion\n\nfor i in range(n_surfaces):\n    confusion[i] = confusion[i] / confusion[i].sum()\n\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(confusion.numpy())\nfig.colorbar(cax)\n\nax.set_xticklabels([''] + all_surfaces, rotation=90)\nax.set_yticklabels([''] + all_surfaces)\n\nax.xaxis.set_major_locator(ticker.MultipleLocator(1))\nax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\nplt.show()\nprint(pd.Series(all_guesses).value_counts())\nprint(f'Validation accuracy = {accuracy:.2%}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = pd.read_csv(f'{base_dir}/X_test.csv')\npredictions = []\nfor series_id in X_test['series_id'].unique():\n    series_tensor = tensor_from_series_id(series_id, X_test)\n    output = evaluate(series_tensor)\n    guess, guess_i = surface_from_output(output)\n    predictions.append((series_id, guess))\nsubmission = pd.DataFrame(predictions, columns=['series_id', 'surface'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(submission.to_csv(index=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('lstm_submission_simple.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}