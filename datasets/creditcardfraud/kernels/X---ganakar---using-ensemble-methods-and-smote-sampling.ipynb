{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0643f837-1b0c-8f7e-3853-2f8a446b9fde"
      },
      "source": [
        "# Credit Card Fraud Detection(Full Solution-XGBoost performs better)\n",
        "\n",
        "**1) Models compared are Logistic Regression(Can consider as benchmark) & Ensemble Methods - Ada Boost, XGBoost, Random Forest** \n",
        "\n",
        "\n",
        "\n",
        "**2) SMOTE(Synthetic Minority Over -sampling Technique) has been used for oversampling(Given this is anomaly detection problem)**\n",
        "\n",
        "\n",
        "\n",
        "**3) Metrics used to evaluate algorithms - Precision Score,Recall score,F1-Score,Area under precision recall curve & Accuracy score-  \n",
        "  \n",
        "* Priority will be given to Recall score so that we don't miss any fraud detection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0e59f399-5ac4-1d5e-2807-f79ca2d47de0"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection  import train_test_split,KFold, cross_val_score,GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,\\\n",
        "recall_score,classification_report,accuracy_score,precision_score,f1_score,make_scorer,average_precision_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from time import time\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import ListedColormap\n",
        "import imp\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e02da9bc-703e-8a71-9b80-22c5eaaa634c"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"../input/creditcard.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8068985c-1907-cb06-7388-c079c6622a00"
      },
      "outputs": [],
      "source": [
        "normal_trans_perc=sum(data['Class']==0)/(sum(data['Class']==0)+sum(data['Class']==1))\n",
        "fraud_trans_perc=1-normal_trans_perc\n",
        "print('Total number of records : {} '.format(len(data)))\n",
        "print('Total number of normal transactions : {}'.format(sum(data['Class']==0)))\n",
        "print('Total number of  fraudulent transactions : {}'.format(sum(data['Class']==1)))\n",
        "print('Percent of normal transactions is : {:.4f}%,  fraudulent transactions is : {:.4f}%'.format(normal_trans_perc*100,fraud_trans_perc*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2e142c0e-2514-5fcd-8b2d-964a86ba447b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "cards_trans_count= pd.Series([normal_trans_perc*100,fraud_trans_perc*100],index=['Normal','Fraud'])\n",
        "cards_trans_count.plot(kind='bar', title='Card Transactions Split')\n",
        "plt.ylabel('Transaction %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c8f50bd5-7063-5a84-445d-a8d8b4ee06ae"
      },
      "outputs": [],
      "source": [
        "#Normalizing Amount column as rest of columns have been already normalized and dropping time as it is just sequence\n",
        "data['NormAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "data = data.drop(['Time','Amount'],axis=1)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3c61cb70-c841-04d4-d4f4-fec3d29fb2e7"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(7,7))  \n",
        "sns.heatmap(data.corr(),annot_kws={\"size\":4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "53a7565f-3e70-1427-9a71-0c16138487d8"
      },
      "outputs": [],
      "source": [
        "X_raw = data.ix[:, data.columns != 'Class']\n",
        "y_raw = data.ix[:, data.columns == 'Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2730b5b9-89bf-eac7-3aaa-b7b3703beb13"
      },
      "outputs": [],
      "source": [
        "#Drop columns(Like V22,V23, V24) low correlaction score\n",
        "X=X_raw.drop(['V22','V23','V24','V25','V26','V27','V28'], axis = 1)\n",
        "y=y_raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "35f57d04-26da-ec79-9e37-19312ca3f08e"
      },
      "source": [
        "###Split into train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "16b7af58-0998-29ba-c458-8450cd74072b"
      },
      "outputs": [],
      "source": [
        "# Split into train and test dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3677dc7b-1d33-51fd-6591-3f58554df022"
      },
      "outputs": [],
      "source": [
        "# Split into train and test dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ae09e499-603c-797a-f191-66338a9aeace"
      },
      "outputs": [],
      "source": [
        "#Stats of training data \n",
        "print('---------Training data statistics-----------')\n",
        "normal_trans_perc=sum( y_train['Class']==0)/(sum( y_train['Class']==0)+sum( y_train['Class']==1))\n",
        "fraud_trans_perc=1-normal_trans_perc\n",
        "print('Total number of records : {} '.format(len(y_train)))\n",
        "print('Total number of normal transactions : {}'.format(sum(y_train['Class']==0)))\n",
        "print('Total number of  fraudulent transactions : {}'.format(sum(y_train['Class']==1)))\n",
        "print('Percent of normal transactions is : {:.4f}%,  fraudulent transactions is : {:.4f}%'.format(normal_trans_perc*100,fraud_trans_perc*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "666f5ee9-d1db-aa6a-c99e-e6b10d62a770"
      },
      "outputs": [],
      "source": [
        "#Stats of testing data \n",
        "print('---------Testing data statistics-----------')\n",
        "normal_trans_perc=sum( y_test['Class']==0)/(sum( y_test['Class']==0)+sum( y_test['Class']==1))\n",
        "fraud_trans_perc=1-normal_trans_perc\n",
        "print('Total number of records : {} '.format(len(y_test)))\n",
        "print('Total number of normal transactions : {}'.format(sum(y_test['Class']==0)))\n",
        "print('Total number of  fraudulent transactions : {}'.format(sum(y_test['Class']==1)))\n",
        "print('Percent of normal transactions is : {:.4f}%,  fraudulent transactions is : {:.4f}%'.format(normal_trans_perc*100,fraud_trans_perc*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "512902e5-3f2a-2bb5-5b43-530424748aa0"
      },
      "source": [
        "### Resampling of data using SMOTE Technique "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "719c4f58-a44f-0664-5ac2-d055d49daae7"
      },
      "outputs": [],
      "source": [
        "sm = SMOTE(ratio=.02,kind='borderline1',random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f97b6970-c9ed-978b-cfb6-3e00db92004c"
      },
      "outputs": [],
      "source": [
        "X_resampled_train, y_resampled_train = sm.fit_sample(X_train, y_train.values.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "700ba39f-d56e-a33b-007c-440207de93b2"
      },
      "outputs": [],
      "source": [
        "# Convert to dataframe\n",
        "X_resampled_train=pd.DataFrame(X_resampled_train,columns=\n",
        "['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', \n",
        " 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'NormAmount'])\n",
        "y_resampled_train=pd.DataFrame(y_resampled_train,columns=['Class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a60201a9-c692-4618-be45-d8ecc13c0cb3"
      },
      "outputs": [],
      "source": [
        "print('---------------Resampled data statistics---------------')\n",
        "normal_trans_perc=sum(y_resampled_train['Class']==0)/(sum(y_resampled_train['Class']==0)+sum(y_resampled_train['Class']==1))\n",
        "fraud_trans_perc=1-normal_trans_perc\n",
        "print('Total number of records : {} '.format(len(y_resampled_train)))\n",
        "print('Total number of normal transactions : {}'.format(sum(y_resampled_train['Class']==0)))\n",
        "print('Total number of  fraudulent transactions : {}'.format(sum(y_resampled_train['Class']==1)))\n",
        "print('Percent of normal transactions is : {:.4f}%,  fraudulent transactions is : {:.4f}%'.format(normal_trans_perc*100,fraud_trans_perc*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7fa270ab-582d-5eb9-963c-1cc227648f2c"
      },
      "outputs": [],
      "source": [
        "X_resampled_train.to_csv('x_train.csv')\n",
        "y_resampled_train.to_csv('y_train.csv')\n",
        "X_test.to_csv('x_test.csv')\n",
        "y_test.to_csv('y_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1bfc1109-4f0f-787f-48e0-f45bee57f38b"
      },
      "outputs": [],
      "source": [
        "def train_predict(learner, X_train, y_train, X_test, y_test): \n",
        "    '''\n",
        "    inputs:\n",
        "       - learner: the learning algorithm to be trained and predicted on       \n",
        "       - X_train: features training set\n",
        "       - y_train: income training set\n",
        "       - X_test: features testing set\n",
        "       - y_test: income testing set\n",
        "    '''\n",
        "    \n",
        "    results = {}\n",
        "   \n",
        "    start = time() # Get start time\n",
        "    learner.fit(X_train, y_train)\n",
        "    end = time() # Get end time\n",
        "      \n",
        "    results['train_time'] = end - start\n",
        "        \n",
        "    start = time() # Get start time\n",
        "    predictions_test = learner.predict(X_test)\n",
        "    predictions_train = learner.predict(X_train)\n",
        "    \n",
        "    predictions_test_prob = learner.predict_proba(X_test)[:,1]\n",
        "    predictions_train_prob = learner.predict_proba(X_train)[:,1]\n",
        "    \n",
        "    \n",
        "    end = time() # Get end time\n",
        "        \n",
        "    results['pred_time'] =end - start\n",
        "            \n",
        "    \n",
        "    results['acc_train'] = accuracy_score(y_train, predictions_train)      \n",
        "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
        "    \n",
        "    results['rec_train'] = recall_score(y_train, predictions_train)      \n",
        "    results['rec_test'] = recall_score(y_test, predictions_test)\n",
        "    \n",
        "    results['prec_train'] = precision_score(y_train, predictions_train)      \n",
        "    results['prec_test'] = precision_score(y_test, predictions_test)\n",
        "    \n",
        "    \n",
        "    results['f1_train'] = f1_score(y_train, predictions_train)\n",
        "    results['f1_test'] = f1_score(y_test, predictions_test)\n",
        "    \n",
        "    results['auc_train'] = average_precision_score(y_train, predictions_train_prob,average='weighted')\n",
        "    results['auc_test'] = average_precision_score(y_test, predictions_test_prob,average='weighted')\n",
        "    \n",
        "    \n",
        "       \n",
        "    # Success\n",
        "    print(\"{} trained in time {:.4f} \".format(learner.__class__.__name__,(end - start)))\n",
        "        \n",
        "    # Return the results\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "81acb5fd-fbfc-448a-2b89-fcc734881054"
      },
      "outputs": [],
      "source": [
        "# Initialize and train the models\n",
        "clf_lr = LogisticRegression(random_state=0)\n",
        "clf_rf = RandomForestClassifier(random_state=0)\n",
        "clf_ab = AdaBoostClassifier(random_state=0)\n",
        "clf_xg = XGBClassifier()\n",
        "\n",
        "# Collect results on the learners\n",
        "results = {}\n",
        "for clf in [clf_lr, clf_ab,clf_rf,clf_xg]:\n",
        "    clf_name = clf.__class__.__name__\n",
        "    results[clf_name] = {}\n",
        "    results[clf_name] = train_predict(clf, X_resampled_train, y_resampled_train.values.ravel(), X_test, y_test.values.ravel())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4bf7359c-750c-4429-28ec-1b628f94971f"
      },
      "outputs": [],
      "source": [
        "lr_res=pd.DataFrame(results['LogisticRegression'],index=['LR'])\n",
        "ab_res=pd.DataFrame(results['AdaBoostClassifier'],index=['AB'])\n",
        "rf_res=pd.DataFrame(results['RandomForestClassifier'],index=['RF'])\n",
        "xg_res=pd.DataFrame(results['XGBClassifier'],index=['XG'])\n",
        "all_res= pd.concat([lr_res,rf_res,ab_res,xg_res])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b64811b1-1a75-bf3a-8b0b-7f0791165fd7"
      },
      "outputs": [],
      "source": [
        "#Untuned Classifiers scores\n",
        "all_res[['train_time','pred_time','acc_train','acc_test','rec_train','rec_test',\\\n",
        "         'prec_train','prec_test','f1_train','f1_test','auc_train','auc_test']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9e1302a7-41bb-8671-3405-7644e8edf93a"
      },
      "outputs": [],
      "source": [
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category = UserWarning, module = \"matplotlib\")\n",
        "#\n",
        "# Display inline matplotlib plots with IPython\n",
        "from IPython import get_ipython\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "###########################################\n",
        "\n",
        "import matplotlib.pyplot as pl\n",
        "import matplotlib.patches as mpatches\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "\n",
        "def evaluate(results):\n",
        "  \n",
        "\t\n",
        "\t# Create figure\n",
        "    fig, ax = pl.subplots(2, 5, figsize = (12,7))\n",
        "    tit_label={0:'Training ',1:'Testing '}\n",
        "\n",
        "\t# Constants\n",
        "    bar_width = 0.2\n",
        "    colors = ['#5F9EA0','#6495ED','#90EE90','#9ACD32']\n",
        "\n",
        "    \n",
        "    # Super loop to plot four panels of data\n",
        "    for k, learner in enumerate(results.keys()):\n",
        "        for j, metric in enumerate(['acc_train','rec_train','prec_train','f1_train','auc_train']):                 \n",
        "           # Creative plot code\n",
        "           ax[0, j].bar(k*bar_width, results[learner][metric], width = bar_width, color = colors[k])\n",
        "           ax[0, j].set_xlim((-0.1, .9))\n",
        "           ax[0,j].set_facecolor('white')\n",
        "           pl.setp(ax[0,j].get_xticklabels(),visible=False)\n",
        "           \n",
        "        for j, metric in enumerate(['acc_test','rec_test','prec_test','f1_test','auc_test']):                 \n",
        "           # Creative plot code\n",
        "           ax[1, j].bar(k*bar_width, results[learner][metric], width = bar_width, color = colors[k])\n",
        "           ax[1, j].set_xlim((-0.1, .9))\n",
        "           ax[1,j].set_facecolor('white')\n",
        "      \n",
        "    for r in range(2):\n",
        "        # Add unique y-labels\n",
        "        ax[r, 0].set_ylabel(\"Accuracy Score\")\n",
        "        ax[r, 1].set_ylabel(\"Recall Score\")\n",
        "        ax[r, 2].set_ylabel(\"Precision score\")\n",
        "        ax[r, 3].set_ylabel(\"F1 - Score\")\n",
        "        ax[r, 4].set_ylabel(\"AUC-score\")\n",
        "        # Add titles\n",
        "        ax[r, 0].set_title(tit_label[r]+\"Accuracy Score\")\n",
        "        ax[r, 1].set_title(tit_label[r]+\"Recall Score\")\n",
        "        ax[r, 2].set_title(tit_label[r]+\"Precision score\")\n",
        "        ax[r, 3].set_title(tit_label[r]+\"F1 - Score\")\n",
        "        ax[r, 4].set_title(tit_label[r]+\"AUC-score\")\n",
        "\t\t\n",
        "    \n",
        "   \n",
        "\n",
        "    # Create patches for the legend\n",
        "    patches = []\n",
        "    for i, learner in enumerate(results.keys()):\n",
        "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
        "        pl.legend(handles = patches, bbox_to_anchor = (-2, 2.4), \\\n",
        "               loc = 'upper center', borderaxespad = 0., ncol = 4, fontsize = 'x-large')\n",
        "    \n",
        "\n",
        "\t# Aesthetics\n",
        "    pl.suptitle(\"Performance Metrics for Four Supervised Learning Models\", fontsize = 16, y = 1.10)\n",
        "    pl.tight_layout()\n",
        "    pl.show()\n",
        "    \n",
        "\n",
        "def comp_stats(results):\n",
        "  \n",
        "\t\n",
        "\t# Create figure\n",
        "    fig, ax = pl.subplots(1, 1, figsize = (4,4))\n",
        "    tit_label={0:'Training ',1:'Testing '}\n",
        "\n",
        "\t# Constants\n",
        "    bar_width = 0.2\n",
        "    colors = ['c','g']\n",
        "    start_l=-0.2\n",
        "\n",
        "    \n",
        "    # Super loop to plot four panels of data\n",
        "    for k, learner in enumerate(results.keys()):\n",
        "        if (k==0):\n",
        "          bar_l=-0.6\n",
        "        else:\n",
        "          bar_l=-0.4\n",
        "        for j, metric in enumerate(['acc_test','rec_test','prec_test','f1_test','auc_test']):                 \n",
        "           bar_l=bar_l+.6 \n",
        "           ax.bar(bar_l, results[learner][metric], width = bar_width, color = colors[k])\n",
        "           \n",
        "\n",
        "    ax.set_xlim((0, 3))\n",
        "    ax.set_xticks([.2, .8, 1.4,2,2.6])\n",
        "    ax.set_xticklabels([\"Accuracy\", \"Recall\", \"Precision\",\"F1\",\"AUC\"])\n",
        "    ax.set_ylabel(\"Score\")\n",
        "    ax.set_facecolor('white')   \n",
        "\t# Create patches for the legend\n",
        "    patches = []\n",
        "    for i, learner in enumerate(results.keys()):\n",
        "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
        "        pl.legend(handles = patches, bbox_to_anchor = (0.4, 1.22), \\\n",
        "               loc = 'upper center', borderaxespad = 0., ncol = 2, fontsize = 10)\n",
        "    \n",
        "    rects = ax.patches\n",
        "    labels=[]\n",
        "\n",
        " \t # Super loop to plot four panels of data\n",
        "    for k, learner in enumerate(results.keys()):\n",
        "        for j, metric in enumerate(['acc_test','rec_test','prec_test','f1_test','auc_test']):                 \n",
        "           labels.append(\"%.4f\" % results[learner][metric])\n",
        "\n",
        "    for rect, label in zip(rects, labels):\n",
        "        height = rect.get_height()\n",
        "        ax.text(rect.get_x() + rect.get_width()/2, height*1.02, label, ha='center', va='bottom',rotation='vertical')\n",
        "\n",
        "\n",
        "\n",
        "\t# Aesthetics\n",
        "    pl.suptitle(\"Metrics for Tuned Models\", fontsize = 14, y = 1.20)\n",
        "    pl.tight_layout()\n",
        "    pl.show()\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bd948a02-9754-dcfe-5e43-41ad03bda481"
      },
      "outputs": [],
      "source": [
        "evaluate(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "10f04c87-2642-2567-9b59-75fe6787de12"
      },
      "source": [
        "-- Based on above graph we can see Random Forest and XGB gives best score, hence taken for further tuning--"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ac495595-58dd-0a26-5491-5b592c33ce8b"
      },
      "source": [
        "#### For XGBoost,below parameters were passed to  GridsearchCV(sklearn.model_selection) procedure \n",
        "\n",
        "{'max_depth': (8, 10)}\n",
        "{'min_child_weight':(2,4)}\n",
        "{'reg_lambda': (0.391, 0.395, 0.399)}\n",
        "{'n_estimators': (150,200)}\n",
        "I could see max_depth=8,min_child_weight=2 were giving best results, hence used for final model \n",
        "\n",
        "For RandomForest Classifier,below parameters were passed to  GridsearchCV(sklearn.model_selection) procedure -\n",
        "{'max_depth': (15, 20)}\n",
        "{'min_samples_split': (3,4)}\n",
        "{'min_samples_leaf': (4,5)}\n",
        "{'n_estimators': (12,14,16)}\n",
        "\n",
        "I could see  max_depth=20,min_samples_leaf=5) were giving best results, hence used for final model \n",
        "\n",
        "**PLEASE NOTE** - *Code for sklearn.model_selection.GridsearchCV is not included here, as I was getting timeout error in Kaggle environment, hence I ran GridsearchCV in my local environment* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2d451eac-3827-bf6d-718d-f9efe00106dd"
      },
      "source": [
        "### Comparison Between Pre & Post Tuned XGB Models(Test Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "59965333-4d83-b0a4-0deb-dedaf32c71aa"
      },
      "outputs": [],
      "source": [
        "clf_pre_tune = XGBClassifier()\n",
        "##Final Tuned XGB Model\n",
        "clf_post_tune = XGBClassifier(max_depth=8,min_child_weight=2)\n",
        "results_tune={}\n",
        "results_tune['XG-PRE-TUNE'] = {}\n",
        "results_tune['XG-PRE-TUNE'] = train_predict(clf_pre_tune, X_resampled_train, y_resampled_train.values.ravel(), X_test, y_test.values.ravel())\n",
        "results_tune['XG-POST-TUNE'] = {}\n",
        "results_tune['XG-POST-TUNE'] = train_predict(clf_post_tune, X_resampled_train, y_resampled_train.values.ravel(), X_test, y_test.values.ravel())\n",
        "\n",
        "xg_pre_tune=pd.DataFrame(results_tune['XG-PRE-TUNE'],index=['XG-PRE-TUNE'])\n",
        "xg_post_tune=pd.DataFrame(results_tune['XG-POST-TUNE'],index=['XG-POST-TUNE'])\n",
        "all_res= pd.concat([xg_pre_tune,xg_post_tune])\n",
        "\n",
        "all_res[['acc_train','acc_test','rec_train','rec_test',\\\n",
        "         'prec_train','prec_test','f1_train','f1_test','auc_train','auc_test']]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "53d9139b-92d8-ab0f-f6b8-3681b89dbdd9"
      },
      "outputs": [],
      "source": [
        "##Comparison between Pre-tuned and post-tuned\n",
        "comp_stats(results_tune)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0e8dd623-5651-d7c9-a3f7-2284954c0728"
      },
      "source": [
        "Comparison(Below one) Between Post Tuned - XGB & RandomForest Classifier(Test Data)\n",
        "------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5822d57e-71b1-dcda-094d-a50c5bcda5d8"
      },
      "outputs": [],
      "source": [
        "## Referred from Random Forest Tuning Notebook\n",
        "clf_post_tune_rf = RandomForestClassifier(random_state=0,max_depth=20,min_samples_leaf=5)\n",
        "##Final Tuned XGB Model\n",
        "clf_post_tune_xgb = XGBClassifier(max_depth=8,min_child_weight=2)\n",
        "results_tune_1={}\n",
        "results_tune_1['RF-POST-TUNE'] = {}\n",
        "results_tune_1['RF-POST-TUNE'] = train_predict(clf_post_tune_rf, X_resampled_train, y_resampled_train.values.ravel(), X_test, y_test.values.ravel())\n",
        "results_tune_1['XG-POST-TUNE'] = {}\n",
        "results_tune_1['XG-POST-TUNE'] = train_predict(clf_post_tune_xgb, X_resampled_train, y_resampled_train.values.ravel(), X_test, y_test.values.ravel())\n",
        "\n",
        "rf_post_tune_1=pd.DataFrame(results_tune_1['RF-POST-TUNE'],index=['RF-POST-TUNE'])\n",
        "xg_post_tune_1=pd.DataFrame(results_tune_1['XG-POST-TUNE'],index=['XG-POST-TUNE'])\n",
        "all_res_1= pd.concat([rf_post_tune_1,xg_post_tune_1])\n",
        "\n",
        "all_res_1[['acc_train','acc_test','rec_train','rec_test',\\\n",
        "         'prec_train','prec_test','f1_train','f1_test','auc_train','auc_test']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "25eba32b-12a9-f3a2-5770-f3019f15ae32"
      },
      "outputs": [],
      "source": [
        "comp_stats(results_tune_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5593555e-a780-4285-8487-5ae7886020d9"
      },
      "source": [
        "## Based on above stats. we can clearly see XGBOOST score is high and best model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e73c4825-1d60-4a40-da47-ea07882a3ab9"
      },
      "source": [
        "Features Importance Chart\n",
        "-------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "34f70893-34f6-f058-0b2e-325b7dd7c486"
      },
      "outputs": [],
      "source": [
        "# feature importance\n",
        "plt.figure(figsize=(6, 6))\n",
        "feature_importance = pd.Series(clf_post_tune.booster().get_fscore()).sort_values(ascending=False)\n",
        "feature_importance.plot(kind='bar', title='Feature Importance')\n",
        "plt.ylabel('Feature Importance Score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "16a83161-d240-7e05-a396-6d51ef61c119"
      },
      "source": [
        "Final Reflection\n",
        "================\n",
        "This problem is highly imbalanced classification problem, where we have more than 99% transactions as normal and <1% as fraud. Data which we got was, PCA applied columns (As original columns were not shared due to privacy reasons)\n",
        "Given data skewedness, classifiers will tend to prefer normal (negative class) transactions and will have challenge identifying fraud positive classes. Hence to overcome this SMOTE (Synthetic Minority Over -sampling Technique) method was used to oversample training data with positive classes, so that classifiers have more positive class to work with.\n",
        "\n",
        "Ensemble methods (Adaboost, RandomForest, XGBoost) were trained on data as ensemble methods tend to predict better for these kinds of problems[4]. RandomForest and XGBoost gave good metrics, were further selected for tuning steps\n",
        "RandomForest and XGBoost were tuned using GridSearchCV 5-fold cross validation data set. Also, I am tuning parameters one by one as tuning multiple parameters at same time was causing program to run for very long time and required lots of memory.\n",
        "\n",
        "***Finally, between 2 classifiers, based on better score, XGBoost is chosen as preferred classifier for the problem.***"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}