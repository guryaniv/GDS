{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ntr = pd.read_csv('../input/train.csv')\nte = pd.read_csv('../input/test.csv')\nfrom nltk.corpus import stopwords\nSCALE = 0.3627","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"850739e54a784705554bb597a1063cf6136d70de"},"cell_type":"code","source":"def word_match_share(x):\n    '''\n    The much-loved word_match_share feature.\n\n    Args:\n        x: source data with question1/2\n        \n    Returns:\n        word_match_share as a pandas Series\n    '''\n    stops = set(stopwords.words('english'))\n    q1 = x.question1.fillna(' ').str.lower().str.split()\n    q2 = x.question2.fillna(' ').str.lower().str.split()\n    q1 = q1.map(lambda l : set(l) - stops)\n    q2 = q2.map(lambda l : set(l) - stops)\n    q = pd.DataFrame({'q1':q1, 'q2':q2})\n    q['len_inter'] = q.apply(lambda row : len(row['q1'] & row['q2']), axis=1)\n    q['len_tot'] = q.q1.map(len) + q.q2.map(len)\n    return (2 * q.len_inter / q.len_tot).fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1a4021f192ebe4f211f6df43cd0c094d0745ab2"},"cell_type":"code","source":"def bin_model(tr, te, bins=100, vpos=1, vss=3):\n    '''\n    Runs a Pandas table model using the word_match_share feature.\n    \n    Args:\n        tr: pandas DataFrame with question1/2 in it\n        te: test data frame\n        bins: word shares are rounded to whole numbers after multiplying by bins.\n        v_pos: number of virtual positives for smoothing (can be non-integer)\n        vss: virtual sample size for smoothing (can be non-integer)\n        \n    Returns:\n        submission in a Pandas Data Frame.\n    '''\n    tr['word_share'] = word_match_share(tr)\n    tr['binned_share'] = (bins * tr.word_share).round()\n    pos = tr.groupby('binned_share').is_duplicate.sum()\n    cts = tr.binned_share.value_counts()\n    te['word_share'] = word_match_share(te)\n    te['binned_share'] = (bins * te.word_share).round()\n    te_pos = te.binned_share.map(pos, na_action='ignore').fillna(0)\n    te_cts = te.binned_share.map(cts, na_action='ignore').fillna(0)\n    prob = (te_pos + vpos) / (te_cts + vss)\n    odds = prob / (1 - prob)\n    scaled_odds = SCALE * odds\n    scaled_prob = scaled_odds / (1 + scaled_odds)\n    sub = te[['test_id']].copy()\n    sub['is_duplicate'] = scaled_prob\n    return sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a02e9830305e4d3d449dc2271f57d62d9c7bdea5"},"cell_type":"code","source":"sub = bin_model(tr, te)\nsub.to_csv('no_ml_model.csv', index=False, float_format='%.6f')\nsub.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92f6d52a24743ee728e33734a6fff310e5215ae6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}