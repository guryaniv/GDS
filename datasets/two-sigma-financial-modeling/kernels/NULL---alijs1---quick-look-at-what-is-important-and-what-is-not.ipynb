{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "76c9fea4-359a-4ede-e0f5-eef60b68e253"
      },
      "source": [
        "In this competition we have only limited time to run kernel for submission, so it's really important to take a good choice of what is imortant and what is not worth to waste a time on..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7d63f49d-f05b-9555-bf75-2487129b72dc"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "with pd.HDFStore(\"../input/train.h5\", \"r\") as train:\n",
        "    df = train.get(\"train\")\n",
        "print(\"Train shape: {}\".format(df.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d7c43410-90cf-0b54-ad33-40b654e0e7a0"
      },
      "outputs": [],
      "source": [
        "# Values from top public kernel https://www.kaggle.com/bguberfain/two-sigma-financial-modeling/univariate-model-with-clip/run/482189\n",
        "low_y_cut = -0.086092\n",
        "high_y_cut = 0.093496\n",
        "\n",
        "print(\"Preparing data for model...\")\n",
        "df = df.sample(frac=0.1)\n",
        "df.fillna(df.mean(axis=0), inplace=True)\n",
        "y_is_within_cut = ((df['y'] > low_y_cut) & (df['y'] < high_y_cut))\n",
        "\n",
        "train_X = df.loc[y_is_within_cut, df.columns[2:-1]]\n",
        "train_y = df.loc[y_is_within_cut, 'y'].values.reshape(-1, 1)\n",
        "print(\"Data for model: X={}, y={}\".format(train_X.shape, train_y.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d0a55e40-523f-8ccb-8994-31c56726b1e1"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "model = xgb.XGBRegressor()\n",
        "print(\"Fitting...\")\n",
        "model.fit(train_X, train_y)\n",
        "print(\"Fitting done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "56624d0b-2a51-76fa-c593-b4fff9fdfc75"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize=(7, 30))\n",
        "xgb.plot_importance(model, ax=ax)\n",
        "print(\"Features importance done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "460218de-253a-fa3c-756e-318985bc718f"
      },
      "source": [
        "Feature techical_20 is on top... not a big surprise, because in currently top public kernel it is the only one feature used. Now I see, why :)\n",
        "\n",
        "To be continued later..."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}