{"cells":[{"metadata":{"trusted":true,"_uuid":"c5072e8dab4677e608e024549e696917ada69d6c"},"cell_type":"code","source":"# References : https://www.kaggle.com/bguberfain/unet-with-depth/notebook\n# https://www.kaggle.com/stefanie04736/simple-keras-model-with-k-fold-cross-validation\n\nimport os\nimport sys\nimport random\nimport warnings\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport cv2\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D, AveragePooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\n\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57a2e41f3147db1a62009151e3fdb0055ce6b227"},"cell_type":"code","source":"# Set some parameters\nim_width = 128\nim_height = 128\nborder = 5\nim_chan = 2 # Number of channels: first is original and second cumsum(axis=0)\nn_features = 1 # Number of extra features, like depth\npath_train = '../input/train/'\npath_test = '../input/test/'\n\ndf_depths = pd.read_csv('../input/depths.csv', index_col='id')\ndf_depths.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b4f8005a550d7b002710d7b441a5605d4ec5ab5","collapsed":true},"cell_type":"code","source":"train_ids = next(os.walk(path_train+\"images\"))[2]\ntest_ids = next(os.walk(path_test+\"images\"))[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a368a2db32093fb65244be341229dfa7c637e9e"},"cell_type":"code","source":"# Get and resize train images and masks\nX = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.float32)\ny = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.float32)\nX_feat = np.zeros((len(train_ids), n_features), dtype=np.float32)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n    path = path_train\n    \n    # Depth\n    X_feat[n] = df_depths.loc[id_.replace('.png', ''), 'z']\n    \n    # Load X\n    img = load_img(path + '/images/' + id_, grayscale=True)\n    x_img = img_to_array(img)\n    x_img = resize(x_img, (128, 128, 1), mode='constant', preserve_range=True)\n    \n    # Create cumsum x\n    x_center_mean = x_img[border:-border, border:-border].mean()\n    x_csum = (np.float32(x_img)-x_center_mean).cumsum(axis=0)\n    x_csum -= x_csum[border:-border, border:-border].mean()\n    x_csum /= max(1e-3, x_csum[border:-border, border:-border].std())\n\n    # Load Y\n    mask = img_to_array(load_img(path + '/masks/' + id_, grayscale=True))\n    mask = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n\n    # Save images\n    X[n, ..., 0] = x_img.squeeze() / 255\n    X[n, ..., 1] = x_csum.squeeze()\n    y[n] = mask / 255\n\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23cbf9dfef6fefa575c3a34170f016b6c0880ad7"},"cell_type":"code","source":"np.sum(y)/y.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0b79c28e03f70914d2d7ff51f1a22ccebba9f4d","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n# Split train and valid\nX_train, X_valid, X_feat_train, X_feat_valid, y_train, y_valid = train_test_split(X, X_feat, y, test_size=0.15, random_state=42)\n# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.16, random_state=42) # Want a balanced split for all the classes\n# for train_index, trainxfeat_index, test_index in sss.split(X,X_feat,y):\n#     print(\"Using {} for training,{} for festing and {} for validation\".format(len(train_index), len(trainxfeat_index), len(test_index)))\n#     x_train, x_valid = X[train_index], X[test_index]\n#     X_feat_train, X_feat_valid = X_feat[trainxfeat_index], X_feat[trainxfeat_index]\n#     y_train, y_valid = y[train_index], y[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5fdfb278b6f88136a81dde128c7d1e64f4e43286"},"cell_type":"code","source":"# Normalize X_feat\nx_feat_mean = X_feat_train.mean(axis=0, keepdims=True)\nx_feat_std = X_feat_train.std(axis=0, keepdims=True)\nX_feat_train -= x_feat_mean\nX_feat_train /= x_feat_std\n\nX_feat_valid -= x_feat_mean\nX_feat_valid /= x_feat_std","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7da913dcc304ea72195ce1486cb90932d7a72471"},"cell_type":"markdown","source":"<div class=\"inner_cell\">\n<div class=\"text_cell_render border-box-sizing rendered_html\">\n<h1 id=\"Build-and-train-our-neural-network\">Build and train our neural network<a class=\"anchor-link\" href=\"#Build-and-train-our-neural-network\" target=\"_self\">¶</a></h1><p>Next we build our U-Net model, loosely based on <a href=\"https://arxiv.org/pdf/1505.04597.pdf\">U-Net: Convolutional Networks for Biomedical Image Segmentation</a> and very similar to <a href=\"https://github.com/jocicmarko/ultrasound-nerve-segmentation\">this repo</a> from the Kaggle Ultrasound Nerve Segmentation competition.</p>\n<p><img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" alt=\"\"></p>\n\n</div>\n</div>"},{"metadata":{"trusted":true,"_uuid":"e570851cda439be11d387151a2912c9dfa361ce0"},"cell_type":"code","source":"def get_model():\n    # Build U-Net model\n    input_img = Input((128,128,2), name='img')\n    input_features = Input((n_features, ), name='feat')\n\n    c1 = Conv2D(32, (3, 3), activation='relu', padding='same') (input_img)\n    c1 = Conv2D(32, (3, 3), activation='relu', padding='same') (c1)\n    p1 = AveragePooling2D((2, 2)) (c1)\n\n    c2 = Conv2D(32, (3, 3), activation='relu', padding='same') (p1)\n    c2 = Conv2D(64, (3, 3), activation='relu', padding='same') (c2)\n    p2 = AveragePooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(64, (3, 3), activation='relu', padding='same') (p2)\n    c3 = Conv2D(64, (3, 3), activation='relu', padding='same') (c3)\n    p3 = AveragePooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(128, (3, 3), activation='relu', padding='same') (p3)\n    c4 = Conv2D(128, (3, 3), activation='relu', padding='same') (c4)\n    p4 = AveragePooling2D(pool_size=(2, 2)) (c4)\n\n    # Join features information in the depthest layer\n    f_repeat = RepeatVector(8*8)(input_features)\n    f_conv = Reshape((8, 8, n_features))(f_repeat)\n    p4_feat = concatenate([p4, f_conv], -1)\n\n    c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4_feat)\n    c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\n    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\n    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\n    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(32, (3, 3), activation='relu', padding='same') (u8)\n    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\n    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(16, (3, 3), activation='relu', padding='same') (u9)\n    c9 = Conv2D(16, (3, 3), activation='relu', padding='same') (c9)\n\n    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\n    model = Model(inputs=[input_img, input_features], outputs=[outputs])\n    model.compile(optimizer='adam', loss='binary_crossentropy') #, metrics=[mean_iou]) # The mean_iou metrics seens to leak train and test values...\n    return model\n\nmodel = get_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"43f40bc916ec017b97a443851519c02290a9277f"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nbatch_size=40\n# Define the image transformations here\ngen = ImageDataGenerator(horizontal_flip = False,\n                         vertical_flip = True,\n                         width_shift_range = 0.1,\n                         height_shift_range = 0.1,\n                         zoom_range = 0.1)\n\n# Here is the function that merges our two generators\n# We use the exact same generator with the same random seed for both the y and angle arrays\ndef gen_flow_for_two_inputs(X1, X2, y):\n    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=666)\n    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=666)\n    while True:\n            X1i = genX1.next()\n            X2i = genX2.next()\n            #Assert arrays are equal - this was for peace of mind, but slows down training\n            #np.testing.assert_array_equal(X1i[0],X2i[0])\n            yield [X1i[0], X2i[1]], X1i[1]\n\n# Finally create generator\ngen_flow = gen_flow_for_two_inputs(X_train, X_feat_train, y_train)\n\ndef get_callbacks():\n    mcp_save =  ModelCheckpoint('model-tgs-salt-1.h5', save_best_only=True, monitor='val_loss', verbose=1)\n    earlystopping = EarlyStopping(patience=10, verbose=1)\n    reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4)\n    return [mcp_save, reduce_lr_loss, earlystopping]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a5f0ad0d57bf673c9428e25d4b41b6b36bc6e6f","scrolled":false,"collapsed":true},"cell_type":"code","source":"# batch_size=16\n# generator = gen.flow({'img': X_train, 'feat': X_feat_train}, y_train, batch_size = batch_size)\n# val_generator = gen.flow({'img': X_train, 'feat': X_feat_train}, y_train, batch_size = batch_size)\ncallbacks = get_callbacks()    \n# results = model.fit({'img': X_train, 'feat': X_feat_train}, y_train, batch_size=16, epochs=50, callbacks=callbacks,\n#                     validation_data=({'img': X_valid, 'feat': X_feat_valid}, y_valid))\n\n# Fit the model using our generator defined above\nresult = model.fit_generator(gen_flow, validation_data=([X_valid, X_feat_valid], y_valid),\n                    steps_per_epoch=len(X_train) / batch_size, epochs=60,callbacks=callbacks)\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"collapsed":true,"_uuid":"774a8adf16ab12d2484fc240a18a0b1227dc64a4"},"cell_type":"code","source":"# for j, train_idx in enumerate(folds):\n#     print('\\nFold ',j)\n#     callbacks = get_callbacks()\n#     generator = gen.flow({'img': X_train, 'feat': X_feat_train}, y_train, batch_size = batch_size)\n#     val_generator = gen.flow({'img': X_train, 'feat': X_feat_train}, y_train, batch_size = batch_size)\n#     model = get_model()\n#     model.fit_generator(\n#                 generator,\n#                 steps_per_epoch=len(X_train)/batch_size,\n#                 epochs=30,\n#                 shuffle=True,\n#                 verbose=1,\n#                 validation_data = val_generator,\n#                 callbacks = callbacks)\n    \n#     print(model.evaluate(X_valid_cv, y_valid_cv))\n\n#     results = model.fit({'img': X_train, 'feat': X_feat_train}, y_train, batch_size=16, epochs=50, callbacks=callbacks,\n#                     validation_data=({'img': X_valid, 'feat': X_feat_valid}, y_valid))  \n#     print(model.evaluate({'img': X_valid, 'feat': X_feat_valid}, y_valid))\n    \n#     model.fit_generator(\n#                 generator,\n#                 steps_per_epoch=len(X_train_cv)/batch_size,\n#                 epochs=15,\n#                 shuffle=True,\n#                 verbose=1,\n#                 validation_data = (X_valid_cv, y_valid_cv),\n#                 callbacks = callbacks)\n\n\n\n\n# for j, (train_idx, val_idx) in enumerate(folds):\n    \n#     print('\\nFold ',j)\n#     X_train_cv = X_train[train_idx]\n#     y_train_cv = y_train[train_idx]\n#     X_valid_cv = X_train[val_idx]\n#     y_valid_cv= y_train[val_idx]\n    \n#     name_weights = \"final_model_fold\" + str(j) + \"_weights.h5\"\n#     callbacks = get_callbacks(name_weights = name_weights, patience_lr=10)\n#     generator = gen.flow(X_train_cv, y_train_cv, batch_size = batch_size)\n#     model = get_model()\n#     model.fit_generator(\n#                 generator,\n#                 steps_per_epoch=len(X_train_cv)/batch_size,\n#                 epochs=15,\n#                 shuffle=True,\n#                 verbose=1,\n#                 validation_data = (X_valid_cv, y_valid_cv),\n#                 callbacks = callbacks)\n    \n#     print(model.evaluate(X_valid_cv, y_valid_cv))\n\n\n# [\n#     ModelCheckpoint('model-tgs-salt-1.h5', save_best_only=True, monitor='val_loss', verbose=1)\n#     EarlyStopping(patience=10, verbose=1),\n# #     ReduceLROnPlateau(patience=3, verbose=1),\n#     ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4),\n# #     ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True, save_weights_only=True)\n#     ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45a96d8f2792c0443adfc0e2dd25fadb59d28881","collapsed":true},"cell_type":"code","source":"# Get and resize test images\nX_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.float32)\nX_feat_test = np.zeros((len(test_ids), n_features), dtype=np.float32)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n    path = path_test\n    \n    # Depth\n    X_feat_test[n] = df_depths.loc[id_.replace('.png', ''), 'z']\n    \n    # Load X\n    img = load_img(path + '/images/' + id_, grayscale=True)\n    x = img_to_array(img)\n    sizes_test.append([x.shape[0], x.shape[1]])\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    \n    # Create cumsum x\n    x_center_mean = x[border:-border, border:-border].mean()\n    x_csum = (np.float32(x)-x_center_mean).cumsum(axis=0)\n    x_csum -= x_csum[border:-border, border:-border].mean()\n    x_csum /= max(1e-3, x_csum[border:-border, border:-border].std())\n\n    # Save images\n    X_test[n, ..., 0] = x.squeeze() / 255\n    X_test[n, ..., 1] = x_csum.squeeze()\n\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e9f7e625d36dc30860f4fc1b3d1f1283028ae946"},"cell_type":"code","source":"# Normalize X_test_feats\nX_feat_test -= x_feat_mean\nX_feat_test /= x_feat_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"adcb608688cfdc46b3792456ab05dc9c2b983c3e"},"cell_type":"code","source":"# Load best model\nmodel.load_weights('model-tgs-salt-1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89e64b1ccfa10fdfc0bead3d0f336b0df2afcec4","collapsed":true},"cell_type":"code","source":"# Evaluate on validation set (this must be equals to the best log_loss)\nmodel.evaluate({'img': X_valid, 'feat': X_feat_valid}, y_valid, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0164f5ad10453b7af0119c146bbc8332c103b1ec","collapsed":true},"cell_type":"code","source":"# Predict on train, val and test\npreds_train = model.predict({'img': X_train, 'feat': X_feat_train}, verbose=1)\npreds_val = model.predict({'img': X_valid, 'feat': X_feat_valid}, verbose=1)\npreds_test = model.predict({'img': X_test, 'feat': X_feat_test}, verbose=1)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ffd1dc803e78366304a5d22cf897c71e57c4918","collapsed":true},"cell_type":"code","source":"# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in tnrange(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdeaa3a0e6aeaa4fc90da99056a3c9279650f2b4","collapsed":true},"cell_type":"code","source":"preds_test_upsampled[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"adcfa4122aef817cb2dd89e68f3564ad3ac48076"},"cell_type":"code","source":"def plot_sample(X, y, preds):\n    ix = random.randint(0, len(X))\n\n    has_mask = y[ix].max() > 0\n\n    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n    ax[0].imshow(X[ix, ..., 0], cmap='seismic')\n    if has_mask:\n        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[0].set_title('Seismic')\n\n    ax[1].imshow(X[ix, ..., 1], cmap='seismic')\n    if has_mask:\n        ax[1].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[1].set_title('Seismic cumsum')\n\n    ax[2].imshow(y[ix].squeeze())\n    ax[2].set_title('Salt')\n\n    ax[3].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n    if has_mask:\n        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[3].set_title('Salt Pred');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"37fcc6fb4fa93887b80719ef17800a2998988cf2"},"cell_type":"code","source":"# src: https://www.kaggle.com/aglotero/another-iou-metric\ndef iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n    \n    true_objects = 2\n    pred_objects = 2\n\n    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins = true_objects)[0]\n    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection / union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp / (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebda2a894e51bb8de20742babd45dce6af89401d","collapsed":true},"cell_type":"code","source":"thres = np.linspace(0.25, 0.75, 20)\nthres_ioc = [iou_metric_batch(y_valid, np.int32(preds_val > t)) for t in tqdm_notebook(thres)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"235b90a7a1fbdad706d5d9f7af4932ed1cd4977b","collapsed":true},"cell_type":"code","source":"plt.plot(thres, thres_ioc);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e059ec9b5d6e31a152677ea2dfd45a705f55dfc8","collapsed":true},"cell_type":"code","source":"best_thres = thres[np.argmax(thres_ioc)]\nbest_thres, max(thres_ioc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69f3446c7451d478cb05118eadf564f8bd5cfb1a","collapsed":true},"cell_type":"code","source":"def RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n\npred_dict = {id_[:-4]:RLenc(np.round(preds_test_upsampled[i] > best_thres)) for i,id_ in tqdm_notebook(enumerate(test_ids))}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0ffc4f230efc7719ec53dc2eac42408005989e48"},"cell_type":"code","source":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59442a6b76283cd7ff402f9de0ecd98723291aac","collapsed":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4e564c0d46095f3a176bde38583913b4f777ebd2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}