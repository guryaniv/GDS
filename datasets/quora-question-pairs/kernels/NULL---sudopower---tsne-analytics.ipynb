{"cells":[{"metadata":{"_cell_guid":"e8acc802-80ba-e4b0-403c-df40ce20cf20","_uuid":"273b50c00b0a1be0cc7e6e47951f54b62a186afa"},"cell_type":"markdown","source":"# Visualizing Word Vectors with t-SNE\n\nTSNE is pretty useful when it comes to visualizing similarity between objects. It works by taking a group of high-dimensional (100 dimensions via Word2Vec) vocabulary word feature vectors, then compresses them down to 2-dimensional x,y coordinate pairs. The idea is to keep similar words close together on the plane, while maximizing the distance between dissimilar words. \n\n### Steps\n\n1. Clean the data\n2. Build a corpus\n3. Train a Word2Vec Model\n4. Visualize t-SNE representations of the most common words \n\nCredit: Some of the code was inspired by this awesome [NLP repo][1]. \n\n\n\n\n  [1]: https://github.com/rouseguy/DeepLearningNLP_Py"},{"metadata":{"_cell_guid":"327a2a48-c101-959c-af2d-cabd82276e65","_uuid":"f490f8e2b73cfe9e90d3260a01cea0ca193575d1","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.options.mode.chained_assignment = None \nimport numpy as np\nimport re\nimport nltk\nimport sys\n\nfrom gensim.models import word2vec\n\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndata = pd.read_csv('../input/train.csv').sample(50000, random_state=23)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c5d7458b-d380-8af7-13cf-5ed65fb42a83","_uuid":"cc8556e5c6ed8b27718fcb658f10661fe5c11f6f","trusted":true},"cell_type":"code","source":"STOP_WORDS = nltk.corpus.stopwords.words()\n\ndef clean_sentence(val):\n    \"remove chars that are not letters or numbers, downcase, then remove stop words\"\n    regex = re.compile('([^\\s\\w]|_)+')\n    sentence = regex.sub('', val).lower()\n    sentence = sentence.split(\" \")\n    \n    for word in list(sentence):\n        if word in STOP_WORDS:\n            sentence.remove(word)  \n            \n    sentence = \" \".join(sentence)\n    return sentence\n\ndef clean_dataframe(data):\n    \"drop nans, then apply 'clean_sentence' function to question1 and 2\"\n    data = data.dropna(how=\"any\")\n    \n    for col in ['question1', 'question2']:\n        data[col] = data[col].apply(clean_sentence)\n    \n    return data\n\ndata = clean_dataframe(data)\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e72326d7-e707-d4e9-928a-519a9193bfc5","_uuid":"4508b391db86f5574a8f916f2a20238ca10339ba","trusted":true},"cell_type":"code","source":"def build_corpus(data):\n    \"Creates a list of lists containing words from each sentence\"\n    corpus = []\n    for col in ['question1', 'question2']:\n        for sentence in data[col].iteritems():\n            word_list = sentence[1].split(\" \")\n            corpus.append(word_list)\n            \n    return corpus\n\ncorpus = build_corpus(data)        \ncorpus[0:2]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c652ad03-be65-f4e6-0afd-02c237449b43","_uuid":"79dbef81dcedca1f436211bbb586976d72898c6d"},"cell_type":"markdown","source":"# Word 2 Vec\n\nThe Word to Vec model produces a vocabulary, with each word being represented by an n-dimensional numpy array (100 values in this example)"},{"metadata":{"_cell_guid":"ee9f9d57-5b3a-16c0-916f-169ef6d7b920","_uuid":"9e3e23001ed0bb32cccfc918615ba94628c6b0af","trusted":true},"cell_type":"code","source":"model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=200, workers=4)\nmodel.wv['trump']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4512c76e-f4da-c793-be73-5b18b5bb70e9","_uuid":"4c59a647cefa9d0836fbcb0c32c76e7429339343","trusted":true},"cell_type":"code","source":"def tsne_plot(model):\n    \"Creates and TSNE model and plots it\"\n    labels = []\n    tokens = []\n\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(16, 16)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"19ec33d2-5160-6556-c8da-a5a53316619a","_uuid":"93bff73dc071b5649d158eef821b313fdccb2603","trusted":true},"cell_type":"code","source":"tsne_plot(model)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b5ffb880-585d-6ea8-51a5-a6351ea2ff20","_uuid":"5449acdc59de685d9eaa2aaa2b084da9d2a2f6fe","trusted":true},"cell_type":"code","source":"# A more selective model\nmodel = word2vec.Word2Vec(corpus, size=100, window=20, min_count=500, workers=4)\ntsne_plot(model)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9f64e341-1967-617f-4004-ef7c6d109277","_uuid":"8b3bdbc614b76e450d742d0680a2485d0a33af0f","trusted":true},"cell_type":"code","source":"# A less selective model\nmodel = word2vec.Word2Vec(corpus, size=100, window=20, min_count=100, workers=4)\ntsne_plot(model)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2ba89a55-30b7-15ea-c571-9e402e1c03d2","_uuid":"f5ecce8e301d67ecc70b725c793215c8c7daf695"},"cell_type":"markdown","source":"# It's Becoming Hard to Read\n\nWith a dataset this large, its difficult to make an easy-to-read TSNE visualization. What you can do is use the model to look up the most similar words from any given point. "},{"metadata":{"_cell_guid":"109ae353-5679-6f7a-74f6-ae13d7042639","_uuid":"3e495f14972d9c5e7191c6c3377fc8633774f96f","trusted":true},"cell_type":"code","source":"model.most_similar('election')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"67a0844e-83d6-22ab-a89b-ae15c19860a8","_uuid":"36366eb4a7bdb65b018cb410a5720936b6c31b63","trusted":true},"cell_type":"code","source":"model.most_similar('indian')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a88070c7-87cd-0daa-61f7-b2d5ab1ca6ad","_uuid":"c41fde8d6ec5685d78591d42694ba83eeecfbd65"},"cell_type":"markdown","source":"# The End\n\nGood luck!"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}