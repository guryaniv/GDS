{"metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "file_extension": ".py", "mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.6.1"}}, "cells": [{"metadata": {"_execution_state": "idle", "_uuid": "e1d72f0851e1df8a556dd53a8aeca8060462c259", "collapsed": false, "_cell_guid": "99e0a08d-7284-48a7-bb3e-91270e87ef3d"}, "execution_count": null, "cell_type": "markdown", "source": "**UPDATE:** Seems that Kaggle kernel doesn't support **bokeh** visualization. So, I've uploaded the ipython notebook at [github][1].\n\nIn the competition, [New York City Taxi Trip Duration][2], Kaggle is challenging you to build a model that predicts the total ride duration of taxi trips in New York City. Your primary dataset is one released by the NYC Taxi and Limousine Commission, which includes pickup time, geo-coordinates, number of passengers, and several other variables.\nIn this notebook, we'll try to make some visualization using New York City Taxi Trip Duration data. There are many good kernels and discussions related to EDA of NYC Taxi data, however, we'll demonstrate how the datashader and bokeh library help make large dataset truely practical.\n\n[Datashader][3] is a data rasterization pipeline for automating the process of creating meaningful representations of large amounts of data. Datashader breaks the creation of images of data into 3 main steps: Projection, Aggregation and Transformation. These aggregates are then further processed, eventually creating an image. Using this very general pipeline, many interesting data visualizations can be created in a performant and scalable way. Datashader contains tools for easily creating these pipelines in a composable manner, using only a few lines of code. Datashader can be used on its own, but it is also designed to work as a pre-processing stage in a plotting library, allowing that library to work with much larger datasets than it would otherwise.\n\n[Bokeh][4] is a Python interactive visualization library that targets modern web browsers for presentation. Its goal is to provide elegant, concise construction of novel graphics in the style of D3.js, and to extend this capability with high-performance interactivity over very large or streaming datasets. Bokeh can help anyone who would like to quickly and easily create interactive plots, dashboards, and data applications.\n\n\n  [1]: https://github.com/akhanss/nyc-taxi-trip-duration/blob/master/Interactive%20Data%20Visualization%20using%20datashader%20and%20bokeh.ipynb\n  [2]: https://www.kaggle.com/c/nyc-taxi-trip-duration\n  [3]: https://github.com/bokeh/datashader\n  [4]: http://bokeh.pydata.org/en/latest/", "outputs": []}, {"metadata": {"_execution_state": "idle", "trusted": false, "_uuid": "8af73343e62d3e09e57286a3fd0cd92c54d04b02", "_cell_guid": "475d8736-361a-4922-964d-0b08ebf4d213"}, "execution_count": null, "cell_type": "code", "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "457275f89485820c7920d4f8901cf63cb69f39ae", "collapsed": false, "_cell_guid": "3e4a9515-f110-4f61-b9b9-c251222bd1bb"}, "execution_count": null, "cell_type": "markdown", "source": "**Load NYC Taxi Trip Data**", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "12e2805825a420e80b17ed7fd1ae8da0108d55a8", "collapsed": false, "_cell_guid": "61041a5e-318c-4861-9c40-a02874f8e16f"}, "execution_count": null, "cell_type": "code", "source": "%time\n# We'll load some important columns only\ndf = pd.read_csv('../input/train.csv',\n                 usecols=['pickup_datetime', 'dropoff_datetime', 'passenger_count', 'pickup_longitude', 'pickup_latitude',\n                          'dropoff_longitude', 'dropoff_latitude',  'trip_duration'])", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "48aa5fd48c19d5bbc01a79fb1ffa2db7768ba781", "collapsed": false, "_cell_guid": "ffe7586a-3af3-45ff-ae6b-b4a9e121e3e0"}, "execution_count": null, "cell_type": "code", "source": "# Let's see some records\ndf.head()", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "582b1299bf84b161db9876f7458571b218c0e526", "collapsed": false, "_cell_guid": "5ef9422d-3826-47e2-8d92-fc346a8caa72"}, "execution_count": null, "cell_type": "markdown", "source": "The training set contains about 1.5 million pickup and dropoff locations with passenger counts and trip durations.", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "b50603b9d44704f09cec1724a6adaaea75ddcc87", "collapsed": false, "_cell_guid": "69e42e74-6880-4ee3-bcc9-3404bd662d42"}, "execution_count": null, "cell_type": "code", "source": "# size of the training set\nprint('Size:', df.shape[0])", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "e5fe53a675ce9376b2cf540e0fc510877d96067f", "collapsed": false, "_cell_guid": "d47a0e5e-d60b-4a70-98ca-2c1eb41d1469"}, "execution_count": null, "cell_type": "code", "source": "from bokeh.plotting import figure, output_notebook, show # bokeh plotting library\n# We'll show the plots in the cells of this notebook\noutput_notebook()", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "44447ff1ac3a4d692a0547fb83d8b32a5e122ae9", "collapsed": false, "_cell_guid": "6168064f-58b0-4018-998f-cf430584da29"}, "execution_count": null, "cell_type": "code", "source": "import numpy as np # linear algebra and Scientific calculation\n\n# let's find pickup and dropoff longitude and latitude range\nprint(np.min(df['pickup_longitude']), np.min(df['pickup_latitude']))\nprint(np.max(df['pickup_longitude']), np.max(df['pickup_latitude']))\n\nprint(np.min(df['dropoff_longitude']), np.min(df['dropoff_latitude']))\nprint(np.max(df['dropoff_longitude']), np.max(df['dropoff_latitude']))", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "ccba768519aabe1aa077d9a79935c3ebf876abbc", "collapsed": false, "_cell_guid": "f6b75340-a0aa-4153-82b1-cf92e353afaa"}, "execution_count": null, "cell_type": "markdown", "source": "So, we've x_range (-121.93334198, -61.3355293274) and y_range is (32.1811408997, 51.8810844421). However, most of the rides occur within the x_range (-74.05, -73.7) and y_range (40.6, 40.9). For nice visualation, we'll omit the outliers from the initial plot. But you can explore the data using the **wheel zooming** facility of the bokeh plot.\n\n**Let's define a base plot**", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "1865a6cba3fc0a423be075c021f863f0f4848fc2", "collapsed": false, "_cell_guid": "49636167-5731-4ed1-b038-db9b52b84b64"}, "execution_count": null, "cell_type": "code", "source": "# NYC = x_range, y_range = ((-121.93334198, -61.3355293274), (32.1811408997, 51.8810844421))\nNYC = x_range, y_range = ((-74.05, -73.7), (40.6, 40.9))\n\nplot_width = int(750)\nplot_height = int(plot_width//1.2)\n\ndef base_plot(tools='pan, wheel_zoom, reset', plot_width=plot_width, plot_height=plot_height, **plot_args):\n    p = figure(tools=tools, plot_width=plot_width, plot_height=plot_height,\n              x_range=x_range, y_range=y_range, outline_line_color=None,\n              min_border=0, min_border_left=0, min_border_right=0,\n              min_border_top=0, min_border_bottom=0, **plot_args)\n    \n    p.xgrid.grid_line_color = None\n    p.ygrid.grid_line_color = None\n    return p\n\noptions = dict(line_color=None, fill_color='blue', size=5)", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "51e92435384aa00c6462ac5288bd789346661e16", "collapsed": false, "_cell_guid": "e49b98dc-d719-4719-8b87-c2bf22919110"}, "execution_count": null, "cell_type": "markdown", "source": "**Let's make 10K pickup-points scatterplot**", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "af975fd872658f24dd2ea55fb66772763b41a227", "collapsed": false, "_cell_guid": "19ab1668-ed03-4231-8191-4cf6de6bf7a7"}, "execution_count": null, "cell_type": "code", "source": "%%time\n# let's plot 10k sample pickup\nsamples = df.sample(n=10000)\np = base_plot()\n\np.circle(x=samples['pickup_longitude'], y=samples['pickup_latitude'], **options)\nshow(p)", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "7aa139f898f2289fe9d94ed8951c83dcde28a93e", "collapsed": false, "_cell_guid": "1e19a120-30f3-40c6-b895-1b7d6ab6eeb9"}, "execution_count": null, "cell_type": "markdown", "source": "This size of the plot can be handled by any plotting library. Here the points are initially overplotting each other, but using zooming button, nearly all of them should be ** clearly visible in the bokeh plot **.\n\n**Here is 10K dropoff-points scatter plot**", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "55b58805fc13b9433d27a408135a0924118c8a70", "collapsed": false, "_cell_guid": "e50ba484-77ac-4700-a36f-a8e7330cd80d"}, "execution_count": null, "cell_type": "code", "source": "%%time\n# Again, let's plot 10k sample dropoff\nsamples = df.sample(n=10000)\np = base_plot()\n\np.circle(x=samples['dropoff_longitude'], y=samples['dropoff_latitude'], **options)\nshow(p)", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "1d33a049fea2ce32b13b18b58133276fb8d909fd", "collapsed": false, "_cell_guid": "3dfa545b-5f82-41af-9f98-94122f35446b"}, "execution_count": null, "cell_type": "markdown", "source": "We've plotted a subsample of data in the above figures and those are not so dense. When datasize grows to include millions and billions of points, traditional visualization techniques break down. Whether you're loading the data into limited memory, or separating the signal from the noise when thousands of data points occupy each pixel, as data gets big, visualization gets challenging.\n\n**Datashader** deconstructs the classical visualization pipeline to place statistical processing at the heart of the visualization task. The result is a scalable, interactive system that is easy to use and produces perceptually accurate renderings of extremely large datasets.", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "0c88a9dc4430f9fe40c772ab46f3774d8b539f6b", "collapsed": false, "_cell_guid": "13b31834-be48-4f9c-a89d-1b777e4092a0"}, "execution_count": null, "cell_type": "code", "source": "import datashader as ds\nfrom datashader import transfer_functions as tr_fns\nfrom datashader.colors import Greys9\nGreys9_r = list(reversed(Greys9))[:2]", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "52a1cc4e0d8032e1ba8fc73e79c4252d9d02bfd7", "collapsed": false, "_cell_guid": "24648419-4878-4739-a406-8151a9bd1fa4"}, "execution_count": null, "cell_type": "code", "source": "%%time\ncvs = ds.Canvas(plot_width=plot_width, plot_height=plot_height, x_range=x_range, y_range=y_range)\nagg = cvs.points(df, 'dropoff_longitude', 'dropoff_latitude', ds.count('passenger_count'))\nimg = tr_fns.shade(agg, cmap=[\"white\", 'darkblue'], how='linear')\n\nimg", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "d1d24fae867173d02d25d149520c9bb7400dbb9e", "collapsed": false, "_cell_guid": "49dbc158-e2b1-4409-aff9-b946536c39f6"}, "execution_count": null, "cell_type": "code", "source": "from datashader.bokeh_ext import InteractiveImage\nfrom functools import partial\nfrom datashader.utils import export_image\nfrom datashader.colors import colormap_select, Greys9, Hot, viridis, inferno\nfrom IPython.core.display import HTML, display\n\nbackground = \"black\"\nexport = partial(export_image, export_path=\"export\", background=background)\ncm = partial(colormap_select, reverse=(background==\"black\"))\n\ndef create_image(x_range, y_range, w=plot_width, h=plot_height):\n    cvs = ds.Canvas(plot_width=w, plot_height=h, x_range=x_range, y_range=y_range)\n    agg = cvs.points(df, 'dropoff_longitude', 'dropoff_latitude', ds.count('passenger_count'))\n    img = tr_fns.shade(agg, cmap=Hot, how='eq_hist')\n    return tr_fns.dynspread(img, threshold=0.5, max_px=4)\n\np = base_plot(background_fill_color=background)\nexport(create_image(*NYC), \"NYCT_hot\")\nInteractiveImage(p, create_image)", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "ab50fa19d557d5fc03a394a6e9e06e465a529ad4", "collapsed": false, "_cell_guid": "ff890813-69af-4ff3-a73f-48c4828ccf7c"}, "execution_count": null, "cell_type": "code", "source": "from functools import partial\n\ndef create_image90(x_range, y_range, w=plot_width, h=plot_height):\n    cvs = ds.Canvas(plot_width=w, plot_height=h, x_range=x_range, y_range=y_range)\n    agg = cvs.points(df, 'dropoff_longitude', 'dropoff_latitude', ds.count('passenger_count'))\n    img = tr_fns.shade(agg.where(agg > np.percentile(agg, 90)), cmap=inferno, how='eq_hist')\n    return tr_fns.dynspread(img, threshold=0.3, max_px=4)\n    \np = base_plot()\nexport(create_image(*NYC), \"NYCT_90th\")\nInteractiveImage(p, create_image90)", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "9c16507753d5f9e3dd51193a73419ab8f16edbc9", "collapsed": false, "_cell_guid": "06fd4dff-2b27-49cb-8d2c-b8b4c8a81272"}, "execution_count": null, "cell_type": "code", "source": "def merged_images(x_range, y_range, w=plot_width, h=plot_height, how='log'):\n    cvs = ds.Canvas(plot_width=w, plot_height=h, x_range=x_range, y_range=y_range)\n    picks = cvs.points(df, 'pickup_longitude', 'pickup_latitude', ds.count('passenger_count'))\n    drops = cvs.points(df, 'dropoff_longitude', 'dropoff_latitude', ds.count('passenger_count'))\n    more_drops = tr_fns.shade(drops.where(drops > picks), cmap=[\"darkblue\", 'cornflowerblue'], how=how)\n    more_picks = tr_fns.shade(drops.where(picks > drops), cmap=[\"darkred\", 'orangered'], how=how)\n    img = tr_fns.stack(more_picks, more_drops)\n    return tr_fns.dynspread(img, threshold=0.3, max_px=4)\n\np = base_plot(background_fill_color=background)\nexport(merged_images(*NYC), \"NYCT_pickups_vs_drops\")\nInteractiveImage(p, merged_images)", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "d7ba02611b5e18e2162d6c00cd2ab4a5b970a68a", "collapsed": false, "_cell_guid": "e090b6e8-c448-4c95-a287-9fc403de3a4f"}, "execution_count": null, "cell_type": "markdown", "source": "**Reference:**\n\n - I used Peter Wang's talk \"Interactive Viz of a Billion Points with Bokeh Datashader\" at PLOTCON 2016 (https://www.youtube.com/watch?v=fB3cUrwxMVY)", "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "0d27b466d459d643b1c02040e7b1cee09b201db6", "collapsed": false, "_cell_guid": "fe397b4f-dda3-4a91-926a-6eba4a5da334"}, "execution_count": null, "cell_type": "code", "source": "", "outputs": []}], "nbformat_minor": 0, "nbformat": 4}