{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**Introduction:**\nThis is based on Fast AI library Lesson 1( Dogs Vs Cats) using resnet 34 pre-trained model with help from A Beginner's Approach to Classification by archaeocharlie & MNIST test with fastai library by Stefan Langenbach\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5fe1c5f33996bade00963d2f32c3e10ef7222873"},"cell_type":"code","source":"# Put these at the top of every notebook, to get automatic reloading and inline plotting\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"913a01f65936ca906b0d1911cc9ac6dd5e2cf5bf","collapsed":true},"cell_type":"code","source":"# This file contains all the main external libs we'll use\nfrom fastai.imports import *\nfrom fastai.transforms import *\nfrom fastai.conv_learner import *\nfrom fastai.model import *\nfrom fastai.dataset import *\nfrom fastai.sgdr import *\nfrom fastai.plots import *\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74d7ffb5b29d4259bc5342228343f7e9ad1eb0a0","collapsed":true},"cell_type":"code","source":"#set the path\nPATH=\"../input\"\nos.listdir(PATH)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc77875edde44dece73a4eb1d811a70069b466d0"},"cell_type":"markdown","source":"Using Pandas to upload the file"},{"metadata":{"trusted":true,"_uuid":"941d9f811829a525cf3ac90d510f6cf90b994484","collapsed":true},"cell_type":"code","source":"train=pd.read_csv(f'{PATH}/train.csv')\ntest=pd.read_csv(f'{PATH}/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"222a1087f8abea0796cd46db001f69c3bd95df39"},"cell_type":"markdown","source":"The above training file contains both images and labels.  These have to be split. First column is a label\n"},{"metadata":{"trusted":true,"_uuid":"a4104642953a44daf26a265e3aa2bdebc101db63","collapsed":true},"cell_type":"code","source":"image=train.iloc[:,1:]\nlbl=train.iloc[:,0:1]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c47baac75bb0328eccc305e5f23fb8d242de772a"},"cell_type":"markdown","source":"To view as image and load into fastai library using image classifier data.  Since pre-trained model resnet has 3 channels, we will have to multiply the channels by 3 the test and train data"},{"metadata":{"trusted":true,"_uuid":"7b3e839212fb6029312fadb5f9d351dbad2a6ee0","collapsed":true},"cell_type":"code","source":"#Reshape an existing 2D pandas.dataframe into 3D-numpy.ndarray\nimg=image.as_matrix()\nimg=img.reshape(-1,28,28)\ntest_img=test.as_matrix()\ntest_img=test_img.reshape(-1,28,28)\n#Add missing color channels to previously reshaped image\nimg=np.stack((img,)*3, axis=-1).astype('float32')\ntest_img=np.stack((test_img,)*3, axis=-1).astype('float32')\n  \n#plt.imshow(img[2])\n#plt.title(lbl.iloc[i,0]);\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79503bceac259445e27ab9dc79595b8d51021437","collapsed":true},"cell_type":"code","source":"plt.imshow(img[3]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94fd589685502a83885dc199e6ea0aef079baedd","collapsed":true},"cell_type":"code","source":"#not required\n#convert images into a proper np.ndarray\n#img=img.flatten()\n#print([i.shape for i in img])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a47922acf342340b72063ce199dbce08d643952"},"cell_type":"markdown","source":"Split the Training dataset into Train and Valid"},{"metadata":{"trusted":true,"_uuid":"128635fd05b4a7aa44e7f70093142a96e8001f52","collapsed":true},"cell_type":"code","source":"train_img, val_img, train_lbl, val_lbl=train_test_split(img, lbl, train_size=0.8,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ee2e3ca3d34548b4ecc3e99e7e0b73457f19ad2","collapsed":true},"cell_type":"code","source":"grp=[train_img, val_img, train_lbl, val_lbl, test_img]\nprint([e.shape for e in grp])\nprint([type(e) for e in grp])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45cca2befe8d2638f22b64477b5d1ee0fe70953d"},"cell_type":"markdown","source":"Since the label is in the form of dataframe, it needs to be converted into array"},{"metadata":{"trusted":true,"_uuid":"679a2185feb1d46ca53946a6c8a505c47765416c","collapsed":true},"cell_type":"code","source":"train_lbl=train_lbl.values.flatten()\nval_lbl=val_lbl.values.flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d874672f57af784d9a24f038536e5710db07a87","collapsed":true},"cell_type":"code","source":"grp=[train_img, val_img, train_lbl, val_lbl]\nprint([e.shape for e in grp])\nprint([type(e) for e in grp])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ec583d3526b95ec10b9c515a4da45ced2a5da29","collapsed":true},"cell_type":"code","source":"arch=resnet34\nsz=28\nclasses=np.unique(train_lbl)\ndata=ImageClassifierData.from_arrays(path=\"/tmp\",trn=(train_img/255, train_lbl),\n                                     val=(val_img/255, val_lbl),\n                                     classes=train_lbl,\n                                     test=test_img/255,\n                                     tfms=tfms_from_model(arch, sz, max_zoom=1.1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"4dca99d6dff10928b562ac6c0b8c5c954cb5de60","collapsed":true},"cell_type":"code","source":"learn=ConvLearner.pretrained(arch, data, precompute=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fac4768fd24c28bba1e974fc3eac8c149800d82","collapsed":true},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e60b255c62bb6375277df32b7ed1b9d8d51c2b3","collapsed":true},"cell_type":"code","source":"learn.sched.plot_lr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"218b22cfa2085283350ab6bd096978f060dcc476","collapsed":true},"cell_type":"code","source":"learn.sched.plot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d04ba59ab69aaa5eceaaa1cd10d3a726fd1441eb"},"cell_type":"markdown","source":"Based on the above plot, we will select 0.01 as the learning rate. Before running the below code, re-run ConvLearner and run the below code"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"298aba23e99dc5551993c82e6e6167f637afb2aa"},"cell_type":"code","source":"learn=ConvLearner.pretrained(arch, data, precompute=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"6f869fa9ba2a95e1f9d48fbf95ef98a8723b9b42","collapsed":true},"cell_type":"code","source":"learn.fit(0.01,9)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38eb7c0ffa6427779b7187a1b20c130fa10ca560"},"cell_type":"markdown","source":"Moving to the second chapter.  We will use cycle rate and data augmentations.  Re-run ConvLearner code again"},{"metadata":{"trusted":true,"_uuid":"67dfb8b4ef4244545278e3442a7913dbe1b5b257","collapsed":true},"cell_type":"code","source":"learn=ConvLearner.pretrained(arch, data, precompute=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14807dd3748b4fee6a81a9518c31c34ae15033d9","collapsed":true},"cell_type":"code","source":"#learn.precompute=False\nlearn.fit(0.01,9, cycle_len=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"304c3369d0011d22a0b26cdacdadf5f7319b6fb3"},"cell_type":"markdown","source":"Cycle_len hasn't improved the accuracy or the loss. Cycle_len enables stochastic gradient descent with restarts (SGDR).  This helps model to jump to the different part in the weight space"},{"metadata":{"trusted":true,"_uuid":"cc77484abc30908ea207ff297c75d0e9a3cd04b3","collapsed":true},"cell_type":"code","source":"learn.sched.plot_lr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac4341b1fe52b3f99bc307c191d50aed5f74d0cd"},"cell_type":"markdown","source":"Fine tuning other layers with final layer being trained. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b7e03d18af43d0b0f44284828093fb2cf83b0cce"},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d70dcde506f5d37a169affa0144f1219890b7c1d"},"cell_type":"markdown","source":" The earlier layers (as we've seen) have more general-purpose features. Therefore we would expect them to need less fine-tuning for new datasets. For this reason we will use different learning rates for different layers: the first few layers will be at 1e-4, the middle layers at 1e-3, and our FC layers we'll leave at 1e-2 as before. We refer to this as differential learning rates,"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dc83f59912783f99973831c5f8b0bd179ea79893"},"cell_type":"code","source":"lr=np.array([1e-4,1e-3,1e-2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"374764f98fc06576bc1f62e980e527f8727cd82e","collapsed":true},"cell_type":"code","source":"learn.fit(lr, 4, cycle_len=1, cycle_mult=2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4158fe7f479f03aed3aa3b6199ccf53a1bc461fd"},"cell_type":"markdown","source":"Cycle Mult multiplies the length of the cycle after each cycle. e.g. epoch=4, cycle_mult=2 then it multiples the length of the cycle after each cycle (1 epoch + 2 epoch + 4 epoch + 8 epoch=15 epochs)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"866daef623bd4357ccc1622d34494e31e67954d7"},"cell_type":"code","source":"learn.sched.plot_lr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"16c1bf859c86360ee53a0496e820eb9ac648a086"},"cell_type":"code","source":"learn.save('4_epochs')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"514bb19d32cd7f7a4d341f82202e94da2239a777","collapsed":true},"cell_type":"code","source":"#predict the test set\n%time log_preds_test, y_test=learn.TTA(is_test=True)\nprobs_test=np.mean(np.exp(log_preds_test),0)\nprobs_test.shape\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2e36b995c467ebddcca5510122e777702d4dbcd"},"cell_type":"markdown","source":"To create a submission file"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a7f48c65af5f2d52b224e0dedf732ddd84afe3fd"},"cell_type":"code","source":"#Create a dataframe from all probabilities\ndf=pd.DataFrame(probs_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b01347c2e4ead8e2acf58c4965c3199a4a7bfa94","collapsed":true},"cell_type":"code","source":"\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ebede39498d1fe0e6aae888aedadea2e88f3b379"},"cell_type":"code","source":"#consider the maxm probability\n\ndf=df.assign(Label=df.values.argmax(axis=1))\ndf=df.assign(ImageId=df.index.values+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f4496093cb39fd77af1be13a34526957b0bc2ab","collapsed":true},"cell_type":"code","source":"df1=df[['ImageId', 'Label']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6fbea9070045f22ca77f8af688ef81ad51a69bb","collapsed":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e053440c20149a9811da2cb1ba7c60b8c5a38ae","collapsed":true},"cell_type":"code","source":"df1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fc0cf07622c45b0dc56b94070053beb6b5e3c01b"},"cell_type":"code","source":"df1.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}