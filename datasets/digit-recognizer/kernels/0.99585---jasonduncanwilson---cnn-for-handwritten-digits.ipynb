{"cells":[{"metadata":{"_uuid":"e40425782f038bcaa0a8269e20a1684c1f6e8612"},"cell_type":"markdown","source":"This is my initial attempt at the Digit Recognizer challenge. The following kernels were very helpful for me to learn from:\n* [Yassine's kernel](https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6)\n* [Moghazy's kernel](https://www.kaggle.com/moghazy/guide-to-cnns-with-data-augmentation-keras)\n\n<br/>\nThe thought of all of these poorly handwritten digits made me think of school children...which in turn led me to think of Pink Floyd and the image below. I'm feeling a strong appreciation for Kaggle right now because there's definitely no \"dark sarcasm in the classroom\" here which is one of the many reasons I'm learning so much."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"92646b8d92b15a4a2311b20e9b144b3c6dd51196"},"cell_type":"code","source":"from IPython.display import Image\nurl = 'https://bplusmovieblog.files.wordpress.com/2016/08/pink-floyd-the-wall-18.png'\nImage(url=url,width=800, height=600)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nfrom keras.utils.np_utils import to_categorical # one hot encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n%matplotlib inline\nsns.set(style='white', context='notebook', palette='deep')\n\n# Set random seed to get a consistent result\nrandom_seed = 2\nnp.random.seed(random_seed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac5e922b1b1026d8be05432eb4e704de8f3ffbdf"},"cell_type":"markdown","source":"**1) Load and Prep Data**\n\nWe first need to load in the handwritten digits for both the train file and the test file."},{"metadata":{"trusted":true,"_uuid":"34a407733ff08336a05fc83140ed0539a33fac00"},"cell_type":"code","source":"# Load the training data and review\ntrain = pd.read_csv(\"../input/train.csv\")\ntrain.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd11f9bac04e645047b32bafc7fb50d6384b1d09"},"cell_type":"code","source":"# Load the test data and review\ntest = pd.read_csv(\"../input/test.csv\")\ntest.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1778f2e4491bc086ec472f0d5b358712b1e23415"},"cell_type":"markdown","source":"Compare columns between training and test data to ensure only the \"label\" column is the difference between the two data sets."},{"metadata":{"trusted":true,"_uuid":"75f28854a94e8521fba6fc7035bc532390c0f79f"},"cell_type":"code","source":"# Compare columns between test and train\nprint(\"Columns in training data but not in testing data\")\nprint([x for x in train.columns if x not in test.columns])\nprint(\"Columns in testing data but not in training data\")\nprint([x for x in test.columns if x not in train.columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9c2b69f1f1fe5d8a5d5314e4f39e1d802494be0"},"cell_type":"code","source":"# Split into x and y for training\nY_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1)\nX_test = test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17963465bae263cba471cc7e63877ad296ebcbdb"},"cell_type":"markdown","source":"If there are only a small amount of images missing values (less than 2%) then automatically remove those images."},{"metadata":{"trusted":true,"_uuid":"e3e87af93b6735cd4e187fc8b2395515c212ba1c"},"cell_type":"code","source":"train_null_rows = sum(X_train.isnull().sum())\nprint(\"Number of train rows with null pixels:\",train_null_rows)\n\n# Drop rows with missing values as long as it doesn't exceed 2% of the data\nif train_null_rows < len(X_train.index)*0.02:\n    X_train = X_train.dropna()\n    \ntest_null_rows = sum(X_test.isnull().sum())\nprint(\"Number of test rows with null pixels:\",train_null_rows)\n\n# Drop rows with missing values as long as it doesn't exceed 2% of the data\nif test_null_rows < len(X_test.index)*0.02:\n    X_test = X_test.dropna()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0db9d6fab20c74212303a21793165f2c7db8781c"},"cell_type":"markdown","source":"**2) Explore and Normalize Data**\n\nA number of data exploration steps give us more insight into how to approach this data."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"ddac15fc7a3aee04bb49d0c146dd36a95007ff76"},"cell_type":"code","source":"fig = plt.figure(figsize=(12, 5))\nax = sns.countplot(Y_train)\nax.set_title(\"Number of training examples per digit\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fc3560fcbdae900108fe2c06a26611c700d1e59"},"cell_type":"markdown","source":"Take data from gray scale 0-255 to 0-1 normalized scale."},{"metadata":{"trusted":true,"_uuid":"83a87aa5694b7eab43185a6376add94fef4d1448"},"cell_type":"code","source":"# Normalize the data\nX_train = X_train / 255.0\nX_test = X_test / 255.0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61c88a5e8e36e06926fc6fa9e3defe74157dd689"},"cell_type":"markdown","source":"Reshape the image data from rows of 1D vectors with 784 values to 3D vectors with dimensions 28x28x1."},{"metadata":{"trusted":true,"_uuid":"766e45a7a5dd7e047adadc85e79836d933edd249"},"cell_type":"code","source":"# Reshape into 3D matrices\nX_train = X_train.values.reshape(X_train.shape[0], 28, 28 , 1).astype('float32')\nX_test = X_test.values.reshape(X_test.shape[0], 28, 28 , 1).astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"764156f07817c01c37b65194749ca1a7d38fb946"},"cell_type":"markdown","source":"Confirm the number of classes as well as new shape of the training data."},{"metadata":{"trusted":true,"_uuid":"40e6063e0054acfd29d12d77d4cb52cf2d0e9d0c"},"cell_type":"code","source":"Y_num_classes = Y_train.nunique()\nprint(\"the number of classes = %i\" % Y_num_classes)\nprint(\"Dimension of images = {:d} x {:d}\".format(X_train[1].shape[0],X_train[1].shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02a3174e03e65137dd028e9ec760f258996d8a45"},"cell_type":"markdown","source":"Display a few of the images."},{"metadata":{"trusted":true,"_uuid":"3785e8ae1e8dda010c30201de1cefab19e496821"},"cell_type":"code","source":"images_and_labels = list(zip(X_train,  Y_train))\nfor index, (image, label) in enumerate(images_and_labels[:12]):\n    plt.subplot(5, 4, index + 1)\n    plt.axis('off')\n    plt.imshow(image.squeeze(), cmap=plt.cm.gray_r, interpolation='nearest')\n    plt.title('label: %i' % label )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf9416e840269853d94518ad831881b441de8738"},"cell_type":"markdown","source":"Encode labels as a \"one hot\" vector - e.g. change a label of \"2\" to \"0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\""},{"metadata":{"trusted":true,"_uuid":"80f106faf0286c41a7ccf86527ef9c9751950856"},"cell_type":"code","source":"# Encode labels to one hot vectors\nY_train = to_categorical(Y_train, num_classes = Y_num_classes)\nprint(\"A few examples of the one hot encoding:\")\nprint(Y_train[:5,:])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ca2a7c86edbe024244173eb63ed1b3392c90845"},"cell_type":"markdown","source":"Split out a validation data set."},{"metadata":{"trusted":true,"_uuid":"f66b49797091f0bee466fd2f0e35852bf5636eb9"},"cell_type":"code","source":"# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, \n                                                  Y_train, \n                                                  test_size = 0.1, \n                                                  stratify=Y_train, #balance digits across data\n                                                  random_state=random_seed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3bc737bf5e3d687f55d42863a498449ed45b3053"},"cell_type":"markdown","source":"**3) Define and train the neural network**"},{"metadata":{"_uuid":"54cf6a1b705be338cb99683c008482c3bac6ebd0"},"cell_type":"markdown","source":"Define the layer architecture of the neural network."},{"metadata":{"trusted":true,"_uuid":"e5342c3e049480f9d3b4a7ac1fa6737f6f03433d"},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, \n                 kernel_size = (5,5),\n                 #strides=2,\n                 padding = 'Same', \n                 activation ='relu', \n                 input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, \n                 kernel_size = (5,5),\n                 #strides=2,\n                 padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Conv2D(filters = 64, \n                 kernel_size = (3,3),\n                 padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, \n                 kernel_size = (3,3),\n                 padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), \n                    strides=(2,2)))\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, \n                activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, \n                activation = \"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"943112ad73e416b0525b3986cb07b192e002277c"},"cell_type":"code","source":"# Define the optimizer\n#optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b259cae0757b78fa88774d9b49f6fcca9c92f284"},"cell_type":"markdown","source":"Compile the model."},{"metadata":{"trusted":true,"_uuid":"9ab9b3a2a052c4a24ef24e100d7fa2a5ab234758"},"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer='adam', \n              #optimizer=optimizer,\n              loss = \"categorical_crossentropy\", \n              metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"910d9480751d2042e3130b0c8ba516af1fa99482"},"cell_type":"markdown","source":"General additional images that are slight alternations of the existing images in order to reduce overfitting and boost the number of examples to train on."},{"metadata":{"trusted":true,"_uuid":"b6615608fe4c1feb0081b4f398f33d0d05146697"},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        rotation_range=10,\n        zoom_range = 0.2,\n        width_shift_range=0.1,\n        height_shift_range=0.1)\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05e31685c676a867c925b869815d86588b4ce6e7"},"cell_type":"code","source":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80d77ec6036e31e213387d8de4ee2651122951fe"},"cell_type":"markdown","source":"Fit the model."},{"metadata":{"trusted":true,"_uuid":"161acae8a18d00a4beea2bd71f7cb84d4d827474"},"cell_type":"code","source":"# 30 epochs ran in roughly 130 minutes with CPU\n# 40 epochs ran in roughly 9 minutes with GPU\nepochs = 40 # set to something around 20 to 30 to increase accuracy\nbatch_size = 86\n\nmodel.fit_generator(datagen.flow(X_train,\n                                 Y_train,\n                                 batch_size=batch_size),\n                    epochs = epochs, \n                    validation_data = (X_val,Y_val),\n                    verbose = 2, \n                    callbacks=[learning_rate_reduction],\n                    steps_per_epoch=X_train.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72fb877207cc39cdcba1d0e77c32e31580393241"},"cell_type":"markdown","source":"Display a confusion matrix of the results."},{"metadata":{"trusted":true,"_uuid":"59094ef182de64d565de535a8e937729759094d1"},"cell_type":"code","source":"# Look at confusion matrix \n\ndef plot_confusion_matrix(cm, \n                          classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(12, 5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1)\n\n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n\n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(Y_num_classes))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9013fbb51ec1a65bddc36a12d6745e0dd6bb574f"},"cell_type":"markdown","source":"**4) Predict and submit results**"},{"metadata":{"_uuid":"3c1899755db471ede7bdb2274e2d146d894b0b55"},"cell_type":"markdown","source":"Predict the results."},{"metadata":{"trusted":true,"_uuid":"5c03b269d2e3af20c965dac2abf07fd7a91b47b3"},"cell_type":"code","source":"# predict results\nresults = model.predict(X_test)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\nresults.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6679222bbfff318b0ebeb0fd28ca94217e3a7c5"},"cell_type":"markdown","source":"Create the submission file."},{"metadata":{"trusted":true,"_uuid":"ae9fb325ac83756a6342d19a7b41a48871b1e766"},"cell_type":"code","source":"results_count = len(results)\nsubmission = pd.concat([pd.Series(range(1,results_count+1),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}