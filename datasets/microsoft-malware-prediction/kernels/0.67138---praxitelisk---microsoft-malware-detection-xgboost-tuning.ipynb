{"cells":[{"metadata":{"_uuid":"45ab671ce78132c4e89737347df00708faa6ecd4"},"cell_type":"markdown","source":"# Microsoft Malware Detection XGBoost Tuning\n\n![](https://winbuzzer.com/wp-content/uploads/2016/02/Microsoft-Logo-1-1.jpg)\n\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRbuYMzpgoRh2tLUj_EVV0z7gtIKwfJfZ7G-DP5dscAvSqcgSR_OQ)\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/Cog-scripted-svg-green.svg/537px-Cog-scripted-svg-green.svg.png)"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\n%matplotlib inline\n\nimport time\n\n\n# due to Kaggle memory limitations and the enormous dataset size, a sample from the whole\n# trainset will be used for ML modeling\ntrain_sample_fraction = None\n\n\n# if we want to avoid using a fraction of the train dataset then using the following variable will suffice\ntrain_sample_num = 1500000\n\n\n# another global variable that must be defined is the NA values rate / theshold to ommit columns with\n# NA values that pass this rate\nna_rate_threshold = 0.9\n\n# theshold to remove columns with unbalanced features to their values \nunbalanced_feature_rate_threshold = 0.9\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# I am grateful for the help of author of this kernel for the main idea to load the dataset and save memory space!!\n# https://www.kaggle.com/theoviel/load-the-totality-of-the-data\n\ndtypes = {\n        'MachineIdentifier':                                    'category',\n        'ProductName':                                          'category',\n        'EngineVersion':                                        'category',\n        'AppVersion':                                           'category',\n        'AvSigVersion':                                         'category',\n        'IsBeta':                                               'int8',\n        'RtpStateBitfield':                                     'float16',\n        'IsSxsPassiveMode':                                     'int8',\n        'DefaultBrowsersIdentifier':                            'float16',\n        'AVProductStatesIdentifier':                            'float32',\n        'AVProductsInstalled':                                  'float16',\n        'AVProductsEnabled':                                    'float16',\n        'HasTpm':                                               'int8',\n        'CountryIdentifier':                                    'int16',\n        'CityIdentifier':                                       'float32',\n        'OrganizationIdentifier':                               'float16',\n        'GeoNameIdentifier':                                    'float16',\n        'LocaleEnglishNameIdentifier':                          'int8',\n        'Platform':                                             'category',\n        'Processor':                                            'category',\n        'OsVer':                                                'category',\n        'OsBuild':                                              'int16',\n        'OsSuite':                                              'int16',\n        'OsPlatformSubRelease':                                 'category',\n        'OsBuildLab':                                           'category',\n        'SkuEdition':                                           'category',\n        'IsProtected':                                          'float16',\n        'AutoSampleOptIn':                                      'int8',\n        'PuaMode':                                              'category',\n        'SMode':                                                'float16',\n        'IeVerIdentifier':                                      'float16',\n        'SmartScreen':                                          'category',\n        'Firewall':                                             'float16',\n        'UacLuaenable':                                         'float32',\n        'Census_MDC2FormFactor':                                'category',\n        'Census_DeviceFamily':                                  'category',\n        'Census_OEMNameIdentifier':                             'float16',\n        'Census_OEMModelIdentifier':                            'float32',\n        'Census_ProcessorCoreCount':                            'float16',\n        'Census_ProcessorManufacturerIdentifier':               'float16',\n        'Census_ProcessorModelIdentifier':                      'float16',\n        'Census_ProcessorClass':                                'category',\n        'Census_PrimaryDiskTotalCapacity':                      'float32',\n        'Census_PrimaryDiskTypeName':                           'category',\n        'Census_SystemVolumeTotalCapacity':                     'float32',\n        'Census_HasOpticalDiskDrive':                           'int8',\n        'Census_TotalPhysicalRAM':                              'float32',\n        'Census_ChassisTypeName':                               'category',\n        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float16',\n        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float16',\n        'Census_InternalPrimaryDisplayResolutionVertical':      'float16',\n        'Census_PowerPlatformRoleName':                         'category',\n        'Census_InternalBatteryType':                           'category',\n        'Census_InternalBatteryNumberOfCharges':                'float32',\n        'Census_OSVersion':                                     'category',\n        'Census_OSArchitecture':                                'category',\n        'Census_OSBranch':                                      'category',\n        'Census_OSBuildNumber':                                 'int16',\n        'Census_OSBuildRevision':                               'int32',\n        'Census_OSEdition':                                     'category',\n        'Census_OSSkuName':                                     'category',\n        'Census_OSInstallTypeName':                             'category',\n        'Census_OSInstallLanguageIdentifier':                   'float16',\n        'Census_OSUILocaleIdentifier':                          'int16',\n        'Census_OSWUAutoUpdateOptionsName':                     'category',\n        'Census_IsPortableOperatingSystem':                     'int8',\n        'Census_GenuineStateName':                              'category',\n        'Census_ActivationChannel':                             'category',\n        'Census_IsFlightingInternal':                           'float16',\n        'Census_IsFlightsDisabled':                             'float16',\n        'Census_FlightRing':                                    'category',\n        'Census_ThresholdOptIn':                                'float16',\n        'Census_FirmwareManufacturerIdentifier':                'float16',\n        'Census_FirmwareVersionIdentifier':                     'float32',\n        'Census_IsSecureBootEnabled':                           'int8',\n        'Census_IsWIMBootEnabled':                              'float16',\n        'Census_IsVirtualDevice':                               'float16',\n        'Census_IsTouchEnabled':                                'int8',\n        'Census_IsPenCapable':                                  'int8',\n        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n        'Wdft_IsGamer':                                         'float16',\n        'Wdft_RegionIdentifier':                                'float16',\n        'HasDetections':                                        'int8'\n        }\n\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage(deep=True).sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9fa66bdccee4111ac7ed2acde1e2748edb13c46","trusted":true},"cell_type":"code","source":"%%time\ntrain = pd.read_csv('../input/train.csv', dtype=dtypes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e20433faf47d6bd83456a35f78a3314adbdc7986","trusted":true},"cell_type":"code","source":"good_cols = list(train.columns)\n\nfor col in train.columns:\n    \n    # remove columns with high NA rate\n    na_rate = train[col].isnull().sum() / train.shape[0]\n    \n    # remove columns with high Unbalanced values rate\n    unbalanced_rate = train[col].value_counts(normalize=True, dropna=False).values[0]\n    \n    if na_rate > na_rate_threshold:\n        good_cols.remove(col)\n    elif unbalanced_rate > unbalanced_feature_rate_threshold:\n        good_cols.remove(col)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f60e134c2fcf4e65a0551d6a0b925c1d33f97265","trusted":true},"cell_type":"code","source":"good_cols","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd629eab88cebfdb7a354103dc9c6767c6d775ea","trusted":true},"cell_type":"code","source":"train = train[good_cols]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7178d430eaccbdf1e099647434e7e44272bba7c9","trusted":true},"cell_type":"code","source":"import gc\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2afcda836a7188b58e82ba9a145d689bab1b1c57","trusted":true},"cell_type":"code","source":"categorical_columns = list(train.loc[:, train.dtypes ==\"category\"].columns)\nnumerical_and_binary_columns = list(train.loc[:, train.dtypes !=\"category\"].columns)\nnumerical_columns = numerical_and_binary_columns\n\ncategorical_columns.remove(\"MachineIdentifier\")\n\nbinary_columns = []\nfor col in (numerical_and_binary_columns):\n    if train[col].nunique() == 2:\n        binary_columns.append(col)\n        numerical_columns.remove(col)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4a4eafe356cf04082ab3ee284f0b352048ce50a"},"cell_type":"markdown","source":"## Machine Learning Modeling and Tuning"},{"metadata":{"_uuid":"0a7bcdda6c53f3cea7059178104fdaed58be7c9f"},"cell_type":"markdown","source":"![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRB40XiqXJooyGCgeV5-6DLkKEdDgFbvefkDgLMFG7_f4Sl0VQt)\n\n![](http://www.pevco.com/wp-content/uploads/2015/05/gears-clear.png)"},{"metadata":{"_uuid":"2fb705fbc15a9009968d7d5a229a5f27ead6e704","trusted":true},"cell_type":"code","source":"if train_sample_fraction is not None:\n    train_sample = train.sample(frac=train_sample_fraction, random_state=42)\nelif train_sample_num is not None:\n    train_sample = train.sample(n=train_sample_num, random_state=42)\nelse:\n    train_sample = train.sample(n=1500000, random_state=42)\n\ndel train\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41fbee6299db8ee267c963d65b7a59336d485098","trusted":true},"cell_type":"code","source":"train_sample.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0cbf8c7f54df79442941de2afd6cedebed96b1d2","trusted":true},"cell_type":"code","source":"test_dtypes = {k: v for k, v in dtypes.items() if k in good_cols}\n\n# get all columns except\ntest = pd.read_csv('../input/test.csv', dtype=test_dtypes, usecols=good_cols[:-1])\n\n#test = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3f304766c39f7e2c6c8fda0056f3e1bdbca3eff","trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"513121ff0b8730ddca7cb469f0219d268b4d4605","trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac15de9d17b067234afdae7e020a6b5de02a7a70","trusted":true},"cell_type":"code","source":"train_sample = train_sample.drop(['MachineIdentifier'], axis=1)\ntest = test.drop(['MachineIdentifier'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a83ccfddbb26500e88c312778908a35753d0cdcf","trusted":true},"cell_type":"code","source":"train_sample = train_sample.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a140c3ce337be0bfe665626d6b3ae2c270056c0"},"cell_type":"markdown","source":"### Filling NA values with the statistical Mode"},{"metadata":{"_uuid":"5baca4dd7ec3d6a07a53274671334a2f786f28fc","trusted":true},"cell_type":"code","source":"modes = train_sample.mode()\n\nfor col in train_sample.columns:\n    train_sample[col] = np.where(train_sample[col].isnull(), modes[col], train_sample[col])\n\ndel modes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ac26a55808e7cc4731241e4eeb625724dd36a24","trusted":true},"cell_type":"code","source":"modes_test = test.mode()\n\nfor col in test.columns:\n    test[col] = np.where(test[col].isnull(), modes_test[col], test[col])\n\n#train_sample.shape\ndel modes_test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5cc83fc5edbee697391c02c63f36478584444ec6"},"cell_type":"markdown","source":"### Concatenate both train_sample and test sets before label encoding"},{"metadata":{"_uuid":"a9b79c3ec6cbd09a299bdf4497251238dc72cc4d","trusted":true},"cell_type":"code","source":"train_shape = train_sample.shape\ntest_shape = test.shape\n\ntrain_and_test = pd.concat([train_sample,test], axis=\"rows\", sort=False)\n\ndel train_sample\ndel test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f51e3d3dafc1bd44f24993bdbe838f16eb9e05c","trusted":true},"cell_type":"code","source":"train_and_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18ce9f155121b34b9d0f01952f912bf6edbd5b80","trusted":true},"cell_type":"code","source":"train_and_test.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b53abfda614ae7c587c7701d6ec1ff602660322"},"cell_type":"markdown","source":"### Encode the Categorical features before machine learning modeling"},{"metadata":{"_uuid":"6ca351ce6699aa9c16555e0d4fc88bcc8a03d515","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\ndef MultiLabelEncoder(columnlist,dataframe):\n    for i in columnlist:\n        #print(i)\n        labelencoder_X=LabelEncoder()\n        dataframe[i]=labelencoder_X.fit_transform(dataframe[i])\n\nMultiLabelEncoder(categorical_columns, train_and_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ebf152f7d3859c64b8f5a59de631ef2283ec51d","trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbc688ee912088949b5ad0457d8fd65e0bfb5ac0"},"cell_type":"markdown","source":"### Back to train and test set after Label Encoding"},{"metadata":{"_uuid":"f32ea815d2d1f28940d9beaf7c2b851fc65837a6","trusted":true},"cell_type":"code","source":"train_sample = train_and_test[0:train_shape[0]]\ntest = train_and_test[(train_shape[0]):(train_and_test.shape[0]+1)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18c499bed0d4f25fb6895332ce7f375b134c1201","trusted":true},"cell_type":"code","source":"del train_and_test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b53deef880d7a28701805c1a626e5976be578b2a"},"cell_type":"markdown","source":"### Remove the HasDetections columns from test set, it has been added during dataframe concatenation."},{"metadata":{"_uuid":"364fe1f26469600443c904641ba009a3518f282d","trusted":true},"cell_type":"code","source":"test = test.drop([\"HasDetections\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a1c7d626d0aa12f9809e2f077a1856ebccffd2c","trusted":true},"cell_type":"code","source":"y = train_sample['HasDetections']\nX = train_sample.drop(['HasDetections'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf909b41fa2e2a66dee6c95f483c67a78a5e648a","trusted":true},"cell_type":"code","source":"del train_sample\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70772cfcf66c4def9848474a92299cc78a64a2d1"},"cell_type":"markdown","source":"### XGBoost Baseline model"},{"metadata":{"trusted":true,"_uuid":"664756f870620a8f9604037a888ecd1d28415fcb"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nimport time\n\n# create a 70/30 split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n\nimport xgboost as xgb\n\nstart_time = time.time()\n\n# special thanks to https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n# these parameters have been found via xgboost tuning, you can see my tries in the commented tuning python snippets below:\n# unfortunately it takes so much time to tune and to produce the final optimal classifier due to 9h time limit in Kaggle kernels.\nclf_xgb = xgb.XGBClassifier(learning_rate=0.1, \n                            n_estimators=1000, \n                            max_depth=5,\n                            min_child_weight=1,\n                            gamma=0,\n                            subsample=0.9,\n                            colsample_bytree=0.6,\n                            objective= 'binary:logistic',\n                            nthread=-1,\n                            scale_pos_weight=1,\n                            reg_alpha = 0,\n                            reg_lambda = 1,\n                            seed=42)\n\nclf_xgb.fit(xtrain, ytrain, eval_set=[(xtrain, ytrain), (xvalid, yvalid)], \n            early_stopping_rounds=100, eval_metric='auc', verbose=100)\n\npredictions = clf_xgb.predict(xvalid)\n\nprint()\nprint(classification_report(yvalid, predictions))\n\nprint()\nprint(\"accuracy_score\", accuracy_score(yvalid, predictions))\n\nprint()\npredictions_probas = clf_xgb.predict_proba(xvalid)\nprint(\"roc-auc score for the class 1, from target 'HasDetections' \", roc_auc_score(yvalid, predictions_probas[:,1]))\n\nprint()\nprint(\"elapsed time in seconds: \", time.time() - start_time)\n\nprint()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc687a13542e759b06b39e0561156c74ce2cd364","trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport scikitplot as skplt\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_confusion_matrix(yvalid, predictions, cmap=\"BrBG\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02492c7c98e2d3032e002f340ab66ced0b7207d9","trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_roc(yvalid, predictions_probas)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"984bbd49fd0884e96fb6df070b02488e2f32e9e9","trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_ks_statistic(yvalid, predictions_probas)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"acc1ec59d4522c5317849a06c93ddd1a4401b4fa","trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_precision_recall(yvalid, predictions_probas)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d545ddd0bcaa79ab3fe60693024e76dea8fdd8bb"},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_lift_curve(yvalid, predictions_probas)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"502f36a6106fb160d505c1f4a644a33b6f4baf74"},"cell_type":"markdown","source":"### Tuning\n#### The following part is commented, I have run tuning in previous versions of this kernel and figured out the optimal (so far) values of the xgboost parameters.\n\n### XGBoost Grid Search Part 1\n#### Tuning parameters:\n- 'max_depth'\n- 'min_child_weight'"},{"metadata":{"_uuid":"3ad65deff0365c802e4972b82b52856ae77aa33e","trusted":true},"cell_type":"code","source":"# I am afraid of variance - bias tradeoff\n\n#idea and a big thank you to https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\nfrom sklearn.model_selection import GridSearchCV   #Perforing grid search\n\ngc.collect()\n\nparam_test1 = {\n    # based on previous personal kernels both parameters show better result having high numbers \n 'max_depth':[3, 5, 7, 9, 11],\n 'min_child_weight':[1, 3, 5, 7, 9]\n}\ngsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=50, gamma=0, subsample=0.9, colsample_bytree=0.6,\n                                                  objective= 'binary:logistic', nthread=-1, scale_pos_weight=1, reg_alpha = 0, \n                                                reg_lambda =1, seed=42), \n                        param_grid = param_test1, scoring='roc_auc', n_jobs=1, iid=False, cv=3, verbose = 1)\n\ngsearch1.fit(xtrain, ytrain)\ngsearch1.best_params_, gsearch1.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa38df0ae5600d19b24b3c25bbecba8b877dbb15"},"cell_type":"code","source":"best_params_1 = gsearch1.best_params_\nprint(best_params_1)\ndel gsearch1\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9220dffa54566d9b622fd248bf364d15eaa718e5"},"cell_type":"markdown","source":"### XGBoost Grid Search Part 2\n#### Tuning parameters:\n- 'gamma'"},{"metadata":{"trusted":true,"_uuid":"872709a79d342fd80c426b7f21111ea5400cf173"},"cell_type":"code","source":"#idea and a big thank you to https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n\nfrom sklearn.model_selection import GridSearchCV   #Perforing grid search\n\ngc.collect()\n\nparam_test2 = {\n 'gamma':[0, 0.2, 0.4]\n}\ngsearch2 = GridSearchCV(estimator = xgb.XGBClassifier(learning_rate =0.1, n_estimators=50, \n                                                      min_child_weight = best_params_1[\"min_child_weight\"],\n                                                      max_depth = best_params_1[\"max_depth\"], subsample=0.9, colsample_bytree=0.6,\n                                                  objective= 'binary:logistic', nthread=-1, scale_pos_weight=1, reg_alpha = 0, \n                                                      reg_lambda =1, seed=42), \n                        param_grid = param_test2, scoring='roc_auc', n_jobs=1, iid=False, cv=3, verbose = 1)\n\ngsearch2.fit(xtrain, ytrain)\ngsearch2.best_params_, gsearch2.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"071cf7a4e74fb74faddf3e711a037c6976785a50"},"cell_type":"code","source":"best_params_2 = gsearch2.best_params_\nprint(best_params_2)\ndel gsearch2\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0a537a5796c87ca7161cc02d5f80b78da95de2e"},"cell_type":"markdown","source":"### XGBoost Grid Search Part 3\n#### Tuning parameters:\n- 'subsample'\n- 'colsample_bytree'"},{"metadata":{"trusted":true,"_uuid":"c25354f036c398a240619b4eb5bd89e47132103d"},"cell_type":"code","source":"#idea and a big thank you to https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\nfrom sklearn.model_selection import GridSearchCV   #Perforing grid search\n\ngc.collect()\n\nparam_test3 = {\n 'subsample':[0.4, 0.6, 0.8, 1],\n \"colsample_bytree\": [0.2, 0.4, 0.6, 0.8]\n}\ngsearch3 = GridSearchCV(estimator = xgb.XGBClassifier(learning_rate =0.1, n_estimators=50, gamma = best_params_2[\"gamma\"],\n                                                      min_child_weight = best_params_1[\"min_child_weight\"],\n                                                      max_depth = best_params_1[\"max_depth\"],\n                                                      objective= 'binary:logistic', nthread=-1, scale_pos_weight=1, reg_alpha = 0,\n                                                      reg_lambda =1, seed=42), \n                        param_grid = param_test3, scoring='roc_auc', n_jobs=1, iid=False, cv=3, verbose = 1)\n\ngsearch3.fit(xtrain, ytrain)\ngsearch3.best_params_, gsearch3.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f2697440bb067f2109e4383b398cc690961e1dc"},"cell_type":"code","source":"best_params_3 = gsearch3.best_params_\nprint(best_params_3)\ndel gsearch3\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9388d91b0b9301245e5a72ea3b347847eff5e536"},"cell_type":"markdown","source":"### XGBoost Grid Search Part 4\n#### Tuning parameters:\n- 'reg_alpha'"},{"metadata":{"trusted":true,"_uuid":"b9554b8ed3ba48be4ecd63b63a986116fdb4105d"},"cell_type":"code","source":"#idea and a big thank you to https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\nfrom sklearn.model_selection import GridSearchCV   #Perforing grid search\n\ngc.collect()\n\nparam_test4 = {\n 'reg_alpha':[0, 0.3, 0.6]  \n}\ngsearch4 = GridSearchCV(estimator = xgb.XGBClassifier(learning_rate =0.1, n_estimators=50, gamma = best_params_2[\"gamma\"],\n                                                      min_child_weight = best_params_1[\"min_child_weight\"],\n                                                      max_depth = best_params_1[\"max_depth\"], subsample=best_params_3[\"subsample\"],\n                                                      colsample_bytree=best_params_3[\"colsample_bytree\"],\n                                                      objective= 'binary:logistic', nthread=-1, scale_pos_weight=1,\n                                                      reg_lambda =1, seed=42), \n                        param_grid = param_test4, scoring='roc_auc', n_jobs=1, iid=False, cv=3, verbose = 1)\n\ngsearch4.fit(xtrain, ytrain)\ngsearch4.best_params_, gsearch4.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26d1bcd88a5ca2593afe291f80159933650a4b44"},"cell_type":"code","source":"best_params_4 = gsearch4.best_params_\nprint(best_params_4)\ndel gsearch4\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53239a65b82fefd0cce0dc0041d25d6cc89ff7dd"},"cell_type":"markdown","source":"### XGBoost Grid Search Part 5\n#### Tuning parameters:\n- 'reg_lambda'"},{"metadata":{"trusted":true,"_uuid":"ee77ae4010c60960863e984dbc0b042e748b4aa3"},"cell_type":"code","source":"#idea and a big thank you to https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\nfrom sklearn.model_selection import GridSearchCV   #Perforing grid search\n\ngc.collect()\n\nparam_test5 = {\n 'reg_lambda':[1, 3, 5, 7]\n}\ngsearch5 = GridSearchCV(estimator = xgb.XGBClassifier(learning_rate =0.1, n_estimators=50, gamma = best_params_2[\"gamma\"],\n                                                      min_child_weight = best_params_1[\"min_child_weight\"],\n                                                      max_depth = best_params_1[\"max_depth\"], subsample=best_params_3[\"subsample\"],\n                                                      colsample_bytree=best_params_3[\"colsample_bytree\"],\n                                                      objective= 'binary:logistic', nthread=-1, scale_pos_weight=1, \n                                                      reg_alpha = best_params_4[\"reg_alpha\"], seed=42), \n                        param_grid = param_test5, scoring='roc_auc', n_jobs=1, iid=False, cv=3, verbose = 1)\n\ngsearch5.fit(xtrain, ytrain)\ngsearch5.best_params_, gsearch5.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93a600540e16e059c3aaecdb988637e56115c07f"},"cell_type":"code","source":"best_params_5 = gsearch5.best_params_\nprint(best_params_5)\ndel gsearch5\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7463651074edcd3df56820bef9db6344880257ef"},"cell_type":"markdown","source":"### Retraining XGBoost after tuning\nAnd increasing now the number of estimators and on the other hand decreasing the learning_rate from 0.1 to 0.03"},{"metadata":{"trusted":true,"_uuid":"559e588dcfa6615eabab81f3ba68fa21710a1b6c"},"cell_type":"code","source":"# special thanks to https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n\nclf_xgb = xgb.XGBClassifier(learning_rate =0.03, \n                            n_estimators=4000, \n                            max_depth=best_params_1[\"max_depth\"],\n                            min_child_weight=best_params_1[\"min_child_weight\"],\n                            gamma=best_params_2[\"gamma\"],\n                            subsample=best_params_3[\"subsample\"],\n                            colsample_bytree=best_params_3[\"colsample_bytree\"],\n                            reg_alpha=best_params_4['reg_alpha'],\n                            reg_lambda = best_params_5['reg_lambda'],\n                            objective= 'binary:logistic',\n                            nthread=-1,\n                            scale_pos_weight=1,\n                            seed=42)\n\nclf_xgb.fit(xtrain, ytrain, eval_set=[(xtrain, ytrain), (xvalid, yvalid)], \n            early_stopping_rounds=100, eval_metric='auc', verbose=100)\n\npredictions = clf_xgb.predict(xvalid)\npredictions_probas = clf_xgb.predict_proba(xvalid)\n\nprint()\nprint(classification_report(yvalid, predictions))\n\nprint()\nprint(\"accuracy_score\", accuracy_score(yvalid, predictions))\n\nprint()\nprint(\"roc-auc score\", roc_auc_score(yvalid, predictions_probas[:,1]))\n\nfrom sklearn.metrics import confusion_matrix\nimport scikitplot as skplt\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_confusion_matrix(yvalid, predictions, cmap=\"BrBG\")\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_roc(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_ks_statistic(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_lift_curve(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(12, 18)})\nxgb.plot_importance(clf_xgb, title='Feature importance', xlabel='F score', ylabel='Features')\n\nprint()\nprint(\"elapsed time in seconds: \", time.time() - start_time)\n\nprint()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad276e45246c6eb85273133b1c1c25054a353e47"},"cell_type":"markdown","source":"### Delete defined variables to free up memory space"},{"metadata":{"_uuid":"a4e3263d4bf6a80b92f0c14e5ab358c45ff26864","trusted":false},"cell_type":"code","source":"del X\ndel y\ndel xvalid\ndel yvalid\ndel xtrain\ndel ytrain\ndel predictions\ndel predictions_probas\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"437a869c49404f98675b3b130062f34af642bf9c"},"cell_type":"markdown","source":"### Make predictions for the test Set\n- Due to memory limitations predictions will be performed in chunks"},{"metadata":{"trusted":true,"_uuid":"4526c09f2207497b579edfabb97761c5c73877b3"},"cell_type":"code","source":"predictions_proba_test_list = []\n\nchunck = 400000\ntest_times = test.shape[0] // chunck\ntest_rest = test.shape[0] % chunck\n\nfor i in  np.arange(0,(chunck * (test_times+1)), chunck):\n    predictions_proba_test = list(clf_xgb.predict_proba(test[i:(i+chunck)])[:,1])\n    predictions_proba_test_list.append(predictions_proba_test)\n    #print(\"times:\", i)\n\n\n# flatten the list of lists\npredictions_proba_test_list = [y for x in predictions_proba_test_list for y in x]\n\nprint(np.shape(predictions_proba_test_list))\nprint(test.shape)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6ca94cb994998642e4d6c46b8da0a305d814dc5"},"cell_type":"markdown","source":"### Prepare Submission File"},{"metadata":{"trusted":true,"_uuid":"2368f1e4055f32da56242891a5d76add2e163cea"},"cell_type":"code","source":"del test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3bdedf1101acae87d7df1347fcfcd79bc872335"},"cell_type":"code","source":"del clf_xgb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a984b61c5bd6e9881f76b9a281aae6bb4e22930","trusted":false},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv')\nsubmission['HasDetections'] = predictions_proba_test_list\nsubmission.to_csv('xgboost.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e163232fc5e4ee1cd248ccf8d319a399912b8239","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"155ba1e850542bb709a19e03f1c177a4b9c1e02e","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}