{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dcfca4fc-5889-cabd-c24a-f3d7373fd065"
      },
      "source": [
        "# Tensorflow with Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ddfe368a-ae7a-9de4-7cad-09fddcb3839e"
      },
      "source": [
        "The main agenda for this analysis is to predict credit crad fraud in the trasaction data.I will be using tensorflow to build the predictive model. To learn more about dataset,visit: https://www.kaggle.com/dalpozz/creditcardfraud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2099d993-46df-ce0b-d032-249535061195",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.gridspec as gridspec\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "006e178b-78ee-d4af-964c-8ddc6eb9607d"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../input/creditcard.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0217c14d-45fb-74f7-8a29-f0c40a22e92a"
      },
      "source": [
        "\n",
        "\n",
        "# Exploring the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "af5aece1-4a07-46d4-eacf-4e23ed876c32"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7c7acfb9-541b-71ab-c376-f1d1b77f6344"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5ce86230-5274-e23d-7232-7bd9382ae96b"
      },
      "source": [
        "No missing value, that makes things a bit easier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3daff603-fbda-fb67-04cf-f242daf4bf73"
      },
      "source": [
        "After alot of heeding and trying different differential graphs for analyzing dataset, i took a step up to create statistical graphs using 'seaborn' module. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "93e055b1-802f-b49c-da99-7139a8190756",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#Select only the anonymized features.\n",
        "v_features = df.ix[:,1:29].columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aa1230f6-6100-5b85-f595-9c3ea6a09edd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,28*4))\n",
        "gs = gridspec.GridSpec(28, 1)\n",
        "for i, cn in enumerate(df[v_features]):\n",
        "    ax = plt.subplot(gs[i])\n",
        "    sns.distplot(df[cn][df.Class == 1], bins=50)\n",
        "    sns.distplot(df[cn][df.Class == 0], bins=50)\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_title('histogram of feature: ' + str(cn))\n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ef9ad368-596c-29be-9e4e-444404a044eb"
      },
      "outputs": [],
      "source": [
        "#Drop all of the features that have very similar distributions between the two types of transactions.\n",
        "df = df.drop(['V28','V27','V26','V25','V24','V23','V22','V20','V15','V13','V8'], axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "85fe11f7-626b-5823-9a84-bd2f82a1de44"
      },
      "outputs": [],
      "source": [
        "# create new fearures for distribution\n",
        "df.loc[df.Class == 0, 'Normal'] = 1\n",
        "df.loc[df.Class == 1, 'Normal'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "44bcdd96-8a9d-0cce-d3a0-b4d28f3e7903"
      },
      "outputs": [],
      "source": [
        "#Rename 'Class' to 'Fraud'.\n",
        "df = df.rename(columns={'Class': 'Fraud'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b88053ca-2f8d-6e9a-d92c-4d0b122c0ccd"
      },
      "outputs": [],
      "source": [
        "#create Fraud and normal feature distribution\n",
        "Fraud = df[df.Fraud == 1]\n",
        "Normal = df[df.Normal == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "66db88ad-6fab-7bc5-7fc1-b4d3228cb6f0"
      },
      "outputs": [],
      "source": [
        "# create X_train by taking 80% of fraud transactions and 80% of normal transactions\n",
        "X_train = Fraud.sample(frac=0.8)\n",
        "count_Frauds = len(X_train)\n",
        "X_train = pd.concat([X_train, Normal.sample(frac = 0.8)], axis = 0)\n",
        "X_test = df.loc[~df.index.isin(X_train.index)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a2df6e44-8bf6-ba81-acbf-dbef5f154b3c"
      },
      "outputs": [],
      "source": [
        "# create Y_train by taking 80% of fraud transactions and 80% of normal transactions\n",
        "y_train = X_train.Fraud\n",
        "y_train = pd.concat([y_train, X_train.Normal], axis=1)\n",
        "y_test = X_test.Fraud\n",
        "y_test = pd.concat([y_test, X_test.Normal], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "394e7b8b-5eba-321d-060e-dfab37149217"
      },
      "outputs": [],
      "source": [
        "# drop the guest features\n",
        "X_train = X_train.drop(['Fraud','Normal'], axis = 1)\n",
        "X_test = X_test.drop(['Fraud','Normal'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "28f7dee3-2e78-ce22-c92f-45ab07a3b3c5"
      },
      "outputs": [],
      "source": [
        "# scale values of features\n",
        "features = X_train.columns.values\n",
        "for feature in features:\n",
        "    mean, std = df[feature].mean(), df[feature].std()\n",
        "    X_train.loc[:, feature] = (X_train[feature] - mean) / std\n",
        "    X_test.loc[:, feature] = (X_test[feature] - mean) / std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "957bfc24-519b-ca42-71b8-eeb1d9a4de65"
      },
      "source": [
        "\n",
        "# Train the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3b4dcec6-6bc7-13a8-7779-4ef12559a45f"
      },
      "outputs": [],
      "source": [
        "#split the dataset for train,test & validation\n",
        "split = int(len(y_test)/2)\n",
        "\n",
        "inputX = X_train.as_matrix()\n",
        "inputY = y_train.as_matrix()\n",
        "inputX_valid = X_test.as_matrix()[:split]\n",
        "inputY_valid = y_test.as_matrix()[:split]\n",
        "inputX_test = X_test.as_matrix()[split:]\n",
        "inputY_test = y_test.as_matrix()[split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f1cfddab-b866-87ab-b1d3-3711715df240"
      },
      "outputs": [],
      "source": [
        "#parameters\n",
        "learning_rate = 0.005\n",
        "training_epoch = 10\n",
        "batch_size = 2048\n",
        "display_step = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8ff1c8f9-0801-f64a-686e-6196e6a4f38f"
      },
      "outputs": [],
      "source": [
        "#tf graph input\n",
        "x = tf.placeholder(tf.float32,[None,19])\n",
        "y = tf.placeholder(tf.float32,[None,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f88df848-fa2a-1139-060d-8961d38f9e8d"
      },
      "outputs": [],
      "source": [
        "#set model weights\n",
        "w = tf.Variable(tf.zeros([19,2]))\n",
        "b = tf.Variable(tf.zeros([2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f2138ba6-6c24-7d2c-ce49-d6a00cd08786"
      },
      "outputs": [],
      "source": [
        "#construct model using softmax activation\n",
        "pred = tf.nn.softmax(tf.matmul(x,w) + b) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0d1475da-53c8-de88-4f9b-76490ceb310d"
      },
      "outputs": [],
      "source": [
        "#minimize error using cross entropy\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ee0dfc52-4a81-b582-5089-0cbd8164c265"
      },
      "outputs": [],
      "source": [
        "#Gradient descent\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d90cbe9d-7c9d-fa70-23d9-a4425d4e7e39"
      },
      "outputs": [],
      "source": [
        "#initializing variables\n",
        "init = tf.global_variables_initializer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "163be27f-af01-5bd0-5dcd-8a2afd29e455"
      },
      "outputs": [],
      "source": [
        "#launch the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    final_output_array = []\n",
        "    #training cycle\n",
        "    for epoch in range(training_epoch):\n",
        "        total_batch = len(inputX)/batch_size\n",
        "        avg_cost = 0\n",
        "        #loop over all the batches\n",
        "        for batch in range(int(total_batch)):\n",
        "            batch_xs = inputX[(batch)*batch_size:(batch+1) *batch_size]\n",
        "            batch_ys = inputY[(batch)*batch_size:(batch+1) *batch_size]\n",
        "\n",
        "            # run optimizer and cost operation\n",
        "            _,c= sess.run([optimizer,cost],feed_dict={x:batch_xs,y:batch_ys})\n",
        "            avg_cost += c/total_batch\n",
        "\n",
        "        correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
        "\n",
        "        #disply log per epoch step\n",
        "        if (epoch+1) % display_step == 0:\n",
        "            train_accuracy, newCost = sess.run([accuracy, cost], feed_dict={x: inputX_test,y: inputY_test})\n",
        "            print (\"epoch:\",epoch+1,\"train_accuracy\",train_accuracy,\"cost\",newCost,\"valid_accuracy\",sess.run([accuracy],feed_dict={x:inputX_valid,y:inputY_valid}))\n",
        "            print (\"\")\n",
        "\n",
        "    print ('optimization finished.')"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}