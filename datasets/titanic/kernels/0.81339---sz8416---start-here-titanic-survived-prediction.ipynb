{"cells":[{"metadata":{"_uuid":"335bf40b68ef1c383addbc68b2c982843ef01926"},"cell_type":"markdown","source":"- <a href='#1'>1. Import Data</a>  \n- <a href='#2'>2. EDA</a>\n    - <a href='#2-1'>2.1 Missing Values</a>\n    - <a href='#2-2'>2.2 Categorical Features</a>\n    - <a href='#2-2'>2.3 Numerical Features</a>\n- <a href='#3'>3. Feature Engineering</a>\n- <a href='#4'>4. Preprocessing</a>\n- <a href='#5'>5. Final Model and Prediction</a>"},{"metadata":{"_uuid":"eb49251a83ef926bd437f4bf6f10a3022aee7489"},"cell_type":"markdown","source":"## <a id='1'>1. Import Data</a>"},{"metadata":{"_uuid":"47ec41da530e39c450a786cdce35ce1871f341fb"},"cell_type":"markdown","source":"### Step 1: Let's import dataset and all required module\n\nTypically, we need: \n\n**pandas**: the most important module for data analysis, includeing various functions for data manipulation. It is very powerful for data exploration and feature engineering\n\n**numpy**: matrix calculation\n\n**matplotlib.pyploy** & **seaborn**: used for EDA and visualiztion\n\n**sklearn**: the most popular machine learning API"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer, MICEImputer\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')\nsubmission = pd.read_csv('../input/submission/final submission.csv')\nsubmission.to_csv('test_submission.csv', index=False)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"071dc78122530ff59075cfebe1d3a331a56047b0","collapsed":true},"cell_type":"code","source":"print('train:', train.shape[0], \"rows and\", train.shape[1],'columns')\nprint('train:', test.shape[0], \"rows and\", test.shape[1],'columns')","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"86d045dcb416781639185f7c992084bd2e886fee"},"cell_type":"markdown","source":"## <a id='2'>2. EDA</a>"},{"metadata":{"_uuid":"23c2059228c088b61db976ffe6a7fbccf27d9bbd"},"cell_type":"markdown","source":"### Step2: exploratory data analysis\n\nIn this stage, we'll explore deeply into data. We usually check missing values and look at the distribution. For numerical and categorical features, we use different plots to visualize and get intuition. \n\nAdditionally, when solving classification problem, pay special attention on the differences betweem **label 1** data and **label 0** data"},{"metadata":{"_uuid":"fa598d652ac4343ae78ebafefb4d95cf69f17f56"},"cell_type":"markdown","source":"### <a id='2-1'>2.1 Missing Values</a>"},{"metadata":{"trusted":true,"_uuid":"9ac59962b83ea453231982957d1876d0225042d8","collapsed":true},"cell_type":"code","source":"def find_missing(data):\n    # number of missing values\n    count_missing = data.isnull().sum().values\n    # total records\n    total = data.shape[0]\n    # percentage of missing\n    ratio_missing = count_missing/total\n    # return a dataframe to show: feature name, # of missing and % of missing\n    return pd.DataFrame(data={'missing_count':count_missing, 'missing_ratio':ratio_missing}, index=data.columns.values)\nfind_missing(train)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"1ea871c31bc33aa2b32a263ef38c77dd6728bf63"},"cell_type":"markdown","source":"### <a id='2-2'>2.2 Categorical Features</a>"},{"metadata":{"_uuid":"e91142ad71845ed53fde14b5f6119725dbf4a599"},"cell_type":"markdown","source":"#### Survived vs Non-survived"},{"metadata":{"trusted":true,"_uuid":"51ee77f4e57ec03f7845de4bb7a743db3e8f59f5","collapsed":true},"cell_type":"code","source":"def plot_categorical(data, col, size=[8 ,6], xlabel_angle=0, title=''):\n    '''use this for ploting the count of categorical features'''\n    plotdata = data[col].value_counts() / len(data)\n    plt.figure(figsize = size)\n    sns.barplot(x = plotdata.index, y=plotdata.values, )\n    plt.title(title)\n    if xlabel_angle!=0: \n        plt.xticks(rotation=xlabel_angle)\n    plt.show()\nplot_categorical(data=train, col='Survived', size=[8 ,4], xlabel_angle=0, title='Train Set: Survived')","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"eaf46d4a4ca26de5ea7e87b91b13d15f6fd14542"},"cell_type":"markdown","source":"#### Pclass"},{"metadata":{"trusted":true,"_uuid":"5f69c6990ea731f76437f6002f1ab52c5ff731a2","collapsed":true},"cell_type":"code","source":"def plot_categorical_bylabel(data, col, type='count', size=[12 ,6], xlabel_angle=0, title=''):\n    '''use it to compare the distribution between label 1 and label 0'''\n    plt.figure(figsize = size)\n    l1 = data.loc[data.Survived==1, col].value_counts()\n    l0 = data.loc[data.Survived==0, col].value_counts()\n    if type == 'ratio':\n        l1 = l1 / l1.sum()\n        l0 = l0 / l0.sum()\n    plt.subplot(1,2,1)\n    sns.barplot(x = l1.index, y=l1.values)\n    plt.title('Default: '+title)\n    plt.xticks(rotation=xlabel_angle)\n    plt.subplot(1,2,2)\n    sns.barplot(x = l0.index, y=l0.values)\n    plt.title('Non-default: '+title)\n    plt.xticks(rotation=xlabel_angle)\n    plt.show()\nplot_categorical_bylabel(train, 'Pclass', type='ratio', title='Class')","execution_count":40,"outputs":[]},{"metadata":{"_uuid":"c0adb68746d6cb0ffda466a6e8e3ab0495a590d7"},"cell_type":"markdown","source":"#### Gender"},{"metadata":{"trusted":true,"_uuid":"91a25247f529530f58efb570192f0fcef4fa8acb","collapsed":true},"cell_type":"code","source":"plot_categorical_bylabel(train, 'Sex', type='ratio', title='Gender')","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"73a60bf6ff796c43fb9d808300179817da79762a"},"cell_type":"markdown","source":"#### Cabin"},{"metadata":{"trusted":true,"_uuid":"60b43ab48a90d6b55f067118ba7abeb33fd6f3e5","collapsed":true},"cell_type":"code","source":"# the first letter of cabin\ndef find_cabin(cabin_list):\n    find_cabin = []\n    nan_find = cabin_list.isnull()\n    for i in range(len(cabin_list)):\n        if nan_find[i]:\n            temp = cabin_list[i]\n        else:\n            temp = cabin_list[i][0]\n        find_cabin.append(temp)\n    return find_cabin\ntrain['Cabin_first_letter'] = find_cabin(train.Cabin)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5b7f8dcdc2a7da96c69c80b54c53db2c2bbe17e","collapsed":true},"cell_type":"code","source":"plot_categorical_bylabel(train, 'Cabin_first_letter', type='ratio', title='Cabin')","execution_count":39,"outputs":[]},{"metadata":{"_uuid":"2e1144918a4e459b91e0cb7b99a976275965cc51"},"cell_type":"markdown","source":"### <a id='2-3'>2.3 Numerical Features</a>"},{"metadata":{"_uuid":"eaaa0d5ef657befaa119dade6b9508edbba913e4"},"cell_type":"markdown","source":"#### Age"},{"metadata":{"trusted":true,"_uuid":"971f1707e1a7023863c76ec869599fab58295589","collapsed":true},"cell_type":"code","source":"def plot_numerical_bylabel(data, col, size=[12, 6]):\n    # print out the correlation\n    corr = data['Survived'].corr(data[col])\n    print('The correlation between %s and the TARGET is %0.4f' % (col, corr))\n    plt.figure(figsize = size)\n    sns.kdeplot(data.ix[data['Survived'] == 0, col], label = 'Survived == 0')\n    sns.kdeplot(data.ix[data['Survived'] == 1, col], label = 'Survived == 1')\n    \n    plt.xlabel(col); plt.ylabel('Density'); plt.title('%s Distribution' % col)\n    plt.legend()\n    plt.show()\nplot_numerical_bylabel(train, 'Age')","execution_count":36,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0a1e9a5555c555b583f605bdecfadb25e58ac49","collapsed":true},"cell_type":"code","source":"plot_numerical_bylabel(train, 'Fare')","execution_count":38,"outputs":[]},{"metadata":{"_uuid":"6470682f14cf0e913cf14f27b1e0d445eebdb269"},"cell_type":"markdown","source":"## <a id='3'>3. Feature Engineering</a>"},{"metadata":{"_uuid":"b4b2018a22108ed2a68e76822b5b46008faf647a"},"cell_type":"markdown","source":"### Step 3: feature engineering based on EDA\n\nAfter understanding the data, we start to create features for classification. Some vairables are good enough for direct use, like age and fare. But for some complicated features, like name, cabin and ticket, they need some special treatment."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fa39aef30873b262895f28503687c455837e388d"},"cell_type":"code","source":"# from name column, find title \ndef find_title(name_list):\n    title_list=[]\n    for i in name_list:\n        i_list = i.split()\n        if i_list[1] in ['Mrs.', 'Miss.', 'Master.', 'Mr.']:\n            title_list.append(i_list[1])\n        elif i_list[2] in ['Mrs.', 'Miss.', 'Master.', 'Mrs']:\n            title_list.append(i_list[2])\n        else:\n            title_list.append('No title')\n    return title_list\n# whether cabin is missing value\ndef cabin_exist(cabin_list):\n    cabin_exist = []\n    nan_find = cabin_list.isnull()\n    for i in range(len(cabin_list)):\n        if nan_find[i]:\n            temp=1\n        else:\n            temp=0\n        cabin_exist.append(temp)\n    return cabin_exist\n# find the first letter of cabin\ndef find_cabin(cabin_list):\n    find_cabin = []\n    nan_find = cabin_list.isnull()\n    for i in range(len(cabin_list)):\n        if nan_find[i]:\n            temp = cabin_list[i]\n        else:\n            temp = cabin_list[i][0]\n        find_cabin.append(temp)\n    return find_cabin\ntrain.Cabin = find_cabin(train.Cabin)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64935821ce59936ee23db08aff922d9d665b965e","collapsed":true},"cell_type":"code","source":"def feature_engineering(df):\n    df2 = df.copy()\n    # passenger in class 3\n    df2['is_class3'] = [1 if i == 3 else 0 for i in df2.Pclass]\n    # passenger is less than 10\n    df2['is_child'] = [1 if i <= 10 else 0 for i in df2.Age]\n    # passenger has no page\n    df2['no_parch'] = [1 if i == 0 else 0 for i in df2.Parch]\n    df2['low_fare'] = [1 if i < 5 else 0 for i in df2.Fare]\n    # passenger's cabin information is not null\n    df2['Cabin_exist'] = cabin_exist(df2.Cabin)\n    df2.Cabin = find_cabin(df2.Cabin)\n    # passenger is in cabin B/C/D/E\n    df2['safe_cabin']=[1 if i in ['B','C','D','E'] else 0 for i in df2.Cabin]\n    df2['title']=find_title(df2.Name)\n    # MR.passenger\n    df2['is_mr']=[1 if i == 'Mr.' else 0 for i in df2.title]\n    # miss passenger\n    df2['is_miss']=[1 if i == 'Miss.' else 0 for i in df2.title]\n    df2['Ticket'] = [i.split()[-1][0] for i in df2.Ticket]\n    df2['Ticket'] = [0 if i=='L' else i for i in df2.Ticket]\n    # passager is at position 3 - 8\n    df2['Position_3to8'] = [1 if ((int(i)>=3)&(int(i)<=8)) else 0 for i in df2.Ticket]\n    df2 = df2.drop(['Pclass', 'SibSp', 'Parch', 'Cabin', 'Ticket', 'Name', 'title'], 1)\n    df2 = pd.get_dummies(df2).drop(['Embarked_Q', 'Embarked_C','Sex_male'],1)\n    return df2\n# create dataset for modeling\ntrain_use = feature_engineering(train)\ntest_use = feature_engineering(test)\nprint(train_use.shape)\nprint(test_use.shape)","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"5b38e1cac4e898ec6772c650c1b80a82ec9da4da"},"cell_type":"markdown","source":"## <a id='4'>4. Preprocessing</a>"},{"metadata":{"_uuid":"59c7270a469429b4c429ea2d1dd2057024b0a0dc"},"cell_type":"markdown","source":"### Step 4: preprocessing: impute missing, normalization, etc.\n\nTypically in real world project, we need to deal with NAs and do some transformation before modeling.\n\nHere, we only need to impute the missing values in *Age* and *Fare*. We use [MiceImputer](http://scikit-learn.org/dev/modules/generated/sklearn.impute.MICEImputer.html) from sklearn. "},{"metadata":{"trusted":true,"_uuid":"7bb3475bdca4f03797c4176fa1b7532e6a1e4ec6","collapsed":true},"cell_type":"code","source":"train_use[train_use.columns.tolist()] = MICEImputer(initial_strategy='median', n_imputations=50, n_nearest_features=20, verbose=False).fit_transform(train_use)\ntest_use[test_use.columns.tolist()] = MICEImputer(initial_strategy='median', n_imputations=50, n_nearest_features=20, verbose=False).fit_transform(test_use)","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"966c515bbd0bb258e22509bee8c4680f0d80d4fe"},"cell_type":"markdown","source":"## <a id='5'>5. Final Model and Prediction</a>"},{"metadata":{"_uuid":"2fabecd6ee6881fd1a7f4d708748d4e37484446b"},"cell_type":"markdown","source":"### Train Model and Tune Parameters"},{"metadata":{"trusted":true,"_uuid":"5e7c824103c7dba6c7f5670114c4236bb404c026","collapsed":true},"cell_type":"code","source":"X = train_use.iloc[:, 2:]\ny = train_use.Survived\nX_pred = test_use.iloc[:, 1:]","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da9a367d24b1e9832f92a1fd50eceb7838210574","collapsed":true},"cell_type":"code","source":"if len(X.columns.tolist()) > 20:\n    X = X.iloc[:, :13]","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"7b87e136e906a1e05d8a7dd6b52cf36c92f4036e"},"cell_type":"markdown","source":"1) learning_rate"},{"metadata":{"trusted":true,"_uuid":"294ce4577ff6ac9719e7e5a2fe57c114a3a41e0a","collapsed":true},"cell_type":"code","source":"params1 = {'learning_rate':np.arange(0.01,0.3, 0.01)}\ngdbt = GradientBoostingClassifier(n_estimators=100, min_samples_split=300,\n                                  min_samples_leaf=20,max_depth=10, subsample=0.8,random_state=10)\ngridscgdbt = GridSearchCV(gdbt, params1, cv=5)\ngridscgdbt.fit(X, y)\nprint(gridscgdbt.best_params_)\nprint(gridscgdbt.best_score_)","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"c6b6ad57ff9fbcec9457e5006d4f5a5b02a198b3"},"cell_type":"markdown","source":"2) max_depth and min_samples_split"},{"metadata":{"trusted":true,"_uuid":"989fd1caae017072c3b5a6146b94b8c946f1e9b7","collapsed":true},"cell_type":"code","source":"params2 = {'max_depth':range(2,8,1), 'min_samples_split':range(20,200,20)}\ngdbt2 = GradientBoostingClassifier(n_estimators=100, learning_rate=gridscgdbt.best_params_['learning_rate'], \n                                   subsample=0.8,random_state=10)\ngridscgdbt2 = GridSearchCV(gdbt2, params2, cv=5)\ngridscgdbt2.fit(X, y)\nprint(gridscgdbt2.best_params_)\nprint(gridscgdbt2.best_score_)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"3bf4d008f2861ce88b914cea0c5bd8ec5ba8bbb1"},"cell_type":"markdown","source":"3) max_features and subsample"},{"metadata":{"trusted":true,"_uuid":"932ca0742f8dab7e3af675fea5103883404b233b","collapsed":true},"cell_type":"code","source":"params3 = {'max_features':np.arange(0.5,1,0.1), 'subsample':np.arange(0.5, 1, 0.1)}\ngdbt3= GradientBoostingClassifier(n_estimators=100, learning_rate=gridscgdbt.best_params_['learning_rate'], \n                                   max_depth=gridscgdbt2.best_params_['max_depth'],\n                                   min_samples_split=gridscgdbt2.best_params_['min_samples_split'],\n                                   subsample=0.8,random_state=10)\ngridscgdbt3 = GridSearchCV(gdbt3, params3, cv=5)\ngridscgdbt3.fit(X, y)\nprint(gridscgdbt3.best_params_)\nprint(gridscgdbt3.best_score_)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76c5f842a2d61a85e1d9869fe30ff9ee24b6c94e","collapsed":true},"cell_type":"code","source":"# final model\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\ngbdt_best = GradientBoostingClassifier(n_estimators=100, learning_rate=gridscgdbt.best_params_['learning_rate'], \n                                   max_depth=gridscgdbt2.best_params_['max_depth'],\n                                   min_samples_split=50,\n                                   subsample=gridscgdbt3.best_params_['subsample'],\n                                   max_features=gridscgdbt3.best_params_['max_features'],\n                                   random_state=3)\ngbdt_best.fit(X_train, y_train)\nprint('The validation accuracy is:', str(round((gbdt_best.predict(X_test) == y_test).mean(),3)))","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70b40f2b9c68637779fd0fdd50f8d24bc4c1523a","collapsed":true},"cell_type":"code","source":"pd.DataFrame({'importance':gbdt_best.feature_importances_}, index=X.columns)","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"d98d5f39f8d5cbca69037d4f03d539057bdd9870"},"cell_type":"markdown","source":"### Prediction"},{"metadata":{"trusted":true,"_uuid":"6b4c4a7b195a490d3979e5e137dbfd07eedd543b","collapsed":true},"cell_type":"code","source":"test_ID = test.PassengerId\ny_pred_test = gbdt_best.predict(X_pred)\nfinal = pd.DataFrame({'PassengerId': test_ID, 'Survived': y_pred_test})\nfinal.Survived = final.Survived.astype(int)\nfinal.to_csv('final submission.csv', index=False)","execution_count":19,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}