{"cells":[{"metadata":{"_cell_guid":"8a83ad7e-d982-4269-0ce6-c24229e3b854","_uuid":"651338cdde841c5a35bcb7b46f3f9fbb630b714a"},"cell_type":"markdown","source":"Get accuracy >98 on first run.. (recommended not to run on Kaggle Kernal Platform)"},{"metadata":{"_cell_guid":"8e828638-e2b5-9b00-8c74-b503acc7db3e","_uuid":"e8815010c31548b116b72c155acd3039fed4699b","trusted":true},"cell_type":"code","source":"\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, Convolution1D\nfrom keras.layers.core import Dense, Activation, Dropout, Flatten\nfrom keras.models import Sequential\nfrom keras.optimizers import SGD\nfrom keras.datasets import mnist\nfrom keras.callbacks import *\n\nimport numpy as np\nimport matplotlib as mpl\nmpl.use('Agg')\nimport matplotlib.pyplot as plt","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"e7849641-b6f0-722a-f879-efcf8c900321","_uuid":"16df17e10605e451959a26a4c225a4dc94c1e754","trusted":true,"collapsed":true},"cell_type":"code","source":"\ndataFile = \"../input/train.csv\"\nqueFile = \"../input/test.csv\"\n","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"5d28a66d-8629-1066-fd4e-f8a4b8fb5574","_uuid":"d329b0df41fe7cb6d33d25b5664f6402f9940a61","trusted":true,"collapsed":true},"cell_type":"code","source":"\nbatch_size = 128\nnb_classes = 10\nnb_epoch = 150 #use 15\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\ninput_shape = (28,28,1)\n# number of convolutional filters to use\nnb_filters = 32\n# size of pooling area for max pooling\npool_size = (2, 2)\n# convolution kernel size\nkernel_size = (3, 3)","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"06ac39f6-c4b5-1c1b-edb6-f4c26503a018","_uuid":"4f000d42a912913462780d3f392dd7be6a86df8c","trusted":true},"cell_type":"code","source":"\nprint (\"^^^INFO: Fix random seed^^^\")\n\nseed = 7\nnp.random.seed(seed)\n\nprint (\"^^^INFO: Load dataset^^^\")\n# dataset = numpy.loadtxt(\"diabetic_data_1000V2.csv\", delimiter=\",\",comments=\"#\")\ndataset = np.genfromtxt(dataFile, delimiter=\",\", comments=\"#\",skip_header=1)\n\n# mask = np.any(np.isnan(dataset), axis=0)\n# dataset = dataset[:,~mask]\n\nprint (\"^^^INFO: Shape of dataset^^^\")\nprint (dataset.shape)\n\n# split into input (X) and output (Y) variables\nX = dataset[:, 1:dataset.shape[1]]\nY = dataset[:, 0]\n\nprint (\"^^^INFO: reShape dataset^^^\")\n\nfrom keras.utils.np_utils import to_categorical\nX = X.reshape(dataset.shape[0],28,28,1)\nY = to_categorical(Y)\n\nprint (\"^^^INFO: Shape of X^^^\")\nprint (X.shape)\nprint (\"^^^INFO: Shape of Y^^^\")\nprint (Y.shape)\n\nprint (\"^^^INFO: Define Model^^^\")\n","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"88d21cde-47be-ca6c-45d7-a6d9a029017e","_uuid":"324fd0ead0cb2fb323a4581a5af4f46ef32cca61","trusted":true,"scrolled":true},"cell_type":"code","source":"\n# create model\nmodel = Sequential()\n\nmodel.add(Convolution2D(nb_filters,kernel_size[0], kernel_size[1],\n                        border_mode='valid', input_shape=input_shape))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=pool_size))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(nb_classes))\nmodel.add(Activation('softmax'))","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3300c469dd0c9a040c6c2f8ad90da41ac6ce4dbf","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_tr,x_val,y_tr,y_val= train_test_split(X,Y, test_size=0.3,stratify=Y)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"160a8b98f4a1eb78b7a686927d5a70153f98fba8"},"cell_type":"code","source":"es = EarlyStopping(min_delta=0.00001,patience=15,verbose=2)\ncp = ModelCheckpoint(\"bst_model_wts\",save_best_only=True)\nrlop = ReduceLROnPlateau(patience=5,factor=0.3)","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"6dcb2d0e-f394-3041-466d-bd7004a35b38","_uuid":"f3f6bc6cae7adc6535f65a5fa3351ad102e442fa","trusted":true},"cell_type":"code","source":"#this will take around 30 minutes on 2 processors\n\nprint (\"^^^INFO: Compile Model^^^\")\nmodel.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy', 'mse'])\n\nprint (\"^^^INFO: Fit Model^^^\")\nhistory = model.fit(x_tr, y_tr, epochs=nb_epoch, batch_size=420, verbose=1,validation_data=(x_val, y_val),callbacks=[es,cp,rlop])\n\nprint (\"^^^INFO: Evaluate Model^^^\")\nscores = model.evaluate(X, Y)\nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"e66b77f6-7c03-2c7d-dccd-97d3cc5ce923","_uuid":"4b5644644bee313ef349f29e6a0db9c10ee2ca83","trusted":true,"collapsed":true},"cell_type":"code","source":"\n# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\n# axes = plt.gca()\n# axes.set_xlim([0,120])\n# axes.set_ylim([90,100])\nplt.savefig('acc.png')  # save the figure to file\nplt.show()\nplt.close()\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('loss.png')\nplt.show()","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"325d8440-36e9-b115-2cc5-f1e8606f8f17","_uuid":"e7508a7c954ca2e92ce4ebc049570acd8909c4e7","trusted":true,"collapsed":true},"cell_type":"code","source":"print (\"^^^INFO: Load dataset for Prediction^^^\")\nqueset_raw = np.genfromtxt(queFile, delimiter=\",\", comments=\"#\")\nqueset_raw=queset_raw[1:,:]\nprint(queset_raw.shape)\n\nqueset = queset_raw.reshape(queset_raw.shape[0],28,28,1)\nprint(queset.shape)\n\nprint (\"^^^INFO: Making Prediction^^^\")\npred_Y = model.predict_classes(queset)\n\nprint (\"^^^INFO: Making Prediction Index^^^\")\nn = list(range(1, pred_Y.shape[0] + 1))\n\nprint (\"^^^INFO: Concat Prediction & Index^^^\")\nprint(pred_Y.shape)\nprint(len(n))\nresult = np.c_[n, pred_Y]\n\nprint (\"^^^INFO: Add Label Prediction^^^\")\nprint(result.shape)\nresult = np.r_[[['ImageId', 'Label']], result]\n\nprint (\"^^^INFO: Prediction to result.csv^^^\")\nprint(result.shape)\n# result.tofile('result.csv',sep=',')\nnp.savetxt('result.csv', result, delimiter=',', fmt='%s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1e8d1d0a2347a131b62941ced4dcc0c3e95e5054"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}