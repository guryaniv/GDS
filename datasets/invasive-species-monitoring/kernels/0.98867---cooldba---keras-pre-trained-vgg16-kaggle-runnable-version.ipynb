{"cells":[{"metadata":{"_uuid":"19b98e2a040defbc811ef3278f6f64f00f5c0fe4"},"cell_type":"markdown","source":"Keras pre-trained VGG16 [KAGGLE RUNNABLE VERSION]\n\n\n\n"},{"metadata":{"_cell_guid":"fdca4192-cf9d-1f5f-7e8f-30ae5e468db4","_uuid":"fea75488c3473a2a4952a1e270bc21db460ad7aa"},"cell_type":"markdown","source":"## resize train data and test data ##"},{"metadata":{"trusted":true,"_uuid":"6f1270232bfaec3a296a1cdece8b4009d0c581ec","collapsed":true},"cell_type":"markdown","source":"import os\n\ncache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\n\n\nmodels_symlink = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_symlink):\n    os.symlink('/kaggle/input/keras-pretrained-models/', models_symlink)"},{"metadata":{"_cell_guid":"aab06a15-51b8-13e2-172a-b3e62aa3738a","_uuid":"ffce9afbed37e5005f74f595df9d2b2b75ef9156","trusted":true,"collapsed":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport math\nfrom glob import glob\nimport os\n\nmaster = pd.read_csv(\"../input/invasive-species-monitoring/train_labels.csv\")\nmaster.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e68a78fc-8470-e081-27ad-eca99e6fdd1f","_uuid":"6f757d92c7d2183ad94bbdb48fa66e4ecbdce3b9","trusted":true,"collapsed":true},"cell_type":"code","source":"img_path = \"../input/invasive-species-monitoring/train/\"\n\ny = []\nfile_paths = []\nfor i in range(len(master)):\n    file_paths.append( img_path + str(master.iloc[i][0]) +'.jpg' )\n    y.append(master.iloc[i][1])\ny = np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"34636940-b7b8-64f6-6ca7-1ad97081ea7b","_uuid":"e5ae1b626ae8aa950ad7528b8f8df7174111fa77","trusted":true,"collapsed":true},"cell_type":"code","source":"#image reseize & centering & crop \n\ndef centering_image(img):\n    size = [256,256]\n    \n    img_size = img.shape[:2]\n    \n    # centering\n    row = (size[1] - img_size[0]) // 2\n    col = (size[0] - img_size[1]) // 2\n    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)\n    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img\n\n    return resized\n\n\nx = []\nfor i, file_path in enumerate(file_paths):\n    #read image\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    #resize\n    if(img.shape[0] > img.shape[1]):\n        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n    else:\n        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n\n    #centering\n    img = centering_image(cv2.resize(img, dsize=tile_size))\n    \n    #out put 224*224px \n    img = img[16:240, 16:240]\n    x.append(img)\n\nx = np.array(x)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1f371b5e-579e-cd78-51f3-bad30c864a85","_uuid":"ec55c4fe8d53ab7bd979dea0254655505f64fe63","trusted":true,"collapsed":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/invasive-species-monitoring/sample_submission.csv\")\nimg_path = \"../input/invasive-species-monitoring/test/\"\n\ntest_names = []\nfile_paths = []\n\nfor i in range(len(sample_submission)):\n    test_names.append(sample_submission.iloc[i][0])\n    file_paths.append( img_path + str(int(sample_submission.iloc[i][0])) +'.jpg' )\n    \ntest_names = np.array(test_names)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8f849642-855e-63b0-26e8-107724628353","_uuid":"2bee4676733586f3e720d9489e1688aecf842018","trusted":true,"collapsed":true},"cell_type":"code","source":"test_images = []\nfor file_path in file_paths:\n    #read image\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    #resize\n    if(img.shape[0] > img.shape[1]):\n        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n    else:\n        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n\n    #centering\n    img = centering_image(cv2.resize(img, dsize=tile_size))\n    \n    #out put 224*224px \n    img = img[16:240, 16:240]\n    test_images.append(img)\n    \n    path, ext = os.path.splitext( os.path.basename(file_paths[0]) )\n\ntest_images = np.array(test_images)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9d5db4fe-b1ca-80d9-eb5a-decb9e71fa8b","_uuid":"e8c186547dd700d9d1155ff67264172ee9823cef"},"cell_type":"markdown","source":"save numpy array.\n\nUsually I separate code, data format and CNN."},{"metadata":{"_cell_guid":"54ee247b-1228-bfb2-46c0-0b08e3455375","_uuid":"ee5b524be0db840ad99ef589b6a1325faec0f2fc","trusted":false,"collapsed":true},"cell_type":"code","source":"#np.savez('224.npz', x=x, y=y, test_images=test_images, test_names=test_names)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2880329f-76a5-b385-a3ba-609820535f34","_uuid":"586045e401316750df9eeb87baa0e072e0c48026"},"cell_type":"markdown","source":"## split train data and validation data  ##"},{"metadata":{"_cell_guid":"aea9535d-9baa-214c-afd1-1595ae44cb0f","_uuid":"9cf6786b89e1bd3ef273afd822e828325deaa84d","trusted":true,"collapsed":true},"cell_type":"code","source":"data_num = len(y)\nrandom_index = np.random.permutation(data_num)\n\nx_shuffle = []\ny_shuffle = []\nfor i in range(data_num):\n    x_shuffle.append(x[random_index[i]])\n    y_shuffle.append(y[random_index[i]])\n    \nx = np.array(x_shuffle) \ny = np.array(y_shuffle)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3aa4f607-c45c-c738-3b99-ced4f3fa5a28","_uuid":"2a156b5f64c34d8728f2d300f0e1bfc43b2f982c","trusted":true,"collapsed":true},"cell_type":"code","source":"val_split_num = int(round(0.2*len(y)))\nx_train = x[val_split_num:]\ny_train = y[val_split_num:]\nx_test = x[:val_split_num]\ny_test = y[:val_split_num]\n\nprint('x_train', x_train.shape)\nprint('y_train', y_train.shape)\nprint('x_test', x_test.shape)\nprint('y_test', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8b6caf1c-bc20-63cb-52a3-33dc71c5529d","_uuid":"01245e94ff330320839c430f24127e4cad20a5b4","trusted":true,"collapsed":true},"cell_type":"code","source":"x_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9fa975c5-3996-8f40-65c0-a49c09ec26ae","_uuid":"a0e9fe99ebdc426e7ad37b108111712a9f4c0386"},"cell_type":"markdown","source":"use Keras pre-trained VGG16\n---------------------------\n\nbut kaggle karnel is not run"},{"metadata":{"_cell_guid":"18861ee9-b81b-27ef-3846-0d04aafd3560","_uuid":"88479e2633833dff88740203e814b35892596b1a","trusted":true,"collapsed":true},"cell_type":"code","source":"from keras.models import Sequential, Model, load_model\nfrom keras import applications\nfrom keras import optimizers\nfrom keras.layers import Dropout, Flatten, Dense\n\nimg_rows, img_cols, img_channel = 224, 224, 3\n\nbase_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a7b158cf-ed3e-6ebc-868f-acddcce92344","_uuid":"66ac6d9a62a27302b5e8da101eae0212f34498ff","trusted":true,"collapsed":true},"cell_type":"code","source":"add_model = Sequential()\nadd_model.add(Flatten(input_shape=base_model.output_shape[1:]))\nadd_model.add(Dense(256, activation='relu'))\nadd_model.add(Dense(1, activation='sigmoid'))\n\nmodel = Model(inputs=base_model.input, outputs=add_model(base_model.output))\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ecf8491d-cbba-505d-e5d8-fecaae32e35e","_uuid":"a1dd9a4439863363f4f0002b5946bca02719ad36","trusted":true,"collapsed":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\n\nbatch_size = 32\nepochs = 50\n\ntrain_datagen = ImageDataGenerator(\n        rotation_range=30, \n        width_shift_range=0.1,\n        height_shift_range=0.1, \n        horizontal_flip=True)\ntrain_datagen.fit(x_train)\n\n\nhistory = model.fit_generator(\n    train_datagen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=x_train.shape[0] // batch_size,\n    epochs=epochs,\n    validation_data=(x_test, y_test),\n    #,callbacks=[ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc', save_best_only=True)]\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb7ed4b7472227aee1ad391bec5b81ac21736a5e"},"cell_type":"markdown","source":"Added to plot history evolution:"},{"metadata":{"trusted":true,"_uuid":"7c7c02f37b2c82b5c3d578d66a335700aedf7550","collapsed":true},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a89754b89189c73f0a2f9f8f416ff70c94f92b67"},"cell_type":"code","source":"print(\"Training loss: {:.2f} / Validation loss: {:.2f}\".\\\n      format(history.history['loss'][-1], history.history['val_loss'][-1]))\nprint(\"Training accuracy: {:.2f}% / Validation accuracy: {:.2f}%\".\\\n      format(100*history.history['acc'][-1], 100*history.history['val_acc'][-1]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e0e5efc6-cf1a-32fb-5b2e-d1ea2b244a5d","_uuid":"5325191678391eac9996bcc0f66b729cd247fc5e"},"cell_type":"markdown","source":"## predict test data ##"},{"metadata":{"_cell_guid":"8c3ac15d-fb29-2531-cbe5-f763c35623a5","_uuid":"aa02c96ba9e2d60ee4ac5efcad3d41fb45b5570c","trusted":true,"collapsed":true},"cell_type":"code","source":"test_images = test_images.astype('float32')\ntest_images /= 255","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7740ecc9-98c6-c62b-f71e-69d8c34ed451","_uuid":"e4e696fa4d514ec65cee8ee213c3257fed06d69b","trusted":true,"collapsed":true},"cell_type":"code","source":"predictions = model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a90d25c4-6587-a574-27db-5af5e9ff17d3","_uuid":"bf211c275f1b210a7a1638c201c649fb5a71277b","trusted":true,"collapsed":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/invasive-species-monitoring/sample_submission.csv\")\n\nfor i, name in enumerate(test_names):\n    sample_submission.loc[sample_submission['name'] == name, 'invasive'] = predictions[i]\n\nsample_submission.to_csv(\"submit.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}