{"nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.4", "mimetype": "text/x-python", "file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python"}}, "nbformat_minor": 1, "cells": [{"cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "execution_count": null, "metadata": {"_uuid": "aae51e97ef03c4384526ba0eeb3d24aa23953161", "_cell_guid": "22c4fc8c-67b2-4b57-99aa-d0c65bfdd916"}, "outputs": []}, {"cell_type": "code", "source": ["# Function for filling the NaN values in the dataframe\n", "def transform_values(data):\n", "    data.fillna(value='missing', inplace = True)\n", "    return data"], "execution_count": null, "metadata": {"_uuid": "b3583176dc743359f3ddf830a412282f0baa7de4", "_cell_guid": "a8808b08-ec44-410b-b142-aaab5c1fed60", "collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["# Read the datafiles\n", "df_train = pd.read_csv('../input/train.tsv', sep='\\t') \n", "df_test = pd.read_csv('../input/test.tsv', sep='\\t')\n", "\n", "# Fill the NaN values with \"missing\"\n", "df_train = transform_values(df_train)\n", "df_test = transform_values(df_test)"], "execution_count": null, "metadata": {"_uuid": "4da942fb29c047b7b8848701f5766c1bc4a5e748", "_cell_guid": "c4ac516c-9d7d-4ae8-b74d-175cd1f8b23b", "collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["# Split the categories into a maincategory, subcategory 1 and subcategory 2\n", "def transform_category_name(category_name):\n", "    # If there is a category split it\n", "    try:\n", "        main, sub1, sub2= category_name.split('/')\n", "        return main, sub1, sub2\n", "    # Else return three times \"missing\"\n", "    except:\n", "        return 'missing', 'missing', 'missing'\n", "\n", "# Splitting the catorgy name, removing the 0 price items and fill in the missing descriptions with \"missing\"\n", "df_train['category_main'], df_train['category_sub1'], df_train['category_sub2'] = zip(*df_train['category_name'].apply(transform_category_name))\n", "df_train[df_train.price != 0.0]\n", "df_train[df_train.item_description != 'missing']\n", "\n", "df_test['category_main'], df_test['category_sub1'], df_test['category_sub2'] = zip(*df_test['category_name'].apply(transform_category_name))\n", "df_test[df_test.item_description != 'missing']"], "execution_count": null, "metadata": {"_uuid": "3953b60a83afe5922215479db0ce2e075b19cd6a", "_cell_guid": "dcaecb72-ad7b-4911-9277-d02bba1cf0bd"}, "outputs": []}, {"cell_type": "code", "source": ["# Name vectorizing with count vectorizer\n", "from sklearn.feature_extraction.text import CountVectorizer\n", "\n", "#Initizializing the countVectorizer\n", "cv = CountVectorizer(ngram_range=(1,2), min_df=7, stop_words='english')\n", "\n", "# Making X-vectors for the name, train and test\n", "X_name_train = cv.fit_transform(df_train['name'])\n", "X_name_test = cv.transform(df_test['name'])\n", "\n"], "execution_count": null, "metadata": {"_uuid": "a0a4762919a22e442da809a7411d7bedb2fef77f", "_cell_guid": "3da3643c-b963-4bc7-956c-5921e91569c6", "collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["# Categories vectorization\n", "cat_cv1 = CountVectorizer()\n", "cat_cv2 = CountVectorizer()\n", "cat_cv3 = CountVectorizer()\n", "\n", "# Vectorize the trainingscategories to count vectors\n", "X_catmain_train = cat_cv1.fit_transform(df_train['category_main'])\n", "X_catsub1_train = cat_cv2.fit_transform(df_train['category_sub1'])\n", "X_catsub2_train = cat_cv3.fit_transform(df_train['category_sub2'])\n", "\n", "# Vectorize the testcategories to count vectors\n", "X_catmain_test = cat_cv1.transform(df_test['category_main'])\n", "X_catsub1_test = cat_cv2.transform(df_test['category_sub1'])\n", "X_catsub2_test = cat_cv3.transform(df_test['category_sub2'])"], "execution_count": null, "metadata": {"_uuid": "7fd1aca883ed0b38d7e75004c14ac8e92df07de6", "_cell_guid": "bcb8399f-e740-4852-8159-a8fe6b00b1df", "collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["from sklearn.feature_extraction.text import TfidfVectorizer\n", "\n", "# create the vectorizer\n", "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=90000, strip_accents=\"ascii\",\n", "                             stop_words='english')\n", "# fit and transform the vectorizer for train\n", "X_description_train = vectorizer.fit_transform(df_train['item_description'])\n", "# fit and transform the vectorizer for test\n", "X_description_test = vectorizer.transform(df_test['item_description'])"], "execution_count": null, "metadata": {"_uuid": "6f4e69c88f3d7a9631470956cca360cf5aed4d85", "_cell_guid": "a4c6411b-5c80-4aae-b8ec-1aa6d9982ce4", "collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["from sklearn.preprocessing import LabelBinarizer\n", "#Brand name binary vectorization train and test set\n", "lb = LabelBinarizer()\n", "X_brand_train = lb.fit_transform(df_train['brand_name'])\n", "X_brand_test = lb.transform(df_test['brand_name'])"], "execution_count": null, "metadata": {"_uuid": "0ca10d4c4ec4bb69b4148c4b6a5cb72716ba4671", "_cell_guid": "f95ffb5d-20be-4b86-8467-7d1f5aa2b1c1", "collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["# Shipping and item state converge to dummies trainingsset\n", "X_shipping_train = pd.get_dummies(df_train['shipping'])\n", "X_condition_train = pd.get_dummies(df_train['item_condition_id'])\n", "\n", "# Shipping and item state converge to dummies testset\n", "X_shipping_test = pd.get_dummies(df_test['shipping'])\n", "X_condition_test = pd.get_dummies(df_test['item_condition_id'])"], "execution_count": null, "metadata": {"_uuid": "9c3ee58a2040ac0e2f1ab038b5d7b5728603f840", "_cell_guid": "2b24706f-6e08-4f3d-b9e6-019b05e6b7e3", "collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["from sklearn.model_selection import train_test_split\n", "from scipy.sparse import hstack\n", "\n", "# Stack all the vectorized data together, trainingsset\n", "vectorized_data_train = hstack((X_name_train, X_catmain_train, X_catsub1_train, X_catsub2_train, \n", "                            X_description_train, X_shipping_train, X_condition_train))\n", "\n", "# Stack all the vectorized data together, testset\n", "vectorized_data_test = hstack((X_name_test, X_catmain_test, X_catsub1_test, X_catsub2_test, \n", "                            X_description_test, X_shipping_test, X_condition_test))\n"], "execution_count": null, "metadata": {"_uuid": "a5b4a001d4258ddff94996005cd82df83417ea76", "_cell_guid": "b9ca87e3-9a32-4f8c-8122-9b46c2189108", "collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["from sklearn.linear_model import Ridge\n", "\n", "Y_train = np.log1p(df_train['price']) #log1p because is nice\n", "\n", "# Training the ridge algorithm on the trainingsset\n", "clf = Ridge(alpha=5.3, fit_intercept=True, normalize=False, \n", "      copy_X=True, max_iter=None, tol=0.01, solver='auto', random_state=None)\n", "clf.fit(vectorized_data_train, Y_train)\n", "\n", "Y_pred_test = clf.predict(vectorized_data_test)"], "execution_count": null, "metadata": {"_uuid": "ffff2114147934300b7ff6e05c2117936c539421", "_cell_guid": "df0dc3f8-1ad0-4ee3-9c9e-0ba302d9d9f6"}, "outputs": []}, {"cell_type": "code", "source": ["submission = pd.DataFrame(data=df_test[['test_id']])\n", "submission['price'] = np.expm1(Y_pred_test)\n", "submission.to_csv(\"submission_ridge.csv\", index=False)"], "execution_count": null, "metadata": {"_uuid": "aa1336820f01e474d11d8132bb8ceb4513d18ebc", "_cell_guid": "bc786ea5-8d5c-42e7-884a-c095272e0257", "collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["import math\n", "#A function to calculate Root Mean Squared Logarithmic Error (RMSLE)\n", "def rmsle(y, y_pred):\n", "    assert len(y) == len(y_pred)\n", "    terms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n", "    return (sum(terms_to_sum) * (1.0/len(y))) ** 0.5\n", "\n", "\n", "#print(rmsle(np.expm1(Y_train_v), np.expm1(Y_pred)))"], "execution_count": null, "metadata": {"_uuid": "f3e72bbe12f77065edb7bd08d8d36f1996d91bdc", "_cell_guid": "afacc796-989a-4f2b-8c41-fe2e6d659fb8", "collapsed": true}, "outputs": []}, {"cell_type": "markdown", "source": ["* alpha 5 = 0.45512\n", "* alpha 5.1 = 0.45513\n", "* alpha 5.2 = 0.45511\n", "* alpha 5.3 = 0.45510\n", "* alpha 5.4 = 0.45512\n", "* alpha 5.5 = 0.45511\n", "* alpha 0.5 = 0.461\n", "* alpha 0.6 = 0.460\n", "* alpha 15 = 0.458\n", "* alpha 100 = 0.481"], "metadata": {"_uuid": "9c6e28d9a2af656d12301919dd00c94bf36d9a00", "_cell_guid": "da1f02c0-1850-42f2-9989-8dc1411f0e1f", "collapsed": true}}]}