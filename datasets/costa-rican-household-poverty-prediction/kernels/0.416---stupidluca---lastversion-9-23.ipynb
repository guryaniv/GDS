{"cells":[{"metadata":{"_uuid":"7b1f3095609357fb2f2d6d0cec88ce6f7373a113"},"cell_type":"markdown","source":"**Introduction**\n"},{"metadata":{"_uuid":"7a81c1f5aef0273e7dc445d4bd9534f25fbceecd"},"cell_type":"markdown","source":"At first, I just tried kNN method training with the first column \"v2a1\" and the \"Target\" to predict. I got a lower score which is about 0.220 after submitting. In order to improve the score, the first thing I need to do is to deal with these missing data. Based on these, I tested different neighbour values of kNN method. However, the result was still not good enough. Therefore, I turn to seek different algorithms to cope with the task. Some algorithms truly have a big improvement, like the GradientBoosting and LightBGM. While, it is still hardly to reach 0.4 of the score. Inspired by the introduction of \"project 3\" that the part of \"Additional feature extraction\", I added some extra columns after analysising the data. These extra columns make a big improvement on the score, which is the main reason that I got a finally 0.432 score."},{"metadata":{"_uuid":"8e0b502e3364f2bfe771764f0af51767182c174e"},"cell_type":"markdown","source":"This notebook will be seperated into five parts. The first section is to deal with the missing data. After that, some extra columns could be joined in. In the third section, a few cluter analysis could be helpful. The different algothrims are tested and compared in the fourth section. Finally, some efforts that I did but not worked well will also be included."},{"metadata":{"trusted":true,"_uuid":"c7f1d5aee1e7e9e8aea8eba499c7074e3d5dda25"},"cell_type":"code","source":"import numpy as np # linear algebra\n\nimport pandas as pd\nfrom sklearn import neighbors\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import f1_score\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import manifold\n\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57206fedfa7587a1e9b9ac9c990907fe94aed7a8"},"cell_type":"code","source":"df = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nsample = pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b6a867043c1b039801320aaa3f94e0e393427b9"},"cell_type":"markdown","source":" **1. Missing Data**\n\nWe can see that there are five colums which miss some data."},{"metadata":{"trusted":true,"_uuid":"a81ed277966275c57595d23782fe3c61a9f05ff9"},"cell_type":"code","source":"total = df.isnull().sum().sort_values(ascending = False)\ntotal[total>0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4914c8de859e1972ad96d25bbce0f9c34ab92c7c"},"cell_type":"markdown","source":"**1.1   \"rez_esc\"**"},{"metadata":{"_uuid":"dac2718409e3c6b31efa30056349b77d55ec0028"},"cell_type":"markdown","source":"The \"rez_esc\" is the represents \"year behind the school\", missing value could be filled as 0.  "},{"metadata":{"trusted":true,"_uuid":"3d636af32a152ababe1a9bea87a65794500483d0"},"cell_type":"code","source":"df['rez_esc'] = df['rez_esc'].fillna(0)\ntest['rez_esc'] = test['rez_esc'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e9c8655337e7b2f5bbd62c2480c8645a9877f53"},"cell_type":"markdown","source":"**1.2 \"v18q1\"**\n"},{"metadata":{"_uuid":"37dff3da6dce240cfdcb6591fc9d2f80a7ae8859"},"cell_type":"markdown","source":"The \"v18q1\" means the \"number of tablets household owns\" which is also depends on \"v18q\". Through further analysis, for all the rows that the value of \"v18q1\" are missing, the values of \"v18q\" are '0'. Therefore, if the value of \"v18q\" is \"0\", we fill the value of \"v18q1\" with 0. Otherwise, keep it the original value."},{"metadata":{"trusted":true,"_uuid":"9d963c2f8ef41d51fbd7671386e27d1872f6ff78"},"cell_type":"code","source":"df[df['v18q1'].isnull()]['v18q'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c52ac6cf07ffecbbc592e9470c2a027f35dfe7bd"},"cell_type":"code","source":"def replace_v18q1(x):\n    if(x['v18q'] == 0):\n        return 0\n    else:\n        return x['v18q1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84105d2fab1a0b8c60c109ce5f4410eee8897e66"},"cell_type":"code","source":"df['v18q1'] = df.apply(lambda x: replace_v18q1(x), axis=1)\ntest['v18q1'] = test.apply(lambda x: replace_v18q1(x), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd63f882f744274132585913ba2adf63a0488124"},"cell_type":"markdown","source":"**1.3 \"v2a1\"**"},{"metadata":{"_uuid":"a758d41672a9c21cbee5cfbfbefb9436f7d214f0"},"cell_type":"markdown","source":"The column \"v2a1\" means the \"Monthly rent payment\". For more details, the reason why some values of this column is missing is that some head own the house and they do not need to pay the rent. The column \"tipovivi3\" proves this that the value of \"tipovivi3\" is \"0\" which means the house is not rented. Thus, we can replaced these values with \"0\"."},{"metadata":{"trusted":true,"_uuid":"d843f9d2d35646f56da2e62c216020e1f8333aef"},"cell_type":"code","source":"df[df['v2a1'].isnull()]['tipovivi3'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c29e7c22d8167872cf7c28cdb01f7244298126f3"},"cell_type":"code","source":"df['v2a1'] = df['v2a1'].fillna(0)\ntest['v2a1'] = test['v2a1'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfca788385a8728ac143e40e3b0eb52fbb62ed16"},"cell_type":"markdown","source":"* **1.4 \"meaneduc\" and \"SQBmeaned\"****"},{"metadata":{"_uuid":"a12813704c3ce440d6793319233fb58055f8c5fc"},"cell_type":"markdown","source":"As there were littile missing values for these columns, I just filled them with \"0\"."},{"metadata":{"trusted":true,"_uuid":"a73aea1849ba15b0355581534ffc329aa44b545b"},"cell_type":"code","source":"df['meaneduc'] = df['meaneduc'].fillna(0)\ntest['SQBmeaned'] = test['SQBmeaned'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"212ce303898b79324fb94d8bd0c1536c2fe12ecf"},"cell_type":"markdown","source":"**1.5 \"yes\" and \"no\"**"},{"metadata":{"_uuid":"c543140cce8e6d29785dbbd867c667e8e332d199"},"cell_type":"markdown","source":"Some values of columns is not number, which are \"yes\" and \"no\". We can replace them number that \"1\" means \"yes\" and \"0\" means \"no\"."},{"metadata":{"trusted":true,"_uuid":"44ed38e7ad0fb2b6e7f63121444808a186a98a75"},"cell_type":"code","source":"df['edjefe'] = df['edjefe'].replace({'no': 0, 'yes':1}).astype(float)\ntest['edjefe'] = test['edjefe'].replace({'no': 0, 'yes':1}).astype(float)\ndf['edjefa'] = df['edjefa'].replace({'no': 0, 'yes':1}).astype(float)\ntest['edjefa'] = test['edjefa'].replace({'no': 0, 'yes':1}).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0ebf29954ae7059e1597b2299e11db7707b6d35"},"cell_type":"markdown","source":"**1.6 \"dependency\"**"},{"metadata":{"_uuid":"7c4bff9b6f1118d84db472b9942ce902de1c80fd"},"cell_type":"markdown","source":"The value of \"SQBdependency\" is the squar of the column \"dependency\". Thus, we can use the square root value of \"SQBdependency\" to replace the values of \"dependency\"."},{"metadata":{"trusted":true,"_uuid":"ae7c7e9735cc02439f3ea29356d508d8c3960e7c"},"cell_type":"code","source":"df['dependency']=np.sqrt(df['SQBdependency'])\ntest['dependency']=np.sqrt(test['SQBdependency'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"252762e40992a3c2c6cbc39758c8d8645c2a9e32"},"cell_type":"markdown","source":"**2. Extra columns**"},{"metadata":{"_uuid":"2ca73aced319df4b4401dc03341413cc0bf4c00e"},"cell_type":"markdown","source":"There are more than one hundred columns which includes the many areas about the household, like ages, rent and rooms. As known, it is the adult who make money and make a living. And the the children and adult over 65 do not work. Thus, I would like to add some columns about the adults, which may be better for the predict. The rents for one house may be bias, but the average rent for adult should be more balance. For the same reason, the column of average rooms should be added."},{"metadata":{"trusted":true,"_uuid":"db69705e1e47619f91b471692a3cb899ee5f8cfb"},"cell_type":"code","source":"df['adult_num'] = df['hogar_adul'] - df['hogar_mayor']\ndf['adult_rate'] = df['adult_num'] / df['hogar_total']\ndf['dependency_num'] = df['hogar_nin'] + df['hogar_mayor']\ndf['dependency_rate'] = df['dependency_num'] / df['hogar_total']\ndf['adult_dependency_rate'] = df['adult_num'] / (df['dependency_num']+0.1)\ndf['children_rate'] = df['hogar_nin'] / df['hogar_total']\ndf['elder_rate'] = df['hogar_mayor'] / df['hogar_total']\n\ndf['rent_per_person'] = df['v2a1'] / df['hogar_total']\ndf['rent_per_adult'] = df['v2a1'] / (df['adult_num']+0.1)\n\ndf['head_is_adult'] = (df['adult_num'] > 0).astype(int)\n\ndf['bedroom_per_person'] = df['bedrooms'] / df['hogar_total']\ndf['bedroom_per_adult'] = df['bedrooms'] / (df['adult_num']+0.1)\n\ndf['rent_per_room'] = df['v2a1'] / df['rooms']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3dccc53876fd74ce87df5e946838624491b00a8"},"cell_type":"code","source":"test['adult_num'] = test['hogar_adul'] - test['hogar_mayor']\ntest['adult_rate'] = test['adult_num'] / test['hogar_total']\ntest['dependency_num'] = test['hogar_nin'] + test['hogar_mayor']\ntest['dependency_rate'] = test['dependency_num'] / test['hogar_total']\ntest['adult_dependency_rate'] = test['adult_num'] / (test['dependency_num']+0.1)\ntest['children_rate'] = test['hogar_nin'] / test['hogar_total']\ntest['elder_rate'] = test['hogar_mayor'] / test['hogar_total']\n\ntest['rent_per_person'] = test['v2a1'] / test['hogar_total']\ntest['rent_per_adult'] = test['v2a1'] / (test['adult_num']+0.1)\n\ntest['head_is_adult'] = (test['adult_num'] > 0).astype(int)\n\ntest['bedroom_per_person'] = test['bedrooms'] / test['hogar_total']\ntest['bedroom_per_adult'] = test['bedrooms'] / (test['adult_num']+0.1)\n\ntest['rent_per_room'] = test['v2a1'] / test['rooms']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be00a7494c5611d5f13e447491ca6deb3990f1e2"},"cell_type":"markdown","source":"**3. Cluster Analysis**"},{"metadata":{"_uuid":"46126926d1811d6f3106d69c41146c4c0b4b22b6"},"cell_type":"markdown","source":"There are more than one hundred columns in this data. In order to visualize, we need to use some algorithms to reduce the dimension. Manifold Learning is such an approach to achieve this. In the package \"Manifold\" there are many different metods to do this. In this notebook, I choose two methods  which are \"Multi-dimensional Scaling (MDS)\" and \"t-distributed Stochastic Neighbor Embedding (t-SNE)\". (http://scikit-learn.org/stable/modules/manifold.html#introduction)"},{"metadata":{"trusted":true,"_uuid":"53ea382c11de9995526dff9ab32dc6aefd2bc74b"},"cell_type":"code","source":"X = df.drop(['Id', 'idhogar', 'Target'], axis=1).fillna(0)\ny = df.Target\n\ntest_X = test.drop(['Id', 'idhogar'], axis=1).fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51e0655055d595780d719db1aac901bd542d5000"},"cell_type":"markdown","source":"**3.1  Multi-dimensional Scaling (MDS)**"},{"metadata":{"trusted":true,"_uuid":"e733484e52c2522d944c2009b567d308e005361c"},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n\nX_ss = pd.DataFrame(StandardScaler().fit(X).transform(X), columns=X.columns)\n\nmds = manifold.MDS(2, max_iter=100, n_init=1);\ntrans_data = mds.fit_transform(X_ss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15f92f3eace3965015c97d1497eb9003013fa547"},"cell_type":"code","source":"y_ = df.Target -1\ncolors = ['r','g','y','c']\n\n# for j, X_ in trans_data.items():\nplt.figure(figsize=(6,4))\nfor i in [0,1,2,3]:\n    plt.scatter(trans_data[y_==i,0], trans_data[y_==i,1], c=colors[i], s=5, label=i+1)\nplt.legend()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12ac3fbf126104e3fa26ac95c415b3e76b82d7d5"},"cell_type":"markdown","source":"**3.2 t-distributed Stochastic Neighbor Embedding (t-SNE)**"},{"metadata":{"trusted":true,"_uuid":"1ca2e7a98dbb448ccf6134ff2fb7aaaf8f021638"},"cell_type":"code","source":"tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\ntrans_data = tsne.fit_transform(X_ss)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75471a9f898205a87d185bf7376614eef0002232"},"cell_type":"code","source":"# for j, X_ in trans_data.items():\nplt.figure(figsize=(6,4))\nfor i in [0,1,2,3]:\n    plt.scatter(trans_data[y_==i,0], trans_data[y_==i,1], c=colors[i], s=5, label=i+1)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02d8c07a1a697794612a4eb348c54e36c48f6a1d"},"cell_type":"markdown","source":"It can be seen that both the methods display that the Target 4, which means the \"non vulnerable households\" household, could be seperated from other 3 Targets. While, the other 3 Targets are difficult to be isolated from each other."},{"metadata":{"_uuid":"7eb82f84560fcefaf3c487fa346e20c9818e65aa"},"cell_type":"markdown","source":"**4. Algorithms**"},{"metadata":{"trusted":true,"_uuid":"53241f25ae22e4f68c49d0778b3e727f33ffc146"},"cell_type":"markdown","source":"In order to improve the score of this task, most of algorithms in the package \"scikit\" were tested, as well as some boosting algorithms. (http://scikit-learn.org/stable/supervised_learning.html#supervised-learning)\n"},{"metadata":{"trusted":true,"_uuid":"a05b9d3bed57d6a84deec5f2e6b131b04b4419cb"},"cell_type":"markdown","source":"**4.1. KNN** "},{"metadata":{"_uuid":"e8d33a1014ebea043d23e5ff40fd6cf24376b057"},"cell_type":"markdown","source":"For the kNN algorithm, I tested it with different values of neighbours."},{"metadata":{"trusted":true,"_uuid":"37a4a9ed210121852468c78908fbe3bbf72bd693"},"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29a09cc7c22b26adf76d6cdaa388d1c77dbf00dc"},"cell_type":"code","source":"scores_knn_distance = pd.DataFrame(columns=['neighbours','score'])\nfor i_ in range(3,20):\n    clf_knn = neighbors.KNeighborsClassifier(n_neighbors=i_, weights=\"distance\")\n    model_knn = clf_knn.fit(X_train,y_train)\n\n    score = f1_score(y_test, model_knn.predict(X_test), average = 'macro')\n    scores_knn_distance = scores_knn_distance.append({'neighbours':i_,'score':score},ignore_index=True)\n    print('distance, neighbours=',i_,', f1_score=',score.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9b22bb53a2530be597fb4b68004e13df5b798d4"},"cell_type":"code","source":"scores_knn_uniform = pd.DataFrame(columns=['neighbours','score'])\nfor i_ in range(3,20):\n    clf_knn = neighbors.KNeighborsClassifier(n_neighbors=i_, weights=\"uniform\")\n    model_knn = clf_knn.fit(X_train,y_train)\n\n    score = f1_score(y_test, model_knn.predict(X_test), average = 'macro')\n    scores_knn_uniform = scores_knn_uniform.append({'neighbours':i_,'score':score},ignore_index=True)\n    print('uniform, neighbours=',i_,', f1_score=',score.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65d3b006cce50f4a1c8586a67746853387c2b263"},"cell_type":"code","source":"scores_knn_distance.plot(kind='line',x='neighbours', y='score')\nplt.ylabel('f1_score')\nplt.xlabel('number of neighbours')\nplt.title(\"the score of neighbours for distance\")\n\nscores_knn_uniform.plot(kind='line',x='neighbours', y='score')\nplt.ylabel('f1_score')\nplt.xlabel('number of neighbours')\nplt.title(\"the score of neighbours for uniform\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"129bcbf6f51b4f37ba7291f73395d457bda343ab"},"cell_type":"markdown","source":"It can be seen that for the \"distance\" weights, as the number of neighbours increases, the score improves until 10 which is the peak. After that, the \"f1_score\" descrease as the increase of number. While, for the \"uniform\" weights, the best score is reached when the number of neighbours is 4, and it keeps decreasing after this."},{"metadata":{"_uuid":"67d539710c1b0302a0025fe1d82942ac27a07aae"},"cell_type":"markdown","source":"**4.2 SVM**"},{"metadata":{"trusted":true,"_uuid":"e4891751f044ee058613a4b0e7688dc6aa922845"},"cell_type":"code","source":"from sklearn import svm\nclf_svm = svm.SVC(gamma='auto')\nmodel_svm = clf_svm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68005c7a850bad1b75e01f3d8df258b3e6768ffd"},"cell_type":"code","source":"scores_svm = f1_score(y_test, model_svm.predict(X_test), average = 'macro')\nprint('svm, f1_score=',scores_svm.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29b5938ee65aeb0ca5734bdf0ebb7bec765faeee"},"cell_type":"markdown","source":"**4.3 SGD**"},{"metadata":{"trusted":true,"_uuid":"5fa500911963dc118452aa383022c81df32dd66d"},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\n\nclf_sgd = SGDClassifier(loss=\"hinge\", penalty=\"l1\", \n                    alpha=0.01, max_iter=200, fit_intercept=True)\nmodel_sgd = clf_sgd.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4a51433f2eb302ce2a034c76f39d4c13b133e38"},"cell_type":"code","source":"scores_sgd = f1_score(y_test, model_sgd.predict(X_test), average = 'macro')\nprint('sgd, f1_score=',scores_sgd.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9cfcc3db5c32d83b896163ff13a9fada721ac61"},"cell_type":"markdown","source":"**4.4 Neural network**"},{"metadata":{"trusted":true,"_uuid":"002946e17ac67a27a4efa38e902d321d3d8e82ea"},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nclf_mlp = MLPClassifier(hidden_layer_sizes=(12,), random_state=1, max_iter=1000, warm_start=True)\nmodel_mlp = clf_mlp.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd97f422f6a1594ede33beb603d001f5f687c745"},"cell_type":"code","source":"scores_mlp = f1_score(y_test, model_mlp.predict(X_test), average = 'macro')\nprint('mlp f1_score=',scores_mlp.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3d79948e18469095fcbf47e0ce64caaecdfaca5"},"cell_type":"markdown","source":"**4.5 Adaboosting**"},{"metadata":{"trusted":true,"_uuid":"81e2b259050b2654ef2249693c461bc024d6971f"},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nclf_ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5, min_samples_split=30, min_samples_leaf=30),\n                         algorithm=\"SAMME.R\",n_estimators=500, learning_rate=1)\nmodel_ada = clf_ada.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4875904924945080ddbe33b44c6e7a11bb80865c"},"cell_type":"code","source":"scores_ada = f1_score(y_test, model_ada.predict(X_test), average = 'macro')\nprint('adaboosting f1_score=',scores_ada.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1500692258aab4458aec40a030b9efb2760a40fc"},"cell_type":"markdown","source":"**4.6 Voting**"},{"metadata":{"trusted":true,"_uuid":"e4846dc49b92e087f3b9950adcc4ff9df34f8178"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\n\nclf1 = LogisticRegression(random_state=1)\nclf2 = RandomForestClassifier(random_state=1)\nclf3 = GaussianNB()\n\neclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n\nclf1 = clf1.fit(X_train,y_train)\nclf2 = clf2.fit(X_train,y_train)\nclf3 = clf3.fit(X_train,y_train)\nmodel_voting = eclf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68b7a70117b0789faab11cf009ab0167c037c5f0"},"cell_type":"code","source":"scores_voting = f1_score(y_test, model_voting.predict(X_test), average = 'macro')\nprint('voting, f1_score=',scores_voting.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2390cc8bb962bba766ad0788640a551e1ab3b742"},"cell_type":"markdown","source":"**4.7 GradientBoosting** "},{"metadata":{"trusted":true,"_uuid":"d582997f6b8df44573e10b2eecbdcb0a229ec935"},"cell_type":"code","source":"clf_gradient = GradientBoostingClassifier(n_estimators=800, learning_rate=0.5, \n                                 max_depth=3, random_state=8)\nmodel_gradient = clf_gradient.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6f65389ea0b1299ad4d320e123bc76c86be550a1"},"cell_type":"code","source":"scores_gradient = f1_score(y_test, model_gradient.predict(X_test), average = 'macro')\nprint('GradientBoosting f1_score=',scores_gradient.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0e058fa868f1eb1f34a64038acb7b415038ee00"},"cell_type":"markdown","source":"**4.8 XGBoosting**"},{"metadata":{"trusted":true,"_uuid":"112e230158bfa57cba7bf9d9db8badce61d3df18"},"cell_type":"code","source":"from xgboost import XGBClassifier\nclf_xgb = XGBClassifier(max_depth=4,booster='dart',\n                           min_child_weight=1,\n                           learning_rate=0.01,\n                           n_estimators=500,\n                           silent=True,\n                           objective='multi:softprob',\n                           gamma=0,\n                           max_delta_step=0,\n                           subsample=0.9,\n                           colsample_bytree=0.9,\n                           colsample_bylevel=1,\n                           reg_alpha=0,\n                           reg_lambda=0,\n                           scale_pos_weight=1,\n                           seed=0,\n                           missing=None)\nmodel_xgb = clf_xgb.fit(X_train, y_train, eval_metric='mlogloss', verbose=100,\n            eval_set=[(X_test, y_test)], early_stopping_rounds=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de486ef3a3f0ed42d2e35bb8716bb3876ddf6fa1"},"cell_type":"code","source":"scores_xgb = f1_score(y_test, model_xgb.predict(X_test), average = 'macro')\nprint('xgb f1_score=',scores_xgb.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be34ccb0e3f56e1cdcc763499ab9ff641d868409"},"cell_type":"markdown","source":"**4.9 LGBMClassifier**"},{"metadata":{"trusted":true,"_uuid":"f130776a8bea940bc6087836c7069a4da5d5282a"},"cell_type":"code","source":"clf_lgbm = lgb.LGBMClassifier(class_weight='balanced', boosting_type='dart',\n                         drop_rate=0.9, min_data_in_leaf=100, \n                         max_bin=255,\n                         n_estimators=500,\n                         bagging_fraction=0.01,\n                         min_sum_hessian_in_leaf=1,\n                         importance_type='gain',\n                         learning_rate=0.1, \n                         max_depth=-1, \n                         num_leaves=31)\nmodel_lgbm = clf_lgbm.fit(X_train, y_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"779ff6716795c1df4bb1c0f4bb982d45c23a3668"},"cell_type":"code","source":"scores_lgbm = f1_score(y_test, model_lgbm.predict(X_test), average = 'macro')\nprint('lgbm f1_score=',scores_lgbm.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4117b38ddabbfef028c0f9f4abf6f23cbc774c7f"},"cell_type":"markdown","source":"**4.10 Compare**"},{"metadata":{"trusted":true,"_uuid":"4eff7cac882bab3782ab6cdef524feb86d5c34f1"},"cell_type":"code","source":"scores_algorithm = pd.DataFrame(columns=['scores'])\nscores_algorithm.loc['kNN_distance'] = scores_knn_distance[scores_knn_distance.neighbours==10].score.values\nscores_algorithm.loc['kNN_uniform'] = scores_knn_distance[scores_knn_uniform.neighbours==4].score.values\nscores_algorithm.loc['SVM'] = scores_svm\nscores_algorithm.loc['SGD'] = scores_sgd\nscores_algorithm.loc['Neural Network'] = scores_mlp\nscores_algorithm.loc['AdaBoosting'] = scores_ada\nscores_algorithm.loc['voting'] = scores_voting\nscores_algorithm.loc['GradientBoosting'] = scores_gradient\nscores_algorithm.loc['XGBoosting'] = scores_xgb\nscores_algorithm.loc['LGBM'] = scores_lgbm\n\nscores_algorithm.plot(kind='bar', use_index=True, y='scores')\nplt.ylabel(\"f1_score\")\nplt.title(\"The f1_score of different algorithms\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2366bf967129eb05cc15774736ade40ea0de4772"},"cell_type":"markdown","source":"It is easily to be seen from the chart that the \"GradientBoosting\" performs the best score in the test. The other algorithms, which are \"Adaboosting\", \"voting\", \"XGBoosting\" and \"LGBM\", also show a better \"f1_score\" than the \"kNN\" methods. While, the \"SVM\", \"SGD\" and \"Neural Network\"  got a lower score than the \"kNN\" methods."},{"metadata":{"_uuid":"56b8afc15c6cbb41b94afbbf75172514aa7e6855"},"cell_type":"markdown","source":"**4.11 Submission**"},{"metadata":{"trusted":true,"_uuid":"ea48e4509e6a7c6b8ffa4f31edf611eea5c5eeee"},"cell_type":"code","source":"# knn distance 10 neighbours 0.293\nclf_knn_distance = neighbors.KNeighborsClassifier(n_neighbors=10, weights=\"distance\")\nmodel_knn_distance = clf_knn_distance.fit(X_train,y_train)\n\ntest['Target'] = model_knn_distance.predict(test_X)\n    \nresult = test[['Id','Target']]\nresult.to_csv(\"result_kNN_10_distance.csv\",index=False,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3aae2b930d8c604d7987757b94f3227b9f6a8139"},"cell_type":"code","source":"# knn uniform 4 neighbours 0.310\nclf_knn_uniform = neighbors.KNeighborsClassifier(n_neighbors=4, weights=\"uniform\")\nmodel_knn_uniform = clf_knn_uniform.fit(X_train,y_train)\n\ntest['Target'] = model_knn_uniform.predict(test_X)\n    \nresult = test[['Id','Target']]\nresult.to_csv(\"result_kNN_4_uniform.csv\",index=False,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c81e5e66a829e8fa05374cd0d10377e40addd52"},"cell_type":"code","source":"# svm 0.209\ntest['Target'] = model_svm.predict(test_X)\n    \nresult = test[['Id','Target']]\nresult.to_csv(\"result_svm.csv\",index=False,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83ba60928b13fa8e61223df4afbd430f185f02f7"},"cell_type":"code","source":"# sgd 0.310\ntest['Target'] = model_sgd.predict(test_X)\n    \nresult = test[['Id','Target']]\nresult.to_csv(\"result_sgd.csv\",index=False,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6df92e67e1e441fbd852cc25e11d351b6b9284e"},"cell_type":"code","source":"# neural network 0.346\ntest['Target'] = model_mlp.predict(test_X)\n    \nresult = test[['Id','Target']]\nresult.to_csv(\"result_neural_network.csv\",index=False,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"039e092b66848068038e15f3cee7a61e96267e20"},"cell_type":"code","source":"# Adaboosting 0.376\ntest['Target'] = model_ada.predict(test_X)\n    \nresult = test[['Id','Target']]\nresult.to_csv(\"result_adaboosting.csv\",index=False,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12a2deb8f350247f98f0cb5ce0fdfcf3b964eb1a"},"cell_type":"code","source":"# voting 0.379\ntest['Target'] = model_voting.predict(test_X)\n    \nresult = test[['Id','Target']]\nresult.to_csv(\"result_voting.csv\",index=False,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f48828c35636b2955870b0263098fae9d25ef74"},"cell_type":"code","source":"# gradient boosting 0.387\ntest['Target'] = model_gradient.predict(test_X)\n    \nresult = test[['Id','Target']]\nresult.to_csv(\"result_gradientboosting.csv\",index=False,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2388b211397ad0f50e8924466557c82bafca4b93"},"cell_type":"code","source":"# XGBoosting 0.342\ntest['Target'] = model_xgb.predict(test_X)\n    \nresult = test[['Id','Target']]\nresult.to_csv(\"result_XGboosting.csv\",index=False,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4094e1927646963e22d96db329725825c1a3a87"},"cell_type":"code","source":"# LGBM 0.416\ntest['Target'] = model_lgbm.predict(test_X)\n    \nresult = test[['Id','Target']]\nresult.to_csv(\"result_LGBM.csv\",index=False,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c56392057c46d8f3bb19326660f939401ebf6a4a"},"cell_type":"markdown","source":"**4.12 Result**"},{"metadata":{"_uuid":"6bd41fbeddc4294d095f57be2a71fe26a8f8a91e"},"cell_type":"markdown","source":"After submit and competion, I got the real score about each algorithms."},{"metadata":{"trusted":true,"_uuid":"748222c315dc2caadc3523f16c6a78509d39a75d"},"cell_type":"code","source":"score_result = pd.DataFrame(columns=['score'])\n\nscore_result.loc['kNN_distance'] = 0.293\nscore_result.loc['kNN_uniform'] = 0.310\nscore_result.loc['SVM'] = 0.209\nscore_result.loc['SGD'] = 0.310\nscore_result.loc['Neural Network'] = 0.346\nscore_result.loc['AdaBoosting'] = 0.376\nscore_result.loc['voting'] = 0.379\nscore_result.loc['GradientBoosting'] = 0.387\nscore_result.loc['XGBoosting'] = 0.342\nscore_result.loc['LGBM'] = 0.416\n\nscore_result.plot(kind='bar', y='score')\nplt.ylabel(\"f1_score\")\nplt.title(\"The f1_score from the kaggle for different algorithms\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b573fe76c8acb60f94846f9cd3fa05a5ba2dd274"},"cell_type":"markdown","source":"Obviously, the \"LGBM\" got the highest score in this task, which reaches 0.416. "},{"metadata":{"_uuid":"8f6ea48abf7523ca8cdb128e72761648704fbb37"},"cell_type":"markdown","source":"**4.13 Only Head Data**"},{"metadata":{"_uuid":"5a5c852be3ff9511845407863816de5003d399cc"},"cell_type":"markdown","source":"According to the rules that only the head of the house will be calculated. Thus, what if we trained with the data only including the head? Let's see whether we could improve the \"f1_score\". (I only trained other methods with head data, but not show in this notebook. In addition, the \"LGBM\" still got the highest score.)"},{"metadata":{"trusted":true,"_uuid":"a58702aa10c80feffc8daf7d434f8cb647b16be4"},"cell_type":"code","source":"df_head = df[df.parentesco1==1]\nX_head = df_head.drop(['Id', 'idhogar', 'Target'], axis=1).fillna(0)\ny_head = df_head.Target\nmodel_lgbm_final = clf_lgbm.fit(X_head,y_head)\n\ntest['Target'] = model_lgbm.predict(test_X)\n\nresult = test[['Id','Target']]\nresult.to_csv(\"result_LGBM_final.csv\",index=False,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30797baa83e06e1c3fb5e64076715c01712b6510"},"cell_type":"markdown","source":"After I submitted, the score really improved that got a 0.432 which is the highest score I got so far."},{"metadata":{"trusted":true,"_uuid":"0e36d8c78b9821261661e8bb8ae4fa4b89fa1276"},"cell_type":"markdown","source":"**5. Other failed works**"},{"metadata":{"_uuid":"cc86e82acc3c0070181517a1a41bd50584d31bb4"},"cell_type":"markdown","source":"Indeed, after the first time I trying to train with only the first column 'v2a1', I used the method df.corr() to find some other columns which have closer relation with the \"Target\". I trained with these columns which the corr > 0.2 or corr < -0.2. It show a better performance than only column 'v2a1'. However, it did not got a better score by comparing to trained with all columns."},{"metadata":{"trusted":true,"_uuid":"01271fb05efb9b2b7ace42f5978adfdd8542a084"},"cell_type":"code","source":"df_corr_target = df.corr()['Target']\nprint(df_corr_target[df_corr_target>0.2])\nprint(df_corr_target[df_corr_target<-0.2])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c33bdf6045d819882ce36c14111e02408e1cf8a"},"cell_type":"markdown","source":"The other parameters I tried with LGBM is the \"early_stopping_rounds\". Unfortunately, it did not work on this task, which got only 0.416 score."},{"metadata":{"trusted":true,"_uuid":"a22e5b58ace6be8c6472dc1bf6998898bac67511"},"cell_type":"code","source":"model_lgbm_test = clf_lgbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], \n            early_stopping_rounds=20, verbose=100)\n\ntest['Target'] = model_lgbm_test.predict(test_X)\n\nresult = test[['Id','Target']]\nresult.to_csv(\"result_LGBM_test.csv\",index=False,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c25a55ab996b7dd3f29f90f9c1a6e6040c29815"},"cell_type":"markdown","source":"**Conclusion**"},{"metadata":{"_uuid":"cdfb6303a7b51bfbabb804728f2f05538d38a931"},"cell_type":"markdown","source":"The process of missing data is important. Some extra columns joined in make a big improvement in this task. The algorithms LGBM perform best in this task so far."},{"metadata":{"trusted":true,"_uuid":"10f789d96e1321c0cb4eaac0204b90ded774995f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}