{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nfrom keras.preprocessing.sequence import pad_sequences\n\nprint(os.listdir(\"../input\"))\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nfrom keras.layers import Conv1D,MaxPooling1D,Dense,Flatten,Dropout,Input,Concatenate\nfrom keras.models import Sequential,Model,load_model\nfrom keras.layers.core import Reshape\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,LearningRateScheduler,EarlyStopping\n\n\nimport keras\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"X_train = pd.read_json(\"../input/train.json\")\nX_test = pd.read_json(\"../input/test.json\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a0bb830d1efc0c0a01f7a63f4495e637157e131"},"cell_type":"code","source":"#X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f797a7c43b1ab52f83e5f2f52cff69a0fe90c25a"},"cell_type":"code","source":"Y_train = X_train['cuisine']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca9230f796936d99c1f1befbe21fa34ed9a1407e"},"cell_type":"code","source":"le = LabelEncoder()\nY_train = le.fit_transform(Y_train)\nY_train = keras.utils.to_categorical(Y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"582158e2baf03c0f699dd1f60407ef28c0782322"},"cell_type":"code","source":"def generate_text(data):\n    ingredients = data['ingredients']\n    text_data = list()\n    for doc in ingredients:\n        str_arr = list()\n        for s in doc:\n            str_arr.append(s.replace(' ', ''))\n        text_data.append(\" \".join(str_arr).lower())\n    # text_data = [\" \".join(doc).lower() for doc in ingredients]\n    return text_data\n\nX_train_text = generate_text(X_train)\nX_test_text = generate_text(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59042b167317bae2e7a83d761e07a00e86263aec"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncount_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(X_train_text)\nX_test_counts = count_vect.transform(X_test_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"beffc294c9e831de5ad591928f9ef7dab25d1c1b"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\ntf_transformer = TfidfTransformer(use_idf=False)\nX_train_tf = tf_transformer.fit_transform(X_train_counts)\n\n#X_train_tf = np.expand_dims(X_train_tf, axis=2) # reshape (569, 30) to (569, 30, 1) \n#np.reshape(X_train_tf, ( X_train_tf.shape[0], X_train_tf.shape[1],1))\nX_train_tf = X_train_tf.reshape((X_train_tf.shape[0], X_train_tf.shape[1],1))\n#b = np.zeros((X_train_tf.shape[0], X_train_tf.shape[1], X_train_tf.max() + 1))\n\n\n\nprint(X_train_tf[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8a41e97824097c0ba52964ce470a33dc224ad8f"},"cell_type":"code","source":"X_test_df  = tf_transformer.transform(X_test_counts)\nX_test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0d6fd7e723cab698e1b0bcaefb52e11f61c382f"},"cell_type":"code","source":"inp = Input(shape=(6782,), dtype='float32')\nreshape = Reshape(target_shape=(6782,1))(inp)\n\nconc=[]\nnormal = BatchNormalization()(reshape)\nconv = Conv1D(128, 3, padding='same', activation='relu', strides=1)(normal)\ndrop = Dropout(0.75)(conv)\nconc.append(drop)\n\n\nnormal1 = BatchNormalization()(drop)\nconv1 = Conv1D(128, 4, padding='same', activation='relu', strides=1)(normal1)\ndrop1 = Dropout(0.75)(conv1)\n\n\nconc.append(drop1)\n    \n    \n\nconcatenate = Concatenate()(conc)\nflatten = Flatten()(concatenate)\ndrop = Dropout(0.75)(flatten)\noutp = Dense(20, activation='softmax')(drop)\n\nmodel = Model(inputs=inp, outputs=outp)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0913fba90c85426bf4fcf115b52095a9e37b406c"},"cell_type":"code","source":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\nlr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=1e-5, patience=2, verbose=1)\n\n\nhistory = model.fit(X_train_tf, Y_train, epochs=15, callbacks=[annealer,lr_reduce],batch_size=128, validation_split=0.1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48e64c4392bff4868f6b435bec2463d59d914cb2"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint(history.history.keys())\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"769d3e6b356efcca4b3599c1634312f6d3db54af"},"cell_type":"code","source":"y_test = model.predict(X_test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87aeb8bd7473e978a487df627a29b21140e9ac66"},"cell_type":"code","source":"y_predict = le.inverse_transform([np.argmax(pred) for pred in y_test])\ny_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79308c312884d97a79d1b4d898003e0159dcfd0e"},"cell_type":"code","source":"test_id = [doc for doc in X_test['id']]\nsub = pd.DataFrame({'id': test_id, 'cuisine': y_predict}, columns=['id', 'cuisine'])\nsub.to_csv('output.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d319fa5c8c80e0bf9f77bbbda0c195aef3f8e791"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}