{"cells": [{"cell_type": "markdown", "source": ["<h1>OVERVIEW</h1>\n", "<p>Recruit Holdings owns Hot Pepper Gourmet (a restaurant review service), AirREGI (a restaurant point of sales service) and Restaurant Board (reservation log management software).</p>\n", "<p>Recruit Holdings wants to expand its service offering by providing a prediction of the number of visitors for individual restaurant. Restaurants can benefit from the accuracy of ordering supplies and proper staffing decisions. For Recruit Holdings it means higher customer retention rate and improving competitive advantage.</p>\n", "<p>We are pleased to propose Data analysis solution to support Recruit Holdings in achieving its goals.</p>\n", "<h1>THE SOLUTION</h1>\n", "<p>Data analysis solution comprises of the following steps:</p>\n", "<h2>Cleaning and preparing data</h2>\n", "<ul>\n", "<li>Choosing required data set.</li>\n", "<li>Removing outliers (number of visitors that are unusually high and could be due to one-time event or technical issue)</li>\n", "<li>Analyzing and filling in missed data with values which are the most possible for a particular restaurant. We have filled in missing data based on the following assumption: number of visitors to each restaurant for each day is equals to the average number of visitors to restaurants in the same area and with the same genre. This number should be adjusted to the size of the restaurant, which we define as the average number of visitors to that restaurant.</li>\n", "</ul>\n", "<h2>Data analysis includes</h2>\n", "<ul>\n", "<li><i>Simple and straightforward method</i>, which could be implemented by the on-site expertise. This simple method is based on the following algorithm: A number of visitors on prediction day will be equal to the average number of visitors on the same day of the week during the last year. If prediction day is a holiday, the number is equal to the average number of visitors on the holidays during last year.</li>\n", "<li><i>Advanced method</i>, which requires utilization of 3rd party library and possible future 3rd party technical support. For an advanced method, we considered [Prophet](https://research.fb.com/prophet-forecasting-at-scale/method) as the more suitable approach to the required task. This is set of the open-source pieces of software developed by [Facebook's Core Data Science team.](https://research.fb.com/category/data-science)</li>\n", "<li>Comparing accuracy estimate for both methods</li>\n", "</ul>\n", "<h1>CONCLUSIONS</h1>\n", "<ul>\n", "<li>For the purpose of making a prediction, there is no need to collect reservation data. </li>\n", "<li>The Simple method shows a decent accuracy of data prediction, while easy to implement and support in the future product. Simple method does not take into account seasonal changes.</li>\n", "<li>The Advanced method improves the accuracy of forecasting by about 6%. However, requires the utilisation of 3rd party library and proper onsite expertise to update model and support it in the future. The Advanced method uses additional information on the number of visitors few days after and/or before holidays. The appropriate expertise of the person who knows visitors behavior during Japanese holidays has to be used to improve accuracy. One year of historical data is not enough to statistically identify visitors behavior before and/or after different kind of holidays.</li>\n", "<li>The accuracy of both methods will be improved when data for few years will be available.</li>\n", "</ul>\n", "<h1>RECOMENDATION</h1>\n", "<p>If Recruit Holdings has already the proper expertise to implement and support the advanced method, then we recommend to use it. If not, Recruit Holdings has to take into account the cost of implementation and future support of the advanced method and make cost/benefit decision on what to use.</p>\n", "<h1>RATIONALE</h1>\n", "<h2>Cleaning and preparing data </h2>\n", "<h3>Import required libraries</h3>\n", "<p> Anywhere further in the text press <b>Code</b> button if want to see actual code and/or <b>Output</b> button if you want to see the output. You might want to try it now </p>"], "metadata": {"_uuid": "37851790eb6afcb5200ae24b87d69c6d3bdd7b46", "_cell_guid": "4e014b16-5e5f-4945-a0fc-785ee16410ca"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "690ab89ad38cd0904d3057d320ce404252e42a4a", "_kg_hide-output": true, "_kg_hide-input": true, "_cell_guid": "ed1d6fd4-3bc6-45c1-bf54-39568bfdf7f3"}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "from scipy.stats import zscore\n", "from fbprophet import Prophet\n", "print('Required libraries have been imported')"]}, {"cell_type": "markdown", "source": ["<h3>Capturing data</h3>\n", "<p>For the purpose of making a prediction, there is no need to collect and analyse reservations data. Although reservations seem to be relevant data, there are so many unknown factors that could make a significant contribution. For example: the number of visitors who made a reservation through another reservation network; or just called directly restaurant; or might come without a reservation. Moreover, these factors will be changing over time, and cannot be reliably predicted. Hence these data should not be used in the future product. In other words- we could estimate the number of visitors who came through Recruit Holdings reservation systems, but we could not make the reliable prediction of the total number of visitors based only on the HPG or AirREGI reservations.</p>\n", "<p>Lets read only data files that we need and convert them into local variables</p> \n"], "metadata": {"_uuid": "4bf763c551f4a460219eac2b8b388b8e59da9fdb", "_cell_guid": "a9427825-6c68-4be1-b21d-794bae610bf9"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "ba029f159c68c5538b7a930973c918a76d37fc1e", "_kg_hide-output": true, "_kg_hide-input": true, "_cell_guid": "5a038fe9-848b-4284-9f4b-bb7920bd96f3"}, "outputs": [], "source": ["path ='../input/'\n", "dfs = {\n", "    'air_visit_data': pd.read_csv(path+'air_visit_data.csv'),\n", "    'air_store_info': pd.read_csv(path+'air_store_info.csv'),\n", "    'sample_submission': pd.read_csv(path+'sample_submission.csv'),\n", "    'date_info': pd.read_csv(path+'date_info.csv')\n", "}\n", "print('files read:{}'.format(list(dfs.keys())))\n", "for key, name in dfs.items(): locals()[key] = name\n", "print('Data captured')"]}, {"cell_type": "markdown", "source": ["<h3>Removing outliers </h3>\n", "<p>To identify outliers, let\u2019s utilize widely used <b>Z-score</b> measurement. The idea is to calculate for how many standard deviations this particular value outstands from the mean. It is commonly accepted that values with Z score above 3 are outliers. Let\u2019s remove them from data.</p>\n"], "metadata": {"_uuid": "c680830d46aaf937ca9da06a1a12a731e1e21db8", "_cell_guid": "6e04e541-e823-4920-9d73-12579e81f3de"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "5c3b0e879de66895f459243e248eca7bdae60ed5", "_kg_hide-output": true, "_kg_hide-input": true, "_cell_guid": "ae224732-3c4e-4613-928b-7bc242fd5577"}, "outputs": [], "source": ["outliers = (air_visit_data.groupby( ['air_store_id'])['visitors'].transform(zscore) > 3)\n", "air_visit_data[outliers]=np.nan\n", "air_visit_data.dropna(inplace=True)\n", "print(str(outliers.sum())+' outliers have been removed')"]}, {"cell_type": "markdown", "source": ["<h3>Filling in missed data</h3>\n", "<p>Quick view on the AirREGI visits data exposed that there are many numbers of visitors to each restaurant for each day are NOT presented. There are plenty of missing data for each restaurant and each day. Missing data will significantly impact prediction performance. This is specifically important for some rare events like Golden week holidays.</p>\n", "<p><i>Lets recover these data.</i><p/> \n", "<p>We will use following assumption for recovery: number of visitors to each restaurant for each day is equals to the average number of visitors to restaurants in the same area and with the same genre. This number should be adjusted to the size of the restaurant, which we define as the average number of visitors to that restaurant.</p>\n", "<p>Firstly, lets split restaurants into several <i>clusters</i>. Each cluster has unique genre_name and area_name. Then define function, which fills in NaNs (missing value) where it is possible. If there were no visitors to any similar restaurants in the same area on certain dates, It is not possible to fill in.</p>\n"], "metadata": {"_uuid": "a529692f02394e680e53f030ce05b0d30b3e3a1e", "_cell_guid": "5ddbbb32-e83b-4428-9e4f-ccbc773c3517"}}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_uuid": "8a0f57610a4ea8b01180f9f2d220a2fd8e06ce97", "_kg_hide-output": false, "_kg_hide-input": true, "_cell_guid": "8a449be4-972f-49de-aa5d-b2d9cc2c2c11"}, "outputs": [], "source": ["#Fill in Nans where possible with average in cluster on that day adjusted by the size of the particular restaurants \n", "def fill_nans_in_cluster(genre_name,area_name):\n", "    #get list of the same type of restaurants in the neighborhood\n", "    neighbors_bool = air_store_info.apply(lambda x:(x.air_genre_name==genre_name and x.air_area_name==area_name), axis=1)\n", "    neighbors_ids=pd.DataFrame((air_store_info[neighbors_bool]))\n", "    neighbors_restaurants= air_visit_data.merge(neighbors_ids,on='air_store_id',how='inner')[['air_store_id','visit_date','visitors']]\n", " \n", "    #pivot neighbors_restaurants to easy fill in possible missing dates.\n", "    neighbors_restaurants=neighbors_restaurants.pivot_table(index='visit_date',columns='air_store_id', values='visitors',aggfunc=sum)\n", "    \n", "    #Fill in missing dates(if any) with Nans\n", "    idx = pd.date_range('2016-01-01', '2017-04-22')\n", "    neighbors_restaurants.index = pd.DatetimeIndex(neighbors_restaurants.index)\n", "    neighbors_restaurants = neighbors_restaurants.reindex(idx, fill_value=np.nan)\n", "\n", "    # Get visitors rate, normalized to the avarage number of visitors per day \n", "    neighbors_restaurants_average= neighbors_restaurants.mean(axis=0).tolist()\n", "    normalized_neighbors_restaurants = neighbors_restaurants.div(neighbors_restaurants_average,axis=1)\n", "\n", "    # Fill in Nans with avarge number of visiotrs in nighbour restaurants \n", "    #axis argument to fillna is Not Implemented, so have to use transpond\n", "    normalized_neighbors_restaurants_with_filled_nans=normalized_neighbors_restaurants.T.fillna(normalized_neighbors_restaurants.mean(axis=1))\n", "    \n", "    #replace normalized values with real vistors by multipliyng back on average per restaurant\n", "    neighbors_restaurants_with_filled_nans = normalized_neighbors_restaurants_with_filled_nans.mul(neighbors_restaurants_average,axis=0).reset_index()\n", "\n", "    #return visit data in the original format \n", "    df_columns = neighbors_restaurants_with_filled_nans.columns[1:]\n", "    return  pd.melt(neighbors_restaurants_with_filled_nans,id_vars=['air_store_id'], value_vars=df_columns)"]}, {"cell_type": "markdown", "source": ["<p>Secondly, let\u2019s process all clusters one by one.</p>"], "metadata": {"_uuid": "e08eb90ed94547bf5d2908528fa00e7ec022dd4c", "_cell_guid": "560f6fa6-0bdd-448e-ada6-d45b0435630f"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "800dbc88965de4c3321cc3324d70b5a470a09fd8", "_kg_hide-output": true, "_kg_hide-input": true, "_cell_guid": "4c9a5a13-2862-4653-b122-767d868a5e14"}, "outputs": [], "source": ["clusters_names= air_store_info.apply(lambda x:(x.air_genre_name + '_' + x.air_area_name), axis=1).unique().tolist()\n", "full_data = pd.DataFrame(columns=air_visit_data.columns)\n", "\n", "for cluster in clusters_names:\n", "    cluster_data = fill_nans_in_cluster (cluster.split('_')[0],cluster.split('_')[1])\n", "    cluster_data.rename(columns={'variable':'visit_date','value':'visitors'},inplace=True )\n", "    full_data=full_data.append(cluster_data,ignore_index=True)\n", "print('Missing data filling complete')"]}, {"cell_type": "markdown", "source": ["<p>We have identified that only 821 restaurants are required for submission.So let's lets focus only on restaurants that are required.</p>"], "metadata": {"_uuid": "c2f529ca09ccac046dbf96dfd9adae4dfdf4b24b", "_cell_guid": "7663d567-a67f-4709-ac89-0bd4f22c7506"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "5b5695264ee560772334de15f6952ff6bbd5f76e", "collapsed": true, "_kg_hide-input": true, "_cell_guid": "2d653c89-993f-4f02-93a4-5ed6e1137e41"}, "outputs": [], "source": ["target_restaurants= pd.DataFrame({'air_store_id':sample_submission['id'].str[:-len('_2017-04-23')].unique()})\n", "full_data=full_data.merge(target_restaurants,on='air_store_id',how='inner')"]}, {"cell_type": "markdown", "source": ["<h3>Preparing data for analysis</h3>\n", "<p>For future data analysis it would be more convenient to merge all required information in one DataFrame. \n", "So add appropriate genre and location to each restaurant. Also let's add days of the week and holidays flags.</p>\n"], "metadata": {"_uuid": "7f730126ffc126c8d8cb0937f1e459c40a7c8295", "_cell_guid": "99dfbf7d-56b5-4906-91bd-878716607148"}}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "_uuid": "4be4543d8d9e838963ce12f62aef1ea9f1d4d215", "_kg_hide-output": true, "_kg_hide-input": true, "_cell_guid": "11cc785b-bcd8-4eb0-aa31-f3c18d885923"}, "outputs": [], "source": ["visit_data = full_data.merge(air_store_info[['air_store_id','air_genre_name','air_area_name']],\n", "                             left_on='air_store_id',right_on='air_store_id',how='left')\n", "date_info['calendar_date']= pd.to_datetime(date_info['calendar_date'])\n", "\n", "visit_data = visit_data.merge(date_info, left_on='visit_date', right_on='calendar_date', how='left')\n", "visit_data.drop('calendar_date', axis=1, inplace=True)\n", "\n", "print('Data ready for analysis')"]}, {"cell_type": "markdown", "source": ["<h2>Data Analysis</h2>"], "metadata": {"_uuid": "90b64bdcfb23724cc541628bbfadad2a427ed15d", "_cell_guid": "6ad5564d-5ba7-4b58-ae27-0eba8bd69ed0"}}, {"cell_type": "markdown", "source": ["<h3> Simple method</h3>\n", "\n", "<p>The simple method is based on the following algorithm:</p>\n", "<li>A number of visitors on prediction day will be equal to the average number of visitors on the same day of the week for the last year.</li>\n", "<li>If prediction day is a holiday, number is equal to the average number of visitors on the holidays during last year.</li>\n", "\n", "<p>The main advantage of the simple method is - it could be implemented by on-site expertise and using pretty much any programming language. The disadvantage is - it does not take into account seasonal changes.</p>\n", "<p>Based on the available visit data file, let\u2019s calculate number of visitors per restaurants per day of the week.</p>"], "metadata": {"_uuid": "fd54cac3c0f67bbe5549b287a21adcf87f0f0f01", "_cell_guid": "673a93c1-cc9f-489c-ae9b-bb3745a1fc34"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "93282f36a7e363650e1da39d8afb15f6f346ad0d", "collapsed": true, "_kg_hide-input": true, "_cell_guid": "b54f78d1-b2f6-47fc-87f3-c9fbb091b1f1"}, "outputs": [], "source": ["#Make a copy of visit da\u0435a so we could use it later \n", "simple_visit_data = visit_data.copy()\n", "\n", "#If there is a holyday mark day of the weel as a Holiday\n", "simple_visit_data.loc[simple_visit_data['holiday_flg']==1,'day_of_week'] = 'Holiday'\n", "\n", "# Calculate average number of the visitors per day of the week. Holiday is treated as day of the week\n", "visitors_per_day_of_the_week = simple_visit_data.groupby(['air_store_id', 'day_of_week']).mean().reset_index()\n", "visitors_per_day_of_the_week.drop('holiday_flg', axis=1, inplace=True)"]}, {"cell_type": "markdown", "source": ["<h3>Prepaire submission file</h3>"], "metadata": {"_uuid": "9a19043911fc7fd38cf049db1c0d569748c44e0b", "_cell_guid": "7e05776b-76f5-4825-aa9b-b67f7645df7c"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "4f2fa3d172644bedd7fbe2cf6c4f9fed9b571503", "_kg_hide-output": true, "_kg_hide-input": true, "_cell_guid": "00f1ef37-5400-4732-8f89-7867bc624dbf"}, "outputs": [], "source": ["#Make a copy of visit da\u0435a so we could use it later \n", "simple_submission = sample_submission.copy()\n", "\n", "#extraxt required restaurant ids and required dates\n", "simple_submission['air_store_id'] = simple_submission['id'].str[:-len('_2017-04-23')] \n", "simple_submission['calendar_date'] = simple_submission['id'].str[-len('2017-04-23'):] \n", "simple_submission.drop(['visitors','id'], axis=1, inplace=True)\n", "simple_submission['calendar_date']= pd.to_datetime(simple_submission['calendar_date'])\n", "\n", "# Using visitors_per_day_of_the_week fill in required position in the submission file\n", "simple_submission = simple_submission.merge(date_info, on='calendar_date', how='left')\n", "simple_submission.loc[simple_submission['holiday_flg']==1,'day_of_week'] = 'Holiday'\n", "simple_submission = simple_submission.merge(visitors_per_day_of_the_week, on=['air_store_id', 'day_of_week'], how='left')\n", "\n", "print('simple submission file is ready')\n"]}, {"cell_type": "markdown", "source": ["<h3>Write simple submission to file</h3>"], "metadata": {"_uuid": "0b327b31f501306a78fcc04cc85c7c38ec1b6ff3", "_cell_guid": "6cfb553f-c71c-4d03-9848-9acd0a1ad254"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "a160a48ff0db0e32450faf2ec0a03f76dd74b626", "_kg_hide-output": true, "_kg_hide-input": true, "_cell_guid": "121b825f-ca0b-4099-b661-1c4ef5e85480"}, "outputs": [], "source": ["simple_submission['id']= simple_submission.apply(lambda row: str(row.air_store_id)+'_' + str(row.calendar_date)[:len('2017-04-23')], axis=1)\n", "simple_submission[['id', 'visitors']].to_csv('simple_submission.csv', index=None)\n", "print(\"Submission for simple method is done\")"]}, {"cell_type": "markdown", "source": ["<h3>Scoring of Simple method</h3>\n", "<p>If we submit file for scoring, we get</p>\n", "<p><b>Score is 0.548</b></p>\n", "<p> This is not the best score in the completion, but this is clear straight forward approach without using any kind of weighted coefficients, which in many cases are difficult to explain and rationalize. Adjusting these kind of coefficients usually leads to better performance on certain dates, which are known prior to the experiment. However, in many cases this approach do not get the same results on other set of dates. This is not practically feasible.</p>\n", "<p><b>Conclusion:</b> This simple approach still gets reasonably good results, while very easy to implement and support in the future.</p>\n", "<h2>Advanced method</h2>\n", "There are several advanced methods were considered and compared in [Be my guest - Recruit Restaurant EDA.](http://s://www.kaggle.com/headsortails/be-my-guest-recruit-restaurant-eda) Many thanks to the author of this kernel for the awesome work. Based on this work, we could see that many advanced methods considered there are very close in terms of the accuracy. However, we think that [Prophet](https://research.fb.com/prophet-forecasting-at-scale/method) as the more suitable approach to the required task. This is set of the open-source pieces of software developed by [Facebook's Core Data Science team.](https://research.fb.com/category/data-science)\n", "<p>Prophet utilizes an additive regression model which decomposes a time series into</p>\n", "<ol>\n", "<li>the linear/logistic trend,</li>\n", "<li>a yearly seasonal component,</li>\n", "<li>a weekly seasonal component, and</li>\n", "<li>an optional list of important days (such as holidays, special events, &hellip;).</li>\n", "</ol>\n", "<p>This tool is backed by Facebook brand and presumably employs work of the world&rsquo;s best data scientist.</p>\n", "<p>It fits our purposes because it was originally designed to forecast data based on the time series and correctly handle data around holidays. If we assume that visitor&rsquo;s behavior is different during holidays, as well as a few days before and after Holidays, then Prophet will handle this irregularity scientifically correct.</p>\n", "<h3>Holidays classification</h3>\n", "<p>Let us assume that visitor\u2019s behavior is different for different holidays. Unfortunately, we have only 1 year of historical data and hence, we have only 1 day of representation of each holiday. This is not enough to predict data reliably in the future. To increase statistical representation of each holiday, we need to classify holidays and split them into groups. Each group would consist of holidays where restaurant\u2019s visitor's behavior are similar. This way, we would collect more data for each group of holidays.</p>\n", "<p>We have manually converted date_info file into Prophet\u2019s format and have assigned meaningful names for each holiday. We had to do so manually because, we have to track different kind of holidays separately from each other. Unfortunately information about holidays names are not present in the date_info file.</p>\n", "Please see below Prophet\u2019s holiday\u2019s definition file. According to Prophet Requirements, we have to identify how many days visitor's behavior is different before and after each holiday. More details on lower_window and upper_window parameters are presented [here.](https://facebook.github.io/prophet/docs/seasonality_and_holiday_effects.html)\n", "<p>We would need someone more familiar with Japanese traditions to adjust these parameters.</p>"], "metadata": {"_uuid": "598eab2af1c77c5d9d387dc230719da30c9ca10d", "collapsed": true, "_cell_guid": "00a4e1e2-9705-4487-8299-2ccca439afb1"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "3b520a333919692f228c33e34c84c5cc09708415", "collapsed": true, "_kg_hide-input": true, "_cell_guid": "c09906c0-6411-4d01-8693-c0e29f3795da"}, "outputs": [], "source": ["#Holidays are presented in the format required by Prophet \n", "new_year_day = pd.DataFrame({\n", "  'holiday': 'new_year_day',\n", "  'ds': pd.to_datetime(['2016-01-01', '2017-01-01']),\n", "  'lower_window': -2, #how many days before holiday are significant \n", "  'upper_window': 1,  #how many days after holiday are significant \n", "})\n", "bank_holiday = pd.DataFrame({\n", "  'holiday': 'bank_holiday',\n", "  'ds': pd.to_datetime(['2016-01-02','2016-01-03', '2016-12-31', '2017-01-02','2017-01-03']),\n", "  'lower_window': 0,\n", "  'upper_window': 0,\n", "})\n", "coming_of_age_day = pd.DataFrame({\n", "  'holiday': 'coming_of_age_day',\n", "  'ds': pd.to_datetime(['2016-01-09','2017-01-11']),\n", "  'lower_window': 0,\n", "  'upper_window': 0,\n", "})\n", "national_foundation_day = pd.DataFrame({\n", "  'holiday': 'national_foundation_day',\n", "  'ds': pd.to_datetime(['2016-02-11','2017-02-11']),\n", "  'lower_window': 0,\n", "  'upper_window': 0,\n", "})\n", "valentines_day = pd.DataFrame({\n", "  'holiday': 'valentines_day',\n", "  'ds': pd.to_datetime(['2016-02-14','2017-02-14']),\n", "  'lower_window':-1,\n", "  'upper_window': 1,\n", "})\n", "dolls_girls_festival = pd.DataFrame({\n", "  'holiday': 'dolls_girls_festival',\n", "  'ds': pd.to_datetime(['2016-03-03','2017-03-03']),\n", "  'lower_window':-1,\n", "  'upper_window': 1,\n", "})\n", "equinox = pd.DataFrame({\n", "  'holiday': 'equinox',\n", "  'ds': pd.to_datetime(['2016-03-20','2016-03-21','2016-09-22','2016-06-20','2017-03-20']),\n", "  'lower_window': 0,\n", "  'upper_window': 0,\n", "})\n", "golden_week = pd.DataFrame({\n", "  'holiday': 'golden_week',\n", "  'ds': pd.to_datetime(['2016-04-29','2016-05-03','2016-05-04','2016-05-05','2017-04-29','2017-05-03','2017-05-04','2017-05-05']),\n", "  'lower_window':-2,\n", "  'upper_window': 1,\n", "})\n", "star_festival = pd.DataFrame({\n", "  'holiday': 'star_festival',\n", "  'ds': pd.to_datetime(['2016-07-07']),\n", "  'lower_window': 0,\n", "  'upper_window': 0,\n", "})\n", "sea_day = pd.DataFrame({\n", "  'holiday': 'sea_day',\n", "  'ds': pd.to_datetime(['2016-07-18']),\n", "  'lower_window': 0,\n", "  'upper_window': 0,\n", "})\n", "mountain_day = pd.DataFrame({\n", "  'holiday': 'mountain_day',\n", "  'ds': pd.to_datetime(['2016-08-11']),\n", "  'lower_window': 0,\n", "  'upper_window': 0,\n", "})\n", "respect_for_the_aged = pd.DataFrame({\n", "  'holiday': 'respect_for_the_aged',\n", "  'ds': pd.to_datetime(['2016-09-19']),\n", "  'lower_window': 0,\n", "  'upper_window': 0,\n", "})\n", "sports_day = pd.DataFrame({\n", "  'holiday': 'sports_day',\n", "  'ds': pd.to_datetime(['2016-10-10']),\n", "  'lower_window': 0,\n", "  'upper_window': 0,\n", "})\n", "culture_day = pd.DataFrame({\n", "  'holiday': 'culture_day',\n", "  'ds': pd.to_datetime(['2016-11-03']),\n", "  'lower_window': 0,\n", "  'upper_window': 0,\n", "})\n", "day_7_5_3 = pd.DataFrame({\n", "  'holiday': 'day_7_5_3',\n", "  'ds': pd.to_datetime(['2016-11-15']),\n", "  'lower_window': 0,\n", "  'upper_window': 0,\n", "})\n", "labor_thanksgiving_day = pd.DataFrame({\n", "  'holiday': 'labor_thanksgiving_day',\n", "  'ds': pd.to_datetime(['2016-11-23']),\n", "  'lower_window':-1,\n", "  'upper_window': 1,\n", "})\n", "christmas = pd.DataFrame({\n", "  'holiday': 'christmas',\n", "  'ds': pd.to_datetime(['2016-12-21','2016-12-23','2016-12-25']),\n", "  'lower_window':-2,\n", "  'upper_window': 1,\n", "})\n", "\n", "holidays = pd.concat((new_year_day, bank_holiday,coming_of_age_day,national_foundation_day,\\\n", "                      valentines_day,dolls_girls_festival,equinox,golden_week,\\\n", "                     star_festival,sea_day,mountain_day,respect_for_the_aged,\\\n", "                     sports_day,culture_day,day_7_5_3,labor_thanksgiving_day,\\\n", "                     christmas))\n"]}, {"cell_type": "markdown", "source": ["<p>Prophet start prediction period from the date of last available data. So, before we begin, lets make sure that we have data for the '2017-04-22' (last date of training set). If not, then fill it in with the average  number for that restaurant on \u2018Saturday\u2019.</p>"], "metadata": {"_uuid": "ed1d03b55ceb8434c3f248f4165ef1c8f32bff48", "_cell_guid": "c950d5f9-ba86-40e5-a3f1-3a5cf33e1e4b"}}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "_uuid": "cfe72a122a1ef5e95a201908d8a142be622ed83a", "_kg_hide-output": true, "_kg_hide-input": true, "_cell_guid": "8b04e2fd-07a7-492d-8ea6-03e5e89ceaaa"}, "outputs": [], "source": ["# get restaraunts with missed data on '2017-04-22'\n", "missings= visit_data['visitors'].isnull() & (visit_data['visit_date'] == '2017-04-22')\n", "\n", "#get average number of visitors on saturdays for these restaurants\n", "visitors_per_day_of_the_week = visit_data.groupby(['air_store_id', 'day_of_week']).mean().reset_index()\n", "visitors_on_Saturdays = visitors_per_day_of_the_week[visitors_per_day_of_the_week['day_of_week']== 'Saturday']\n", "\n", "#apply to visit data\n", "visit_data.loc[missings, 'visitors'] = visit_data[missings].merge(\n", "    visitors_on_Saturdays[['air_store_id', 'visitors']], on='air_store_id', how='left')['visitors_y'].values\n", "print('Data ready for advanced method')\n"]}, {"cell_type": "markdown", "source": ["<h3> Prophet prediction for one restaurant</h3>\n", "<p>Lets define function for Prophet prediction for one restaurant</p>"], "metadata": {"_uuid": "60b8352dd68963eadcb34873d17b8fd1a7a05450", "_cell_guid": "4aa594db-4929-43cd-807e-6cc18297affb"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "9cfb2c05379fd7248041862355ca296dbd61aab5", "collapsed": true, "_kg_hide-input": true, "_cell_guid": "06e6245c-2dab-4236-bb61-3c81a60c7414"}, "outputs": [], "source": ["def prophet_prediction (air_id):\n", "    #get restaurant data\n", "    restaurant_visit_data = visit_data[visit_data['air_store_id'] == air_id]\n", "    \n", "    #fill it into Prophet model and fit the model\n", "    df=pd.DataFrame()\n", "    df['ds']=restaurant_visit_data['visit_date']\n", "    df['y'] = np.log(restaurant_visit_data['visitors'])\n", "    model = Prophet(changepoint_prior_scale=0.5, yearly_seasonality=False)\n", "    model.fit(df)\n", "    \n", "    #run prediction for the next 39 days\n", "    future_data = model.make_future_dataframe(periods=39)\n", "    forecast_data = model.predict(future_data)\n", "    return forecast_data.iloc[-39:,:][['ds', 'yhat']]\n"]}, {"cell_type": "markdown", "source": ["<p>Let's calculate prediction for each restaurant and prepare submittion file.</p>"], "metadata": {"_uuid": "e4325c79a2c160b5860048557238c1f30c92af1f", "_cell_guid": "9ffebcf5-e013-498f-9868-8d9a65a3384e"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "be23b5fbba8cc0680a74bc4b663ef20e5350c336", "_kg_hide-output": true, "_kg_hide-input": true, "_cell_guid": "85c4709f-ed66-45ec-9d6a-3a44ec309378"}, "outputs": [], "source": ["#prepare submission file\n", "submission= pd.DataFrame(columns=('id','visitors'))\n", "for row in target_restaurants['air_store_id']:\n", "    submission_to_append= pd.DataFrame(columns=('id','visitors'))\n", "    temp_submission=prophet_prediction(row)\n", "    submission_to_append['id']= temp_submission['ds'].map(lambda x: str(row)+'_'+str(x)[:len('2017-04-23')])\n", "    submission_to_append['visitors']= np.exp(temp_submission['yhat'])\n", "    submission = submission.append(submission_to_append,ignore_index=True)\n"]}, {"cell_type": "markdown", "source": ["<p>Save submission to the file</p>"], "metadata": {"_uuid": "53f3c752a4feab9d28eced0cc4331ac1bd745d93", "_cell_guid": "067745dd-609a-45a7-8439-68dc7a768500"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "4fdd250652801d70bfb9636edbd5eef55fb0d96b", "_kg_hide-output": true, "_kg_hide-input": true, "_cell_guid": "de779df2-a220-422a-8a62-87e9a2f08aa8"}, "outputs": [], "source": ["prophet_submission= pd.DataFrame(submission).reset_index()\n", "submission[['id','visitors']].to_csv('prophet_submission.csv', index=None)\n", "print(\"Submission for advanced method is done\")"]}, {"cell_type": "markdown", "source": ["<h3>Scoring of Advanced method</h3>\n", "<p>If we submit file for scoring, we get</p>\n", "<p><b>Score is 0.512</b></p>\n", "\n", "<p>The Advanced method improves the accuracy of forecasting by about 6%. However, requires the utilisation of 3rd party library and proper onsite expertise to update model and support it in the future. The Advanced method uses additional information on the number of visitors few days after and/or before holidays. The appropriate expertise of the person who knows visitors behavior during Japanese holidays has to be used to improve accuracy. One year of historical data is not enough to statistically identify visitors behavior before and/or after different kind of holidays.</p>The accuracy of both methods will be improved when data for few years will be available.</p>\n", "<h1>RECOMENDATION</h1>\n", "<p>If Recruit Holdings has already the proper expertise to implement and support the advanced method, then we recommend to use it. If not, Recruit Holdings has to take into account the cost of implementation and future support of the advanced method and make cost/benefit decision on what to use.</p>"], "metadata": {"_uuid": "74c9be6a2ce123c38eb3625e8cc1f5ce0eaa4884", "_cell_guid": "730810c2-bea3-4b9d-bee3-fc1ac8764c4a"}}], "nbformat_minor": 1, "metadata": {"language_info": {"file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "version": "3.6.4"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4}