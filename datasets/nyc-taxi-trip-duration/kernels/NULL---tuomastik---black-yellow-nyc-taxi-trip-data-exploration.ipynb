{"cells": [{"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "e655d573-25c8-44f0-8d2f-609a4f319eae", "_uuid": "15f1432344ff64ccb57a06ccde7e2291dc5437c6"}, "source": ["%%HTML\n", "\n", "<!DOCTYPE HTML>\n", "<html>\n", "  <head>\n", "    <meta charset=\"utf-8\" />\n", "    <style>\n", "\n", "body {\n", "  padding-bottom: 40px;\n", "}\n", "\n", "#content-container {\n", "  position: relative;\n", "  width: 820px;\n", "  height: 200px;\n", "}\n", "\n", ".car {\n", "  position: absolute;\n", "  width: 58px;\n", "  top: 0px;\n", "  /* Flip the car horizontally */\n", "  -moz-transform: scaleX(-1);\n", "  -webkit-transform: scaleX(-1);\n", "  -o-transform: scaleX(-1);\n", "  transform: scaleX(-1);\n", "  -ms-filter: fliph; /*IE*/\n", "  filter: fliph; /*IE*/\n", "  /* Animation */\n", "  -webkit-animation: car-animation 10s ease infinite; /* Safari 4+ */\n", "  -moz-animation:    car-animation 10s ease infinite; /* Fx 5+ */\n", "  -o-animation:      car-animation 10s ease infinite; /* Opera 12+ */\n", "  animation:         car-animation 10s ease infinite; /* IE 10+, Fx 29+ */\n", "}\n", "@-webkit-keyframes car-animation {\n", "  0%   { opacity: 0; left:   0px; }\n", "  40%  { opacity: 1; left: 256px; }\n", "  75%  { opacity: 1; left: 555px; }\n", "  100% { opacity: 0; left: 777px; }\n", "}\n", "@-moz-keyframes car-animation {\n", "  0%   { opacity: 0; left:   0px; }\n", "  40%  { opacity: 1; left: 256px; }\n", "  75%  { opacity: 1; left: 555px; }\n", "  100% { opacity: 0; left: 777px; }\n", "}\n", "@-o-keyframes car-animation {\n", "  0%   { opacity: 0; left:   0px; }\n", "  40%  { opacity: 1; left: 256px; }\n", "  75%  { opacity: 1; left: 555px; }\n", "  100% { opacity: 0; left: 777px; }\n", "}\n", "@keyframes car-animation {\n", "  0%   { opacity: 0; left:   0px; }\n", "  40%  { opacity: 1; left: 256px; }\n", "  75%  { opacity: 1; left: 555px; }\n", "  100% { opacity: 0; left: 777px; }\n", "}\n", "\n", "\n", ".passenger-start {\n", "  position: absolute;\n", "  width: 30px;\n", "  top: 11px;\n", "  -webkit-animation: passenger-start-animation 10s ease infinite; /* Safari 4+ */\n", "  -moz-animation:    passenger-start-animation 10s ease infinite; /* Fx 5+ */\n", "  -o-animation:      passenger-start-animation 10s ease infinite; /* Opera 12+ */\n", "  animation:         passenger-start-animation 10s ease infinite; /* IE 10+, Fx 29+ */\n", "}\n", "@-webkit-keyframes passenger-start-animation {\n", "  0%   { opacity: 0; left: 265px; }\n", "  20%  { opacity: 1; left: 265px; }\n", "  40%  { opacity: 1; left: 265px; }\n", "  45%  { opacity: 0; left: 265px; }\n", "  100% { opacity: 0; left: 265px; }\n", "}\n", "@-moz-keyframes passenger-start-animation {\n", "  0%   { opacity: 0; left: 265px; }\n", "  20%  { opacity: 1; left: 265px; }\n", "  40%  { opacity: 1; left: 265px; }\n", "  45%  { opacity: 0; left: 265px; }\n", "  100% { opacity: 0; left: 265px; }\n", "}\n", "@-o-keyframes passenger-start-animation {\n", "  0%   { opacity: 0; left: 265px; }\n", "  20%  { opacity: 1; left: 265px; }\n", "  40%  { opacity: 1; left: 265px; }\n", "  45%  { opacity: 0; left: 265px; }\n", "  100% { opacity: 0; left: 265px; }\n", "}\n", "@keyframes passenger-start-animation {\n", "  0%   { opacity: 0; left: 265px; }\n", "  20%  { opacity: 1; left: 265px; }\n", "  40%  { opacity: 1; left: 265px; }\n", "  45%  { opacity: 0; left: 265px; }\n", "  100% { opacity: 0; left: 265px; }\n", "}\n", "\n", "\n", ".passenger-stop {\n", "  position: absolute;\n", "  width: 30px;\n", "  top: 11px;\n", "  -webkit-animation: passenger-stop-animation 10s ease infinite; /* Safari 4+ */\n", "  -moz-animation:    passenger-stop-animation 10s ease infinite; /* Fx 5+ */\n", "  -o-animation:      passenger-stop-animation 10s ease infinite; /* Opera 12+ */\n", "  animation:         passenger-stop-animation 10s ease infinite; /* IE 10+, Fx 29+ */\n", "}\n", "@-webkit-keyframes passenger-stop-animation {\n", "  0%   { opacity: 0; left: 564px; }\n", "  68%  { opacity: 0; left: 564px; }\n", "  75%  { opacity: 1; left: 564px; }\n", "  80%  { opacity: 1; left: 564px; }\n", "  100% { opacity: 0; left: 564px; }\n", "}\n", "@-moz-keyframes passenger-stop-animation {\n", "  0%   { opacity: 0; left: 564px; }\n", "  68%  { opacity: 0; left: 564px; }\n", "  75%  { opacity: 1; left: 564px; }\n", "  80%  { opacity: 1; left: 564px; }\n", "  100% { opacity: 0; left: 564px; }\n", "}\n", "@-o-keyframes passenger-stop-animation {\n", "  0%   { opacity: 0; left: 564px; }\n", "  68%  { opacity: 0; left: 564px; }\n", "  75%  { opacity: 1; left: 564px; }\n", "  80%  { opacity: 1; left: 564px; }\n", "  100% { opacity: 0; left: 564px; }\n", "}\n", "@keyframes passenger-stop-animation {\n", "  0%   { opacity: 0; left: 564px; }\n", "  68%  { opacity: 0; left: 564px; }\n", "  75%  { opacity: 1; left: 564px; }\n", "  80%  { opacity: 1; left: 564px; }\n", "  100% { opacity: 0; left: 564px; }\n", "}\n", "\n", "\n", ".header {\n", "  position: absolute;\n", "  left: 0px;\n", "  top: 40px;\n", "  text-align: center;\n", "  vertical-align: middle;\n", "  background: #ffb700;\n", "  width: 820px;\n", "  height: 163px;\n", "  border: 10px solid #111111;\n", "  -webkit-border-radius: 25px 25px 25px 25px;\n", "  border-radius: 25px 25px 25px 25px; \n", "}\n", "\n", ".competition-name {\n", "  margin: 0;\n", "  font-size: 50px;\n", "  color: #111111;\n", "  display: inline-block;\n", "}\n", "\n", ".taxi-text {\n", "  background: #111111;\n", "  color: #ffb700;\n", "  border: 10px solid #111111;\n", "  -moz-border-radius: 0px;\n", "  -webkit-border-radius: 25px 25px 0px 0px;\n", "  border-radius: 25px 25px 0px 0px; \n", "  margin-left: 20px;\n", "  margin-right: 20px;\n", "  padding: 7px 15px 0 15px;\n", "}\n", "\n", "\n", "    </style>\n", "  </head>\n", "  <body>\n", "\n", "    <div id=\"content-container\">\n", "      <div>\n", "        <div>\n", "          <!-- Icon made by Freepik from www.flaticon.com -->\n", "          <!-- https://www.flaticon.com/free-icon/taxi_89131 -->\n", "          <img class=\"car\" src=\"https://image.flaticon.com/icons/svg/89/89131.svg\"/>\n", "        </div>\n", "        <div>\n", "          <!-- Icon made by Freepik from www.flaticon.com -->\n", "          <!-- https://www.flaticon.com/free-icon/call-taxi_10931 -->\n", "          <img class=\"passenger-start\" src=\"https://image.flaticon.com/icons/svg/10/10931.svg\"/>\n", "        </div>\n", "        <div>\n", "          <!-- Icon made by Freepik from www.flaticon.com -->\n", "          <!-- https://www.flaticon.com/free-icon/businessman-with-suitcase_49205 -->\n", "          <img class=\"passenger-stop\" src=\"https://image.flaticon.com/icons/svg/49/49205.svg\"/>\n", "        </div>\n", "      </div>\n", "\n", "      <div class=\"header\">\n", "        <h1 class=\"competition-name\"           style=\"font-size: 40px; margin-top: 30px;\">New York City</h1>\n", "        <h1 class=\"competition-name taxi-text\" style=\"font-size: 40px; margin-top: 30px;\n", "                                                      margin-left: 15px; margin-right: 15px;\n", "                                                      color: #ffb700;\">TAXI</h1>\n", "        <h1 class=\"competition-name\"           style=\"font-size: 40px; margin-top: 30px;\">Trip Duration</h1>\n", "      </div>\n", "    </div>\n", "\n", "  </body>\n", "</html>"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ded9e50f-5171-4924-af02-313efb645825", "_uuid": "384c76a3209610769724d56441419aa8881e6882"}, "source": ["# Contents\n", "\n", "1. Introduction <br>\n", "2. Getting to Know the Data <br>\n", "    2.1. Reading the Data<br>\n", "    2.2. The Shape of the Data<br>\n", "3. Visualizing Variables<br>\n", "    3.1. Categorical and Ordinal Variables<br>\n", "    3.2. Continuous Variables<br>\n", "4. Conclusions<br>\n", "5. References\n"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "9ee485e4-0f85-4373-8da6-5e5054bcdf36", "_uuid": "9872e5d79b94b9d5e8e5cecd07cfca41bdf7341f"}, "source": ["# 1. Introduction\n", "\n", "The aim of this Kaggle competition is to predict the duration of taxi trips in New York City. Accurate estimates of taxi trip durations can improve the taxi utilization and the satisfaction of drivers and passengers. If a taxi dispatching system knew approximately when a taxi driver would be ending their current ride, it would help identifying which drivers should be assigned to which pickup locations. Additionally, the predictive model could be used for finding optimal routes for different kinds of trips.\n", "\n", "Kaggle provides a starting point dataset consisting of the records of ~1.5 million taxi trips that took place in 2016. The competition also allows the use of external data, which is not, however, considered in this notebook. This notebook walks the reader through the process of understanding the individual variables in the data by presenting beautiful, clear, and interactive data visualizations along with some approaches to their interpretation.\n", "\n", "Humans are visual creatures. It is much easier for our brains to process information by looking at charts rather than scrolling through text stored in huge spreadsheets. Data visualization is an essential component to ensure the success of any machine learning project. The benefits of data visualization include, for example, determining which model fits the data best, spotting trends and patterns that provide actionable insights, identifying areas that need attention or improvement, and providing an efficient tool for presenting the results of an analysis to a non-technical audience."]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "aa37127d-f0a3-49a5-9976-9202cb316aad", "_uuid": "d7ca5306048ab7a66089d85cccb4804fd4772bd3"}, "source": ["# Set things up\n", "\n", "# Make Matplotlib to work with Jupyter Notebook\n", "%matplotlib inline\n", "\n", "# Ignore ugly DeprecationWarnings\n", "from bokeh import BokehDeprecationWarning\n", "import warnings\n", "warnings.filterwarnings(\"ignore\", category=BokehDeprecationWarning)\n", "\n", "import datetime\n", "import calendar\n", "\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "from matplotlib import cm\n", "from matplotlib import colors\n", "from bokeh.io import output_notebook\n", "from bokeh.charts import show\n", "from bokeh.layouts import row\n", "from bokeh.models import ColumnDataSource, DataRange1d, HoverTool, PanTool, WheelZoomTool\n", "from bokeh.models.widgets import DataTable, TableColumn\n", "from bokeh.models.widgets import DateFormatter, StringFormatter\n", "from bokeh.plotting import figure\n", "import folium\n", "from sklearn.cluster import DBSCAN\n", "from shapely.geometry import MultiPoint\n", "from geopy.distance import great_circle\n", "\n", "plt.style.use('ggplot')  # Change Matplotlib style to something nicer\n", "plt.rc('font', size=12)  # Set default Matplotlib font size\n", "output_notebook(hide_banner=True)  # Make Bokeh to work with Jupyter Notebook\n", "\n", "# Define colors\n", "COLOR_DARK = \"#212121\"\n", "COLOR_YELLOW = \"#ffb700\"\n", "# Define custom colormap\n", "plt.register_cmap(cmap=colors.LinearSegmentedColormap.from_list(\n", "    'TaxiYellow', [\"#ffffff\", COLOR_YELLOW]))"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "310dfc6f-eb2a-4eec-acdb-6ba30f95c213", "_uuid": "7d380668c1ce07f52198d3dfde6983f47bb93f20"}, "source": ["# 2. Getting to Know the Data\n", "\n", "In this chapter, we take a first glance at the data. The data is loaded, its shape is checked and the variables are described. \n", "\n", "## 2.1. Reading the Data\n", "\n", "It is very straightforward to read tabular data into Python with Pandas library's [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) function. The function can conveniently convert time information into [`datetime`](https://docs.python.org/3/library/datetime.html) objects by setting `infer_datetime_format` parameter to `True` and providing the names of the time information columns to `parse_dates` parameter. The `\"id\"` column (unique trip identifier) can be set as the index of `train` and `test` `DataFrames` since it has no predictive value."]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "fb3df97d-90a5-47a5-9e93-d4ffbb794ff4", "collapsed": true, "_uuid": "05f4c928818b62513b3da068f9a7cf173f09768e"}, "source": ["train = pd.read_csv(filepath_or_buffer='../input/train.csv', index_col='id',\n", "                    parse_dates=['pickup_datetime', 'dropoff_datetime'],\n", "                    infer_datetime_format=True)\n", "\n", "test = pd.read_csv(filepath_or_buffer='../input/test.csv', index_col='id',\n", "                   parse_dates=['pickup_datetime'],\n", "                   infer_datetime_format=True)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "7d5cb7a4-1174-45e4-99bf-312443c69c95", "_uuid": "91002219aa0f45ad04181d35281f21387fa1e9e3"}, "source": ["## 2.2. The Shape of the Data"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "69420647-a7ad-45b2-a3bb-8f7369f4c569", "_uuid": "514476be897d08b0423e17654043d39aaa21a725"}, "source": ["n_train_rows, n_train_cols = train.shape\n", "n_test_rows, n_test_cols = test.shape\n", "print('- Training data has {:9,} rows and {:2,} columns.'.format(*train.shape))\n", "print('- Testing data has  {:9,} rows and {:2,} columns.'.format(*test.shape))\n", "print('- There are {:.1f} times more (#{:,}) training data examples than '\n", "      'testing data examples.'.format(n_train_rows / n_test_rows,\n", "                                        n_train_rows - n_test_rows))\n", "print(\"- There are %i missing values in the training data.\" % train.isnull().sum().sum())\n", "print(\"- There are %i missing values in the testing data.\" % test.isnull().sum().sum())"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "675014d8-d561-4f98-a443-0b6e5bd7e567", "_uuid": "a45cdb60dcdcfe8b1a729ce27f4b5ef145b099ca"}, "source": ["As it can be seen from the above output, there are two columns less in the testing data when compared to training data. Those columns are `\"dropoff_datetime\"` and `\"trip_duration\"`. The columns are missing from the testing data because they would give out the answers since they are to be predicted in this competition. More specifically, the aim is to predict the duration of each taxi trip, which is calculated by subtracting pick-up time from drop-off time.\n", "\n", "In the below Markdown table, there is a description of each of the 11 variables:\n", "\n", "| Variable name      \t| Variable description                                                                                                                                                                                                        \t|\n", "|--------------------\t|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\t|\n", "| id                 \t| A unique identifier for each trip                                                                                                                                                                                           \t|\n", "| vendor_id          \t| A code indicating the provider associated with the trip record                                                                                                                                                              \t|\n", "| pickup_datetime    \t| Date and time when the meter was engaged                                                                                                                                                                                    \t|\n", "| dropoff_datetime   \t| Date and time when the meter was disengaged                                                                                                                                                                                 \t|\n", "| passenger_count    \t| The number of passengers in the vehicle (driver entered value)                                                                                                                                                              \t|\n", "| pickup_longitude   \t| The longitude where the meter was engaged                                                                                                                                                                                   \t|\n", "| pickup_latitude    \t| The latitude where the meter was engaged                                                                                                                                                                                    \t|\n", "| dropoff_longitude  \t| The longitude where the meter was disengaged                                                                                                                                                                                \t|\n", "| dropoff_latitude   \t| The latitude where the meter was disengaged                                                                                                                                                                                 \t|\n", "| store_and_fwd_flag \t| This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server.<br>Y=store and forward; N=not a store and forward trip \t|\n", "| trip_duration      \t| Duration of the trip in seconds                                                                                                                                                                                             \t|"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "a0902ee8-984d-41cb-abea-371f8e0b26ad", "_uuid": "810130967dc53c74c4267050867db8bd62647245"}, "source": ["Next, let's show the beginning of each dataset in an interactive Bokeh table and visualize the number of examples in each dataset with a bar chart."]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "26b96dcd-393d-42b3-a5ea-ffac655a226d", "_uuid": "a2cbaabdda81ab6132df344b86b58dc3f3e80c11"}, "source": ["print(\"The first 10 rows of the training data shown in an interactive Bokeh table:\")\n", "show(DataTable(\n", "    source=ColumnDataSource(train.head(10)), editable=True,\n", "    columns=[TableColumn(\n", "        field=c, title=c,\n", "        formatter=DateFormatter() if 'datetime' in c else StringFormatter())\n", "        for c in train.columns],\n", "    width=820, height=300))\n", "\n", "print(\"The first 10 rows of the testing data shown in an interactive Bokeh table:\")\n", "show(DataTable(\n", "    source=ColumnDataSource(test.head(10)),\n", "    columns=[TableColumn(\n", "        field=c, title=c,\n", "        formatter=DateFormatter() if 'datetime' in c else StringFormatter())\n", "        for c in test.columns],\n", "    width=820, height=300))\n", "\n", "# -----------------------------------------------------------------------------\n", "\n", "# Let's visualize the number of examples in each file\n", "ax = pd.DataFrame({'Train': [n_train_rows], 'Test': [n_test_rows]}).plot.barh(\n", "    figsize=(14.1, 2), legend='reverse', rot=90, color=[COLOR_YELLOW, COLOR_DARK])\n", "ax.set(xlabel='Number of examples', ylabel='Dataset')\n", "ax.set_title('The number of examples in each dataset', fontsize=14)\n", "ax.get_yaxis().set_ticks([])\n", "# For readability, add commas to separate thousand in the x-axis labels\n", "ax.set_xticklabels([format(label, ',.0f') for label in ax.get_xticks()]);"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "7ce86a58-47ec-4f62-b9f0-c5ecd56901b7", "_uuid": "fccf5288ad6bc8e00827adb3e6b3703b567521c0"}, "source": ["# 3. Visualizing Raw Variables\n", "\n", "In this chapter, different visualizations are created for each of the variables using `matplotlib`, `bokeh` and `folium` packages. \n", "\n", "## 3.1. Categorical and Ordinal Variables\n", "\n", "The datasets contain one ordinal variable `\"passenger_count\"` and two categorical variables `\"vendor_id\"` and `\"store_and_fwd_flag\"`. Let's visualize the distributions of their values in training and testing data by bar charts."]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "08e8226c-4002-4d17-904d-8b8636f0e1c1", "_uuid": "517e095f0135fca1ffe35a325cb777670fd7f8af"}, "source": ["for col_name_pretty, col_name_official, figsize in zip(\n", "        ['passenger count', 'vendor ID', 'store and forward flag'],\n", "        ['passenger_count', 'vendor_id', 'store_and_fwd_flag'],\n", "        [(14.1, 6), (14.1, 2), (14.1, 2)]):\n", "    ax = pd.DataFrame({\n", "        col_name_pretty.capitalize() + ' (train)':\n", "            train[col_name_official].value_counts() /\n", "            train[col_name_official].value_counts().sum() * 100,\n", "        col_name_pretty.capitalize() + ' (test)':\n", "            test[col_name_official].value_counts() /\n", "            test[col_name_official].value_counts().sum() * 100}).plot.barh(\n", "        figsize=figsize, legend='reverse', rot=90, stacked=False,\n", "        color=[COLOR_YELLOW, COLOR_DARK])\n", "    ax.set(xlabel='Percentage of all values', ylabel='Value')\n", "    ax.set_title('Value proportions of %s in training and testing data' % col_name_pretty,\n", "                 fontsize=14)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "a7af97b8-2a12-4be6-a6cc-5d68abeeec53", "_uuid": "6988981b937e4a08f6030ec50e9fc3146114fad5"}, "source": ["By looking at the above plots, we can make the following observations:\n", "* ~70 % of the time people travel alone. The most popular way of sharing a taxi is to share it with a single friend. The second most popular way of sharing a taxi is to travel in a group of five people.\n", "* There are two vendors in the data, with the second vendor representing the majority.\n", "* Store and forward flag has almost always (99.4 % of the trips) been \"No\".\n", "* It seems that the data has been split between the training and testing set by preserving similar value counts in each dataset, since the black and yellow bars have approximately the same lengths. This is a good thing because if the testing data was very different from training data, applying the learned representation of the training data to testing data would not necessarily produce accurate predictions. This phenomenon is a common assumption in machine learning and is known as [independent and identically distributed random variables (i.i.d.)](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables).\n", "\n", "## 3.2. Continuous Variables\n", "\n", "When it comes to continuous variables, the data includes:\n", "* Two date and time variables: `\"pickup_datetime`\" and `\"dropoff_datetime\"`\n", "* One time variable: `\"trip_duration\"`\n", "* Four location variables: `\"pickup_longitude\"`, `\"pickup_latitude\"`, `\"dropoff_longitude\"` and `\"dropoff_latitude\"`\n", "\n", "Let's start the visualization of continuous variables by plotting the counts of `\"pickup_datetime`\" and `\"dropoff_datetime\"` grouped by unique days."]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "e0a93554-28d4-425a-88d0-06af117ef113", "_uuid": "a2e1748accfa18b5f5cf31299dca50a91e4ea561"}, "source": ["for var_name_pretty, var_name_official, datasets, dataset_names, cmaps in zip(\n", "        [\"pickup date\", \"drop-off date\"],\n", "        [\"pickup_datetime\", \"dropoff_datetime\"],\n", "        # \"dropoff_datetime\" is not included in the testing data\n", "        [[train, test], [train]], [['train', 'test'], ['train']],\n", "        [[cm.get_cmap('binary'), cm.get_cmap('TaxiYellow')], [cm.get_cmap('binary')]]):\n", "\n", "    fig = figure(plot_width=820, plot_height=400, x_axis_type=\"datetime\",\n", "                 tools=('wheel_zoom, pan, save, tap, reset',\n", "                        HoverTool(tooltips=[(var_name_pretty.capitalize(), '@time'),\n", "                                            ('Count', '@Count')])),\n", "                 x_axis_location='below', toolbar_location=\"above\", logo=None,\n", "                 x_axis_label=var_name_pretty.capitalize(), y_axis_label='Count',\n", "                 y_range=(0, 10000), x_range=DataRange1d(range_padding=0.0),\n", "                 title='Counts of %ss in %s data' % (\n", "                     var_name_pretty, ' and '.join(dataset_names)))\n", "\n", "    for dataset, dataset_name, cmap in zip(datasets, dataset_names, cmaps):\n", "        # Group date and time counts by years, months and days\n", "        grouped = pd.DataFrame(dataset[var_name_official].groupby(\n", "            [dataset[var_name_official].dt.year,\n", "             dataset[var_name_official].dt.month,\n", "             dataset[var_name_official].dt.day]).count()).rename(\n", "            columns={var_name_official: 'Count'})\n", "        # Convert MultiIndex to datetime\n", "        grouped['date'] = [datetime.datetime(*i) for i in grouped.index]\n", "        # Determine left, right and bottom coordinates of each bar in the plot\n", "        grouped['left'] = grouped['date'] - datetime.timedelta(days=0.5)\n", "        grouped['right'] = grouped['date'] + datetime.timedelta(days=0.5)\n", "        grouped['bottom'] = [0] * grouped.shape[0]\n", "        # Set date as the new index\n", "        grouped.index = grouped['date']\n", "        # Create additional 'time' variable, which is shown in hover tooltip\n", "        grouped['time'] = grouped['date'].map(lambda x: x.strftime('%d %B %Y (%A)'))\n", "        grouped = grouped.sort_index()  # Sort just in case\n", "        # Create colors for bars based on bar height\n", "        norm = colors.Normalize(vmax=grouped['Count'].max(),\n", "                                vmin=grouped['Count'].min() - 2 * grouped['Count'].min())\n", "        bar_colors = [colors.rgb2hex(cmap(norm(c))) for c in grouped['Count']]\n", "        # Draw one bar for each date\n", "        fig.quad(top='Count', bottom='bottom', left='left', right='right',\n", "                 source=ColumnDataSource(grouped), color=bar_colors,\n", "                 legend=dataset_name.capitalize())\n", "    fig.legend.location = 'bottom_right'\n", "    show(fig)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "9d7e0a6c-31f4-4427-8448-20d60ffe682e", "_uuid": "c9223476902f5e216650c02bce83860982a047c9"}, "source": ["By looking at the above plots, we can make some interesting observations:\n", "* The time span of training and testing data is the same: from January 1st 2016 to June 30th 2016, except that there are also 127 drop-off counts on July 1st 2016.\n", "* There are records for each day during the mentioned time span.\n", "* There is a clear periodic pattern each month: the number of records grows from Monday to Saturday, which then drops on Sunday.\n", "* There is a big drop in records on January 23rd and 24th. After a quick web search, an explanation for the drop is found as it turns out that a [historic snowstorm](https://en.wikipedia.org/wiki/January_2016_United_States_blizzard) paralyzed travel across the eastern United States, leading to a declaration of travel ban in New York on January 23-24. Note that there is a danger of model overfitting to this sudden and \"random\" drop, if the model was built with this 2016 data only.\n", "* There is also a small drop in taxi trip counts on May 30th, which might have been caused by [Memorial Day](https://en.wikipedia.org/wiki/Memorial_Day).  \n", "\n", "Let's further study the counts of `\"pickup_datetime`\" and `\"dropoff_datetime\"` by grouping them by months."]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "727e5d67-c0dd-4016-ac8a-8026d015fc15", "_uuid": "7e0c5be74ad09da501b1c8d7efc1d90a77caa1ce"}, "source": ["figs = []\n", "for var_name_pretty, var_name_official, datasets, dataset_names, cmaps in zip(\n", "        [\"pickup month\", \"drop-off month\"],\n", "        [\"pickup_datetime\", \"dropoff_datetime\"],\n", "        # \"dropoff_datetime\" is not included in the testing data\n", "        [[train, test], [train]], [['train', 'test'], ['train']],\n", "        [[cm.get_cmap('binary'), cm.get_cmap('TaxiYellow')], [cm.get_cmap('binary')]]):\n", "\n", "    fig = figure(plot_width=410, plot_height=400, x_axis_type=\"datetime\",\n", "                 tools=('wheel_zoom, pan, save, tap, reset',\n", "                        HoverTool(tooltips=[(var_name_pretty.capitalize(), '@time'),\n", "                                            ('Count', '@Count')])),\n", "                 x_axis_location='below', toolbar_location=\"right\", logo=None,\n", "                 x_axis_label=var_name_pretty.capitalize(), y_axis_label='Count',\n", "                 y_range=(0, 270000), x_range=DataRange1d(range_padding=0.0),\n", "                 title='Counts of %ss in %s data' % (\n", "                     var_name_pretty, ' and '.join(dataset_names)))\n", "\n", "    for dataset, dataset_name, cmap in zip(datasets, dataset_names, cmaps):\n", "        # Group date and time counts by months\n", "        grouped = pd.DataFrame(dataset[var_name_official].groupby(\n", "            dataset[var_name_official].dt.month).count()).rename(\n", "            columns={var_name_official: 'Count'})\n", "        # Convert MultiIndex to datetime\n", "        grouped['date'] = [datetime.datetime(year=2016, month=i, day=1) for i in grouped.index]\n", "        # Determine left, right and bottom coordinates of each bar in the plot\n", "        grouped['left'] = grouped['date']\n", "        grouped['right'] = [d + datetime.timedelta(calendar.monthrange(2016, d.month)[1])\n", "                            for d in grouped['date']]\n", "        grouped['bottom'] = [0] * grouped.shape[0]\n", "        # Set date as the new index\n", "        grouped.index = grouped['date']\n", "        # Create additional 'time' variable, which is shown in hover tooltip\n", "        grouped['time'] = grouped['date'].map(lambda x: x.strftime('%B %Y'))\n", "        grouped = grouped.sort_index()  # Sort just in case\n", "        # Create colors for bars based on bar height\n", "        norm = colors.Normalize(vmax=grouped['Count'].max(),\n", "                                vmin=grouped['Count'].min() - 1 * grouped['Count'].min())\n", "        bar_colors = [colors.rgb2hex(cmap(norm(c))) for c in grouped['Count']]\n", "        # Draw one bar for each month\n", "        fig.quad(top='Count', bottom='bottom', left='left', right='right',\n", "                 source=ColumnDataSource(grouped), color=bar_colors,\n", "                 legend=dataset_name.capitalize())\n", "    fig.legend.location = 'bottom_left'\n", "    figs.append(fig)\n", "show(row(figs))"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "cd864775-2a61-437d-aa8a-b38c170bd068", "_uuid": "63c5ca02ac57d8cb387dde382c9d7742e17c1821"}, "source": ["The above plots show that the number of taxi trips is the lowest in January and highest in March. It is difficult to say what are the factors behind this monthly difference in taxi trip counts, but I would guess that vacations and weather conditions could have something to do with this. Also, the January taxi trip counts are ~10,000 trips lower than normal because of the snowstorm.\n", "\n", "Let's continue by grouping the counts of `\"pickup_datetime`\" and `\"dropoff_datetime\"` by hours."]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "9f38a629-57da-4c67-9343-ca200957b225", "_uuid": "b7b8b7c8b88b91852ef5b594910a1d9fdd5f9279"}, "source": ["for var_name_pretty, var_name_official, datasets, dataset_names, cmaps in zip(\n", "        [\"pickup hour\", \"drop-off hour\"],\n", "        [\"pickup_datetime\", \"dropoff_datetime\"],\n", "        # \"dropoff_datetime\" is not included in the testing data\n", "        [[train, test], [train]], [['train', 'test'], ['train']],\n", "        [[cm.get_cmap('binary'), cm.get_cmap('TaxiYellow')], [cm.get_cmap('binary')]]):\n", "\n", "    fig = figure(plot_width=820, plot_height=400,\n", "                 tools=('wheel_zoom, pan, save, tap, reset',\n", "                        HoverTool(tooltips=[(var_name_pretty.capitalize(), '$index'),\n", "                                            ('Count', '@Count')])),\n", "                 x_axis_location='below', toolbar_location=\"above\", logo=None,\n", "                 x_axis_label=var_name_pretty.capitalize(), y_axis_label='Count',\n", "                 x_range=(-0.5, 23.5), y_range=(0, 99999),\n", "                 title='Counts of %ss in %s data' % (\n", "                     var_name_pretty, ' and '.join(dataset_names)))\n", "\n", "    for dataset, dataset_name, cmap in zip(datasets, dataset_names, cmaps):\n", "        # Group date and time counts by hours\n", "        grouped = pd.DataFrame(dataset[var_name_official].groupby(\n", "            [dataset[var_name_official].dt.hour]).count()).rename(\n", "            columns={var_name_official: 'Count'})\n", "        # Determine left, right and bottom coordinates of each bar in the plot\n", "        grouped['left'] = grouped.index - 0.5\n", "        grouped['right'] = grouped.index + 0.5\n", "        grouped['bottom'] = [0] * grouped.shape[0]\n", "        # Create colors for bars based on bar height\n", "        norm = colors.Normalize(vmax=grouped['Count'].max(),\n", "                                vmin=grouped['Count'].min() - 7 * grouped['Count'].min())\n", "        bar_colors = [colors.rgb2hex(cmap(norm(c))) for c in grouped['Count']]\n", "        # Draw one bar for each hour\n", "        fig.quad(top='Count', bottom='bottom', left='left', right='right',\n", "                 source=ColumnDataSource(grouped), color=bar_colors,\n", "                 legend=dataset_name.capitalize())\n", "    fig.legend.location = 'top_left'\n", "    show(fig)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "6d1ee20e-2b16-481c-87f2-aff951b3a343", "_uuid": "14ed7ce30a9eac69ded67bc7dd4fd370366efdde"}, "source": ["The above bar charts show that the number of tax trips rapidly rises when people travel to work in the morning between 6 a.m. and 8 a.m. From 8 a.m. to 5 p.m. the number of taxi trips continues to grow, but with a greatly smaller rate. There is a slight drop in the taxi trips at 4 p.m. perhaps because of traffic. The taxi trip counts peak at 6-7 p.m. when other people are going home from work and some are going out to enjoy the evening. Taxi usage starts to slowly decrease from 8 p.m. to 10 p.m., after which the decrease continues with greater rate from 11 p.m. to 5 a.m..\n", "\n", "Next, let's visualize the taxi trip durations with histograms and a box plot."]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "d217cade-7732-4853-b90b-75dd69efaae7", "_uuid": "cac3167d9484da8de977d98bb9a35825919da65e"}, "source": ["trip_dur_mins = train['trip_duration'] / 60\n", "figs = []\n", "for var, var_name, y_range in zip([trip_dur_mins, np.log10(trip_dur_mins)],\n", "                                  [\"Trip duration (minutes)\", \"Log10(Trip duration (minutes))\"],\n", "                                  [(0, 15e5), (0, 2.5e5)]):\n", "    # Calculate histogram\n", "    counts, bin_edges = np.histogram(var, bins=50)\n", "    # Generate colors for the histogram bars\n", "    colormap = cm.get_cmap('hot')\n", "    norm = colors.Normalize(vmax=np.max(np.array(counts)) + .5 * np.max(np.array(counts)),\n", "                            vmin=np.min(np.array(counts)))\n", "    hist_colors = [colors.rgb2hex(colormap(norm(n_vals))) for n_vals in counts]\n", "    source = ColumnDataSource(data=dict(top=counts, bottom=[0] * counts.size,\n", "                                        left=bin_edges[:-1], right=bin_edges[1:]))\n", "    fig = figure(width=410, height=300,\n", "                 tools=('wheel_zoom', 'pan', 'save, tap, reset', HoverTool(\n", "                     tooltips=[(var_name.replace(\" (minutes)\", \"\"),\n", "                                \"@left-@right\"), (\"Count\", \"@top\")])),\n", "                 x_axis_location='below', toolbar_location=\"right\", logo=None,\n", "                 x_axis_label=var_name, y_axis_label='Count', y_range=y_range,\n", "                 title=\"Histogram of %s\" % var_name.lower())\n", "    fig.quad(source=source, top='top', right='right', left='left', bottom='bottom',\n", "             color=hist_colors)\n", "    figs.append(fig)\n", "show(row(figs))\n", "\n", "# Plot the beginning of a boxplot of the original, non-normalized data\n", "# to realize the skewness of the distribution\n", "ax = plt.figure(figsize=(14.1, 3)).add_subplot(111)\n", "boxplot = ax.boxplot(trip_dur_mins, vert=False, patch_artist=True, showfliers=False)\n", "ax.set(xlabel='Minutes', ylabel='Trip duration', xlim=(-5, 40))\n", "ax.get_yaxis().set_ticks([])\n", "for item in ['boxes', 'whiskers', 'fliers', 'caps']:\n", "        plt.setp(boxplot[item], color=COLOR_DARK, linewidth=1.5)\n", "plt.setp(boxplot[\"medians\"], color=COLOR_YELLOW, linewidth=3)\n", "plt.title(\"Box plot of trip duration (minutes) without large outliers.\", size=14)\n", "plt.show();\n", "\n", "# Print some statistics\n", "print(\"The duration of %i %% of the taxi trips was less than 35 minutes.\" % \n", "      (100 * np.where(trip_dur_mins < 35)[0].size / train['trip_duration'].size))\n", "print(\"The median taxi trip duration was %i minutes.\" % trip_dur_mins.median())\n", "print(\"The shortest taxi trip duration was %i second.\" % train['trip_duration'].min())\n", "print(\"The longest taxi trip duration was %i days and %i hours.\" % (\n", "    np.floor(trip_dur_mins.max() / (60 * 24)),\n", "    np.floor(trip_dur_mins.max() / (60 * 24) % 1 * 24)))"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "23268f02-49e1-4cb0-a6e8-7a004ed628e7", "_uuid": "23287a33e391d8e50defe002046acb7ae03e1481"}, "source": ["In the leftmost histogram, there is only one bar visible. There actually are other bars as well, but they are so tiny that we cannot see them without zooming in. This is due to the fact that the distribution of trip duration is [positively skewed](https://en.wikipedia.org/wiki/Skewness). It means that the majority of the taxi trips lasted a short time (<35 minutes), but there were exceptions where the trip lasted much longer such as the longest trip, which took 40 days and 19 hours (this must be an error in the data). Now, in the histogram on the right-hand side, there is $\\log_{10}$ transformed version of the same variable. Its distribution of values looks more normally distributed, which is one of the key assumptions of many methods in statistics. Because it is difficult to interpret log-transformed values, there is also a box plot of the non-transformed trip durations without outliers plotted under the histograms.\n", "\n", "Next, let's use an interactive Folium map to visualize pickup and drop-off locations in the training data by plotting their clusters found by density based clustering algorithm [DBSCAN](https://en.wikipedia.org/wiki/DBSCAN). To speed up the computation, let's round latitudes and longitudes to four decimal places and remove duplicated entries. [By rounding to four decimal places, we lose around 11 meters in accuracy](https://en.wikipedia.org/wiki/Decimal_degrees). There are two hyperparameters in DBSCAN that we need to specify: `eps` and `min_samples`. `eps` or epsilon ($\\epsilon$) or radius defines the maximum distance between two samples for them to be considered as in the same cluster. `min_samples` is the number of samples in a neighborhood for a point to be considered as a core point (point at the interior of a cluster). There are approaches for choosing values for these hyperparameters, but here, they were chosen (`eps` = 400 meters, `min_samples` = 0.08 % of samples) by combining intuition and interpretation of the results. "]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "5a45a9fc-a906-4b14-b54a-d3d785c3f8a3", "_uuid": "3620623eba5b1ba14363f5ae273b24147371e8ec"}, "source": ["KMS_PER_RADIAN = 6371.0088\n", "ROUND_DECIMALS = 4\n", "\n", "def get_centermost_point(cluster):\n", "    centroid = (MultiPoint(cluster).centroid.x, MultiPoint(cluster).centroid.y)\n", "    centermost_point = min(cluster, key=lambda point: great_circle(point, centroid).m)\n", "    return tuple(centermost_point)\n", "\n", "map_osm = folium.Map(location=[40.730610, -73.935242], zoom_start=11, tiles='cartodbpositron')\n", "\n", "for var_descr, var_names, color, icon in zip(\n", "        [\"Pickup location\", \"Drop-off location\"],\n", "        [[\"pickup_latitude\", \"pickup_longitude\"], [\"dropoff_latitude\", \"dropoff_longitude\"]],\n", "        [\"orange\", \"black\"], [\"arrow-up\", \"arrow-down\"]):\n", "    print(\"Rounding to %i decimal places and removing duplicates from %s data.\" % (\n", "        ROUND_DECIMALS, var_descr.lower()))\n", "    train_copy = train.copy()  # Let's leave the original untouched\n", "    train_copy[var_names] = train_copy[var_names].round(ROUND_DECIMALS)\n", "    coords = train_copy[var_names].drop_duplicates()\n", "    print(\"Kept %.1f %% of the %s data.\" % (100 * coords.shape[0] / train_copy.shape[0],\n", "                                            var_descr.lower()))\n", "    db = DBSCAN(eps=0.4 / KMS_PER_RADIAN, min_samples=0.0008*coords.shape[0], algorithm='ball_tree',\n", "                metric='haversine', n_jobs=-1).fit(np.radians(coords.as_matrix()))\n", "    # There is one cluster for noisy examples, labeled as -1 \n", "    n_clusters = (len(set(db.labels_)) - 1 if -1 in db.labels_ else\n", "                  len(set(db.labels_)))\n", "    print('Found {} {} clusters.\\n-----------------------------------'.format(\n", "        n_clusters, var_descr.lower()))\n", "    clusters_coords = [coords[db.labels_ == n] for n in range(n_clusters)]\n", "    # Find the point in each cluster that is closest to its centroid\n", "    centermost_points = [get_centermost_point(list(c.itertuples(index=False))) for\n", "                         c in clusters_coords]\n", "    clusters_with_all_orig_data = [pd.merge(train_copy, c, how='inner', on=var_names)\n", "                                   for c in clusters_coords]\n", "    for i, ((lat, lng), c) in enumerate(zip(centermost_points, clusters_with_all_orig_data)):\n", "        \n", "        popup = folium.Popup(folium.IFrame(html=\"\"\"\n", "        <head>\n", "          <style> body {{ font-family: sans-serif, helvetica, arial; font-size: 14px; }} </style>\n", "        </head>\n", "        <body>\n", "          <p><b>{var_name} cluster no.</b> {cluster_ix}</p>\n", "          <p><b>Nr. of examples in cluster</b>: {n_examples:9,}</p>\n", "          <p><b>Average number of passengers</b>: {avg_pass}</p>\n", "          <p><b>Median trip duration (minutes)</b>: {avg_trip_dur}</p>\n", "          <p><b>Most common {pickup_or_dropoff} hour</b>: {pickup_h}</p>\n", "        </body>\n", "        \"\"\".format(\n", "            var_name=var_descr, cluster_ix=i + 1, n_examples=c.shape[0],\n", "            avg_pass=np.round(c[\"passenger_count\"].mean(), 1),\n", "            avg_trip_dur=np.round((c[\"trip_duration\"] / 60).median(), 1),\n", "            pickup_or_dropoff=var_names[0].split('_')[0],\n", "            pickup_h=np.bincount(np.array([dt.hour for dt in c[\n", "                \"%s_datetime\" % var_names[0].split('_')[0]]])).argmax()),\n", "            width=290, height=165))\n", "        \n", "        [folium.Marker([lat, lng], popup=popup, icon=folium.Icon(color=color, icon=icon)).add_to(map_osm)]\n", "map_osm"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "8245b353-b9f8-411f-b281-4b2ed2ebebb9", "_uuid": "cd62a8f6c4bba22160526d81ef76ae447525be30"}, "source": ["On the map above, the yellow markers stand for pickup location cluster center points and the black markers stand for drop-off location cluster center points. The markers can be clicked to see summary statistics calculated from all the trips in the original data belonging to that particular cluster.\n", "\n", "We can make the following observations about the clusters:\n", "* There are clusters in three airports:\n", "    * Newark Liberty International Airport (the westernmost marker)\n", "    * John F. Kennedy International Airport (the southernmost marker)\n", "    * LaGuardia Airport (in the northeast)\n", "* Afternoon is the most popular drop-off time at the airports.\n", "* Evening is the most popular pickup time at the airports. \n", "* In the center of the Manhattan, there is a pickup and drop-off cluster with median trip duration around 10 minutes. These clusters are clearly the biggest clusters with trip counts being more than million. The number of taxi trips is less than 100,000 in all the other clusters.\n", "* South of Manhattan, there are three pickup clusters with most common pickup hour between 23-02. I'm not familiar with the boroughs of New York City, but I would guess that people go to enjoy their evenings around these clusters.\n", "* East of Manhattan, there is a pickup cluster with most popular pickup time at 7 a.m.. Perhaps this is a popular residential area where people often take a taxi to work in the morning."]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 4. Conclusions\n", "\n", "In this notebook, we saw how valuable and intriguing insights can be drawn from the data by simply visualizing the individual variables. The analysis provides a good starting point for further exploration. If one were to continue the visualization process, the next step would be to study variable-variable interactions to better understand the underlying mechanisms of the New York City taxi network. "]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "405e6aea-ae0f-42f4-8729-a89364e2e47d", "_uuid": "cb265f439a9316d9d91f95b903fb75e2cc6e064e"}, "source": ["# 5. References\n", "\n", "* [Geoff Boeing: Clustering to Reduce Spatial Data Set Size](http://geoffboeing.com/2014/08/clustering-to-reduce-spatial-data-set-size/)\n", "* Icons in the banner have been made by Freepik ([www.flaticon.com](www.flaticon.com))"]}], "nbformat_minor": 1, "nbformat": 4, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.1", "file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}, "celltoolbar": "Tags"}}