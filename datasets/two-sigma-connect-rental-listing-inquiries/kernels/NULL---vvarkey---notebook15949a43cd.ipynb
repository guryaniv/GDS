{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6f738121-4bd4-0977-6b58-970ca69a8a63"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import scipy\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "df=pd.read_json(\"../input/train.json\")\n",
        "df['priceperbed']=(df['price'].clip(upper=7000)/df['bedrooms'].clip(lower=1))\n",
        "df['created']=df['created'].astype(np.datetime64)\n",
        "df['created_day']=np.array(df.created.values, dtype='datetime64[D]').astype(np.float32)%7\n",
        "df['created_week']=np.array(df.created.values, dtype='datetime64[W]').astype(np.float32)\n",
        "df['created_hour']=np.array(df.created.values, dtype='datetime64[h]').astype(np.float32)%24\n",
        "df['desc_count']=df.description.apply(lambda x: len(x.split())).clip(upper=150)\n",
        "df['features_count']=df.features.apply(lambda x: len(x))\n",
        "df['photos_count']=df.photos.apply(lambda x: len(x))\n",
        "\n",
        "lbl = preprocessing.LabelEncoder()\n",
        "lbl.fit(list(df['manager_id'].values))\n",
        "df['manager_id'] = lbl.transform(list(df['manager_id'].values))\n",
        "\n",
        "feature_list=['no fee', 'hardwood floors', 'laundry in building']\n",
        "df['features']=df['features'].apply(lambda x: list(map(str.lower, x)))\n",
        "for feature in feature_list:\n",
        "        df[feature]=df['features'].apply(lambda x: feature in x)\n",
        "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
        "                                 stop_words='english')\n",
        "vectorizer.fit(df.description.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cccba8ab-9d7b-96bb-1872-8841233d1575"
      },
      "outputs": [],
      "source": [
        "df_tv, df_test = train_test_split(df, random_state=0)\n",
        "df_train, df_val = train_test_split(df_tv, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cc507f39-b701-dd3c-24e1-d5f45a9d298f"
      },
      "outputs": [],
      "source": [
        "cols=['price', 'bathrooms', 'bedrooms', 'latitude', 'longitude', 'desc_count', 'priceperbed',\n",
        "      'photos_count', 'features_count', 'created_hour', 'no fee', 'hardwood floors', 'laundry in building']\n",
        "\n",
        "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
        "X_train = svd.fit_transform(vectorizer.transform(df_train.description))\n",
        "X_train=np.hstack([X_train, df_train[cols].values])\n",
        "X_val = svd.transform(vectorizer.transform(df_val.description))\n",
        "X_val=np.hstack([X_val, df_val[cols].values])\n",
        "X_test = svd.transform(vectorizer.transform(df_test.description))\n",
        "X_test=np.hstack([X_test, df_test[cols].values])\n",
        "clf=ExtraTreesClassifier(max_depth=23, n_estimators=1000,\n",
        "                             min_samples_split=10, random_state=0) \n",
        "clf.fit(X_train, df_train['interest_level'])\n",
        "y_pred=clf.predict_proba(X_train)\n",
        "score=log_loss(df_train['interest_level'].values, y_pred)\n",
        "y_pred=clf.predict_proba(X_val)\n",
        "score2=log_loss(df_val['interest_level'].values, y_pred)\n",
        "y_pred=clf.predict_proba(X_test)\n",
        "score3=log_loss(df_test['interest_level'].values, y_pred)\n",
        "print(\"%.6f %.6f %.6f\"%(score, score2, score3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "969af18c-b6ae-df96-aaf1-4a61374d8ab6"
      },
      "outputs": [],
      "source": [
        "cols=['price', 'bathrooms', 'bedrooms', 'latitude', 'longitude', 'desc_count', 'priceperbed',\n",
        "      'photos_count', 'features_count', 'manager_id', 'created_hour', 'no fee', 'hardwood floors', 'laundry in building']\n",
        "\n",
        "X_train = svd.transform(vectorizer.transform(df_train.description))\n",
        "X_train=np.hstack([X_train, df_train[cols].values])\n",
        "X_val = svd.transform(vectorizer.transform(df_val.description))\n",
        "X_val=np.hstack([X_val, df_val[cols].values])\n",
        "X_test = svd.transform(vectorizer.transform(df_test.description))\n",
        "X_test=np.hstack([X_test, df_test[cols].values])\n",
        "clf=ExtraTreesClassifier(max_depth=23, n_estimators=1000,\n",
        "                             min_samples_split=10, random_state=0) \n",
        "clf.fit(X_train, df_train['interest_level'])\n",
        "y_pred=clf.predict_proba(X_train)\n",
        "score=log_loss(df_train['interest_level'].values, y_pred)\n",
        "y_pred=clf.predict_proba(X_val)\n",
        "score2=log_loss(df_val['interest_level'].values, y_pred)\n",
        "y_pred=clf.predict_proba(X_test)\n",
        "score3=log_loss(df_test['interest_level'].values, y_pred)\n",
        "print(\"%.6f %.6f %.6f\"%(score, score2, score3))"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}