{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nimport time\nimport s2sphere\nfrom calendar import timegm\n\nfrom keras.layers import Dense, Input, Dropout\nfrom keras.models import Model\nfrom keras import regularizers\n\n# from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19ef6a9577d2ccb90f02e33e616a25c92fb895dc"},"cell_type":"markdown","source":"# Feature extraction and data cleaning"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"HOURS_PER_DAY = 24\nSECONDS_PER_HOUR = 3600\nDAYS_PER_WEEK = 7\n\nSECONDS_PER_DAY = SECONDS_PER_HOUR * HOURS_PER_DAY\nSECONDS_PER_WEEK = SECONDS_PER_DAY * DAYS_PER_WEEK\n\n# coarse modeling of bottlenecks in space\nS2CELL_DEPTH = 11\n\ndef pickup_time(row):\n    utc_time = time.strptime(row[\"pickup_datetime\"], \"%Y-%m-%d %H:%M:%S UTC\")\n    return utc_time\n\ndef pickup_epoch(row):\n    return timegm(row[\"pickup_time\"])\n\ndef year(row):\n    return row[\"pickup_time\"].tm_year\n\ndef month(row):\n    return row[\"pickup_time\"].tm_mon\n\ndef day(row):\n    return row[\"pickup_time\"].tm_mday\n\ndef tod(row):\n    tod_sec = row[\"pickup_epoch\"] % SECONDS_PER_DAY\n    tod_hr = int(tod_sec // SECONDS_PER_HOUR)\n    return tod_hr\n\ndef tow_hr(row):\n    tow_sec = row[\"pickup_epoch\"] % SECONDS_PER_WEEK\n    tow_hr = int(tow_sec // SECONDS_PER_HOUR)\n    return tow_hr\n\ndef tow_day(row):\n    tow_sec = row[\"pickup_epoch\"] % SECONDS_PER_WEEK\n    tow_day = int(tow_sec // SECONDS_PER_DAY)\n    return tow_day\n\ndef distance(row):\n    lat1 = row[\"pickup_latitude\"]\n    lon1 = row[\"pickup_longitude\"]\n    lat2 = row[\"dropoff_latitude\"]\n    lon2 = row[\"dropoff_longitude\"]\n    radius = 6371 # kilometers\n\n    dlat = math.radians(lat2-lat1)\n    dlon = math.radians(lon2-lon1)\n    a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n        * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n    d = radius * c\n    return d # int(np.nan_to_num(np.round(d, 0)))\n\ndef pickup_cell_id(row):\n    geohash = ''\n    try:\n        geohash =  s2sphere.CellId.from_lat_lng(\n            s2sphere.LatLng.from_degrees(lat=row[\"pickup_latitude\"], lng=row[\"pickup_longitude\"])\n        ).parent(S2CELL_DEPTH).to_token()\n    except:\n        pass\n    return geohash\n\ndef dropoff_cell_id(row):\n    geohash = ''\n    try:\n        geohash = s2sphere.CellId.from_lat_lng(\n            s2sphere.LatLng.from_degrees(lat=row[\"dropoff_latitude\"], lng=row[\"dropoff_longitude\"])\n        ).parent(S2CELL_DEPTH).to_token()\n    except:\n        pass\n    return geohash\n\ndef enrich(df):\n    df[\"pickup_time\"] = df.apply(pickup_time, axis=1)\n    df[\"pickup_epoch\"] = df.apply(pickup_epoch, axis=1)\n    df[\"year\"] = df.apply(year, axis=1)\n    df[\"month\"] = df.apply(month, axis=1)\n    df[\"day\"] = df.apply(day, axis=1)\n    df[\"tod\"] = df.apply(tod, axis=1)\n    df[\"tow_hr\"] = df.apply(tow_hr, axis=1)\n    df[\"tow_day\"] = df.apply(tow_day, axis=1)\n    df[\"distance\"] = df.apply(distance, axis=1)\n    df[\"pickup_cell_id\"] = df.apply(pickup_cell_id, axis=1)\n    df[\"dropoff_cell_id\"] = df.apply(dropoff_cell_id, axis=1)\n    return df\n\ndef clean_dataset(x):\n    return x[(x.fare_amount>0)& (x.pickup_longitude !=0) & (x.pickup_latitude !=0) & \n            (x.dropoff_longitude !=0) &(x.dropoff_latitude !=0)]\n\ndef process(df, train=True):\n    if train:\n        #drop empty cells\n        df = df.dropna(how='any', axis='rows')\n        #removing zeros \n        df = clean_dataset(df)\n    return enrich(df)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f59fedcb6a64b086b345567811ef00c6731f4411"},"cell_type":"code","source":"cat_cols = ['pickup_cell_id', 'dropoff_cell_id', 'passenger_count', 'tod', \n            'tow_hr', 'tow_day', 'year', 'month', 'day']\nfeature_cols = cat_cols + ['distance']\nlabel_col = 'fare_amount'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db5d12e5d95722e4051aed58882838229ff032c1"},"cell_type":"markdown","source":"# Convert categorical variables into a k-hot vector\n* We first need to idenfy repeated categorical features\n* We will use 1M rows for this"},{"metadata":{"trusted":true,"_uuid":"0f9b5361d27ab808e9e98ef5730f4d59132f7906"},"cell_type":"code","source":"# Lets read 1M rows to define categorical features\nMIN_FEAT_REP = 10 # out of 1M rows the feature should at least repeat 10 times\ndf = pd.read_csv('../input/train.csv', nrows=1_000_000)\ndf = process(df)\n\nCOUNT_FEAT = {}\nfor feat in cat_cols:\n    COUNT_FEAT[feat] = {}\n    for val in df[feat]:\n        COUNT_FEAT[feat][val] = COUNT_FEAT[feat].setdefault(val, 0) + 1\n\nidx = 0\nFEAT_TO_IDX = {}\nfor feat in cat_cols:\n    FEAT_TO_IDX[feat] = {}\n    for val in df[feat].unique():\n        if COUNT_FEAT[feat][val] >= MIN_FEAT_REP:\n            FEAT_TO_IDX[feat][val] = idx\n            idx += 1\n\nNUM_CAT_FEATS = idx\nNUM_FEATS = NUM_CAT_FEATS + 1 # distance is not treated as categorical\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e96b269efb5618bacc212034cec01dbcea700b49"},"cell_type":"code","source":"del df\nimport gc; gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b689f1c1f273d838175afbc6c1e0f2613632572"},"cell_type":"markdown","source":"We have identified 456 categorical features + 1 for distance"},{"metadata":{"trusted":true,"_uuid":"6a3e506cce5021690bbc811610b408554fb036bc"},"cell_type":"code","source":"print (NUM_FEATS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62b83ebf062c3b87a0d41ef3c63f96a33f4ac7e0"},"cell_type":"code","source":"def get_labeled_feats(df):\n    if label_col in df.columns: \n        y = df[label_col].values \n    else:\n        y = None\n    X = np.zeros((df.shape[0], NUM_FEATS))\n    for i, irow in enumerate(df.iterrows()):\n        _, row = irow\n        X[i, -1] = row[\"distance\"]\n        for feat in cat_cols:\n            idx = FEAT_TO_IDX[feat].get(row[feat])\n            if idx is not None: X[i, idx] = 1.\n    return np.nan_to_num(X), np.nan_to_num(y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae089bec53ddc34c88c2de118e3429426913e67f"},"cell_type":"markdown","source":"# Define a simple DNN \n* The linear layer is the \"embedding\" layer for the categorical features"},{"metadata":{"trusted":true,"_uuid":"62a3e681c4ee08924c8471c52ba6ede42d72ee40"},"cell_type":"code","source":"inp = Input(shape=(NUM_FEATS,))\nx = Dense(128, activation=\"linear\", kernel_regularizer=regularizers.l2(0.001))(inp)\nx = Dense(64, activation=\"elu\")(x)\nx = Dense(32, activation=\"elu\")(x)\nx = Dense(16, activation=\"elu\")(x)\nx = Dense(1, activation=\"relu\")(x)\nmodel = Model(inputs=inp, outputs=x)\nmodel.compile(loss='mse', optimizer='adam', metrics=['mse'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"223b095ca6ecb3b2f62865b726a1a66e634be037"},"cell_type":"markdown","source":"# Train the DNN in batches of 1M rows\n* Use 10 epochs per batch of 500K rows"},{"metadata":{"trusted":true,"_uuid":"99585d1c765148446ef4da9b8591b19e8fd5bc24"},"cell_type":"code","source":"chunksize = 500_000\ndef process_fully(df, num_epochs=10):\n    df = process(df)\n    X, y = get_labeled_feats(df)\n    model.fit(X, y, batch_size=512, epochs=num_epochs)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78b5698d76c0de4404d5f8768c0567eda1f0540b"},"cell_type":"markdown","source":"# Apply the model on the test dataset as we train"},{"metadata":{"trusted":true,"_uuid":"8d701f3bac3a0d357f8ac75defcc04cc79766b2e"},"cell_type":"code","source":"test_df = process(pd.read_csv('../input/test.csv'), train=False)\ntest_X, _ = get_labeled_feats(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb71e64b2c5be868e74d7c662b936e17327e99cd"},"cell_type":"code","source":"for chunk in pd.read_csv('../input/train.csv', chunksize=chunksize):\n    process_fully(chunk)\n    test_y_pred = model.predict(test_X, batch_size=1024)[:, 0]\n    out_df = pd.DataFrame({\"key\": test_df[\"key\"].values})\n    out_df['fare_amount'] = test_y_pred\n    out_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57ba817e5e1fd80ede0934c10f84a861861ba159"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}