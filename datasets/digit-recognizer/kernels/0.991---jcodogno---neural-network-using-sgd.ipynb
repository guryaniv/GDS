{"metadata": {"language_info": {"version": "3.6.1", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "cells": [{"source": "import numpy as np\nimport pandas as pd\nimport sys\n\nimport matplotlib.pyplot as plt\nnp.random.seed(1070)", "metadata": {"_cell_guid": "86990557-b034-c88c-bc3e-0e0bb666606b", "_uuid": "7bcae0a7c40933c487ffa53fd08aabc8071b20ce", "_active": false, "_execution_state": "idle", "trusted": false}, "cell_type": "code", "execution_state": "idle", "execution_count": null, "outputs": []}, {"source": "df = pd.read_csv(\"../input/train.csv\")\ndata = df.as_matrix()\nnp.random.shuffle(data)\ndata_y = data[:,0].astype('float32')\ndata_x = data[:,1:].astype('float32')", "metadata": {"_active": false, "_cell_guid": "48c61204-4638-a851-06da-2e07208e7b35", "_uuid": "6c7855986fa68686cc3ef7317881a7d4b023ca0c", "collapsed": false, "_execution_state": "idle", "trusted": false}, "cell_type": "code", "execution_state": "idle", "execution_count": null, "outputs": []}, {"cell_type": "code", "outputs": [], "source": "data_y = pd.get_dummies(data_y).as_matrix()\n\nmeio = 255/2\ndata_x = (data_x-meio)/meio", "execution_count": null, "metadata": {"_uuid": "9d98b46d9d70692be12f54ca56901fda9c2b4d38", "collapsed": false, "_execution_state": "idle"}}, {"cell_type": "code", "metadata": {"_cell_guid": "3e8a4950-709d-42da-87c0-44c66304a482", "_execution_state": "idle", "collapsed": false, "_uuid": "ac332dc6b38ba3479ec0f4ad18bfb4cdba8d67e6", "trusted": false}, "source": "VALID_SIZE = round(data_x.shape[0]*0.15)\n\n\nx_train = data_x[VALID_SIZE:]\nx_valid = data_x[:VALID_SIZE]\n\nd_train = data_y[VALID_SIZE:]\nd_valid = data_y[:VALID_SIZE]\n\ndata_x = None\ndata_y = None\n\nx_train.shape\n", "outputs": [], "execution_count": 7}, {"source": "def initializationWeights():\n    ##Initialization of the Weights and the Biases with the random gaussian function with mean zeron, and variance between 1/sqtr(num_inputs_layer)\n    \n    ninputs = 784\n    wl1 = 128\n    wl2 = 64\n    nclass = 10\n    \n    mean = 0\n    \n    #layer1\n    variance = 1.0/np.sqrt(ninputs)\n    w1 = np.random.normal(mean, variance, [ninputs,wl1])\n    b1 = np.random.normal(mean, variance, [1,wl1])\n    dw1 = np.zeros([ninputs,wl1])\n    db1 = np.zeros([1,wl1])\n    \n    #Layer2\n    variance = 1.0/np.sqrt(wl1)\n    w2 = np.random.normal(mean, variance, [wl1,wl2])\n    b2 = np.random.normal(mean, variance, [1,wl2])\n    dw2 = np.zeros([wl1,wl2])\n    db2 = np.zeros([1,wl2])\n\n    #Layer3\n    variance = 1.0/np.sqrt(wl2)\n    w3 = np.random.normal(mean, variance, [wl2,nclass])\n    b3 = np.random.normal(mean, variance, [1,nclass])\n    dw3 = np.zeros([wl2,nclass])\n    db3 = np.zeros([1,nclass])\n    \n    return w1,w2,w3,b1,b2,b3,dw1,dw2,dw3,db1,db2,db3", "metadata": {"_cell_guid": "8b6b4180-318c-ce22-54e6-570055cb7777", "_uuid": "f76da0094629441448dfbd0db7a14888b564f0ed", "_active": false, "_execution_state": "idle", "trusted": false}, "cell_type": "code", "execution_state": "idle", "execution_count": null, "outputs": []}, {"source": "##Activation Function's and Cross-entropy Function\n\ndef ReLu(x, derivative=False):\n    if(derivative==False):\n        return x*(x > 0)\n    else:\n        return 1*(x > 0)\n    \ndef LReLu(x, derivative=False):\n    if(derivative==False):\n        return x*(x > 0) + 0.1*x*(x<0)\n    else:\n        return 1*(x > 0) + 0.1*(x<0)\n\ndef sigmoid(x, derivative=False):\n    if(derivative==False):\n        return 1/(1+np.exp(-x))\n    else:\n        return x*(1-x)\n       \ndef softmax(x):\n        if(x.ndim==1 or x.ndim==0):\n            e_x = np.exp(x - np.max(x))\n            return e_x/e_x.sum(axis=0)\n        else:\n            k = 0\n            x3 = np.empty((0,0))\n            for x2 in x:\n                if(k==0):\n                    x3 = np.array([softmax(x2)])\n                    k=1\n                else:\n                    x4 = softmax(x2)\n                    x3 = np.concatenate((x3,[x4]), axis=0)\n            return np.array(x3)\n\ndef cost(Y_predict, Y_right):\n    Loss = -np.mean(Y_right*np.nan_to_num(np.log(Y_predict)),keepdims=True)\n    return Loss", "metadata": {"_cell_guid": "7f2c05ac-da5c-2513-fde6-27d85ffc3956", "_uuid": "23dd420a9a47d17072c6724b869dbf6b05527c26", "_active": false, "_execution_state": "idle", "trusted": false}, "cell_type": "code", "execution_state": "idle", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "eca5943a-a56b-4b79-8572-9ae9906c28f3", "_execution_state": "idle", "collapsed": false, "_uuid": "3e6e26acabfad2028a19c585a79b9dc053112c5a", "trusted": false}, "source": "def accuracy(output, y):\n    hit = 0\n    output = np.argmax(output, axis=1)\n    y = np.argmax(y, axis=1)\n    for y in zip(output, y):\n        if(y[0]==y[1]):\n            hit += 1\n\n    p = (hit*100)/output.shape[0]\n    return p", "outputs": [], "execution_count": 10}, {"source": "def run(x_train, y_train, x_valid, y_valid, epochs = 10, nbatchs=25, alpha = 1e-3, decay = 0, momentum = 0, l2 = 0.001, DROPOUT = 0):\n  \n    pross = x_train.shape[0]*0.05\n    w1,w2,w3,b1,b2,b3,dw1,dw2,dw3,db1,db2,db3  = initializationWeights()\n    index = np.arange(x_train.shape[0])\n    \n    print(\"Train data: %d\" % (x_train.shape[0]))\n    print(\"Validation data: %d \\n\" % (x_valid.shape[0]))\n    \n    for j in range(epochs):\n        np.random.shuffle(index)\n        t = 0\n        iterations = round(x_train.shape[0]/nbatchs)\n        prog = \"\"\n        sacurr = 0\n        sloss = 0\n        sys.stdout.write(\"\\nEpochs: %2d \\ %2d \\n\"% (j+1,epochs))\n        for i in range(iterations):\n         \n            f = i*nbatchs\n            l = f+nbatchs\n            \n            if(l>(x_train.shape[0]-1)):\n                l = x_train.shape[0]\n                \n            x = x_train[index[f:l]]\n            y = y_train[index[f:l]]\n\n            #1-Hidden Layer\n       \n            first = ReLu(x.dot(w1)+b1)\n            if(DROPOUT!=1):\n                first *= np.random.binomial([np.ones_like(first)],1-DROPOUT)[0]  /(1-DROPOUT)\n            #2-Hidden Layer\n            second = ReLu(first.dot(w2)+b2)\n            if(DROPOUT!=1):\n                second *= np.random.binomial([np.ones_like(second)],1-DROPOUT)[0] / (1-DROPOUT)\n            #Output Layer\n            output = softmax(second.dot(w3)+b3)\n         \n            loss = cost(output, y)\n            \n            error = y-output\n            \n            accuracy_t = accuracy(output, y)\n            \n            sacurr += accuracy_t\n            sloss += loss\n            \n            accuracy_train = sacurr/(i+1)\n            loss_train = sloss/(i+1)\n            \n            w3_delta = error\n            \n            w2_error = w3_delta.dot(w3.T)\n            w2_delta = w2_error * ReLu(second,derivative=True)\n            \n            w1_error = w2_delta.dot(w2.T)\n            w1_delta = w1_error * ReLu(first,derivative=True)\n            \n            mew3 = np.mean(w3)\n            meb3 = np.mean(b3)\n            mew2 = np.mean(w2)\n            meb2 = np.mean(b2)\n            mew1 = np.mean(w1)\n            meb1 = np.mean(b1)\n        \n            w3 += alpha * (momentum*w3 + second.T.dot(w3_delta)) - l2 * mew3\n            b3 += alpha * (momentum*b3 + second.T.dot(w3_delta).sum(axis=0)) - l2 * meb3\n            w2 += alpha * (momentum*w2 + first.T.dot(w2_delta)) - l2 * mew2\n            b2 += alpha * (momentum*b2 + first.T.dot(w2_delta).sum(axis=0)) - l2 * meb2\n            w1 += alpha * (momentum*w1 + x.T.dot(w1_delta)) - l2 * mew1\n            b1 += alpha * (momentum*b1 + x.T.dot(w1_delta).sum(axis=0)) - l2 * meb1\n            \n            \n            \n            t+= x.shape[0]\n            \n            qtd = round(t/pross)\n            prog = \"[\"\n            for p in range(20):\n                if(p<qtd-1):\n                    prog += \"-\"\n                elif(p==qtd-1):\n                    prog += \">\"\n                else:\n                    prog += \" \"\n            prog += \"]\"\n\n           \n            sys.stdout.write(\"\\r%5d : %5d %s Train Acc.: %.4f - Train Loss: %.4f\\n\" % (x_train.shape[0],t, prog, accuracy_train, loss_train))\n        \n        alpha = alpha - (alpha*decay)\n        #1-Hidden Layer\n        first = ReLu(x_valid.dot(w1)+b1)\n        #2-Hidden Layer\n        second = ReLu(first.dot(w2)+b2)\n        #Output Layer\n        output = softmax(second.dot(w3)+b3)\n        \n        loss_valid = cost(output, y_valid)\n        accuracy_valid = accuracy(output, y_valid)\n        \n        sys.stdout.write(\"\\r%5d : %5d %s  Train Acc: %.4f - Train Loss: %.4f - Valid Acc: %.4f - Valid Loss: %.4f\\n\" % ( x_train.shape[0],t, prog, accuracy_train, loss_train, accuracy_valid, loss_valid))", "metadata": {"_cell_guid": "c421dda0-0e37-9d62-8a8d-7660befa4bdd", "_uuid": "be8bea97cddcadbc2ee018101373ff2937943a88", "_active": false, "_execution_state": "idle", "trusted": false}, "cell_type": "code", "execution_state": "idle", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "8935ff94-fd2a-4e19-9d4e-c31a47fda938", "_execution_state": "busy", "collapsed": false, "_uuid": "5cb3502552ff369cb0870625d4c11cd5282bfc7a", "trusted": false}, "source": "alpha = 1e-3\nepochs = 10\nrun(x_train, d_train, x_valid, d_valid, epochs = epochs, nbatchs=25, alpha = alpha, decay = alpha/epochs, momentum = 1e-9, l2 = 0.01, DROPOUT = 0.25)", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {"_cell_guid": "1d4f8fc7-1ae7-4e7a-b91f-a48ba27f5ea5", "_execution_state": "idle", "collapsed": false, "_uuid": "cad2c3ae5c3e9cc397c3d86704efbb17409996e4", "trusted": false}, "source": "", "outputs": [], "execution_count": null}], "nbformat_minor": 0, "nbformat": 4}