{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cb76d8af-c47e-e251-9bcd-f5c10060b0f3"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "\n",
        "import time\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,AdaBoostClassifier, IsolationForest\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict,cross_val_score,train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,auc,precision_recall_curve\n",
        "\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "03532c3e-8e8b-f641-7837-125ca2a38cfc"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"../input/creditcard.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "492c144f-3337-109a-eb2a-b31d1ed45731"
      },
      "outputs": [],
      "source": [
        "## add time stamps\n",
        "df['hour'] = df['Time'].apply(lambda x: np.ceil(float(x)/3600) % 24)\n",
        "## rescale amount\n",
        "## data pre processing\n",
        "df[\"Normalized Amount\"] = (df[\"Amount\"]-np.mean(df[\"Amount\"]))/np.std(df[\"Amount\"])\n",
        "df.drop([\"Time\",\"Amount\"],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ae0d8e45-8e7d-8fe1-5f47-75ed2de42f21"
      },
      "outputs": [],
      "source": [
        "def oversample(df_x,frauds,nonfrauds,percent):\n",
        "    n_nonfrauds = len(nonfrauds)\n",
        "    oversample_frauds_indices = np.array(np.random.choice(frauds,round(percent*n_nonfrauds),replace =True))\n",
        "    oversample_indices = np.concatenate([np.array(nonfrauds),oversample_frauds_indices])\n",
        "    print(\"We have\", round(percent*n_nonfrauds),\" fraud cases\" )\n",
        "    print(\"We have\", (n_nonfrauds) ,\"non fraud cases\" )\n",
        "    oversample = df_x.iloc[oversample_indices]\n",
        "    return oversample "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5f76e5fd-cd0f-59b0-dcc0-b2896868bf18"
      },
      "outputs": [],
      "source": [
        "def sample_split(df,times):\n",
        "    df_label = df.Class\n",
        "    df_feature = df.drop(\"Class\", axis= 1)\n",
        "    data_features_train,data_features_test,data_labels_train,data_labels_test=train_test_split(df_feature, df_label,test_size=0.3)\n",
        "    df_train = np.concatenate( [data_features_train,data_labels_train])\n",
        "    frauds = np.array(df[df.Class == 1].index)\n",
        "    nonfrauds = np.array(df[df.Class == 0].index)\n",
        "    \n",
        "    sample_data = oversample(df,frauds,nonfrauds,times)\n",
        "    sample_label = sample_data.Class\n",
        "    sample_feature = sample_data.drop(\"Class\", axis= 1)\n",
        "    \n",
        "    sample_features_train,sample_features_test,sample_labels_train,sample_labels_test = train_test_split(sample_feature,sample_label,test_size=0.3)\n",
        "    return [sample_features_train,sample_features_test,sample_labels_train,sample_labels_test,data_features_train,data_features_test,data_labels_train,data_labels_test]\n",
        "def choose_supervised_model(model):\n",
        "    if model == \"LR\":\n",
        "        print(\"Logsitic regression model\")   \n",
        "        clf=LogisticRegression()\n",
        "    elif model == \"SVC\":\n",
        "        print(\"SVC model\")   \n",
        "        clf = LinearSVC()\n",
        "    elif model == \"RF\":\n",
        "        print(\"Random Forest model\")   \n",
        "        clf = RandomForestClassifier(n_estimators=100)\n",
        "    return clf\n",
        "def report_oversample(df,model):\n",
        "    for i in [0.01,0.5,1.00,1.50,1.80,2.0]:\n",
        "        print(\"ratio\", i)\n",
        "        print()\n",
        "        sample_features_train,sample_features_test,sample_labels_train,sample_labels_test,data_features_train,data_features_test,data_labels_train,data_labels_test= sample_split(df,i)\n",
        "        clf = choose_supervised_model(model)\n",
        "        clf.fit(sample_features_train,sample_labels_train)\n",
        "        pred=clf.predict(data_features_test)\n",
        "        print() \n",
        "        print(classification_report(data_labels_test,pred))\n",
        "        print(\"======================================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f291c3ac-fdf7-ab6b-8bff-0f6a40b5dc43"
      },
      "outputs": [],
      "source": [
        "report_oversample(df,\"RF\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9ed5f182-9343-462d-beea-88bec6c97654"
      },
      "outputs": [],
      "source": [
        "df_label = df.Class\n",
        "df_feature = df.drop(\"Class\", axis= 1)\n",
        "data_features_train,data_features_test,data_labels_train,data_labels_test=train_test_split(df_feature, df_label,test_size=0.3)\n",
        "df_train = np.concatenate( [data_features_train,data_labels_train])\n",
        "frauds = np.array(df[df.Class == 1].index)\n",
        "nonfrauds = np.array(df[df.Class == 0].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f011397d-bd48-6135-be9e-2d9a055be035"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}