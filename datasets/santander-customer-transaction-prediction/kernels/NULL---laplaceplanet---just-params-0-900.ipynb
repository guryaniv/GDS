{"cells":[{"metadata":{"trusted":true,"_uuid":"d3ba6b92d9d2d9af850069d509df132a7455efe6"},"cell_type":"code","source":"from sklearn.model_selection import KFold,StratifiedKFold,KFold\nfrom scipy.stats import norm, rankdata\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\nimport pandas as pd\nimport time\nimport gc\nrandom_state = 13\nnp.random.seed(random_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c30bd0719c6b88728dbe1d3a5d679700362f6a4"},"cell_type":"code","source":"print('read data')\ndf_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')\nlen(df_train[df_train.target == 1]) / len(df_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12911c2e1f0862189c85974e314b25638cfbb1af"},"cell_type":"code","source":"df_train = df_train.round(3)\ndf_test = df_test.round(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab8e3e0ef862c6ce8447be14f9f43c8513a7596c"},"cell_type":"code","source":"df_train_one = df_train[df_train.target == 1]\ndf_train_zero = df_train[df_train.target == 0]\none_mean = df_train_one.describe().loc['mean'] \nzero_mean = df_train_zero.describe().loc['mean'] \ndiff = one_mean - zero_mean\ntop_features = [c for c in (diff.sort_values().head(5).index)] \ntail_features = [c for c in diff.sort_values().tail(5).index] \nimp_features = top_features + tail_features\ntop_mean = [c for c in (diff.sort_values().head(5).values)] \ntail_mean = [c for c in diff.sort_values().tail(5).values] \nimp_mean = top_mean + tail_mean\nprint(imp_mean)\nprint(imp_features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"test_ID = df_test['ID_code'].values\nY = df_train.target.values.astype(np.float32)\ntarget = df_train.target\ndf_train = df_train.drop(['ID_code','target'], axis=1)\ndf_test = df_test.drop(['ID_code'], axis=1)\noriginal_features = df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b260b2d3e842a278e946747cb71fe39ac22c228"},"cell_type":"code","source":"# len_train = len(df_train)\n# merged = pd.concat([df_train, df_test])\n# del df_test, df_train\n# gc.collect()\n# for col in imp_features:\n#     # Normalize the data, so that it can be used in norm.cdf(), \n#     # as though it is a standard normal variable\n#     merged[col] = ((merged[col] - merged[col].mean()) \n#     / merged[col].std()).astype('float32')\n#     # Square\n#     merged[col+'^2'] = merged[col] * merged[col]\n#     # Cube\n#     merged[col+'^3'] = merged[col] * merged[col] * merged[col]\n#     # 4th power\n#     merged[col+'^4'] = merged[col] * merged[col] * merged[col] * merged[col]\n#     # Cumulative percentile (not normalized)\n#     merged[col+'_cp'] = rankdata(merged[col]).astype('float32')\n#     # Cumulative normal percentile\n#     merged[col+'_cnp'] = norm.cdf(merged[col]).astype('float32')\n    \n# important features statics information\n# merged['imp_features_mean'] = merged[imp_features].mean(axis = 1)\n# merged['imp_features_sum'] = merged[imp_features].sum(axis = 1)\n# merged['imp_features_max'] = merged[imp_features].max(axis = 1)\n# merged['imp_features_min'] = merged[imp_features].min(axis = 1)\n# merged['imp_features_var'] = merged[imp_features].var(axis = 1)\n# merged['imp_features_median'] = merged[imp_features].median(axis = 1)\n\n# # all features statics information\n# merged['all_features_mean'] = merged.mean(axis = 1)\n# merged['all_features_sum'] = merged.sum(axis = 1)\n# merged['all_features_max'] = merged.max(axis = 1)\n# merged['all_features_min'] = merged.min(axis = 1)\n# merged['all_features_var'] = merged.var(axis = 1)\n# merged['all_features_median'] = merged.median(axis = 1)\n\n# + - * /\n# for i in range(len(imp_features)):\n#     for j in range(i+1,len(imp_features)):\n#         merged[imp_features[i] + 'minus' + imp_features[j]] = merged[imp_features[i]] - merged[imp_features[j]]  \n#         merged[imp_features[i] + 'plus' + imp_features[j]] = merged[imp_features[i]] + merged[imp_features[j]]  \n#         merged[imp_features[i] + 'multi' + imp_features[j]] = merged[imp_features[i]] * merged[imp_features[j]]  \n#         merged[imp_features[i] + 'divide' + imp_features[j]] = merged[imp_features[i]] / merged[imp_features[j]]  \n        \n# new_features = set(merged.columns) - set(original_features)\n# for col in imp_features:\n#     merged[col] = ((merged[col] - merged[col].mean()) \n#     / merged[col].std()).astype('float32')\n# df_train = merged.iloc[:len_train]\n# df_test = merged.iloc[len_train:]\n# df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d76c60b6b420bca5858f7b65cbbed1c658ff79ac"},"cell_type":"code","source":"# for df in [df_train,df_test]:\n#     for col in imp_features:\n#         df[col + '_category'] = df[col].round(0).astype('category')\n# category_features = [col + '_category' for col in imp_features]\n# df_train[category_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a4131ef9f72834975b66cdebda09b477afa2d90"},"cell_type":"code","source":"# # count features\n# for df in[df_train,df_test]:\n#     df['positive'] = df.apply(lambda x: sum(x > 0),axis = 1)\n#     df['negative'] = df.apply(lambda x: sum(x < 0),axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# param = {\n#     \"objective\" : \"binary\",\n#     \"metric\" : 'auc',\n#     \"max_depth\" : 2,\n#     \"num_leaves\" : 2,\n#     \"learning_rate\" : 0.055,\n#     \"bagging_fraction\" : 0.3,\n#     \"feature_fraction\" : 0.15,\n#     \"lambda_l1\" : 5,\n#     \"lambda_l2\" : 5,\n#     \"bagging_seed\" : 42,\n#     \"verbosity\" : 1,\n#     \"random_state\": 4950 \n# }\nparam = {\n    \"objective\" : \"binary\",\n    \"metric\" : 'auc',\n#      'boost' : \"gbdt\",\n    'boost_from_average' : \"false\",\n#     'tree_learner': \"serial\",\n    \"max_depth\" : -1,\n    \"num_leaves\" : 13,\n    \"learning_rate\" : 0.01,\n    \"bagging_fraction\" : 0.4,\n     'bagging_freq' : 5,\n     'min_data_in_leaf' : 80,\n     'min_sum_hessian_in_leaf' : 10.0,\n    \"feature_fraction\" : 0.05,\n#     \"lambda_l1\" : 5,\n#     \"lambda_l2\" : 5,\n    \"bagging_seed\" : 42,\n    \"verbosity\" : 1,\n    \"random_state\": 4950,\n     'num_threads': 8,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"155a79dd0866c07d757b19893e9a777032369e92"},"cell_type":"code","source":"# from imblearn.over_sampling import SMOTE\n# sm = SMOTE(random_state=2,sampling_strategy = 0.115 ,k_neighbors = 8,n_jobs = 4)\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=31415)\noof = np.zeros(len(df_train))\npredictions = np.zeros(len(df_test))\n# feature_importance_df = pd.DataFrame()\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n    print(\"Fold {}\".format(fold_))\n#     X_train_res, y_train_res = sm.fit_sample(df_train.iloc[trn_idx],target.iloc[trn_idx])\n#     print(sum(target.iloc[trn_idx]) / len(df_train.iloc[trn_idx]))\n#     print(sum(y_train_res) / len(df_train.iloc[trn_idx]))\n    trn_data = lgb.Dataset(df_train.iloc[trn_idx],target.iloc[trn_idx])\n    val_data = lgb.Dataset(df_train.iloc[val_idx], label=target.iloc[val_idx])\n    # watchlist is xgb version\n    # watchlist = [(trn_data, 'train'), (val_data, 'valid')]\n    lgb_model = lgb.train(param, trn_data, 40000, \n                          valid_sets = [trn_data, val_data], \n                          early_stopping_rounds=2000, \n                          verbose_eval=1000)\n#                          categorical_feature= category_features )          \n    oof[val_idx] = lgb_model.predict(df_train.iloc[val_idx], num_iteration = lgb_model.best_iteration)\n    predictions += lgb_model.predict(df_test, num_iteration = lgb_model.best_iteration) / folds.n_splits\n#     fold_importance_df = pd.DataFrame()\n#     fold_importance_df[\"Feature\"] = features\n#     fold_importance_df[\"importance\"] = clf.feature_importance()\n#     fold_importance_df[\"fold\"] = fold_ + 1\n#     feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5222dd960f9e387d881a43215dc40d733149442d"},"cell_type":"code","source":"# clf = lgb.train(param, trn_data, len(lgb_cv[\"auc-mean\"]), valid_sets=(trn_data), verbose_eval=1000)\n# y_pred = clf.predict(df_test, num_iteration=clf.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4aa87e60cea57f80224a14253d9b5e382ea0c49b"},"cell_type":"code","source":"print('save result.')\npd.DataFrame({'ID_code':test_ID,'target':predictions}).to_csv('submission.csv',index=False)\nprint('done.')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}