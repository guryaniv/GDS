{"cells":[{"metadata":{"_uuid":"4363a106cf54eb6a7972c9b0e9dcc03f8d99c201"},"cell_type":"markdown","source":"## NYC Taxi Fare Prediction: EDA, DBSCAN GeoSpatial Clustering & Regression Modeling\n#### Sunil Kumar\n\n"},{"metadata":{"_uuid":"564fa4a3044821c473559332928617b98efd8ecd"},"cell_type":"markdown","source":"## Decision Summary\n\nMy primary interest in solving this Playground Competition was to closely experience the challenes of working with Latitude & Longitude data, introduce pickups & dropoffs desnity feature and asses its impact on NYC Taxi Fare Prediction. The geospatial clustered density of pickup & dropoff has been estimated using DBSCAN algorithm with predefined maximum cluster radius 0.5 km (EPS_IN_KM) and minimum pickup/dropoff count 500 (MIN_SAMPLES_CLUSTER).\n\nThe purpose of choosing DBSCAN [ref. 1] was to identify low-density pickups/dropoffs locations which DBSCAN calls Outliers. Note that the other popular clustering algorithm K-Means determines k (predefined number) centroids which would not serve the purpose due to irregular geospatial distribution. Prior to hitting upon Clustering & specifically DBSCAN, I explored the options of geospatial 2-D binning (tiles, hexbin, etc.) but they are more useful for visualization and not so suitable for my problem statement & sparse dataset.\n\nThe 'train' data pruning has been performed to ensure that original + engineered features' {domain} are not compromised in 'test' - refer to comments at the beginning of code blocks in Data Cleaning & Feature Engineering sections. Minimal data clearning [ref. 5] has been done to get a descent working dataset.\n\n## Useful Insights on DBSCAN\n\n* Refer to [ref. 1] for consice explanation.\n* Refer to [ref. 2] for pros & cons of DBSCAN. NOTE that most of its cons are not applicable to geospatial use cases.\n* Though DBSCAN has a worst-case runtime comlexity of O(n²), its database-oriented range-query formulation of DBSCAN allows for index acceleration for better performance upto O(n log n).\n* Dealing with large geospatial dataset is quite a challenge, hence realistic datasets would necessarily need Big Data implementation of this algorithm [ref. 3].\n* Sklearnc.luster.DBSCAN performance compares very well with repsect to other alternatives [ref. 4]"},{"metadata":{"_uuid":"4f19c5cd595bdf33a8d5d3c7967295ece322bc51"},"cell_type":"markdown","source":"## Global Stuff"},{"metadata":{"trusted":true,"_uuid":"5cb47f36899f6bf71f5eceab7b85c0051b4cfc70"},"cell_type":"code","source":"##############################################################\n# Constants\n##############################################################\n\nKMS_PER_RADIAN = 6371.0088\n\nJFK_GEO_LOCATION = (40.6413, -73.7781)\nLGR_GEO_LOCATION = (40.7769, -73.8740)\nEWR_GEO_LOCATION = (40.6895, -74.1745)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de7a3956bc09a9544e18d747cf51f7b32a3826d2"},"cell_type":"code","source":"##############################################################\n# Input Parameters used with 1M training data points\n##############################################################\n\n# Training data rows to read\nMAX_TRAINING_SIZE = 1_000_00\n\n# Input parameters for DBSCAN GeoSpatial Desnity based clustering\nEPS_IN_KM = 0.1           ## NOTE that lat/long are available till 5th decimal value & 0.1km = 1.xe-5, hence avoid using smaller DBSCAN's eps, i.e., radius threshold for clustering\nMIN_SAMPLES_CLUSTER = 500\n\n# Pickup/dropoff within small radius of airports geo location\nRADIUS_VICINITY_AIRPORTS = 1.0\n\n# Thershold for trip fare rate to remove those spurious trips involving exorbitant fare rate\nTHERSHOLD_TRIP_FARE_RATE = 50.0\n\n# Thereshold for compressing trip distance range from 0.0-110.x to 0.0-25.0\nTHRESHOLD_TRIP_DISTANCE = 25.0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n% matplotlib inline\nplt.style.use('seaborn-whitegrid')\n\nfrom pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n\nimport timeit\nfrom sklearn import metrics\nfrom haversine import haversine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f1406683d16b6554ab4915985c73da02c7760c4"},"cell_type":"code","source":"start_time = timeit.default_timer()\n\n# read data in pandas dataframe\ndf_train =  pd.read_csv('../input/train.csv', nrows = MAX_TRAINING_SIZE, parse_dates=[\"pickup_datetime\"])\ndf_holdout =  pd.read_csv('../input/test.csv', parse_dates=[\"pickup_datetime\"])\ntest_key = df_holdout['key']\ndf_train.drop(columns = ['key'], inplace=True)\ndf_holdout.drop(columns = ['key'], inplace=True)\n\nelapsed = timeit.default_timer() - start_time\nelapsed","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ddea018c70d2ba1c0905151b2ba4745ae15642d"},"cell_type":"markdown","source":"## Naive Data Cleaning"},{"metadata":{"trusted":true,"_uuid":"0e5832930db78db07fe111bba8b6676c7d80d42f"},"cell_type":"code","source":"print('Old size: %d' % len(df_train))\n\n### Ignore -ve fare\ndf_train = df_train[df_train.fare_amount >=0]\n\n### NOTE that there is no missing or NA in 'test'\n### Remove rows with NA in any field\ndf_train = df_train.dropna(how='any', axis='rows')\n\n### 'test': No spurious passenger_count (min is 1 & max is 6)\n### 'train': passengers_count max is 208... just 11 out of 1M trips with count > 7, hence removing those trips\ndf_train = df_train.drop(index= df_train[df_train.passenger_count >= 7].index, axis='rows')\ndf_train = df_train.drop(index= df_train[df_train.passenger_count == 0].index, axis='rows')\n\nprint('New size: %d' % len(df_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"590931b8e9b6128347c3e5d1ae592457252a6ba1"},"cell_type":"code","source":"### NOTE that 'test' lat-long are well within NYC boundary, whereas there are few spurious 'train' datapoints outside of NYC boundary hence removing those trips\n\n#min(df_train.pickup_longitude.min(), df_train.dropoff_longitude.min()), max(df_train.pickup_longitude.max(), df_train.dropoff_longitude.max())\n#min(df_train.pickup_latitude.min(), df_train.dropoff_latitude.min()), max(df_train.pickup_latitude.max(), df_train.dropoff_latitude.max())\n\ndef select_within_boundingbox(df, BB):\n    return (df.pickup_longitude >= BB[0]) & (df.pickup_longitude <= BB[1]) & \\\n           (df.pickup_latitude >= BB[2]) & (df.pickup_latitude <= BB[3]) & \\\n           (df.dropoff_longitude >= BB[0]) & (df.dropoff_longitude <= BB[1]) & \\\n           (df.dropoff_latitude >= BB[2]) & (df.dropoff_latitude <= BB[3])\n            \n#Times Square (40.7590° N, 73.9845° W)\n#BB = (-74.2, -73.8, 40.6, 41.0)\n\n# load image of NYC map\nBB = (-74.5, -72.8, 40.5, 41.8)\n\nprint('Old size: %d' % len(df_train))\ndf_train = df_train[select_within_boundingbox(df_train, BB)]\nprint('New size: %d' % len(df_train))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1e33495c9fa3e76d5893b590d06aadd941feb44"},"cell_type":"markdown","source":"## EDA, Feature Engineering & Data Cleaning"},{"metadata":{"_kg_hide-output":false,"trusted":true,"_uuid":"c867782140f055cdd0d93be59f1e0db4605580f2"},"cell_type":"code","source":"# IDEA.n: Ideally, shortest route distance should be used\ndef addPickDropDistanceFeature(df):\n\n    df['trip_distance'] = df.apply(\n        (lambda row: haversine(\n            (row['pickup_latitude'], row['pickup_longitude']),\n            (row['dropoff_latitude'], row['dropoff_longitude']))\n        ),\n        axis='columns'\n    )\n    return df\n\ndef addAirportDistanceFeatures(df):\n\n    df['pickup_distance_to_jfk'] = df.apply(\n        (lambda row: haversine(\n            (row['pickup_latitude'], row['pickup_longitude']),\n            (JFK_GEO_LOCATION[0], JFK_GEO_LOCATION[1]))\n        ),\n        axis='columns'\n    )\n\n    df['drop_distance_to_jfk'] = df.apply(\n        (lambda row: haversine(\n            (row['dropoff_latitude'], row['dropoff_longitude']),\n            (JFK_GEO_LOCATION[0], JFK_GEO_LOCATION[1]))\n        ),\n        axis='columns'\n    )\n\n    df['pickup_distance_to_lgr'] = df.apply(\n        (lambda row: haversine(\n            (row['pickup_latitude'], row['pickup_longitude']),\n            (LGR_GEO_LOCATION[0], LGR_GEO_LOCATION[1]))\n        ),\n        axis='columns'\n    )\n\n    df['drop_distance_to_lgr'] = df.apply(\n        (lambda row: haversine(\n            (row['dropoff_latitude'], row['dropoff_longitude']),\n            (LGR_GEO_LOCATION[0], LGR_GEO_LOCATION[1]))\n        ),\n        axis='columns'\n    )\n\n    df['pickup_distance_to_ewr'] = df.apply(\n        (lambda row: haversine(\n            (row['pickup_latitude'], row['pickup_longitude']),\n            (EWR_GEO_LOCATION[0], EWR_GEO_LOCATION[1]))\n        ),\n        axis='columns'\n    )\n\n    df['drop_distance_to_ewr'] = df.apply(\n        (lambda row: haversine(\n            (row['dropoff_latitude'], row['dropoff_longitude']),\n            (EWR_GEO_LOCATION[0], EWR_GEO_LOCATION[1]))\n        ),\n        axis='columns'\n    )\n    \n    return df\n\ndef getAirportTrips(df, airportVicinity):\n    ids = (df.pickup_distance_to_jfk < airportVicinity) | (df.drop_distance_to_jfk < airportVicinity) | (df.pickup_distance_to_lgr < airportVicinity) | (df.drop_distance_to_lgr < airportVicinity) | (df.pickup_distance_to_ewr < airportVicinity) | (df.drop_distance_to_ewr < airportVicinity)\n    \n    return ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58b559ac9fd6971674fcbd65b72bc1580be6e09a"},"cell_type":"code","source":"start_time = timeit.default_timer()\n\n# Add pickup-dropoff distance feature\ndf_train = addPickDropDistanceFeature(df_train)\ndf_holdout = addPickDropDistanceFeature(df_holdout)\n\nelapsed = timeit.default_timer() - start_time\nelapsed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e1cfe6897ebe027a52909cf92b18fbbbd082cb2"},"cell_type":"code","source":"# With 1M datapoints, trip_distance range can be compressed from 0.0-110.83 to 0.0-25.0\n# which would drop just 690 & 11 training & testing datapoints, i.e., \n# worst case impact on prediction accuracy by 0.1% (11/test_size*100)\n\nbucketsCount = 100\nfeat = 'trip_distance'\n\ndf_train[feat].hist(bins=bucketsCount, figsize = (15,8))\ndf_holdout[feat].hist(bins=bucketsCount, figsize = (15,8))\nplt.yscale('log')\nplt.xlabel(feat)\nplt.ylabel(\"Frequency Log\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abaeeeb8d8ccfab4d413f6f148c8cad25d9eaaab"},"cell_type":"code","source":"#(len(df_train[df_train[feat] > THRESHOLD_TRIP_DISTANCE]), len(df_holdout[df_holdout[feat] > THRESHOLD_TRIP_DISTANCE]))\n\nprint('Old size: %d' % len(df_train))\ndf_train = df_train[df_train.trip_distance < THRESHOLD_TRIP_DISTANCE]\nprint('New size: %d' % len(df_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19595730b1ea6b6448ef677999859770d33bb4f2"},"cell_type":"code","source":"def add_datetime_features(df):\n    #Convert to datetime format\n    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'],format=\"%Y-%m-%d %H:%M:%S UTC\")\n    \n    df['hour'] = df.pickup_datetime.dt.hour\n    df['day'] = df.pickup_datetime.dt.day\n    df['month'] = df.pickup_datetime.dt.month\n    df['weekday'] = df.pickup_datetime.dt.weekday\n    df['year'] = df.pickup_datetime.dt.year\n    \n    return df\n\nstart_time = timeit.default_timer()\n\ndf_train = add_datetime_features(df_train)\ndf_holdout = add_datetime_features(df_holdout)\n\nelapsed = timeit.default_timer() - start_time\nelapsed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6544019409d050115664a571fd7bddfa3ca37c2f"},"cell_type":"code","source":"hour_bins = [-1, 5, 7, 10, 16, 21, 23]\nbin_names = ['late_night', 'morning', 'morning_peak', 'afternoon', 'evening', 'night']\ndf_train['hour_type'] = pd.cut(df_train.hour, bins=hour_bins, labels=bin_names).cat.codes\ndf_holdout['hour_type'] = pd.cut(df_train.hour, bins=hour_bins, labels=bin_names).cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1080b593ebd2e484061acd195fe5142f266c2032"},"cell_type":"code","source":"# Merging both 'train' & 'holdout' for common feature engineering afterwhich 'holdout' data will be extracted\ntrain_len = len(df_train)\ndf_nyc_taxi = pd.concat([df_train, df_holdout], axis=0, ignore_index=False, sort=False)\n#df_nyc_taxi.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1fdf9bf2e4e0a5bb9cc9ac3fdd08869dab90fdc"},"cell_type":"code","source":"from sklearn.cluster import DBSCAN\n\nEPS_IN_RADIAN = EPS_IN_KM / KMS_PER_RADIAN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"089e908a9040b917e588304fc920a51832e23190"},"cell_type":"code","source":"start_time = timeit.default_timer()\n\ndbscan_pick = DBSCAN(eps=EPS_IN_RADIAN, min_samples=MIN_SAMPLES_CLUSTER, algorithm='ball_tree', metric='haversine').fit(np.radians(df_nyc_taxi.loc[:,'pickup_longitude':'pickup_latitude']))\nlabels_pick = dbscan_pick.labels_\n\nelapsed = timeit.default_timer() - start_time\nelapsed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb9c246cb935e86daffc49ce413d44a9637e554d"},"cell_type":"code","source":"# Number of clusters in labels, ignoring noise if present.\nn_clusters_pick = len(set(labels_pick)) - (1 if -1 in labels_pick else 0)\nn_clusters_pick","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f6b5eaee05fbf0cec3dc897ff683fd617d18022"},"cell_type":"code","source":"start_time = timeit.default_timer()\n\ndbscan_drop = DBSCAN(eps=EPS_IN_RADIAN, min_samples=MIN_SAMPLES_CLUSTER, algorithm='ball_tree', metric='haversine').fit(np.radians(df_nyc_taxi.loc[:,'dropoff_longitude':'dropoff_latitude']))\nlabels_drop = dbscan_drop.labels_\n\nelapsed = timeit.default_timer() - start_time\nelapsed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"312a9dabdaa5b8b86ed339ea163a31097661deb4"},"cell_type":"code","source":"# Number of clusters in labels, ignoring noise if present.\nn_clusters_drop = len(set(labels_drop)) - (1 if -1 in labels_drop else 0)\nn_clusters_drop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be149b59280e1939fd36a715ddf84a00f942d2b2"},"cell_type":"code","source":"df_nyc_taxi['density_DBSCAN_pickup'] = labels_pick\ndf_nyc_taxi['density_DBSCAN_dropoff'] = labels_drop\n#df_nyc_taxi['dense_DBSCAN_trips'] = ((labels_pick != -1) & (labels_drop != -1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7d34f7d503c7cc9b9cdf3e3923974b02f79f22e"},"cell_type":"code","source":"'''\n# NOTE that our focus of DBSCAN is not to differentiate levels of clusters, i.e., set of connected clusters => hence we are plotting all clusters together\ndf_tmp = df_nyc_taxi.loc[df_nyc_taxi.dense_DBSCAN_trips == 1]\nplt.plot(df_tmp.pickup_longitude, df_tmp.pickup_latitude, 'o')\nplt.xlabel(\"Pickup Longitude\")\nplt.ylabel(\"Pickup Latitude\")\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"832a6f6c97196d4aba65b7c122b32104bb1dc807"},"cell_type":"code","source":"'''\nplt.plot(df_tmp.dropoff_longitude, df_tmp.dropoff_latitude, 'o')\nplt.xlabel(\"Dropoff Longitude\")\nplt.ylabel(\"Dropoff Latitude\")\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ea1026a0a89c18e1fad25e4d8dc1924c87fb3c3"},"cell_type":"code","source":"df_train = df_nyc_taxi.iloc[:train_len, :]\ndf_holdout = df_nyc_taxi.iloc[train_len:, :].iloc[:, df_nyc_taxi.columns != 'fare_amount']\n\n(len(df_train), len(df_holdout))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8f9a53158d5f65ad0763dc5c4bf80e0cc48e820"},"cell_type":"code","source":"# Ceiling near-zero fare values to 0.2 to check fare/dist behavior\ndf_train.loc[df_train.trip_distance < 0.2, 'trip_distance'] = 0.2\n\n(df_train.fare_amount / df_train.trip_distance).hist(bins=bucketsCount, figsize = (15,8))\nplt.yscale('log')\nplt.xlabel('trip_rate')\nplt.ylabel(\"Log Frequency\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30e6ffcda33cbed3e8d30fe34bbb500028d8cca6"},"cell_type":"code","source":"df_train['trip_rate'] = df_train.apply(\n    (lambda row: (row.fare_amount / row.trip_distance)),\n    axis='columns'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dbd347c8b406a9e6768a0aec62c208647f7b306"},"cell_type":"code","source":"#len(df_train.loc[df_train.trip_rate > THERSHOLD_TRIP_FARE_RATE])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e2ca44cd5f725ec7f900dd5f9a553a42f99b92d"},"cell_type":"code","source":"#Trying to check if not removing 50+ trip_rate improve the score!\nids = (df_train.trip_rate < THERSHOLD_TRIP_FARE_RATE)\n\nprint('Old size: %d' % len(df_train))\ndf_train = df_train[ids]\nprint('New size: %d' % len(df_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab5aedf745d4a644d8f2f60e28480fb4dbda66c3"},"cell_type":"code","source":"start_time = timeit.default_timer()\n\n# Add airport trips distance features\ndf_train = addAirportDistanceFeatures(df_train)\ndf_holdout = addAirportDistanceFeatures(df_holdout)\n\nelapsed = timeit.default_timer() - start_time\nelapsed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23d6e3b10d0f114d4b7dc5eb860977266d9319b1"},"cell_type":"code","source":"#df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9396397bfcb121c4cb867166e0a6041e98c7213"},"cell_type":"code","source":"# Split training data into Airport & City trips\n\nairportTripsIds = getAirportTrips(df_holdout, RADIUS_VICINITY_AIRPORTS)\ndf_holdout['airport_bound'] = airportTripsIds\n\nairportTripsIds = getAirportTrips(df_train, RADIUS_VICINITY_AIRPORTS)\ndf_train['airport_bound'] = airportTripsIds\ndf_airport_trips = df_train.loc[airportTripsIds]\ndf_city_trips = df_train.loc[-airportTripsIds]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6edb273ad0ec6ba77dd3702453c162fd81621559"},"cell_type":"code","source":"# Compare trip_rate for Airport & City trips\npd.DataFrame(data={'Airport Trips' : df_airport_trips.trip_rate, 'City Trips' : df_city_trips.trip_rate}).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a233fc0ed0b246e7c7e750fca218c088a6ddbdd","scrolled":true},"cell_type":"code","source":"# Compare trip_rate for good -vs- poorly dense trips\n#pd.DataFrame(data={'Good Density Trips' : df_train.loc[df_train.dense_DBSCAN_trips == 1].trip_rate, 'LOW Density Pickups' : df_train.loc[df_train.dense_DBSCAN_trips == 0].trip_rate}).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d61ae894b6384d1412360b60600966f62400be4"},"cell_type":"code","source":"df_train = df_train.drop(columns = ['pickup_datetime', 'pickup_distance_to_jfk', 'drop_distance_to_jfk', 'pickup_distance_to_lgr', 'drop_distance_to_lgr', 'pickup_distance_to_ewr', 'drop_distance_to_ewr', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'trip_rate', 'hour'])\ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"373e251bcf61d31059bff8a1e1dc1dc09ba088f7"},"cell_type":"code","source":"y = df_train['fare_amount']\ntrain = df_train.drop(columns=['fare_amount'])\n\nx_train, x_test, y_train, y_test = train_test_split(train, y, random_state=0, test_size=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3b96c9fe00cf23ae1aaab8bd3bfa3cb4669ef65d"},"cell_type":"code","source":"#Cross-validation\nparams = {\n    # Parameters that we are going to tune.\n    'max_depth': 8, #Result of tuning with CV\n    'eta':.03, #Result of tuning with CV\n    'subsample': 1, #Result of tuning with CV\n    'colsample_bytree': 0.8, #Result of tuning with CV\n    # Other parameters\n    'objective':'reg:linear',\n    'eval_metric':'rmse',\n    'silent': 1\n}\n\n#Block of code used for hypertuning parameters. Adapt to each round of parameter tuning.\n#Turn off CV in submission\nCV=False\nif CV:\n    dtrain = xgb.DMatrix(train,label=y)\n    gridsearch_params = [\n        (eta)\n        for eta in np.arange(.04, 0.12, .02)\n    ]\n\n    # Define initial best params and RMSE\n    min_rmse = float(\"Inf\")\n    best_params = None\n    for (eta) in gridsearch_params:\n        print(\"CV with eta={} \".format(\n                                 eta))\n\n        # Update our parameters\n        params['eta'] = eta\n\n        # Run CV\n        cv_results = xgb.cv(\n            params,\n            dtrain,\n            num_boost_round=1000,\n            nfold=3,\n            metrics={'rmse'},\n            early_stopping_rounds=10\n        )\n\n        # Update best RMSE\n        mean_rmse = cv_results['test-rmse-mean'].min()\n        boost_rounds = cv_results['test-rmse-mean'].argmin()\n        print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n        if mean_rmse < min_rmse:\n            min_rmse = mean_rmse\n            best_params = (eta)\n\n    print(\"Best params: {}, RMSE: {}\".format(best_params, min_rmse))\nelse:\n    #Print final params to use for the model\n    params['silent'] = 0 #Turn on output\n    print(params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6516ece5c786c65d898282f479597dbe1c6caca3"},"cell_type":"code","source":"def XGBmodel(x_train,x_test,y_train,y_test,params):\n    matrix_train = xgb.DMatrix(x_train,label=y_train)\n    matrix_test = xgb.DMatrix(x_test,label=y_test)\n    model=xgb.train(params=params,\n                    dtrain=matrix_train,num_boost_round=5000, \n                    early_stopping_rounds=10,evals=[(matrix_test,'test')])\n    return model\n\nmodel = XGBmodel(x_train,x_test,y_train,y_test,params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35324eb9603ded412659ee3fb8bcec827d1a586d"},"cell_type":"code","source":"#Read and preprocess test set\nx_pred = df_holdout.drop(columns = ['pickup_datetime', 'pickup_distance_to_jfk', 'drop_distance_to_jfk', 'pickup_distance_to_lgr', 'drop_distance_to_lgr', 'pickup_distance_to_ewr', 'drop_distance_to_ewr', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'hour'])\n\n#Predict from test set\nprediction = model.predict(xgb.DMatrix(x_pred), ntree_limit = model.best_ntree_limit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93cc96f21ee4d92646c3633af5828a900628e2a2"},"cell_type":"code","source":"len(test_key)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f840c4fcfce8e792f782d33988923a28e81bb80"},"cell_type":"code","source":"#Create submission file\nsubmission = pd.DataFrame({\n        \"key\": test_key,\n        \"fare_amount\": prediction.round(2)\n})\n\nsubmission.to_csv('taxi_fare_submission.csv',index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e126d84e02aee7f5eb858e8b8ad2e40f985e77bf"},"cell_type":"markdown","source":"## References\n\n1. [Density based Clustering by Manojit Nandi, Domino Data Lab](https://blog.dominodatalab.com/topology-and-density-based-clustering/)\n2. [DBSCAN Wiki](https://en.wikipedia.org/wiki/DBSCAN)\n3. [Efficient Large Scale Clustering based on Data Partitioning](https://arxiv.org/pdf/1704.03421.pdf)\n4. [Benchmarking Performance and Scaling of Python Clustering Algorithms](https://hdbscan.readthedocs.io/en/latest/performance_and_scalability.html)\n5. [Kaggle kernel for Data Exploration](https://www.kaggle.com/breemen/nyc-taxi-fare-data-exploration/notebook)\n6. [Kaggle kernel for XGBoost](https://www.kaggle.com/gunbl4d3/xgboost-ing-taxi-fares)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}