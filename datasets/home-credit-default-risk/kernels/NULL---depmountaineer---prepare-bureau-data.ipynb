{"cells":[{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7ee5990acf50506363bcf751483de391be0f1127"},"cell_type":"code","source":"#requires: original input only: ../input/bureau_balance.csv and ../input/bureau.csv\n#provides: bureau_merged.csv, a merged-rolled-up-cleaned-numericized file.\n\n#input parameters for this kernel\ninfile = '../input/bureau_balance.csv'\ninfile2 = '../input/bureau.csv'\noutfile = 'bureau_merged.csv'\nindex_in = 'SK_ID_BUREAU' #to define records coming in\nindex_out = 'SK_ID_CURR' #to define records going out; ultimately merged with test/train data so use the same ID\ndrop1 = ['MONTHS_BALANCE'] #executive decision to just skip this column\ncat1 = ['STATUS'] #categorical column to be one-hot encoded from infile\ncat2 = ['CREDIT_CURRENCY', 'CREDIT_ACTIVE'] #categorical columns to be one-hot encoded from infile2\ncol_mean = ['DAYS_ENDDATE_FACT', 'DAYS_CREDIT_UPDATE', 'AMT_CREDIT_SUM_LIMIT', 'DAYS_CREDIT_ENDDATE', 'CREDIT_DAY_OVERDUE'] #when rolling up, use mean for these (why? just a guess)\ncol_sum = ['AMT_CREDIT_MAX_OVERDUE', 'CNT_CREDIT_PROLONG', 'AMT_CREDIT_SUM', 'AMT_CREDIT_SUM_DEBT', 'AMT_CREDIT_SUM_OVERDUE', 'AMT_ANNUITY', 'DAYS_CREDIT'] #when rolling up use sum for these; always use sum for one-hot encoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b63b60ca8b9fc90f1ae9ffdc9c35313f05102f52"},"cell_type":"code","source":"#Utility function used in this kernel\n#made specifically for Home Credit data, where 'XNA' is used for NA data\ndef one_hot(df, columns, abbr=False):\n    \"\"\"\n    one-hot encode specified columns in place.\n\n    df: dataframe\n    columns: columns to encode\n    abbr: true, false, or dict {col:abbr, col:abbr, ...}; if set to true, automatically determine abbreviations.  Uniqueness not guaranteed! (alpha software)\n    return: {oldcol:[newcol, newcol, ...], oldcol:[newcol, newcol, ...], ...}\n    \"\"\"\n    colmap = {}\n    if type(columns) == str:\n        columns = [columns] #allow using a string for a single column\n    if abbr is True: \n        abbr = {}\n        for col in columns:\n            #make a reasonable abbraviation\n            c = str(col).replace(' ', '_').replace('(', '_').replace(')', '_').replace('__', '_').replace('__', '_').replace('__', '_') \n            if c.endswith('_'):\n                c=c[:-1]\n            if c.startswith('_'):\n                c=c[1:]\n            abbr[col] = ''.join([x[0] for x in c.split('_') if len(x)])\n    for col in columns:\n        #one-hot encode\n        d = pd.get_dummies(df[col])\n        if 'XNA' in d: #drop XNA if it exists\n            del d['XNA']\n        else:\n            del d[d.columns[-1]] #else, drop the last entry\n        if abbr and col in abbr: #create new columns out of abbreviated column name and mildly-abbreviatied dummy categorical values\n            d.columns = [abbr[col] + '_' + str(x).replace(' ','').replace('/','').replace(':','').replace('(','').replace(')','').replace(',','') for x in d.columns]\n        else:#create new columns out of full column name and full dummy categorical values\n            d.columns = [str(col) + '_' + str(x) for x in d.columns]\n        df.drop(columns=col, inplace=True) #drop the original columns\n        df[d.columns] = d #add the new dummy columns\n        colmap[col] = d.columns #put new columns in dict so we can return it\n    return colmap","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f2e1b6bd7cbd051b24e3a39aff17d24e1bb9ba28"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n#import matplotlib as plt\n#import seaborn as sbn\nimport os, sys\n\n#cause all of cell, not just last, line to display result\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"8dad279fdabb3ca3849ad5298a10a28419a93fae"},"cell_type":"code","source":"#read the file, using bureau IDs as dataframe index; AFAIK the future warning is harmless and I don't know how to get rid of it\ndf = pd.read_csv(infile, index_col=index_in)\ndf.head()\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a2afb4433f367fddfce1d94eae42c57dfd68b398"},"cell_type":"code","source":"#one-hot encode the categorical columns\ncol = one_hot(df, columns=cat1, abbr=True)\n\n#drop the unwanted column\ndf.drop(columns=drop1, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9db31dd62d13d08c6dbaaac81a82e71811ef33b8"},"cell_type":"code","source":"#Aggregate the columns; for infile1, they are ALL summed since they were one-hot encoded\ndf = df.groupby(by=index_in).agg({x:'sum' for x in df.columns})\ndf.head()\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"2928010e0df50a7290a7ef7966fe3b3b231bdef5"},"cell_type":"code","source":"#Read the second file that will be merged with the first data; AFAIK the future warning is harmless and I don't know how to get rid of it\ndf2 = pd.read_csv(infile2, index_col=index_in)\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"647a431242d21f6841405ada619a7faaed5a93c7"},"cell_type":"code","source":"#Merge it by index\ndf = pd.merge(df2, df, left_index=True, right_index=True, how='left')\ndf.head()\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"8805508fcb8400f80317f986a619e497d8fefb58"},"cell_type":"code","source":"#One-hot encode categorical columns\ncol2 = one_hot(df, columns=cat2, abbr=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"18eab911532dc31cd907a6ff1905f6ec9e0290f6"},"cell_type":"code","source":"#Create the aggregation dictionary for group-and-aggregate\nagg = {}\nfor c in col:\n    agg = {x:'sum' for x in col[c]}\nfor c in col2:\n    agg.update({x:'sum' for x in col2[c]})\nfor c in col_mean:\n    agg[c] = 'mean'\nfor c in col_sum:\n    agg[c] = 'sum'\nagg\n\nfor c in df.columns:\n    if c not in agg:\n        print(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a6800988c95ace375c2f66385bb1f91c63ae966f"},"cell_type":"code","source":"#first put 0s for NAs so they don't ruin the sums and means\ndf.fillna(0, inplace=True)\n#Group by outgoing index, and aggregate\ndf = df.groupby(by=index_out).agg(agg)\ndf.head()\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"fa4cce155db60ac6db20cbbbd269eeaf4c438e46"},"cell_type":"code","source":"#Just be extra sure there are no dupes\ndf = df[~df.index.duplicated(keep='first')]\n#Just be extra sure no NaNs somehow slipped through\ndf.fillna(0, inplace=True)\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"0d2ad55e26c00265007b979124c24cf22e2588e5"},"cell_type":"code","source":"#Write the output, with index field as one of the csv fields\n#uncomment if you actually want to write\n\n#df.to_csv(outfile, index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e58dffff93c0806c4a50ac66e29018bad1111b90"},"cell_type":"code","source":"df.head()\nlen(df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}