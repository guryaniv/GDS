{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestRegressor\n%matplotlib inline\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fce0ff527ed0d2b8ab97cbc9e9521fbfa158781a"},"cell_type":"markdown","source":"## Loading data"},{"metadata":{"trusted":true,"_uuid":"3a5103447ff1d5217dea3715e1b1cbf6855584f4"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\nprint(\"shape of Training  dataset\", train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c88fb7b99d568e4a37ea2900e871800b04397a1e"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"07a16fdec13c6c8d6c27fb39b6a8c0e043f901f7"},"cell_type":"markdown","source":"## checking missing values in train dataset"},{"metadata":{"trusted":true,"_uuid":"9f487081c66c50ff7eada70f11df0c550ad179c5"},"cell_type":"code","source":"train.isnull().sum().sort_values(ascending=False).sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bbeebb15356c51383c41eb371026694b1972c828"},"cell_type":"markdown","source":"## Visualization of X and Target values\n"},{"metadata":{"trusted":true,"_uuid":"a7bfcd83e19e2e798c1711eafe94097f7c113932"},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nxflat = train.iloc[:,2:].values.flatten() # remove id and target\nxflat = pd.DataFrame(np.log1p(xflat[xflat>0])) # remove zeros\nhist = np.histogram(xflat, 30)\nsns.distplot(xflat, bins=hist[1], kde=False).set_title('Log histogram of Training Features (X)')\nplt.xlabel('log(x)')\nplt.ylabel('count')\nprint('Train mean: {}, std: {}'.format(xflat.values.mean(), xflat.values.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ea67dbfef3e1f7c9bb0a0281f556e2372d48f03"},"cell_type":"code","source":"plt.figure(figsize=(10,6))\ntarget = pd.DataFrame(np.log1p(train.target))\nsns.distplot(target, bins=hist[1], kde=False).set_title('Log histogram of Training Features (X)')\nplt.xlabel('log target')\nplt.ylabel('count')\nprint('Target mean: {}, std: {}'.format(target.values.mean(), target.values.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6326a47bbb291634e67a83e31409d904262e3a81","collapsed":true},"cell_type":"code","source":"# now let's check the test dataset\ntest = pd.read_csv('../input/test.csv')\ndel test['ID']\ntest = test.values","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true,"_uuid":"c4dd5f5ecb59e6859f0acf1f4062ccbd3c94972b"},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nxflat_test = test.flatten() # remove id\nxflat_test = pd.DataFrame(np.log1p(xflat_test[xflat_test>0])) # remove zeros\nsns.distplot(xflat_test, bins=hist[1], kde=False).set_title('Log histogram of Test Features')\nplt.xlabel('log(x)')\nplt.ylabel('count')\nprint('Test mean: {}, std: {}'.format(xflat_test.values.mean(), xflat_test.values.std()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e28736f05483836247faccf28b741e2f6981ed78"},"cell_type":"markdown","source":"### All stacked now"},{"metadata":{"trusted":true,"_uuid":"8d614801b8fc975dd56d278dacef47ae5f1d2d3a"},"cell_type":"code","source":"print('Train mean: {}, std: {}'.format(xflat.values.mean(), xflat.values.std()))\nprint('Test mean: {}, std: {}'.format(xflat_test.values.mean(), xflat_test.values.std()))\nprint('Target mean: {}, std: {}'.format(target.values.mean(), target.values.std()))\n\nplt.figure(figsize=(10,6))\nplt.hist(xflat_test.values, alpha=.8, label='test', bins=hists[1], density=True,  histtype='bar')\nplt.hist(xflat.values, alpha=.5, label='training', bins=hists[1], density=True,  histtype='bar')\nplt.hist(target.values, alpha=.3, label='target', bins=hists[1], density=True,  histtype='bar')\n\nplt.legend(prop={'size': 12})\nplt.title('Normalized Log Histogram of Training Features, Test and Target');\nplt.xlabel('log scale')\nplt.ylabel('distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70770075df25dcb52d6281e1e9e6da10072ab986"},"cell_type":"markdown","source":"Very probably from the same distribution... however target seems to be truncated between 10 and 17"},{"metadata":{"_uuid":"6492d2ddb722f81a35cd3302e1f20dcd0799371e"},"cell_type":"markdown","source":"### Agregation features"},{"metadata":{"trusted":true,"_uuid":"fb9f8eae84ebb0ac26ba1dd1a9704fb13a447e00","collapsed":true},"cell_type":"code","source":"df = np.log1p(train.drop([\"ID\"], axis=1))\n\n# Drop columns with less than 20% non-zeros\ndf = df.loc[:, (df != 0).sum() > df.shape[0]*0.2]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8801234cc4c26c8036d5595a48b1a71b642eabb3","collapsed":true},"cell_type":"code","source":"# remove crytpic column names \ncols = [str(n) for n in np.arange(-1, df.shape[1]-1)]\ncols[0:1] = ['target']\ndf.columns = cols\ndf['max'] = np.log1p(train.iloc[:,2:].max(axis=1).values)    # without id and target\ndf['muLog'] = np.log1p(train.iloc[:,2:]).mean(axis=1).values # mean of the log\ndf['mu'] = np.log1p(train.iloc[:,2:].mean(axis=1).values)    # log of the mean\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb628b6fd9b62ec03f0c1d15b7b076188d006f16"},"cell_type":"markdown","source":"## Exploring direct correlations"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"49e9a54ad69d311dc275b2bec37f3d8b69a69fbb"},"cell_type":"code","source":"def plot_corr(dframe):\n    # Compute the correlation matrix\n    corr = dframe.corr(method='pearson')\n    # Generate a mask for the upper triangle\n    mask = np.zeros_like(corr, dtype=np.bool)\n    mask[np.triu_indices_from(mask)] = True\n\n    # Set up the matplotlib figure\n    f, ax = plt.subplots(figsize=(11, 9))\n\n    # Generate a custom diverging colormap\n    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n    # Draw the heatmap with the mask and correct aspect ratio\n    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69f95c8dbcb87e5e471da632ee55c8c0b68af23b","collapsed":true},"cell_type":"code","source":"fix_cols = ['target','mu','muLog','max']\nrand_cols = [str(n) for n in np.arange(0, df.shape[1]-3, 3)] # from non-zero columns\n\nplot_corr(df[fix_cols + rand_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b630b4bae37f8504e9fa8637d2ae1c8d55ed110a","collapsed":true},"cell_type":"code","source":"# more pretty bad correlations\nrand_cols = [str(n) for n in np.arange(0, df.shape[1]-3, 12)]\nsns.pairplot(df[['target'] + rand_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e1db7bfc6ec5588d1eb65e49cfc789df69f4648","collapsed":true},"cell_type":"code","source":"# somewhat better on averages?\nsns.pairplot(df[fix_cols])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e9dfb6a3fb1e2a23a6c4d4701e65a4bb7864fb8"},"cell_type":"markdown","source":"## Time series features"},{"metadata":{"trusted":true,"_uuid":"b8194fae1ed4d00ba9a396de726507e1a6c7be08","collapsed":true},"cell_type":"code","source":"# assuming the columnss are actually days (or similar)\nts = train.iloc[:,2:] ## drop ID and target\nts.columns = np.arange(ts.shape[1])\nquart_log = np.log1p(ts.T).rolling(365, min_periods=1, center=True, win_type='gaussian').mean(std=80).iloc[::91].T # quartal mean of the log\nlog_quart = np.log1p(ts.T.rolling(365, min_periods=1, center=True, win_type='gaussian').mean(std=80)).iloc[::91].T # log of the quartal mean\nquart_log.columns = ['ql'+str(n) for n in quart_log.columns]\nlog_quart.columns = ['lq'+str(n) for n in log_quart.columns]\ndf = df.join(quart_log) # get target back\ndf = df.join(log_quart)\nquart_log.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c91335844ef3fbb929ce4ad0b4e5d9725e71b0e6","collapsed":true},"cell_type":"code","source":"new_cols = ['target','ql0','ql91','ql4641','ql4732','lq0','lq91','lq4641','lq4732']\ng = sns.pairplot(df[new_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f56b093ed80b2258ab91a246afcc6e493e76921","collapsed":true},"cell_type":"code","source":"plot_corr(df[new_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4dc7cfe169f204e40e008cc404eee3f21a6952b5","collapsed":true},"cell_type":"code","source":"# How do they actually look like\nlog_quart.T.iloc[:,:5].plot(figsize=(20,6))\nprint(df.iloc[:5].target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93f6f4712e95dcc3e6ba2f55488a17a295809112","collapsed":true},"cell_type":"code","source":"# Let's see some real data (first row [target + all columns])\ng = np.log1p(train.iloc[:1, 1:].T).plot(figsize=(20,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96f9132277654283e21835dddc747dbc0b8f8f76","collapsed":true},"cell_type":"code","source":"# Median changes over \"time\"? (assuming the columns are sorted transaction times/days)\ncol_mean = pd.DataFrame((log_quart.median())).reset_index()\ncol_mean.columns = ['index', 'mean']\ncol_mean['index'] = np.arange(0,train.shape[1],91)\ng = sns.lmplot(data=col_mean, x='index', y='mean')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2839466f59b7b158415c7e6b346ed6cdb74706e6"},"cell_type":"markdown","source":"## Possible conclusions:\nDue to the regularity on the data, I'm  making a strong assumption that the data columns could represent days and the order is kept even after the anonymisation.\nIf that assumption holds moving averages of different granularity should reduce the amount of data and finally improve our predictive power.\nThis has still to be proven heuristically..."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}