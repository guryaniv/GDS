{"metadata": {"language_info": {"version": "3.6.3", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "name": "python", "mimetype": "text/x-python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat_minor": 1, "cells": [{"outputs": [], "execution_count": null, "metadata": {"_uuid": "76a4489d06e8b686764dc0093d6220696efe1d14", "_cell_guid": "6c6cabd2-f186-460c-b2ca-25bc54be7062"}, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "import numpy as np\n", "import pandas as pd\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import log_loss\n", "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n", "from os.path import join as opj\n", "import keras\n", "\n", "#from matplotlib import pyplot as plt\n", "from mpl_toolkits.mplot3d import Axes3D\n", "#import pylab\n", "#plt.rcParams['figure.figsize'] = 10, 10\n", "#%matplotlib inline\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."]}, {"outputs": [], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": ["path = \"../input\"\n", "train = pd.read_json(path+\"/train.json\")\n", "target_train=train['is_iceberg']\n", "test = pd.read_json(path+\"/test.json\")\n", "\n", "target_train=train['is_iceberg']\n", "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n", "train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n", "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n", "X_angle=train['inc_angle']\n", "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n", "X_test_angle=test['inc_angle']\n", "\n", "#Generate the training data\n", "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n", "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n", "#X_band_3=(X_band_1+X_band_2)/2\n", "X_band_3=np.fabs(np.subtract(X_band_1,X_band_2))\n", "X_band_4=np.maximum(X_band_1,X_band_2)\n", "X_band_5=np.minimum(X_band_1,X_band_2)\n", "#X_band_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in train[\"inc_angle\"]])\n", "X_train = np.concatenate([\n", "                          \n", "                          X_band_3[:, :, :, np.newaxis],X_band_4[:, :, :, np.newaxis],X_band_5[:, :, :, np.newaxis]], axis=-1)\n", "\n", "\n", "\n", "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n", "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n", "#X_band_test_3=(X_band_test_1+X_band_test_2)/2\n", "X_band_test_3=np.fabs(np.subtract(X_band_test_1,X_band_test_2))\n", "X_band_test_4=np.maximum(X_band_test_1,X_band_test_2)\n", "X_band_test_5=np.minimum(X_band_test_1,X_band_test_2)\n", "#X_band_test_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in test[\"inc_angle\"]])\n", "X_test = np.concatenate([\n", "                          X_band_test_3[:, :, :, np.newaxis], X_band_test_4[:, :, :, np.newaxis],X_band_test_5[:, :, :, np.newaxis]],axis=-1)\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["# Loading libraries"]}, {"outputs": [], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": ["\n", "#Import Keras.\n", "#from matplotlib import pyplot\n", "from keras.optimizers import RMSprop\n", "from keras.preprocessing.image import ImageDataGenerator\n", "from keras.models import Sequential\n", "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n", "from keras.layers import *\n", "from keras.layers.normalization import BatchNormalization\n", "from keras.layers.merge import Concatenate\n", "from keras.models import Model\n", "from keras import initializers\n", "from keras.optimizers import Adam\n", "from keras.optimizers import rmsprop\n", "from keras.layers.advanced_activations import LeakyReLU, PReLU\n", "from keras.optimizers import SGD\n", "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n", "\n", "from keras.datasets import cifar10\n", "from keras.applications.inception_v3 import InceptionV3\n", "from keras.applications.vgg16 import VGG16\n", "from keras.applications.xception import Xception\n", "from keras.applications.mobilenet import MobileNet\n", "from keras.applications.vgg19 import VGG19\n", "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n", "from keras.preprocessing import image\n", "from keras.applications.vgg16 import preprocess_input\t\n", "\n", "#Data Aug for multi-input\n", "from keras.preprocessing.image import ImageDataGenerator\n", "batch_size=32"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Define Data augmentation"]}, {"outputs": [], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# Define the image transformations here\n", "gen = ImageDataGenerator(horizontal_flip = True,\n", "                         vertical_flip = True,\n", "                         width_shift_range = 0.,\n", "                         height_shift_range = 0.,\n", "                         channel_shift_range=0,\n", "                         zoom_range = 0.5,\n", "                         rotation_range = 10)\n", "\n", "# Here is the function that merges our two generators\n", "# We use the exact same generator with the same random seed for both the y and angle arrays\n", "def gen_flow_for_two_inputs(X1, X2, y):\n", "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n", "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n", "    while True:\n", "            X1i = genX1.next()\n", "            X2i = genX2.next()\n", "            #Assert arrays are equal - this was for peace of mind, but slows down training\n", "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n", "            yield [X1i[0], X2i[1]], X1i[1]\n", "\n", "# Finally create generator\n", "def get_callbacks(filepath, patience=2):\n", "   #es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n", "   es = EarlyStopping('val_loss', patience=20, mode=\"min\")\n", "   msave = ModelCheckpoint(filepath, save_best_only=True)\n", "   return [es, msave]\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Define Model "]}, {"outputs": [], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": ["def getVggAngleModel():\n", "    input_2 = Input(shape=[1], name=\"angle\")\n", "    angle_layer = Dense(1, )(input_2)\n", "    base_model = VGG16(weights='imagenet', include_top=False, \n", "                 input_shape=X_train.shape[1:], classes=1)\n", "    x = base_model.get_layer('block5_pool').output\n", "    x = GlobalMaxPooling2D()(x)\n", "    base_model2 = keras.applications.mobilenet.MobileNet(weights=None, alpha=0.9,input_tensor = base_model.input,include_top=False, input_shape=X_train.shape[1:])\n", "\n", "    x2 = base_model2.output\n", "    x2 = GlobalAveragePooling2D()(x2)\n", "\n", "    merge_one = concatenate([x, x2, angle_layer])\n", "\n", "    merge_one = Dropout(0.6)(merge_one)\n", "    predictions = Dense(1, activation='sigmoid',kernel_initializer='he_normal')(merge_one)\n", "    \n", "    model = Model(input=[base_model.input, input_2], output=predictions)\n", "    \n", "    sgd = Adam(lr=1e-4) #SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n", "    model.compile(loss='binary_crossentropy',\n", "                  optimizer=sgd,\n", "                  metrics=['accuracy'])\n", "    return model\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Define kfold CV"]}, {"outputs": [], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": ["\n", "#Using K-fold Cross Validation with Data Augmentation.\n", "def myAngleCV(X_train, X_angle, X_test):\n", "    K=5\n", "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(X_train, target_train))\n", "    y_test_pred_log = 0\n", "    y_train_pred_log=0\n", "    y_valid_pred_log = 0.0*target_train\n", "    for j, (train_idx, test_idx) in enumerate(folds):\n", "        print('\\n===================FOLD=',j)\n", "        X_train_cv = X_train[train_idx]\n", "        y_train_cv = target_train[train_idx]\n", "        X_holdout = X_train[test_idx]\n", "        Y_holdout= target_train[test_idx]\n", "        \n", "        #Angle\n", "        X_angle_cv=X_angle[train_idx]\n", "        X_angle_hold=X_angle[test_idx]\n", "\n", "        #define file path and get callbacks\n", "        file_path = \"%s_aug_model_weights.hdf5\"%j\n", "        callbacks = get_callbacks(filepath=file_path, patience=10)\n", "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n", "        galaxyModel= getVggAngleModel()\n", "        galaxyModel.fit_generator(\n", "                gen_flow,\n", "                steps_per_epoch=24,\n", "                epochs=100,\n", "                shuffle=True,\n", "                verbose=1,\n", "                validation_data=([X_holdout,X_angle_hold], Y_holdout),\n", "                callbacks=callbacks)\n", "\n", "        #Getting the Best Model\n", "        galaxyModel.load_weights(filepath=file_path)\n", "        #Getting Training Score\n", "        score = galaxyModel.evaluate([X_train_cv,X_angle_cv], y_train_cv, verbose=0)\n", "        print('Train loss:', score[0])\n", "        print('Train accuracy:', score[1])\n", "        #Getting Test Score\n", "        score = galaxyModel.evaluate([X_holdout,X_angle_hold], Y_holdout, verbose=0)\n", "        print('Test loss:', score[0])\n", "        print('Test accuracy:', score[1])\n", "\n", "        #Getting validation Score.\n", "        pred_valid=galaxyModel.predict([X_holdout,X_angle_hold])\n", "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n", "\n", "        #Getting Test Scores\n", "        temp_test=galaxyModel.predict([X_test, X_test_angle])\n", "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n", "\n", "        #Getting Train Scores\n", "        temp_train=galaxyModel.predict([X_train, X_angle])\n", "        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n", "\n", "    y_test_pred_log=y_test_pred_log/K\n", "    y_train_pred_log=y_train_pred_log/K\n", "\n", "    print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n", "    print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n", "    return y_test_pred_log\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Run 5-fold cv\n", "(this code run 25 minutes locally on a GTX 1070)"]}, {"outputs": [], "execution_count": null, "metadata": {}, "cell_type": "code", "source": ["preds=myAngleCV(X_train, X_angle, X_test)\n", "#Submission for each day.\n", "submission = pd.DataFrame()\n", "submission['id']=test['id']\n", "submission['is_iceberg']=preds\n", "submission.to_csv('sub.csv', index=False)"]}, {"outputs": [], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": ["from IPython.display import FileLink\n", "#%cd $LESSON_HOME_DIR\n", "FileLink('sub.csv')"]}], "nbformat": 4}