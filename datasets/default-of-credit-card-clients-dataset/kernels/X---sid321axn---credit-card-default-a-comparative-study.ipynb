{"cells":[{"metadata":{"_uuid":"498a22e6a3354d6b4d7c40c097cf12ee957a30dc"},"cell_type":"markdown","source":"**Welcome to my Kernel**\n\nIn this dataset, we have to predict default payment of credit and to find which variables are the strongest predictors of default payment? and How does the probability of default payment vary by categories of different demographic variables?\n\nSo, first we will see what are features and how many features are available to predict default payment.\n\nThere are 25 variables:\n\n**1. ID:** ID of each client <br>\n**2. LIMIT_BAL:** Amount of given credit in NT dollars (includes individual and family/supplementary credit<br>\n**3. SEX:** Gender (1=male, 2=female)<br>\n**4. EDUCATION:** (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)<br>\n**5. MARRIAGE:** Marital status (1=married, 2=single, 3=others)<br>\n**6. AGE:** Age in years<br>\n**7. PAY_0:** Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months,8=payment delay for eight months, 9=payment delay for nine months and above)<br>\n**8. PAY_2:** Repayment status in August, 2005 (scale same as above)<br>\n**9. PAY_3:** Repayment status in July, 2005 (scale same as above)<br>\n**10. PAY_4:** Repayment status in June, 2005 (scale same as above)<br>\n**11. PAY_5:** Repayment status in May, 2005 (scale same as above)<br>\n**12. PAY_6:** Repayment status in April, 2005 (scale same as above)<br>\n**13. BILL_AMT1:** Amount of bill statement in September, 2005 (NT dollar)<br>\n**14. BILL_AMT2:** Amount of bill statement in August, 2005 (NT dollar)<br>\n**15. BILL_AMT3:** Amount of bill statement in July, 2005 (NT dollar)<br>\n**16. BILL_AMT4:** Amount of bill statement in June, 2005 (NT dollar)<br>\n**17. BILL_AMT5:** Amount of bill statement in May, 2005 (NT dollar)<br>\n**18. BILL_AMT6:** Amount of bill statement in April, 2005 (NT dollar)<br>\n**19. PAY_AMT1:** Amount of previous payment in September, 2005 (NT dollar)<br>\n**20. PAY_AMT2:** Amount of previous payment in August, 2005 (NT dollar)<br>\n**21. PAY_AMT3:** Amount of previous payment in July, 2005 (NT dollar)<br>\n**22. PAY_AMT4:** Amount of previous payment in June, 2005 (NT dollar)<br>\n**23. PAY_AMT5:** Amount of previous payment in May, 2005 (NT dollar)<br>\n**24. PAY_AMT6:** Amount of previous payment in April, 2005 (NT dollar)<br>\n**25. default.payment.next.month:** Default payment (1=yes, 0=no)<br>\n\nNow, we know about the overall structure of a dataset . So let's apply some of the steps that we should generally do while applying machine learning models."},{"metadata":{"_uuid":"630529a1d9f2a0033c71153f2d55615a4367ebee"},"cell_type":"markdown","source":"**STEP 1 : IMPORTING LIBRARIES**"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cross_validation import ShuffleSplit\nimport sklearn.learning_curve as curves\nfrom time import time\nimport os\nprint(os.listdir(\"../input\"))\nfrom IPython.display import display\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/UCI_Credit_Card.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f544054dba4e202ff50fb71c1dbd44c7c27366d9","trusted":true},"cell_type":"code","source":"# Now lets see how the data looks like\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87a14942ddeef260e15da6940696c32e4e366bc6","trusted":true},"cell_type":"code","source":"# Checking the last few entries of dataset to see the distribution of data\ndataset.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a76aa515ea166affeaf00b535c60b87e19630407"},"cell_type":"markdown","source":"**Step 2 : Preprocessing & Cleaning of Data**"},{"metadata":{"_uuid":"3a66334e4dd4cb9d8030ea26d3630764621006fa","trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2919414a4da3230f84db9b216ffc412d6b4812a0"},"cell_type":"markdown","source":"Means there are 30,000 entries with 25 columns"},{"metadata":{"_uuid":"eeefe576c75291a24521f9ebf854f70fdc21670b","trusted":true},"cell_type":"code","source":"# Checking the object type of all the columns to see if there is not a object type mismatch in any column \nprint(dataset.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4d71ec8d5fcff2858c0efad9dbbb9d3679beb34"},"cell_type":"markdown","source":"From the above output it is clear that there is no object type mismatch in any column."},{"metadata":{"_uuid":"08ab928ac5ab9580773decf399813209b5ff89a3","trusted":true},"cell_type":"code","source":"#Checking the number of Null entries in the data columnwise.\ndataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6489c10d5fa3f8a7fa874db2f4d71501a8bec96b"},"cell_type":"markdown","source":"**STEP 3. Data Visualization & Exploratory Data Analysis**"},{"metadata":{"_uuid":"829e802479a9c3c3872dee6ea97ef24ce970e6f9","trusted":true},"cell_type":"code","source":"# Checking the number of counts of defaulters and non defaulters sexwise\ng=sns.countplot(x=\"SEX\", data=dataset,hue=\"default.payment.next.month\", palette=\"muted\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"244efbfc628d926438f8ec2b3f7077d110c5deb0"},"cell_type":"markdown","source":"It is evident from the above output that females have overall less default payments wrt males"},{"metadata":{"_uuid":"c0869ac842763b3f6f6df154084b7adbcc51d81f","trusted":true},"cell_type":"code","source":"g=sns.countplot(x=\"MARRIAGE\", data=dataset,hue=\"default.payment.next.month\", palette=\"muted\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78842adb5d81352c8ec5a26c591d9c8ffd37a31c"},"cell_type":"markdown","source":"From the above plot it is clear that those people who have marital status single have less default payment wrt married status people."},{"metadata":{"_uuid":"5b249152180c6bb93b2c36b19f950cc42b17e742","trusted":true},"cell_type":"code","source":"sns.boxplot(x='default.payment.next.month',y='AGE',data=dataset,palette='Set2')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc720bffec89d9184f281c62ce887370e243a3cc","trusted":true},"cell_type":"code","source":"sns.boxplot(x='default.payment.next.month',hue='MARRIAGE', y='AGE',data=dataset,palette=\"Set3\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1df49eeeb000e06a0b7ec19ca27898aea26cf6c","trusted":true},"cell_type":"code","source":"sns.pairplot(dataset, hue = 'default.payment.next.month', vars = ['AGE', 'MARRIAGE', 'SEX', 'EDUCATION', 'LIMIT_BAL'] )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"118c0ec2741659c79d114d827ed0e44711063d83","trusted":true},"cell_type":"code","source":"sns.jointplot(x='LIMIT_BAL',y='AGE',data=dataset)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34e5de850e268c3e72d6686a1149b5bbcab096b8"},"cell_type":"markdown","source":"**Distribution of Male and Female according to their age**"},{"metadata":{"_uuid":"fb2192e3b711110e365c7503951235da0c6b698d","trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(data=dataset,col='SEX')\ng.map(plt.hist,'AGE')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7dc56ae254d4132f6c12bf1bde0611d79339e3cd","trusted":true},"cell_type":"code","source":"dataset['LIMIT_BAL'].plot.density(lw=5,ls='--')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eaff94037472c7cea1c0eb427a04d842da3bf49c"},"cell_type":"markdown","source":"**STEP 4. Finding Correlation**"},{"metadata":{"_uuid":"f2b845ff70407285aa5c98c4e150dc8a20290fb6","trusted":true},"cell_type":"code","source":"X = dataset.drop(['default.payment.next.month'],axis=1)\ny = dataset['default.payment.next.month']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b9725bb35bb31b659b3d89dabc9bf59680b09af","trusted":true},"cell_type":"code","source":"X.corrwith(dataset['default.payment.next.month']).plot.bar(\n        figsize = (20, 10), title = \"Correlation with Default\", fontsize = 20,\n        rot = 90, grid = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3aaea3be517d488e4a57754315a99398b9cd73c6"},"cell_type":"markdown","source":"It seems from the above graph is that most negatively correlated feature is LIMIT_BAL but we cannot blindly remove this feature because according to me it is very important feature for prediction. ID is unimportant and it has no role in prediction so we will remove it later."},{"metadata":{"_uuid":"a3952cf1ed3f36ef07ac80453425469eced3b412","trusted":true},"cell_type":"code","source":"dataset2 = dataset.drop(columns = ['default.payment.next.month'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"194afecf587b80d0f3a901560a268b148e410ee2","trusted":true},"cell_type":"code","source":"sns.set(style=\"white\")\n\n# Compute the correlation matrix\ncorr = dataset2.corr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33008b7162f52862c577cae5d0d445ca80e080f1","trusted":true},"cell_type":"code","source":"mask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(18, 15))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(250, 15, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0114096280c711fff936cb092e857ce46e05cbc"},"cell_type":"markdown","source":"**STEP 5 : SPLITTING DATA INTO TRAINING AND TESTING SET** <br>\n\nThe training dataset and test dataset must be similar, usually have the same predictors or variables. They differ on the observations and specific values in the variables. If you fit the model on the training dataset, then you implicitly minimize error or find correct responses. The fitted model provides a good prediction on the training dataset. Then you test the model on the test dataset. If the model predicts good also on the test dataset, you have more confidence. You have more confidence since the test dataset is similar to the training dataset, but not the same nor seen by the model. It means the model transfers prediction or learning in real sense.\n\nSo,by splitting dataset into training and testing subset, we can efficiently measure our trained model since it never sees testing data before.Thus it's possible to prevent overfitting.\n\nI am just splitting dataset into 20% of test data and remaining 80% will used for training the model."},{"metadata":{"_uuid":"dcfae5267b8ad2ab131bcdb993fc985ef1aed2c0","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65150d860171a93f97557abc2b4975a57d63b950"},"cell_type":"markdown","source":"**STEP 6: Normalizing the data : Feature Scaling** <br>\n\nFeature scaling through standardization (or Z-score normalization) can be an important preprocessing step for many machine learning algorithms. Standardization involves rescaling the features such that they have the properties of a standard normal distribution with a mean of zero and a standard deviation of one.\n\nWhile many algorithms (such as SVM, K-nearest neighbors, and logistic regression) require features to be normalized, "},{"metadata":{"_uuid":"79804d884b3771817c0de6e635117b04041dff3e","trusted":true},"cell_type":"code","source":"min_train = X_train.min()\nrange_train = (X_train - min_train).max()\nX_train_scaled = (X_train - min_train)/range_train","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0dedf8af91d4d6eb78c6f8d0bbbf9f705f1fc051","trusted":true},"cell_type":"code","source":"min_test = X_test.min()\nrange_test = (X_test - min_test).max()\nX_test_scaled = (X_test - min_test)/range_test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c45ad81f6ee1f7d6c5bc7393acac5afe9866ad67"},"cell_type":"markdown","source":"**STEP 7: Applying Machine Learning Models**"},{"metadata":{"_uuid":"e80a90da3aacc28f26bcc60afeb305410387d903","trusted":true},"cell_type":"code","source":"from sklearn.ensemble  import AdaBoostClassifier\nadaboost =AdaBoostClassifier()\n\nstart = time()\nadaboost.fit(X_train_scaled, y_train)\nend = time()\ntrain_time_ada=end-start","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd2fcd4c1b24463c2bc3a2b43fb7a897ba67b01e","trusted":true},"cell_type":"code","source":"y_pred = adaboost.predict(X_test_scaled)\nfrom sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\nroc=roc_auc_score(y_test, y_pred)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nresults = pd.DataFrame([['Adaboost', acc,prec,rec, f1,roc]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e288c030e6ed056a487fe56e5dbe312918fae1d9"},"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb_classifier = XGBClassifier()\nstart = time()\n\nxgb_classifier.fit(X_train_scaled, y_train,verbose=True)\nend=time()\ntrain_time_xgb=end-start","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"112761889cde92cbb6e4d5ec6d3ee6021f5014d0"},"cell_type":"code","source":"y_pred = xgb_classifier.predict(X_test_scaled)\nfrom sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\nroc=roc_auc_score(y_test, y_pred)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['XGboost', acc,prec,rec, f1,roc]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\nresults = results.append(model_results,sort=True)\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6c07602adbd55c3adf8976f065eb6fb670dc6ee"},"cell_type":"code","source":"from sklearn import linear_model\nsgd = linear_model.SGDClassifier(max_iter=1000)\nstart = time()\nsgd.fit(X_train_scaled, y_train)\nend=time()\ntrain_time_sgd=end-start","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5abd6f8b88744c27909e849ec6e54b62739a07c3"},"cell_type":"code","source":"y_pred = sgd.predict(X_test_scaled)\nfrom sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\nroc=roc_auc_score(y_test, y_pred)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['SGD 1000 iter', acc,prec,rec, f1,roc]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\nresults = results.append(model_results,sort=True)\nresults","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3886781964c2e3c64e69bb641d3c98fbc3c082f1","trusted":true},"cell_type":"code","source":"from sklearn  import ensemble\ngboost =ensemble.GradientBoostingClassifier()\nstart = time()\ngboost.fit(X_train_scaled, y_train)\nend=time()\ntrain_time_g=end-start","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"042bea48b22050580b4bacbeecd3502d24d8f02a","trusted":true},"cell_type":"code","source":"y_pred = gboost.predict(X_test_scaled)\nfrom sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\nroc=roc_auc_score(y_test, y_pred)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Gboost', acc,prec,rec, f1,roc]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\nresults = results.append(model_results,sort=True)\nresults","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edf8cfe6fae89418d9f522a333ff6005226dd9bd"},"cell_type":"markdown","source":"**Applying Random Forest with 100 trees and criterion entropy**"},{"metadata":{"_uuid":"7098ae734d8d83621b6458f3d4d81417a8d071a3","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(random_state = 47, \n                                    criterion = 'entropy',n_estimators=100)\nstart = time()\nclassifier.fit(X_train_scaled, y_train)\nend=time()\ntrain_time_r100=end-start","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"937695136fea2c18ee95cf8c4467d82ca49b631d","trusted":true},"cell_type":"code","source":"y_pred_r = classifier.predict(X_test_scaled)\nfrom sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\nroc=roc_auc_score(y_test, y_pred_r)\nacc = accuracy_score(y_test, y_pred_r)\nprec = precision_score(y_test, y_pred_r)\nrec = recall_score(y_test, y_pred_r)\nf1 = f1_score(y_test, y_pred_r)\n\nmodel_results = pd.DataFrame([['Random_forest_ent100 ', acc,prec,rec, f1,roc]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\nresults = results.append(model_results, ignore_index = True)\nresults","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ee36611ef8e6925f9af50e269860b552aa73535","trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC \n\nsvc_model = SVC(kernel='rbf', gamma=0.1,C=100)\n\nstart = time()\nsvc_model.fit(X_train_scaled, y_train)\nend=time()\ntrain_time_svc=end-start","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"643da88b19698c4861004be3be3a923bd42c1db8","trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\ny_pred_svc = svc_model.predict(X_test_scaled)\nfrom sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\nroc=roc_auc_score(y_test, y_pred_svc)\nacc = accuracy_score(y_test, y_pred_svc)\nprec = precision_score(y_test, y_pred_svc)\nrec = recall_score(y_test, y_pred_svc)\nf1 = f1_score(y_test, y_pred_svc)\n\nmodel_results = pd.DataFrame([['SVC ', acc,prec,rec, f1,roc]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\nresults = results.append(model_results, ignore_index = True)\nresults","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"40fae109bffa5a940e07c0177adcdae4ac1ee0b4","trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 7)\n\nstart = time()\nknn.fit(X_train_scaled, y_train)\nend=time()\ntrain_time_knn=end-start","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1012c1cb16318c74cd11579f8d9bbb1b3e3aad25","trusted":true},"cell_type":"code","source":"y_pred_g = knn.predict(X_test_scaled)\nfrom sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\nroc=roc_auc_score(y_test, y_pred_g)\nacc = accuracy_score(y_test, y_pred_g)\nprec = precision_score(y_test, y_pred_g)\nrec = recall_score(y_test, y_pred_g)\nf1 = f1_score(y_test, y_pred_g)\n\nmodel_results = pd.DataFrame([['KNN 7', acc,prec,rec, f1,roc]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\nresults = results.append(model_results, ignore_index = True)\nresults","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06ed5deec0a5c4e748067f50f37015e7b15d8124"},"cell_type":"markdown","source":"**STEP 8 : ANALYZING AND COMPARING  TRAINING  TIME OF MACHINE LEARNING MODELS**"},{"metadata":{"trusted":true,"_uuid":"cd323c93aa9e78486355eb2b098ae396f2701db9"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nmodel = ['Adaboost','XGBoost','SGD', 'SVC', 'GBOOST', 'Random forest', 'KNN7']\nTrain_Time = [\n    train_time_ada,\n    train_time_xgb,\n    train_time_sgd,\n    train_time_svc,\n    train_time_g,\n    train_time_r100,\n    \n    train_time_knn\n]\nindex = np.arange(len(model))\nplt.bar(index, Train_Time)\nplt.xlabel('Machine Learning Models', fontsize=15)\nplt.ylabel('Training Time', fontsize=15)\nplt.xticks(index, model, fontsize=8, )\nplt.title('Comparison of Training Time of all ML models')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc906d4b1aac45f6fdf68ffa0e95ee372caf134b"},"cell_type":"markdown","source":"As from the above graph it is evident that Adaboost and XGboost have taken very less time to train in comparison to other models where as SVC has taken maximum time the reason may be we have passed some crucial parameters to SVC."},{"metadata":{"_uuid":"bdb5c96345943d7d182e11d09bcc0241345bd9a7"},"cell_type":"markdown","source":"**STEP 9. Model Optimization**"},{"metadata":{"_uuid":"fce12419123f805aaa2509d33b09fa45a69e8073"},"cell_type":"markdown","source":"Random search outperformed grid search on this dataset across every number of iterations. Also random search seemed to converge to an optimum more quickly than grid search, which means random search with fewer iterations is comparable to grid search with more iterations.\n\nIn highdimensional parameter space, grid search would perform worse with the same iterations because points become more sparse. Also it is common that one of the hyperparameters is unimportant to finding the optimal hyperparameters, in which case grid search wastes a lot of iterations where as random search does not waste any iteration.\n\nNow we will optimize models accuracy  using Randomsearch cv.As shown in above table Adaboost performs best in this dataset. So we will try to further optimize adaboost and SVC by fine tuning its hyperparameters."},{"metadata":{"_uuid":"f46389e3598f5e4b8145a6f9581dedf69d6e3341"},"cell_type":"markdown","source":"**Parameter Tuning using random Searchcv**"},{"metadata":{"_uuid":"029dc2a79f941ac325dbae7c24d8b19ed6c36887","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV, cross_val_score\nparam_dist = {\n      'n_estimators': [10,20,50,100,120,150,200],  \n    'random_state':[47],\n        'learning_rate':[0.1,0.01,0.001,0.0001]}\n\n# run randomized search\nn_iter_search =20\nrandom_search = RandomizedSearchCV(adaboost, param_distributions=param_dist,\n                                   n_iter=n_iter_search, cv=5)\n\n\nrandom_search.fit(X_train_scaled,y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43d13f5cf0355da0e3a9aee8814f47212159a898"},"cell_type":"markdown","source":"Now, lets see what are the best parameters of adaboost"},{"metadata":{"_uuid":"164c5acf779fd54d840d38f1cc1ed42981101ada","trusted":true},"cell_type":"code","source":"random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"221532617c5096c472435fe6ef07aeda4f90e086","trusted":true},"cell_type":"code","source":"y_pred_ada = random_search.predict(X_test_scaled)\nfrom sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\nroc=roc_auc_score(y_test, y_pred_ada)\nacc = accuracy_score(y_test, y_pred_ada)\nprec = precision_score(y_test, y_pred_ada)\nrec = recall_score(y_test, y_pred_ada)\nf1 = f1_score(y_test, y_pred_ada)\n\nresults_tuned = pd.DataFrame([['Adaboost Tuned', acc,prec,rec, f1,roc]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\nresults_tuned","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f6f7a2d3c15febf9145155be2979f0b95fc922a"},"cell_type":"code","source":"from sklearn.model_selection import  RandomizedSearchCV, cross_val_score\nparam_dist ={'n_estimators': [50,100,150,200], 'max_depth': [3,5,7,10], 'min_child_weight': [2,3,4,5]} \n\n# run randomized search\nn_iter_search =10\nrandom_search = RandomizedSearchCV(xgb_classifier, param_distributions=param_dist,\n                                   n_iter=n_iter_search, cv=5)\n\n\nrandom_search.fit(X_train_scaled,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34daf781505a600247a2f179119ef80389b1b886"},"cell_type":"code","source":"random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c0f4913cc5f47160bf503ace85af04f34421ac4"},"cell_type":"code","source":"y_pred_xgb = random_search.predict(X_test_scaled)\nfrom sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\nroc=roc_auc_score(y_test, y_pred_xgb)\nacc = accuracy_score(y_test, y_pred_xgb)\nprec = precision_score(y_test, y_pred_xgb)\nrec = recall_score(y_test, y_pred_xgb)\nf1 = f1_score(y_test, y_pred_xgb)\n\nmodel =  pd.DataFrame([['XGBoost Tuned', acc,prec,rec, f1,roc]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\nresults_tuned = results_tuned.append(model, ignore_index = True)\nresults_tuned","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cee86b7990009aa71b2da8d19ca77a81937e0f33"},"cell_type":"code","source":"from sklearn.model_selection import  RandomizedSearchCV, cross_val_score\nparam_dist ={'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3], # learning rate\n    'n_iter': [1000], # number of epochs\n    'loss': ['log'], # logistic regression,\n    'penalty': ['l2'],\n    'n_jobs': [-1]} \n\n# run randomized search\nn_iter_search =8\nrandom_search = RandomizedSearchCV(sgd, param_distributions=param_dist,\n                                   n_iter=n_iter_search, cv=5)\n\n\nrandom_search.fit(X_train_scaled,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5504cb53d8012a1358754e0196e8358c1b3585d"},"cell_type":"code","source":"random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eeab5541a767fd04b5aa4540ad17f1011a770fb4"},"cell_type":"code","source":"y_pred_sgd = random_search.predict(X_test_scaled)\nfrom sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\nroc=roc_auc_score(y_test, y_pred_sgd)\nacc = accuracy_score(y_test, y_pred_sgd)\nprec = precision_score(y_test, y_pred_sgd)\nrec = recall_score(y_test, y_pred_sgd)\nf1 = f1_score(y_test, y_pred_sgd)\n\nmodel_results = pd.DataFrame([['SGD Tuned', acc,prec,rec, f1,roc]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\nresults_tuned = results_tuned.append(model_results, ignore_index = True)\nresults_tuned","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"beca3cbf73fb253d891bacdb34f64ccfc0fdff21"},"cell_type":"markdown","source":"That's great all the metrics parameters accuracy, F1 score Precision, ROC, Recall iof the  three  models adaboost,XGBoost and SGD are optimized now. Further we can also try some other combination of parameters to see if there will be further improvement or not. "},{"metadata":{"_uuid":"6654602612f45a996c91d86ce7338a3ba77885aa"},"cell_type":"markdown","source":"**Plotting of ROC Curve**"},{"metadata":{"trusted":true,"_uuid":"ba7f68a73ccb6842bfa351a058ce63530f1f2090"},"cell_type":"code","source":"from sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble  import AdaBoostClassifier,GradientBoostingClassifier,RandomForestClassifier\nfrom sklearn.svm import SVC \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import SGDClassifier\n\nplt.figure()\n\n# Add the models to the list that you want to view on the ROC plot\nmodels = [\n{\n    'label': 'Adaboost',\n    'model': AdaBoostClassifier(random_state=47,n_estimators=120,learning_rate=0.01),\n},\n{\n    'label': 'Gradient Boosting',\n    'model': GradientBoostingClassifier(),\n},\n    {\n    'label': 'XGBoost',\n    'model': XGBClassifier(),\n},\n    {\n    'label': 'SGD',\n    'model': SGDClassifier(max_iter=1000,penalty= 'l2', n_jobs= -1, loss= 'log', alpha=0.0001) ,\n},\n    \n    {\n    'label': 'KNN',\n    'model': KNeighborsClassifier(n_neighbors = 5),\n},\n    {\n    'label': 'Randomforest',\n    'model': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n            max_depth=3, max_features=10, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=10,\n            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n            oob_score=False, random_state=47, verbose=0, warm_start=False),        \n    }\n]\n\n# Below for loop iterates through your models list\nfor m in models:\n    model = m['model'] # select the model\n    model.fit(X_train_scaled, y_train) # train the model\n    y_pred=model.predict(X_test_scaled) # predict the test data\n# Compute False postive rate, and True positive rate\n    fpr, tpr, thresholds = metrics.roc_curve(y_test, model.predict_proba(X_test_scaled)[:,1])\n# Calculate Area under the curve to display on the plot\n    auc = metrics.roc_auc_score(y_test,model.predict(X_test_scaled))\n# Now, plot the computed values\n    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (m['label'], auc))\n# Custom settings for the plot \nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('1-Specificity(False Positive Rate)')\nplt.ylabel('Sensitivity(True Positive Rate)')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f6113e93538f730ebfc8e42b89fa98f352ab492","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import validation_curve\n# Create range of values for parameter\nparam_range = np.arange(1, 250, 2)\n# Calculate accuracy on training and test set using range of parameter values\ntrain_scores, test_scores = validation_curve(AdaBoostClassifier(), \n                                             X_train_scaled, \n                                             y_train, \n                                             param_name=\"n_estimators\", \n                                             param_range=param_range,\n                                             cv=3, \n                                             scoring=\"accuracy\", \n                                             n_jobs=-1)\n\n# Calculate mean and standard deviation for training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Calculate mean and standard deviation for test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\n# Plot mean accuracy scores for training and test sets\nplt.plot(param_range, train_mean, label=\"Training score\", color=\"black\")\nplt.plot(param_range, test_mean, label=\"Cross-validation score\", color=\"dimgrey\")\n\n# Plot accurancy bands for training and test sets\nplt.fill_between(param_range, train_mean - train_std, train_mean + train_std, color=\"gray\")\nplt.fill_between(param_range, test_mean - test_std, test_mean + test_std, color=\"gainsboro\")\n\n# Create plot\nplt.title(\"Validation Curve With ADABOOST\")\nplt.xlabel(\"Number Of Trees\")\nplt.ylabel(\"Accuracy Score\")\nplt.tight_layout()\nplt.legend(loc=\"best\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"998076201d4fd612a2d40bdfabe4c7fa1c98305c"},"cell_type":"markdown","source":"**Interpretation of the Validation Curve**\n\nif the number of trees are around 10, then the  model suffers from high bias. Two scores are quite close,but both the scores are too far from acceptable level so I think it's a high bias problem.In other words, the model is underfitting. \n\nAt a maximun number of trees of 250, model suffers from high variance since training score is 0.82 but validation score is about 0.81.In other words, a model is overfitting. Again, the data points suggest a sort of graceful curve. However, our model uses a very complex curve to get as close to every data point as possible. Consequently, a model with high variance has very low bias because it makes little to no assumption about the data. In fact, it adapts too much to the data.\n\nAs we see from the curve, max trees of around  30 to 40 best generalizes the unseen data. As max trees increases, bias becomes lower and variance becomes higher. We should keep the balance between the two. Just after  30 to 40 number of trees training score increase upwards and validation score starts to goes down, so I it begins to suffer from overfitting. So that's why any number of trees between 30 and 40  should be a good choice."},{"metadata":{"_uuid":"e7e4729113f9a8e8b56230e1950445da7ef58131"},"cell_type":"markdown","source":"**Conclusion**\n\nSo, we have seen that accuracy of tuned Adaboost is around 82.95% and also achieved decent  score of all other performance metric such as F1 score, Precision, ROC and Recall.\n\nFurther we can also perform model optimization by using Randomsearch or Gridsearch to find the appropriate parameters to increase the accuracy of the models.\n\nI think all these three models if properly tuned will perform better.\n\nApart from that, your valuable suggestions for further improvement and optimization are always welcome from my side do comment !!"},{"metadata":{"trusted":true,"_uuid":"28c6cbe271bb14c81427662654c720a7f5c0874f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}