{"cells":[{"metadata":{"_uuid":"57250d0f9272843c722662636889477a801c0b7a"},"cell_type":"markdown","source":"My code references https://www.kaggle.com/rdebbe/is-segnet-a-good-model-for-sharp-edge-masking"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e05f437429ec8eeac2c8afd8360d8e92873059f5"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nfrom skimage.io import imread,imshow\nfrom skimage.transform import resize\nimport os\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\n#import Augmentor\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b7e110dde52f1ac5fad35d7ad6755313e751375","collapsed":true},"cell_type":"code","source":"from keras.models import Model,Sequential\nfrom keras.layers.core import Activation, Reshape, Permute\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import Input, merge, Conv2D,Concatenate\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\nfrom keras.callbacks import ReduceLROnPlateau, TensorBoard, Callback\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\nfrom keras.losses import binary_crossentropy\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9f6908194f90a6da8c497461e337d5d5026e29d0"},"cell_type":"code","source":"IMG_ROW=IMG_COL=64\nIMG_CHANNEL=3\nTRAIN_IMG_DIR='../input/train/images/'\nTRAIN_MASK_DIR='../input/train/masks/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9d195a4a5a64fc6f7716de4349a8eaece90d5698"},"cell_type":"code","source":"def get_img_mask_array(imgpath,maskpath):\n    img=imread(imgpath)[:,:,:IMG_CHANNEL]\n    img=resize(img,(IMG_ROW,IMG_COL),mode='constant',\n               preserve_range=True)\n    mask=np.zeros((IMG_ROW,IMG_COL,1),dtype=np.bool)\n    mask_=imread(maskpath)\n    mask_=np.expand_dims(resize(mask_,(IMG_ROW,IMG_COL),\n                                mode='constant',preserve_range=True),\n                         axis=-1)\n    mask=np.maximum(mask,mask_)\n    mask1=[]\n    for i in range(len(mask)):\n        arr1=[]\n        for j in range(len(mask[i])):\n            if(mask[i][j]==0.):\n                arr1.append(1)\n                arr1.append(0)\n            else:\n                arr1.append(0)\n                arr1.append(1)\n        mask1.append(np.asarray(arr1))\n    mask1=np.asarray(mask1)\n    mask=mask1.reshape((IMG_ROW*IMG_COL,2))\n    return np.asarray(img),np.asarray(mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04172861b76680e31aab4180170c0e306ba2f875","collapsed":true},"cell_type":"code","source":"imgarray=[]\nmaskarray=[]\nfor path in os.listdir(TRAIN_IMG_DIR):\n    #print(i)\n    if(os.path.isfile(TRAIN_IMG_DIR+path)):\n        img,mask=get_img_mask_array(TRAIN_IMG_DIR+path,TRAIN_MASK_DIR+path)\n        imgarray.append(img)\n        maskarray.append(mask)\nprint(np.asarray(imgarray).shape)\nprint(np.asarray(maskarray).shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"799accdf3c7313b65368992581b98719a11df2cd"},"cell_type":"code","source":"def build_model(img_w, img_h, filters):\n    n_labels = 2\n\n    kernel = 3\n\n    encoding_layers = [\n        Conv2D(64, (kernel, kernel), input_shape=(img_h, img_w, 3), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(64, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPooling2D(),\n\n        Convolution2D(128, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(128, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPooling2D(),\n\n        Convolution2D(256, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(256, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(256, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPooling2D(),\n\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPooling2D(),\n\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPooling2D(),\n    ]\n\n    autoencoder =Sequential()\n    autoencoder.encoding_layers = encoding_layers\n\n    for l in autoencoder.encoding_layers:\n        autoencoder.add(l)\n\n    decoding_layers = [\n        UpSampling2D(),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n\n        UpSampling2D(),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(256, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n\n        UpSampling2D(),\n        Convolution2D(256, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(256, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(128, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n\n        UpSampling2D(),\n        Convolution2D(128, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(64, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n\n        UpSampling2D(),\n        Convolution2D(64, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(n_labels, (1, 1), padding='valid', activation=\"sigmoid\"),\n        BatchNormalization(),\n    ]\n    autoencoder.decoding_layers = decoding_layers\n    for l in autoencoder.decoding_layers:\n        autoencoder.add(l)\n\n    autoencoder.add(Reshape((n_labels, img_h * img_w)))\n    autoencoder.add(Permute((2, 1)))\n    autoencoder.add(Activation('softmax'))\n\n    #with open('model_5l.json', 'w') as outfile:\n    #    outfile.write(json.dumps(json.loads(autoencoder.to_json()), indent=2))\n    autoencoder.summary()\n    return autoencoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd18d10119e94a089286bf4957b122b431fac0af","collapsed":true},"cell_type":"code","source":"model=build_model(IMG_ROW,IMG_COL,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8e66b613d7107472f6ce2dc79aed9742bad580e3"},"cell_type":"code","source":"def RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"98b59bbab7daac9051239ebf96eac21cc4c5a321"},"cell_type":"code","source":"img_size_ori = 101\nimg_size_target = 64\n\ndef upsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n    #res = np.zeros((img_size_target, img_size_target), dtype=img.dtype)\n    #res[:img_size_ori, :img_size_ori] = img\n    #return res\n    \ndef downsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n    #return img[:img_size_ori, :img_size_ori]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c345370fc2b5cb9b5453a520709b6f4fb5c8955","collapsed":true},"cell_type":"code","source":"from tqdm import tqdm_notebook\n\"\"\"train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\ntrain_df = train_df.join(depths_df)\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce49445edb5159ecbf095082d436a629bf122b46","collapsed":true},"cell_type":"code","source":"#test_df.head()\ndepth=pd.read_csv('../input/depths.csv')\ntest_path='../input/test/images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dfdfcac53c3bb78470dd250320248d440a302c1a"},"cell_type":"code","source":"test_df=os.listdir(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a47aae71ea012f710d0a4d58b325c46516de9a1b"},"cell_type":"code","source":"test_df=np.asarray(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f96da4215f7a8a91ae220bf07c208d85449728a","collapsed":true},"cell_type":"code","source":"test_df[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bb896b0ea29b3d93b68b8951c49e4ca219a46d4b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b29326f0c02c3c245aaaf71bb83ec7649e8beb74","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"674aebc79ca65a90036a56ef3de0167291d43f7b","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d244611b8b76bb582ca6ba51cd90625a58b4091","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"19928025e66cfa1e3c9f65a4671c3c3a40ae6f36","collapsed":true},"cell_type":"code","source":"#pred_dict = {idx: RLenc(np.round(downsample(preds_test[i]) > 0.41)) for i, idx in enumerate(tqdm_notebook(test_df))}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a27592182100a2193319e17f70b35cbddebcdb3","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c269afc81c665e3800cd3ef7ff15b206c1d57f8c","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3f8767a9d7437523957a4705212b183788c2f342"},"cell_type":"code","source":"#!pip install kaggle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"dfec30d2e55c7d22d32e6f7d7392a9511edecbbc","collapsed":true},"cell_type":"code","source":"os.listdir('../input/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"01a3dbd7620926f36b5ae913283f81f0f70860b2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bb7f52a7d866f6d61f926f5c2fa4aaaeb280362","collapsed":true},"cell_type":"code","source":"depth.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66fa4aa68f8ada6018d4ab18b91c921607fec871","collapsed":true},"cell_type":"code","source":"#train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4ca3048589ab450a1cc241e0631c3042ff2ca121"},"cell_type":"code","source":"#sub=pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e76d6beadc732442aef56f207ba78c0151fc9be","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"029a064e51228b62ad6be8420f071730e5db0814"},"cell_type":"code","source":"def get_iou_vector(A, B):\n    batch_size = A.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        t, p = A[batch], B[batch]\n        if np.count_nonzero(t) == 0 and np.count_nonzero(p) > 0:\n            metric.append(0)\n            continue\n        if np.count_nonzero(t) >= 1 and np.count_nonzero(p) == 0:\n            metric.append(0)\n            continue\n        if np.count_nonzero(t) == 0 and np.count_nonzero(p) == 0:\n            metric.append(1)\n            continue\n\n        intersection = np.logical_and(t, p)\n        union = np.logical_or(t, p)\n        iou = np.sum(intersection > 0) / np.sum(union > 0)\n        thresholds = np.arange(0.5, 1, 0.05)\n        s = []\n        for thresh in thresholds:\n            s.append(iou > thresh)\n        metric.append(np.mean(s))\n\n    return np.mean(metric)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1bd06363439526404d218cfdcf8baf1e935022b3"},"cell_type":"code","source":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred = K.cast(y_pred, 'float32')\n    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n    intersection = y_true_f * y_pred_f\n    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n    return score\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n\ndef bce_logdice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n\ndef weighted_bce_loss(y_true, y_pred, weight):\n    epsilon = 1e-7\n    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n    logit_y_pred = K.log(y_pred / (1. - y_pred))\n    loss = weight * (logit_y_pred * (1. - y_true) + \n                     K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n    return K.sum(loss) / K.sum(weight)\n\ndef weighted_dice_loss(y_true, y_pred, weight):\n    smooth = 1.\n    w, m1, m2 = weight, y_true, y_pred\n    intersection = (m1 * m2)\n    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n    loss = 1. - K.sum(score)\n    return loss\n\ndef weighted_bce_dice_loss(y_true, y_pred):\n    y_true = K.cast(y_true, 'float32')\n    y_pred = K.cast(y_pred, 'float32')\n    # if we want to get same size of output, kernel size must be odd\n    averaged_mask = K.pool2d(\n            y_true, pool_size=(50, 50), strides=(1, 1), padding='same', pool_mode='avg')\n    weight = K.ones_like(averaged_mask)\n    w0 = K.sum(weight)\n    weight = 5. * K.exp(-5. * K.abs(averaged_mask - 0.5))\n    w1 = K.sum(weight)\n    weight *= (w0 / w1)\n    loss = weighted_bce_loss(y_true, y_pred, weight) + dice_loss(y_true, y_pred)\n    return loss\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3691dbfe17b7bf0d903093f2bf5706a9bb5029ae","collapsed":true},"cell_type":"code","source":"optimizer = Adam(lr=0.005)\nmodel.compile(loss=bce_dice_loss, optimizer=optimizer, metrics=[dice_coef])\ncallbacks=[\n    EarlyStopping(patience=5,monitor='val_loss',verbose=1),\n    ReduceLROnPlateau(patience=3,monitor='val_loss',verbose=1),\n    ModelCheckpoint('model2_with_dice.h5',save_best_only=True)\n]\nhistory=model.fit(np.asarray(imgarray),np.asarray(maskarray),epochs=40,\n                  validation_split=0.1,callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"046d7d4187910f0fac41a85dff093baec53d9fa4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a20263cd9816ce7ace84e6488f155d813b0597c5"},"cell_type":"code","source":"x_test = np.array([upsample(np.array(load_img(\"../input/test/images/{}\".format(idx), grayscale=True))) / 255 for idx in tqdm_notebook(test_df)]).reshape(-1, img_size_target, img_size_target, 3)\npreds_test = model.predict(x_test)\npred_dict={}\nfor i,idx in enumerate(tqdm_notebook(test_df)):\n    try:\n        pred_dict[idx[:-4]]=RLenc(np.round(downsample(preds_test[i]>0.41)))\n    except:\n        pred_dict[idx[:-4]]=np.NaN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3f71b683f23d9e85a59212f09eb378242b0dcef0"},"cell_type":"code","source":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f1ca18a914d17e0a32b92c213e2bd30cc76b1721"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}