{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2d054a07-f49d-cb3e-95ea-317776dc3c5e"
      },
      "source": [
        "Test simple convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "85948edd-9b17-8cc8-38d8-9db7938c55cc"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a20776da-092f-9b1a-19f5-2cf74119cfd9"
      },
      "outputs": [],
      "source": [
        "import os, cv2, random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "import seaborn as sns\n",
        "%matplotlib inline \n",
        "\n",
        "TRAIN_DIR = '../input/train/'\n",
        "TEST_DIR = '../input/test_stg1/'\n",
        "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
        "ROWS = 720\n",
        "COLS = 1280\n",
        "CHANNELS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fe8924b4-5c08-e8aa-f39a-62a649da7d24"
      },
      "outputs": [],
      "source": [
        "def get_images(fish,dirr=TRAIN_DIR):\n",
        "    \"\"\"Load files from train folder\"\"\"\n",
        "    fish_dir = dirr +'{}'.format(fish)\n",
        "    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n",
        "    return images\n",
        "\n",
        "def read_image(src):\n",
        "    \"\"\"Read and resize individual images\"\"\"\n",
        "    im = cv2.imread(src, cv2.IMREAD_COLOR)\n",
        "    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n",
        "    return im\n",
        "\n",
        "\n",
        "files = []\n",
        "y_all = []\n",
        "for i,fish in enumerate(FISH_CLASSES):\n",
        "    fish_files = get_images(fish)\n",
        "    files.extend(fish_files)\n",
        "    \n",
        "    y_fish = np.tile(i, len(fish_files))\n",
        "    y_all.extend(y_fish)\n",
        "    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n",
        "    \n",
        "y_all = np.array(y_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ab72fae2-ef66-19e8-fb8a-b53056527f3a"
      },
      "outputs": [],
      "source": [
        "X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
        "\n",
        "for i, im in enumerate(files): \n",
        "    #X_all[i] = read_image(TRAIN_DIR+im)\n",
        "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n",
        "\n",
        "print(X_all.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cb8bfb50-dc46-e524-a0eb-d3d081a7eb5d"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X_all[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "30d33dc0-9258-153e-80ed-c3dcb8ec17c4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "def CNN(inputs, is_training = True,num_classes=8):        \n",
        "        batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}\n",
        "        with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
        "                            normalizer_fn=slim.batch_norm,\n",
        "                            normalizer_params=batch_norm_params):\n",
        "            #x = tf.reshape(inputs, [-1, ROWS, COLS, CHANNELS])\n",
        "\n",
        "            # For slim.conv2d, default argument values are like\n",
        "            # normalizer_fn = None, normalizer_params = None, <== slim.arg_scope changes these arguments\n",
        "            # padding='SAME', activation_fn=nn.relu,\n",
        "            # weights_initializer = initializers.xavier_initializer(),\n",
        "            # biases_initializer = init_ops.zeros_initializer,\n",
        "            layers = 8\n",
        "            net = inputs\n",
        "            for i in range(layers):\n",
        "                net = slim.conv2d(net, 8*(2**(i)), [5, 5], scope='conv{}'.format(i))\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool{}'.format(i))\n",
        "            print(net.get_shape().as_list())\n",
        "            net = slim.flatten(net, scope='flatten3')\n",
        "\n",
        "            # For slim.fully_connected, default argument values are like\n",
        "            # activation_fn = nn.relu,\n",
        "            # normalizer_fn = None, normalizer_params = None, <== slim.arg_scope changes these arguments\n",
        "            # weights_initializer = initializers.xavier_initializer(),\n",
        "            # biases_initializer = init_ops.zeros_initializer,\n",
        "            net = slim.fully_connected(net, 1024, scope='fc3')\n",
        "            net = slim.dropout(net, is_training=is_training, scope='dropout3')  # 0.5 by default\n",
        "            outputs = slim.fully_connected(net, num_classes, activation_fn=None, normalizer_fn=None, scope='fco')\n",
        "        return outputs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f4919e95-8f24-ca0d-7480-90a2bb9e1034"
      },
      "outputs": [],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8c5be8a8-0d68-2b93-a05c-4cfd7bfe2c98"
      },
      "outputs": [],
      "source": [
        "inp = tf.placeholder(tf.float32, [None, ROWS, COLS, CHANNELS])\n",
        "lab = tf.placeholder(tf.float32, [None, 8])\n",
        "\n",
        "logits = CNN(inp)\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=lab, logits=logits))\n",
        "arg_predict = tf.argmax(logits,1)\n",
        "correct_prediction = tf.equal(arg_predict, tf.argmax(lab,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "learning_rate = 0.01\n",
        "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5f96910a-4918-85bd-78dc-3d6a730d7e90"
      },
      "outputs": [],
      "source": [
        "saverM = tf.train.Saver(tf.trainable_variables())\n",
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "tloss= 0\n",
        "tacc = 0\n",
        "display_step = 2\n",
        "global_step = 0\n",
        "epoch = 110\n",
        "batch_size = 2\n",
        "def norm(batch):\n",
        "    m = np.amax(batch)\n",
        "    mi = np.amin(batch)\n",
        "    batch = (batch - mi) / (m-mi)\n",
        "    return  (batch-0.5)\n",
        "    \n",
        "def to_one_hot(batch,cl=8):\n",
        "    y = np.zeros((len(batch),cl))\n",
        "    #batch = [np.int32(i) for i in batch]\n",
        "    y[batch] = 1.0\n",
        "    return y\n",
        "\n",
        "def  get_batch(batch_size):\n",
        "    X_all = np.ndarray((batch_size, ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
        "    ids_train = random.sample(range(0, len(files)), batch_size)\n",
        "    for i, im in enumerate(files[ids_train]): \n",
        "        X_all[i] = read_image(TRAIN_DIR+im)\n",
        "        \n",
        "    return X_all, y_all[ids_train]\n",
        "    \n",
        "for i in range(global_step,epoch):\n",
        "            \n",
        "            #batch_xs = X_all[ids_train]\n",
        "            #batch_ys = y_all[ids_train]\n",
        "            batch_xs, batch_ys = get_batch(batch_size)\n",
        "            _,loss, acc = sess.run([train_step,cross_entropy,accuracy ],\n",
        "                                        feed_dict={inp: norm(batch_xs), \n",
        "                                                   lab: to_one_hot(batch_ys)})\n",
        "            tloss += loss\n",
        "            tacc += acc\n",
        "            if i% display_step == 0 and i>0:\n",
        "                print('step:',i, ' loss train:',round(tloss/display_step,4), \n",
        "                      ', acc train:', round(tacc/display_step,4))\n",
        "                tloss= 0\n",
        "                tacc = 0\n",
        "if False:     \n",
        "    model_dir = \"\"\n",
        "    if not os.path.isdir(model_dir) and False:\n",
        "                  os.makedirs(model_dir)\n",
        "    checkpoint_file = os.path.join(model_dir, 'checkpoint')\n",
        "    saverM.save(sess, checkpoint_file, global_step=epoch)\n",
        "    print('model saved!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d7e7e275-f27d-3919-3a55-246a560b6fca"
      },
      "outputs": [],
      "source": [
        "batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "31710463-f68f-6d39-c91d-956867421d90"
      },
      "outputs": [],
      "source": [
        "test_files = [im for im in os.listdir(TEST_DIR)]\n",
        "test = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
        "id_img = []\n",
        "\n",
        "for i, im in enumerate(test_files): \n",
        "    test[i] = read_image(TEST_DIR+im)\n",
        "    id_img.append(im)\n",
        "test.shape , id_img[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "33a540eb-23ca-25f2-c9a8-ee7e368ae84f"
      },
      "outputs": [],
      "source": [
        "submit = open('submit.SVM.csv','w')\n",
        "submit.write('image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\\n')\n",
        "i=0\n",
        "while i<test.shape[0]:\n",
        "    xx = norm(test[i:i+batch_size])\n",
        "    y_pred = sess.run([logits],feed_dict={inp: xx, lab: np.zeros((len(xx),8))})\n",
        "    \n",
        "    for idx in range(len(y_pred)):\n",
        "        probs=['%s' % p for p in y_pred[idx]]        \n",
        "        submit.write('%s,%s\\n' % (id_img[(i)+idx],','.join(probs)))\n",
        "        \n",
        "    i += batch_size\n",
        "submit.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7c300e0d-7c71-638b-7eac-4da11311d43a"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "502d76b9-87bc-9013-9d34-1368c071ea70"
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dbf4c54c-4e86-d030-7ff9-c38ee7c038fa"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}