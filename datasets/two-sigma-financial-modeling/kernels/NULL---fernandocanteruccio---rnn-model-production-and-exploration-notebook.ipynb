{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "21aea7ea-c393-c133-84d2-797921a7b99e"
      },
      "source": [
        "# RNN Model Production and Exploration Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "615f83f5-71c6-33d5-85fd-83040b7661b4"
      },
      "outputs": [],
      "source": [
        "# import modules\n",
        "import kagglegym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, LSTM\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn import preprocessing as pp\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from time import time\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b82ab515-7617-db13-a88f-82827deeade4"
      },
      "outputs": [],
      "source": [
        "# Start environment\n",
        "env = kagglegym.make()\n",
        "observation = env.reset()\n",
        "train = observation.train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "31d32e64-5dc0-44c8-25be-f03f2ca9b8cc"
      },
      "source": [
        "Lets print our dataset head to see how it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b4ee3bb4-3f66-828c-531e-4a2aff59e0d2"
      },
      "outputs": [],
      "source": [
        "observation.train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f948e52c-e920-1245-d5e9-369d5e5780dd"
      },
      "outputs": [],
      "source": [
        "# Data preprocessing\n",
        "\n",
        "# https://www.kaggle.com/bguberfain/two-sigma-financial-modeling/univariate-model-with-clip/run/482189/code\n",
        "# Clipped target value range to use\n",
        "low_y_cut = -0.086093\n",
        "high_y_cut = 0.093497\n",
        "\n",
        "y_is_above_cut = (train.y > high_y_cut)\n",
        "y_is_below_cut = (train.y < low_y_cut)\n",
        "y_is_within_cut = (~y_is_above_cut & ~y_is_below_cut)\n",
        "\n",
        "# Select the features to use\n",
        "excl = ['id', 'sample', 'y', 'timestamp']\n",
        "#feature_vars = [c for c in train.columns if c not in excl]\n",
        "features_to_use = ['technical_30', 'technical_20', 'technical_19', 'fundamental_11']\n",
        "target_var = ['y']\n",
        "\n",
        "features = train.loc[y_is_within_cut, features_to_use]\n",
        "X_train = features.values\n",
        "\n",
        "targets = train.loc[y_is_within_cut, target_var]\n",
        "y_train = targets.values\n",
        "\n",
        "im = pp.Imputer(strategy='median')\n",
        "X_train = im.fit_transform(X_train)\n",
        "X_scaler = pp.RobustScaler()\n",
        "X_train = X_scaler.fit_transform(X_train)\n",
        "y_scaler = pp.RobustScaler()\n",
        "y_train = y_scaler.fit_transform(y_train.reshape([-1,1]))\n",
        "\n",
        "X_train = pd.DataFrame(X_train, columns=features_to_use)\n",
        "y_train = pd.DataFrame(y_train, columns=target_var)\n",
        "preprocess_dict = {'fillna': im, 'X_scaler': X_scaler, 'y_scaler': y_scaler}\n",
        "\n",
        "del y_is_above_cut, y_is_below_cut, excl, targets, features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2c70aac9-f19c-c030-cc8f-cb31a5346159"
      },
      "source": [
        "Lets take a peek in our dataset head again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dec25d94-9813-00eb-aa54-46d3830a2091"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7d9263d9-3d87-90ce-6a1e-20c6528bee56"
      },
      "source": [
        "Right! Now we have scaled values and without NaN values. Better this way!\n",
        "Now we can start to build our models. This time we gonna try some deep neural network arquitetures and see how it performs. Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f296f4b-3001-cfc0-df3f-8555152b9c96"
      },
      "outputs": [],
      "source": [
        "def dnn(shape,timesteps,l2_coef,drop_coef):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(shape[1], input_shape=(timesteps, shape[0])))\n",
        "    model.add(Dense(shape[2], input_dim=shape[0], init='he_uniform', W_regularizer=l2(l2_coef)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(drop_coef))\n",
        "    model.add(Dense(shape[3], init='he_uniform', W_regularizer=l2(l2_coef)))\n",
        "\n",
        "    optm = SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=True)\n",
        "    model.compile(loss='mse',\n",
        "                  optimizer=optm,\n",
        "                  metrics=None,\n",
        "                  verbose=2)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "48ee4ef3-eb7c-046a-b251-e942a0c5e05b"
      },
      "outputs": [],
      "source": [
        "print(\"Training model\")\n",
        "t0 = time()\n",
        "timesteps = 1\n",
        "X_train_ts = pad_sequences(np.reshape(X_train.values, (X_train.values.shape[0], timesteps, X_train.values.shape[1])))\n",
        "print(X_train_ts.shape)\n",
        "model1 = dnn(shape=[4,8,64,1],timesteps=timesteps,l2_coef=0.0001,drop_coef=0.7)\n",
        "model1.fit(X_train_ts, y_train.values,\n",
        "          nb_epoch=33,\n",
        "          batch_size=X_train.values.shape[0],\n",
        "          verbose=2\n",
        "          );\n",
        "print(\"Done! Training time:\", time() - t0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "de091747-97d7-62f6-51e6-abd9f37ed277"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluating model on training set\")\n",
        "t0 = time()\n",
        "m1_loss = model1.evaluate(X_train_ts, y_train.values, batch_size=X_train.values.shape[0], verbose=0)\n",
        "print(\"Done! Eval time:\",time() - t0)\n",
        "print(\"Mean squared error for train dataset:\",m1_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "367d3ff3-1e94-45b9-7f3c-db8f7aa20996"
      },
      "outputs": [],
      "source": [
        "print(\"Predicting target on training dataset\")\n",
        "t0 = time()\n",
        "m1_preds = model1.predict(X_train_ts, batch_size=X_train.values.shape[0], verbose=0)\n",
        "score = r2_score(y_train, m1_preds)\n",
        "print(\"Done! Prediction time:\",time() - t0)\n",
        "print(\"R2 score for train dataset\",score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "40f1cfe4-fe62-4b7a-518f-19624786790f"
      },
      "outputs": [],
      "source": [
        "# Predict-step-predict routine ################################################################################\n",
        "def gen_preds(model, preprocess_dict, features_to_use, print_info=True):\n",
        "    env = kagglegym.make()\n",
        "    # We get our initial observation by calling \"reset\"\n",
        "    observation = env.reset()\n",
        "\n",
        "    im = preprocess_dict['fillna']\n",
        "    X_scaler = preprocess_dict['X_scaler']\n",
        "    y_scaler = preprocess_dict['y_scaler']\n",
        "    \n",
        "    reward = 0.0\n",
        "    reward_log = []\n",
        "    timestamps_log = []\n",
        "    pos_count = 0\n",
        "    neg_count = 0\n",
        "\n",
        "    total_pos = []\n",
        "    total_neg = []\n",
        "\n",
        "    print(\"Predicting\")\n",
        "    t0= time()\n",
        "    while True:\n",
        "    #    observation.features.fillna(mean_values, inplace=True)\n",
        "\n",
        "        # Predict with model\n",
        "        features_dnn = im.transform(observation.features.loc[:,features_to_use].values)\n",
        "        features_dnn = X_scaler.transform(features_dnn)\n",
        "        \n",
        "        features_dnn_ts = pad_sequences(np.reshape(features_dnn,\n",
        "                                                   (features_dnn.shape[0], timesteps, features_dnn.shape[1])))\n",
        "\n",
        "        y_dnn = model.predict(features_dnn_ts,batch_size=features_dnn.shape[0],\n",
        "                              verbose=0).clip(low_y_cut, high_y_cut)\n",
        "\n",
        "        # Fill target df with predictions \n",
        "        observation.target.y = y_scaler.inverse_transform(y_dnn)\n",
        "\n",
        "        observation.target.fillna(0, inplace=True)\n",
        "        target = observation.target\n",
        "        timestamp = observation.features[\"timestamp\"][0]\n",
        "        \n",
        "        observation, reward, done, info = env.step(target)\n",
        "\n",
        "        timestamps_log.append(timestamp)\n",
        "        reward_log.append(reward)\n",
        "\n",
        "        if (reward < 0):\n",
        "            neg_count += 1\n",
        "        else:\n",
        "            pos_count += 1\n",
        "\n",
        "        total_pos.append(pos_count)\n",
        "        total_neg.append(neg_count)\n",
        "        \n",
        "        if timestamp % 100 == 0:\n",
        "            if print_info:\n",
        "                print(\"Timestamp #{}\".format(timestamp))\n",
        "                print(\"Step reward:\", reward)\n",
        "                print(\"Mean reward:\", np.mean(reward_log[-timestamp:]))\n",
        "                print(\"Positive rewards count: {0}, Negative rewards count: {1}\".format(pos_count, neg_count))\n",
        "                print(\"Positive reward %:\", pos_count / (pos_count + neg_count) * 100)\n",
        "\n",
        "            pos_count = 0\n",
        "            neg_count = 0\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "    print(\"Done: %.1fs\" % (time() - t0))\n",
        "    print(\"Total reward sum:\", np.sum(reward_log))\n",
        "    print(\"Final reward mean:\", np.mean(reward_log))\n",
        "    print(\"Total positive rewards count: {0}, Total negative rewards count: {1}\".format(np.sum(total_pos),\n",
        "                                                                                        np.sum(total_neg)))\n",
        "    print(\"Final positive reward %:\", np.sum(total_pos) / (np.sum(total_pos) + np.sum(total_neg)) * 100)\n",
        "    print(info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c679d322-8aa3-2654-fd71-d225f4ea2489"
      },
      "outputs": [],
      "source": [
        "gen_preds(model1, preprocess_dict, features_to_use)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9db8a68a-fe2a-964b-ec8f-60e4c0bef6b2"
      },
      "source": [
        "### Analysing Training Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "33880a48-6d4e-5314-6a69-f8bb341480b7"
      },
      "outputs": [],
      "source": [
        "market_df = observation.train[['timestamp', 'y']].groupby('timestamp').agg([np.mean, np.std]).reset_index()\n",
        "y_mean = np.array(market_df['y']['mean'])\n",
        "t = market_df['timestamp']\n",
        "\n",
        "print(\"Predicting target on training dataset\")\n",
        "t0 = time()\n",
        "m1_preds = model1.predict(X_train_ts, batch_size=X_train_ts.shape[0], verbose=0)\n",
        "score = r2_score(y_train, m1_preds)\n",
        "print(\"Done! Prediction time:\",time() - t0)\n",
        "print(\"R2 score for train dataset\",score)\n",
        "cum_ret = np.log(1+y_mean).cumsum()\n",
        "pred_ret = pd.DataFrame(np.vstack((observation.train.timestamp.loc[y_is_within_cut], m1_preds[:,0])).T,\n",
        "                        columns=['timestamp','y']).groupby('timestamp').agg([np.mean, np.std]).reset_index()\n",
        "cum_pred1 = np.log(1+pred_ret['y']['mean']).cumsum()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,7))\n",
        "ax.set_xlabel(\"Timestamp\");\n",
        "ax.set_title(\"Cumulative target signal and predictions over time\");\n",
        "sns.tsplot(cum_ret,t,ax=ax,color='b');\n",
        "sns.tsplot(cum_pred1,t,ax=ax,color='r');\n",
        "ax.set_ylabel('Target / Prediction');\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,7))\n",
        "ax.set_title(\"Target Variable Distribution. (True vs Prediction)\");\n",
        "#plt.ylim([0, 100000])\n",
        "sns.distplot(observation.train.y ,ax=ax, color='b', kde=False, bins=100);\n",
        "sns.distplot(m1_preds ,ax=ax, color='r', kde=False, bins=100);\n",
        "ax.set_ylabel('Target / Prediction');"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}