{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "344dd1d4-fd11-8f03-417b-0195ce44b12e"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "\"\"\"image_classification.py: Classify images to classify fish types\"\"\"\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import joblib\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.cluster import vq\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "__author__ = \"Pradeep Kumar A.V.\"\n",
        "\n",
        "\n",
        "CLASSES = {\n",
        "    'ALB': 1,\n",
        "    'BET': 2,\n",
        "    'DOL': 3,\n",
        "    'LAG': 4,\n",
        "    'NoF': 5,\n",
        "    'OTHER': 6,\n",
        "    'SHARK': 7,\n",
        "    'YFT': 8\n",
        "}\n",
        "\n",
        "CLASSES_REV = {value: key for key, value in CLASSES.items()}\n",
        "\n",
        "\n",
        "class Saliency(object):\n",
        "    \"\"\"Generate saliency map from RGB images with the spectral residual method\n",
        "\n",
        "        This class implements an algorithm that is based on the spectral\n",
        "        residual approach (Hou & Zhang, 2007).\n",
        "    \"\"\"\n",
        "    def __init__(self, img, use_numpy_fft=True, gauss_kernel=(3, 3)):\n",
        "        \"\"\"Constructor\n",
        "\n",
        "            This method initializes the saliency algorithm.\n",
        "\n",
        "            :param img: an RGB input image\n",
        "            :param use_numpy_fft: flag whether to use NumPy's FFT (True) or\n",
        "                                  OpenCV's FFT (False)\n",
        "            :param gauss_kernel: Kernel size for Gaussian blur\n",
        "        \"\"\"\n",
        "        self.use_numpy_fft = use_numpy_fft\n",
        "        self.gauss_kernel = gauss_kernel\n",
        "        self.frame_orig = self._enhance_image(img)\n",
        "\n",
        "        # downsample image for processing\n",
        "        self.small_shape = (24, 24)\n",
        "        self.frame_small = cv2.resize(img, self.small_shape[1::-1])\n",
        "\n",
        "    @staticmethod\n",
        "    def _enhance_image(img):\n",
        "        \"\"\"\n",
        "        :param img: RGB color image\n",
        "        :return: enhanced image\n",
        "        \"\"\"\n",
        "        img_yuv = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
        "\n",
        "        # equalize the histogram of the Y channel\n",
        "        img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])\n",
        "\n",
        "        # convert the YUV image back to RGB format\n",
        "        img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
        "        return img_output\n",
        "\n",
        "    def get_saliency_map(self):\n",
        "        \"\"\"Returns a saliency map\n",
        "\n",
        "            This method generates a saliency map for the image that was\n",
        "            passed to the class constructor.\n",
        "\n",
        "            :returns: grayscale saliency map\n",
        "        \"\"\"\n",
        "        # haven't calculated saliency map for this image yet\n",
        "        # multiple channels: consider each channel independently\n",
        "        sal = np.zeros_like(self.frame_small).astype(np.float32)\n",
        "        for c in xrange(self.frame_small.shape[2]):\n",
        "            small = self.frame_small[:, :, c]\n",
        "            sal[:, :, c] = self._get_channel_sal_magn(small)\n",
        "\n",
        "        # overall saliency: channel mean\n",
        "        sal = np.mean(sal, 2)\n",
        "\n",
        "        # postprocess: blur, square, and normalize\n",
        "        if self.gauss_kernel is not None:\n",
        "            sal = cv2.GaussianBlur(sal, self.gauss_kernel, sigmaX=1,\n",
        "                                   sigmaY=0)\n",
        "        sal **= 2\n",
        "        sal = np.float32(sal)/np.max(sal)\n",
        "\n",
        "        # scale up\n",
        "        sal = cv2.resize(sal, self.frame_orig.shape[1::-1])\n",
        "\n",
        "        return sal\n",
        "\n",
        "    def _get_channel_sal_magn(self, channel):\n",
        "        \"\"\"Returns the log-magnitude of the Fourier spectrum\n",
        "\n",
        "            This method calculates the log-magnitude of the Fourier spectrum\n",
        "            of a single-channel image. This image could be a regular grayscale\n",
        "            image, or a single color channel of an RGB image.\n",
        "\n",
        "            :param channel: single-channel input image\n",
        "            :returns: log-magnitude of Fourier spectrum\n",
        "        \"\"\"\n",
        "        # do FFT and get log-spectrum\n",
        "        if self.use_numpy_fft:\n",
        "            img_dft = np.fft.fft2(channel)\n",
        "            magnitude, angle = cv2.cartToPolar(np.real(img_dft),\n",
        "                                               np.imag(img_dft))\n",
        "        else:\n",
        "            img_dft = cv2.dft(np.float32(channel),\n",
        "                              flags=cv2.DFT_COMPLEX_OUTPUT)\n",
        "            magnitude, angle = cv2.cartToPolar(img_dft[:, :, 0],\n",
        "                                               img_dft[:, :, 1])\n",
        "\n",
        "        # get log amplitude\n",
        "        log_ampl = np.log10(magnitude.clip(min=1e-9))\n",
        "\n",
        "        # blur log amplitude with avg filter\n",
        "        log_ampl_blur = cv2.blur(log_ampl, (3, 3))\n",
        "\n",
        "        # residual\n",
        "        residual = np.exp(log_ampl - log_ampl_blur)\n",
        "\n",
        "        # back to cartesian frequency domain\n",
        "        if self.use_numpy_fft:\n",
        "            real_part, imag_part = cv2.polarToCart(residual, angle)\n",
        "            img_combined = np.fft.ifft2(real_part + 1j*imag_part)\n",
        "            magnitude, _ = cv2.cartToPolar(np.real(img_combined),\n",
        "                                           np.imag(img_combined))\n",
        "        else:\n",
        "            img_dft[:, :, 0], img_dft[:, :, 1] = cv2.polarToCart(residual,\n",
        "                                                                 angle)\n",
        "            img_combined = cv2.idft(img_dft)\n",
        "            magnitude, _ = cv2.cartToPolar(img_combined[:, :, 0],\n",
        "                                           img_combined[:, :, 1])\n",
        "\n",
        "        return magnitude\n",
        "\n",
        "\n",
        "class FishClassifierBOVW(object):\n",
        "    def __init__(self, pre_trained_model=None, descriptor='ORB',\n",
        "                 n_visual_words=5, use_saliency=False):\n",
        "        self.model = joblib.load(pre_trained_model) \\\n",
        "            if pre_trained_model else None\n",
        "        self.n_visual_words = n_visual_words\n",
        "        self.descriptor = descriptor\n",
        "        self.use_saliency = use_saliency\n",
        "\n",
        "    # Helper functions\n",
        "    @staticmethod\n",
        "    def _load_img(path):\n",
        "        \"\"\"\n",
        "        :param path: path of image to be loaded.\n",
        "        :return: cv2 image object\n",
        "        \"\"\"\n",
        "        img = cv2.imread(path)\n",
        "        # Convert the image from cv2 default BGR format to RGB\n",
        "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    @staticmethod\n",
        "    def _pretty_print(msg):\n",
        "            print()\n",
        "            print('=' * len(msg))\n",
        "            print(msg)\n",
        "            print('=' * len(msg))\n",
        "\n",
        "    def _detect_and_describe(self, image):\n",
        "        \"\"\"\n",
        "        :param image: Input RGB color image\n",
        "        :return: keypoints and features tuple\n",
        "        \"\"\"\n",
        "        # detect and extract features from the image\n",
        "        if self.descriptor == 'SIFT':\n",
        "            descriptor = cv2.xfeatures2d.SIFT_create()\n",
        "        elif self.descriptor == 'ORB':\n",
        "            descriptor = cv2.ORB_create()\n",
        "        else:\n",
        "            data = image.reshape((-1, 3))\n",
        "            data = np.float32(data)\n",
        "            return None, data\n",
        "        (kps, features) = descriptor.detectAndCompute(image, None)\n",
        "\n",
        "        # convert the keypoints from KeyPoint objects to NumPy\n",
        "        # arrays\n",
        "        kps = np.float32([kp.pt for kp in kps])\n",
        "        features = np.float32(features)\n",
        "\n",
        "        # return a tuple of keypoints and features\n",
        "        return kps, features\n",
        "\n",
        "    @staticmethod\n",
        "    def _kmeans_clustering(data, k=5):\n",
        "        \"\"\"\n",
        "        :param data: input data\n",
        "        :param k: K value\n",
        "        :return: k-Means clusters\n",
        "        \"\"\"\n",
        "        crit = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "        flags = cv2.KMEANS_RANDOM_CENTERS\n",
        "        ret, label, centers = cv2.kmeans(data, k, None, crit, 10, flags)\n",
        "        return centers\n",
        "\n",
        "    #  Main wrapper methods\n",
        "\n",
        "    def _extract_img_features(self, img_data_dir, mode='train'):\n",
        "        \"\"\"\n",
        "        :param img_data_dir: directory path where the images reside.\n",
        "         The training images should reside in class named folders\n",
        "        :param: mode: 'train' or 'test'\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if mode == 'train':\n",
        "            files = glob.glob(\"%s/*/*\" % img_data_dir)\n",
        "        else:\n",
        "            files = glob.glob(\"%s/*\" % img_data_dir)\n",
        "        dataset_size = len(files)\n",
        "        resp = np.zeros((dataset_size, 1))\n",
        "\n",
        "        print(\"\\nProcessing images, and generating descriptors..\\n\")\n",
        "        ctr = 0\n",
        "        des_list = []\n",
        "        for f in files:\n",
        "            print(\"Processing image %s\" % f)\n",
        "            img = self._load_img(f)\n",
        "            if self.use_saliency:\n",
        "                sal = Saliency(img)\n",
        "                smap = sal.get_saliency_map()\n",
        "                img[:, :, 0] *= smap\n",
        "                img[:, :, 1] *= smap\n",
        "                img[:, :, 2] *= smap\n",
        "            kpts, des = self._detect_and_describe(img)\n",
        "            des_list.append((f, des))\n",
        "            if type == 'train':\n",
        "                resp[ctr] = CLASSES[f.split('/')[-2]]\n",
        "                ctr += 1\n",
        "\n",
        "        descriptors = des_list[0][1]\n",
        "        for image_path, descriptor in des_list[1:]:\n",
        "            descriptors = np.vstack((descriptors, descriptor))\n",
        "\n",
        "        print(\"\\nClustering the descriptors to form BOVW dictionary..\\n\")\n",
        "        centers = self._kmeans_clustering(descriptors, self.n_visual_words)\n",
        "        im_features = np.zeros((dataset_size, self.n_visual_words), \"float32\")\n",
        "        for i in range(dataset_size):\n",
        "            words, distance = vq.vq(des_list[i][1], centers)\n",
        "            for w in words:\n",
        "                im_features[i][w] += 1\n",
        "\n",
        "        # Scaling the values of features\n",
        "        slr = StandardScaler().fit(im_features)\n",
        "        im_features = slr.transform(im_features)\n",
        "\n",
        "        resp = np.float32(resp)\n",
        "        return files, im_features, resp\n",
        "\n",
        "    def train_classifier(self, train_data_dir, save_model=True):\n",
        "        \"\"\"\n",
        "        :param train_data_dir: training data directory\n",
        "        :param save_model: save classifier model as a pickle file\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # Extract features and train the classifier\n",
        "        self._pretty_print(\"Extracting training image features\")\n",
        "        train_files, train_data, train_resp = \\\n",
        "            self._extract_img_features(train_data_dir)\n",
        "        self._pretty_print(\"Training the classifier\")\n",
        "        self.model = GaussianNB()\n",
        "        self.model.fit(train_data, train_resp)\n",
        "        if save_model:\n",
        "            joblib.dump(self.model, 'model.pkl', protocol=2)\n",
        "\n",
        "    def test_classifier(self, test_data_dir, submission_file=\"submission.csv\"):\n",
        "        \"\"\"\n",
        "        :param test_data_dir: test data directory\n",
        "        :param submission_file: file name to save predictions\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        self._pretty_print(\"Extracting testing image features\")\n",
        "        test_files, test_data, test_resp = \\\n",
        "            self._extract_img_features(test_data_dir, type='test')\n",
        "        self._pretty_print(\"Testing the classifier\")\n",
        "        predictions = self.model.predict_proba(test_data)\n",
        "\n",
        "        columns = [CLASSES_REV[int(entry)] for entry in self.model.classes_]\n",
        "        submission = pd.DataFrame(predictions, columns=columns)\n",
        "        images = [f.split('/')[-1] for f in test_files]\n",
        "        submission.insert(0, 'image', images)\n",
        "        submission.head()\n",
        "        submission.to_csv(submission_file, index=False)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main wrapper to call the classifier\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    pre_trained_model_file = 'model.pkl'\n",
        "    training_data_dir = '../input/train'\n",
        "    testing_data_dir = '../input/test_stg1'\n",
        "    submission_file_name = 'Bag_of_visual_words_ORB_NB.csv'\n",
        "\n",
        "    parameters = {\n",
        "        'descriptor': 'ORB',\n",
        "        'n_visual_words': 5,\n",
        "        'use_saliency': True\n",
        "    }\n",
        "\n",
        "    if os.path.exists(pre_trained_model_file):\n",
        "        cls = FishClassifierBOVW(pre_trained_model_file, **parameters)\n",
        "        cls.train_classifier(training_data_dir)\n",
        "    else:\n",
        "        cls = FishClassifierBOVW(**parameters)\n",
        "\n",
        "    cls.test_classifier(testing_data_dir, submission_file_name)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c90be43c-7fd9-ad89-a9f0-359241900855"
      },
      "outputs": [],
      "source": [
        "from subprocess import check_output\n",
        "print(check_output([\"ls\"]).decode(\"utf8\"))"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}