{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1cda80eb-38f9-9456-3aa6-71b99e0351d1"
      },
      "source": [
        "In this notebook I will train and cross-validate an algorithm to predict credit card fraud, with highest possible \"accuracy\". Due to the highly imbalanced nature of the data we need to be careful how to measure error. I will distinguish between two types of error: (a) percentage of frauds detected among non-fraudulent transactions (1st kind), and (b) percentage of frauds that are not recognized (2nd kind)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "64f7436b-4006-44dd-7113-f527301e03c9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "df = pd.read_csv(\"../input/creditcard.csv\")\n",
        "df_orig = df.copy(deep = True)        # keep a copy for cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1233d4fb-cb1f-fc1e-6644-17e7b41dd35d"
      },
      "source": [
        "I have tried several algorithms, but Logistic Regression performed best (I cannot tell about SVC - I have tried it, but I had to abort it after many hours). Note the weight-option - this compensates for the imbalance of classes (i.e. fraud vs. non-fraud):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ed0f4ab7-cf0d-1031-0dcd-3fd66e84dd03"
      },
      "outputs": [],
      "source": [
        "lrn = LogisticRegression(penalty = 'l2', C= 1, class_weight='balanced' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "04e6a988-4f34-ba0b-2e44-32bce11c901e"
      },
      "source": [
        "Now I will shuffle the data, split it into a training set (80%) and a test set (20%), train the algorithm on the training set, and then test it. I repeat this N times, in order to get a good measure of the quality of the classifier. For sake of clarity I define functions that I will loop over afterwards."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a0d18b32-6b6d-e7f2-148d-ad2527991035"
      },
      "source": [
        "Create training and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "57400c59-e1ee-a6be-f301-5bfb941578e5"
      },
      "outputs": [],
      "source": [
        "def create_sets():\n",
        "    df = df_orig.copy(deep = True)\n",
        "    df = df.sample(frac=1).reset_index(drop=True)        #shuffle\n",
        "    \n",
        "    y = df.Class.tolist()\n",
        "    df = df.drop('Class', 1)\n",
        "    X = df.as_matrix()\n",
        "    \n",
        "    # create test and training set\n",
        "    p = 0.2                      #fraction of test sample\n",
        "    X_test = X[:int(p*len(y))]\n",
        "    y_test = y[:int(p*len(y))]\n",
        "    X_train = X[int(p*len(y)):]\n",
        "    y_train = y[int(p*len(y)):]\n",
        "    return X_test, y_test, X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6c7dec33-5788-597f-b725-b5fb84432653"
      },
      "source": [
        "Training of the algorithm and then testing it. For testing, we count the errors of first and second kind (see first paragraph):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ec8e8fa6-856c-81bc-3f19-4e44c265d558"
      },
      "outputs": [],
      "source": [
        "def train_test():\n",
        "    X_test, y_test, X_train, y_train = create_sets()\n",
        "    \n",
        "    lrn.fit(X_train, y_train)\n",
        "    \n",
        "    y_predict = lrn.predict(X_test)\n",
        "\n",
        "    # count the errors:\n",
        "    c_0 = 0\n",
        "    c_1 = 0\n",
        "    for i in range(len(y_test)):\n",
        "        if (y_test[i] == 0) and (y_predict[i] == 1):\n",
        "            c_0 += 1\n",
        "        if (y_test[i] == 1) and (y_predict[i] == 0):\n",
        "            c_1 += 1\n",
        "\n",
        "    n_fraud = np.sum(y_test)\n",
        "    return (100*c_0)/(len(y_test)-n_fraud), (100*c_1)/(n_fraud)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b969ee3a-0d50-dc16-8128-966a9f07ac9c"
      },
      "source": [
        "Now we will run through train_test() many times in order to get good estimates for the errors (I have used this crossvalidation for different algorithms, as well in order to obtain the optimal C in the logistic regression):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ea4165c8-1689-b7fb-b776-2cf5eec74880"
      },
      "outputs": [],
      "source": [
        "N = 10        #number of iterations\n",
        "f_1 = 0      #counts the errors of the first kind (already in percent)\n",
        "f_2 = 0      #counts the errors of the second kind\n",
        "for n in range(N):\n",
        "    a, b = train_test()\n",
        "    f_1 += a\n",
        "    f_2 += b\n",
        "\n",
        "print(\"Error of first kind  = {}%\".format(((10*f_1)//N)/10))\n",
        "print(\"Error of second kind = {}%\".format(((10*f_2)//N)/10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "55173692-a52e-1250-5656-4fa604488a4c"
      },
      "source": [
        "This is not too bad - however, there is still room for improvement. One aspect might be to reduce the error of first kind - 2% false alarms for non-fraudulent transactions can be pretty annoying in practice."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}