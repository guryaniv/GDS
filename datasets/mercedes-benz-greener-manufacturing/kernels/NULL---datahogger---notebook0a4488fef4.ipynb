{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "abf82a49-eb9d-5a1f-a802-f69fe7a3133e"
      },
      "source": [
        "#This is my first Kernel!! \n",
        "##Performing first level data exploration which I've used to sketch my game plan. \n",
        "\n",
        "Comments welcome! \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "adb84317-435e-87f1-e7ce-510858407497"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import spearmanr\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7c2d9e6e-a07e-0895-5912-e75b92610522"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a160d8be-4d73-1a22-edcc-6e9c13777cec"
      },
      "source": [
        "Rudimentary Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0368b2d5-6763-1a4e-010f-4b742885d339"
      },
      "outputs": [],
      "source": [
        "print(\"Are there NaNs in the dataset?: \",train.isnull().values.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c2279c7c-53b7-8c64-7804-5c8aec687af5"
      },
      "outputs": [],
      "source": [
        "binary = []\n",
        "cate = []\n",
        "for c in train:\n",
        "    if c == 'ID' or c == 'y':\n",
        "        pass\n",
        "    else:\n",
        "        if train[[c]].isin([0,1]).all().values :\n",
        "            binary.append(c)\n",
        "        else:\n",
        "            cate.append(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f8f6a283-b348-e9ef-37a3-0e54ff05a760"
      },
      "outputs": [],
      "source": [
        "print(\"Number of Binary features      \",len(binary))\n",
        "print(\"Number of Categorical features \",len(cate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d12bf8ce-da42-7ed2-cc20-c33f053ff102"
      },
      "outputs": [],
      "source": [
        "qq = [ np.unique(train[[x]].values) for x in cate]\n",
        "xq = [i for xqq in qq for i in xqq] # flattening\n",
        "w = np.unique(xq,return_counts=True)\n",
        "if np.all(w[1] == 1):\n",
        "    print(\"All of the entries in categorical features are unique.\")\n",
        "else:\n",
        "    print(\"There is a repetition of entries across the categorical features.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5ce4dab7-9928-4c13-4062-8d17c6df1ead"
      },
      "source": [
        "#Trends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "068a5c46-4a88-2b32-0e94-f737502029f0"
      },
      "outputs": [],
      "source": [
        "sr = []\n",
        "for x in binary:\n",
        "    try :\n",
        "        sr.append(spearmanr(train[[x]].values,train[['y']])[0])\n",
        "    except:\n",
        "        sr.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "639e9e10-bf71-3a4f-b2e5-fb70b80c0441"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(40,20))\n",
        "plt.plot(sr,'-r',lw=1)\n",
        "plt.grid(True)\n",
        "plt.xticks(np.arange(len(sr)),binary,rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4688bd8d-a91e-00ee-3476-2d0d284dcfc3"
      },
      "source": [
        "##Mutual Information\n",
        "\n",
        "The code used here is taken from MIFS(Mutual Information Feature Selection)[MIFS][1] and from [GIST][2]. \n",
        "While the original code kind of returns NaNs for large datasets, I used Stirling approximation so that the gamma function doesn't return NaNs.\n",
        "\n",
        "There is still a major trouble here and that is, the mutual information is returning negative.  Will be a great help if you can explain me why it fails!!\n",
        "  [1]: https://github.com/danielhomola/mifs/\n",
        "  [2]: https://gist.github.com/GaelVaroquaux/ead9898bd3c973c40429"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45dd1223-e2a1-e8fc-04e0-35961f9986b7"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.special import gamma,psi\n",
        "from scipy import ndimage\n",
        "from scipy.linalg import det\n",
        "from numpy import pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bd692b70-d360-cdda-99a7-95ce4b46bbf5"
      },
      "outputs": [],
      "source": [
        "def MI_DC(x, y, k):\n",
        "    \"\"\"\n",
        "    Calculates the mututal information between a continuous vector x and a\n",
        "    disrete class vector y.\n",
        "    This implementation can calculate the MI between the joint distribution of\n",
        "    one or more continuous variables (X[:, 1:3]) with a discrete variable (y).\n",
        "    Thanks to Adam Pocock, the author of the FEAST package for the idea.\n",
        "    Brian C. Ross, 2014, PLOS ONE\n",
        "    Mutual Information between Discrete and Continuous Data Sets\n",
        "    \"\"\"\n",
        "    y = y.flatten()\n",
        "    n = x.shape[0]\n",
        "    classes = np.unique(y)\n",
        "    knn = NearestNeighbors(n_neighbors=k)\n",
        "    # distance to kth in-class neighbour\n",
        "    d2k = np.empty(n)\n",
        "    # number of points within each point's class\n",
        "    Nx = []\n",
        "    for yi in y:\n",
        "        Nx.append(np.sum(y == yi))\n",
        "\n",
        "    # find the distance of the kth in-class point\n",
        "    for c in classes:\n",
        "        mask = np.where(y == c)[0]\n",
        "        knn.fit(x[mask, :])\n",
        "        d2k[mask] = knn.kneighbors()[0][:, -1]\n",
        "\n",
        "    # find the number of points within the distance of the kth in-class point\n",
        "    knn.fit(x)\n",
        "    m = knn.radius_neighbors(radius=d2k, return_distance=False)\n",
        "    m = [i.shape[0] for i in m]\n",
        "\n",
        "    # calculate MI based on Equation 2 in Ross 2014\n",
        "    MI = psi(n) - np.mean(psi(Nx)) + psi(k) - np.mean(psi(m))\n",
        "    return MI\n",
        "\n",
        "\n",
        "def MI_CC(variables, k=1):\n",
        "    \"\"\"\n",
        "    Returns the mutual information between any number of variables.\n",
        "    Here it is used to estimate MI between continuous X(s) and y.\n",
        "    Written by Gael Varoquaux:\n",
        "    https://gist.github.com/GaelVaroquaux/ead9898bd3c973c40429\n",
        "    \"\"\"\n",
        "\n",
        "    all_vars = np.hstack(variables)\n",
        "    return (sum([Entropy(X, k=k) for X in variables]) -\n",
        "            Entropy(all_vars, k=k))\n",
        "\n",
        "\n",
        "def Nearest_Distance(X, k=1):\n",
        "    '''\n",
        "    X = array(N,M)\n",
        "    N = number of points\n",
        "    M = number of dimensions\n",
        "    returns the distance to the kth nearest neighbor for every point in X\n",
        "    '''\n",
        "    knn = NearestNeighbors(n_neighbors=k)\n",
        "    knn.fit(X)\n",
        "    d, _ = knn.kneighbors(X) # the first nearest neighbor is itself\n",
        "    return d[:, -1] # returns the distance to the kth nearest neighbor\n",
        "\n",
        "def Entropy(X, k=1):\n",
        "    ''' Returns the entropy of the X.\n",
        "    Parameters\n",
        "    ===========\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        The data the entropy of which is computed\n",
        "    k : int, optional\n",
        "        number of nearest neighbors for density estimation\n",
        "    Notes\n",
        "    ======\n",
        "    Kozachenko, L. F. & Leonenko, N. N. 1987 Sample estimate of entropy\n",
        "    of a random vector. Probl. Inf. Transm. 23, 95-101.\n",
        "    See also: Evans, D. 2008 A computationally efficient estimator for\n",
        "    mutual information, Proc. R. Soc. A 464 (2093), 1203-1215.\n",
        "    and:\n",
        "    Kraskov A, Stogbauer H, Grassberger P. (2004). Estimating mutual\n",
        "    information. Phys Rev E 69(6 Pt 2):066138.\n",
        "    '''\n",
        "\n",
        "    # Distance to kth nearest neighbor\n",
        "    r = Nearest_Distance(X, k) # squared distances\n",
        "    n, d = X.shape\n",
        "#     volume_unit_ball = (pi**(.5*d)) / gamma(.5*d + 1)\n",
        "    ge = .5*d + 1\n",
        "    lv = 0.5*d*np.log(pi) - .5*np.log(2*pi*ge) - ge*np.log(ge) + ge - d*np.log(2)\n",
        "    '''\n",
        "    F. Perez-Cruz, (2008). Estimation of Information Theoretic Measures\n",
        "    for Continuous Random Variables. Advances in Neural Information\n",
        "    Processing Systems 21 (NIPS). Vancouver (Canada), December.\n",
        "    return d*mean(log(r))+log(volume_unit_ball)+log(n-1)-log(k)\n",
        "    '''\n",
        "    return (d*np.mean(np.log(r + np.finfo(np.float).eps))\n",
        "            + lv + psi(n) - psi(k))\n",
        "\n",
        "\n",
        "def MI(variables, k=1):\n",
        "    '''\n",
        "    Returns the mutual information between any number of variables.\n",
        "    Each variable is a matrix X = array(n_samples, n_features)\n",
        "    where\n",
        "      n = number of samples\n",
        "      dx,dy = number of dimensions\n",
        "    Optionally, the following keyword argument can be specified:\n",
        "      k = number of nearest neighbors for density estimation\n",
        "    Example: mutual_information((X, Y)), mutual_information((X, Y, Z), k=5)\n",
        "    '''\n",
        "    if len(variables) < 2:\n",
        "        raise AttributeError(\n",
        "                \"Mutual information must involve at least 2 variables\")\n",
        "    all_vars = np.hstack(variables)\n",
        "    return (sum([Entropy(X, k=k) for X in variables])\n",
        "            - Entropy(all_vars, k=k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f6fdea4d-e31a-630e-7495-cb57bdf96e4c"
      },
      "outputs": [],
      "source": [
        "midc = []\n",
        "for x in binary:\n",
        "    try :\n",
        "        z = MI_CC([train[['y']].values,train[[x]].values],3)\n",
        "        midc.append(z)\n",
        "    except:\n",
        "        print(\"x\",x)\n",
        "        midc.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "860be3ab-66e3-373c-7a01-0c9ea749c3c8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(40,20))\n",
        "plt.plot(midc,'-r',lw=1)\n",
        "plt.grid(True)\n",
        "plt.xticks(np.arange(len(midc)),binary,rotation=90)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}