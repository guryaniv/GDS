{"cells": [{"source": [], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "b13c8256d6b43bde80ed575d942bda4099ad3392", "_cell_guid": "cb03b7aa-cc9b-4106-b6bc-e797b99695c6"}}, {"source": ["#load with pandas, manipulate with numpy, plot with matplotlib\n", "import numpy as np \n", "import pandas as pd \n", "import matplotlib.pyplot as plt\n", "import cv2\n", "from skimage import filters\n", "from skimage import data, exposure\n", "from sklearn.feature_extraction import image\n", "from sklearn.cluster import spectral_clustering\n", "from scipy import ndimage\n", "\n", "\n", "from sklearn.mixture import GMM\n", "\n", "\n", "#ML - we will classify using a naive xgb with stratified cross validation\n", "import xgboost as xgb\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.metrics import log_loss\n", "\n", "\n", "\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "e6b43e7b7d786bc565deb7c52acd78d2885d9837", "_cell_guid": "08e02f57-9c97-487a-ab0d-b2afad161d53"}}, {"source": ["#filenames\n", "inputFolder = \"../input/\"\n", "trainSet = 'train.json'\n", "#testSet = 'test.json'\n", "subName = 'iceberg-svd-xgb-3fold.csv'\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "027ce3e753ae41fbe6600369f6dd38047e1fdd59", "_cell_guid": "232aecf4-a711-415c-8b23-d277824788c3"}}, {"source": ["#load data\n", "trainDF = pd.read_json(inputFolder+trainSet)\n", "#testDF = pd.read_json(inputFolder+testSet)"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "f52fbe147c7723767b3f03200c9746ba5abdaae5", "_cell_guid": "2d055ac8-6c5d-4bd3-8f93-c981379fe57a"}}, {"source": ["trainDF.head(15)"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "f580f9b454f136aa5c10f950bec1358f32f11dfe", "_cell_guid": "9b3ba319-00d2-4899-872a-33a65f1baca0"}}, {"source": ["#get numpy arrays for train/test data, prob there is a more pythonic approach\n", "band1 = trainDF['band_1'].values\n", "im1 = np.zeros((len(band1),len(band1[0])))\n", "for j in range(len(band1)):\n", "    im1[j,:]=np.asarray(band1[j])\n", "    \n", "band2 = trainDF['band_2'].values\n", "im2 = np.zeros((len(band2),len(band2[0])))\n", "for j in range(len(band2)):\n", "    im2[j,:]=np.asarray(band2[j])\n", "    \n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "7f08caa08f99b025488c086b4a610333e306d087", "_cell_guid": "a2ff70e4-e630-419b-b6b3-9a8be46a7014"}}, {"source": ["basic view\n", "---"], "cell_type": "markdown", "metadata": {"_uuid": "4e1004363a6628deb377f64d7610cb66337b0c3b", "_cell_guid": "80d7b907-ea64-4f60-a102-aeec7ffa9e24"}}, {"source": ["\n", "from time import time\n", "\n", "import matplotlib.pyplot as plt\n", "from mpl_toolkits.mplot3d import Axes3D\n", "from matplotlib.ticker import NullFormatter\n", "import random\n", "from sklearn import manifold, datasets\n", "\n", "# Next line to silence pyflakes. This import is needed.\n", "Axes3D\n", "image=im1[6,:]\n", "image2=im2[6,:]\n", "image=image-image.min()\n", "image=image/image.max()*254+1\n", "image2=image2-image2.min()\n", "image2=image2/image2.max()*254+1\n", "n_points = 75*75\n", "\n", "X, color = datasets.samples_generator.make_s_curve(n_points, random_state=0)\n", "for xi in range(0,75):\n", "    for yi in range(0,75):\n", "        X[xi+yi*75,0]=xi+random.random()/100\n", "        X[xi+yi*75,1]=yi+random.random()/100 #image[xi+yi*75]\n", "        X[xi+yi*75,2]=image[xi+yi*75]/2+image2[xi+yi*75]/2+random.random()/100\n", "color=image               \n", "n_neighbors = 15\n", "n_components = 2\n", "\n", "fig = plt.figure(figsize=(20, 10))\n", "plt.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n", "             % (1000, n_neighbors), fontsize=14)\n", "\n", "\n", "ax = fig.add_subplot(251, projection='3d')\n", "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)\n", "ax.view_init(4, -72)\n", "\n", "methods = ['standard', 'hessian', 'modified', 'ltsa']\n", "labels = ['LLE', 'Hessian LLE', 'Modified LLE', 'LTSA']\n", "\n", "for i, method in enumerate(methods):\n", "    t0 = time()\n", "    Y = manifold.LocallyLinearEmbedding(n_neighbors, n_components,\n", "                                        eigen_solver='auto',\n", "                                        method=method).fit_transform(X)\n", "    t1 = time()\n", "    print(\"%s: %.2g sec\" % (methods[i], t1 - t0))\n", "\n", "    ax = fig.add_subplot(252 + i)\n", "    plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\n", "    plt.title(\"%s (%.2g sec)\" % (labels[i], t1 - t0))\n", "    ax.xaxis.set_major_formatter(NullFormatter())\n", "    ax.yaxis.set_major_formatter(NullFormatter())\n", "    plt.axis('tight')\n", "\n", "t0 = time()\n", "Y = manifold.Isomap(n_neighbors, n_components).fit_transform(X)\n", "t1 = time()\n", "print(\"Isomap: %.2g sec\" % (t1 - t0))\n", "ax = fig.add_subplot(257)\n", "plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\n", "plt.title(\"Isomap (%.2g sec)\" % (t1 - t0))\n", "ax.xaxis.set_major_formatter(NullFormatter())\n", "ax.yaxis.set_major_formatter(NullFormatter())\n", "plt.axis('tight')\n", "\n", "\n", "t0 = time()\n", "mds = manifold.MDS(n_components, max_iter=100, n_init=1)\n", "Y = mds.fit_transform(X)\n", "t1 = time()\n", "print(\"MDS: %.2g sec\" % (t1 - t0))\n", "ax = fig.add_subplot(258)\n", "plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\n", "plt.title(\"MDS (%.2g sec)\" % (t1 - t0))\n", "ax.xaxis.set_major_formatter(NullFormatter())\n", "ax.yaxis.set_major_formatter(NullFormatter())\n", "plt.axis('tight')\n", "\n", "\n", "t0 = time()\n", "se = manifold.SpectralEmbedding(n_components=n_components,\n", "                                n_neighbors=n_neighbors)\n", "Y = se.fit_transform(X)\n", "t1 = time()\n", "print(\"SpectralEmbedding: %.2g sec\" % (t1 - t0))\n", "ax = fig.add_subplot(259)\n", "plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\n", "plt.title(\"SpectralEmbedding (%.2g sec)\" % (t1 - t0))\n", "ax.xaxis.set_major_formatter(NullFormatter())\n", "ax.yaxis.set_major_formatter(NullFormatter())\n", "plt.axis('tight')\n", "\n", "t0 = time()\n", "tsne = manifold.TSNE(n_components=n_components, init='pca', random_state=0)\n", "Y = tsne.fit_transform(X)\n", "t1 = time()\n", "print(\"t-SNE: %.2g sec\" % (t1 - t0))\n", "ax = fig.add_subplot(2, 5, 10)\n", "plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\n", "plt.title(\"t-SNE (%.2g sec)\" % (t1 - t0))\n", "ax.xaxis.set_major_formatter(NullFormatter())\n", "ax.yaxis.set_major_formatter(NullFormatter())\n", "plt.axis('tight')\n", "\n", "plt.show()"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"scrolled": true}}, {"source": ["import time\n", "import warnings\n", "\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "from sklearn import cluster, datasets, mixture\n", "from sklearn.neighbors import kneighbors_graph\n", "from sklearn.preprocessing import StandardScaler\n", "from itertools import cycle, islice\n", "imagematrix=np.reshape(im1[6,:],(75,75))\n", "imagematrix=imagematrix-imagematrix.min()\n", "no_structure = imagematrix,None\n", "np.random.seed(0)\n", "\n", "# ============\n", "# Generate datasets. We choose the size big enough to see the scalability\n", "# of the algorithms, but not too big to avoid too long running times\n", "# ============\n", "\n", "# ============\n", "# Set up cluster parameters\n", "# ============\n", "plt.figure(figsize=(9 * 2 + 3, 12.5))\n", "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n", "                    hspace=.01)\n", "\n", "plot_num = 1\n", "\n", "default_base = {'quantile': .3,\n", "                'eps': .3,\n", "                'damping': .9,\n", "                'preference': -200,\n", "                'n_neighbors': 10,\n", "                'n_clusters': 3}\n", "\n", "datasets = [ (no_structure, {})]\n", "\n", "for i_dataset, (dataset, algo_params) in enumerate(datasets):\n", "    # update parameters with dataset-specific values\n", "    params = default_base.copy()\n", "    params.update(algo_params)\n", "\n", "    X, y = dataset\n", "\n", "    # normalize dataset for easier parameter selection\n", "    X = StandardScaler().fit_transform(X)\n", "\n", "    # estimate bandwidth for mean shift\n", "    bandwidth = cluster.estimate_bandwidth(X, quantile=params['quantile'])\n", "\n", "    # connectivity matrix for structured Ward\n", "    connectivity = kneighbors_graph(\n", "        X, n_neighbors=params['n_neighbors'], include_self=False)\n", "    # make connectivity symmetric\n", "    connectivity = 0.5 * (connectivity + connectivity.T)\n", "\n", "    # ============\n", "    # Create cluster objects\n", "    # ============\n", "    ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n", "    two_means = cluster.MiniBatchKMeans(n_clusters=params['n_clusters'])\n", "    ward = cluster.AgglomerativeClustering(\n", "        n_clusters=params['n_clusters'], linkage='ward',\n", "        connectivity=connectivity)\n", "    spectral = cluster.SpectralClustering(\n", "        n_clusters=params['n_clusters'], eigen_solver='arpack',\n", "        affinity=\"nearest_neighbors\")\n", "    dbscan = cluster.DBSCAN(eps=params['eps'])\n", "    affinity_propagation = cluster.AffinityPropagation(\n", "        damping=params['damping'], preference=params['preference'])\n", "    average_linkage = cluster.AgglomerativeClustering(\n", "        linkage=\"average\", affinity=\"cityblock\",\n", "        n_clusters=params['n_clusters'], connectivity=connectivity)\n", "    birch = cluster.Birch(n_clusters=params['n_clusters'])\n", "    gmm = mixture.GaussianMixture(\n", "        n_components=params['n_clusters'], covariance_type='full')\n", "\n", "    clustering_algorithms = (\n", "        ('MiniBatchKMeans', two_means),\n", "        ('AffinityPropagation', affinity_propagation),\n", "        ('MeanShift', ms),\n", "        ('SpectralClustering', spectral),\n", "        ('Ward', ward),\n", "        ('AgglomerativeClustering', average_linkage),\n", "        ('Birch', birch),\n", "        ('GaussianMixture', gmm)\n", "    )\n", "\n", "    for name, algorithm in clustering_algorithms:\n", "        t0 = time.time()\n", "\n", "        # catch warnings related to kneighbors_graph\n", "        with warnings.catch_warnings():\n", "            warnings.filterwarnings(\n", "                \"ignore\",\n", "                message=\"the number of connected components of the \" +\n", "                \"connectivity matrix is [0-9]{1,2}\" +\n", "                \" > 1. Completing it to avoid stopping the tree early.\",\n", "                category=UserWarning)\n", "            warnings.filterwarnings(\n", "                \"ignore\",\n", "                message=\"Graph is not fully connected, spectral embedding\" +\n", "                \" may not work as expected.\",\n", "                category=UserWarning)\n", "            algorithm.fit(X)\n", "\n", "        t1 = time.time()\n", "        if hasattr(algorithm, 'labels_'):\n", "            y_pred = algorithm.labels_.astype(np.int)\n", "        else:\n", "            y_pred = algorithm.predict(X)\n", "\n", "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n", "        if i_dataset == 0:\n", "            plt.title(name, size=18)\n", "\n", "        colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n", "                                             '#f781bf', '#a65628', '#984ea3',\n", "                                             '#999999', '#e41a1c', '#dede00']),\n", "                                      int(max(y_pred) + 1))))\n", "        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n", "\n", "        plt.xlim(-2.5, 2.5)\n", "        plt.ylim(-2.5, 2.5)\n", "        plt.xticks(())\n", "        plt.yticks(())\n", "        plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n", "                 transform=plt.gca().transAxes, size=15,\n", "                 horizontalalignment='right')\n", "        plot_num += 1\n", "\n", "plt.show()"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": ["import time\n", "\n", "import numpy as np\n", "import scipy as sp\n", "import matplotlib.pyplot as plt\n", "\n", "from sklearn.feature_extraction import image\n", "from sklearn.cluster import spectral_clustering\n", "\n", "for xi in range(0,15):\n", "    face=np.reshape(im1[xi,:],(75,75))\n", "    face= face-face.min()\n", "    face= face/face.max()*255\n", "    # Resize it to 10% of the original size to speed up the processing\n", "    face = sp.misc.imresize(face, 0.5) / 255.\n", "\n", "    # Convert the image into a graph with the value of the gradient on the\n", "    # edges.\n", "    graph = image.img_to_graph(face)\n", "\n", "    # Take a decreasing function of the gradient: an exponential\n", "    # The smaller beta is, the more independent the segmentation is of the\n", "    # actual image. For beta=1, the segmentation is close to a voronoi\n", "    beta = 2\n", "    eps = 1e-6\n", "    graph.data = np.exp(-beta * graph.data / graph.data.std()) + eps\n", "\n", "    # Apply spectral clustering (this step goes much faster if you have pyamg\n", "    # installed)\n", "    N_REGIONS = 2\n", "\n", "    for assign_labels in ('kmeans', 'discretize'):\n", "        t0 = time.time()\n", "        labels = spectral_clustering(graph, n_clusters=N_REGIONS,\n", "                                 assign_labels=assign_labels, random_state=1)\n", "        t1 = time.time()\n", "        labels = labels.reshape(face.shape)\n", "\n", "        plt.figure(figsize=(5, 5))\n", "        plt.imshow(face, cmap=plt.cm.gray)\n", "        for l in range(N_REGIONS):\n", "            plt.contour(labels == l, contours=1,\n", "                        colors=[plt.cm.spectral(l / float(N_REGIONS))])\n", "        plt.xticks(())\n", "        plt.yticks(())\n", "        title = 'Spectral clustering: %s, %.2fs' % (assign_labels, (t1 - t0))\n", "        print(title)\n", "        plt.title(title)\n", "    plt.show()"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "53d0866f7f7c37e403e38923dd364fffeb6002fa", "_cell_guid": "f5f22393-aed1-442e-937e-031f1fdc9396"}}, {"source": [], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "106820a81529defc2c11d2f02f0709efd2bd8785", "_cell_guid": "c9652703-d59d-46c6-92e9-d8c19ac3c3c2"}}, {"source": ["from sklearn.metrics.pairwise import cosine_similarity\n", "\n", "\n", "for xi in range(0,15):\n", "    image=np.reshape(im1[xi,:],(75,75))\n", "    Ui,si,Vi=np.linalg.svd(image)\n", "    imagecore=Ui[:,:3].dot(Vi[:,:3].T)\n", "    image=np.corrcoef(imagecore)\n", "    imainv=np.linalg.inv(image)    \n", "    imacos=cosine_similarity(Ui[:,:3],Vi[:,:3])\n", "\n", "    fig, ax = plt.subplots(1,2) \n", "    ax[0].imshow(imagecore, cmap='nipy_spectral',interpolation='nearest')\n", "    ax[1].imshow( imacos, cmap='nipy_spectral', interpolation='nearest')\n", "    ax[1].set_xlabel(trainDF.iloc[xi]['is_iceberg'])\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "59930dd75691f984099d9ec896581bba41e683ba", "_cell_guid": "9811d193-c0b6-4bf7-b7ce-102af9dc5afb"}}, {"source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral,\n", "                                 denoise_wavelet, estimate_sigma)\n", "from skimage import data, img_as_float, color\n", "from skimage.util import random_noise\n", "\n", "\n", "original =np.reshape(im1[xi,:],(75,75))\n", "original = original-original.min()\n", "original = (original+original.T)/2\n", "#original = original * 255/original.max()\n", "#print(original)\n", "sigma = original.std()*4\n", "noisy = random_noise(original, var=sigma**2)\n", "\n", "fig, ax = plt.subplots(nrows=2, ncols=4, figsize=(8, 5), sharex=True,\n", "                       sharey=True, subplot_kw={'adjustable': 'box-forced'})\n", "\n", "plt.gray()\n", "\n", "# Estimate the average noise standard deviation across color channels.\n", "sigma_est = estimate_sigma(noisy, multichannel=True, average_sigmas=True)\n", "# Due to clipping in random_noise, the estimate will be a bit smaller than the\n", "# specified sigma.\n", "print(\"Estimated Gaussian noise standard deviation = {}\".format(sigma_est))\n", "\n", "ax[0, 0].imshow(noisy)\n", "ax[0, 0].axis('off')\n", "ax[0, 0].set_title('Noisy')\n", "ax[0, 1].imshow(denoise_tv_chambolle(noisy, weight=0.1, multichannel=False))\n", "ax[0, 1].axis('off')\n", "ax[0, 1].set_title('TV')\n", "ax[0, 2].imshow(denoise_bilateral(noisy, sigma_color=0.05, sigma_spatial=15,\n", "                multichannel=False))\n", "ax[0, 2].axis('off')\n", "ax[0, 2].set_title('Bilateral')\n", "ax[0, 3].imshow(denoise_wavelet(noisy, multichannel=False))\n", "ax[0, 3].axis('off')\n", "ax[0, 3].set_title('Wavelet denoising')\n", "\n", "ax[1, 1].imshow(denoise_tv_chambolle(noisy, weight=0.2, multichannel=False))\n", "ax[1, 1].axis('off')\n", "ax[1, 1].set_title('(more) TV')\n", "ax[1, 2].imshow(denoise_bilateral(noisy, sigma_color=0.1, sigma_spatial=15,\n", "                multichannel=False))\n", "ax[1, 2].axis('off')\n", "ax[1, 2].set_title('(more) Bilateral')\n", "ax[1, 3].imshow(denoise_wavelet(noisy, multichannel=True, convert2ycbcr=False))\n", "ax[1, 3].axis('off')\n", "ax[1, 3].set_title('Wavelet denoising\\nin YCbCr colorspace')\n", "ax[1, 0].imshow(original)\n", "ax[1, 0].axis('off')\n", "ax[1, 0].set_title('Original')\n", "\n", "fig.tight_layout()\n", "\n", "plt.show()"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "f51550fc566a93618311f7694994b73f0e46cc7b", "_cell_guid": "dcb0ee9f-16c2-42db-b8d7-e5ae9e4ace56"}}, {"source": ["statistical\n", "---\n", "* above mean\n", "*  normalized "], "cell_type": "markdown", "metadata": {"_uuid": "eddf283d245376f7597ab6f1db736a09274e0634", "_cell_guid": "e2ff92a2-8ddb-4f70-b52f-926d15fd80fb"}}, {"source": ["for xi in range(0,15):\n", "    image=np.reshape(im1[xi,:],(75,75))\n", "    fig, ax = plt.subplots(1,2) \n", "    ax[0].imshow(image*(image > image.mean()), cmap='nipy_spectral', interpolation='nearest')\n", "    ax[1].imshow( ( image -image.min() )/ (image.max()-image.min() )*image.var(), cmap='nipy_spectral', interpolation='nearest')\n", "    ax[1].set_xlabel(trainDF.iloc[xi]['is_iceberg'])\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "0cebdd8231772bc8bebcf8320bb0c72fe208ac0a", "_cell_guid": "5ffa65f1-5533-4f53-b0d4-f821059127e2"}}, {"source": ["gaussian filter\n", "---\n", "pure noise filter\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "ddeada0895d3fcf63e832753676c805d60172c7b", "_cell_guid": "fd75405c-e4da-4f89-b2ca-2d20c6df7bf1"}}, {"source": ["for xi in range(0,15):\n", "    image=np.reshape(im1[xi,:],(75,75))\n", "    fig, ax = plt.subplots(1,2) \n", "    image_gf=ndimage.gaussian_filter(image, 3)\n", "    image_perf=image*(image*1.3 < image_gf)\n", "    ax[0].imshow(image_gf)\n", "    ax[1].imshow(image_perf)\n", "    ax[1].set_xlabel(trainDF.iloc[xi]['is_iceberg'])\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "21357c8adf7a8d87fc4529f2f856cf3e022baa96", "_cell_guid": "a094c3c3-62df-47d1-a6b5-31199f4948ff"}}, {"source": ["gaussian laplace\n", "---"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "268ee70359147ce8c6a2e162f5c9d0d20669a964", "_cell_guid": "ed4e05cf-4c71-46cb-890e-6cf2056ccfb6"}}, {"source": ["for xi in range(0,15):\n", "    image=np.reshape(im1[xi,:],(75,75))\n", "    image_gl=ndimage.filters.gaussian_laplace(image, image.std(), output=None, mode='reflect', cval=0.0)\n", "    fig, ax = plt.subplots(1,2) \n", "    ax[0].imshow(image_gl)\n", "    ax[1].imshow(image_gl, cmap='nipy_spectral', interpolation='nearest')\n", "    ax[1].set_xlabel(trainDF.iloc[xi]['is_iceberg'])\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "2e35ca6732e0cfe6750d62b8ecb43be467076d74", "_cell_guid": "c97c58f0-b2c6-45ec-8361-26919e8aad85"}}, {"source": ["\n", "#hsobel_text = filters.sobel_h(image)\n", "#val = filters.threshold_otsu(image)\n", "\n", "for xi in range(0,15):\n", "    image=np.reshape(im1[xi,:],(75,75))    \n", "    hist, bin_edges = np.histogram(image, bins=60)\n", "    #print(hist.shape, bin_edges.shape)\n", "    camera_equalized = exposure.equalize_hist(image)\n", "\n", "    threshold = np.mean(image)-image.std()\n", "    binary_img = image > threshold\n", "    fig, ax = plt.subplots(1,4) \n", "    ax[0].hist(img, bins=20)\n", "    ax[1].imshow(image*binary_img, cmap='nipy_spectral', interpolation='nearest')\n", "    ax[3].imshow(camera_equalized)\n", "\n", "\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "965cc1220c4946e27e8f36982a44f9c4112d4369", "_cell_guid": "25fa4fcb-a1cf-40e1-ac65-bb84cd4669b3"}}, {"source": ["from math import sqrt\n", "from skimage import data\n", "from skimage.feature import blob_dog, blob_log, blob_doh\n", "from skimage.color import rgb2gray\n", "\n", "import matplotlib.pyplot as plt\n", "\n", "for xi in range(0,15):\n", "    image=np.reshape(im1[xi,:],(75,75))\n", "    image_gray = rgb2gray(image)\n", "    blobs_log = blob_log(image_gray, max_sigma=30, num_sigma=10, threshold=.1)\n", "    # Compute radii in the 3rd column.\n", "    blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n", "    blobs_dog = blob_dog(image_gray, max_sigma=30, threshold=.0001)\n", "    blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n", "    blobs_doh = blob_doh(image_gray, max_sigma=30, threshold=.1)\n", "    blobs_list = [blobs_log, blobs_dog, blobs_doh]\n", "    colors = ['yellow', 'lime', 'red']\n", "    titles = ['Laplacian of Gaussian', 'Difference of Gaussian',\n", "          'Determinant of Hessian']\n", "    sequence = zip(blobs_list, colors, titles)\n", "\n", "    fig, axes = plt.subplots(1, 3, figsize=(9, 3), sharex=True, sharey=True,\n", "                         subplot_kw={'adjustable': 'box-forced'})\n", "    ax = axes.ravel()\n", "\n", "    for idx, (blobs, color, title) in enumerate(sequence):\n", "        ax[idx].set_title(title)\n", "        ax[idx].imshow(image, interpolation='nearest')\n", "        for blob in blobs:\n", "            y, x, r = blob\n", "            c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)\n", "            ax[idx].add_patch(c)\n", "        ax[idx].set_axis_off()\n", "\n", "    plt.tight_layout()\n", "    plt.show()"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "b55a3a12d9545e5a1eb6bbcfeab50e8f08d0eab1", "_cell_guid": "bf0cabd8-1dff-47af-8078-1821fc956c23"}}, {"source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "from scipy import ndimage as ndi\n", "\n", "from skimage import feature\n", "\n", "for xi in range(0,15):\n", "    # Generate noisy image of a square\n", "    im = np.reshape(im1[xi,:],(75,75))\n", "    im = ndimage.gaussian_filter(im, 3)\n", "\n", "    # Compute the Canny filter for two values of sigma\n", "    edges1 = feature.canny(im)\n", "    edges2 = feature.canny(im, sigma=5)\n", "\n", "    # display results\n", "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\n", "                                    sharex=True, sharey=True)\n", "\n", "    ax1.imshow(im, cmap=plt.cm.gray)\n", "    ax1.axis('off')\n", "    ax1.set_title('noisy image', fontsize=20)\n", "\n", "    ax2.imshow(edges1, cmap=plt.cm.seismic)\n", "    ax2.axis('off')\n", "    ax2.set_title('Canny filter, $\\sigma=1$', fontsize=20)\n", "\n", "    ax3.imshow(edges2, cmap=plt.cm.spectral)\n", "    ax3.axis('off')\n", "    #ax3.set_title('Canny filter, $\\sigma=3$', fontsize=20)\n", "    ax3.set_title(trainDF.iloc[xi]['is_iceberg'])        \n", "\n", "    fig.tight_layout()\n", "\n", "    plt.show()"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "aecddc95df97f53e88e18931cb6ec5a44f3f2e01", "_cell_guid": "02b21dd5-9f6d-4587-ad9e-045bf8eac46c"}}, {"source": ["import cv2\n", "import numpy as np\n", "from matplotlib import pyplot as plt\n", "\n", "# loading image\n", "#img0 = cv2.imread('SanFrancisco.jpg',)\n", "img0 = image = np.reshape(im1[9,:],(75,75))\n", "from skimage.exposure import equalize_hist\n", "\n", "equalized_image = equalize_hist(img0)\n", "\n", "\n", "# remove noise\n", "img = cv2.GaussianBlur(equalized_image,(3,3),0)\n", "\n", "# convolute with proper kernels\n", "laplacian = cv2.Laplacian(img,cv2.CV_64F)\n", "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)  # x\n", "sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)  # y\n", "\n", "plt.subplot(2,2,1),plt.imshow(img,cmap = 'nipy_spectral')\n", "plt.title('Original'), plt.xticks([]), plt.yticks([])\n", "plt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'nipy_spectral')\n", "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n", "plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'nipy_spectral')\n", "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n", "plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'nipy_spectral')\n", "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n", "\n", "plt.show()\n", "from skimage.feature import corner_harris,corner_peaks\n", "\n", "# More pyplot!\n", "def show_corners(corners,image,title=None):\n", "    \"\"\"Display a list of corners overlapping an image\"\"\"\n", "    fig = plt.figure()\n", "    plt.imshow(image,cmap = 'gray')\n", "    # Convert coordinates to x and y lists\n", "    y_corner,x_corner = zip(*corners)\n", "    plt.plot(x_corner,y_corner,'v') # Plot corners\n", "    if title:\n", "        plt.title(title)\n", "    plt.xlim(0,image.shape[1])\n", "    plt.ylim(image.shape[0],0) # Images use weird axes\n", "    fig.set_size_inches(np.array(fig.get_size_inches()) * 1.5)\n", "    plt.show()\n", "    print (\"Number of corners:\",len(corners) )\n", "\n", "# Make a checker board\n", "checkers = np.zeros((100,100),dtype=np.bool)\n", "ind = np.arange(100).reshape((10,10))[::2].flatten()\n", "checkers[ind,:] = True\n", "checkers[:,ind] = np.invert(checkers[:,ind])\n", "checkers = np.where(checkers,1.,0.)\n", "\n", "# Run Harris\n", "checkers_corners = corner_peaks(corner_harris(checkers),min_distance=2)\n", "show_corners(checkers_corners,checkers)\n", "corners = corner_peaks(corner_harris(image),min_distance=2)\n", "show_corners(corners,image,\n", "             title=\"Harris Corner Algorithm\")"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "bb301af51f9a359f4cd63d604cf5bb0841707568", "_cell_guid": "37751614-5c21-43ba-a755-d4efc9f58fcb"}}, {"source": ["U1,s1,V1  = np.linalg.svd(im1,full_matrices = 0)\n", "#U2,s2,V2  = np.linalg.svd(im2,full_matrices = 0)\n", "print(U1[:,:100].shape,V1.shape)"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "fc7c8798fa82e8a614df8aec951baf8bdc490583", "_cell_guid": "6631c80c-86a7-43d6-9c51-12d92e0c7d58"}}, {"source": ["from sklearn.metrics.pairwise import cosine_similarity\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "0044e9c1841f18f554ee33c3dbbfe74f2c5dde83", "_cell_guid": "036ce5ab-57c4-4168-9863-dcc6a6e1b2ce"}}, {"source": ["Singular reformed images\n", "---\n", "\n", "less (noise) is more (iceberg)"], "cell_type": "markdown", "metadata": {"_uuid": "f900b9378d8d5b1a07371f50952b8988b66e21a5", "_cell_guid": "dee4a78c-053a-4d23-8970-a88ace2ff42c"}}, {"source": ["\n", "\n", "for rank in range(3,50,3):\n", "    im1cs=cosine_similarity(U1[:,:rank],V1[:rank,:].T)\n", "    image=np.reshape(im1cs[13,:],(75,75))\n", "    fig, ax = plt.subplots(1,3) \n", "    ax[0].imshow(image)\n", "    ax[1].imshow(image, cmap='nipy_spectral', interpolation='nearest')\n", "    ax[2].imshow(image, cmap='gray', interpolation='nearest')\n", "\n"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "77d5dcf0ec7254a09d0a08bff52b6694075eedbe", "_cell_guid": "b984d7af-f610-461a-8ddb-7a61218ae4f5"}}, {"source": ["print(np.reshape(im1[13,:],(75,75)))\n", "im1ce = exposure.equalize_hist(im1)\n", "U1,s1,V1  = np.linalg.svd(im1ce,full_matrices = 0)"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "8aa37e369e8ebb2243bdd564014a604bb7da9655", "_cell_guid": "47f9a1a8-8a85-4691-b3ea-f0d2fd0f0348"}}, {"source": ["camera exposure equilizing\n", "---"], "cell_type": "markdown", "metadata": {"_uuid": "1dd1af0611b9e5b650b07bcf0ca314c81602a6b9", "_cell_guid": "d3de8827-d164-4cdc-8f0a-dfd17e70c15d"}}, {"source": ["for rank in range(3,50,3):\n", "    im1cs=cosine_similarity(U1[:,:rank],V1[:rank,:].T)\n", "    image=np.reshape(im1cs[13,:],(75,75))\n", "    fig, ax = plt.subplots(1,3) \n", "    ax[0].imshow(image)\n", "    ax[1].imshow(image, cmap='nipy_spectral', interpolation='nearest')\n", "    ax[2].imshow(image, cmap='gray', interpolation='nearest')"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "7e500a34a030f7702902d9b48d6bb13a438d665e", "_cell_guid": "81714912-dd01-4500-810b-5ed82450949d"}}, {"source": ["from sklearn.preprocessing import normalize\n", "def distanc(X,Y):\n", "    Z=X\n", "    for yi in range(0,len(X)):\n", "        Z[yi]=angle_between((X[yi],Y[yi],0),(1,0,0))\n", "    return Z #np.reshape(Z,(75,75))\n", "\n", "def unit_vector(vector):\n", "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n", "    return vector / np.linalg.norm(vector)\n", "\n", "def angle_between(v1, v2):\n", "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n", "\n", "            >>> angle_between((1, 0, 0), (0, 1, 0))\n", "            1.5707963267948966\n", "            >>> angle_between((1, 0, 0), (1, 0, 0))\n", "            0.0\n", "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n", "            3.141592653589793\n", "    \"\"\"\n", "    v1_u = unit_vector(v1)\n", "    v2_u = unit_vector(v2)\n", "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n", "\n", "ima=im1\n", "for xi in range(0,len(im1)):\n", "    xi1=np.reshape(im1[xi,:],(75,75))\n", "    xi2=np.reshape(im2[xi,:],(75,75))\n", "    ima[xi]=distanc(im1[xi,:],im2[xi,:])"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "394fb73718bb13e64a5643de468bb9971973d8ff", "_cell_guid": "b5f4060a-b6fa-4538-8810-0c4e92e180a9"}}, {"source": ["U1,s1,V1  = np.linalg.svd(ima,full_matrices = 0)\n", "\n", "for rank in range(3,50,3):\n", "    im1cs=cosine_similarity(U1[:,:rank],V1[:rank,:].T)\n", "    image=np.reshape(im1cs[13,:],(75,75))\n", "    fig, ax = plt.subplots(1,3) \n", "    ax[0].imshow(image)\n", "    ax[1].imshow(image, cmap='nipy_spectral', interpolation='nearest')\n", "    ax[2].imshow(image, cmap='gray', interpolation='nearest')"], "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "884958a9dcccee18b64d2eb062de6e0a63cf323e", "_cell_guid": "a36784ca-7365-4e01-b873-d463fbe74ec5"}}], "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "version": "3.6.3"}}, "nbformat_minor": 1, "nbformat": 4}