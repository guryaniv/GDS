{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "af0e9383-e776-787a-c5e5-9e13c9bc13b2"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn import linear_model\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "matplotlib.style.use('fivethirtyeight')\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "efdafe29-e8e8-a723-b3b8-cf451baf42cd"
      },
      "outputs": [],
      "source": [
        "trainDF = pd.read_csv('../input/train.csv')\n",
        "testDF = pd.read_csv('../input/test.csv')\n",
        "trainDF = trainDF.dropna(how=\"any\").reset_index(drop=True)\n",
        "trainDF.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c78c21b-5308-3106-822d-27ed483964fc"
      },
      "outputs": [],
      "source": [
        "featureExtractionStartTime = time.time()\n",
        "\n",
        "\n",
        "maxNumFeatures = 10000\n",
        "\n",
        "\n",
        "q1_list = np.array(trainDF['question1']).tolist()\n",
        "q2_list = np.array(trainDF['question2']).tolist()\n",
        "\n",
        "cl = TfidfVectorizer(max_df=1000, min_df=1, max_features=maxNumFeatures, \n",
        "                                      analyzer='word', ngram_range=(1,4), stop_words = 'english', \n",
        "                                      binary=False, lowercase=True)\n",
        "\n",
        "q1_matrix = cl.fit_transform(q1_list)\n",
        "q2_matrix = cl.fit_transform(q2_list)\n",
        "\n",
        "y = np.array(trainDF.ix[:,'is_duplicate'])\n",
        "\n",
        "featureExtractionDurationInMinutes = (time.time()-featureExtractionStartTime)/60.0\n",
        "print(\"feature extraction took %.2f minutes\" % (featureExtractionDurationInMinutes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dbf93c8a-3546-2f3e-4367-d71f1de1b6d6"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "crossValidationStartTime = time.time()\n",
        "\n",
        "numCVSplits = 8\n",
        "numSplitsToBreakAfter = 4\n",
        "\n",
        "X = (q1_matrix != q2_matrix).astype(int) + q1_matrix.multiply(q2_matrix)\n",
        "\n",
        "logisticRegressor = linear_model.LogisticRegression(C= 0.1, solver='sag')\n",
        "#RFC = RandomForestClassifier(n_estimators = 5)\n",
        "#knn = KNeighborsClassifier(n_neighbors=4)\n",
        "\n",
        "\n",
        "logRegAccuracy = []\n",
        "logRegLogLoss = []\n",
        "logRegAUC = []\n",
        "\n",
        "print('---------------------------------------------')\n",
        "stratifiedCV = model_selection.StratifiedKFold(n_splits=numCVSplits, random_state=2)\n",
        "flag = 0\n",
        "for k, (trainInds, validInds) in enumerate(stratifiedCV.split(X, y)):\n",
        "    flag+=1\n",
        "    print (flag)\n",
        "    foldTrainingStartTime = time.time()\n",
        "\n",
        "    X_train_cv = X[trainInds,:]\n",
        "    X_valid_cv = X[validInds,:]\n",
        "\n",
        "    y_train_cv = y[trainInds]\n",
        "    y_valid_cv = y[validInds]\n",
        "    \n",
        "    logisticRegressor.fit(X_train_cv, y_train_cv)\n",
        "   \n",
        "    y_train_hat =  logisticRegressor.predict_proba(X_train_cv)[:,1]\n",
        "    y_valid_hat =  logisticRegressor.predict_proba(X_valid_cv)[:,1]\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    logRegAccuracy.append(accuracy_score(y_valid_cv, y_valid_hat > 0.5))\n",
        "    logRegLogLoss.append(log_loss(y_valid_cv, y_valid_hat))\n",
        "    logRegAUC.append(roc_auc_score(y_valid_cv, y_valid_hat))\n",
        "    \n",
        "    foldTrainingDurationInMinutes = (time.time()-foldTrainingStartTime)/60.0\n",
        "    print('fold %d took %.2f minutes: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (k+1,\n",
        "             foldTrainingDurationInMinutes, logRegAccuracy[-1],logRegLogLoss[-1],logRegAUC[-1]))\n",
        "\n",
        "    if (k+1) >= numSplitsToBreakAfter:\n",
        "        break\n",
        "\n",
        "\n",
        "    crossValidationDurationInMinutes = (time.time()-crossValidationStartTime)/60.0\n",
        "    \n",
        "    print('---------------------------------------------')\n",
        "    print('cross validation took %.2f minutes' % (crossValidationDurationInMinutes))\n",
        "    print('mean CV: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (np.array(logRegAccuracy).mean(),\n",
        "                                                                 np.array(logRegLogLoss).mean(),\n",
        "                                                                 np.array(logRegAUC).mean()))\n",
        "    print('---------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c0bb792f-b3ac-89d2-44a5-65c3fe952ef8"
      },
      "outputs": [],
      "source": [
        "#\u043f\u043e \u0430\u043d\u0430\u043b\u043e\u0433\u0438\u0438 \u0441\u0434\u0435\u043b\u0430\u043b\u0438 \u0442\u0430\u043a\u0443\u044e \u0448\u0442\u0443\u0447\u043a\u0443))\n",
        "\n",
        "matplotlib.rcParams['font.size'] = 14\n",
        "matplotlib.rcParams['figure.figsize'] = (10,10)\n",
        "\n",
        "plt.figure(); \n",
        "sns.kdeplot(y_valid_hat[y_valid_cv==0], shade=True, color=\"b\", bw=0.01)\n",
        "sns.kdeplot(y_valid_hat[y_valid_cv==1], shade=True, color=\"g\", bw=0.01)\n",
        "plt.legend(['non duplicate','duplicate'],fontsize=24)\n",
        "plt.title('Validation Accuracy = %.3f, Log Loss = %.4f, AUC = %.3f' %(logRegAccuracy[-1],\n",
        "                                                                      logRegLogLoss[-1],\n",
        "                                                                      logRegAUC[-1]))\n",
        "\n",
        "plt.xlabel('Prediction'); plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\n",
        "\n",
        "numFeaturesToShow = 30\n",
        "\n",
        "sortedCoeffients = np.sort(logisticRegressor.coef_)[0]\n",
        "featureNames = cl.get_feature_names()\n",
        "\n",
        "sortedFeatureNames = [featureNames[x] for x in list(np.argsort(logisticRegressor.coef_)[0])]\n",
        "\n",
        "matplotlib.rcParams['font.size'] = 14\n",
        "matplotlib.rcParams['figure.figsize'] = (10,12)\n",
        "\n",
        "plt.figure()\n",
        "plt.suptitle('Feature Importance',fontsize=24)\n",
        "ax = plt.subplot(1,2,1); plt.title('top non duplicate predictors'); \n",
        "plt.xlabel('minus logistic regression coefficient')\n",
        "ax.barh(range(numFeaturesToShow), -sortedCoeffients[:numFeaturesToShow][::-1], align='center'); \n",
        "\n",
        "plt.ylim(-1,numFeaturesToShow); ax.set_yticks(range(numFeaturesToShow)); \n",
        "ax.set_yticklabels(sortedFeatureNames[:numFeaturesToShow][::-1],fontsize=20)\n",
        "\n",
        "ax = plt.subplot(1,2,2); plt.title('top duplicate predictors'); \n",
        "plt.xlabel('logistic regression coefficient')\n",
        "ax.barh(range(numFeaturesToShow), sortedCoeffients[-numFeaturesToShow:], align='center'); \n",
        "plt.ylim(-1,numFeaturesToShow); ax.set_yticks(range(numFeaturesToShow)); \n",
        "ax.set_yticklabels(sortedFeatureNames[-numFeaturesToShow:],fontsize=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a0373f6-2b8d-ca06-2042-d11f0b346a30"
      },
      "outputs": [],
      "source": [
        "logisticRegressor = linear_model.LogisticRegression(C=1, solver='sag', \n",
        "                                                    class_weight={1: 0.4, 0: 1.34})\n",
        "                                                    \n",
        "logisticRegressor.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f681b863-f218-5bf0-db75-721a37a74470"
      },
      "outputs": [],
      "source": [
        "testPredictionStartTime = time.time()\n",
        "\n",
        "testDF.ix[testDF['question1'].isnull(),['question1','question2']] = 'random empty question'\n",
        "testDF.ix[testDF['question2'].isnull(),['question1','question2']] = 'random empty question'\n",
        "q1_testmat  = cl.transform(testDF.ix[:,'question1'])   \n",
        "q2_testmat  = cl.transform(testDF.ix[:,'question2'])   \n",
        "\n",
        "X_test = (q1_testmat != q2_testmat).astype(int) + q1_testmat.multiply(q2_testmat)\n",
        "\n",
        "seperators= [750000,1500000]\n",
        "testPredictions1 = logisticRegressor.predict_proba(X_test[:seperators[0],:])[:,1]\n",
        "testPredictions2 = logisticRegressor.predict_proba(X_test[seperators[0]:seperators[1],:])[:,1]\n",
        "testPredictions3 = logisticRegressor.predict_proba(X_test[seperators[1]:,:])[:,1]\n",
        "testPredictions = np.hstack((testPredictions1,testPredictions2,testPredictions3))\n",
        "\n",
        "matplotlib.rcParams['font.size'] = 14\n",
        "matplotlib.rcParams['figure.figsize'] = (9,9)\n",
        "\n",
        "plt.figure(); \n",
        "plt.subplot(2,1,1); sns.kdeplot(y_valid_hat, shade=True, color=\"b\", bw=0.01); \n",
        "plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\n",
        "plt.title('mean valid prediction = ' + str(np.mean(y_valid_hat)))\n",
        "plt.subplot(2,1,2); sns.kdeplot(testPredictions, shade=True, color=\"b\", bw=0.01);\n",
        "plt.xlabel('Prediction'); plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\n",
        "plt.title('mean test prediction = ' + str(np.mean(testPredictions)))\n",
        "\n",
        "testPredictionDurationInMinutes = (time.time()-testPredictionStartTime)/60.0\n",
        "print('predicting on test took %.2f minutes' % (testPredictionDurationInMinutes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8fb8b895-8e8b-f1f6-7e89-34e16e44d274"
      },
      "outputs": [],
      "source": [
        "submissionName = 'shallowBenchmark_'\n",
        "\n",
        "submission = pd.DataFrame()\n",
        "submission['test_id'] = testDF['test_id']\n",
        "submission['is_duplicate'] = (testPredictions)# + prev['is_duplicate'])/2\n",
        "submission.to_csv(submissionName + '.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}