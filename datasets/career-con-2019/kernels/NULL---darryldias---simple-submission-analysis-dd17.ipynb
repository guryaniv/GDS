{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nimport sys\n# Any results you write to the current directory are saved as output.\nfrom datetime import datetime\nfrom IPython.core.display import display, HTML\nimport math\nimport csv\nbln_create_df_all_csv_file = True\nbln_create_words_csv_file = False\nint_df_all_version = 6\nbln_ready_to_commit = True\nbln_create_estimate_files = False\nbln_upload_input_estimates = False\nbln_recode_variables = True\nbln_create_crosstabs = False\npd.set_option(\"display.max_rows\", 500)\npd.set_option(\"display.max_columns\", 100)\n\ndf_time_check = pd.DataFrame(columns=['Stage','Start','End', 'Seconds', 'Minutes'])\nint_time_check = 0\ndat_start = datetime.now()\ndat_program_start = dat_start\n\nif not bln_ready_to_commit:\n    int_read_csv_rows = 100000\nelse:\n    int_read_csv_rows= None\n    \n# generate crosstabs  {0 = nothing; 1 = screen}\nint_important_crosstab = 1\nint_past_crosstab = 0\nint_current_crosstab = 1\n\nbln_read_train = True\nbln_read_test = True","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"551373aa49cf808272e5ab283458a0f3c245f749"},"cell_type":"code","source":"def get_translations_analysis_description(df_input, str_language, str_group, int_code):\n    # created by darryldias 25may2018\n    df_temp = df_input[(df_input['language']==str_language) & (df_input['group']==str_group) & (df_input['code']==int_code)] \\\n                    ['description']\n    return df_temp.iloc[0]\n\n#translations_analysis = pd.read_csv('../input/ulabox-translations-analysis/translations_analysis.csv')\nstrg_count_column = 'count'   #get_translations_analysis_description(translations_analysis, str_language, 'special', 2)\n\ndef start_time_check():\n    # created by darryldias 21may2018 - updated 8june2018\n    global dat_start \n    dat_start = datetime.now()\n    \ndef end_time_check(dat_start, str_stage):\n    # created by darryldias 21may2018 - updated 8june2018\n    global int_time_check\n    global df_time_check\n    int_time_check += 1\n    dat_end = datetime.now()\n    diff_seconds = (dat_end-dat_start).total_seconds()\n    diff_minutes = diff_seconds / 60.0\n    df_time_check.loc[int_time_check] = [str_stage, dat_start, dat_end, diff_seconds, diff_minutes]\n\ndef create_topline(df_input, str_item_column, str_count_column):\n    # created by darryldias 21may2018; updated by darryldias 29may2018\n    str_percent_column = 'percent'   #get_translations_analysis_description(translations_analysis, str_language, 'special', 3)\n    df_temp = df_input.groupby(str_item_column).size().reset_index(name=str_count_column)\n    df_output = pd.DataFrame(columns=[str_item_column, str_count_column, str_percent_column])\n    int_rows = df_temp.shape[0]\n    int_columns = df_temp.shape[1]\n    int_total = df_temp[str_count_column].sum()\n    flt_total = float(int_total)\n    for i in range(int_rows):\n        str_item = df_temp.iloc[i][0]\n        int_count = df_temp.iloc[i][1]\n        flt_percent = round(int_count / flt_total * 100, 1)\n        df_output.loc[i] = [str_item, int_count, flt_percent]\n    \n    df_output.loc[int_rows] = ['total', int_total, 100.0]\n    return df_output        \n\ndef get_dataframe_info(df_input, bln_output_csv = False, str_filename = None):\n    # created by darryldias 24may2018 - updated 25jan2019\n    int_rows = df_input.shape[0]\n    int_cols = df_input.shape[1]\n    flt_rows = float(int_rows)\n    int_size_mb = get_size_mb(df_input)\n\n    df_output = pd.DataFrame(columns=[\"Column\", \"Type\", \"Not Null\", 'Null', '% Not Null', '% Null'])\n    df_output.loc[0] = ['Table Row Count', '', int_rows, '', '', '']\n    df_output.loc[1] = ['Table Column Count', '', int_cols, '', '', '']\n    df_output.loc[2] = ['Table Size (MB)', '', int_size_mb, '', '', '']\n    int_table_row = 2\n    for i in range(int_cols):\n        str_column_name = df_input.columns.values[i]\n        str_column_type = df_input.dtypes.values[i]\n        int_not_null = df_input[str_column_name].count()\n        int_null = sum( pd.isnull(df_input[str_column_name]) )\n        flt_percent_not_null = round(int_not_null / flt_rows * 100, 1)\n        flt_percent_null = round(100 - flt_percent_not_null, 1)\n        int_table_row += 1\n        df_output.loc[int_table_row] = [str_column_name, str_column_type, int_not_null, int_null, flt_percent_not_null, flt_percent_null]\n\n    if bln_output_csv:\n        df_output.to_csv(str_filename)\n        print ('Dataframe information output created in file: ' + str_filename)\n        return None\n    return df_output\n\ndef check_numeric_var(str_question, int_groups):\n    # created by darryldias 3jul2018  \n    #print(df_output.iloc[3][2])\n    flt_min = application_all[str_question].min()\n    flt_max = application_all[str_question].max()\n    flt_range = flt_max - flt_min \n    flt_interval = flt_range / int_groups \n    df_output = pd.DataFrame(columns=['interval', 'value', 'count', 'percent', 'code1', 'code2'])\n\n    int_total = application_all[ (application_all[str_question] <= flt_max) ][str_question].count()\n    for i in range(0, int_groups + 1):\n        flt_curr_interval = i * flt_interval\n        flt_value = flt_min + flt_curr_interval\n        int_count = application_all[ (application_all[str_question] <= flt_value) ][str_question].count()\n        flt_percent = int_count /  int_total * 100.0\n        str_code_value = \"{0:.6f}\".format(flt_value)\n        str_code1 = \"if row['\" + str_question + \"'] <= \" + str_code_value + \":\"\n        str_code2 = \"return '(x to \" + str_code_value + \"]'\"\n        df_output.loc[i] = [flt_curr_interval, flt_value, int_count, flt_percent, str_code1, str_code2]\n\n    return df_output\n\ndef find_file(str_input_variable):\n    df_file_info = pd.read_csv('../input/dd15d-files/file_information2.csv')\n    int_rows = df_file_info.shape[0]\n    for i in range(int_rows):\n        str_dataset = df_file_info.iloc[i][1]\n        str_file = df_file_info.iloc[i][2]\n        str_column = df_file_info.iloc[i][3]\n        if str_column == str_input_variable:\n            str_file = str_file.replace('train', '')\n            return [str_dataset, str_file]\n\ndef load_analysis_data():\n    lst_file_info1 = find_file('Analysis_C301')\n    df_temp = pd.read_csv( '../input/' + lst_file_info1[0] + '/train' + lst_file_info1[1] )\n    lst_file_info2 = find_file('SmartScreen_C2')\n    df_temp2 = pd.read_csv( '../input/' + lst_file_info2[0] + '/train' + lst_file_info2[1] )\n    df_temp = pd.merge(df_temp, df_temp2, how='left', on=['KId'])\n    df_temp['train_or_test'] = 1\n    df_temp2 = pd.read_csv('../input/dd15-files/train_target.csv')\n    df_temp = pd.merge(df_temp, df_temp2, how='left', on=['KId'])\n\n    df_temp2 = pd.read_csv( '../input/' + lst_file_info1[0] + '/test' + lst_file_info1[1] )\n    df_temp3 = pd.read_csv( '../input/' + lst_file_info2[0] + '/test' + lst_file_info2[1] )\n    df_temp2 = pd.merge(df_temp2, df_temp3, how='left', on=['KId'])\n    df_temp2['train_or_test'] = 2\n\n    df_temp = pd.concat([df_temp, df_temp2], sort=False)\n    df_temp['overall'] = 1\n    return df_temp\n\ndef load_variable_data(df_input, str_variable):\n    lst_file_info = find_file(str_variable)\n    df_temp1 = pd.read_csv( '../input/' + lst_file_info[0] + '/train' + lst_file_info[1] )\n    df_temp2 = pd.read_csv( '../input/' + lst_file_info[0] + '/test' + lst_file_info[1] )\n    df_temp1 = pd.concat([df_temp1, df_temp2], sort=False)\n    df_input = pd.merge(df_input, df_temp1, how='left', on=['KId'])\n    return df_input\n\ndef load_variable_data_old(str_variable):\n    lst_file_info = find_file(str_variable)\n    df_temp = pd.read_csv( '../input/' + lst_file_info[0] + '/train' + lst_file_info[1] )\n    df_temp2 = pd.read_csv('../input/dd15-files/train_target.csv')\n    df_temp = pd.merge(df_temp, df_temp2, how='left', on=['KId'])\n    df_temp['train_or_test'] = 1\n    df_temp2 = pd.read_csv( '../input/' + lst_file_info[0] + '/test' + lst_file_info[1] )\n    df_temp2['train_or_test'] = 2\n    df_temp = pd.concat([df_temp, df_temp2], sort=False)\n    df_temp['overall'] = 1\n    return df_temp\n\ndef show_folder_items(str_folder):\n    # darryldias 8jan2019\n    df_return = pd.DataFrame(columns=['Folder', 'Item'])\n    lst_items = sorted( os.listdir(str_folder) )\n    int_row = 0\n    for str_item in lst_items:\n        int_row += 1\n        df_return.loc[int_row] = [str_folder, str_item]\n    \n    return df_return\n\ndef get_size_raw(df_input):\n    return sys.getsizeof(df_input)\n\ndef get_size_mb(df_input):\n    int_size_raw = get_size_raw(df_input)\n    flt_size = float(int_size_raw) / 1000000 \n    return int(flt_size)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"469a413332fbddb4f190422fd2ca9f6f8cd4760e"},"cell_type":"code","source":"def get_column_analysis(int_analysis, int_code):\n    # created by darryldias 24jul2018 \n    if int_code == 1:\n        return ['overall', 'test', 'train', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n    elif int_code == 2:\n        return ['overall', 'train_or_test', 'train_or_test', 'surface_id', 'surface_id', 'surface_id', 'surface_id', 'surface_id', \\\n                'surface_id', 'surface_id', 'surface_id', 'surface_id']\n    elif int_code == 3:\n        return [1, 2, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n    else:\n        return None\n\ndef create_crosstab_type1(df_input, str_row_question, int_output_destination):\n    # created by darryldias 10jun2018 - updated 27sep2018 \n    # got some useful code from:\n    # https://chrisalbon.com/python/data_wrangling/pandas_missing_data/\n    # https://www.tutorialspoint.com/python/python_lists.htm\n    # https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points\n\n    if int_output_destination == 0:\n        return None\n    \n    str_count_desc = 'count'  #get_translations_analysis_description(translations_analysis, str_language, 'special', 3)\n    str_colpercent_desc = 'col percent'\n    \n    list_str_column_desc = get_column_analysis(1, 1)\n    list_str_column_question = get_column_analysis(1, 2)\n    list_str_column_category = get_column_analysis(1, 3)\n    int_columns = len(list_str_column_desc)\n    list_int_column_base = []\n    list_flt_column_base_percent = []\n    \n    df_group = df_input.groupby(str_row_question).size().reset_index(name='count')\n    int_rows = df_group.shape[0]\n\n    for j in range(int_columns):\n        int_count = df_input[ df_input[str_row_question].notnull() & (df_input[list_str_column_question[j]]==list_str_column_category[j]) ] \\\n                                [list_str_column_question[j]].count()\n        list_int_column_base.append(int_count)\n        if int_count == 0:\n            list_flt_column_base_percent.append('')\n        else:\n            list_flt_column_base_percent.append('100.0')\n        \n    list_output = []\n    list_output.append('row_question')\n    list_output.append('row_category')\n    list_output.append('statistic')\n    for k in range(1, int_columns+1):\n        str_temp = 'c' + str(k)\n        list_output.append(str_temp)\n    df_output = pd.DataFrame(columns=list_output)\n\n    int_row = 1\n    list_output = []\n    list_output.append(str_row_question)\n    list_output.append('')\n    list_output.append('')\n    for k in range(int_columns):\n        list_output.append(list_str_column_desc[k])\n    df_output.loc[int_row] = list_output\n    \n    int_row = 2\n    list_output = []\n    list_output.append(str_row_question)\n    list_output.append('total')\n    list_output.append(str_count_desc)\n    for k in range(int_columns):\n        list_output.append(list_int_column_base[k])\n    df_output.loc[int_row] = list_output\n    \n    int_row = 3\n    list_output = []\n    list_output.append(str_row_question)\n    list_output.append('total')\n    list_output.append(str_colpercent_desc)\n    for k in range(int_columns):\n        list_output.append(list_flt_column_base_percent[k])\n    df_output.loc[int_row] = list_output\n\n    for i in range(int_rows):\n        int_row += 1\n        int_count_row = int_row\n        int_row += 1\n        int_colpercent_row = int_row\n\n        str_row_category = df_group.iloc[i][0]\n\n        list_int_column_count = []\n        list_flt_column_percent = []\n        for j in range(int_columns):\n            int_count = df_input[ (df_input[str_row_question]==str_row_category) & \\\n                                  (df_input[list_str_column_question[j]]==list_str_column_category[j]) ] \\\n                                [list_str_column_question[j]].count()\n            list_int_column_count.append(int_count)\n            flt_base = float(list_int_column_base[j])\n            if flt_base > 0:\n                flt_percent = round(100 * int_count / flt_base,1)\n                str_percent = \"{0:.1f}\".format(flt_percent)\n            else:\n                str_percent = ''\n            list_flt_column_percent.append(str_percent)\n        \n        list_output = []\n        list_output.append(str_row_question)\n        list_output.append(str_row_category)\n        list_output.append(str_count_desc)\n        for k in range(int_columns):\n            list_output.append(list_int_column_count[k])\n        df_output.loc[int_count_row] = list_output\n        \n        list_output = []\n        list_output.append(str_row_question)\n        list_output.append(str_row_category)\n        list_output.append(str_colpercent_desc)\n        for k in range(int_columns):\n            list_output.append(list_flt_column_percent[k])\n        df_output.loc[int_colpercent_row] = list_output\n        \n    return df_output        \n\ndef get_ct_statistic2(df_input, str_row_question, str_col_question, str_col_category, str_statistic):\n    # created by darryldias 17jul2018\n    if str_statistic == 'total':\n        int_temp = df_input[ (df_input[str_col_question] == str_col_category) ][str_row_question].isnull().count() \n    elif str_statistic == 'notnull':\n        int_temp = df_input[ (df_input[str_col_question] == str_col_category) ][str_row_question].count() \n    elif str_statistic == 'null':\n        int_temp = df_input[ (df_input[str_col_question] == str_col_category) ][str_row_question].isnull().sum() \n    elif str_statistic == 'mean':\n        int_temp = df_input[ (df_input[str_col_question] == str_col_category) ][str_row_question].mean() \n    elif str_statistic == 'median':\n        int_temp = df_input[ (df_input[str_col_question] == str_col_category) ][str_row_question].median() \n    elif str_statistic == 'minimum':\n        int_temp = df_input[ (df_input[str_col_question] == str_col_category) ][str_row_question].min() \n    elif str_statistic == 'maximum':\n        int_temp = df_input[ (df_input[str_col_question] == str_col_category) ][str_row_question].max() \n    else:\n        int_temp = None\n    return int_temp\n \ndef create_crosstab_type2(df_input, str_row_question, int_output_destination):\n    # created by darryldias 24jul2018\n    if int_output_destination == 0:\n        return None\n\n    list_str_column_desc = get_column_analysis(1, 1)\n    list_str_column_question = get_column_analysis(1, 2)\n    list_str_column_category = get_column_analysis(1, 3)\n    int_analysis_columns = len(list_str_column_question)\n\n    list_str_statistics = ['total', 'notnull', 'null', 'mean', 'median', 'minimum', 'maximum']\n    list_str_counts = ['total', 'notnull', 'null']\n    int_statistics = len(list_str_statistics)\n\n    df_output = pd.DataFrame(columns=['row_question', 'row_category', 'statistic', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', \\\n                                      'c10', 'c11', 'c12'])\n    int_row = 1\n\n    list_values = []\n    list_values.append(str_row_question)\n    list_values.append('')\n    list_values.append('')\n    for j in range(int_analysis_columns):\n        list_values.append(list_str_column_desc[j])\n    df_output.loc[int_row] = list_values\n\n    for i in range(int_statistics):\n        str_statistic = list_str_statistics[i] \n        list_values = []\n        list_values.append(str_row_question)\n        if str_statistic in list_str_counts:\n            list_values.append(str_statistic)\n            list_values.append('count')\n        else:\n            list_values.append('numeric')\n            list_values.append(str_statistic)\n    \n        for j in range(int_analysis_columns):\n            str_col_question = list_str_column_question[j]\n            str_col_category = list_str_column_category[j]\n            num_statistic = get_ct_statistic2(df_input, str_row_question, str_col_question, str_col_category, str_statistic)\n            list_values.append(num_statistic)\n        int_row += 1\n        df_output.loc[int_row] = list_values\n    return df_output","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"str_count_column = 'count'\nshow_folder_items('../input')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"5e866c49c2199c2dae9e6a95acb36e3651a27b8d"},"cell_type":"code","source":"show_folder_items('../input/career-con-2019')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2171fec5f634a8cc875ce9317296f09066843fe3"},"cell_type":"markdown","source":"## sample submission file"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0b9d283934a646c515608d7400a67fe5ebfb7dc6"},"cell_type":"code","source":"df_sample_submission = pd.read_csv('../input/career-con-2019/sample_submission.csv')\ndf_sample_submission.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0325db4ba4c21a3fb67b9d50f93d77a1ddc855d7"},"cell_type":"code","source":"get_dataframe_info(df_sample_submission)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"fc4864b71864fc723146d5226e9036fd00290b60"},"cell_type":"code","source":"create_topline(df_sample_submission, 'surface', str_count_column)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"240e18a809cfd4d4bc8d2424879e78befae5f1b7"},"cell_type":"markdown","source":"#### The sample submission file contains value concrete for all records and scores 0.16 on public lb. What happens if it is changed to another value? I thought I would check this out (yes I don't have many submissions remaining at the moment...)\n* 0.06 - carpet\n* 0.16 - concrete\n* 0.09 - fine_concrete\n* 0.06 - hard_tiles\n* 0.10 - hard_tiles_large_space\n* 0.17 - soft_pvc\n* 0.23 - soft_tiles\n* 0.03 - tiled\n* 0.06 - wood"},{"metadata":{"_kg_hide-input":true,"_uuid":"a910e57ecc0ac4a8b7f9da7ddaeb25ec6aaebd3a"},"cell_type":"markdown","source":"## train data"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"c3d03abeede289ddb95c5f9a90ac9db4df098bb8"},"cell_type":"code","source":"df_y_train = pd.read_csv('../input/career-con-2019/y_train.csv')\ndf_y_train.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"914fc55e01f9d08653a91f3ef9b84878c5acd6f3"},"cell_type":"code","source":"get_dataframe_info(df_y_train)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"a892557be5ceac13c659df1cc6118778409e8590"},"cell_type":"code","source":"create_topline(df_y_train, 'surface', str_count_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f91b4875d95fd765f554dbc2a99958918fb4bc9"},"cell_type":"markdown","source":"## prashantkikani's 0.70 submission\n#### interested in seeing surface percentages for a current high scoring public submission ( [https://www.kaggle.com/prashantkikani/help-humanity-by-helping-robots](https://www.kaggle.com/prashantkikani/help-humanity-by-helping-robots) )"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"848be410affbca70010573c0b2979c292e259a3a"},"cell_type":"code","source":"df_sample_submission = pd.read_csv('../input/dd17-public/sub_prashantkikani_070_v12.csv')\ndf_sample_submission.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"b6c303ea1966ce433e484642bc099fa229b04238"},"cell_type":"code","source":"create_topline(df_sample_submission, 'surface', str_count_column)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"1270688d0d85aba1d1736637ad7c95fdeff1d157"},"cell_type":"code","source":"end_time_check(dat_program_start, 'overall')\ndf_time_check","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}