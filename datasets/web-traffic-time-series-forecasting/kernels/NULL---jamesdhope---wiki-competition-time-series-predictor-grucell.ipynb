{"cells": [{"execution_count": null, "metadata": {"_uuid": "fc01a487f43de82a61b6fb85d957a161268daa78", "_cell_guid": "8be69e0b-c898-47f5-aa31-f723aab64781", "_execution_state": "idle"}, "cell_type": "markdown", "source": "This Notebook superseeds my basic RNN example for predicting multiple time series. \n\nThis model is constructed using the GRUCell rather than the BasicRNNCell which provides the model with persistence in the patterns observed over the series. This model is again easily adaptable and shown here to run over 10 pages of the training set.\n\nExtending this model to run over the entire training set is likely to require a distributed architecture. \n\nComments, suggestions welcome Twitter DM @jamesdhope", "outputs": []}, {"outputs": [], "metadata": {"_uuid": "7fcf66bbdf68cb02bbcbf59d702407c3825f367d", "_cell_guid": "0de6cf11-a8b9-4e2c-a6f4-0f0bd1838592", "trusted": false, "collapsed": true}, "cell_type": "code", "source": "import tensorflow as tf\nimport numpy.random as rnd\nimport numpy as np", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "05d3f88b0819e0c5b5065084e2890eb0b4e2e58c", "_cell_guid": "74c9b9ea-da33-4d8e-be56-a0233fd100f9", "trusted": false, "_execution_state": "idle", "collapsed": true}, "cell_type": "code", "source": "# To plot pretty figures\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "2a3104a672860718333737f5e19878ae8ca86929", "_cell_guid": "43518500-5c02-4de9-a66a-23d1f57834d3", "trusted": false, "_execution_state": "idle", "collapsed": true}, "cell_type": "code", "source": "# to make this notebook's output stable across runs\ndef reset_graph(seed=42):\n    tf.reset_default_graph()\n    tf.set_random_seed(seed)\n    np.random.seed(seed)", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "63cf7d263d96a23af44a11996e8faec8699006d1", "_cell_guid": "ad96072a-4545-4f4f-aa18-7b3c88a31169", "trusted": false, "_execution_state": "idle", "collapsed": true}, "cell_type": "code", "source": "reset_graph()\n\n#CONSTRUCTION PHASE\nn_steps = 39\nn_inputs = 10 #same as rows\nn_neurons = 100\nn_outputs = 10 #same as rows\nn_layers = 6\n\nlearning_rate = 0.001\n\nX = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n\n#y has the same shape\ny = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n\n#create the cells and the layers of the network\nlayers = [tf.contrib.rnn.OutputProjectionWrapper(tf.contrib.rnn.GRUCell(num_units=n_neurons, activation=tf.nn.relu),output_size=n_outputs) for layer in range(n_layers)]\nmulti_layer_cell = tf.contrib.rnn.MultiRNNCell(layers, state_is_tuple=True)\noutputs, states = tf.nn.dynamic_rnn(multi_layer_cell,X,dtype=tf.float32)\n\nprint(outputs.shape)\nprint(y.shape)\n\n#define the cost function and optimization\nloss = tf.reduce_mean(tf.square(outputs - y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntraining_op = optimizer.minimize(loss)\n\n#Adds an op to initialize all variables in the model\ninit = tf.global_variables_initializer()", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "c481c9cd3d4e9e04cc3c80fcf99343d21fffd355", "_cell_guid": "a053d1b4-cb68-46cc-a155-408f393b1867", "trusted": false, "_execution_state": "idle", "collapsed": true}, "cell_type": "code", "source": "#Import training data\nimport csv\nfrom numpy import genfromtxt\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport random\nfrom sklearn.preprocessing import Imputer\n\n#read the csv into a dataframe\ndf=pd.read_csv('../input/train_1.csv', sep=',', error_bad_lines=False, warn_bad_lines=True)\n\n#clean the data\ndf.drop(['Page'], axis=1, inplace = True)\ndf = df.replace(np.nan, 0, regex=True)\n\n#grab the relevant rows\nX_test = df.values.astype(int)\nrows = print(len(X_test))\n\n#number of rows to read \nrows = 10\n\n#fetch the rows\nX_test = df.values.astype(int)\nX_test = X_test[:rows,0:]\n\n#set the labelled data as the time step + 1\nY_test = X_test[:,1:]\n\n#strip n numbers off the rows for reshape\nX_test = X_test[:,:-4]\nY_test = Y_test[:,:-3]\n\n#print(\"unshaped X data\", X_test)\n#print(\"unshaped X data shape\", X_test.shape)\n\n#print(\"unshaped Y data\", Y_test)\n#print(\"unshaped Y data shape\", Y_test.shape)\n\nfor iteration in range(len(X_test)):\n    plt.plot(X_test[iteration,:], label=\"page\"+str(iteration+1))\n\nplt.xlabel(\"Time\")\nplt.ylabel(\"Value\")\nplt.legend()\nplt.show()    \n    \nY_test = Y_test.reshape((-1, n_steps, n_inputs))\nX_test = X_test.reshape((-1, n_steps, n_inputs))\n\n#print(\"transformed X data\", X_test[0])\n#print(\"transformed X data\", X_test[1])\n#print(\"transformed Y data\", Y_test[0])", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "04a05f94993f6969f82579ad52c911d54af362c5", "_cell_guid": "69c5b8b5-35ac-4f85-9238-fbc96908838f", "trusted": false, "_execution_state": "idle", "collapsed": true}, "cell_type": "code", "source": "#TRAINING PHASE\n\nimport numpy\nn_epochs = 3000\nbatch_size = 10\ninstances = X_test.shape[0]\nsaver = tf.train.Saver()\n\nprint(\"RNN construction\", \"n_layers\", n_layers, \"n_neurons\", n_neurons, \"n_inputs\", n_inputs, \"n_outputs\", n_outputs)\nprint(\"training dataset\", \"shape\", X_test.shape, \"instances\", instances, \"batch_size\", batch_size)\nprint(\"training with\", \"n_epochs\", n_epochs, \"iterations (instances // batch_size)\", (instances//batch_size))\n\n#open a TensorFlow Session\nwith tf.Session() as sess:\n    init.run()\n    \n    #Epoch is a single pass through the entire training set, followed by testing of the verification set.\n    for epoch in range(n_epochs):\n    \n        #print(\"X_test\",X_test)\n        idxs = numpy.random.permutation(instances) #shuffled ordering\n        #print(idxs)\n        #print(idxs.shape)\n        X_random = X_test[idxs]\n        #print('X_random', X_random)\n        Y_random = Y_test[idxs]\n        #print('Y_random', Y_random)\n    \n        #Number of batches, here we exhaust the training set\n        for iteration in range(instances // batch_size):   \n\n            #get the next batch - we permute the examples in each batch\n            #X_batch, y_batch = next_batch(batch_size, n_steps)\n            X_batch = X_random[iteration * batch_size:(iteration+1) * batch_size]\n            y_batch = Y_random[(iteration * batch_size):((iteration+1) * batch_size)]\n            \n            #print(\"iteration\", iteration, \"X_batch\", X_batch)\n            #print(\"iteration\", iteration, \"y_batch\", y_batch)\n            \n            X_batch = X_batch.reshape((-1, n_steps, rows))\n            y_batch = y_batch.reshape((-1, n_steps, rows))\n        \n            #feed in the batch\n            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n        \n            if (epoch % 100 == 0 and iteration == 0):\n                #check contents of first example in each batch\n                #print(\"iteration\", iteration, \"X_batch\", X_batch[0])\n                #print(\"iteration\", iteration, \"y_batch\", y_batch[0])\n                mse = loss.eval(feed_dict={X:X_batch, y:y_batch})\n                print(\"epoch\", epoch, \"iteration\", iteration, \"\\tMSE:\", mse)\n            \n            #print(epoch)\n    \n    saver.save(sess, \"./my_model\") ", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "8a5dfe76a0b4dbd5389c08e66c6d720ddccd9871", "_cell_guid": "72354c66-acaf-45a1-9c7b-91fb36abd933", "trusted": false, "_execution_state": "idle", "collapsed": true}, "cell_type": "code", "source": "#Sequence generation using the model\n\nmax_iterations = 90 #number of time steps to look forward\n\nwith tf.Session() as sess:                        \n    saver.restore(sess, \"./my_model\") \n\n    sequence = [[0] * n_steps] * rows\n    for iteration in range(max_iterations):\n        #print(\"iteration\", iteration)\n        \n        X_batch = np.array(sequence[-n_steps*rows:]).reshape(-1,n_steps,rows)\n        #print(X_batch)\n        \n        y_pred = sess.run(outputs, feed_dict={X: X_batch})\n        #print(\"Y\", y_pred)\n        #print(\"numbers to be added\", np.array(y_pred[0,n_steps-1]))\n            \n        sequence = np.append(sequence, y_pred[0,n_steps-1])      \n        #print(\"sequence so far...\", np.array(sequence))\n        \n    #print(\"end sequence\", np.array(sequence))\n    sequence[numpy.where(sequence<0)] = 0\n    #print(sequence)\n    sequence = np.array(sequence).reshape(-1,rows)\n    #print(sequence)", "execution_count": null}, {"execution_count": null, "metadata": {"_uuid": "75bdc39fa0b6ec8ac4f17467769833aa8d5c36cc", "_cell_guid": "b1b269cb-fc91-4978-8919-77005b6ddfe2"}, "cell_type": "markdown", "source": "Visualising the results.", "outputs": []}, {"outputs": [], "metadata": {"_uuid": "91300723a8f299d555f3718209a173d6b5109a12", "_cell_guid": "bed39fb7-00e7-44ae-9133-55ce54873684", "trusted": false, "_execution_state": "idle", "collapsed": true}, "cell_type": "code", "source": "plt.figure(figsize=(8,4))\n\n#print(sequence[:,0])\n\nplt.figure(1)\nplt.grid(True)\nplt.title(\"Full iteration of prediction\")\n\n#print(sequence)\n#print(n_steps)\n\nfor iteration in range(rows):\n    plt.plot(sequence[n_steps:,iteration], label = \"page\"+str(iteration+1))\n\nplt.xlabel(\"Time\")\nplt.ylabel(\"Value\")\nplt.legend()\n\nplt.figure(2)\nplt.grid(True)\nplt.title(\"First 10 time steps in predicted sequence\")\n\nfor iteration in range(rows):\n    #plt.plot(sequence[n_steps:n_steps+10,iteration], label = \"page\"+str(iteration+1))\n    plt.plot(sequence[n_steps:n_steps+10,iteration])\n\nplt.xlabel(\"Time\")\nplt.ylabel(\"Value\")\nplt.legend()\n\nplt.show()", "execution_count": null}], "nbformat": 4, "metadata": {"language_info": {"version": "3.6.1", "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "name": "python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat_minor": 1}