{"cells":[{"metadata":{"_uuid":"8b00a673cc856da7ce265485b0941990cad37546"},"cell_type":"markdown","source":"I saw a lot of people asking how to find the data leak from scratch. Here is the method I used at the very begining. I was also curious about this after Giba disclosed his findings. Therefore, I tried to do this from scratch without Giba's rows and columns. Though I trust Giba, I think it is still a little dangerous to use other people's findings directly.\n\nMy solution is based on [Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index) and some graph techniques. I found 30 sets of columns using this simple algorithm, and 2 of them have length 40."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from functools import partial\nfrom concurrent.futures import ProcessPoolExecutor\nfrom collections import Counter\n\nimport numpy as np\nimport pandas as pd\nimport networkx as nx\nfrom tqdm import tnrange","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\n    '../input/santander-value-prediction-challenge/train.csv', index_col='ID')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c956376fcb11efa8ded7e382876c579d7598cc2"},"cell_type":"markdown","source":"## Calculate row value counts"},{"metadata":{"trusted":true,"_uuid":"c26ea45f001383f177d551aaab72bff6ce565702"},"cell_type":"code","source":"row_value_counts = [\n    {'id': row_id, 'value_counts': row_s[row_s != 0].value_counts()}\n    for row_id, row_s in train_df.iterrows()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b49d8b453ab2efd543ca7c984863457ce85fd23b","scrolled":true},"cell_type":"code","source":"row_value_counts[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b726af60956a3b4fd40c0ff306ab9964cc7c85f0"},"cell_type":"markdown","source":"## Calculate Jaccard Index"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"841a12e2c9f9e3edd8124c0cc34cee6780383b8e"},"cell_type":"code","source":"def get_jaccard_index(row_value_count, row_value_count2):\n    intersection = (pd.concat(\n                        (row_value_count['value_counts'], row_value_count2['value_counts']),\n                        axis=1, join='inner')\n                    .min(1).sum())\n    union = (row_value_count['value_counts'].sum()\n             + row_value_count2['value_counts'].sum()\n             - intersection)\n    return intersection / union\n\ntry:\n    # The processs runs too long, so let's use the result I generated previously.\n    jaccard_index_df = pd.read_hdf('../input/svpc-additional-data/jaccard_index.h5')\nexcept IOError:\n    jaccard_index = []\n    with ProcessPoolExecutor() as executor:\n        for i in tnrange(len(row_value_counts) - 1):\n            result = executor.map(partial(get_jaccard_index, row_value_counts[i]),\n                                  row_value_counts[i+1:],\n                                  chunksize=8)\n            jaccard_index.extend(result)\n    index = pd.MultiIndex.from_tuples((i, j)\n                                      for i in range(len(row_value_counts) - 1)\n                                      for j in range(i+1, len(row_value_counts)))\n    jaccard_index_df = pd.DataFrame({'jaccard_index': jaccard_index}, index=index)\n    jaccard_index_df.to_hdf('jaccard_index.h5', 'df')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bc12adcb1a8078c85687c3364c36dd70f33fcbc"},"cell_type":"code","source":"jaccard_index_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f277e12fd075617df271c550b3bf2d6e00675925"},"cell_type":"code","source":"jaccard_index_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"68c5a52fc8ee6536482d0c6155e5332fa4306959"},"cell_type":"code","source":"jaccard_index_df['jaccard_index'].hist(bins=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89d87d8e498835d7bdeea82a6100294ad6e061d4"},"cell_type":"markdown","source":"## Use Jaccard Index to find row time series"},{"metadata":{"trusted":true,"_uuid":"a6250576b8ddff9e3f1f8159c430e872eac7a668"},"cell_type":"code","source":"threshold = 0.95\npairs = jaccard_index_df.index[jaccard_index_df['jaccard_index'] > threshold].tolist()\nprint(\"number of pairs:\", len(pairs))\ng = nx.Graph()\ng.add_edges_from(pairs)\nprint(\"number of rows:\", len(g))\nconnected_components = list(nx.connected_components(g))\nprint(\"number of groups:\", len(connected_components))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f597bf7f72c60e4e897c7950dc0574ee6bfc172"},"cell_type":"code","source":"biggest_component = max(connected_components, key=len)\n# biggest_component = connected_components[2]\nnx.draw_networkx(g.subgraph(biggest_component))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7f99648ead74d830538e30ef0be197a210bc86c"},"cell_type":"markdown","source":"- there is an obvious order\n- we actually need more analysis to make sure they are really close, but we simply trust it now"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"03bc30f0605c3517da60fad35f917a4ed5f9ed85"},"cell_type":"code","source":"rows = [2276, 1327, 2803, 1366, 3901, 2536, 2779, 4309]\nsame_user_df = train_df.iloc[rows]\nsame_user_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3358fb4782f0d62c3dfcb8de17ad707cc4bbde3a"},"cell_type":"markdown","source":"## Find column time series based on the row time series we have found"},{"metadata":{"trusted":true,"_uuid":"e711094ada32bea1f1162f5e8e36e8e91ac1f7d0"},"cell_type":"code","source":"def find_feature_pairs(assumed_future: np.ndarray, cols_to_match: np.ndarray):\n    is_matched = np.isclose(assumed_future, cols_to_match).all(0)\n    return np.where(is_matched)[0]\n            \n# remove all zero columns\nno_all_zeros_same_user_df = (same_user_df.loc[:, ~(same_user_df == 0).all()]\n                             .drop(columns='target'))\nlag_data = no_all_zeros_same_user_df.iloc[:-1].values\nfuture_data = no_all_zeros_same_user_df.iloc[1:].values\ncolumn_pairs = []\nfor i in range(lag_data.shape[1]):\n    matched_idx = find_feature_pairs(lag_data[:, [i]], future_data)\n    col_i = no_all_zeros_same_user_df.columns[i]\n    column_pairs.extend((col_i, no_all_zeros_same_user_df.columns[idx])\n                        for idx in matched_idx)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cb2301449b713cd776b3209ee7e2e9004a466b3"},"cell_type":"markdown","source":"## Build a directed graph"},{"metadata":{"trusted":true,"_uuid":"b965696102b5eb66e9d02549455a067dd3430583"},"cell_type":"code","source":"print(\"number of pairs:\", len(column_pairs))\nfeature_g = nx.DiGraph()\nfeature_g.add_edges_from(column_pairs)\nprint(\"number of matched features:\", len(feature_g))\nprint(\"number of groups:\", nx.number_weakly_connected_components(feature_g))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a83c8e3af19c1eb7fab15c61eff3bfc91ff6f13"},"cell_type":"markdown","source":"## Prune suspicious edges"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"17a601ef5e1cc85091e89178f98985eb84dba8cb"},"cell_type":"code","source":"# remove the in/out edges of the nodes that have multiple in/out edges\nfor node in list(feature_g.nodes):\n    out_edges = list(feature_g.out_edges(node))\n    if len(out_edges) > 1:\n        feature_g.remove_edges_from(out_edges)\n    in_edges = list(feature_g.in_edges(node))\n    if len(in_edges) > 1:\n        feature_g.remove_edges_from(in_edges)\n# remove isolated nodes\nfeature_g.remove_nodes_from(list(nx.isolates(feature_g)))\n\nprint(\"number of matched features:\", len(feature_g))\ncomponents = list(nx.weakly_connected_components(feature_g))\nprint(\"number of groups:\", len(components))\ncomponents.sort(key=len, reverse=True)\nCounter(len(c) for c in components)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b27416ae3e4d299c5730390121194d52613f45f3"},"cell_type":"markdown","source":"## Let's see the 2 time series that have length 40"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a6ca5fcbaba4f456b26eb11bd06481db28ca484e"},"cell_type":"code","source":"time_series_features = list(nx.topological_sort(feature_g.subgraph(components[0])))\nprint(time_series_features)\nsame_user_df[['target'] + time_series_features]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd9c185268e060b5bf49e37090fff3794c2bc633"},"cell_type":"markdown","source":"- this is obviously the label-related series"},{"metadata":{"trusted":true,"_uuid":"77d33cb251155bd6389029c163f4fe44dc346d35"},"cell_type":"code","source":"time_series_features = list(nx.topological_sort(feature_g.subgraph(components[1])))\nprint(time_series_features)\nsame_user_df[['target'] + time_series_features]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2586b14b8b1783054e686a9f8bd21b000fef902d"},"cell_type":"markdown","source":"- this is another time series that have a lot of non-zero values"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}