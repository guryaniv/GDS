{"nbformat_minor": 0, "cells": [{"cell_type": "markdown", "source": ["# First analysis of the Mercedes training data set"], "metadata": {"_cell_guid": "0dc56d56-3d46-44c0-8b0f-f99950535e8e", "_uuid": "0af8dafa510c4e0b61cc17f03717e9e7db267147"}}, {"outputs": [], "cell_type": "code", "source": ["# Importing main packages and settings\n", "import numpy as np\n", "import pandas as pd\n", "import xgboost as xgb\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "%matplotlib inline\n", "pd.set_option('display.max_columns', 50)"], "execution_count": null, "metadata": {"_cell_guid": "fcbb1bc8-8bef-2a23-66ff-a4113d84029f", "_uuid": "2c0078b6e6f438af1b245f8df540906851b5501c"}}, {"outputs": [], "cell_type": "code", "source": ["# Loading the training dataset\n", "df_train = pd.read_csv('../input/train.csv')\n", "df_test = pd.read_csv('../input/test.csv')"], "execution_count": null, "metadata": {"_cell_guid": "40a08aaa-c824-47b3-efa0-0dc825706d9f", "_uuid": "49f6e0638a05782546117de4196d3fd116e4bc23"}}, {"outputs": [], "cell_type": "code", "source": ["# first view of the training data set\n", "df_train.head()"], "execution_count": null, "metadata": {"_cell_guid": "1b0b6dbe-1892-abde-7be0-2c34982724b5", "_uuid": "7d8f12e15684e2d6d9bf32b0f405bf187106e746"}}, {"outputs": [], "cell_type": "code", "source": ["# additional information about the training data set\n", "print(df_train.info())\n", "print(df_train.dtypes)"], "execution_count": null, "metadata": {"_cell_guid": "d3f5ee3a-0925-ecf0-7a44-48d7a140dcbe", "_uuid": "a5ec463958074179335fa32b8ec084441361ac89"}}, {"outputs": [], "cell_type": "code", "source": ["# analysis of the object features of the training data set\n", "object_features = df_train.select_dtypes(include=[np.object])\n", "object_features.describe()"], "execution_count": null, "metadata": {"_cell_guid": "0885a151-bed3-379e-1df0-92b32b8d7219", "_uuid": "bc52df75d72dc86609b8dffc24242c480d535d3b"}}, {"outputs": [], "cell_type": "code", "source": ["# analysis of the object features of the test data set\n", "# note the different number of unique values compared to the training set\n", "object_features_test = df_test.select_dtypes(include=[np.object])\n", "object_features_test.describe()"], "execution_count": null, "metadata": {"_cell_guid": "7bbfa71f-ae3b-d04a-991d-252aa2f197c5", "_uuid": "04e7959987accd10f846d26f202232aeaa795332"}}, {"outputs": [], "cell_type": "code", "source": ["# analysis of the numerical features of the training data set\n", "numeric_features = df_train.select_dtypes(include=[np.number])\n", "numeric_features.describe()"], "execution_count": null, "metadata": {"_cell_guid": "a1c1707e-9bd0-a8eb-f384-07a6d4420431", "_uuid": "d9bb67f6321cf6276676ece0ba509495845c1c98"}}, {"outputs": [], "cell_type": "code", "source": ["# turning object features into dummy variables\n", "df_train_dummies = pd.get_dummies(df_train, drop_first=True)\n", "df_test_dummies = pd.get_dummies(df_test, drop_first=True)\n", "\n", "# dropping ID and the target variable\n", "df_train_dummies = df_train_dummies.drop(['ID','y'], axis=1)\n", "df_test_dummies = df_test_dummies.drop('ID', axis=1)\n", "\n", "print(\"Clean Train DataFrame With Dummy Variables: {}\".format(df_train_dummies.shape))\n", "print(\"Clean Test DataFrame With Dummy Variables: {}\".format(df_test_dummies.shape))"], "execution_count": null, "metadata": {"_cell_guid": "3a661141-59fc-b46b-a00b-04e8fd85f034", "_uuid": "fb883d390c2c19b7cf18998cff0262264b5fc3f9"}}, {"outputs": [], "cell_type": "code", "source": ["# concatenate to only include columns in both data sets\n", "# the number should be based on the number of columns. Original is 30471. Now set to 15471 after outlier handling etc.\n", "df_temp = pd.concat([df_train_dummies, df_test_dummies], join='inner')\n", "df_temp_train = df_temp[:len(df_train.index)]\n", "df_temp_test = df_temp[len(df_train.index):]\n", "\n", "# check shapes of combined df and split out again\n", "print(df_temp.shape)\n", "print(df_temp_train.shape)\n", "print(df_temp_test.shape)"], "execution_count": null, "metadata": {"_cell_guid": "bebc74ab-0d88-3489-4a10-6a43e3c56955", "_uuid": "dc5f30de374247f08c4b177e3e8c0a7c47253fbd"}}, {"outputs": [], "cell_type": "code", "source": ["# defining X and y\n", "X = df_temp_train\n", "test_X = df_temp_test\n", "y = df_train['y']"], "execution_count": null, "metadata": {"_cell_guid": "2a483b88-fe5c-dec2-ae67-ec1823ceedf2", "_uuid": "96b4ec7eadeafd196786acbc02be567d8f00ba51"}}, {"outputs": [], "cell_type": "code", "source": ["# Import the relevant sklearn packages\n", "from sklearn.model_selection import cross_val_score, train_test_split\n", "from sklearn.feature_selection import SelectFromModel, VarianceThreshold, SelectKBest, f_regression\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.ensemble import GradientBoostingRegressor\n", "from sklearn.linear_model import Lasso, Ridge, ElasticNet, LassoCV, RidgeCV, ElasticNetCV\n", "from sklearn.metrics import mean_squared_error"], "execution_count": null, "metadata": {"_cell_guid": "7dfa6598-c516-bb0b-4a03-53916021157e", "_uuid": "a45561db6ed70e7b7a5442723b5e59d0cc72712b"}}, {"cell_type": "markdown", "source": ["# First GBR tests on full data set"], "metadata": {"_cell_guid": "d062dacf-1cb3-029b-2bc0-a983197295f3", "_uuid": "90e13d6d9c308751ef6faf4fb714a24633a0e7c0"}}, {"outputs": [], "cell_type": "code", "source": ["# instantiating\n", "gbr = GradientBoostingRegressor()\n", "\n", "# setting up steps for the pipeline, with and without imputating\n", "steps = [('GradientBoostingRegressor', gbr)]\n", "\n", "# instantiating the pipeline\n", "pipe = Pipeline(steps)\n", "\n", "# creating train ang test sets using train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n", "\n", "# fitting and predicting\n", "pipe.fit(X_train, y_train)\n", "y_pred = pipe.predict(X_test)\n", "\n", "# Compute and print R^2 and RMSE\n", "print(\"R^2: {}\".format(pipe.score(X_test, y_test)))\n", "mse = mean_squared_error(y_test, y_pred)\n", "print(\"Mean Squared Error: {}\".format(mse))"], "execution_count": null, "metadata": {"_cell_guid": "313bb0f6-c156-6b76-bbe2-b2710c492c59", "_uuid": "cee473cb894e2fd101d5aeed8b4edd4c7dbf8b0e"}}, {"outputs": [], "cell_type": "code", "source": ["# Compute 5-fold cross-validation scores: cv_scores\n", "cv_scores_dummies = cross_val_score(pipe, X, y, cv=5)\n", "\n", "# Print the 5-fold cross-validation scores\n", "print(cv_scores_dummies)\n", "\n", "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_dummies)))"], "execution_count": null, "metadata": {"_cell_guid": "f572405a-d2cd-57fb-094b-85798e9a4905", "_uuid": "b97bdcdf9847890da9a504e4b720835ab8e54c75"}}, {"cell_type": "markdown", "source": ["# Removing features with a low amount of variation"], "metadata": {"_cell_guid": "5fa829f6-3806-f8a4-f843-88efe6c8dade", "_uuid": "a52de0c0c603e4d2575884a567bddf2dece4d40f"}}, {"outputs": [], "cell_type": "code", "source": ["# Fitting a feature selector\n", "def feature_selection(data):\n", "    selector = VarianceThreshold(.98 * (1 - .98))\n", "    selector.fit(data)\n", "    return selector\n", " \n", "#Learn the features to filter from train set\n", "fs = feature_selection(X)\n", " \n", "#Transform train and test subsets\n", "X_transformed = fs.transform(X)\n", "test_X_transformed = fs.transform(test_X)\n", "\n", "print(X_transformed.shape)\n", "print(test_X_transformed.shape)"], "execution_count": null, "metadata": {"_cell_guid": "391afc83-d4db-0a0e-b9f1-1bf54dae96c7", "_uuid": "e06cbcc129709f8fea6e16f48baadce4bdb27e61"}}, {"outputs": [], "cell_type": "code", "source": ["# instantiating\n", "gbr = GradientBoostingRegressor()\n", "\n", "# setting up steps for the pipeline, with and without imputating\n", "steps = [('GradientBoostingRegressor', gbr)]\n", "\n", "# instantiating the pipeline\n", "pipe = Pipeline(steps)\n", "\n", "# creating train ang test sets using train_test_split\n", "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)\n", "\n", "# fitting and predicting\n", "pipe.fit(X_transformed_train, y_train)\n", "y_pred = pipe.predict(X_transformed_test)\n", "\n", "# Compute and print R^2 and RMSE\n", "print(\"R^2: {}\".format(pipe.score(X_transformed_test, y_test)))\n", "mse = mean_squared_error(y_test, y_pred)\n", "print(\"Mean Squared Error: {}\".format(mse))"], "execution_count": null, "metadata": {"_cell_guid": "09951442-ce1f-8ed7-7dfc-cbc5dc3ba401", "_uuid": "0eb04924a0bf4aaf078a33648b18fc424e978562"}}, {"outputs": [], "cell_type": "code", "source": ["# Compute 5-fold cross-validation scores: cv_scores\n", "cv_scores_dummies = cross_val_score(pipe, X_transformed, y, cv=5)\n", "\n", "# Print the 5-fold cross-validation scores\n", "print(cv_scores_dummies)\n", "\n", "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_dummies)))"], "execution_count": null, "metadata": {"_cell_guid": "7bff55ba-95d1-1abb-5034-f33d15c30d4b", "_uuid": "17ca7aa70365c760a2182f739da146201427099e"}}, {"cell_type": "markdown", "source": ["# Selecting only kBest features\n", "Not working although it did work when I wasn't yet using dummy variables for the object features. Need to look into."], "metadata": {"_cell_guid": "58dab8a1-349f-fe11-f6d5-c6e0516d1469", "_uuid": "94139e6e341db72af02219fe9720569a45eba099"}}, {"outputs": [], "cell_type": "code", "source": ["skb = SelectKBest(f_regression, k=50)\n", "\n", "#Learn the features to filter from train set\n", "skb.fit(X, y)\n", "\n", "# transform the data sets\n", "X_transformed_kbest = skb.transform(X)\n", "test_X_transformed_kbest = skb.transform(test_X)\n", "\n", "print(X_transformed_kbest.shape)\n", "print(test_X_transformed_kbest.shape)"], "execution_count": null, "metadata": {"_cell_guid": "29c962f6-0368-d7e1-00e2-422b6b5677e9", "_uuid": "3125e795b0f9467bf2c857ae0918b7cf1899b6cf"}}, {"cell_type": "markdown", "source": ["## Lasso and LassoCV"], "metadata": {"_cell_guid": "698f5cc3-31e3-0707-08ec-b3067efe5562", "_uuid": "a7b2490e8246e0d06df8eed26462555d02319d73"}}, {"outputs": [], "cell_type": "code", "source": ["# instantiating\n", "las = Lasso(alpha=0.1)\n", "\n", "# setting up steps for the pipeline, with and without imputating\n", "steps = [('Lasso', las)]\n", "\n", "# instantiating the pipeline\n", "pipe = Pipeline(steps)\n", "\n", "# creating train ang test sets using train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n", "\n", "# fitting and predicting\n", "pipe.fit(X_train, y_train)\n", "y_pred = pipe.predict(X_test)\n", "\n", "# Compute and print R^2 and RMSE\n", "print(\"R^2: {}\".format(pipe.score(X_test, y_test)))\n", "mse = mean_squared_error(y_test, y_pred)\n", "print(\"Mean Squared Error: {}\".format(mse))"], "execution_count": null, "metadata": {"_cell_guid": "ba4b9fb0-0593-e5f9-1c16-307c981ad188", "_uuid": "86d7f1980a09fbdfb130e35f24fdfc7591535269"}}, {"outputs": [], "cell_type": "code", "source": ["# initiating\n", "lscv = LassoCV()\n", "\n", "# setting up steps for the pipeline, with and without imputating\n", "steps = [('LassoCV', lscv)]\n", "\n", "# instantiating the pipeline\n", "pipe = Pipeline(steps)\n", "\n", "# creating train ang test sets using train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n", "\n", "# fitting and predicting\n", "pipe.fit(X_train, y_train)\n", "y_pred = pipe.predict(X_test)\n", "\n", "# Compute and print R^2 and RMSE\n", "print(\"R^2: {}\".format(pipe.score(X_test, y_test)))\n", "mse = mean_squared_error(y_test, y_pred)\n", "print(\"Mean Squared Error: {}\".format(mse))"], "execution_count": null, "metadata": {"_cell_guid": "46d6c3bd-5c65-796b-7b72-7c06c8d17c6c", "_uuid": "38a56d3c3ea23f8f8026b5808652583de266ea9e"}}, {"cell_type": "markdown", "source": ["## Ridge and RidgeCV"], "metadata": {"_cell_guid": "51755617-f218-4094-f82e-f69b92aa85cf", "_uuid": "915c6ddb184f0330fb26b1a5e477c1b88049df96"}}, {"outputs": [], "cell_type": "code", "source": ["# instantiating\n", "rid = Ridge()\n", "\n", "# setting up steps for the pipeline, with and without imputating\n", "steps = [('Ridge', rid)]\n", "\n", "# instantiating the pipeline\n", "pipe = Pipeline(steps)\n", "\n", "# creating train ang test sets using train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n", "\n", "# fitting and predicting\n", "pipe.fit(X_train, y_train)\n", "y_pred = pipe.predict(X_test)\n", "\n", "# Compute and print R^2 and RMSE\n", "print(\"R^2: {}\".format(pipe.score(X_test, y_test)))\n", "mse = mean_squared_error(y_test, y_pred)\n", "print(\"Mean Squared Error: {}\".format(mse))"], "execution_count": null, "metadata": {"_cell_guid": "5e5a6ba7-dabb-a22f-34f6-f8a79ae97bf6", "_uuid": "a39c9f26ee3ef9039389f5a471143fa7578b73aa"}}, {"outputs": [], "cell_type": "code", "source": ["# instantiating\n", "rcv = RidgeCV()\n", "\n", "# setting up steps for the pipeline, with and without imputating\n", "steps = [('RidgeCV', rcv)]\n", "\n", "# instantiating the pipeline\n", "pipe = Pipeline(steps)\n", "\n", "# creating train ang test sets using train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n", "\n", "# fitting and predicting\n", "pipe.fit(X_train, y_train)\n", "y_pred = pipe.predict(X_test)\n", "\n", "# Compute and print R^2 and RMSE\n", "print(\"R^2: {}\".format(pipe.score(X_test, y_test)))\n", "mse = mean_squared_error(y_test, y_pred)\n", "print(\"Mean Squared Error: {}\".format(mse))"], "execution_count": null, "metadata": {"_cell_guid": "cab2780f-9c62-d57a-4ab1-292808c37340", "_uuid": "a89fc87ae46bf42a692a47e50ab39ddee2d3d15b"}}, {"cell_type": "markdown", "source": ["## ElasticNet and ElasticNet CV"], "metadata": {"_cell_guid": "cb108f7b-9cd0-d5aa-2deb-d0792b41151b", "_uuid": "6d2c840ff18eb38f72ca8d3edd5293183337e0b5"}}, {"outputs": [], "cell_type": "code", "source": ["# instantiating\n", "els = ElasticNet()\n", "\n", "# setting up steps for the pipeline, with and without imputating\n", "steps = [('ElasticNet', els)]\n", "\n", "# instantiating the pipeline\n", "pipe = Pipeline(steps)\n", "\n", "# creating train ang test sets using train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n", "\n", "# fitting and predicting\n", "pipe.fit(X_train, y_train)\n", "y_pred = pipe.predict(X_test)\n", "\n", "# Compute and print R^2 and RMSE\n", "print(\"R^2: {}\".format(pipe.score(X_test, y_test)))\n", "mse = mean_squared_error(y_test, y_pred)\n", "print(\"Mean Squared Error: {}\".format(mse))"], "execution_count": null, "metadata": {"_cell_guid": "dd25064b-ba89-fc7b-aca9-2a88e30b574e", "_uuid": "0e76662ef1d1ab7a8cb0eeb436117c904a5e9927"}}, {"outputs": [], "cell_type": "code", "source": ["# instantiating\n", "elcv = ElasticNetCV()\n", "\n", "# setting up steps for the pipeline, with and without imputating\n", "steps = [('ElasticNetCV', elcv)]\n", "\n", "# instantiating the pipeline\n", "pipe = Pipeline(steps)\n", "\n", "# creating train ang test sets using train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n", "\n", "# fitting and predicting\n", "pipe.fit(X_train, y_train)\n", "y_pred = pipe.predict(X_test)\n", "\n", "# Compute and print R^2 and RMSE\n", "print(\"R^2: {}\".format(pipe.score(X_test, y_test)))\n", "mse = mean_squared_error(y_test, y_pred)\n", "print(\"Mean Squared Error: {}\".format(mse))"], "execution_count": null, "metadata": {"_cell_guid": "bfd4eb02-b2d0-0347-8893-3a240a6cde3c", "_uuid": "c111b7734ebcaacbe64daf8c1f92ee4b1b5931c0"}}, {"outputs": [], "cell_type": "code", "source": ["df_columns = df_train.columns\n", "\n", "# Instantiate a lasso regressor: lasso\n", "lasso = Lasso(alpha=0.4, normalize=True)\n", "\n", "# Fit the regressor to the data\n", "lasso.fit(X, y)\n", "\n", "# Compute and print the coefficients\n", "lasso_coef = lasso.coef_\n", "# print(lasso_coef)\n", "\n", "# Plot the coefficients\n", "plt.plot(range(len(df_columns)), lasso_coef)\n", "plt.xticks(range(len(df_columns)), df_columns.values, rotation=60)\n", "plt.margins(0.02)\n", "plt.show()"], "execution_count": null, "metadata": {"_cell_guid": "09166faf-1c0c-9f17-2388-3e05f0b3ee80", "_uuid": "ef066687fb9cc39083b2b302cc7150337c7ddc4d"}}, {"cell_type": "markdown", "source": ["# Regularized regression tests"], "metadata": {"_cell_guid": "60487854-77c9-46b2-ffe0-ad4a5987a5d7", "_uuid": "e5546619b79030e487a504f4b84418626e883389"}}, {"cell_type": "markdown", "source": ["# All the below is older testing work on feature selection"], "metadata": {"_cell_guid": "7b5c5ce0-a60f-8a9d-e99d-9414006a2be5", "_uuid": "869a614b595820f03dc2cd84946d29a7d3071004"}}, {"outputs": [], "cell_type": "code", "source": ["X1 = df_train.drop(['ID', 'y'], axis=1)\n", "X1 = X.select_dtypes(include=[np.number])"], "execution_count": null, "metadata": {"_cell_guid": "221c8d43-e311-b7b2-1179-d9563a8f4bb0", "_uuid": "2aab99f896d993cc07f312e57fcbed1bb768aa19"}}, {"outputs": [], "cell_type": "code", "source": ["X1_test = df_test.drop(['ID'], axis=1)\n", "X1_test = X1_test.select_dtypes(include=[np.number])"], "execution_count": null, "metadata": {"_cell_guid": "22d16c13-4a86-52fb-8d12-a17fb40df996", "_uuid": "53c4b9701efde0831a7debfef078b6abbb0576c3"}}, {"outputs": [], "cell_type": "code", "source": ["y = df_train['y']"], "execution_count": null, "metadata": {"_cell_guid": "af34a94e-c28b-7058-f6ba-e5ff0f116fab", "_uuid": "3fbc07042178a23a3aa004b04fb478e634858449"}}, {"outputs": [], "cell_type": "code", "source": ["from sklearn.feature_selection import VarianceThreshold\n", "from sklearn.feature_selection import SelectKBest\n", "from sklearn.feature_selection import f_regression"], "execution_count": null, "metadata": {"_cell_guid": "5cda6a69-e80e-581e-ebe7-94275c7494bd", "_uuid": "9338c3c563c0b76cc62af00ce4ebacac3e0eda32"}}, {"outputs": [], "cell_type": "code", "source": ["# Fitting a feature selector\n", "def feature_selection(data):\n", "    selector = VarianceThreshold(.95 * (1 - .95))\n", "    selector.fit(data)\n", "    return selector\n", " \n", "#Learn the features to filter from train set\n", "fs = feature_selection(X1)\n", " \n", "#Transform train and test subsets\n", "X1_transformed = fs.transform(X1)\n", "X1_test_transformed = fs.transform(X1_test)\n", "\n", "print(X1_transformed.shape)\n", "print(X1_test_transformed.shape)"], "execution_count": null, "metadata": {"_cell_guid": "270d98c1-6580-3e21-87cc-49ccf2a2a2a1", "_uuid": "77a4b29e2b5b943afaa8cd7787fe28d60bed472a"}}, {"outputs": [], "cell_type": "code", "source": ["# Fitting a feature selector\n", "def feature_selection(data):\n", "    selector = VarianceThreshold(.95 * (1 - .95))\n", "    selector.fit(data)\n", "    return selector\n", " \n", "#Learn the features to filter from train set\n", "fs = feature_selection(X1)\n", " \n", "#Transform train and test subsets\n", "X1_transformed = fs.transform(X1)\n", "X1_test_transformed = fs.transform(X1_test)\n", "\n", "print(X1_transformed.shape)\n", "print(X1_test_transformed.shape)"], "execution_count": null, "metadata": {"_cell_guid": "03a040d1-1738-1fd0-6ecf-ae4c77802193", "_uuid": "7f8e844f0f3efc796a80ae53ca37bc376aca7ffa"}}, {"outputs": [], "cell_type": "code", "source": ["skb = SelectKBest(f_regression, k=30)\n", "\n", "skb.fit(X1_transformed, y)\n", "X1_transformed_kbest = skb.transform(X1_transformed)\n", "X1_test_transformed_kbest = skb.transform(X1_test_transformed)\n", "\n", "print(X1_transformed_kbest.shape)\n", "print(X1_test_transformed_kbest.shape)"], "execution_count": null, "metadata": {"_cell_guid": "71baa364-221d-d0fc-0063-904fb7d9a7bc", "_uuid": "2d66fa608f853eb19805dd18f036ee56bb27c150"}}], "nbformat": 4, "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"nbconvert_exporter": "python", "name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "version": "3.6.0", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}, "_change_revision": 0, "_is_fork": false}}