{"nbformat_minor": 1, "nbformat": 4, "cells": [{"outputs": [], "execution_count": null, "source": ["from datetime import datetime \n", "start = datetime.now()\n", "#Importing libraries\n", "import pandas as pd\n", "import numpy as np\n", "import scipy as sci\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "import multiprocessing\n", "%matplotlib inline"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "5c083b5a1e71d7d99661b59a24ace295bcdf9c4f", "_cell_guid": "0b5e892c-3be3-477c-9b11-d4af9d656e92"}}, {"outputs": [], "execution_count": null, "source": ["train = pd.read_csv(\"../input/train.tsv\", sep='\\t')\n", "test = pd.read_csv(\"../input/test.tsv\", sep='\\t')"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "d41a5b16854d741a8e55c677c018df95f7a81504", "_cell_guid": "c1cbd6d5-038a-4818-8483-c9e6a1f1be04"}}, {"outputs": [], "execution_count": null, "source": ["#Getting rid of outliers\n", "train['bigger_than_200'] = train['price'].map(lambda x: 1 if x >200 else 0)\n", "train = train[train['bigger_than_200'] ==0]\n", "del train['bigger_than_200']"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "649af4fc08b8e9a7ec1ee7c5603a9b36c635badd", "_cell_guid": "0894e0d5-3596-4996-ba01-5d8fc0db592a"}}, {"outputs": [], "execution_count": null, "source": ["print(train.shape)\n", "print(test.shape)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "b4ac71eab56e3cac6d96627e9a4bce36877391ea", "_cell_guid": "2fe0462c-49f3-4cc7-8a53-7f81de004c35"}}, {"outputs": [], "execution_count": null, "source": ["#Checking any missing values,\n", "import missingno as msno\n", "msno.bar(train,sort=True,figsize=(10,5))\n", "msno.bar(test,sort=True,figsize=(10,5))"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "ac40409a61fb37845e03e41ef57f7ccfa6b9f6f2", "_cell_guid": "40f45355-7b2d-4932-b480-6c941b13b8d7"}}, {"outputs": [], "execution_count": null, "source": ["#Getting the length of item description\n", "train['length'] = train['item_description'].map(lambda x: len(str(x)))\n", "test['length'] = test['item_description'].map(lambda x: len(str(x)))\n", "\n", "np.mean(train['length'])\n", "np.mean(test['length'])"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "ac8ef0c80276ae5e59b867ddc29434bc90918326", "_cell_guid": "94e1f728-fe0a-4602-a0cb-1dd169a2e37d"}}, {"source": ["They are close. Good !"], "cell_type": "markdown", "metadata": {"_uuid": "cfb95ad6812a4ff82b9a34112f2603ef58fd344d", "_cell_guid": "ecf3224f-4074-4b92-b39a-f0e9338e7fa0"}}, {"outputs": [], "execution_count": null, "source": ["train.head()"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "4e8c3e7ea763d70e3df79e34a98d5858a0a26cc8", "_cell_guid": "b3a7525f-2fc8-4343-b373-625b53dfb5cb"}}, {"outputs": [], "execution_count": null, "source": ["#Merging data\n", "data = pd.concat([train,test])\n", "#Defining a variable\n", "data['train_or_not'] = data['train_id'].map(lambda x: 1 if x.is_integer() else 0)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "56057dfa36f67c199021d2b7fee6d0cef6a74ffe", "_cell_guid": "6ceff7dd-9dbd-4fbd-abee-6acb44d4c0fd"}}, {"outputs": [], "execution_count": null, "source": ["#lowering letters\n", "data['brand_name'] = data['brand_name'].map(lambda x: str(x).lower())\n", "data['category_name'] = data['category_name'].map(lambda x: str(x).lower())\n", "data['item_description'] = data['item_description'].map(lambda x: str(x).lower())\n", "data['name'] = data['name'].map(lambda x: str(x).lower())"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "1dc0c2bb985c725b848d3cce6f45c002c3ead3f4", "_cell_guid": "adeb7c90-0bb5-4abc-b3c0-45859805a687"}}, {"outputs": [], "execution_count": null, "source": ["data['no_of_words'] = data['item_description'].map(lambda x: len(str(x).split()))\n", "\n", "np.mean(data['no_of_words'])"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "b1cd5acecce7f85e075797b424d4edc21385dbdc", "_cell_guid": "0cbacbcc-94e7-41b6-bc74-4229c205c71f"}}, {"source": ["There are 25.63 words in a description on average"], "cell_type": "markdown", "metadata": {"_uuid": "02e111dc206fd2a743e8bfeff0165da63d355d0e", "_cell_guid": "3f7dee6d-e7d7-4c36-86e3-ad46e58d1f89"}}, {"outputs": [], "execution_count": null, "source": ["##Brand names\n", "#Number of unique brand names\n", "print(len(set(data['brand_name'])))\n", "print('brand_name in train',len(set(train['brand_name'])))\n", "print('brand_name in test',len(set(test['brand_name'])))"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "d99c625c0261372b5b3d932fae4b4247c6039d49", "_cell_guid": "998b6847-5a74-443d-893f-f5fd2a93f806"}}, {"outputs": [], "execution_count": null, "source": ["train_cat_names= list(set(train['brand_name']))\n", "test_cat_names= list(set(test['brand_name']))\n", "\n", "in_test_not_in_train = [x for x in test_cat_names if x not in train_cat_names]\n", "print(len(in_test_not_in_train))\n", "\n", "in_train_not_in_test = [x for x in train_cat_names if x not in test_cat_names]\n", "print(len(in_train_not_in_test))\n"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "1ad1c6ecbd459f128290e33466fec65296dff7b6", "_cell_guid": "917b2d34-0741-4a38-8f12-ed954e350228"}}, {"outputs": [], "execution_count": null, "source": ["#category\n", "data['categories'] = data['category_name'].map(lambda x: list(str(x).split('/')))"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "0e679e3958576b06e8b95791a32543722b3cbb42", "_cell_guid": "4feb0d8d-00c8-45c5-8997-d2f812d4142d"}}, {"outputs": [], "execution_count": null, "source": ["#no descriptions\n", "data['no_description'] = data['item_description'].map(lambda x: 1 if str(x) =='no description yet' else 0)\n", "print(len(data[data['no_description']==1]))"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "d0e01e199625c1df274341ae5ecae5096413696d", "_cell_guid": "d007c33d-4529-4bd5-83cf-b119c6bc4c14"}}, {"outputs": [], "execution_count": null, "source": ["print('brand_name = nan & no description',len(data[(data['brand_name']=='nan') & (data['no_description'] ==1)]))\n"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "708b9b2c93e65be3b97c4f2cf8e5aa391f7604c2", "_cell_guid": "054f6a6a-a154-46c7-9a09-2f0cf9e63d8b"}}, {"outputs": [], "execution_count": null, "source": ["#No brand name and no desc\n", "no_desc_no_brand = data[(data['brand_name']=='nan') & (data['no_description'] ==1)]\n", "no_desc_no_brand['test'] = no_desc_no_brand['test_id'].map(lambda x: 1 if x.is_integer() else 0)\n", "no_desc_no_brand = no_desc_no_brand[no_desc_no_brand['test'] ==0]"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "81e67c385f4299e722c150ff3e119298b1682337", "_cell_guid": "6eed2bbe-5f35-414f-92f7-8683fe053d1d"}}, {"outputs": [], "execution_count": null, "source": ["plt.style.use('fivethirtyeight')\n", "plt.subplots(figsize=(10,5))\n", "no_desc_no_brand['price'].hist(bins=150,edgecolor='black',grid=False)\n", "plt.xticks(list(range(0,100,5)))\n", "plt.title('Price vs no brand&no_description')\n", "plt.show() "], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "c7d8c994b864e17d98271111401e8bb74e4f7b17", "_cell_guid": "82a19f63-ef73-4b4b-80e6-c8cac06f9878"}}, {"outputs": [], "execution_count": null, "source": ["#No of rows whose price is bigger than 100\n", "print(\"No of rows whose price is bigger than hundred in no_brand&no_description\",len(no_desc_no_brand[no_desc_no_brand['price'] >200]))\n", "\n", "no_desc_no_brand['price'].describe()\n", "del no_desc_no_brand"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "85866864cb55a549bed1a06efb020455f9c915c6", "_cell_guid": "84302b13-78c0-4f67-8838-5af72b04366c"}}, {"outputs": [], "execution_count": null, "source": ["from ggplot import *\n", "p = ggplot(aes(x='price'), data=train[train['price']<200]) + geom_histogram(binwidth=10)+ theme_bw() + ggtitle('Histogram of price in train data')\n", "print(p)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "31b9578f9726f25ac7d3b16368a43f8e1c6213ce", "_cell_guid": "2dd28fa5-7af4-4319-91ce-75991cc0882f"}}, {"outputs": [], "execution_count": null, "source": ["data['price'].describe().apply(lambda x: format(x, 'f'))"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "4fdc8e2acaab0245fbe3105dbc05afd43ab0554e", "_cell_guid": "dfa0861d-968d-4ce8-9666-174b8cdf84bd"}}, {"outputs": [], "execution_count": null, "source": ["#Length of categories\n", "data['len_categories'] = data['categories'].map(lambda x: len(x))"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "1b495645348679f0c942551e54c1028b85f8af80", "_cell_guid": "ef52ced5-9b7d-48e7-8d52-8dd9a452274f"}}, {"source": ["Most of products have 3 categories"], "cell_type": "markdown", "metadata": {"_uuid": "34f4bc3cda80378b0bea490b1c9a271745054e4a", "_cell_guid": "f8eb1e35-1d28-41b9-996f-1f880f9721c7"}}, {"outputs": [], "execution_count": null, "source": ["#Value_counts for item_condition_id\n", "temp1=data['item_condition_id'].value_counts()[:5].to_frame()\n", "sns.barplot(temp1.index,temp1['item_condition_id'],palette='inferno')\n", "plt.title('Item condition id')\n", "plt.xlabel('')\n", "fig=plt.gcf()\n", "fig.set_size_inches(10,10)\n", "plt.show()"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "2d921cabe82212027c67c45c77d0bbcf258f68c0", "_cell_guid": "ac83a0b7-1cea-47eb-8298-df8cc5822c3c"}}, {"outputs": [], "execution_count": null, "source": ["#Making binary 'item_condition_id'\n", "ic_list = list(set(data['item_condition_id']))\n", "\n", "for i in ic_list:\n", "    data['item_condition_id'+str(i)] = data['item_condition_id'].map(lambda x: 1 if x==i else 0)\n", "\n", "del data['item_condition_id']"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "fa8df88a0136f0e75a725f086341f7c0986580ed", "_cell_guid": "2b3c7b29-bb89-4547-97a4-d4d8b78572b9"}}, {"outputs": [], "execution_count": null, "source": ["#Correlation between no_of_words and price\n", "corr = data[['no_of_words','price','shipping','len_categories','length']].corr()\n", "\n", "# Set up the matplot figure\n", "f,ax = plt.subplots(figsize=(12,9))\n", "\n", "#Draw the heatmap using seaborn\n", "sns.heatmap(corr, cmap='inferno', annot=True)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "26229e7c997de43a40a895df55880620628b048b", "_cell_guid": "e7546881-8957-48d4-aa1b-a2bb4c57e793"}}, {"source": ["Please don't care the name of variables I defined below, I defined them according to 100 but due to time constrain, i lowered them."], "cell_type": "markdown", "metadata": {"_uuid": "dc18b6a9fb54b36fd890fd1442b96f953d671160", "_cell_guid": "cd671689-5e45-40de-8e12-3908ef94dd38"}}, {"outputs": [], "execution_count": null, "source": ["##Name\n", "import nltk\n", "import collections as co\n", "stopWords =co.Counter( nltk.corpus.stopwords.words() )\n", "words = list(data['name'])\n", "#Merging in a big string\n", "big_string=\" \".join(words)\n", "#Splitting them via blank\n", "name_list = big_string.split()\n", "#Omitting splitwords\n", "name_list = [x for x in name_list if x not in stopWords]\n", "#Getting unique words\n", "unique_names = list(set(name_list))\n", "#Counting them\n", "c = co.Counter(name_list)\n", "most_common_100 = c.most_common(60)\n", "most_common_100_2 = [x[0] for x in most_common_100]\n", "#Making them a column\n", "for i in most_common_100_2:\n", "    data['name_'+str(i)] = data['name'].map(lambda x: 1 if i in x else 0)\n", "\n", "print(\"name completed\")"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "f7aa269305d183179d28520486a5459ca12be721", "_cell_guid": "97e86058-8bf2-4d02-a796-60a5065a1820"}}, {"source": ["Please don't care the name of variables I defined below. Due to time constraint, I reduced number of columns."], "cell_type": "markdown", "metadata": {"_uuid": "cbca85855592d26be8e56f3f00c53f1536f08fde", "_cell_guid": "fd940dbb-8a1b-4f02-8eba-e1a6923988b3"}}, {"outputs": [], "execution_count": null, "source": ["##Description\n", "words1 = list(data['item_description'])\n", "big_string1=\" \".join(words1)\n", "name_list1 = big_string1.split()\n", "\n", "name_list1 = [x for x in name_list1 if x not in stopWords]\n", "\n", "unique_names1 = list(set(name_list1))\n", "\n", "c = co.Counter(name_list1)\n", "most_common_100_desc = c.most_common(60)\n", "most_common_100_2_desc = [x[0] for x in most_common_100_desc]\n", "for i in most_common_100_2_desc:\n", "    data['item_description_'+str(i)] = data['item_description'].map(lambda x: 1 if i in x else 0)\n", "\n", "print(\"description completed\")"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "4395463efca9d6253b7cc07492cff7c2c0ae19cd", "_cell_guid": "cc37e55e-5621-4dd1-9fc5-aa545b8dcd96"}}, {"outputs": [], "execution_count": null, "source": ["##First common 200 brands\n", "most_common_brands = data['brand_name'].value_counts().sort_values(ascending=False)[:100]\n", "\n", "most_common_brands = list(most_common_brands.index)\n", "#If a brand not in common brands, it was labeled as other_brand\n", "other_brand = \"other_brand\"\n", "data['brand_name'] = data['brand_name'].map(lambda x: x if x in most_common_brands else other_brand)\n", "\n", "empty_df = pd.get_dummies(data['brand_name'])\n", "emp_list = list(empty_df.columns.values)\n", "emp_list = ['brand_' + str(x) for x in emp_list]\n", "empty_df.columns = emp_list\n", "        \n", "data2 = pd.concat([data,empty_df],axis=1)\n", "data = data2\n", "del data2,empty_df\n", "del name_list,name_list1,words,words1,big_string,big_string1\n", "print(\"brand completed\")"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "bfbbb5f347995b3725fdf4ea822c390b7580e92d", "_cell_guid": "3eb094d5-8a48-4f4d-a8bd-3500253aa749"}}, {"outputs": [], "execution_count": null, "source": ["#categories\n", "data['categories']= data['categories'].map(lambda x: list(x)+[0,0,0,0])\n", "data['cat1']=data['categories'].map(lambda x: x[0])\n", "data['cat2']=data['categories'].map(lambda x: x[1])\n", "data['cat3']=data['categories'].map(lambda x: x[2])\n", "data['cat4']=data['categories'].map(lambda x: x[3])\n", "data['cat5']=data['categories'].map(lambda x: x[4])\n", "most_common_cat1=data['cat1'].value_counts().sort_values(ascending=False)[:11]\n", "most_common_cat2=data['cat2'].value_counts().sort_values(ascending=False)[:35]\n", "most_common_cat3=data['cat3'].value_counts().sort_values(ascending=False)[:50]\n", "most_common_cat4=data['cat4'].value_counts().sort_values(ascending=False)[:100]\n", "most_common_cat5=data['cat5'].value_counts().sort_values(ascending=False)[:100]\n", "\n", "\n", "#Categories, we fill focus on first 3 categories\n", "cat1_list = list(most_common_cat1.index)\n", "cat2_list = list(most_common_cat2.index)\n", "cat3_list = list(most_common_cat3.index)\n"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "b86c8bfec28112d4950b14ef5121539461f2bd0a", "_cell_guid": "817b7745-57eb-4d17-be62-a9c884304010"}}, {"outputs": [], "execution_count": null, "source": ["#If a category not in cat1, it was labeled as 'cat1_other'\n", "cat1_other = \"cat1_other\"\n", "data['cat1'] = data['cat1'].map(lambda x: x if x in cat1_list else cat1_other)\n", "#If a category not in cat2, it was labeled as 'cat2_other'\n", "cat2_other = \"cat2_other\"\n", "data['cat2'] = data['cat2'].map(lambda x: x if x in cat2_list else cat2_other)\n", "#If a category not in cat3, it was labeled as 'cat3_other'\n", "cat3_other = \"cat3_other\"\n", "data['cat3'] = data['cat3'].map(lambda x: x if x in cat3_list else cat3_other)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "c368b264a91327b875bd08bc6930ae86823b7814", "_cell_guid": "83f5d040-80db-4b99-acd0-de999705a721"}}, {"outputs": [], "execution_count": null, "source": ["#Making binary for cat1\n", "empty_df1 = pd.get_dummies(data['cat1'])\n", "emp_list1 = list(empty_df1.columns.values)\n", "emp_list1 = ['cat1_' + str(x) for x in emp_list1]\n", "empty_df1.columns = emp_list1\n", "#Making binary for cat2\n", "empty_df2 = pd.get_dummies(data['cat2'])\n", "emp_list2 = list(empty_df2.columns.values)\n", "emp_list2 = ['cat2_' + str(x) for x in emp_list2]\n", "empty_df2.columns = emp_list2\n", "#Making binary for cat3\n", "empty_df3 = pd.get_dummies(data['cat3'])\n", "emp_list3 = list(empty_df3.columns.values)\n", "emp_list3 = ['cat3_' + str(x) for x in emp_list3]\n", "empty_df3.columns = emp_list3\n", "#Merging them\n", "data2 = pd.concat([data,empty_df1,empty_df2,empty_df3],axis=1)\n", "data = data2\n", "#Deleting unnecessary things\n", "del data2,empty_df1,empty_df2,empty_df3\n", "del data['cat1'],data['cat2'],data['cat3'],data['cat4'],data['cat5'],data['item_description'],data['name'],data['categories'],data['category_name'],data['brand_name']"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "bcab5f9daa6ee8b88fbcc2a5af6d7efadcddac46", "_cell_guid": "2c223800-9698-4d07-be3d-38ed688f52b0"}}, {"outputs": [], "execution_count": null, "source": ["print(\"category completed\")\n", "stop = datetime.now()\n", "execution_time = stop-start \n", "print(execution_time)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "99643e975fbb7227576a3ccf53be9b0a43cff139", "_cell_guid": "42022f06-107f-4441-9791-e76c1b65eef7"}}, {"outputs": [], "execution_count": null, "source": ["test_id = data['test_id']\n", "train_id = data['train_id']\n", "del data['train_id'],data['test_id']\n", "data_head = data.head()\n", "#Separating the merged data into train and test\n", "training = data[data['train_or_not'] ==1]\n", "testing = data[data['train_or_not'] ==0]"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "30e39538440661ce5a633f122915be91ed736598", "_cell_guid": "83b63b96-2554-43f4-8cc2-12bc9130c95c"}}, {"outputs": [], "execution_count": null, "source": ["del training['train_or_not']\n", "del testing['train_or_not']"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "ddaf310eed8409c382709e8e4b1e0d4b780ec57d", "_cell_guid": "23e1cb15-e0bf-4e71-a6b9-f366a815469e"}}, {"outputs": [], "execution_count": null, "source": ["y = training['price'].values\n", "#Deleting unnecessary columns\n", "del training['price']\n", "del testing['price']\n", "train_size = len(list(training.columns.values))\n", "train_names = list(training.columns.values)\n"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "8bc0ed9f9dfd090fdfe4ba228e4534e9389456ca", "_cell_guid": "b52b54da-9f62-40e7-9880-dbe8c0450384"}}, {"source": ["I decided which parameters are important via XGBoost .The code below takes approximately 45 minutes on a CPU. I made it comment because I donT we have enough time"], "cell_type": "markdown", "metadata": {"_uuid": "ec5357f212473f16313c8f95e53cd1d2dd194146", "_cell_guid": "3b9d52e9-6d34-480e-be74-f01c9df72712"}}, {"outputs": [], "execution_count": null, "source": ["\"\"\"\n", "training = training.values\n", "testing = testing.values\n", "start = datetime.now()\n", "import xgboost as xgb\n", "model = xgb.XGBRegressor(n_estimators=50)\n", "model.fit(training,y)\n", "ending = datetime.now()\n", "print(ending-start)\n", "print (model)\n", "\n", "\n", "from xgboost import plot_importance\n", "fig, ax = plt.subplots(figsize=(20, 15))\n", "plot_importance(model, ax=ax)\n", "\n", "training = pd.DataFrame(training)\n", "testing= pd.DataFrame(testing)\n", "\n", "temp = pd.DataFrame(model.feature_importances_)\n", "temp2 = list(temp[temp[0]>0].index)\n", "\"\"\""], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "8bcf3b2b3f42e5c819651b5223116fb56ec1eb9f", "_cell_guid": "06b0ebad-204d-4010-9dba-697fd86f5511"}}, {"outputs": [], "execution_count": null, "source": ["#The numbers below represent which columns are important.We obtained them via the code above\n", "temp2 =[0, 1, 4, 5, 8, 10, 11, 14, 17, 21, 23, 27, 50, 52, 53, 63, 65, 70, 71, 72, 73, 74, 84, 89, 91, 102, 104, 109, 110, 115, 124, 125, 131, 133, 139, 157, 158, 162, 173, 174, 178, 180, 185, 188, 194, 196, 205, 208, 218, 220, 231, 232, 235, 236, 247, 248, 251, 259, 265, 268, 272, 277, 281, 284, 288, 289, 303, 306, 308, 310, 312]\n"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "cd888af894b7ee95930a19dedbf6073f48e5e6ff", "_cell_guid": "15cbc592-d8e4-4ca2-abab-27f5bd056c6f"}}, {"outputs": [], "execution_count": null, "source": ["#Getting the names of important features via indexing\n", "temp3 = [train_names[x] for x in temp2]\n", "print(\"some important features are \",temp3[:20])"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "bc2ee3c8880cb69d3fa438637d140d2c31fb68aa", "_cell_guid": "d4bb439c-1edf-4e33-930c-b489b926c94c"}}, {"outputs": [], "execution_count": null, "source": ["#Preparing model for ANN\n", "testing.columns = train_names\n", "training.columns = train_names\n", "#Getting important columns\n", "training_last = training[temp3]\n", "testing_last = testing[temp3]\n", "print(training_last.shape)\n", "print(testing_last.shape)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "90d5e7ada8934c7ba25cfe0e4f49ce57a1976697", "_cell_guid": "b32d24dc-2bcb-4c9c-93d4-b6481814d6ff"}}, {"outputs": [], "execution_count": null, "source": ["input_node = len(list(training_last.columns.values))\n", "print(\"there are \",input_node,\" nodes in input layer\")\n", "#Makin ndarray\n", "training_last = training_last.values\n", "testing_last = testing_last.values"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "1febd0a5b2550fd9c7275928dd73da54d485648a", "_cell_guid": "2479c1b2-a3f8-4445-9143-32d50a7e5563"}}, {"source": ["I didn't normalize the columns because it takes time. Most of our columns are binary. Therefore, it doesn't look logical to standardize."], "cell_type": "markdown", "metadata": {"_uuid": "df50214a9e13c6f0ce26b415972afb7286081b0c", "_cell_guid": "e3c36926-b8af-4acc-a2e3-a062e9b80189"}}, {"outputs": [], "execution_count": null, "source": ["#part 2 :Let'S make ANN\n", "# importing the keras library\n", "import keras\n", "# required to initialize NN\n", "from keras.models import Sequential\n", "#Required to build layers of NN\n", "from keras.layers import Dense\n", "from keras.layers import Dropout\n", "#Initializing the ANN\n", "classifier = Sequential()"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "e7ac7befebd57f8c28b0cf768ae0ff0c92109e44", "_cell_guid": "4da57d83-0176-45a6-829f-1b483b93c5ba"}}, {"outputs": [], "execution_count": null, "source": ["#adding the input layer and first hidden layer (71 nodes on Input layer, 71 nodes on Hidden Layer 1) and RELU\n", "classifier.add(Dense(output_dim = 100 , init ='he_normal', activation ='relu',input_dim = input_node))\n", "classifier.add(Dropout(p=0.15))\n", "#Adding the second layer(71 nodes on Hidden layer 1, 60 nodes on Hidden Layer 2) and RELU\n", "classifier.add(Dense(output_dim = 40 , init ='glorot_uniform', activation ='tanh'))\n", "classifier.add(Dropout(p=0.07))\n", "#adding the output layer- \n", "classifier.add(Dense(output_dim = 1 , init ='uniform'))\n", "#compiling ANN- optimizer for weights on ANN , adam = storchastik gradient descentlerden birisi\n", "classifier.compile( optimizer='adam' , loss='mean_squared_logarithmic_error', metrics = ['mae']  )"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "db32896684202371081e994365d5d66186969de2", "_cell_guid": "f2ae7a1b-4310-4570-b399-c9514d009c17"}}, {"outputs": [], "execution_count": null, "source": ["start = datetime.now()\n", "classifier.fit(training_last, y ,batch_size=64,nb_epoch=8)\n", "stop = datetime.now()\n", "execution_time = stop-start \n", "print(execution_time)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "060c54a6fa8d44bfd644bfeb3198599cfb617ac5", "_cell_guid": "3c493f6d-9deb-4c9e-8a2a-db81ad0d894c"}}, {"outputs": [], "execution_count": null, "source": ["#Preparing the submission file\n", "our_pred = classifier.predict(testing_last)\n", "our_pred = pd.DataFrame(our_pred)\n", "ourpred = pd.DataFrame(our_pred).rename(columns={0:'price'})\n", "\n", "test_id = test_id[len(train):len(data)]\n", "test_id = test_id.map(lambda x: int(x))\n", "test_id = test_id.reset_index(drop=True)\n", "test_id = pd.DataFrame(test_id)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "0dc9127642146c66f222b890cf0bff0ee7ef1564", "_cell_guid": "47548e04-259c-4e26-bdf3-683c69ab4895"}}, {"outputs": [], "execution_count": null, "source": ["output_file = pd.concat([test_id,ourpred],axis=1)\n", "\n", "print(\"average of test predictions = \",np.mean(output_file['price']))\n", "\n", "output_file.to_csv('16-01-2018-mercari-ANN3.csv',index=False)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "00d4abae20851aee7538aa45e41a0fcc177f1c5c", "_cell_guid": "1d8e9317-bfa6-475a-b42c-928304f51e81"}}, {"outputs": [], "execution_count": null, "source": [], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "285774f0f7b2d92a140eb63e0b5656c32ce23b0b", "_cell_guid": "72684c96-c030-4f09-994a-fdb08e8d13f4"}}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"file_extension": ".py", "pygments_lexer": "ipython3", "name": "python", "version": "3.6.4", "nbconvert_exporter": "python", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}}}}