{"nbformat_minor": 1, "cells": [{"cell_type": "markdown", "source": ["# Visualizing Word Vectors with t-SNE\n", "\n", "TSNE is pretty useful when it comes to visualizing similarity between objects. It works by taking a group of high-dimensional (100 dimensions via Word2Vec) vocabulary word feature vectors, then compresses them down to 2-dimensional x,y coordinate pairs. The idea is to keep similar words close together on the plane, while maximizing the distance between dissimilar words. \n", "\n", "### Steps\n", "\n", "1. Clean the data\n", "2. Build a corpus\n", "3. Train a Word2Vec Model\n", "4. Visualize t-SNE representations of the most common words \n", "\n", "Credit: Some of the code was inspired by this awesome [NLP repo][1]. \n", "\n", "\n", "\n", "\n", "  [1]: https://github.com/rouseguy/DeepLearningNLP_Py"], "metadata": {"_cell_guid": "e8acc802-80ba-e4b0-403c-df40ce20cf20", "_uuid": "e5fe6d38878391cfd64a79f6ace83d7663cfcfd6"}}, {"cell_type": "code", "outputs": [], "source": ["import pandas as pd\n", "pd.options.mode.chained_assignment = None \n", "import numpy as np\n", "import re\n", "import nltk\n", "\n", "from gensim.models import word2vec\n", "\n", "from sklearn.manifold import TSNE\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "data = pd.read_csv('../input/train.csv').sample(50000, random_state=23)"], "metadata": {"_cell_guid": "327a2a48-c101-959c-af2d-cabd82276e65", "_uuid": "d11607b121e544156f838efeb3df884520143e77", "collapsed": true}, "execution_count": null}, {"cell_type": "code", "outputs": [], "source": ["STOP_WORDS = nltk.corpus.stopwords.words()\n", "\n", "def clean_sentence(val):\n", "    \"remove chars that are not letters or numbers, downcase, then remove stop words\"\n", "    regex = re.compile('([^\\s\\w]|_)+')\n", "    sentence = regex.sub('', val).lower()\n", "    sentence = sentence.split(\" \")\n", "    \n", "    for word in list(sentence):\n", "        if word in STOP_WORDS:\n", "            sentence.remove(word)  \n", "            \n", "    sentence = \" \".join(sentence)\n", "    return sentence\n", "\n", "def clean_dataframe(data):\n", "    \"drop nans, then apply 'clean_sentence' function to question1 and 2\"\n", "    data = data.dropna(how=\"any\")\n", "    \n", "    for col in ['question1', 'question2']:\n", "        data[col] = data[col].apply(clean_sentence)\n", "    \n", "    return data\n", "\n", "data = clean_dataframe(data)\n", "data.head(5)"], "metadata": {"_cell_guid": "c5d7458b-d380-8af7-13cf-5ed65fb42a83", "_uuid": "6b42983b5c826eb4ec298ca03d3c5b9da29fdadf", "collapsed": true}, "execution_count": null}, {"cell_type": "code", "outputs": [], "source": ["def build_corpus(data):\n", "    \"Creates a list of lists containing words from each sentence\"\n", "    corpus = []\n", "    for col in ['question1', 'question2']:\n", "        for sentence in data[col].iteritems():\n", "            word_list = sentence[1].split(\" \")\n", "            corpus.append(word_list)\n", "            \n", "    return corpus\n", "\n", "corpus = build_corpus(data)        \n", "corpus[0:2]"], "metadata": {"_cell_guid": "e72326d7-e707-d4e9-928a-519a9193bfc5", "_uuid": "6c66b614038c49b03428c4b44e717cc4f04af63f", "collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": ["# Word 2 Vec\n", "\n", "The Word to Vec model produces a vocabulary, with each word being represented by an n-dimensional numpy array (100 values in this example)"], "metadata": {"_cell_guid": "c652ad03-be65-f4e6-0afd-02c237449b43", "_uuid": "ff8af5f446f4cf4c941953bf115476075d60323f"}}, {"cell_type": "code", "outputs": [], "source": ["model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=200, workers=4)\n", "model.wv['trump']"], "metadata": {"_cell_guid": "ee9f9d57-5b3a-16c0-916f-169ef6d7b920", "_uuid": "f4e3863c7d0111533a9e35eddc0048c7c324471c", "collapsed": true}, "execution_count": null}, {"cell_type": "code", "outputs": [], "source": ["def tsne_plot(model):\n", "    \"Creates and TSNE model and plots it\"\n", "    labels = []\n", "    tokens = []\n", "\n", "    for word in model.wv.vocab:\n", "        tokens.append(model[word])\n", "        labels.append(word)\n", "    \n", "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n", "    new_values = tsne_model.fit_transform(tokens)\n", "\n", "    x = []\n", "    y = []\n", "    for value in new_values:\n", "        x.append(value[0])\n", "        y.append(value[1])\n", "        \n", "    plt.figure(figsize=(16, 16)) \n", "    for i in range(len(x)):\n", "        plt.scatter(x[i],y[i])\n", "        plt.annotate(labels[i],\n", "                     xy=(x[i], y[i]),\n", "                     xytext=(5, 2),\n", "                     textcoords='offset points',\n", "                     ha='right',\n", "                     va='bottom')\n", "    plt.show()"], "metadata": {"_cell_guid": "4512c76e-f4da-c793-be73-5b18b5bb70e9", "_uuid": "86fdd32e2780ad05e7c487eb8d8f7b5956a6e5fc", "collapsed": true}, "execution_count": null}, {"cell_type": "code", "outputs": [], "source": ["tsne_plot(model)"], "metadata": {"_cell_guid": "19ec33d2-5160-6556-c8da-a5a53316619a", "_uuid": "0d95120d425dab64bd612d96bfe806565fc3e332", "collapsed": true}, "execution_count": null}, {"cell_type": "code", "outputs": [], "source": ["# A more selective model\n", "model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=500, workers=4)\n", "tsne_plot(model)"], "metadata": {"_cell_guid": "b5ffb880-585d-6ea8-51a5-a6351ea2ff20", "_uuid": "d8a2dd5e15caf6279ba8e693acd4add1f5a1cbab", "collapsed": true}, "execution_count": null}, {"cell_type": "code", "outputs": [], "source": ["# A less selective model\n", "model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=100, workers=4)\n", "tsne_plot(model)"], "metadata": {"_cell_guid": "9f64e341-1967-617f-4004-ef7c6d109277", "_uuid": "e02d3b2895ce982be120f9352877e19741d4716e", "collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": ["# It's Becoming Hard to Read\n", "\n", "With a dataset this large, its difficult to make an easy-to-read TSNE visualization. What you can do is use the model to look up the most similar words from any given point. "], "metadata": {"_cell_guid": "2ba89a55-30b7-15ea-c571-9e402e1c03d2", "_uuid": "84f2710029e399b8fe56710e48ac5b84098d969e"}}, {"cell_type": "code", "outputs": [], "source": ["model.most_similar('trump')"], "metadata": {"_cell_guid": "109ae353-5679-6f7a-74f6-ae13d7042639", "_uuid": "bc731814739cc9f3922387cd51ab1f7b8961255d", "collapsed": true}, "execution_count": null}, {"cell_type": "code", "outputs": [], "source": ["model.most_similar('universe')"], "metadata": {"_cell_guid": "67a0844e-83d6-22ab-a89b-ae15c19860a8", "_uuid": "3e53277a9ee97327e12c375893a63852471b3a8a", "collapsed": true}, "execution_count": null}, {"cell_type": "markdown", "source": ["# The End\n", "\n", "Good luck!"], "metadata": {"_cell_guid": "a88070c7-87cd-0daa-61f7-b2d5ab1ca6ad", "_uuid": "a16278a58aa7edd5c00bf2084a2b39c30f42006a"}}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "mimetype": "text/x-python", "version": "3.6.4", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}, "_is_fork": false, "_change_revision": 0}, "nbformat": 4}