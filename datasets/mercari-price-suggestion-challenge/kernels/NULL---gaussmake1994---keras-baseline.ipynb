{"cells": [{"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["%matplotlib inline\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["dftrain = pd.read_csv('../input/train.tsv', delimiter='\\t')\n", "dftest = pd.read_csv('../input/test.tsv', delimiter='\\t')"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["dftrain.head()"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["len(dftrain)"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["def fillna(df):\n", "    df['category_name'] = df['category_name'].fillna('NaN')\n", "    df['brand_name'] = df['brand_name'].fillna('NaN')\n", "    df['item_description'] = df['item_description'].fillna('NaN')\n", "    return df\n", "\n", "dftrain = fillna(dftrain)\n", "dftest = fillna(dftest)"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["from sklearn.preprocessing import LabelEncoder"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["category_encoder = LabelEncoder().fit(list(dftrain['category_name']) + list(dftest['category_name']))\n", "dftrain['category_index'] = category_encoder.transform(dftrain['category_name'])\n", "dftest['category_index'] = category_encoder.transform(dftest['category_name'])"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["dftrain.head()"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["brand_encoder = LabelEncoder().fit(list(dftrain['brand_name']) + list(dftest['brand_name']))\n", "dftrain['brand_index'] = brand_encoder.transform(dftrain['brand_name'])\n", "dftest['brand_index'] = brand_encoder.transform(dftest['brand_name'])"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["dftrain.head()"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.preprocessing.text import Tokenizer"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["name_tokenizer = Tokenizer()\n", "name_tokenizer.fit_on_texts(dftrain['name'])"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["description_tokenizer = Tokenizer()\n", "description_tokenizer.fit_on_texts(dftrain['item_description'])"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["dftrain['seq_name'] = name_tokenizer.texts_to_sequences(dftrain['name'])\n", "dftest['seq_name'] = name_tokenizer.texts_to_sequences(dftest['name'])"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["dftrain['seq_description'] = name_tokenizer.texts_to_sequences(dftrain['item_description'])\n", "dftest['seq_description'] = name_tokenizer.texts_to_sequences(dftest['item_description'])"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["dftrain.head()"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["sum(map(len, dftrain['seq_name'])) / len(dftrain), max(map(len, dftrain['seq_name']))"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["sum(map(len, dftrain['seq_description'])) / len(dftrain), max(map(len, dftrain['seq_description']))"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["from keras.preprocessing.sequence import pad_sequences"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["def padded_sequences(values, maxlen):\n", "    padded = pad_sequences(np.array(values), maxlen=maxlen)\n", "    return [row for row in padded]"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["dftrain['seq_name_padded'] = padded_sequences(dftrain['seq_name'], 10)\n", "dftest['seq_name_padded'] = padded_sequences(dftest['seq_name'], 10)"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["dftrain['seq_description_padded'] = padded_sequences(dftrain['seq_description'], 40)\n", "dftest['seq_description_padded'] = padded_sequences(dftest['seq_description'], 40)"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["dftrain.head()"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["from keras import backend as K"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["def RMSLE(y_true, y_pred):\n", "    y_true_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.0)\n", "    y_pred_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.0)\n", "    return K.sqrt(K.mean(K.square(y_true_log - y_pred_log), \n", "                         axis=-1))\n", "\n", "def RMSE(y_true, y_pred):\n", "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) "], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["from keras.layers import Input, Embedding, LSTM, concatenate, Dropout, Dense, Flatten\n", "from keras.models import Model"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["len(name_tokenizer.word_index)"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["len(description_tokenizer.word_index)"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["len(category_encoder.classes_)"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["def build_model(name_input_length, description_input_length,\n", "                name_embedding_size, description_embedding_size, \n", "                brand_embedding_size, category_embedding_size, condition_embedding_size):\n", "    name_input = Input(shape=(name_input_length,), dtype='int32')\n", "    description_input = Input(shape=(description_input_length,), dtype='int32')\n", "    brand_input = Input(shape=(1,), dtype='int32')\n", "    category_input = Input(shape=(1,), dtype='int32')\n", "    condition_input = Input(shape=(1,), dtype='int32')\n", "    shipping_input = Input(shape=(1,), dtype='float32')\n", "    \n", "    name_embedding = Embedding(len(name_tokenizer.word_index) + 1, name_embedding_size)(name_input)\n", "    description_embedding = Embedding(len(description_tokenizer.word_index) + 1, description_embedding_size)(description_input)\n", "    brand_embedding = Embedding(len(brand_encoder.classes_) + 1, brand_embedding_size)(brand_input)\n", "    category_embedding = Embedding(len(category_encoder.classes_) + 1, category_embedding_size)(category_input)\n", "    condition_embedding = Embedding(len(set(dftrain['item_condition_id'])) + 1, condition_embedding_size)(condition_input)\n", "    \n", "    name_rnn = LSTM(8, activation='relu')(name_embedding)\n", "    description_rnn = LSTM(16, activation='relu')(description_embedding)\n", "    \n", "    concat = concatenate([\n", "        name_rnn,\n", "        description_rnn,\n", "        Flatten()(brand_embedding),\n", "        Flatten()(category_embedding),\n", "        Flatten()(condition_embedding),\n", "        shipping_input\n", "    ])\n", "    fc1 = Dropout(0.5)(Dense(128, activation='relu')(concat))\n", "    fc2 = Dropout(0.5)(Dense(64, activation='relu')(fc1))\n", "    fc3 = Dense(1, activation='linear')(fc2)\n", "    \n", "    model = Model([name_input, description_input, brand_input, category_input, condition_input, shipping_input],\n", "                  fc3)\n", "    model.compile(optimizer='rmsprop', loss='mean_squared_logarithmic_error', metrics=[RMSLE])\n", "    return model"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["model = build_model(name_input_length=10,\n", "                    description_input_length=40,\n", "                    name_embedding_size=50,\n", "                    description_embedding_size=50,\n", "                    brand_embedding_size=10,\n", "                    category_embedding_size=10,\n", "                    condition_embedding_size=5)"], "cell_type": "code"}, {"execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["model.summary()"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["X = [np.array([row for row in dftrain['seq_name_padded']]),\n", "     np.array([row for row in dftrain['seq_description_padded']]),\n", "     np.array(dftrain['brand_index']),\n", "     np.array(dftrain['category_index']),\n", "     np.array(dftrain['item_condition_id']),\n", "     np.array(dftrain['shipping']) * 1.0]\n", "y = np.array(dftrain[['price']]) + 1"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["from keras.callbacks import ModelCheckpoint, EarlyStopping"], "cell_type": "code"}, {"execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["model.fit(X, y, epochs=5, validation_split=0.1, batch_size=20000, callbacks=[\n", "    ModelCheckpoint('checkpoint.hdf5', save_best_only=True),\n", "    EarlyStopping(patience=5),\n", "])"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["model.fit(X, y, epochs=5, validation_split=0.1, batch_size=20000, callbacks=[\n", "    ModelCheckpoint('checkpoint.hdf5', save_best_only=True),\n", "    EarlyStopping(patience=5),\n", "])"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["model.fit(X, y, epochs=5, validation_split=0.1, batch_size=20000, callbacks=[\n", "    ModelCheckpoint('checkpoint.hdf5', save_best_only=True),\n", "    EarlyStopping(patience=5),\n", "])"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["model.fit(X, y, epochs=5, validation_split=0.1, batch_size=20000, callbacks=[\n", "    ModelCheckpoint('checkpoint.hdf5', save_best_only=True),\n", "    EarlyStopping(patience=5),\n", "])"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["model.load_weights('checkpoint.hdf5')"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["X = [np.array([row for row in dftest['seq_name_padded']]),\n", "     np.array([row for row in dftest['seq_description_padded']]),\n", "     np.array(dftest['brand_index']),\n", "     np.array(dftest['category_index']),\n", "     np.array(dftest['item_condition_id']),\n", "     np.array(dftest['shipping']) * 1.0]\n", "prediction = model.predict(X, verbose=True, batch_size=20000)[:, 0]"], "cell_type": "code"}, {"execution_count": null, "metadata": {}, "outputs": [], "source": ["from collections import OrderedDict\n", "\n", "df = pd.DataFrame(OrderedDict([\n", "    ('test_id', dftest['test_id']),\n", "    ('price', prediction)\n", "]))\n", "df.head()"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["df.to_csv('submission.csv', index=None)"], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": [], "cell_type": "code"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "version": "3.6.2", "nbconvert_exporter": "python"}}, "nbformat": 4, "nbformat_minor": 1}