{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7427ebee-e1ef-69d9-8716-4c3ab0d15471"
      },
      "source": [
        "## Shallow Benchmark ##\n",
        "\n",
        "in this script we will explore perhaps the most trivial benchmark one can think of:\n",
        "\n",
        "extraction of \"bag of words\"/\"bag of letter sequences\" features followed by a logistic regression classifier\n",
        "\n",
        "\n",
        "----------\n",
        "**Note:** due to runtime limitation in the kernels platform one cannot really run this script to get a reasonable LB score, so **you will have to run it locally on your computer** and change some of the script parameters in CountVectorizer:\n",
        "\n",
        " - max_features = 300000 \n",
        " - min_df = 50\n",
        " - ngram_range = (1,10)\n",
        "\n",
        "On my laptop, this script with the above parameters runs for a little less than an hour, and achieves a LB score of 0.31675"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4e10dc37-1221-e94d-dca7-2d5163ebda6f"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn import linear_model\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "matplotlib.style.use('fivethirtyeight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0b06a93e-de0a-f661-7dac-8291033a5c6e"
      },
      "source": [
        "Load data and show some samples of the data\n",
        "-------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "673cdfe0-18d1-affb-c98b-3a38175f3e37"
      },
      "outputs": [],
      "source": [
        "#%% load train data\n",
        "\n",
        "trainDF = pd.read_csv('../input/train.csv')\n",
        "trainDF = trainDF.dropna(how=\"any\").reset_index(drop=True)\n",
        "\n",
        "trainDF.ix[:7,3:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "628f8925-df02-f77a-30cb-8864dc88ed45"
      },
      "source": [
        "Create dictionary and extract Bag of Words features from each question\n",
        "----------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d1b57ff2-8de3-92be-e910-41b553ac9bcb"
      },
      "outputs": [],
      "source": [
        "#%% create dictionary and extract BOW features from questions\n",
        "\n",
        "featureExtractionStartTime = time.time()\n",
        "\n",
        "maxNumFeatures = 300\n",
        "\n",
        "# bag of letter sequences (chars)\n",
        "BagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=1000, max_features=maxNumFeatures, \n",
        "                                      analyzer='char', ngram_range=(1,2), \n",
        "                                      binary=True, lowercase=True)\n",
        "# bag of words\n",
        "#BagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=10, max_features=maxNumFeatures, \n",
        "#                                      analyzer='word', ngram_range=(1,6), stop_words='english', \n",
        "#                                      binary=True, lowercase=True)\n",
        "\n",
        "BagOfWordsExtractor.fit(pd.concat((trainDF.ix[:,'question1'],trainDF.ix[:,'question2'])).unique())\n",
        "\n",
        "trainQuestion1_BOW_rep = BagOfWordsExtractor.transform(trainDF.ix[:,'question1'])\n",
        "trainQuestion2_BOW_rep = BagOfWordsExtractor.transform(trainDF.ix[:,'question2'])\n",
        "lables = np.array(trainDF.ix[:,'is_duplicate'])\n",
        "\n",
        "featureExtractionDurationInMinutes = (time.time()-featureExtractionStartTime)/60.0\n",
        "print(\"feature extraction took %.2f minutes\" % (featureExtractionDurationInMinutes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "73804e3a-8822-af41-cb8a-2430bae34a01"
      },
      "source": [
        "Cross Validation\n",
        "----------------\n",
        "\n",
        "combine the word representation to a single feature vector and run cross validation with logistic regression classifier\n",
        "\n",
        "**The first version of a possible feature is:**\n",
        "\n",
        " - take the value  \" 0\" if the particular letter sequence is either present or not present in both questions\n",
        " - take the value  \"-1\" if the particular letter sequence is present in one question but not the other question\n",
        "\n",
        "\n",
        "**The second version of a possible feature is:**\n",
        "\n",
        " - take the value  \" 1\" if the particular letter sequence is present in both questions\n",
        " - take the value  \" 0\" if the particular letter sequence is not present in any question\n",
        " - take the value \"-1\" if the particular letter sequence is present in one question but not the other question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "152b4460-aaa0-6021-70a3-c7968ef60ea7"
      },
      "outputs": [],
      "source": [
        "0#%% prefrom cross validation\n",
        "\n",
        "crossValidationStartTime = time.time()\n",
        "\n",
        "numCVSplits = 8\n",
        "numSplitsToBreakAfter = 2\n",
        "\n",
        "X = -(trainQuestion1_BOW_rep != trainQuestion2_BOW_rep).astype(int)\n",
        "#X = -(trainQuestion1_BOW_rep != trainQuestion2_BOW_rep).astype(int) + \\\n",
        "#      trainQuestion1_BOW_rep.multiply(trainQuestion2_BOW_rep)\n",
        "y = lables\n",
        "\n",
        "logisticRegressor = linear_model.LogisticRegression(C=0.1, solver='sag')\n",
        "\n",
        "logRegAccuracy = []\n",
        "logRegLogLoss = []\n",
        "logRegAUC = []\n",
        "\n",
        "print('---------------------------------------------')\n",
        "stratifiedCV = model_selection.StratifiedKFold(n_splits=numCVSplits, random_state=2)\n",
        "for k, (trainInds, validInds) in enumerate(stratifiedCV.split(X, y)):\n",
        "    foldTrainingStartTime = time.time()\n",
        "\n",
        "    X_train_cv = X[trainInds,:]\n",
        "    X_valid_cv = X[validInds,:]\n",
        "\n",
        "    y_train_cv = y[trainInds]\n",
        "    y_valid_cv = y[validInds]\n",
        "\n",
        "    logisticRegressor.fit(X_train_cv, y_train_cv)\n",
        "\n",
        "    y_train_hat =  logisticRegressor.predict_proba(X_train_cv)[:,1]\n",
        "    y_valid_hat =  logisticRegressor.predict_proba(X_valid_cv)[:,1]\n",
        "\n",
        "    logRegAccuracy.append(accuracy_score(y_valid_cv, y_valid_hat > 0.5))\n",
        "    logRegLogLoss.append(log_loss(y_valid_cv, y_valid_hat))\n",
        "    logRegAUC.append(roc_auc_score(y_valid_cv, y_valid_hat))\n",
        "    \n",
        "    foldTrainingDurationInMinutes = (time.time()-foldTrainingStartTime)/60.0\n",
        "    print('fold %d took %.2f minutes: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (k+1,\n",
        "             foldTrainingDurationInMinutes, logRegAccuracy[-1],logRegLogLoss[-1],logRegAUC[-1]))\n",
        "\n",
        "    if (k+1) >= numSplitsToBreakAfter:\n",
        "        break\n",
        "\n",
        "\n",
        "crossValidationDurationInMinutes = (time.time()-crossValidationStartTime)/60.0\n",
        "\n",
        "print('---------------------------------------------')\n",
        "print('cross validation took %.2f minutes' % (crossValidationDurationInMinutes))\n",
        "print('mean CV: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (np.array(logRegAccuracy).mean(),\n",
        "                                                                 np.array(logRegLogLoss).mean(),\n",
        "                                                                 np.array(logRegAUC).mean()))\n",
        "print('---------------------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6065b41d-555b-2748-2f1b-8ff8c9d91941"
      },
      "source": [
        "Show predictions and \"feature importance\"\n",
        "----------------------------------------\n",
        "\n",
        "Show prediction distribution on the validation set vs the ground truth \n",
        "\n",
        "Show the letter sequences that correspond to the largest positive coefficients and the largest negative (in absolute value) coefficients of the logistic regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5c8152fc-972f-29d9-9393-69e51c5c2741"
      },
      "outputs": [],
      "source": [
        "9#%% show prediction distribution and \"feature importance\"\n",
        "\n",
        "matplotlib.rcParams['font.size'] = 14\n",
        "matplotlib.rcParams['figure.figsize'] = (10,10)\n",
        "\n",
        "plt.figure(); \n",
        "sns.kdeplot(y_valid_hat[y_valid_cv==0], shade=True, color=\"b\", bw=0.01)\n",
        "sns.kdeplot(y_valid_hat[y_valid_cv==1], shade=True, color=\"g\", bw=0.01)\n",
        "plt.legend(['non duplicate','duplicate'],fontsize=24)\n",
        "plt.title('Validation Accuracy = %.3f, Log Loss = %.4f, AUC = %.3f' %(logRegAccuracy[-1],\n",
        "                                                                      logRegLogLoss[-1],\n",
        "                                                                      logRegAUC[-1]))\n",
        "plt.xlabel('Prediction'); plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\n",
        "\n",
        "\n",
        "numFeaturesToShow = 30\n",
        "\n",
        "sortedCoeffients = np.sort(logisticRegressor.coef_)[0]\n",
        "featureNames = BagOfWordsExtractor.get_feature_names()\n",
        "sortedFeatureNames = [featureNames[x] for x in list(np.argsort(logisticRegressor.coef_)[0])]\n",
        "\n",
        "matplotlib.rcParams['font.size'] = 14\n",
        "matplotlib.rcParams['figure.figsize'] = (10,12)\n",
        "\n",
        "plt.figure()\n",
        "plt.suptitle('Feature Importance',fontsize=24)\n",
        "ax = plt.subplot(1,2,1); plt.title('top non duplicate predictors'); \n",
        "plt.xlabel('minus logistic regression coefficient')\n",
        "ax.barh(range(numFeaturesToShow), -sortedCoeffients[:numFeaturesToShow][::-1], align='center'); \n",
        "plt.ylim(-1,numFeaturesToShow); ax.set_yticks(range(numFeaturesToShow)); \n",
        "ax.set_yticklabels(sortedFeatureNames[:numFeaturesToShow][::-1],fontsize=20)\n",
        "\n",
        "ax = plt.subplot(1,2,2); plt.title('top duplicate predictors'); \n",
        "plt.xlabel('logistic regression coefficient')\n",
        "ax.barh(range(numFeaturesToShow), sortedCoeffients[-numFeaturesToShow:], align='center'); \n",
        "plt.ylim(-1,numFeaturesToShow); ax.set_yticks(range(numFeaturesToShow)); \n",
        "ax.set_yticklabels(sortedFeatureNames[-numFeaturesToShow:],fontsize=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "23bc169f-f1f6-6935-ee19-a1f3fd74c7af"
      },
      "source": [
        "Train on the full training data\n",
        "-------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3fcca600-6314-88f9-217f-0a73b7ce3afd"
      },
      "outputs": [],
      "source": [
        "#%% train on full training data\n",
        "\n",
        "trainingStartTime = time.time()\n",
        "\n",
        "logisticRegressor = linear_model.LogisticRegression(C=0.1, solver='sag', \n",
        "                                                    class_weight={1: 0.46, 0: 1.32})\n",
        "logisticRegressor.fit(X, y)\n",
        "\n",
        "trainingDurationInMinutes = (time.time()-trainingStartTime)/60.0\n",
        "print('full training took %.2f minutes' % (trainingDurationInMinutes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "51575bb5-e7e3-6d31-bdbb-02e3b88beb45"
      },
      "source": [
        "Extract features and make predictions on the test data\n",
        "------------------------------------------------------\n",
        "\n",
        "show the distribution of the validation predictions and the test predictions to make sure that the distributions are in fact different due to changing of the \"class weight\" argument in the logistic regression class definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cd409e0f-1819-e4ae-04fa-ade2aac87ca6"
      },
      "outputs": [],
      "source": [
        "0#%% load test data, extract features and make predictions\n",
        "\n",
        "testPredictionStartTime = time.time()\n",
        "\n",
        "testDF = pd.read_csv('../input/test.csv')\n",
        "testDF.ix[testDF['question1'].isnull(),['question1','question2']] = 'random empty question'\n",
        "testDF.ix[testDF['question2'].isnull(),['question1','question2']] = 'random empty question'\n",
        "\n",
        "testQuestion1_BOW_rep = BagOfWordsExtractor.transform(testDF.ix[:,'question1'])\n",
        "testQuestion2_BOW_rep = BagOfWordsExtractor.transform(testDF.ix[:,'question2'])\n",
        "\n",
        "X_test = -(testQuestion1_BOW_rep != testQuestion2_BOW_rep).astype(int)\n",
        "#X_test = -(testQuestion1_BOW_rep != testQuestion2_BOW_rep).astype(int) + \\\n",
        "#           testQuestion1_BOW_rep.multiply(testQuestion2_BOW_rep)\n",
        "\n",
        "#testPredictions = logisticRegressor.predict_proba(X_test)[:,1]\n",
        "\n",
        "# quick fix to avoid memory errors\n",
        "seperators= [750000,1500000]\n",
        "testPredictions1 = logisticRegressor.predict_proba(X_test[:seperators[0],:])[:,1]\n",
        "testPredictions2 = logisticRegressor.predict_proba(X_test[seperators[0]:seperators[1],:])[:,1]\n",
        "testPredictions3 = logisticRegressor.predict_proba(X_test[seperators[1]:,:])[:,1]\n",
        "testPredictions = np.hstack((testPredictions1,testPredictions2,testPredictions3))\n",
        "\n",
        "matplotlib.rcParams['font.size'] = 14\n",
        "matplotlib.rcParams['figure.figsize'] = (9,9)\n",
        "\n",
        "plt.figure(); \n",
        "plt.subplot(2,1,1); sns.kdeplot(y_valid_hat, shade=True, color=\"b\", bw=0.01); \n",
        "plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\n",
        "plt.title('mean valid prediction = ' + str(np.mean(y_valid_hat)))\n",
        "plt.subplot(2,1,2); sns.kdeplot(testPredictions, shade=True, color=\"b\", bw=0.01);\n",
        "plt.xlabel('Prediction'); plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\n",
        "plt.title('mean test prediction = ' + str(np.mean(testPredictions)))\n",
        "\n",
        "testPredictionDurationInMinutes = (time.time()-testPredictionStartTime)/60.0\n",
        "print('predicting on test took %.2f minutes' % (testPredictionDurationInMinutes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "20dd38fc-dbf3-cfa9-234f-cac33bbbdf5a"
      },
      "source": [
        "Create a Submission\n",
        "-------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1d7eb295-d4db-d7e7-1f1f-56016e33e960"
      },
      "outputs": [],
      "source": [
        "#%% create a submission\n",
        "\n",
        "submissionName = 'shallowBenchmark'\n",
        "\n",
        "submission = pd.DataFrame()\n",
        "submission['test_id'] = testDF['test_id']\n",
        "submission['is_duplicate'] = testPredictions\n",
        "submission.to_csv(submissionName + '.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}