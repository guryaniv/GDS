{"cells":[{"metadata":{"_uuid":"1c592418a9ebedbf2d6aadfc819d0c18aa9bc7f2"},"cell_type":"markdown","source":"# PUBG predictions with Gradient Boost\n\nI previously created a notebook going through some [exploratory anaylsys] of the PUBG data. I went through many of the different features avalailable and displayed an interesting plot describing the data and potential correlation with the target variable.\n\n* I found that there was one missing value for the target variable and decided that this row of data should be removed, as there was only one player for the match identified by the missing value.\n\n* I also made a few decisions about creating new features and one important way of breaking the data up to gain higher correllations with our features for seperate match types.\n\n## Why Gradient Boost?\nI've created a [kernel] that runs through a number of models to deteremine which model would be best. I've decided to create predictions for a few of the models that had a reasonable accuracy. This Kernel runs the same feature engineering and scaling before fitting the data to the training data and making predictions for the testing data. The Gradient Boost Regression model was the best, with a 92.86% on the validation data (30% of the testing data).\n\n[exploratory anaylsys]: https://www.kaggle.com/beaubellamy/pubg-eda#\n[kernel]: https://www.kaggle.com/beaubellamy/pubg-predictions"},{"metadata":{"_uuid":"363226b9fe854d7a825a17e6c2eca55ff5c756c7"},"cell_type":"markdown","source":"## Import libraries\nWe import the required libraries and import the data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nsns.set()\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train_V2.csv')\ntest = pd.read_csv('../input/test_V2.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc90a34196fbffc09ef9a9f14cc99c1abb275b5d"},"cell_type":"markdown","source":"Lets check out the data again."},{"metadata":{"trusted":true,"_uuid":"59fee04c6a6a4285dfc6b54e3c6e18ff71768a93"},"cell_type":"code","source":"\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d23e88ceebc824b4d7686fe98dc5c23e6c1bbdf5"},"cell_type":"markdown","source":"## Missing Data\nBased on our EDA, we found a row that had a NULL value for the target variable. We will remove the irrelevant row of data."},{"metadata":{"trusted":true,"_uuid":"90cf3cfbb4f386335af97e836b7e442f940bc9cc"},"cell_type":"code","source":"# Remove the row with the missing target value\ntrain = train[train['winPlacePerc'].isna() != True]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"627ead1a30264239d56af16da9b08925fde68501"},"cell_type":"markdown","source":"## Lets Engineer some features\nWe'll process the testing data the same way we do for the training data so the testing data has the same features and scaling as our training data.\n\n\n### PlayersJoined\nWe can determine the number of players that joined each match by grouping the data by matchID and counting the players."},{"metadata":{"trusted":true,"_uuid":"db2303527c8ecb0a4fca2b3a430c4295ca7c1796"},"cell_type":"code","source":"# Add a feature containing the number of players that joined each match.\ntrain['playersJoined'] = train.groupby('matchId')['matchId'].transform('count')\ntest['playersJoined'] = test.groupby('matchId')['matchId'].transform('count')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e8844d03bdcd8cf022e3f4e2a25861f45679c54"},"cell_type":"code","source":"# Lets look at only those matches with more than 50 players.\ndata = train[train['playersJoined'] > 50]\n\nplt.figure(figsize=(15,15))\nsns.countplot(data['playersJoined'].sort_values())\nplt.title('Number of players joined',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3eae047591d0e6db4f2467bbb3283d47db19fec"},"cell_type":"markdown","source":"You can see that there isn't always 100 players in each match, in fact its more likely to have between 90 and 100 players. It may be benficial to normalise those features that are affected by the number of players.\n\n### Normalised Features\nHere, I am making the assumption that it is easier to find an enemy when there are 100 players, than it is when there are 90 players.\n"},{"metadata":{"trusted":true,"_uuid":"9c25114718a07ecf171f6bbdb3f8c74e966f399b"},"cell_type":"code","source":"def normaliseFeatures(train):\n    train['killsNorm'] = train['kills']*((100-train['playersJoined'])/100 + 1)\n    train['headshotKillsNorm'] = train['headshotKills']*((100-train['playersJoined'])/100 + 1)\n    train['killPlaceNorm'] = train['killPlace']*((100-train['playersJoined'])/100 + 1)\n    train['killPointsNorm'] = train['killPoints']*((100-train['playersJoined'])/100 + 1)\n    train['killStreaksNorm'] = train['killStreaks']*((100-train['playersJoined'])/100 + 1)\n    train['longestKillNorm'] = train['longestKill']*((100-train['playersJoined'])/100 + 1)\n    train['roadKillsNorm'] = train['roadKills']*((100-train['playersJoined'])/100 + 1)\n    train['teamKillsNorm'] = train['teamKills']*((100-train['playersJoined'])/100 + 1)\n    train['damageDealtNorm'] = train['damageDealt']*((100-train['playersJoined'])/100 + 1)\n    train['DBNOsNorm'] = train['DBNOs']*((100-train['playersJoined'])/100 + 1)\n    train['revivesNorm'] = train['revives']*((100-train['playersJoined'])/100 + 1)\n\n    # Remove the original features we normalised\n    train = train.drop(['kills', 'headshotKills', 'killPlace', 'killPoints', 'killStreaks', \n                        'longestKill', 'roadKills', 'teamKills', 'damageDealt', 'DBNOs', 'revives'],axis=1)\n\n    return train\n\ntrain = normaliseFeatures(train)\ntest = normaliseFeatures(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5996305e8c7a615bde60829be74c19c82bbb713"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"565787b793b989b5d51e67326f9df0f99387569e"},"cell_type":"markdown","source":"### TotalDistance\nAn additional feature we can create is the total distance the player travels. This is a combination of all the distance features in the original data set."},{"metadata":{"trusted":true,"_uuid":"7c9cb57049be6172d5c6bd1f7403041824efd7c0"},"cell_type":"code","source":"# Total distance travelled\ntrain['totalDistance'] = train['walkDistance'] + train['rideDistance'] + train['swimDistance']\ntest['totalDistance'] = test['walkDistance'] + test['rideDistance'] + test['swimDistance']\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b37809c8ec4d04e57898b3ada407006e63d4181"},"cell_type":"markdown","source":"# Standardize the matchType feature\nHere I decided that many of the existing 16 seperate modes of game play were just different versions of four types of game.\n\n1. Solo: Hunger Games style, last man/women standing.\n2. Duo: Teams of two against all other players.\n3. Squad: Teams of up to 4 players against All other players\n4. Other: These modes consist of custom and special events modes"},{"metadata":{"trusted":true,"_uuid":"94e0117b066266679ee5643b6b4161797e5f3c4c"},"cell_type":"code","source":"# Normalise the matchTypes to standard fromat\ndef standardize_matchType(data):\n    data['matchType'][data['matchType'] == 'normal-solo'] = 'Solo'\n    data['matchType'][data['matchType'] == 'solo'] = 'Solo'\n    data['matchType'][data['matchType'] == 'solo-fpp'] = 'Solo'\n    data['matchType'][data['matchType'] == 'normal-solo-fpp'] = 'Solo'\n    data['matchType'][data['matchType'] == 'normal-duo-fpp'] = 'Duo'\n    data['matchType'][data['matchType'] == 'duo'] = 'Duo'\n    data['matchType'][data['matchType'] == 'normal-duo'] = 'Duo'\n    data['matchType'][data['matchType'] == 'duo-fpp'] = 'Duo'\n    data['matchType'][data['matchType'] == 'squad'] = 'Squad'\n    data['matchType'][data['matchType'] == 'squad-fpp'] = 'Squad'\n    data['matchType'][data['matchType'] == 'normal-squad'] = 'Squad'\n    data['matchType'][data['matchType'] == 'normal-squad-fpp'] = 'Squad'\n    data['matchType'][data['matchType'] == 'flaretpp'] = 'Other'\n    data['matchType'][data['matchType'] == 'flarefpp'] = 'Other'\n    data['matchType'][data['matchType'] == 'crashtpp'] = 'Other'\n    data['matchType'][data['matchType'] == 'crashfpp'] = 'Other'\n\n    return data\n\n\ntrain = standardize_matchType(train)\ntest = standardize_matchType(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62a6f6b2eeb8c34b70843a5df7d015d85b02a972"},"cell_type":"code","source":"train = train.drop(['Id','groupId','matchId'], axis=1)\n# Save the Ids for the submission later on\ntest_ids = test['Id']\ntest = test.drop(['Id','groupId','matchId'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"980e01433dbefcb4bd3269669465b3e6c2bccdd5"},"cell_type":"markdown","source":"Now we can transform the matchTypes into dummy values so we can use them in the model."},{"metadata":{"trusted":true,"_uuid":"780310f7f4fc97455589c6a7a915c84ebbaaa08c"},"cell_type":"code","source":"# Transform the matchType into scalar values\nle = LabelEncoder()\ntrain['matchType']=le.fit_transform(train['matchType'])\ntest['matchType']=le.fit_transform(test['matchType'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db727750a32ed96e38a0602b85db869a0700e0b9"},"cell_type":"code","source":"# We can do a sanity check of the data, making sure we have the new \n# features created and the matchType feature is standardised.\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aba7e56a98c08f6bfc58f45beb13397c576b22c0"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0c82acaa8fecd6b2089ceadf724b4e3c32b7c54"},"cell_type":"markdown","source":"# Scale the features\nSome of the features have large variances, so in order to make sure they dont over influence the training or predictions. We can scale all our features so they provide the same influence over the model."},{"metadata":{"trusted":true,"_uuid":"5d710a638a6cd63130dac34e83c0ebb1102ba0d0"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3202fe27a7d22b7d011068f5b35e3df95645b93f"},"cell_type":"markdown","source":"You can see most features range 0 to 100 or 1000's, but there are two features that doesn't really need scaling, VehicleDestroys and matchType, as they only range between 0 to 5, 6. Its not neccassary to scale these features, but we will any way, because it makes the code easier."},{"metadata":{"trusted":true,"_uuid":"e3478558c107dca6fdc27eb820b5a1b5bdf069e4"},"cell_type":"code","source":"scaler = MinMaxScaler()\ntrain_scaled = pd.DataFrame(scaler.fit_transform(train), columns=train.columns)\ntest_scaled = pd.DataFrame(scaler.fit_transform(test), columns=test.columns)\n\ntrain_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc93d5c7f80a56b1c57ab37d2a94d96c1ba35f69"},"cell_type":"code","source":"train_scaled.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c68dd021ddefb7c8c99a5b4c5f90ba78fc5c2d6"},"cell_type":"markdown","source":"# Model Development\nWe'll first validate the model by keeping a small part of the data to validate the results.\n"},{"metadata":{"trusted":true,"_uuid":"7a3ec1477e97d5df286c689095361def4e2bbf2f"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ccb87c50874baa40f2c2d264e8d9fbc85138cdd2"},"cell_type":"markdown","source":"We need to extract the target variable and split the data up into a training and validation set."},{"metadata":{"trusted":true,"_uuid":"269ecd54461d174e664fb9bde9723b4204fc9357"},"cell_type":"code","source":"# Train Test Split\ny = train_scaled['winPlacePerc']\nX = train_scaled.drop(['winPlacePerc'],axis=1)\nsize = 0.30\nseed = 42\n\nX_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=size, random_state=seed)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3fe5cd35b8902c4a16d3315ceeea42b9f486e160"},"cell_type":"markdown","source":"## Gradient Boost Regressor\n"},{"metadata":{"trusted":true,"_uuid":"99154fa564777c9dd010849b49cfee7a9c475a30"},"cell_type":"code","source":"GBR = GradientBoostingRegressor(learning_rate=0.8)\nGBR.fit(X,y)\n\npredictions = GBR.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f538eb1c23ba9f73abc6a2e94a8f5368d32fef8"},"cell_type":"markdown","source":"Before we make the submission of our predictions, we need to make sure they are consistent with the boundaries of the target variable. The target variable \"winPlacePerc\" is a number between 0 and 1, so anything outside that will contribute to incorrect predictions.\n\nHere we'll force these values back down to the boundaries."},{"metadata":{"trusted":true,"_uuid":"9f91b4f89ad20ebc7d638a21612ce434ab0a0780"},"cell_type":"code","source":"predictions[predictions > 1] = 1\npredictions[predictions < 0] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1fd1c9071148f3377ae25565740df0ecac58ee0"},"cell_type":"code","source":"submission = pd.DataFrame({'Id': test_ids, 'winPlacePerc': predictions})\nsubmission.to_csv('submission_GBR.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a908e8f3df4b0a4d240edcdcd6cbab10a5a8b9d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}