{"cells":[{"metadata":{"_uuid":"df4ba5bc621979ac372d9d99acfa7651c4ac5a87"},"cell_type":"markdown","source":"**Extra Tree Classification Baseline Kernel**\n\nThis kernel is a simple exercise in using basic techniques in machine learning. It is meant as a jumping off point to develop more complex and better models to increase your LB score."},{"metadata":{"_uuid":"1586ae6fd0602f62602a10f65854d575fabaf44d"},"cell_type":"markdown","source":"**Load Data and Develop Features**\n\nThere are many kernels that do EDA so I won't get into that here. So, let's just develop some new features. We will have a few similar to those developed in other kernels plus some newer ones. \n\nSince we don't know if points are in the same direction or in opposite directions or even right angles to each other we can just generate a few combinations via adding and subtracting some fo the values. We can also expand on the shadiness as well, whether or not that makes much difference. I will not add any soil features though other kernels have some success with combining soil features."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV\nfrom sklearn.feature_selection import RFECV\n\nfrom scipy import stats\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\n# set up dataset\nnumber_classes = 7\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\n\nknown = train_df['Cover_Type']\ntrain_df = train_df.drop(['Cover_Type','Id'],axis=1)\n\nId_test = test_df['Id']\ntest_df = test_df.drop(['Id'],axis=1)\n\n####################### Test data #############################################\ntrain_df['HF1'] = train_df['Horizontal_Distance_To_Hydrology']+train_df['Horizontal_Distance_To_Fire_Points']\ntrain_df['HF2'] = (train_df['Horizontal_Distance_To_Hydrology']-train_df['Horizontal_Distance_To_Fire_Points'])\ntrain_df['HR1'] = (train_df['Horizontal_Distance_To_Hydrology']+train_df['Horizontal_Distance_To_Roadways'])\ntrain_df['HR2'] = (train_df['Horizontal_Distance_To_Hydrology']-train_df['Horizontal_Distance_To_Roadways'])\ntrain_df['FR1'] = (train_df['Horizontal_Distance_To_Fire_Points']+train_df['Horizontal_Distance_To_Roadways'])\ntrain_df['FR2'] = (train_df['Horizontal_Distance_To_Fire_Points']-train_df['Horizontal_Distance_To_Roadways'])\ntrain_df['EV1'] = train_df.Elevation+train_df.Vertical_Distance_To_Hydrology\ntrain_df['EV2'] = train_df.Elevation-train_df.Vertical_Distance_To_Hydrology\ntrain_df['Mean_HF1'] = train_df.HF1/2\ntrain_df['Mean_HF2'] = train_df.HF2/2\ntrain_df['Mean_HR1'] = train_df.HR1/2\ntrain_df['Mean_HR2'] = train_df.HR2/2\ntrain_df['Mean_FR1'] = train_df.FR1/2\ntrain_df['Mean_FR2'] = train_df.FR2/2\n\ntrain_df['slope_hyd'] = (train_df['Horizontal_Distance_To_Hydrology']**2+train_df['Vertical_Distance_To_Hydrology']**2)**0.5\ntrain_df.slope_hyd=train_df.slope_hyd.map(lambda x: 0 if np.isinf(x) else x) # remove infinite value if any\n\n#Mean distance to Amenities \ntrain_df['Mean_Amenities']=(train_df.Horizontal_Distance_To_Fire_Points + train_df.Horizontal_Distance_To_Hydrology + train_df.Horizontal_Distance_To_Roadways) / 3 \n#Mean Distance to Fire and Water \ntrain_df['Mean_Fire_Hyd1']=(train_df.Horizontal_Distance_To_Fire_Points + train_df.Horizontal_Distance_To_Hydrology) / 2\ntrain_df['Mean_Fire_Hyd2']=(train_df.Horizontal_Distance_To_Fire_Points - train_df.Horizontal_Distance_To_Hydrology) / 2\n\n#Shadiness\ntrain_df['Shadiness_morn_noon'] = train_df.Hillshade_9am/(train_df.Hillshade_Noon+1)\ntrain_df['Shadiness_noon_3pm'] = train_df.Hillshade_Noon/(train_df.Hillshade_3pm+1)\ntrain_df['Shadiness_morn_3'] = train_df.Hillshade_9am/(train_df.Hillshade_3pm+1)\ntrain_df['Shadiness_morn_avg'] = (train_df.Hillshade_9am+train_df.Hillshade_Noon)/2\ntrain_df['Shadiness_afernoon'] = (train_df.Hillshade_Noon+train_df.Hillshade_3pm)/2\ntrain_df['Shadiness_total_mean'] = (train_df.Hillshade_9am+train_df.Hillshade_Noon+train_df.Hillshade_3pm)/3\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"524d19b59da032478c7c421bcd34b1cf97601e61"},"cell_type":"markdown","source":"Apply the same features to the test data as well."},{"metadata":{"trusted":true,"_uuid":"e2e2d4dca50786948023ef0970c3478c35f67cb5"},"cell_type":"code","source":"test_df['HF1'] = test_df['Horizontal_Distance_To_Hydrology']+test_df['Horizontal_Distance_To_Fire_Points']\ntest_df['HF2'] = (test_df['Horizontal_Distance_To_Hydrology']-test_df['Horizontal_Distance_To_Fire_Points'])\ntest_df['HR1'] = (test_df['Horizontal_Distance_To_Hydrology']+test_df['Horizontal_Distance_To_Roadways'])\ntest_df['HR2'] = (test_df['Horizontal_Distance_To_Hydrology']-test_df['Horizontal_Distance_To_Roadways'])\ntest_df['FR1'] = (test_df['Horizontal_Distance_To_Fire_Points']+test_df['Horizontal_Distance_To_Roadways'])\ntest_df['FR2'] = (test_df['Horizontal_Distance_To_Fire_Points']-test_df['Horizontal_Distance_To_Roadways'])\ntest_df['EV1'] = test_df.Elevation+test_df.Vertical_Distance_To_Hydrology\ntest_df['EV2'] = test_df.Elevation-test_df.Vertical_Distance_To_Hydrology\ntest_df['Mean_HF1'] = test_df.HF1/2\ntest_df['Mean_HF2'] = test_df.HF2/2\ntest_df['Mean_HR1'] = test_df.HR1/2\ntest_df['Mean_HR2'] = test_df.HR2/2\ntest_df['Mean_FR1'] = test_df.FR1/2\ntest_df['Mean_FR2'] = test_df.FR2/2\n\ntest_df['slope_hyd'] = (test_df['Horizontal_Distance_To_Hydrology']**2+test_df['Vertical_Distance_To_Hydrology']**2)**0.5\ntest_df.slope_hyd=test_df.slope_hyd.map(lambda x: 0 if np.isinf(x) else x) # remove infinite value if any\n\n#Mean distance to Amenities \ntest_df['Mean_Amenities']=(test_df.Horizontal_Distance_To_Fire_Points + test_df.Horizontal_Distance_To_Hydrology + test_df.Horizontal_Distance_To_Roadways) / 3 \n#Mean Distance to Fire and Water \ntest_df['Mean_Fire_Hyd1']=(test_df.Horizontal_Distance_To_Fire_Points + test_df.Horizontal_Distance_To_Hydrology) / 2\ntest_df['Mean_Fire_Hyd2']=(test_df.Horizontal_Distance_To_Fire_Points + test_df.Horizontal_Distance_To_Hydrology) / 2\n\n#Shadiness\ntest_df['Shadiness_morn_noon'] = test_df.Hillshade_9am/(test_df.Hillshade_Noon+1)\ntest_df['Shadiness_noon_3pm'] = test_df.Hillshade_Noon/(test_df.Hillshade_3pm+1)\ntest_df['Shadiness_morn_3'] = test_df.Hillshade_9am/(test_df.Hillshade_3pm+1)\ntest_df['Shadiness_morn_avg'] = (test_df.Hillshade_9am+test_df.Hillshade_Noon)/2\ntest_df['Shadiness_afernoon'] = (test_df.Hillshade_Noon+test_df.Hillshade_3pm)/2\ntest_df['Shadiness_total_mean'] = (test_df.Hillshade_9am+test_df.Hillshade_Noon+test_df.Hillshade_3pm)/3\n\nprint('Total number of features : %d' % (train_df.shape)[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a9557f355d2636be74af0a7a15fb9ce135f462b"},"cell_type":"markdown","source":"**Feature Selection**\n\nThe let's do feature selection. I haven't gone through features to check correlation or checked for other things like that. We could try things like PCA but I think that is over kill and would require scaling. Therefore, I will use Recursive Feature Extraction with Cross-Validation (RFECV) using an ExtraTree Classifier estimator. You can play with this and it likely can be improveed but it is a start. RFECV will get rid of low variance features as well which is a bonus. (So soil7 and soil15 for example). This takes a bit to run so don't worry if it takes 10 minutes."},{"metadata":{"trusted":true,"_uuid":"b15452de543775b8dc55f28cd1305d3c3d07202a"},"cell_type":"code","source":"selector = RFECV(estimator=ExtraTreesClassifier(n_estimators=200, criterion='entropy', min_samples_split=3, n_jobs=-1),step=1, cv=5)\nselector = selector.fit(train_df,known)\nprint('Optimal number of features : %d' % selector.n_features_)\nX_train = selector.transform(train_df)\nX_test = selector.transform(test_df)\n#print(train_df.columns[selector.support_].values) #Uncomment if you want to see what features were selected","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97e42b8b6cd45fd53e60397f8bf10b18e3a95b18"},"cell_type":"markdown","source":"**Run ExtraTree Model**\n\nGreat - now we have the best features to use. The first thing we should do is set up a k-fold to iterate over when developing the models. So, let's use a stratified k-fold. I use stratified here to keep the training groups with approximately the same groupings of cover. I used 9 folds but you could experiment with that if you like.\n\nYou will notice that at the end of the for loop, I create a prediction on the test data for each model. This generates 'k' sets of data that I can use for some basic ensembling on the test data."},{"metadata":{"trusted":true,"_uuid":"d4870f200f9cd15cfeebe0a7cf333d002c81b133"},"cell_type":"code","source":"strat_kfold = StratifiedKFold(n_splits=5)\np_corr = []\ny_true = []\npred_ens = []\n\nfor train_index, cv_index in strat_kfold.split(X_train, known):\n\n    Xtrain, X_cv = (np.array(X_train))[train_index], (np.array(X_train))[cv_index]\n    Ytrain, y_cv = (np.array(known))[train_index], (np.array(known))[cv_index]\n    \n    etr = ExtraTreesClassifier(n_estimators=700, criterion='entropy', min_samples_split=3, n_jobs=-1)\n    trained_model = etr.fit(Xtrain, Ytrain)\n    \n    pred_te = (trained_model.predict(X_cv))    \n    \n    y_true = np.hstack((y_true,y_cv))\n    pred_ens = np.hstack((pred_ens,pred_te))\n   \n    predictions = (trained_model.predict(np.array(X_test)))     \n    p_corr.append(predictions)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ba67ba7a5792a60a6edd279abd31def02c6dfa9"},"cell_type":"markdown","source":"**Results**\n\nSo, how did our models work out? Let's look at the confusion matrix. You can see we do a good job of predicting everything in general. The accuracy shows a reasonable value that turns out close to the LB score, so we know we aren't over fitting anything horribly.\n\nOne thing to note is that cover 1 and cover 2 are often \"confused\" - most of the errors in cover 1 are confused for cover 2 and vice versa. That means, to really improve the predictions, we need to address this issue."},{"metadata":{"trusted":true,"_uuid":"af0c17cab4a7dfc82fbaf32490ccf684f1a16cbb"},"cell_type":"code","source":"print('\\n5-fold Confusion Matrix')\nprint(confusion_matrix(y_true,pred_ens))\n\nprint('\\n5-fold Accuracy:')\nprint(accuracy_score(y_true,pred_ens))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea13c3ce53ffd8d28d59ea4d793ea931f8d9ce67"},"cell_type":"markdown","source":"**Make a Submission File**\n\nSo, let's prep a submission. Since we have 'k' predictions, we can ensemble those in some way. I use the most simplest of methods. I just grab the mode value of the 7 predictions. This works fine if there is a clear majority of course, but if there is a tie, mode fails. Other methods could be to use VotingClassifier for instance - or a blending/stacking method as well. It works fine here though for a basic baseline."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"q = (stats.mode(p_corr[:],axis=0)).mode\n\nsub = pd.DataFrame()\nsub['Id'] = Id_test\nsub['Cover_Type'] = q.reshape(-1)\nsub.head()\nsub.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}