{"cells":[{"metadata":{"collapsed":true,"_uuid":"bf55b7981ee043ec907d6b0634c56e55a1c4369d","_cell_guid":"0365369d-e443-4b35-aa90-7b3762d2e83b","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"61907af48dec6938d79a2c3043b7e78f21bc07a5","_cell_guid":"baf85875-fb06-4f9c-8648-482d08764d4c","trusted":false},"cell_type":"code","source":"from keras.models import *\nfrom keras.layers import *\nfrom keras.applications import *\nfrom keras.preprocessing.image import *\n\nimport h5py","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"165f3f0de141f4b7d65ce8b9cef967379faf2552","_cell_guid":"faefd94a-9adb-4ff7-b5ff-b60f88993a8d","trusted":false},"cell_type":"code","source":"from keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.models import Sequential, load_model, Model\nfrom keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\nfrom keras.optimizers import SGD\nfrom keras.callbacks import EarlyStopping\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom sklearn.utils import shuffle\nimport os\nimport h5py\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\n\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"99c8f4131a4450e61535c665f1665433260eaa48","_cell_guid":"d1b7f08d-a3d0-46d3-bab1-6bc0e8401ff2","trusted":false},"cell_type":"code","source":"batch_size = 32\n\ndata_root_dir = '../input/dogs-vs-cats-redux-kernels-edition/'\n\nkeras_models_dir = '../input/keras-models/'\n\nprint(check_output([\"ls\", keras_models_dir]).decode(\"utf8\"))\nprint(check_output([\"ls\", data_root_dir]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"8a1aba1db8cdb50542f170ddc144180325702a88","_cell_guid":"ab92a75b-9aa1-4587-a3d5-153b18f6df84","trusted":false},"cell_type":"code","source":"img_width, img_height = 224, 224\n\nvgg16 = applications.VGG16(include_top=False, weights=None) #input_shape = (3, img_width, img_height)\n\ndef load_split_weights(model, model_path_pattern='model_%d.h5', memb_size=102400000):  \n    model_f = h5py.File(model_path_pattern, \"r\", driver=\"family\", memb_size=memb_size)\n    topology.load_weights_from_hdf5_group_by_name(model_f, model.layers)\n    return model\n\nmodel_path_pattern = keras_models_dir + \"vgg16_weights_tf_dim_ordering_tf_kernels_%d.h5\" \nvgg16 = load_split_weights(vgg16, model_path_pattern = model_path_pattern)\n\n# set the first 25 layers (up to the last conv block) to non-trainable (weights will not be updated)\nfor layer in vgg16.layers[:25]:\n    layer.trainable = False\n\nx = vgg16.get_layer('block5_conv3').output\nx = GlobalAveragePooling2D()(x)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=vgg16.input, outputs=x)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"3496065ce98084dfd336282c35a98e1a44e12c76","_cell_guid":"9f93bc9a-527a-4708-9223-237007fd72b2","trusted":false},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"d47ca7e3cbd04fb4a5754d3420759cd67e56f542","_cell_guid":"61365efc-4604-4ea1-9ca7-816cd8aef54b","trusted":false},"cell_type":"code","source":"def augment(src, choice):\n    if choice == 0:\n        # Rotate 90\n        src = np.rot90(src, 1)\n    if choice == 1:\n        # flip vertically\n        src = np.flipud(src)\n    if choice == 2:\n        # Rotate 180\n        src = np.rot90(src, 2)\n    if choice == 3:\n        # flip horizontally\n        src = np.fliplr(src)\n    if choice == 4:\n        # Rotate 90 counter-clockwise\n        src = np.rot90(src, 3)\n    if choice == 5:\n        # Rotate 180 and flip horizontally\n        src = np.rot90(src, 2)\n        src = np.fliplr(src)\n    return src","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"196cab0182c846cf55473344caf5684be7a55b38","_cell_guid":"8cfeb9e5-e717-456f-93c7-95e8cc10e85a","trusted":false},"cell_type":"code","source":"import glob\nfrom sklearn.cross_validation import train_test_split\nfrom numpy import random\n\ntrain_dogs = glob.glob(data_root_dir + \"train/dog.*\")\ntrain_cats = glob.glob(data_root_dir + \"train/cat.*\")\n#print (train_cats[:1])\n\n# slice datasets for memory efficiency on Kaggle Kernels, delete if using full dataset\nimages = train_dogs[:1200] + train_cats[:1200]\nrandom.shuffle(images)\n\n#print(images[:2])\nlabels = []\nfor i in images:\n    #print(i)\n    if \"dog.\" in i:\n        labels.append(1)\n    else:\n        labels.append(0)\n        \nbatch_size = 10\n\ndef process_img(i):\n    img = load_img(dogs[i])  # this is a PIL image\n    x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n    #x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n    return x;\n\ntrain_images, validation_images = train_test_split(images, test_size=0.4)\n\n#print(\"Train shape: {}\".format(train.shape))\n#print(\"Test shape: {}\".format(test.shape))\n#print(\"Validation shape: {}\".format(valid.shape))\n#print(len(train_images))\nprint(train_images[:1])\nprint(validation_images[:1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c3aee421d1afef89211ae025b0754eaabde30ef","_cell_guid":"0aeb5d1d-373a-4b67-8bce-d3bd671e71c9"},"cell_type":"markdown","source":"http://sujitpal.blogspot.com.au/2017/02/using-keras-imagedatagenerator-with.html"},{"metadata":{"collapsed":true,"_uuid":"963f9542497fc13936698d87552f63a8764acfc0","_cell_guid":"03d304a1-d9ee-4763-9034-bc544f655c18","trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom scipy.misc import imresize\n\ndef imread(image_path):\n    image = plt.imread(image_path)\n    image = imresize(image, (img_width, img_height))\n    return image\n\ndef preprocess_images(image_names, seed, datagen):\n    #print (image_names)\n    np.random.seed(seed)\n    X = np.zeros((len(image_names), img_width, img_height, 3))\n    for i, image_name in enumerate(image_names):\n        #print (image_name)\n        image = imread(image_name)\n        X[i] = datagen.random_transform(image)\n    return X\n\ndef image_triple_generator(train_images, batch_size):\n    datagen_args = dict(rotation_range=10,\n                        width_shift_range=0.2,\n                        height_shift_range=0.2,\n                        shear_range=0.2,\n                        zoom_range=0.2,\n                        horizontal_flip=True)\n    datagen = ImageDataGenerator(**datagen_args)\n    \n    while True:\n        # loop once per epoch\n        num_recs = len(train_images)\n        #print(num_recs)\n        indices = np.random.permutation(np.arange(num_recs))\n        num_batches = num_recs // batch_size\n        for bid in range(num_batches):\n            # loop once per batch\n            batch_indices = indices[bid * batch_size : (bid + 1) * batch_size]\n            #print(batch_indices)\n            batch = [train_images[i] for i in batch_indices]\n            #print(batch)\n            # make sure image data generators generate same transformations\n            seed = np.random.randint(low=0, high=1000, size=1)[0]\n            batch_label = []\n            batch_img = preprocess_images(batch, seed, datagen)\n            for i in batch:\n                if \"dog.\" in i:\n                    batch_label.append(1)\n                else:\n                    batch_label.append(0)\n                    \n            yield batch_img, batch_label\n            \nbatches = image_triple_generator(train_images, 4)\nval_batches = image_triple_generator(validation_images, 4)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"3433d8f7f85a98907e426b9bbc35ec80de067f61","_cell_guid":"050e48c7-85a8-435a-b33d-f38ecbb3d710","trusted":false},"cell_type":"code","source":"trn_classes = len(train_images)\nval_classes = len(validation_images)\nsteps_per_epoch=int(np.ceil(trn_classes/batch_size))\nvalidation_steps=int(np.ceil(val_classes/batch_size))    \nepochs=15\n\nprint (\"epochs:\" + str(epochs))\nprint (\"batch_size:\" + str(batch_size))\nprint (\"trn_classes:\" + str(trn_classes))\nprint (\"val_classes:\" + str(val_classes))\nprint (\"steps_per_epoch:\" + str(steps_per_epoch))\nprint (\"validation_steps:\" + str(validation_steps))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"5755d4b6ff4c5252f8bb12526ae6f99c9ed7f85d","_cell_guid":"214dee06-1f62-47f2-82bd-0c5b4c725cc8","trusted":false},"cell_type":"code","source":"from keras.preprocessing import image\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.callbacks import LearningRateScheduler\nimport os.path\n\nfine_weights_path = 'tune_weights.h5'\n\nif os.path.isfile(fine_weights_path) :\n    print (\"load fine_weights_path:\" + fine_weights_path)\n    model.load_weights(fine_weights_path)\n    \ndef step_decay(epoch):\n    if epoch >= 0 and epoch < 2:\n        lrate = 0.0001 #Default Adam lr=0.001\n    elif epoch >= 2 and epoch < 5:\n        lrate = 0.00001\n    elif epoch >= 5 and epoch < 10:\n        lrate = 0.000001\n    elif epoch >= 15 and epoch < 20:\n        lrate = 0.0000001\n    else:\n        lrate = 0.0000001\n    \n    print (str(epoch) + \" learning rate:%.6f\" % lrate)\n    return lrate\n\nreduce_lr = LearningRateScheduler(step_decay)\n\ncallbacks_list = [\n    ModelCheckpoint(fine_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n    EarlyStopping(monitor='val_acc', patience=5, verbose=1),reduce_lr]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"2e4b27241086f8d0f870c59d9d368466331bd739","_cell_guid":"53771d87-135b-4b9f-8765-4263851e4201","trusted":false},"cell_type":"code","source":"history = model.fit_generator(batches, \n                    steps_per_epoch=steps_per_epoch, \n                    epochs=epochs, \n                    validation_data=val_batches, \n                    validation_steps=validation_steps,\n                    callbacks=callbacks_list,          \n                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"1a48fd121f2747f6424d5c5dcd3e03da1d90dc9c","_cell_guid":"fa6e209a-249e-42d2-9deb-8124b14da452","trusted":false},"cell_type":"code","source":"import seaborn\n\nseaborn.countplot(labels)\n#seaborn.plt.title('Cats and Dogs')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"eefdc9a94c02787c94288327cc9bad9128b3aa7a","_cell_guid":"047bcf6c-ba04-4d0c-b3c4-9cd0f1dfb28d","trusted":false},"cell_type":"code","source":" print(\"Training accuracy: %.2f%% / Validation accuracy: %.2f%%\" % (100*history.history['acc'][-1], 100*history.history['val_acc'][-1]))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"6d4c94cce89fc37a38bc009588dad24e3cb17003","_cell_guid":"dea5340b-3726-411b-8a3a-6b689d03b7b8","trusted":false},"cell_type":"code","source":"model.save_weights(fine_weights_path)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"1e26d738563ddc0db8a7d5df58fe102b0c3e6ba1","_cell_guid":"c258dd9f-ba56-4423-8fe4-b25b509bca4f","trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# list all data in history\nprint(history.history.keys())\n\nplt.plot(history.history['val_acc'])\nplt.plot(history.history['acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"034996bafb90357ceb79192b38d83586c1de53b8","_cell_guid":"085e6471-9663-4938-99f9-29a55714d0af","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}