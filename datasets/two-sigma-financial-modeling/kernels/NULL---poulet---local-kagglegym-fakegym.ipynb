{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a4869fd7-5b45-7654-3d3a-ab22ffe28bec"
      },
      "source": [
        "Please note that the R2 calculation is highly inefficient (I don't know why, help? :D), so I calculate it only for %100==0 timestamps and the last one. Also, I could not understand why the R value is different for the all timestamps expect for the last one (it works because this is the public scoreboard score using this train set)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ab8c77b8-8ac7-a97d-7fb1-acbf89709e1f"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np        \n",
        "        \n",
        "class FakeGym():\n",
        "    def __init__(self, df):\n",
        "        self._df=df\n",
        "        self._current_ts=math.floor(df[\"timestamp\"].max()/2)+1\n",
        "        self._max_ts=df[\"timestamp\"].max()\n",
        "        self._R=-1\n",
        "        self._predicted=[]\n",
        "        self._actual=[]\n",
        "        \n",
        "        self._done=False\n",
        "        self._info={}\n",
        "        \n",
        "        \n",
        "        self.train=df[df[\"timestamp\"]<self._current_ts]\n",
        "        self.target=df[df[\"timestamp\"]==self._current_ts][[\"id\",\"y\"]]\n",
        "        self.target.loc[:,\"y\"]=0\n",
        "        self.target=self.target.reset_index()[[\"id\",\"y\"]]\n",
        "        \n",
        "        col_list=df.columns.tolist()\n",
        "        col_list.pop()\n",
        "        self._col_list=col_list\n",
        "        self.features=self._df[self._df[\"timestamp\"]==self._current_ts][self._col_list]\n",
        "        self.features=self.features.reset_index()[self._col_list]\n",
        "        \n",
        "    def step(self,target):\n",
        "        self.train=None\n",
        "        actual_target=self._df.loc[self._df[\"timestamp\"]==self._current_ts,[\"id\",\"y\"]]\n",
        "        self._predicted += target[\"y\"].tolist()\n",
        "        self._actual += actual_target[\"y\"].tolist()\n",
        "        #R calculation\n",
        "        if observation._current_ts % 100 == 0 or self._current_ts == self._max_ts:\n",
        "            s_actual=pd.Series(self._actual)\n",
        "            s_predicted=pd.Series(self._predicted)\n",
        "            ybar=s_actual.mean()\n",
        "            self._R = 1-np.sum((s_predicted-s_actual)**2)/np.sum((ybar-s_actual)**2)\n",
        "            self._R = np.sign(self._R)*(abs(self._R)**0.5)\n",
        "\n",
        "        self._current_ts += 1\n",
        "        if self._current_ts > self._max_ts:\n",
        "            self._done=True\n",
        "            self._info[\"public_score\"]=self._R\n",
        "        else:\n",
        "            self.target=self._df.loc[df[\"timestamp\"]==self._current_ts,[\"id\",\"y\"]]\n",
        "            self.target.loc[:,\"y\"]=0\n",
        "            self.target=self.target.reset_index()[[\"id\",\"y\"]]\n",
        "            self.features=self._df.loc[self._df[\"timestamp\"]==self._current_ts,self._col_list]\n",
        "            self.features=self.features.reset_index()[self._col_list]\n",
        "        return self, self._R, self._done, self._info\n",
        "            \n",
        "            \n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a7b2c83b-7c2b-d690-abc5-51d6829f6770"
      },
      "source": [
        "The next cell uses the FakeGym class to evalutate an all-zeros prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eb12f316-bff8-3ab4-8243-8cf222017ee1"
      },
      "outputs": [],
      "source": [
        "with pd.HDFStore(\"../input/train.h5\", \"r\") as train:\n",
        "    df = train.get(\"train\")\n",
        "    \n",
        "observation = FakeGym(df) #different\n",
        "\n",
        "# Note that the first observation we get has a \"train\" dataframe\n",
        "print(\"Train has {} rows\".format(len(observation.train)))\n",
        "\n",
        "# The \"target\" dataframe is a template for what we need to predict:\n",
        "print(\"Target column names: {}\".format(\", \".join(['\"{}\"'.format(col) for col in list(observation.target.columns)])))\n",
        "\n",
        "while True:\n",
        "    timestamp = observation.features[\"timestamp\"][0]\n",
        "    target = observation.target\n",
        "    # We perform a \"step\" by making our prediction and getting back an updated \"observation\":\n",
        "    observation, reward, done, info = observation.step(target) #different\n",
        "    if timestamp % 100 == 0:\n",
        "        print(\"Timestamp #{}\".format(timestamp))\n",
        "        print(\"Reward {}\".format(reward))\n",
        "    if done:\n",
        "        print(\"Public score: {}\".format(info[\"public_score\"]))\n",
        "        break\n",
        "        \n",
        "#Manual check all predicted=0\n",
        "actual=df[\"y\"][(df[\"timestamp\"] >= 907)]\n",
        "actual=actual.reset_index()[\"y\"]\n",
        "num = np.sum(actual**2)\n",
        "ybar=actual.mean()\n",
        "den = np.sum((actual-ybar)**2)\n",
        "R2=1-num/den\n",
        "R=np.sign(R2)*(abs(R2)**0.5)\n",
        "print(\"Manually checked public score: {}\".format(R))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ad816a37-6bd4-dd9d-6457-7de80620eeeb"
      },
      "source": [
        "Now let's compare the kagglegym output vs FakeGym output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d01e8c6b-966a-507a-92bc-769f6ad389e0"
      },
      "outputs": [],
      "source": [
        "import kagglegym\n",
        "# The \"environment\" is our interface for code competitions\n",
        "env = kagglegym.make()\n",
        "\n",
        "# We get our initial observation by calling \"reset\"\n",
        "observation = env.reset()\n",
        "\n",
        "# Note that the first observation we get has a \"train\" dataframe\n",
        "print(\"Train has {} rows\".format(len(observation.train)))\n",
        "\n",
        "# The \"target\" dataframe is a template for what we need to predict:\n",
        "print(\"Target column names: {}\".format(\", \".join(['\"{}\"'.format(col) for col in list(observation.target.columns)])))\n",
        "\n",
        "while True:\n",
        "    timestamp = observation.features[\"timestamp\"][0]\n",
        "    target = observation.target\n",
        "    # We perform a \"step\" by making our prediction and getting back an updated \"observation\":\n",
        "    observation, reward, done, info = env.step(target)\n",
        "    if timestamp % 100 == 0:\n",
        "        print(\"Timestamp #{}\".format(timestamp))\n",
        "        print(\"Reward {}\".format(reward))\n",
        "\n",
        "    \n",
        "    if done:\n",
        "        print(\"Public score: {}\".format(info[\"public_score\"]))\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "33f3c3ca-ba6b-1ca4-1b57-e455c963c4be"
      },
      "source": [
        "Any idea why rewards calculated in between do not have similar values to the ones I calculated? :("
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "546e3368-509b-96d5-2afc-fee1900a68fc"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}