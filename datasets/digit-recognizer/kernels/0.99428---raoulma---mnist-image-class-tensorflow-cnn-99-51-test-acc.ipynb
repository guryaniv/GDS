{"metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "file_extension": ".py", "version": "3.6.3", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "name": "python"}}, "nbformat": 4, "cells": [{"source": ["CNN classifier for handwritten digits of the MNIST dataset. The dataset consists of 42000 images of size 28x28 = 784 pixels (one color number) including the corresponding labels from 0,..,9. The basic architecture of the NN is given by:\n", "\n", "- Layer: input = [42000,784]\n", "- Layer: Conv1 -> ReLu -> MaxPool: [.,14,14,32] \n", "- Layer: Conv2 -> ReLu -> MaxPool: [.,7,7,64]\n", "- Layer: FC -> ReLu: [.,1024]\n", "- Layer: FC -> ReLu: [.,10]\n", "\n", "Using a split of 95%/5% on the labeled data this implementation, trained on 40000 training images for 8 epochs with suitable hyperparameters, achieves a 99.45% accuracy on the validation set of 2000 images.\n", "\n", "## Libraries and Settings"], "cell_type": "markdown", "metadata": {"_cell_guid": "ae26a5da-aab9-47a2-b7dd-644778615a16", "_uuid": "8abac6e9d07e55338b420f9789904bc957f8fa0c"}}, {"execution_count": null, "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import matplotlib.cm as cm # cm = colormap\n", "import tensorflow as tf\n", "%matplotlib inline\n", "import os;\n", "import itertools\n", "\n", "dir_logs = os.getcwd()+'/logs'; # directory to save models\n", "val_set_size = 2000; # validation set size \n", "\n", "#display parent directory and working directory\n", "print(os.path.dirname(os.getcwd())+':', os.listdir(os.path.dirname(os.getcwd())));\n", "print(os.getcwd()+':', os.listdir(os.getcwd()));"], "cell_type": "code", "metadata": {"_cell_guid": "8fc7ff0a-f896-485a-9628-2f4c639942d0", "_uuid": "420cf9cf5d64f79d38869ba265edfd759f1e4865"}, "outputs": []}, {"source": ["## Data Preprocessing"], "cell_type": "markdown", "metadata": {"_cell_guid": "e1bd0032-cf12-45cd-840d-bbe8b36b8383", "_uuid": "15744e6161356ffdfaba3da0eb55c469f187a246"}}, {"execution_count": null, "source": ["## read training and validation data [42000,785] dataframe\n", "\n", "if os.path.isfile('../input/train.csv'):\n", "    data = pd.read_csv('../input/train.csv') # on kaggle \n", "    print('train.csv loaded: data({0[0]},{0[1]})'.format(data.shape))\n", "elif os.path.isfile('data/train.csv'):\n", "    data = pd.read_csv('data/train.csv') # on local environment\n", "    print('train.csv loaded: data({0[0]},{0[1]})'.format(data.shape))\n", "else:\n", "    print('Error: train.csv not found')"], "cell_type": "code", "metadata": {"_cell_guid": "1c4dc51a-add1-410d-a586-58e934d0afd5", "_uuid": "cd465ec1f9f87cfe2432ad669e81bf142aac1352"}, "outputs": []}, {"execution_count": null, "source": ["## look at data and split into training and validation sets\n", "\n", "# extract images\n", "images = data.iloc[:,1:].values # (42000,784) array\n", "images = images.astype(np.float) # convert from int64 to float\n", "images = np.multiply(images, 1.0 / 255.0) # convert from [0:255] to [0.0:1.0]\n", "image_size = images.shape[1] # = 784\n", "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8) # = 28\n", "\n", "# extract image labels\n", "labels_flat = data.iloc[:,0].values\n", "labels_count = np.unique(labels_flat).shape[0]; # number of different labels = 10\n", "\n", "#plot some images and labels\n", "plt.figure(figsize=(15,2))\n", "for i in range(0,10):\n", "    plt.subplot(2,10,1+i)\n", "    plt.title(labels_flat[i])\n", "    plt.imshow(images[i].reshape(image_width,image_height),cmap=cm.binary)\n", "    \n", "# convert class labels from scalars to one-hot vectors e.g. 1 => [0 1 0 0 0 0 0 0 0 0]\n", "def dense_to_one_hot(labels_dense, num_classes):\n", "    num_labels = labels_dense.shape[0]\n", "    index_offset = np.arange(num_labels) * num_classes\n", "    labels_one_hot = np.zeros((num_labels, num_classes))\n", "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n", "    return labels_one_hot\n", "\n", "# labels in one hot representation\n", "labels = dense_to_one_hot(labels_flat, labels_count).astype(np.uint8)\n", "#labels = labels.astype(np.uint8)\n", "\n", "# split data into training & validation\n", "train_images = images[val_set_size:]\n", "train_labels = labels[val_set_size:]\n", "val_images = images[:val_set_size]\n", "val_labels = labels[:val_set_size]\n", "\n", "print('images({0[0]},{0[1]}),'.format(images.shape),'labels_flat({0[0]})'.format(labels_flat.shape))\n", "print('train_images({0[0]},{0[1]})'.format(train_images.shape),'labels({0[0]},{0[1]})'.format(labels.shape),'val_images({0[0]},{0[1]})'.format(val_images.shape),'val_labels({0[0]},{0[1]})'.format(val_labels.shape))\n", "print ('image_size = {0}, image_width = {1}, image_height = {2}, labels_count = {3}'.format(image_size,image_width,image_height,labels_count))\n"], "cell_type": "code", "metadata": {"_cell_guid": "64f637d5-34c4-49ea-a743-fbc1b2cd917b", "_uuid": "4021b771e17a5f9787c9b71ad5c6733c92ec860c"}, "outputs": []}, {"source": ["## TensorFlow Graph"], "cell_type": "markdown", "metadata": {"_cell_guid": "1eff9850-60ba-4f02-8de7-941865a8d91c", "_uuid": "21a49993c6e32b06ca3cb76a76d4c688ac15a161"}}, {"execution_count": null, "source": ["#tf.set_random_seed(1)\n", "#np.random.seed(1)\n", "\n", "# weight and bias initialization\n", "def weight_variable(shape):\n", "    initial = tf.truncated_normal(shape, stddev=0.1)\n", "    return tf.Variable(initial)\n", "\n", "def bias_variable(shape):\n", "    initial = tf.constant(0.1, shape=shape) #  positive bias\n", "    return tf.Variable(initial)\n", "\n", "# 2D convolution\n", "def conv2d(x, W):\n", "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n", "\n", "# max pooling\n", "def max_pool_2x2(x):\n", "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n", "\n", "# variables for input and output \n", "x = tf.placeholder('float', shape=[None, image_size])\n", "y_ = tf.placeholder('float', shape=[None, labels_count])\n", "\n", "# 1. layer: convolution + max pooling\n", "image = tf.reshape(x, [-1,28,28,1]) # (.,784) => (.,28,28,1)\n", "W_conv1 = weight_variable([5, 5, 1, 32]) # (5,5,1,32)\n", "b_conv1 = bias_variable([32]) # (32)\n", "h_conv1 = tf.nn.relu(conv2d(image, W_conv1) + b_conv1) # => (.,28,28,32)\n", "h_pool1 = max_pool_2x2(h_conv1) # => (.,14,14,32)\n", "\n", "# 2. layer: convolution + max pooling\n", "W_conv2 = weight_variable([5, 5, 32, 64])\n", "b_conv2 = bias_variable([64])\n", "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # => (.,14,14,64)\n", "h_pool2 = max_pool_2x2(h_conv2) # => (.,7,7,64)\n", "\n", "# 3.layer: fully connected\n", "W_fc1 = weight_variable([7*7*64,1024])\n", "b_fc1 = bias_variable([1024])\n", "h_pool2_flat = tf.reshape(h_pool2, [-1,7*7*64]) # (.,7,7,64) => (.,3136)\n", "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) # => (.,1024)\n", "\n", "# dropout\n", "tf_keep_prob = tf.placeholder('float')\n", "h_fc1_drop = tf.nn.dropout(h_fc1, tf_keep_prob)\n", "\n", "# 4.layer: fully connected\n", "W_fc2 = weight_variable([1024, labels_count])\n", "b_fc2 = bias_variable([labels_count])\n", "y = tf.matmul(h_fc1_drop, W_fc2) + b_fc2 # => (.,10)\n", "\n", "# cost function\n", "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n", "\n", "# optimisation function\n", "global_step = tf.Variable(0, trainable=False)\n", "tf_learn_rate = tf.placeholder(dtype='float', name=\"tf_learn_rate\")\n", "train_step = tf.train.AdamOptimizer(tf_learn_rate).minimize(cross_entropy)\n", "\n", "# evaluation\n", "correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y),1), tf.argmax(y_,1))\n", "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n", "\n", "# prediction function\n", "predict = tf.argmax(tf.nn.softmax(y),1) # [0.1, 0.9, 0.2, 0.1, 0.1 0.3, 0.5, 0.1, 0.2, 0.3] => 1\n", "\n", "# function: to get the next mini batch\n", "def next_batch(batch_size):\n", "    global train_images, train_labels, index_in_epoch;\n", "    assert batch_size <= num_examples\n", " \n", "    start = index_in_epoch\n", "    index_in_epoch += batch_size\n", "    \n", "    if index_in_epoch > num_examples:\n", "        perm = np.arange(num_examples) \n", "        np.random.shuffle(perm) # shuffle the data\n", "        train_images = train_images[perm]\n", "        train_labels = train_labels[perm]\n", "        start = 0 # start next epoch\n", "        index_in_epoch = batch_size\n", "        \n", "    end = index_in_epoch\n", "    return train_images[start:end], train_labels[start:end]"], "cell_type": "code", "metadata": {"_cell_guid": "d3bedd5b-c40d-46a7-8e7e-19af7f2a5773", "collapsed": true, "_uuid": "57d7213a23ff15c677946c5ee3c81b04579c87ec"}, "outputs": []}, {"source": ["## Training and Validation"], "cell_type": "markdown", "metadata": {"_cell_guid": "e2b7c61e-88bb-40dd-bde0-5ec1977d8365", "_uuid": "180614885e56beb180592796a1267c0fbcab30ac"}}, {"execution_count": null, "source": ["## set parameters\n", "\n", "sess = tf.InteractiveSession() # start TensorFlow session\n", "sess.run(tf.global_variables_initializer()) # initialize global variables\n", "\n", "# variables and parameters\n", "num_examples = train_images.shape[0];\n", "index_in_epoch = 0;\n", "train_acc, val_acc, train_loss, val_loss = np.array([]),np.array([]),np.array([]),np.array([]);  \n", "log_step = 50; # log results each step\n", "epoch_no = 8; # no of epochs \n", "\n", "# test hyperparameters\n", "mb_size_range = [50]; # mini batch size\n", "keep_prob_range = [0.5]; # dropout regularization with keeping probability\n", "learn_rate_range = [10*1e-4, 5*1e-4, 2.5*1e-4, 1*1e-4, 0.5*1e-4, 0.25*1e-4, 0.1*1e-4, \n", "                    0.05*1e-4, 0.025*1e-4, 0.01*1e-4];\n", "learn_rate_step = 1.0; # change learning rate each learn_rate_step in epochs"], "cell_type": "code", "metadata": {"_cell_guid": "96416e2d-9d37-408a-b690-812a7328e7fb", "collapsed": true, "_uuid": "767d03d478b0a3a5a6cf97751db20ddd054de78c"}, "outputs": []}, {"execution_count": null, "source": ["## training model\n", "\n", "for mb_size,keep_prob in itertools.product(mb_size_range,keep_prob_range):\n", "    mb_no = int(np.floor(epoch_no*num_examples/mb_size)); # no of mini batches\n", "    learn_rate_step = int(np.floor(learn_rate_step*num_examples/mb_size)); # steps in batches\n", "    print('epoch_no = %.0f, mb_size = %.0f, keep_prob = %.2f'%(epoch_no,mb_size,keep_prob))\n", "    learn_rate_pos = -1;\n", "    \n", "    for i in range(0,mb_no+1):\n", "        \n", "        if (i%learn_rate_step == 0) and ((learn_rate_pos+1) < len(learn_rate_range)):\n", "            learn_rate_pos+=1;\n", "            learn_rate = learn_rate_range[learn_rate_pos]  # adapt learn_rate\n", "            print('set current learn rate to: %.6f'%learn_rate)\n", "        \n", "        #learn_rate = 0.001*1e-4;\n", "        \n", "        batch_xs, batch_ys = next_batch(mb_size) #get new batch\n", "        \n", "        if i > 0:\n", "             sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys, \n", "                                                tf_keep_prob: keep_prob, \n", "                                                tf_learn_rate: learn_rate})\n", "        if i%log_step == 0 or i == mb_no:\n", "            train_loss = np.append(train_loss, sess.run(cross_entropy, feed_dict={x:train_images[0:2000], y_:train_labels[0:2000], tf_keep_prob:1.0}));\n", "            train_acc = np.append(train_acc, accuracy.eval(feed_dict={x:train_images[0:2000], y_:train_labels[0:2000], tf_keep_prob:1.0}));      \n", "            if val_set_size > 0:\n", "                train_loss = np.append(train_loss, sess.run(cross_entropy, feed_dict={x:train_images[0:val_set_size], y_:train_labels[0:val_set_size], tf_keep_prob:1.0}));\n", "                train_acc = np.append(train_acc, accuracy.eval(feed_dict={x:train_images[0:val_set_size], y_:train_labels[0:val_set_size], tf_keep_prob:1.0}));      \n", "                val_loss = np.append(val_loss, sess.run(cross_entropy, feed_dict={x:val_images, y_: val_labels, tf_keep_prob: 1.0}));\n", "                val_acc = np.append(val_acc, accuracy.eval(feed_dict={x: val_images, y_: val_labels,tf_keep_prob: 1.0}));                                  \n", "            else: \n", "                val_loss = [0]; val_acc = [0];\n", "            print('%.2f epoch: train/val loss = %.4f/%.4f , train/val acc = %.4f/%.4f'%(i*mb_size/num_examples,train_loss[-1],val_loss[-1],train_acc[-1], val_acc[-1]))\n", "\n", "    # save model\n", "    #if not os.path.exists(dir_logs): # check if directory for logs exists\n", "    #    os.makedirs(dir_logs)\n", "    #np.savez(dir_logs+'/model.npz', \n", "    #        learn_rate = learn_rate, keep_prob = keep_prob, mb_size = mb_size, log_step = log_step,\n", "    #        W_conv1 = np.asarray(W_conv1.eval()), b_conv1 = np.asarray(b_conv1.eval()), W_conv2 = np.asarray(W_conv2.eval()),\n", "    #        b_conv2 = np.asarray(b_conv2.eval()), W_fc1 = np.asarray(W_fc1.eval()), b_fc1 = np.asarray(b_fc1.eval()),\n", "    #        W_fc2 = np.asarray(W_fc2.eval()), b_fc2 = np.asarray(b_fc2.eval()),\n", "    #        train_loss = train_loss, val_loss = val_loss, train_acc = train_acc,\n", "    #        val_acc = val_acc, val_loss_final = val_loss_final, val_acc_final = val_acc_final);\n", "\n", "    #close session\n", "    #sess.close();\n"], "cell_type": "code", "metadata": {"_cell_guid": "2ca5e137-2767-4261-ac20-65d86042e856", "_uuid": "98c599d07113cfa8bfee30244e31655400737184"}, "outputs": []}, {"execution_count": null, "source": ["'''\n", "## load model\n", "\n", "#print(dir_logs + ': ' + str(os.listdir(dir_logs)))\n", "print('load '+ dir_logs + '/model.npz')\n", "npzFile = np.load(dir_logs+'/model.npz');\n", "#print(npzFile.files);\n", "learn_rate = npzFile['learn_rate'];\n", "keep_prob = npzFile['keep_prob'];\n", "mb_size = npzFile['mb_size'];\n", "log_step = npzFile['log_step'];\n", "train_loss = npzFile['train_loss'];\n", "val_loss = npzFile['val_loss'];\n", "train_acc = npzFile['train_acc'];\n", "val_acc = npzFile['val_acc'];\n", "val_loss_final = npzFile['val_loss_final'];\n", "val_acc_final = npzFile['val_acc_final'];\n", "\n", "sess = tf.InteractiveSession() # start TensorFlow session\n", "#sess.run(tf.global_variables_initializer()) # initialiue global variables\n", "W_conv1.load(npzFile['W_conv1'], session=sess)\n", "b_conv1.load(npzFile['b_conv1'], session=sess)\n", "W_conv2.load(npzFile['W_conv2'], session=sess)\n", "b_conv2.load(npzFile['b_conv2'], session=sess)\n", "W_fc1.load(npzFile['W_fc1'], session=sess)\n", "b_fc1.load(npzFile['b_fc1'], session=sess)\n", "W_fc2.load(npzFile['W_fc2'], session=sess)\n", "b_fc2.load(npzFile['b_fc2'], session=sess)\n", "'''"], "cell_type": "code", "metadata": {"_cell_guid": "ec43e6f6-51f7-4590-96d4-7e45bad659ec", "_uuid": "5d8fd8ba7e1bd518979de953f41594fc924ff2de"}, "outputs": []}, {"execution_count": null, "source": ["## confusion matrix\n", "y_predict = sess.run(tf.argmax(y,1), feed_dict={x: val_images,tf_keep_prob: 1.0});\n", "y_target = sess.run(tf.argmax(val_labels,1));\n", "print('confusion matrix:')\n", "print(sess.run(tf.contrib.metrics.confusion_matrix(predictions = y_predict, labels = y_target)))"], "cell_type": "code", "metadata": {"_cell_guid": "083ed09c-7e93-49e5-ae28-eccc9282d20f", "collapsed": true, "_uuid": "55718aab0eed2d5894f5df7764645c5c24f9f605"}, "outputs": []}, {"execution_count": null, "source": ["## final loss, accuracy \n", "\n", "val_loss_final = sess.run(cross_entropy, feed_dict={x: val_images,y_: val_labels, tf_keep_prob: 1.0});        \n", "val_acc_final = accuracy.eval(feed_dict={x: val_images, y_: val_labels, tf_keep_prob: 1.0})\n", "print('final: val_loss = %.4f, val_acc = %.4f'%(val_loss_final,val_acc_final))\n", "\n", "plt.figure(figsize=(10, 5));\n", "plt.subplot(1,2,1);\n", "plt.plot(np.arange(0,len(train_acc))*log_step*mb_size/num_examples, train_acc,'-b', label='Training')\n", "plt.plot(np.arange(0,len(val_acc))*log_step*mb_size/num_examples, val_acc,'-g', label='Validation')\n", "plt.legend(loc='lower right', frameon=False)\n", "plt.ylim(ymax = 1.1, ymin = 0.0)\n", "plt.ylabel('accuracy')\n", "plt.xlabel('epoch');\n", "\n", "plt.subplot(1,2,2)\n", "plt.plot(np.arange(0,len(train_loss))*log_step*mb_size/num_examples, train_loss,'-b', label='Training')\n", "plt.plot(np.arange(0,len(val_loss))*log_step*mb_size/num_examples, val_loss,'-g', label='Validation')\n", "plt.legend(loc='lower right', frameon=False)\n", "plt.ylim(ymax = 3.0, ymin = 0.0)\n", "plt.ylabel('loss')\n", "plt.xlabel('epoch');"], "cell_type": "code", "metadata": {"_cell_guid": "7e351ab9-f9dc-41d1-80ee-802b1c8a9114", "collapsed": true, "_uuid": "6541c6ca89fd856531b2f0280cbe78d91da87183"}, "outputs": []}, {"execution_count": null, "source": ["## visualize weights\n", "\n", "W_conv1_vis = W_conv1.eval();\n", "print('W_conv1: min = ' + str(np.min(W_conv1_vis)) + ' max = ' + str(np.max(W_conv1_vis))\n", "      + ' mean = ' + str(np.mean(W_conv1_vis)) + ' std = ' + str(np.std(W_conv1_vis)))\n", "W_conv1_vis = np.reshape(W_conv1_vis,(5,5,1,4,8))\n", "W_conv1_vis = np.transpose(W_conv1_vis,(3,0,4,1,2))\n", "W_conv1_vis = np.reshape(W_conv1_vis,(20,40,1))\n", "plt.gca().set_xticks(np.arange(-0.5, 40, 5), minor = True);\n", "plt.gca().set_yticks(np.arange(-0.5, 20, 5), minor = True);\n", "plt.grid(which = 'minor', color='b', linestyle='-', linewidth=1)\n", "plt.title('W_conv1 ' + str(W_conv1.shape))\n", "plt.colorbar(plt.imshow(W_conv1_vis[:,:,0], cmap=cm.binary));\n", "plt.show();\n", "\n", "W_conv2_vis = W_conv2.eval();\n", "print('W_conv2: min = ' + str(np.min(W_conv2_vis)) + ' max = ' + str(np.max(W_conv2_vis))\n", "      + ' mean = ' + str(np.mean(W_conv2_vis)) + ' std = ' + str(np.std(W_conv2_vis)))\n", "W_conv2_vis = np.reshape(W_conv2_vis,(5,5,4,8,64))\n", "W_conv2_vis = np.transpose(W_conv2_vis,(2,0,3,1,4))\n", "W_conv2_vis = np.reshape(W_conv2_vis,(4*5,8*5,8,8))\n", "W_conv2_vis = np.transpose(W_conv2_vis,(2,0,3,1))\n", "W_conv2_vis = np.reshape(W_conv2_vis,(8*4*5,8*8*5))\n", "plt.figure(figsize=(15,10))\n", "plt.gca().set_xticks(np.arange(-0.5, 320, 40), minor = True);\n", "plt.gca().set_yticks(np.arange(-0.5, 160, 20), minor = True);\n", "plt.grid(which = 'minor', color='b', linestyle='-', linewidth=1)\n", "plt.title('W_conv2 ' + str(W_conv2.shape))\n", "plt.colorbar(plt.imshow(W_conv2_vis[:,:], cmap=cm.binary));\n", "\n", "#b_conv1_vis = b_conv1.eval();\n", "#print('b_conv1 = ',b_conv1_vis)\n", "#b_conv2_vis = b_conv2.eval();\n", "#print('b_conv2 = ',b_conv2_vis)"], "cell_type": "code", "metadata": {"_cell_guid": "add9e626-e259-4b3f-82ef-078778113782", "collapsed": true, "_uuid": "5532356d3a392b9d76205c02cdc17d92fdfe2481"}, "outputs": []}, {"execution_count": null, "source": ["## visualize activations\n", "\n", "IMG_NO = 10;\n", "feed_dict = {x: train_images[IMG_NO:IMG_NO+1], tf_keep_prob: 1.0}\n", "\n", "# original image\n", "plt.figure(figsize=(15,10))\n", "plt.subplot(2,3,1)\n", "plt.title('prediction: %d'%predict.eval(feed_dict = feed_dict))\n", "plt.imshow(train_images[IMG_NO].reshape(image_width,image_height),cmap=cm.binary);\n", "\n", "# 1. convolution\n", "h_conv1_vis = h_conv1.eval(feed_dict = feed_dict);\n", "plt.subplot(2,3,2)\n", "plt.title('h_conv1 ' + str(h_conv1_vis.shape))\n", "h_conv1_vis = np.reshape(h_conv1_vis,(-1,28,28,4,8))\n", "h_conv1_vis = np.transpose(h_conv1_vis,(0,3,1,4,2))\n", "h_conv1_vis = np.reshape(h_conv1_vis,(-1,4*28,8*28))\n", "plt.imshow(h_conv1_vis[0], cmap=cm.binary);\n", "\n", "# 1. max pooling\n", "h_pool1_vis = h_pool1.eval(feed_dict = feed_dict);\n", "plt.subplot(2,3,3)\n", "plt.title('h_pool1 ' + str(h_pool1_vis.shape))\n", "h_pool1_vis = np.reshape(h_pool1_vis,(-1,14,14,4,8))\n", "h_pool1_vis = np.transpose(h_pool1_vis,(0,3,1,4,2))\n", "h_pool1_vis = np.reshape(h_pool1_vis,(-1,4*14,8*14))\n", "plt.imshow(h_pool1_vis[0], cmap=cm.binary);\n", "\n", "# 2. convolution\n", "h_conv2_vis = h_conv2.eval(feed_dict = feed_dict);\n", "plt.subplot(2,3,4)\n", "plt.title('h_conv2 ' + str(h_conv2_vis.shape))\n", "h_conv2_vis = np.reshape(h_conv2_vis,(-1,14,14,8,8))\n", "h_conv2_vis = np.transpose(h_conv2_vis,(0,3,1,4,2))\n", "h_conv2_vis = np.reshape(h_conv2_vis,(-1,8*14,8*14))\n", "plt.imshow(h_conv2_vis[0], cmap=cm.binary);\n", "\n", "# 2. max pooling\n", "h_pool2_vis = h_pool2.eval(feed_dict = feed_dict);\n", "plt.subplot(2,3,5)\n", "plt.title('h_pool2 ' + str(h_pool2_vis.shape))\n", "h_pool2_vis = np.reshape(h_pool2_vis,(-1,7,7,8,8))\n", "h_pool2_vis = np.transpose(h_pool2_vis,(0,3,1,4,2))\n", "h_pool2_vis = np.reshape(h_pool2_vis,(-1,8*7,8*7))\n", "plt.imshow(h_pool2_vis[0], cmap=cm.binary);\n", "\n", "# 3. FC layer\n", "h_fc1_vis = h_fc1.eval(feed_dict = feed_dict);\n", "plt.subplot(2,3,6)\n", "plt.title('h_fc1 ' + str(h_fc1_vis.shape))\n", "h_fc1_vis = np.reshape(h_fc1_vis,(-1,32,32))\n", "plt.imshow(h_fc1_vis[0], cmap=cm.binary);\n", "plt.show()\n", "\n", "# 4. FC layer\n", "h_fc2_vis = y.eval(feed_dict = feed_dict);\n", "np.set_printoptions(precision=2)\n", "print('h_fc2 = ', h_fc2_vis)"], "cell_type": "code", "metadata": {"_cell_guid": "ab004898-a7ec-4e89-9be2-503db6e24d66", "collapsed": true, "_uuid": "3f169ddac4c3639ba734f67048ba41b775d68094"}, "outputs": []}, {"source": ["## Testing"], "cell_type": "markdown", "metadata": {"_cell_guid": "069e66b4-fb6c-4a55-9dd0-5f0d23717388", "_uuid": "176c76821d5518569b5e33569dd127fd91039cc4"}}, {"execution_count": null, "source": ["# read test data from CSV file \n", "if os.path.isfile('../input/test.csv'):\n", "    test_data = pd.read_csv('../input/test.csv') # on kaggle \n", "    print('test.csv loaded: test_data({0[0]},{0[1]})'.format(test_data.shape))\n", "elif os.path.isfile('data/test.csv'):\n", "    test_data = pd.read_csv('data/test.csv') # on local environment\n", "    print('test.csv loaded: test_data({0[0]},{0[1]})'.format(test_data.shape))\n", "else:\n", "    print('Error: test.csv not found')\n", "    \n", "test_images = test_data.iloc[:,0:].values # (28000,784) array\n", "test_images = test_images.astype(np.float)\n", "test_images = np.multiply(test_images, 1.0 / 255.0) # convert from [0:255] => [0.0:1.0]\n", "print('read: test_images({0[0]},{0[1]})'.format(test_images.shape));\n", "\n", "\n", "# using mini batches is more resource efficient\n", "predicted_labels = np.zeros(test_images.shape[0])\n", "BATCH_SIZE = 1000;\n", "for i in range(0,int(test_images.shape[0]/BATCH_SIZE)):\n", "    predicted_labels[i*BATCH_SIZE:(i+1)*BATCH_SIZE] = predict.eval(feed_dict={x: test_images[i*BATCH_SIZE:(i+1)*BATCH_SIZE], tf_keep_prob: 1.0})\n", "print('compute predicted_labels({0})'.format(len(predicted_labels)))\n", "\n", "# save predictions\n", "np.savetxt('submission.csv', \n", "           np.c_[range(1,len(test_images)+1),predicted_labels], \n", "           delimiter=',', \n", "           header = 'ImageId,Label', \n", "           comments = '', \n", "           fmt='%d')\n", "\n", "print('saved: submission.csv');"], "cell_type": "code", "metadata": {"_cell_guid": "2286dd81-8199-44ab-a119-1f7d5470b757", "scrolled": true, "collapsed": true, "_uuid": "dd5c3638434505b4491ddd8c804bf53e9d20dfa6"}, "outputs": []}, {"execution_count": null, "source": ["# look at test images and predicted labels\n", "plt.figure(figsize=(10,15))\n", "for j in range(0,5):\n", "    for i in range(0,10):\n", "        plt.subplot(10,10,j*10+i+1)\n", "        plt.title('%d'%predicted_labels[j*10+i])\n", "        plt.imshow(test_images[j*10+i].reshape(28,28),cmap=cm.binary)\n"], "cell_type": "code", "metadata": {"_cell_guid": "7689a5ba-fdd8-4dcd-ab67-23fc2e3bf0fa", "collapsed": true, "_uuid": "85b4ef639e68901b701d9281fcd65933f699c05a"}, "outputs": []}, {"execution_count": null, "source": ["sess.close()"], "cell_type": "code", "metadata": {"_cell_guid": "c906dec2-00ac-4c25-9b79-cdc5e1d6e496", "collapsed": true, "_uuid": "1f39c8494c0e34ea4eecc5941a67c7f3a9443d11"}, "outputs": []}], "nbformat_minor": 1}