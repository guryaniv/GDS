{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Reading first 10M training data\ntrain_df = pd.read_csv('../input/train.csv', nrows=10000000)\ntrain_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22667ed4c5d8f259dede9e1f2bb7452870c9df2d"},"cell_type":"code","source":"# Adding Manhattan Distance as features\ndef add_travel_vector_features(df):\n    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n\nadd_travel_vector_features(train_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5917c3e8d5ba04aa5892f7749cdb48aaafe4fd17"},"cell_type":"code","source":"print(train_df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"796a1de4ec121488d693ef6d6b93f8f3718bedd0"},"cell_type":"code","source":"# Given that nulls are lesser in number, let's remove these from the training dataset\nprint('Old size: %d' %len(train_df))\ntrain_df = train_df.dropna(how='any', axis='rows')\nprint('New size: %d' %len(train_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e44ad76003b7ad655bd98930362afa3ad84585c5"},"cell_type":"code","source":"# Let's plot a subset of travel vector feature we added to see it's distribution\nplot = train_df.iloc[:4000].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"545ea1ae86b0d26adb3db11f9c450057fc7085ea"},"cell_type":"markdown","source":"We expect most of these values to be very small since the trips are within  a city and hence let's drop the extreme values."},{"metadata":{"trusted":true,"_uuid":"a6ccbeaca1be33d10dfc3b7866cff3f9ebce57cf"},"cell_type":"code","source":"print('Old size: %d' %len(train_df))\ntrain_df = train_df[(train_df.abs_diff_longitude < 5.0) & (train_df.abs_diff_latitude < 5.0)]\nprint('New size: %d' %len(train_df))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"702d4fa365aec2bd0bcde8f619228a03b3b60d6a"},"cell_type":"markdown","source":"**Training**\n\nLet's train our model with Simple Linear Regression over Manhattan distance components only."},{"metadata":{"trusted":true,"_uuid":"4ce7afa5164e3030883c64b7519dc7b5f22258aa"},"cell_type":"code","source":"def get_input_matrix(df):\n    return np.column_stack((df.abs_diff_longitude, df.abs_diff_latitude, np.ones(len(df))))\n                           \ntrain_X = get_input_matrix(train_df)\ntrain_y = np.array(train_df['fare_amount'])\n                           \nprint(train_X.shape)\nprint(train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b65b5e4e91c6e5a470432fffea2ff32a3bb8674"},"cell_type":"code","source":"# Now let's use lstsq function to find the optimal weights\n(w, _, _, _) = np.linalg.lstsq(train_X, train_y, rcond=None)\nprint(w)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fffa89f8c9b51c92126c6e2a563a95250fccfed9"},"cell_type":"markdown","source":"We can also calculate the weights using Ordinary Least Squares:\n$$w = (X^TX)^{-1}X^Ty$$"},{"metadata":{"trusted":true,"_uuid":"325ba247a0fbeac8aee422a765fbc45df46013d8"},"cell_type":"code","source":"w_OLS = np.matmul(np.matmul(np.linalg.inv(np.matmul(train_X.T, train_X)), train_X.T), train_y)\nprint(w_OLS)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d152d301823db93033098d94e2a14dde46a266a1"},"cell_type":"markdown","source":"**Making Prediction on the test dataset**"},{"metadata":{"trusted":true,"_uuid":"2ba5557665cba3bb371efabc0b0becd0a54e0e4b"},"cell_type":"code","source":"test_df = pd.read_csv('../input/test.csv')\ntest_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"188169e4dec6cd3c0bd2ce955c81644984d1057b"},"cell_type":"code","source":"add_travel_vector_features(test_df)\ntest_X = get_input_matrix(test_df)\n\ntest_y_predictions = np.matmul(test_X, w).round(decimals=2)\n\nsubmission = pd.DataFrame({'key':test_df.key, 'fare_amount':test_y_predictions}, \n                          columns=['key', 'fare_amount'])\n\nsubmission.to_csv('submission.csv', index=False)\n\nprint(os.listdir('.'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c0cb3112669d173d42d186cd32edfe1d970b640"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"a4f6c0da0b2df02dd1661a0c901c5d7111877aff"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"c440a23ee66976478fb7b880799c4e68800d33e3"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"55ab842459adde6c7daa2f0b293460f01e7d3a39"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"ab89c53cda5c609a57ee2eb078eca2173785fedd"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}