{"cells":[{"metadata":{"_cell_guid":"9013109f-99c2-4038-b198-554c42f3b2a7","_uuid":"e771535b43a4aec572f083ae3c8b2a5729c52cbd"},"cell_type":"markdown","source":"### First, let's import libraries, recruit models, and load the data we will work with.\n\nFirst, let's import the libraries that we'll need."},{"metadata":{"collapsed":true,"_cell_guid":"d9323913-bcb0-446d-a0ad-30bb70c7668a","_uuid":"1ef480cb74b61aed92942d9602c8e97cedadf96d","trusted":false},"cell_type":"code","source":"# print_function for compatibility with Python 3\nfrom __future__ import print_function\n\n# NumPy for numerical computing\nimport numpy as np\n\n# Pandas for DataFrames\nimport pandas as pd\npd.set_option('display.max_columns', 100)\n# pd.options.mode.chained_assignment = None  # default='warn'\n\n# Matplotlib for visualization\nfrom matplotlib import pyplot as plt\n\n# display plots in the notebook\n%matplotlib inline \n\n# Seaborn for easier visualization\nimport seaborn as sns\n\n# Pickle for reading model files\nimport pickle\n\n# Scikit-Learn for Modeling\nimport sklearn\nfrom sklearn.model_selection import train_test_split # Scikit-Learn 0.18+","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"735037e3-0477-40d7-bdce-1aed04f58932","_uuid":"9c7bbed2f1a110fc7511c4024d7cb2353d399628"},"cell_type":"markdown","source":"Next, let's import the classifcation problem algorithms we will work with."},{"metadata":{"collapsed":true,"_cell_guid":"55ac5a89-16b3-42af-babe-5d8c070b558c","_uuid":"28f31d82665312149afd0b09ea13974ba8963573","trusted":false},"cell_type":"code","source":"# Import Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\n# Import RandomForestClassifier and GradientBoostingClassifer\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9f8df3f5-ea02-40ac-97ab-44e3b1aab5c1","_uuid":"9d14956ba1a154745010849febfc11fb0e0c01d4"},"cell_type":"markdown","source":"Next, let's import the Scikit-Learn functions and helpers we'll need."},{"metadata":{"collapsed":true,"_cell_guid":"7ba982e2-363d-497f-8195-c0bd07b7e6f9","_uuid":"91fed6d4e0d68fcf40b2d76701b53844dde4009d","trusted":false},"cell_type":"code","source":"# Function for splitting training and test set\nfrom sklearn.model_selection import train_test_split\n\n# Function for creating model pipelines\nfrom sklearn.pipeline import make_pipeline\n\n# For standardization\nfrom sklearn.preprocessing import StandardScaler\n\n# Helper for cross-validation\nfrom sklearn.model_selection import GridSearchCV\n\n# Classification metrics\nfrom sklearn.metrics import roc_curve, precision_recall_curve, auc","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"77a513fa-a1e7-4da0-805a-af4b694cbd7f","_uuid":"7bcbe489797001e64ead23586ca3be332a462325"},"cell_type":"markdown","source":"Finally, let's read the data we have collected for this problem."},{"metadata":{"_cell_guid":"5285dff3-2d0d-4e78-9be7-17d03012a5f5","_uuid":"a142262a77c0150cdad64bec5884c65ddf2049a0","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"# Load kaggle credit card transactions data\ndf = pd.read_csv('../input/creditcard.csv')\n\ndf.head(50)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0abc847a-e200-4f2f-bca3-ee9b0c15a063","_uuid":"1ce9fe14ac2bdcef15f6f3ad710938189d740ff2"},"cell_type":"markdown","source":"<span id=\"split\"></span>\n# 1. Split your dataset\n\nlet's start by splitting our data into separate training and test sets. \n\n<br>\n**First, separate the dataframe into separate objects for the target variable, <code style=\"color:steelblue\">y</code>, and the input features, <code style=\"color:steelblue\">X</code>.**"},{"metadata":{"collapsed":true,"_cell_guid":"a89ba4e6-3310-4a3f-acf0-ae1c0a5dc3b0","_uuid":"6841bb0ef0506860dcbc3ae72a111fa54d051c14","trusted":false},"cell_type":"code","source":"# Create separate object for target variable\ny = df.Class\n\n# Create separate object for input features\nX = df.drop('Class', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"73c14cfe-f6e1-47f4-b40b-73338e21a653","_uuid":"21cd928f7c30d47e43e55afce68582014d3a57f4"},"cell_type":"markdown","source":"**After you've imported the <code style=\"color:steelblue\">train_test_split()</code> function, split <code style=\"color:steelblue\">X</code> and <code style=\"color:steelblue\">y</code> into training and test sets.**\n* Pass in the argument <code style=\"color:steelblue\">test_size=<span style=\"color:crimson\">0.2</span></code> to set aside 20% of our observations for the test set.\n* Pass in <code style=\"color:steelblue\">random_state=<span style=\"color:crimson\">1234</span></code> to set the random state for replicable results.\n* **Important:** Also pass in the argument <code style=\"color:steelblue\">stratify=<span style=\"color:crimson\">df.Class</span></code> in order to make sure the target variable's classes are balanced in each subset of data! This is **stratified random sampling**.\n* Then, print the number of observations in each subset to check that it was done correctly."},{"metadata":{"_cell_guid":"56293216-124c-49c9-bee4-f22ad3e34805","_uuid":"4f3d0d20b832fe61d426329ea31ddfe4e018349a","trusted":false,"collapsed":true},"cell_type":"code","source":"# Split X and y into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234, stratify=df.Class)\n\n# Print number of observations in X_train, X_test, y_train, and y_test\nprint( len(X_train), len(X_test), len(y_train), len(y_test) )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eece2cae-5ed9-4bf7-9df9-7781fda1767e","_uuid":"2b3e0f2d5a053f6a0b5fd2cf19c8b2fd341e5dda"},"cell_type":"markdown","source":"<span id=\"pipelines\"></span>\n# 2. Build model pipelines\n\nNext, let's set up preprocessing pipelines for each of our algorithms.\n\n<br>\n**Create a single <span style=\"color:royalblue\">pipeline dictionary</span> with pipelines for each algorithm**.\n* Use the keys:\n    * <code style=\"color:crimson\">'l1'</code> for $L_1$-regularized logistic regression\n    * <code style=\"color:crimson\">'l2'</code> for $L_2$-regularized logistic regression\n    * <code style=\"color:crimson\">'rf'</code> for random forest\n    * <code style=\"color:crimson\">'gb'</code> for gradient boosted tree.\n* Each pipeline should standardize the data first.\n* Remember to set <code style=\"color:steelblue\">random_state=<span style=\"color:crimson\">123</span></code> for each algorithm to ensure replicable results."},{"metadata":{"collapsed":true,"_cell_guid":"d37a5c67-3751-4089-a54c-b8a560ff052c","_uuid":"1664f49920849d9ce1582ffc7249e52673443af2","trusted":false},"cell_type":"code","source":"# Pipeline dictionary\npipelines = {\n    'l1': make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', random_state=123)),\n    'l2': make_pipeline(StandardScaler(), LogisticRegression(penalty='l2', random_state=123)),\n    'rf': make_pipeline(StandardScaler(), RandomForestClassifier(random_state=123)),\n    'gb': make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=123))\n}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c0931a29-188d-434a-87dd-0916895c7058","_uuid":"9af38a493de691bf11cdbf139b9b1069f7a2ce63"},"cell_type":"markdown","source":"<span id=\"hyperparameters\"></span>\n# 3. Declare hyperparameters to tune\n\nNext, let's declare hyperparameters to tune.\n\n<br>\n**First, list the tunable hyperparameters of your $L_1$-regularized logistic regression pipeline.**"},{"metadata":{"_cell_guid":"46e62de0-dc9e-43ee-b4c1-f3cdf666573a","_uuid":"344021427c565f227093c50cf794f0dd84353a32","trusted":false,"collapsed":true},"cell_type":"code","source":"# List tuneable hyperparameters of our Logistic pipeline\npipelines['l1'].get_params()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3a9160e6-acff-415a-89aa-78bf42ef6e98","_uuid":"7b750652b5df993cb8476cfe35f9c743909f46a0"},"cell_type":"markdown","source":"Let's declare the **hyperparameter grids** to tune."},{"metadata":{"collapsed":true,"_cell_guid":"ba87cf73-9447-41da-bd05-aa07e296d156","_uuid":"d0a995af6e7b7fe9045edd4b09192466911203e8","trusted":false},"cell_type":"code","source":"# Logistic Regression hyperparameters\nl1_hyperparameters = {\n    'logisticregression__C' : np.linspace(1e-3, 1e3, 10),\n}\n\nl2_hyperparameters = {\n    'logisticregression__C' : np.linspace(1e-3, 1e3, 10),\n}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bf2f7f80-0839-44d4-b07c-f57261a1480c","_uuid":"c05525539f0187f70a1a3703e5a0039f88729514"},"cell_type":"markdown","source":"**Declare the hyperparameter grid for the random forest.**"},{"metadata":{"collapsed":true,"_cell_guid":"3aa035c5-a4ee-4a4c-b6b5-ad514705842a","_uuid":"c0fc609965f31f982cec1dd7c825518966907b73","trusted":false},"cell_type":"code","source":"# Random Forest hyperparameters\nrf_hyperparameters = {\n    'randomforestclassifier__n_estimators': [100, 200],\n    'randomforestclassifier__max_features': ['auto', 'sqrt', 0.33]\n}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eff72252-d065-42d0-8c86-9c3f830fbb57","_uuid":"1bd69a1b5b53e6607ceb3ef7194890788c274725"},"cell_type":"markdown","source":"**Declare the hyperparameter grid for the boosted tree.**"},{"metadata":{"collapsed":true,"_cell_guid":"4ccf7214-3e92-42fb-80bc-c94bea710296","_uuid":"7f3fd183efb5a02a579e43b0e17d2f60e737b272","trusted":false},"cell_type":"code","source":"# Boosted Tree hyperparameters\ngb_hyperparameters = {\n    'gradientboostingclassifier__n_estimators': [100, 200],\n    'gradientboostingclassifier__learning_rate': [0.05, 0.1, 0.2],\n    'gradientboostingclassifier__max_depth': [1, 3, 5]\n}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b9c76939-f993-4894-8bdd-9965c6e22365","_uuid":"faf883811476e61b041c1b5156de4c7c8f9b6db4"},"cell_type":"markdown","source":"**Create a <code style=\"color:steelblue\">hyperparameters</code> dictionary**.\n* Use the same keys as in the <code style=\"color:steelblue\">pipelines</code> dictionary."},{"metadata":{"collapsed":true,"_cell_guid":"c453b8f1-fb57-4c0b-9564-7c50f010a484","_uuid":"d466f6f851358d61531b921c42f7d61a4692d4ed","trusted":false},"cell_type":"code","source":"# Create hyperparameters dictionary\nhyperparameters = {\n    'l1' : l1_hyperparameters,\n    'l2' : l2_hyperparameters,\n    'rf' : rf_hyperparameters,\n    'gb' : gb_hyperparameters\n}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"49e1f3f6-104e-4a4c-99a4-8d08d2529114","_uuid":"33256955c8e19a42b629e996b3696b9d7c376941"},"cell_type":"markdown","source":"<span id=\"fit-tune\"></span>\n# 4. Fit and tune models with cross-validation\n\nNow that we have our <code style=\"color:steelblue\">pipelines</code> and <code style=\"color:steelblue\">hyperparameters</code> dictionaries declared, we're ready to tune our models with **cross-validation**.\n\n<br>\n**Create a <code style=\"color:SteelBlue\">fitted_models</code> dictionary that includes models that have been tuned using cross-validation.**\n* The keys should be the same as those in the <code style=\"color:SteelBlue\">pipelines</code> and <code style=\"color:SteelBlue\">hyperparameters</code> dictionaries. \n* The values should be <code style=\"color:steelblue\">GridSearchCV</code> objects that have been fitted to <code style=\"color:steelblue\">X_train</code> and <code style=\"color:steelblue\">y_train</code>.\n* After fitting each model, print <code style=\"color:crimson\">'{name} has been fitted.'</code> just to track the progress.\n* (Optionally) You can set <code style=\"color:steelblue\">n_jobs=<span style=\"color:crimson\">-1</span></code> to use as many cores as available on your computer.\n\nThis step can take a few minutes, so please be patient."},{"metadata":{"_cell_guid":"ea964428-3075-4701-8b8c-793b62c94df0","_uuid":"b65710697b1c79f943547f2b84910803b8a4ace6","trusted":false,"collapsed":true},"cell_type":"code","source":"# Create empty dictionary called fitted_models\nfitted_models = {}\n\n# Loop through model pipelines, tuning each one and saving it to fitted_models\nfor name, pipeline in pipelines.items():\n    # Create cross-validation object from pipeline and hyperparameters\n    model = GridSearchCV(pipeline, hyperparameters[name], cv=10)\n    \n    # Fit model on X_train, y_train\n    model.fit(X_train, y_train)\n    \n    # Store model in fitted_models[name] \n    fitted_models[name] = model\n    \n    # Print '{name} has been fitted'\n    print(name, 'has been fitted.')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1bdf3e13-0aad-4a8b-9a59-659f93dffe14","_uuid":"bd80a9c89c855ea551b6b3879c96eb8d482a5e77"},"cell_type":"markdown","source":"<span id=\"evaluate\"></span>\n# 5. Evaluate metrics\n\nFinally, it's time to evaluate our models and pick the best one.\n\n<br>\n**First, display the <code style=\"color:steelblue\">best\\_score_</code> attribute for each fitted model.**"},{"metadata":{"collapsed":true,"_cell_guid":"ef5c636a-8ab2-46de-9e37-e48cc2ab013b","_uuid":"6f2345b0a41cc26b5b47e887712d8c8c015d0721","trusted":false},"cell_type":"code","source":"# Display best_score_ for each fitted model\nfor name, model in fitted_models.items():\n    print( name, model.best_score_ )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b781f10c-4b99-470f-9fa3-a590351f6587","_uuid":"df57d6fdc2b0cfb3a382ceb898a777a0b0d9168c"},"cell_type":"markdown","source":"<span id=\"auroc\"></span>\n# 6. Area under ROC (Receiver Operating Characteristics) curve\n\n**Area under ROC curve** is one of the most reliable metric for classification tasks."},{"metadata":{"collapsed":true,"_cell_guid":"32d9bd25-aa06-4c49-9002-7c2be6654d77","_uuid":"a268ae9501c833111e28ac1fe8abc092b0ce80ed","trusted":false},"cell_type":"code","source":"# Code here\nfor name, model in fitted_models.items():\n    pred = model.predict_proba(X_test)\n    pred = [p[1] for p in pred]\n    \n    fpr, tpr, thresholds = roc_curve(y_test, pred)\n    print( name, auc(fpr, tpr) )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"16edb4e7-9c22-4ae3-8914-951fe9b56e38","_uuid":"c39ce8b6fcad7631b1aba06ff488199a8fa2d107"},"cell_type":"markdown","source":"<span id=\"auroc\"></span>\n# 7. Area under PR (Precision Recall) curve\n\nStraight accuracy (Holdout Accuracy) score from cross-validation is not always the best way to evaluate a classification model especially for class imbalance problems. **Area under PR curve** is one of the most reliable metric for classification tasks and should be used for measuring accuracy for or class imbalance problems like this one."},{"metadata":{"_cell_guid":"9d02a4db-30af-4e7d-91da-d6244b1da1a8","_uuid":"8093c8073b53cf5d59ac45ae3a4098b7b2a09600"},"cell_type":"markdown","source":"First, let's plot the precision recall curve."},{"metadata":{"_cell_guid":"2657b4e9-32dc-493a-8d84-51dc36e3d88b","_uuid":"8704a11e6d81932ef6610d2c334b16d0b000ae3b","trusted":false,"collapsed":true},"cell_type":"code","source":"precision, recall, thresholds = precision_recall_curve(y_test, pred)\n\n# Initialize figure\nfig = plt.figure(figsize=(8,8))\nplt.title('Precision Recall')\n\nplt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n\n# Plot PR curve\nplt.plot(precision, recall, label='l1')\nplt.legend(loc='lower right')\n\n# Diagonal 45 degree line\nplt.plot([0,1],[0,1],'k--')\n\n# Axes limits and labels\nplt.xlim([-0.1,1.1])\nplt.ylim([-0.1,1.1])\nplt.ylabel('Precision')\nplt.xlabel('Recall')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a94a0ac4-929a-45ea-88ac-bca9fde333af","_uuid":"7645b0c206633ef882e3998a4f1ba3b020c7565a"},"cell_type":"markdown","source":"Next, let's calculate AUPR, using the <code style=\"color:steelblue\">auc()</code> function in conjunction with the <code style=\"color:steelblue\">precision_recall_curve()</code> function."},{"metadata":{"collapsed":true,"_cell_guid":"dd1eb0e7-b436-4c4c-a992-afa5c8f4aa50","_uuid":"f9c6c341c8f67a50d7805c37f786151915ecaa9a","trusted":false},"cell_type":"code","source":"# Code here\nfor name, model in fitted_models.items():\n    pred = model.predict_proba(X_test)\n    pred = [p[1] for p in pred]\n    \n    precision, recall, thresholds = precision_recall_curve(y_test, pred)\n    print( name, auc(recall, precision) )","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"2824f9d2-e35b-4127-9a69-27b1a1c65b05","_uuid":"287bf1273e45bddf7e3ea270492761d2c87509f9","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"53fc2e14-566b-4a29-a842-1d592421dc37","_uuid":"081aa3c4433617563fe1cfdf0fe8a7ca20803986","trusted":false},"cell_type":"code","source":"# Save winning model as winning_model.pkl\nwith open('winning_model.pkl', 'wb') as f:\n    pickle.dump(fitted_models['rf'].best_estimator_, f)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}