{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# cross-validation and resampling for heavily imbalanced data\n\nIn this notebook, I will demonstrate good methodology for evaluating a classifier on this data set using k-fold cross-validation.  I write this notebook because many of the top rated kaggle kernels for this data set have major overfitting problems or use the wrong metrics.\n\nWe will only evaluate a logistic regression model for the sake of example. The code is flexible enough  that you can use it to evaluate whatever other Scikit-learn classifier (or wrapped classifier) you like.  \n\nWe experiment with over/undersampling using the different samplers available from the imblearn package.\n\n### Methods and common mistakes\n\n- **Area under the precision-recall curve:** In this notebook, we choose AUPRC as our evaluation metric, as recommended on the [kaggle dataset page](https://www.kaggle.com/mlg-ulb/creditcardfraud) for heavily imbalanced datasets with few positive samples where the goal is to detect as many of the postive examples as possible.  This is explained nicely i [this blog post](https://towardsdatascience.com/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba). AUPRC is not one of the metrics directly included in sklearn, so we create our own function.\n\n- **Do not over-sample before k-fold cross-validation:** Over-sampling before performing the k-fold split introduces identical samples in the training and test sets for each fold, which leads to an overestimate of model performance.  This is explained very nicely in this [blog post](https://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation).  There are various different methods of over/under sampling provided by the imblearn package. We compare these methods. Over/under-sampling is also crucial when training neural networks with sgd.\n\n- **Do not do feature selection before cross-validation:** In discussions about the creditcard dataset several people point out that some models seem to perform better or worse when the Time feature is excluded. One may also observe from distribution plots that Time does not appear to be correlated with Fraud.  However, using a distribution plot or any other analysis of the whole data set to perform feature selection before performing the cross-validation split will result in overestimating model performance, so we do not do it here.\n\n- **Don't test on resampled data:** Although we use resampling for the training sets, test sets should be as representative as the \"true\" distribution as possible.  \n\n- **Use stratified k-folds:** Since there are so few positive examples in the dataset (~400/300,000), it is important that each fold has a representative number of positive examples. "},{"metadata":{"collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# functions needed for pr_auc_score()\nfrom sklearn.metrics import auc, precision_recall_curve\n\n# functions needed for imbalanced_cross_validation_score()\nfrom sklearn.model_selection import StratifiedKFold\n\n# sampler objects\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Classification models to compare\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.neural_network import MLPClassifier","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"f51dcaa1-7cf8-4aaa-9c82-bd1828f92e08","_uuid":"dd0d5c15253a145f10d0d6dccca767e34139daac","trusted":true},"cell_type":"code","source":"# load data\ndf = pd.read_csv(\"../input/creditcard.csv\")\nA  = df.values\nx  = A[:,:-1]     \ny  = A[:,-1]","execution_count":5,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"a8befcd5-ff4b-49b2-a556-d98cc1fe9f99","_uuid":"6b769b3e48b6323d2ebb9bc53eec6a09a56a21fa","trusted":true},"cell_type":"code","source":"def pr_auc_score(clf, x, y):\n    '''\n        This function computes area under the precision-recall curve. \n    '''\n      \n    precisions, recalls,_ = precision_recall_curve(y, clf.predict_proba(x)[:,1], pos_label=1)\n    \n    return auc(recalls, precisions)","execution_count":6,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"7aa5624e-9f73-416e-9e66-cf26720a6ecd","_uuid":"4119f7b7d18a6dca1d856d5ad2c2221fb989f30f","trusted":true},"cell_type":"code","source":"def imbalanced_cross_validation_score(clf, x, y, cv, scoring, sampler):\n    '''\n        This function computes the cross-validation score of a given \n        classifier using a choice of sampling function to mitigate \n        the class imbalance, and stratified k-fold sampling.\n        \n        The first five arguments are the same as \n        sklearn.model_selection.cross_val_score.\n        \n        - clf.predict_proba(x) returns class label probabilities\n        - clf.fit(x,y) trains the model\n        \n        - x = data\n        \n        - y = labels\n        \n        - cv = the number of folds in the cross validation\n        \n        - scoring(classifier, x, y) returns a float\n        \n        The last argument is a choice of random sampler: an object \n        similar to the sampler objects available from the python \n        package imbalanced-learn. In particular, this \n        object needs to have the method:\n        \n        sampler.fit_sample(x,y)\n        \n        See http://contrib.scikit-learn.org/imbalanced-learn/\n        for more details and examples of other sampling objects \n        available.  \n    \n    '''\n    \n    cv_score = 0.\n    train_score = 0.\n    test_score = 0.\n    \n    # stratified k-fold creates folds with the same ratio of positive \n    # and negative samples as the entire dataset.\n    \n    skf = StratifiedKFold(n_splits=cv, random_state=0, shuffle=False)\n    \n    for train_idx, test_idx in skf.split(x,y):\n        \n        xfold_train_sampled, yfold_train_sampled = sampler.fit_sample(x[train_idx],y[train_idx])\n        clf.fit(xfold_train_sampled, yfold_train_sampled)\n        \n        train_score = scoring(clf, xfold_train_sampled, yfold_train_sampled)\n        test_score  = scoring(clf, x[test_idx], y[test_idx])\n        \n        print(\"Train AUPRC: %.2f Test AUPRC: %.2f\"%(train_score,test_score))\n\n        cv_score += test_score\n        \n    return cv_score/cv","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"cf9be8d7-16f3-4dba-bfde-8c12d08f9f82","_uuid":"d82cbaf5b3da427ee0a6b80a2c0a2c31caa20ddf"},"cell_type":"markdown","source":"## Basic models\n\nLet's compare several basic models with different types of \nover/under sampling. We will use \n\n    RandomOverSampler()\n\n    SMOTE()\n\n    ADASYN() \n\n    RandomUnderSampler() \n\nDocumentation about these samplers can be found here:\nhttp://contrib.scikit-learn.org/imbalanced-learn/\n\nWe use 5-fold validation for all our tests, for the sake of \nspeed. One could also try 10-fold with a bit of patience."},{"metadata":{"collapsed":true,"_cell_guid":"b8c9fddc-ce67-49bb-99c6-c07573627ca6","_uuid":"bdd0daab7b78ee389da46238b1f751ce369cd004","trusted":true},"cell_type":"code","source":"cv = 5  \n\nRegressionModel    = LogisticRegression()\n\n# here are some other models you could try. You can also try grid searching their hyperparameters\nRandomForrestModel = RandomForestClassifier()\nExtraTreesModel    = ExtraTreesClassifier()\nAdaBoostModel      = AdaBoostClassifier()","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"d952252e-b826-4d51-9a3a-35b8d9a8e7e1","_uuid":"f64fa62ed73dd06dc112649d8c0ea1bd6210c8f9","trusted":true},"cell_type":"code","source":"# Logistic regression score with Random Over-sampling\nprint(\"Random over-sampling\")\nscore = imbalanced_cross_validation_score(RegressionModel, x, y, cv, pr_auc_score, RandomOverSampler())\nprint(\"Cross-validated AUPRC score: %.2f\"%score)\n\n# Logistic regression score with SMOTE\nprint(\"SMOTE over-sampling\")\nscore = imbalanced_cross_validation_score(RegressionModel, x, y, cv, pr_auc_score, SMOTE())\nprint(\"Cross-validated AUPRC score: %.2f\"%score)\n\n# Logistic regression score with ADASYN\nprint(\"ADASYN over-sampling\")\nscore = imbalanced_cross_validation_score(RegressionModel, x, y, cv, pr_auc_score, ADASYN())\nprint(\"Cross-validated AUPRC score: %.2f\"%score)\n\n# Logistic regression score with Random Under Sampling\nprint(\"Random under-sampling\")\nscore = imbalanced_cross_validation_score(RegressionModel, x, y, cv, pr_auc_score, RandomUnderSampler())\nprint(\"Cross-validated AUPRC score: %.2f\"%score)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"066f4d44-00f4-4214-b745-0572dae617b5","_uuid":"05739fba9f3fe9d05ba011d031e55c739a5eb3b1","trusted":false},"cell_type":"code","source":"# for fun, let's plot one of the precision-recall curves that is computed above\n#\nsampler = SMOTE()\nskf = StratifiedKFold(n_splits=cv, random_state=0, shuffle=False)\nclf = RegressionModel\n\ntrain_idx, test_idx = skf.split(x,y).__next__()\nxfold_train_sampled, yfold_train_sampled = sampler.fit_sample(x[train_idx],y[train_idx])\n\nclf.fit(xfold_train_sampled, yfold_train_sampled)\n\nprecisions, recalls,_ = precision_recall_curve(y[test_idx], clf.predict_proba(x[test_idx])[:,1], pos_label=1)\n\nplt.step(recalls, precisions, color='b', alpha=0.2,\n         where='post')\nplt.fill_between(recalls, precisions, step='post', alpha=0.2,\n                 color='b')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.0, 1.05])\nplt.xlim([0.0, 1.0])\nplt.title('Precision-Recall curve')","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}