{"cells":[{"metadata":{"_uuid":"7180c2d71c29da64336f28cbeabbf84e82718183"},"cell_type":"markdown","source":"# Exploratry Data Analysis and Prediction Model for Cuisine Prediction"},{"metadata":{"_uuid":"750029c5ba235659e42dc285699a2f7f99787b5c"},"cell_type":"markdown","source":"![](https://timesofoman.com/uploads/images/2017/10/04/746773.jpg)"},{"metadata":{"_uuid":"4504051c6e30c4f85432a1e0fb0eccbeac0f2598"},"cell_type":"markdown","source":"## 1. Import "},{"metadata":{"_uuid":"f45e5a2f071ff6b37c5f27f5ddf8427fad2bd5c6"},"cell_type":"markdown","source":"### 1.1. Import Library"},{"metadata":{"trusted":true,"_uuid":"fbc1a56e886e6a8174a035b32192ec00957f5e22"},"cell_type":"code","source":"# System\nimport sys\nimport os\nfrom os import path\nimport argparse\n\n# Time\nimport time\nimport datetime\n\n# Numerical Data\nimport random\nfrom random import shuffle\nimport numpy as np \nimport pandas as pd\n\n# Tools\nimport itertools\nfrom glob import glob\n\n# NLP\nimport re\nimport nltk\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import SnowballStemmer, WordNetLemmatizer\nfrom bs4 import BeautifulSoup\n\n# Preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.utils import class_weight as cw\n\n# Model Selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n\n# Machine Learning Models\nfrom sklearn import svm\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.multiclass import OneVsRestClassifier\n\n# Evaluation Matrics\nfrom sklearn import metrics \nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\n# Graph/ Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Image\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS\n\nimport json\n\nnp.random.seed(7)\n\nlemmatizer = WordNetLemmatizer()\nstemmer=SnowballStemmer('english')\n\n%matplotlib inline\n\n# Input data\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b60d1b47a4dc4b19532599ae09ef084cb562ce9"},"cell_type":"markdown","source":"## 2. Read Data"},{"metadata":{"trusted":true,"_uuid":"f4a63bfa22e0b25dd8888b7fe08c3bc3da2b9534"},"cell_type":"code","source":"def read_data(path):\n    return json.load(open(path)) \n\ndef generate_text(data):\n    text_data = [\" \".join(x['ingredients']).lower() for x in data]\n    return text_data \n\ndef prep(t):\n    for i in range(len(t)):\n        text = t[i].lower().split(\" \")\n        text = [re.sub(\"[^a-zA-Z\\s+]\", \"\", t) for t in text]\n        text = [re.sub(\"\\s+\", \"-\", t) for t in text]\n        text = [t.strip() for t in text if t.strip()!=\"\"]\n        t[i] = \" \".join(text)\n    return t\n\n\ndef get_tok(text):\n    t = []\n    for i in text:\n        t.extend(i.split(\" \"))\n    t = list(set(t))\n    return t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd871325f4c7f6bcd8276f016b699f3b7bcd05fb"},"cell_type":"code","source":"train = read_data('../input/train.json')\ntest = read_data('../input/test.json')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7cc9872ad6262949db6d81b42e429d6ff09f2872"},"cell_type":"markdown","source":"## 2. Preprocess Data"},{"metadata":{"trusted":true,"_uuid":"814c72951111fa25a79db2131881940d430c52b3"},"cell_type":"code","source":"test_id = [doc['id'] for doc in test]\ntrain_text = generate_text(train)\ntest_text = generate_text(test)\ntarget = [doc['cuisine'] for doc in train]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5577c09fc602263913e0e764ceee9d0729758712"},"cell_type":"code","source":"train_text = prep(train_text)\ntest_text = prep(test_text)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b32763d1f261dc23733ab1af79270de86270923c"},"cell_type":"markdown","source":"## 3. Visualization"},{"metadata":{"trusted":true,"_uuid":"5e76a04e967090726a56a0fdb6db1ff1f061add0"},"cell_type":"code","source":"def get_params():\n    params = {'legend.fontsize' : 'Large',\n              'figure.figsize'  : (16,8),\n              'axes.labelsize'  : 'x-large',\n              'axes.titlesize'  : 'xx-large',\n              'xtick.labelsize' : 'Large',\n              'ytick.labelsize' : 'Large'}\n    return params","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0b4662ba7c74d2083415bad63cba5bad3ff2c80"},"cell_type":"markdown","source":"### 3.1. Showing Recipe Count per Cuisine"},{"metadata":{"trusted":true,"_uuid":"5ee21cd0b039b4f5a7b98c3a7d4390e4fcb391ee"},"cell_type":"code","source":"# sns.set(style=\"ticks\")\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(16,8))\nparams = get_params()\nplt.rcParams.update(params)\nplt.tick_params(labelsize=12)\nsns.countplot(y=target)\nplt.yticks(fontsize=18)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94e78ffe99c2d772a2b7cb9931e64133c279d7b1"},"cell_type":"markdown","source":"## 4. Preprocessing "},{"metadata":{"trusted":true,"_uuid":"6fc7c89654d9b6d112f73245f0dbebc95e5599af"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train_text, target, test_size=.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a61d5a893033a3f3134a02a98e89bc9aaf83c7a1"},"cell_type":"code","source":"vect = TfidfVectorizer()\n\nvect.fit(X_train)\n\nX_train_df = vect.transform(X_train)\nX_test_df = vect.transform(X_test)\n\ntest_text_df = vect.transform(test_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc530270bd836f9d55d315f0e0bdb4a11bba085b"},"cell_type":"code","source":"lbl_enc = LabelEncoder()\ny_train_label = lbl_enc.fit_transform(y_train)\n\nlbl_enc_test = LabelEncoder()\ny_test_label = lbl_enc_test.fit_transform(y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efc22fc7d190d8a468ec68ddad87bddc30a3bbad"},"cell_type":"markdown","source":"## 5. Training "},{"metadata":{"trusted":true,"_uuid":"57e575ce065cdeb4e5f00cb6ca322f1d4135b668"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n# parameters = {'C': np.arange(1, 100, 5)}\nmodel = LinearSVC()\n# model = LogisticRegression(multi_class='multinomial')\n# model = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n# model = SVC()\n\nmodel = OneVsRestClassifier(model)\n# model = BaggingRegressor(model, n_estimators=100)\n# model = GridSearchCV(model, parameters, n_jobs=-1, verbose=2, cv=3)\n\nprint(cross_val_score(model, X_train_df, y_train_label, scoring='accuracy', n_jobs=-1, cv=3)) \n\nmodel.fit(X_train_df, y_train_label)\nmodel.score(X_test_df, y_test_label)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1396a3e5ba03f7cff0b98a81488f26a259735010"},"cell_type":"markdown","source":"## 6. Prediction "},{"metadata":{"trusted":true,"_uuid":"f701c42b98715d3a72805e40b8f27cd88e2a4798"},"cell_type":"code","source":"y_pred = model.predict(test_text_df)\ny_pred = lbl_enc_test.inverse_transform(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0947457c257df9cffe6f682159148c6deeb7cf50"},"cell_type":"code","source":"df = pd.DataFrame({'cuisine' : y_pred , 'id' : test_id }, columns=['id', 'cuisine'])\ndf.to_csv('submission.csv', index = False)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47d32609c5fe176f181c4c58d1c1e5da937dd322","_kg_hide-input":true},"cell_type":"code","source":"# from sklearn.linear_model import LogisticRegression\n# from sklearn.ensemble import VotingClassifier, RandomForestClassifier, AdaBoostClassifier\n\n# clf1 = LogisticRegression()\n# clf1 = OneVsRestClassifier(clf1, n_jobs=-1)\n\n# clf2 = model = LinearSVC()\n# clf2 = OneVsRestClassifier(clf2, n_jobs=-1)\n\n\n# model = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)])\n\n\n# # model = AdaBoostClassifier(n_estimators=100)\n# r = np.arange(0.1, 1, 0.1)\n\n# parameters = {'C': r}\n\n# # model = GridSearchCV(model, parameters, n_jobs=-1, verbose=2, cv=3)\n\n# model.fit(X_train_df, y_train_label)\n# # print(cross_val_score(model, X_train_df, y_train_label, scoring='accuracy', n_jobs=-1, cv=3)) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d545e7410b8f905df0c164c353560cff3c03e2a1"},"cell_type":"markdown","source":"# Reference\n1. [Shivam Bansal's TF-IDF with OvR SVM : What's Cooking](https://www.kaggle.com/shivamb/tf-idf-with-ovr-svm-what-s-cooking)"},{"metadata":{"_uuid":"3b9dbf60b994cc32466ec21326a1335fa76c3cf9"},"cell_type":"markdown","source":"# Image Credit\n1. https://timesofoman.com/uploads/images/2017/10/04/746773.jpg"},{"metadata":{"trusted":true,"_uuid":"ad5874ef6a06c855a8e3b8f9d8cf05cb8b01c6e1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}