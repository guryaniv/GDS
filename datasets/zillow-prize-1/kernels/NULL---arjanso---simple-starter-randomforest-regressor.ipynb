{"nbformat": 4, "cells": [{"execution_count": null, "cell_type": "markdown", "source": "<h1> This Notebook takes all steps from loading data & packages to creating a submission .csv file </h1>\n<p>The goal here is to show a basic example script that runs reasonably fast. Therefore, certain columns are eliminated and the RandomForest is fitted with a relatively low number of estimators </p>\n<ol>\n<li> Packages are imported</li>\n<li> Configuration is set </li>\n<li> Data is loaded </li>\n<li> Data is prepared for model  </li>\n<li> RandomForestRegressor is trained </li>\n<li> Results are evaluated </li>\n<li> Prediction submission file is made </li>\n</ol>", "outputs": [], "metadata": {"_uuid": "bd5272bf57de390e8f81b9d0a7e83a3670adae33", "collapsed": false, "_cell_guid": "860c267d-8c47-4432-9853-21bf3496fc70", "_execution_state": "idle"}}, {"execution_count": null, "cell_type": "markdown", "source": "<h2> 1 | Packages </h2>", "outputs": [], "metadata": {"_uuid": "167fa527cc414b782bee3d0d7965626e82ee6a9b", "collapsed": false, "_cell_guid": "e140714a-e14c-456d-9ade-733cef080895", "_execution_state": "idle"}}, {"execution_count": null, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nimport os\nimport re\nimport random\nimport datetime\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV", "outputs": [], "metadata": {"_uuid": "1fbc10e40dcfed9d695bd3746a5d0575bf05ca9e", "_execution_state": "busy", "_cell_guid": "24d7540f-0e24-48db-b12e-7a3fb19bd975", "trusted": false}}, {"execution_count": null, "cell_type": "markdown", "source": "<h2> 2 | Configuration </h2>", "outputs": [], "metadata": {"_uuid": "2c12defeb389d790ea44cc4be98b45e3dbf99aa2", "collapsed": false, "_cell_guid": "1311b329-6f21-4f2d-89a5-254512dc18aa", "_execution_state": "idle"}}, {"execution_count": null, "cell_type": "code", "source": "random.seed(3)  #To make the randomization reproducible\npd.options.mode.chained_assignment = None  #To turn off specific warnings", "outputs": [], "metadata": {"_uuid": "08e155a217d85a1d1796971a55b42023076c99f1", "collapsed": false, "_cell_guid": "ad5ed093-ea47-4edb-9a9e-dcf365327f0a", "_execution_state": "busy", "trusted": false}}, {"execution_count": null, "cell_type": "markdown", "source": "<h2> 3 | Load Data </h2>\n", "outputs": [], "metadata": {"_uuid": "6ed9e8d37f464b19f0f525b2ce16c8d2391fd67d", "collapsed": false, "_cell_guid": "1bda58f0-acda-4cb0-a5af-23597cff5d8b", "_execution_state": "idle"}}, {"execution_count": null, "cell_type": "code", "source": "train = pd.read_csv(r\"../input/train_2016_v2.csv\")   #The parcelid's with their outcomes\nprops = pd.read_csv(r\"../input/properties_2016.csv\")  #The properties dataset\nsamp = pd.read_csv(r\"../input/sample_submission.csv\")  #The parcelid's for the testset", "outputs": [], "metadata": {"_uuid": "0b825586640acec47da23b42259949ea5c72bbfd", "collapsed": false, "_cell_guid": "4b688915-0daf-4f7f-a661-3ba8e1c6bd85", "_execution_state": "busy", "trusted": false}}, {"execution_count": null, "cell_type": "markdown", "source": "<h2> 4 | Prepare Data </h2>", "outputs": [], "metadata": {"_uuid": "3abc0c230c5bcfc3e11303b53dbb69df945238f5", "collapsed": false, "_cell_guid": "3891e67a-138c-4a8c-b06a-615ceaa83e7e", "_execution_state": "idle"}}, {"execution_count": null, "cell_type": "code", "source": "props = props.select_dtypes(exclude=[object])  #For this example, we take only numerical data, since strings require more processing\nprops.fillna(-1,inplace=True)  #Fill missing data so we can run the model\ntrain = train.loc[:,['parcelid','logerror']].merge(props,how='left',left_on='parcelid',right_on='parcelid')\ntrain_x = train.drop(['parcelid','logerror'],axis=1,inplace=False)\ntrain_y = train['logerror']\n\ntest = samp.loc[:,['ParcelId']].merge(props,how='left',left_on='ParcelId',right_on='parcelid')\ntest_x = test.drop(['ParcelId','parcelid'],axis=1,inplace=False)", "outputs": [], "metadata": {"_uuid": "eaabecfca73d074f3f8111b9e22b0665f3ecc48d", "collapsed": false, "_cell_guid": "4e32ec40-d961-4883-9fbd-1674d1043f51", "_execution_state": "busy", "trusted": false}}, {"execution_count": null, "cell_type": "markdown", "source": "<h2> 5 | Fit RandomForestRegressor </h2>", "outputs": [], "metadata": {"_uuid": "ce9d643c180e0d48a6b8a752c43feee626b3e850", "collapsed": false, "_cell_guid": "de5011ea-fc5c-47f3-8244-ef4f39293c5c", "_execution_state": "idle"}}, {"execution_count": null, "cell_type": "code", "source": "parameters = {'n_estimators':[5,10,15],'n_jobs':[-1],'oob_score':[False]}  # this can be extended\nmodel = RandomForestRegressor()\ngrid = GridSearchCV(model,param_grid=parameters,scoring='neg_mean_absolute_error',cv=3)  \ngrid.fit(train_x,train_y)", "outputs": [], "metadata": {"_uuid": "877cae89b8aa357815154c43a892c6c5d5ecdfbf", "collapsed": false, "_cell_guid": "62113bd9-4858-4973-b35b-bec7f94a83f7", "_execution_state": "busy", "trusted": false}}, {"execution_count": null, "cell_type": "markdown", "source": "<h2> 6 | Evaluate </h2>\n<p> We can see the test scores in the crossvalidation table. Also, we see the 20 most important features in a column chart. </p>", "outputs": [], "metadata": {"_uuid": "d120085c6bbc015c4e48057fc892c8b3f2a8b63f", "collapsed": false, "_cell_guid": "fca7d586-53d6-43ac-89a8-86a668fa2335", "_execution_state": "idle"}}, {"execution_count": null, "cell_type": "code", "source": "cv_results = pd.DataFrame(grid.cv_results_)\nprint(cv_results[[\"param_n_estimators\",\"mean_test_score\",\"std_test_score\"]])\n\nfeat_imps = grid.best_estimator_.feature_importances_\nfi = pd.DataFrame.from_dict({'feat':train_x.columns,'imp':feat_imps})\nfi.set_index('feat',inplace=True,drop=True)\nfi = fi.sort_values('imp',ascending=False)\nfi.head(20).plot.bar()", "outputs": [], "metadata": {"_uuid": "9b689569c6aa53a39ab674ee74324c0e524c214f", "collapsed": false, "_cell_guid": "e3d06748-04e3-47e0-bd9c-b7ad07a86fca", "_execution_state": "busy", "trusted": false}}, {"execution_count": null, "cell_type": "markdown", "source": "<h2> 7 | Predict and Make Submission File </h2>\n<p> The submission file is prepared with a datetime stamp so that it is not overwrited by consecutive submission files and it remains clear when the submission file was generated. For now, we assume the result is the same fot each month. </p>", "outputs": [], "metadata": {"_uuid": "f5787a6e4ba8edc17e0a0572e454d3b656474e52", "collapsed": false, "_cell_guid": "90a49f3b-e175-48bc-89dc-c433f5d07a3b", "_execution_state": "idle"}}, {"execution_count": null, "cell_type": "code", "source": "test_y = grid.predict(test_x)\ntest_y = pd.DataFrame(test_y)\ntest_y[1] = test_y[0]\ntest_y[2] = test_y[0]\ntest_y[3] = test_y[0]\ntest_y[4] = test_y[0]\ntest_y[5] = test_y[0]  #For simplicity make identical predictions for all months\ntest_y.columns = [\"201610\",\"201611\",\"201612\",\"201710\",\"201711\",\"201712\"]\nsubmission = test_y.copy()\nsubmission[\"parcelid\"] = samp[\"ParcelId\"].copy()\ncols = [\"parcelid\",\"201610\",\"201611\",\"201612\",\"201710\",\"201711\",\"201712\"]\nsubmission = submission[cols]\nfilename = \"Prediction_\" + str(submission.columns[0]) + re.sub(\"[^0-9]\", \"\",str(datetime.datetime.now())) + '.csv'\nprint(filename)\nsubmission.to_csv(filename,index=False)\n", "outputs": [], "metadata": {"_uuid": "ab273524b4ed80d9a403979af549335f4fd174df", "collapsed": false, "_cell_guid": "1268302d-9815-405c-a66e-e299c9368c3b", "_execution_state": "busy", "trusted": false}}], "nbformat_minor": 0, "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"version": "3.6.1", "file_extension": ".py", "name": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python"}}}