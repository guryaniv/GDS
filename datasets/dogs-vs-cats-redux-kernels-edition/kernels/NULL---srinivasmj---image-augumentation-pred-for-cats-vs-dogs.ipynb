{"cells": [{"metadata": {"_uuid": "5b2018fb96e463de37133c8e9b660fc1cd529c81", "_cell_guid": "01a9b8ab-8655-4b05-8f62-a29711f84567"}, "cell_type": "markdown", "source": ["## Seperate Cat & Dog Images\n", "\n", "[This blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)  inspired me to run this kernal. My objective of running this kernal is to achieve >90% of score by using modern deep learning techniques with only the 8% of the dataset\n", "\n", "Here i tried with Batch Normalization, Image Augumentation, and 125 epochs to reach my goal. Adding Description is in progress"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "54be226c57691fde2eb5640298dc6cb52fa0b8f2", "collapsed": true, "_cell_guid": "a9ac9563-33c2-4fca-9c9d-93f7c83301e5"}, "source": ["import os, cv2, random\n", "import keras\n", "from keras.models import Sequential\n", "from keras.utils import np_utils\n", "from keras.preprocessing.image import ImageDataGenerator\n", "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n", "from keras.layers import Conv2D, MaxPooling2D\n", "from keras import regularizers, optimizers\n", "\n", "import numpy as np\n", "import PIL\n", "import scipy\n", "import pandas as pd\n", "import h5py\n", "\n", "import matplotlib.pyplot as plt\n", "from matplotlib import ticker\n", "import seaborn as sns\n", "\n", "from tqdm import tqdm\n", "%matplotlib inline \n", "\n", "seed = 7\n", "np.random.seed(seed)"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "419f66ca4693e8198c26e9d1a63e182b107c9735", "collapsed": true, "_cell_guid": "0081fed0-322d-429e-ad02-c0896816ed68"}, "source": ["TRAIN_DIR = '../input/train'\n", "TEST_DIR = '../input/test'\n", "\n", "CHANNELS = 3\n", "\n", "IMG_SIZE = 50\n", "#LR = 0.001\n", "\n", "\n", "dog_images = [i for i in os.listdir(TRAIN_DIR) if i.split('.')[-3]=='dog']\n", "cat_images = [i for i in os.listdir(TRAIN_DIR) if i.split('.')[-3]=='cat']\n", "print(dog_images[:10])\n", "train_input = dog_images[:1000] + cat_images[:1000]\n", "test_images = dog_images[-500:] + cat_images[-500:]\n", "\n", "#test_images = [i for i in os.listdir(TEST_DIR)[:1000]]\n", "print(test_images[-10:])\n", "\n", "    "]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "c7c2f2749628f1bdede6962192c9c56e8384d1dc", "collapsed": true, "_cell_guid": "a4c864bc-633c-468e-aaee-229cfd96788d"}, "source": ["#Feeding only 1000 Dogs and 1000 Cats images into model\n", "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n", "def label_images(img):\n", "    word_label = img.split('.')[-3]\n", "    if word_label == 'cat': return [0, 1]\n", "    elif word_label == 'dog': return [1, 0]\n", "    \n", "def create_train_data():\n", "    training_data = []\n", "    for img in tqdm(train_input):\n", "    #for img in tqdm(os.listdir(TRAIN_DIR)):\n", "        label = label_images(img)\n", "        path = os.path.join(TRAIN_DIR, img)\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE ))\n", "        training_data.append([np.array(img), np.array(label)])\n", "    np.save('training_data.npy', training_data)\n", "        \n", "    return training_data\n", "\n", "       #img = img.reshape(img.shape[0], 3, 50, 50).astype('float32')\n", "             \n", "def processing_test_data():\n", "    test_data = []\n", "    for img in tqdm(test_images):\n", "        label = label_images(img)\n", "        path = os.path.join(TRAIN_DIR, img)\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n", "        test_data.append([np.array(img), np.array(label)])\n", "        \n", "        \n", "    np.save('testing_data.npy', test_data)\n", "    return test_data\n", "\n", "train_data = create_train_data()\n", "test_data = processing_test_data()"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "18fe338738b9c6a8639eec0a2c56ba7c53a18114", "collapsed": true, "_cell_guid": "b4dee36a-9c68-4eb9-81ca-d6b1e50fd568"}, "source": ["train = train_data\n", "test = test_data\n", "#print(test_data[:5])\n", "X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n", "Y = np.array([i[1] for i in train])\n", "#print(Y.shape)\n", "print(\"X_Shape\", X.shape)\n", "print(\"Y_shape\", Y.shape)\n", "X_test = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n", "Y_test = np.array([i[1] for i in test])\n", "print(\"X_test_shape\", X_test.shape)\n", "print(\"Y_test_shape\", Y_test.shape)\n", "\n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "e498cb3f3a5b45acabfab7327b5404a2ffd97780", "collapsed": true, "_cell_guid": "72092143-3373-4ea4-a9fe-25a60720a43a"}, "source": ["from keras.models import Sequential\n", "from keras.layers import Conv2D, MaxPooling2D\n", "from keras.layers import Activation, Dropout, Flatten, Dense\n", "\n", "basefilter = 32\n", "lr = 0.0001\n", "\n", "model = Sequential()\n", "model.add(Conv2D(basefilter, (3,3), padding='same',\n", "                 input_shape=(X.shape[1:])))\n", "model.add(Activation('relu'))\n", "model.add(BatchNormalization())\n", "model.add(Conv2D(basefilter, (3,3), padding='same',\n", "                 input_shape=(X.shape[1:])))\n", "model.add(Activation('relu'))\n", "model.add(BatchNormalization())\n", "model.add(MaxPooling2D(pool_size=(2,2)))\n", "model.add(Dropout(0.2))\n", "\n", "model.add(Conv2D(basefilter*2, (3,3), padding='same',\n", "                 input_shape=(X.shape[1:])))\n", "model.add(Activation('relu'))\n", "model.add(BatchNormalization())\n", "model.add(Conv2D(basefilter*2, (3,3), padding='same',\n", "                 input_shape=(X.shape[1:])))\n", "model.add(Activation('relu'))\n", "model.add(BatchNormalization())\n", "model.add(MaxPooling2D(pool_size=(2,2)))\n", "model.add(Dropout(0.3))\n", "\n", "\n", "model.add(Conv2D(basefilter*4, (3,3), padding='same',\n", "                 input_shape=(X.shape[1:])))\n", "model.add(Activation('relu'))\n", "model.add(BatchNormalization())\n", "model.add(Conv2D(basefilter*4, (3,3), padding='same',\n", "                 input_shape=(X.shape[1:])))\n", "model.add(Activation('relu'))\n", "model.add(BatchNormalization())\n", "model.add(MaxPooling2D(pool_size=(2,2)))\n", "model.add(Dropout(0.4))\n", "\n", "model.add(Flatten())\n", "\n", "model.add(Dense(64))\n", "model.add(Activation('relu'))\n", "model.add(Dropout(0.5))\n", "model.add(Dense(2))\n", "model.add(Activation('sigmoid'))\n", "\n", "model.summary()\n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "bed87b0dfb709e78cf20969f1e646425f5806600", "collapsed": true, "_cell_guid": "57c5f0bb-18b6-4bdf-8eb0-46a1a28f4538"}, "source": ["from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n", "datagen = ImageDataGenerator(rotation_range=40, \n", "                             zoom_range=0.2,\n", "                             shear_range=0.2,\n", "                             horizontal_flip=True,)\n", "\n", "datagen.fit(X)\n", "for X_batch, y_batch in datagen.flow(X, Y):\n", "    X_batch = X_batch[:5]\n", "    \n", "    for img in range(0,5):\n", "        plt.figure(figsize=(5,5))\n", "        plt.imshow(X_batch[img])\n", "        plt.show()\n", "    break\n", "    \n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "55941415cfb97f7390e8681ba6696e30f9bf6715", "collapsed": true, "_cell_guid": "ee99c962-0b44-4320-b83a-b8ae859d1f1f"}, "source": ["#Model Training\n", "batch_size = 100\n", "epochs = 25\n", "\n", "rms_opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n", "\n", "model.compile(loss='binary_crossentropy',\n", "              optimizer=rms_opt,\n", "              metrics=['accuracy'])\n", "    \n", "model.fit_generator(datagen.flow(X, Y, \n", "                                 batch_size=batch_size),\n", "                                 steps_per_epoch=X.shape[0] // batch_size, \n", "                                 epochs = 2*epochs,\n", "                                 verbose=1, validation_data=(X_test, Y_test))\n", "model.save_weights('dog_cats_img_augument_50.h5')\n", "\n", "\n", "scores = model.evaluate(X_test, Y_test, verbose=0)\n", "print(\"Accuracy_50: %.2f%%\" % (scores[1]*100))\n", "\n", "rms_opt = keras.optimizers.rmsprop(lr=0.0003, decay=1e-6)\n", "\n", "model.compile(loss='binary_crossentropy',\n", "              optimizer=rms_opt,\n", "              metrics=['accuracy'])\n", "    \n", "model.fit_generator(datagen.flow(X, Y, \n", "                                 batch_size=batch_size),\n", "                                 steps_per_epoch=X.shape[0] // batch_size, \n", "                                 epochs = 3*epochs,\n", "                                 verbose=1, validation_data=(X_test, Y_test))\n", "model.save_weights('dog_cats_img_augument_75.h5')\n", "\n", "\n", "scores = model.evaluate(X_test, Y_test, verbose=0)\n", "print(\"Accuracy_75: %.2f%%\" % (scores[1]*100))\n", "\n", "rms_opt = keras.optimizers.rmsprop(lr=0.0005, decay=1e-6)\n", "\n", "model.compile(loss='binary_crossentropy',\n", "              optimizer=rms_opt,\n", "              metrics=['accuracy'])\n", "    \n", "model.fit_generator(datagen.flow(X, Y, \n", "                                 batch_size=batch_size),\n", "                                 steps_per_epoch=X.shape[0] // batch_size, \n", "                                 epochs = 5*epochs,\n", "                                 verbose=1, validation_data=(X_test, Y_test))\n", "model.save_weights('dog_cats_img_augument_125.h5')\n", "\n", "\n", "scores = model.evaluate(X_test, Y_test, verbose=0)\n", "print(\"Accuracy_125: %.2f%%\" % (scores[1]*100))"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "5163714ba252b7c6b776a4d42fb33bf3fb205074", "collapsed": true, "_cell_guid": "006fb633-2fdf-4401-9b3b-3adaca903847"}, "source": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "version": "3.6.3", "file_extension": ".py", "nbconvert_exporter": "python"}}, "nbformat": 4, "nbformat_minor": 1}