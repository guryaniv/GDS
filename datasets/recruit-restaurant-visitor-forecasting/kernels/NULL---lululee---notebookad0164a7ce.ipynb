{"nbformat": 4, "cells": [{"outputs": [], "cell_type": "code", "metadata": {}, "source": ["import pandas as pd\n", "import numpy as np\n", "import os,glob\n", "import lightgbm as lgb\n", "file_list = []\n", "for file in glob.glob(\"../input/*.csv\"):\n", "    file_list.append(file)\n", "    print(file)\n"], "execution_count": 9}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["store_relation = pd.read_csv(file_list[1])\n", "store_relation.head()"], "execution_count": 15}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["hpg_store_info = pd.read_csv(file_list[-2])\n", "print(hpg_store_info.head())\n", "hpg_store_info = to_radians(hpg_store_info,'longitude')\n", "\n", "print(len(set(hpg_store_info['hpg_area_name'].values)))"], "execution_count": 16}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["hpg_store_info.at[0,'latitude'] = math.radians(hpg_store_info['latitude'][0])"], "execution_count": 17}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["hpg_reserve = pd.read_csv(file_list[5])\n", "hpg_reserve.head()"], "execution_count": 18}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["air_store_info = pd.read_csv(file_list[-1])\n", "print(air_store_info.head())\n", "print(len(set(air_store_info['air_area_name'].values)))"], "execution_count": 19}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["air_reserve = pd.read_csv(file_list[2])\n", "air_reserve.head()"], "execution_count": 20}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["air_visit = pd.read_csv(file_list[4])\n", "air_visit.head()"], "execution_count": 21}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["date_data = pd.read_csv(file_list[0])\n", "date_data.head()"], "execution_count": 22}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true}, "source": ["from sklearn import preprocessing\n", "import re\n", "import numpy as np\n", "import pandas as pd\n", "import math\n", "def to_radians(df,col_name):\n", "    for i in range(len(df)):\n", "        df.at[i,col_name] = math.radians(df[col_name][i])\n", "    return df\n", "\n", "def merge_dataset(data):\n", "    # merge hpg reserve and id relation according to hpg store id\n", "    data['hpg_reserve'] = pd.merge(data['hpg_reserve'],data['id_relation'],how='inner',on=['hpg_store_id'])\n", "    for df in ['air_reserve','hpg_reserve']:\n", "        data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n", "        data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n", "        data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n", "        data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n", "        data[df]['reserve_datetime_diff'] = data[df].apply(lambda r: (\n", "            r['visit_datetime'] - r['reserve_datetime']).days,axis=1)\n", "        tmp1 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[\n", "            ['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date'\n", "                                                                                 , 'reserve_datetime_diff': 'rs1'\n", "                                                                                 , 'reserve_visitors':'rv1'})\n", "        tmp2 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[\n", "            ['reserve_datetime_diff', 'reserve_visitors']].mean().rename(columns={'visit_datetime':'visit_date',\n", "                                                                                  'reserve_datetime_diff': 'rs2',\n", "                                                                                  'reserve_visitors':'rv2'})\n", "        data[df] = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])\n", "    for df in ['train','test']:\n", "        if df is 'test':\n", "            data[df]['visit_date'] = data['test']['id'].map(lambda x: str(x).split('_')[2])\n", "        data[df]['visit_date'] = pd.to_datetime(data[df]['visit_date'])\n", "        data[df]['dow'] = data[df]['visit_date'].dt.dayofweek\n", "        data[df]['year'] = data[df]['visit_date'].dt.year\n", "        data[df]['month'] = data[df]['visit_date'].dt.month\n", "        data[df]['visit_date'] = data[df]['visit_date'].dt.date\n", "    data['test']['air_store_id'] = data['test']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n", "    unique_stores = data['test']['air_store_id'].unique()\n", "    stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, \n", "                                      'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, \n", "                                   ignore_index=True).reset_index(drop=True)\n", "    for col in ['min_visitors','mean_visitors','median_visitors','max_visitors','count_observations']:\n", "        temp = data['train'].groupby(['air_store_id','dow'], as_index=False)['visitors'].min().rename(columns={\n", "            'visitors':col})\n", "        stores = pd.merge(stores, temp, how='left', on=['air_store_id','dow']) \n", "    stores = pd.merge(stores, data['air_store'], how='left', on=['air_store_id']) \n", "    stores['air_genre_name'] = stores['air_genre_name'].map(lambda x: str(str(x).replace('/',' ')))\n", "    stores['air_area_name'] = stores['air_area_name'].map(lambda x: str(str(x).replace('-',' ')))\n", "    \n", "    encode_label = preprocessing.LabelEncoder()\n", "    for i in range(10):\n", "        stores['air_genre_name'+str(i)] = encode_label.fit_transform(\n", "            stores['air_genre_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n", "        stores['air_area_name'+str(i)] = encode_label.fit_transform(\n", "            stores['air_area_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n", "    stores['air_genre_name'] = encode_label.fit_transform(stores['air_genre_name'])\n", "    stores['air_area_name'] = encode_label.fit_transform(stores['air_area_name'])\n", "    \n", "    data['holiday']['visit_date'] = pd.to_datetime(data['holiday']['visit_date'])\n", "    data['holiday']['day_of_week'] = encode_label.fit_transform(data['holiday']['day_of_week'])\n", "    data['holiday']['visit_date'] = data['holiday']['visit_date'].dt.date\n", "    train = pd.merge(data['train'], data['holiday'], how='left', on=['visit_date']) \n", "    test = pd.merge(data['test'], data['holiday'], how='left', on=['visit_date']) \n", "\n", "    train = pd.merge(train, stores, how='left', on=['air_store_id','dow']) \n", "    test = pd.merge(test, stores, how='left', on=['air_store_id','dow'])\n", "\n", "    for df in ['air_reserve','hpg_reserve']:\n", "        train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n", "        test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n", "\n", "    train['id'] = train.apply(lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), axis=1)\n", "\n", "    train['total_reserv_sum'] = train['rv1_x'] + train['rv1_y']\n", "    train['total_reserv_mean'] = (train['rv2_x'] + train['rv2_y']) / 2\n", "    train['total_reserv_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y']) / 2\n", "\n", "    test['total_reserv_sum'] = test['rv1_x'] + test['rv1_y']\n", "    test['total_reserv_mean'] = (test['rv2_x'] + test['rv2_y']) / 2\n", "    test['total_reserv_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y']) / 2\n", "    train['date_int'] = train['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n", "    test['date_int'] = test['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n", "\n", "    train = to_radians(train,'latitude')\n", "    train = to_radians(train,'longitude')\n", "    test = to_radians(test,'latitude')\n", "    test = to_radians(test,'longitude')\n", "\n", "    train['var_max_lat'] = train['latitude'].max() - train['latitude']\n", "    train['var_max_long'] = train['longitude'].max() - train['longitude']\n", "    test['var_max_lat'] = test['latitude'].max() - test['latitude']\n", "    test['var_max_long'] = test['longitude'].max() - test['longitude']\n", "    encoder2 = preprocessing.LabelEncoder()\n", "    train['air_store_id2'] = encoder2.fit_transform(train['air_store_id'])\n", "    test['air_store_id2'] = encoder2.transform(test['air_store_id'])\n", "    \n", "    return train,test\n", "\n", "def RMSLE(y, pred):\n", "    return metrics.mean_squared_error(y, pred)**0.5"], "execution_count": 24}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["data = {\n", "    'train':pd.read_csv('../input/air_visit_data.csv'),\n", "    'air_store':pd.read_csv('../input/air_store_info.csv'),\n", "    'hpg_store':pd.read_csv('../input/hpg_store_info.csv'),\n", "    'air_reserve':pd.read_csv('../input/air_reserve.csv'),\n", "    'hpg_reserve':pd.read_csv('../input/hpg_reserve.csv'),\n", "    'id_relation':pd.read_csv('../input/store_id_relation.csv'),\n", "    'test':pd.read_csv('../input/sample_submission.csv'),\n", "    'holiday':pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'}),\n", "}"], "execution_count": 26}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["train,test = merge_dataset(data)\n", "print(train.head())\n", "print(test.head())"], "execution_count": 27}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true}, "source": ["import pickle\n", "pickle.dump(train,open('preprocessed_train.pkl','wb'))\n", "pickle.dump(test,open('preprocessed_test.pkl','wb'))"], "execution_count": 28}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true}, "source": ["import pickle\n", "import numpy as np\n", "train = pickle.load(open('preprocessed_train.pkl','rb'))\n", "test = pickle.load(open('preprocessed_test.pkl','rb'))"], "execution_count": 29}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["from sklearn import *\n", "def RMSLE(y, pred):\n", "    return metrics.mean_squared_error(y, pred)**0.5"], "execution_count": 30}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true}, "source": ["col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date','visitors']]\n", "train = train.fillna(-1)\n", "test = test.fillna(-1)"], "execution_count": 31}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["import lightgbm as lgbm\n", "\n", "params = {\n", "        'boosting_type': 'gbdt', 'objective': 'regression', 'nthread': -1, 'verbose': 1,\n", "        'num_leaves': 700, 'learning_rate': 0.02, 'max_depth': -1,\n", "        'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.6,\n", "        'reg_alpha': 1, 'reg_lambda': 0.001, 'metric': 'rmse',\n", "        'min_split_gain': 0.5, 'min_child_weight': 1, 'min_child_samples': 20, 'scale_pos_weight': 1}\n", "    \n", "#kf = KFold(n_splits=5, shuffle=True, random_state=seed_val)\n", "# pred_test_y = np.zeros(test[col].shape[0])\n", "\n", "train_set = lgbm.Dataset(train[col], np.log1p(train['visitors'].values), silent=True)\n", "model = lgbm.train(params, train_set=train_set, num_boost_round=100,feature_name=col)\n", "print('RMSE GradientBoostingRegressor: ', RMSLE(np.log1p(train['visitors'].values), model.predict(train[col])))"], "execution_count": 32}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["print('Feature names:', model.feature_name())\n", "\n", "# feature importances\n", "print('Feature importances:', list(model.feature_importance()))\n", "model.save_model('model.txt')"], "execution_count": 33}, {"outputs": [], "cell_type": "code", "metadata": {}, "source": ["test.head()\n", "print (test.head())\n", "train.head()\n", "print (train.head())\n", "\n", "y_pred = model.predict(test[col])\n", "submission = pd.read_csv('../input/sample_submission.csv')  # check where you place the submission.csv\n", "submission['visitors'] = np.asarray(y_pred)\n", "submission.to_csv(\"lightgbm_baseline.csv\",index=False)"], "execution_count": 34}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true}, "source": [], "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true}, "source": [], "execution_count": null}], "nbformat_minor": 1, "metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.5.2", "nbconvert_exporter": "python", "mimetype": "text/x-python", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}}