{"cells": [{"cell_type": "markdown", "source": ["<h1 align=center> Freak Separate modelling for Timelines </h1>\n", "<i align=center> by Kirill Vlasov </i>"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "\n", "\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "from sklearn.ensemble import GradientBoostingRegressor\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import mean_squared_error\n", "\n", "from tqdm import tqdm_notebook \n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "%matplotlib inline\n", "\n", "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n", "from plotly import graph_objs as go\n", "init_notebook_mode(connected = True)"], "metadata": {}}, {"cell_type": "markdown", "source": ["In this kernel we will use only time date, but it's possible for use other additional datas.\n", "  \n", "soooo... ** let's start and load datafiles **"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["tra = pd.read_csv('../input/air_visit_data.csv')\n", "tst = pd.read_csv('../input/sample_submission.csv')\n", "hol = pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'})"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["tra['visit_date'] = pd.to_datetime(tra['visit_date'])\n", "tra['dow'] = tra['visit_date'].dt.dayofweek\n", "tra['year'] = tra['visit_date'].dt.year\n", "tra['day'] = tra['visit_date'].dt.day\n", "tra['month'] = tra['visit_date'].dt.month\n", "tra['visit_date'] = tra['visit_date'].dt.date\n", "\n", "tst['visit_date'] = tst['id'].map(lambda x: str(x).split('_')[2])\n", "tst['air_store_id'] = tst['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n", "tst.drop('id', axis=1, inplace=True)\n", "tst['visit_date'] = pd.to_datetime(tst['visit_date'])\n", "tst['dow'] = tst['visit_date'].dt.dayofweek\n", "tst['year'] = tst['visit_date'].dt.year\n", "tst['day'] = tst['visit_date'].dt.day\n", "tst['month'] = tst['visit_date'].dt.month\n", "tst['visit_date'] = tst['visit_date'].dt.date\n", "tst = tst[tra.columns]"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["hol['visit_date'] = pd.to_datetime(hol['visit_date'])\n", "hol['day_of_week'] = hol['day_of_week']\n", "hol['visit_date'] = hol['visit_date'].dt.date\n", "train = pd.merge(tra, hol, how='left', on=['visit_date']) \n", "test = pd.merge(tst, hol, how='left', on=['visit_date'])"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["LE = LabelEncoder()\n", "train['air_store_id'] = LE.fit_transform(train['air_store_id'])\n", "test['air_store_id'] = LE.transform(test['air_store_id'])\n", "\n", "train['day_of_week'] = LE.fit_transform(train['day_of_week'])\n", "test['day_of_week'] = LE.transform(test['day_of_week'])"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["train.head(3)"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["test.head(3)"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["def plotly_df(df, title = 'Visitors'):\n", "    data = []\n", "\n", "    #for column in df.columns:\n", "    trace = go.Scatter(\n", "            x = df.visit_date,\n", "            y = df.visitors,\n", "            mode = 'lines',\n", "            name = 'visitors')\n", "    data.append(trace)\n", "\n", "    layout = dict(title = title)\n", "    fig = dict(data = data, layout = layout)\n", "    iplot(fig, show_link=False)"], "metadata": {"collapsed": true}}, {"cell_type": "markdown", "source": ["looks for timelines of one Restaraunt"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["time_series = train[train.air_store_id == train.air_store_id.unique()[17]][['visit_date', 'visitors']]\n", "plotly_df(time_series, title = \"Visitors\")"], "metadata": {}}, {"cell_type": "markdown", "source": ["... and other one"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["time_series = train[train.air_store_id == train.air_store_id.unique()[84]][['visit_date', 'visitors']]\n", "plotly_df(time_series, title = \"Visitors\")"], "metadata": {}}, {"cell_type": "markdown", "source": ["we can conclude that the distribution of each store isn't similar"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["print('Test dataset contains ', test.air_store_id.unique().shape[0], ' unique id and train ', \n", "      train.air_store_id.unique().shape[0])"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["id_from_test = test.air_store_id.unique()\n", "id_from_train = train.air_store_id.unique()\n", "\n", "for i in range(len(id_from_test)):\n", "    sver = id_from_test[i]\n", "    alert = 1\n", "    for j in range(len(id_from_train)):\n", "        if id_from_train[j] == sver:\n", "            alert = 0\n", "    if alert == 1:\n", "        print('In train dataset absent restoraunt: ', test.air_store_id.unique()[i])\n", "print('End!')"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["train = train.fillna(0)\n", "test = test.fillna(0)"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["col = [c for c in train if c not in ['visit_date','visitors']]"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["X_for_submission = test[col]"], "metadata": {"collapsed": true}}, {"cell_type": "markdown", "source": ["## let's go freak modelling! ##\n", "we will train separates models for every restoraunt"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["model = GradientBoostingRegressor(loss='ls', n_estimators=200, random_state=1818)\n", "\n", "metrics = []\n", "sub = []\n", "\n", "\n", "for i in tqdm_notebook(range(len(X_for_submission.air_store_id.unique()))):\n", "    id_filter = X_for_submission.air_store_id.unique()[i]\n", "    y_train = np.log(train[train.air_store_id == id_filter]['visitors']+1)\n", "    X_train = train[train.air_store_id == id_filter][col]\n", "    X_test = X_for_submission[X_for_submission.air_store_id == id_filter][col]\n", "\n", "\n", "    if train[train.air_store_id == id_filter].shape[0] > 100:\n", "        test_index = X_train.shape[0]\n", "        X_con = pd.concat((X_train, X_test), ignore_index=True)\n", "\n", "        y_test = pd.Series(np.zeros(X_con.shape[0]-test_index), name='Visitors')\n", "        y_con = pd.concat((y_train, y_test), ignore_index=True)\n", "\n", "        lag_start = 39\n", "        lag_end   = 59\n", "        \n", "        \n", "        for i in range(lag_start, lag_end):\n", "                X_con[\"lag_{}\".format(i)] = y_con.shift(i)\n", "        \n", "        X_train = X_con.loc[:test_index-1] \n", "        X_test = X_con.loc[test_index:]\n", "        y_train = y_con.loc[:test_index-1]\n", "\n", "        X_train['visitors'] = y_train\n", "        X_train.dropna(inplace=True)\n", "        col2 = [c for c in X_train if c not in ['visitors']]\n", "\n", "        y_train = X_train['visitors']\n", "        X_train = X_train[col2]\n", "\n", "    \n", "    \n", "    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, train_size=0.8, random_state=18, shuffle=False)\n", "    model.fit(X_tr, y_tr)\n", "    coef = mean_squared_error(y_val, model.predict(X_val))\n", "    metrics = np.append(metrics, coef)\n", "    pred = model.predict(X_test)\n", "    \n", "    sub = np.append(sub, pred)"], "metadata": {}}, {"cell_type": "markdown", "source": ["Check metrics"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["print('Minimum of RMSLE = ', np.round(np.sqrt(metrics.min()), decimals=3), ', ', \n", "      'Mean of RMSLE = ', np.round(np.sqrt(metrics.mean()), decimals=3), ', ',\n", "      'Max of RMSLE = ' ,np.round(np.sqrt(metrics.max()), decimals=3))"], "metadata": {}}, {"cell_type": "markdown", "source": ["Not Bad! Let's try to submit"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["submission = pd.read_csv('../input/sample_submission.csv')\n", "submission.visitors = np.exp(sub)-1\n", "submission['visitors'] = submission['visitors'].apply(lambda x: 0 if x < 0 else x) \n", "submission.to_csv('submit.csv', index=False)\n", "submission.head(7)"], "metadata": {}}], "nbformat": 4, "nbformat_minor": 1, "metadata": {"language_info": {"version": "3.6.3", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "name": "python"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}}