{"cells":[{"metadata":{"_uuid":"c80d9b06a92c8a3818b5d2ef49b5abf6640f92b4"},"cell_type":"markdown","source":"<h1 id=\"tocheading\">Table of Contents</h1>\n<div id=\"toc\"></div>"},{"metadata":{"_uuid":"0e7d5ca081cf48e6f7b7aa8cd965bd0e67189fa1"},"cell_type":"markdown","source":"This notebook is published as part of a coursera course challenge assignment https://www.coursera.org/learn/advanced-data-science-capstone/home/welcome"},{"metadata":{"_uuid":"86b0842bba2501510aadf21599426e3d461d0488"},"cell_type":"markdown","source":"Run the following cell to generate the Table of Contents"},{"metadata":{"trusted":true,"_uuid":"eb74bad08df6ab825a9fe642d0d078080a1b59a3"},"cell_type":"code","source":"%%javascript\n$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77152a96451db1d06f415dc1fa21855ff3542524"},"cell_type":"markdown","source":"# Imports and Dependencies"},{"metadata":{"trusted":true,"_uuid":"a25d6c6cd547d25883a911addc5e58b15691aebe"},"cell_type":"code","source":"import sys, os\n\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\ninit_notebook_mode()\n\n# use plotly cufflinks\nimport plotly.tools as tls\ntls.embed('https://plot.ly/~cufflinks/8')\nimport cufflinks as cf\n# ensure offline mode\ncf.go_offline()\ncf.set_config_file(world_readable=False,offline=True, theme='ggplot')\n\nfrom scipy.stats import spearmanr\nimport numpy as np\nimport pandas as pd\nfrom pandas_summary import DataFrameSummary\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\n\n\nimport tensorflow as tf\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import regularizers\n\nfrom keras import backend as K\nfrom keras import regularizers\nfrom keras.layers import Dropout\nfrom keras.constraints import max_norm\nfrom keras.wrappers.scikit_learn import KerasClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff6c334f9cca15d0676367dd0e4d6f5d53cf797e"},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true,"_uuid":"880c26784a32d27f42de0dfb71f9dd6c8f3f907a"},"cell_type":"code","source":"id_col = 'ID_code'\ntarget_col = 'target'\ndf_play = pd.read_csv('../input/train.csv', index_col=id_col, low_memory=False)\ndf_comp = pd.read_csv('../input/test.csv', index_col=id_col, low_memory=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9077f51422246ae51d0486b44e340d223301316e"},"cell_type":"markdown","source":"The competition test data set in `test.csv` is loaded into `df_comp`. This data will be held aside until after the EDA and then be used for a submission file.\n\nThen we can split the training data, in `train.csv`, into actual training and validation data."},{"metadata":{"_uuid":"71d62dfb452dbaf0e80fe284fb1f538eb4972644"},"cell_type":"markdown","source":"### Split data into local train and local test sets"},{"metadata":{"_uuid":"97b5aa8f19cbb841d0cad87482cb8f7e1484b1c9"},"cell_type":"markdown","source":"We shuffle and split training and test sets and are currently taking only a 10% stratified sample for both train and test sets.\n\nThis train size can be increased after model improvements are made in order to improve overall score."},{"metadata":{"trusted":true,"_uuid":"85a46b2284742427ea1a371a896341f78df126e7"},"cell_type":"code","source":"train_df, test_df = train_test_split(df_play, test_size=.1, train_size=.1, stratify=df_play.target, shuffle=True, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6494c564135b452460d447884973911cbb7225e4"},"cell_type":"markdown","source":"### Separate features from targert variable"},{"metadata":{"_uuid":"5ea40048c0ddcebc69b83cd28188264a61ba6e91"},"cell_type":"markdown","source":"Here we create some shorthand convenience variables for later use in model exploration and comparision."},{"metadata":{"trusted":true,"_uuid":"0d123a9c087e9e9464553855c8558cd976164c14"},"cell_type":"code","source":"# prepare training and validation dataset\nX = train_df.drop(target_col, axis=1)\ny = train_df[target_col]\nX_val = test_df.drop(target_col, axis=1)\ny_val = test_df[target_col]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab4802ad2a9f7f3cb156efd4701feceada2e1d64"},"cell_type":"markdown","source":"# Data Quality Assessment"},{"metadata":{"trusted":true,"_uuid":"7adda3a8622446583af418ab6cfb44dc61a071d6"},"cell_type":"code","source":"# limit the columns that are returned from summarize\n# restricted to numeric by difference of values in compare_dataframes \nmain_cols = ['std', 'min', 'mean', 'max', 'counts', 'missing', 'uniques']\n\n\ndef summarize(df, sample_size=0):\n    \"sumamrize a dataframe for quality assesment\"\n    dtypes = pd.DataFrame(df.dtypes, columns=['dtype'])\n    stats = DataFrameSummary(df).summary().T\n    summary = dtypes.merge(stats, left_index=True, right_index=True)\n    summary = summary.merge(dtypes.rename({'dtype':'dtype2'}, axis=1), left_index=True, right_index=True).rename({'dtype':'dtype1'}, axis=1).sort_values('dtype1')\n    if sample_size:\n        samples = df.sample(sample_size).T\n        summary = samples.merge(summary, left_index=True, right_index=True).rename({'dtype':'dtype1'}, axis=1).sort_values('dtype1')\n        return summary \n    else:\n        return summary[main_cols]\n    \ndef display_all(df):\n    \"display the entirity of a dataframe in the cell with scroll bars\"\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000):\n        display(df)\n\n\ndef compare_dataframes(train_df, test_df, target_col):\n    \"compare the summaries for 2 dataframes\"\n    # make summaries for the train and test data sets and join them together\n    test_summary = summarize(test_df)\n    train_summary = summarize(train_df.drop(target_col, axis=1))\n    summary = train_summary.merge(test_summary, left_index=True, right_index=True, suffixes=('_train', '_test'))\n    # take the differnce of summary values and make a dataframe of them and return it \n    train_test_diff_df = pd.DataFrame(test_summary.values - train_summary.values, index=test_summary.index, columns=[c + '_diff' for c in main_cols])\n    summary = summary.merge(train_test_diff_df, left_index=True, right_index=True)\n    return summary","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e64a38d705e02044eaa57e6160ac173c8fe3c23a"},"cell_type":"markdown","source":"Using `pandas_summary` we can get an easy idea of our dataset's null-count along with other standard descriptive statisics. The `summarize` function collects this info along with the pandas dtypes and possibly some samples if intersted. `compare_dataframes` uses summarize on both and merges the summaries into a single dataframe. It also shows the difference in value for each statistic and feature in a third column.   "},{"metadata":{"trusted":true,"_uuid":"02758e3833aac4de900840bdf03a416e7fe4edb7"},"cell_type":"code","source":"summary = compare_dataframes(df_play, df_comp, target_col)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d42b9bd4beb86ee6a5515710d3433cda463fef4c"},"cell_type":"markdown","source":"Using `display_all` we can investigate the full dataframe. It can be seen already from here that there are not any missing values in any column. Also the difference in the given datasets `train.csv` and `test.csv` do not seem to be anything remarkable.   "},{"metadata":{"trusted":true,"_uuid":"492ecdd0021848cd3aa0b41de831aecefb2d2b81"},"cell_type":"code","source":"display_all(summary.sort_index(axis=1, ascending=False).sort_values('std_diff', ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c0af0299ff35317f5e9279fbed817c704902a34"},"cell_type":"markdown","source":"Here we can choose a column to inspect more closely in the next two cells. This should be a column name from the summary dataframe (as opposed to the feature column names)."},{"metadata":{"trusted":true,"_uuid":"1861cc823a224349a1254519ac2ec8a0dada8429"},"cell_type":"code","source":"inspect_col = 'std_train'\nsummary[inspect_col].iplot(kind='hist', bins=100, title=f'Frequency Histogram for {inspect_col}', \n                          yTitle=f'Number of times value appeared', xTitle=f'Value for {inspect_col}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48e3495f6c16b6d9f2820b5bc781450746e4c190"},"cell_type":"code","source":"hist_data = [list(summary[inspect_col].values - summary[inspect_col].values.mean())]\nlabels = [inspect_col]    \n\nfig = ff.create_distplot(hist_data, labels)\n\n# update the plot titles\nfig.layout.xaxis.update(title=f'Value for {inspect_col}')\nfig.layout.yaxis.update(title=f'Probability that value appeared')\nfig.layout.update(title=f'Distribution Plot for {inspect_col}');\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"915159719dbc95c023e8a9d1d5667565a5b4e1ec"},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"_uuid":"d1ec792b82e63f6255cead8a7564e920f29ac081"},"cell_type":"markdown","source":"To check more in depth than the general descriptive statistics above here we can consider column correlation using Spearman's rank correlation.\n\nWe can build a correlation matrix here and check the max values for each feature."},{"metadata":{"trusted":true,"_uuid":"ca771be49c51d560b2a89a3a4c6f44a2e65184ab"},"cell_type":"code","source":"corr = np.round(spearmanr(train_df).correlation, 4)\ndf_corr = pd.DataFrame(data=corr, index=train_df.columns, columns=train_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67d9151dd2de739bccfd333c218627f525d85cb1"},"cell_type":"markdown","source":"The next transforms the matrix to remove duplicate info in the bottom left half of the matrix and also ends with a singele series for the correlataion value and a multiindex for the two features it arises from.   "},{"metadata":{"trusted":true,"_uuid":"c58ec6bfc1f4c1dd17024627b2d5184edbaea77c"},"cell_type":"code","source":"keep = np.triu(np.ones(df_corr.shape)).astype('bool').reshape(df_corr.size)\nc = df_corr.stack()[keep]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3985efdab80109bbb5109a38bda0cb71c5269a5c"},"cell_type":"markdown","source":"Then we can remove the rows showing correlation between a feature and itself. Also we can remove the correlation between features and the target variable."},{"metadata":{"trusted":true,"_uuid":"5a4a379d6a1941fcfd2321795204c75b40650851"},"cell_type":"code","source":"c = c.loc[c.index.get_level_values(1)!=c.index.get_level_values(0),]\nc = c.loc[c.index.get_level_values(0)!='target',]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de09ea23f656e996a9aa7df2e0590d6a471b9dca"},"cell_type":"markdown","source":"To look at the top N most correlated values"},{"metadata":{"trusted":true,"_uuid":"be90087ddf2ea4a6c4fc3bd579820b68fd2d9033"},"cell_type":"code","source":"N_corr = 20\nc.sort_values()[-N_corr:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5617351c09eefe65fc40778edcdbba013ecf73c5"},"cell_type":"markdown","source":"or the most negatively correlated values."},{"metadata":{"trusted":true,"_uuid":"34c71b3a928b23cd21d57b9b4cf95fdc87e6a70d"},"cell_type":"code","source":"c.sort_values()[:N_corr]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d25d0b6258485b3b06235a60e51a788d240de4c"},"cell_type":"markdown","source":"All values are quite low and do not require specific treatment at this point."},{"metadata":{"_uuid":"26472dd575584684a9638b40b8c3290af1b8c18e"},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{"trusted":true,"_uuid":"d13df7652685ed6eeff26d07caeb0b1eb65578b9"},"cell_type":"code","source":"def dist_plots(var_name='var_1', sample_size=5000):\n    \"Make a distribution plot for a single variable from the dataset\"\n    hist_data = [df_play[var_name].sample(sample_size).values, df_comp[var_name].sample(sample_size).values]\n    group_labels = ['train', 'test']\n    fig = ff.create_distplot(hist_data, group_labels, show_hist=False, show_rug=False)\n    return fig","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79de90b150166c725fee35b46e07d9d73934654b"},"cell_type":"markdown","source":"Here we can make distribution plots for a number of variables in a single figure. I find batches of 25 to be manageable to look at once. \n\nThe following code will show 25 variables from the dataset at time, beginning from `var_N` where `N` is the `offset` value defined in the next variable assignment. "},{"metadata":{"trusted":true,"_uuid":"1340813b83c06a35359f7ed7db0fc193dc650d5f"},"cell_type":"code","source":"offset = 50\nplots = [dist_plots(f'var_{i+offset}') for i in range(25)]\n\nfor ix, plot in enumerate(plots, 1):\n    plot.layout.update(title=f'var {ix+offset}')\n    for trace in plot.data:\n        trace.showlegend = False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ea8af1397e8af30a72889e67066cecf28c35c2e"},"cell_type":"markdown","source":"From this we can visual inspect the difference in distributions for our trainable dataset version the competition dataset."},{"metadata":{"trusted":true,"_uuid":"2048d153c4749a42dd61a5c127af21aa8e20935a"},"cell_type":"code","source":"iplot(cf.subplots(plots, shape=(5, 5), \n                  subplot_titles=[f'var_{i+offset}' for i in range(25)]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a11ea3bee8eb0c3e9dd2da4f64ec005b68c4c5cc"},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"_uuid":"61c1f923b106fbcf63d67bf3ea1eec05ad48ad79"},"cell_type":"markdown","source":"Without any missing values for any features we do not need any kind of imputation. We can perfrom standard scaling on the features to see if that improves the model's performance. "},{"metadata":{"_uuid":"59d63afb385f60ce47816aa790801a7657f8ad6a"},"cell_type":"markdown","source":"#### Scale Features"},{"metadata":{"trusted":true,"_uuid":"339ce64f9a908fce6d1d5054d57d4cf438df2393"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_sc = sc.fit_transform(X)\nX_val_sc = sc.transform(X_val)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1b1c426450c91977bd23ad5d37abd2b9bfd8028"},"cell_type":"markdown","source":"# Model Performance Indicator"},{"metadata":{"_uuid":"f558a0f986c15ea019878a778bc9664b15617ecc"},"cell_type":"markdown","source":"The score function used in the competiton is the Area Under the Reciever Operator Characteristic Curve.\n\nAfter training each model to compare, we can save the roc plot data in the folowing `roc_data` variable in order to plot all results together at the end."},{"metadata":{"trusted":true,"_uuid":"24ed6ed6ab5d782dff56819904485c2482e9ae8a"},"cell_type":"code","source":"roc_data = {}\nroc_auc_scores = {}\nprediction_df = y_val.to_frame('ground_truth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60979343a80a85d0814bc35465873a5ac819eba2"},"cell_type":"code","source":"def make_roc_fig(roc_data=None):\n    \"Takes a list of roc_curve results and plots each of the items on the same figure\"\n    if not roc_data: roc_data = {}\n    data = []\n    # plot the line for random chance comparison\n    trace = go.Scatter(x=[0, 1], y=[0, 1], \n                       mode='lines', \n                       line=dict(width=2, color='black', dash='dash'),\n                       name='Luck')\n    data.append(trace)\n    # plot each of the roc curves given in arg\n    for clf_name, roc in roc_data.items():\n        fpr, tpr, thresholds = roc\n        roc_auc = auc(fpr, tpr)\n        trace = go.Scatter(x=fpr, y=tpr, \n                           mode='lines', \n                           line=dict(width=2),\n                           name=f'{clf_name} ROC AUC (area = {roc_auc:0.2f})')\n        data.append(trace)\n    # add layout\n    layout = go.Layout(title='Receiver Operating Characteristic',\n                       xaxis=dict(title='False Positive Rate', showgrid=False,\n                                  range=[-0.05, 1.05]),\n                       yaxis=dict(title='True Positive Rate', showgrid=False,\n                                  range=[-0.05, 1.05]))\n    # create fig then return\n    fig = go.Figure(data=data, layout=layout)\n    return fig\n\ndef score_model(clf_name ,y_pred):\n    \"collect data from the models prediction for final analysis and model comparison. Return the roc curve data for immediate plotting\"\n    # Make predictions and add to df for final summary\n    prediction_df[clf_name] = y_pred\n    # Store score for final judegment\n    score = roc_auc_score(y_val, y_pred)\n    roc_auc_scores[clf_name] = score\n    # Make the ROCs for plotting\n    roc = roc_curve(y_val, y_pred)\n    roc_data[clf_name] = roc\n    print(f'The {clf_name} model has ROC AUC: {score}')\n    return roc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"091ac02eb678cc326326b3cf5ceb7cb09a6451a8"},"cell_type":"markdown","source":"# Model Building"},{"metadata":{"_uuid":"eae8ea382cae751f8a1825091ca5b35b1b0c5b03"},"cell_type":"markdown","source":"Here is a comparison of two models, Random Forest and a simple DNN Feed Forward Network. Most of the ways to improve the models have yet to be implemented, but they still have a reasonably good skill. Examples of such are otpimizing other hyperparameters, experiment with these ones further, training the models on the full dataset etc...\n\nFor comparison the model is fitted to both the scaled and unscaled data and the Receiver Operator Characteristic curve will be plotted. Afterwards all curves are shown on a single plot and models are judged by the sum of the area under its ROC curve, calculated with `roc_auc_score` and `dnn_auc`."},{"metadata":{"_uuid":"944b4a6106856d2af721f2b0a37ccd01035b80ab"},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":true,"_uuid":"819c5c332785921111e105cab42a5aee5fb80788"},"cell_type":"code","source":"rf_param = {\n 'min_samples_leaf': 10,\n 'max_features': .5,\n 'n_estimators': 100}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"503f735b281f50bc15858a21f81d6d83feb3dda6"},"cell_type":"code","source":"rfm = RandomForestClassifier(**rf_param, n_jobs=-1, random_state=0)\nrfm.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"082b27d1252d09499227a432e3b1b6842014b6d2"},"cell_type":"code","source":"clf_name = 'rf'\n\ny_pred = rfm.predict_proba(X_val)[:,1]\n\nroc = score_model(clf_name, y_pred.tolist())\n\niplot(make_roc_fig({clf_name: roc}))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"feb8f215c08b0061c91b767211e3de565997fbae"},"cell_type":"markdown","source":"#### Fit and score the scaled values"},{"metadata":{"trusted":true,"_uuid":"d0c363fe9b09c9a5c10d89fd2466df025c336053"},"cell_type":"code","source":"rfm = RandomForestClassifier(**rf_param, n_jobs=-1, random_state=0)\nrfm.fit(X_sc, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba79bb3982433d2d6dbfa67cc63939696fe2ab97"},"cell_type":"code","source":"clf_name = 'rf_sc'\n\ny_pred = rfm.predict_proba(X_val_sc)[:,1]\n\nroc = score_model(clf_name, y_pred)\n\niplot(make_roc_fig({clf_name: roc}))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d2b966081855b762749cad19e4ac5a4460e44f0"},"cell_type":"markdown","source":"## Deep Learning Model"},{"metadata":{"trusted":true,"_uuid":"cdda2d11c6c1d46453ddf056b3aaa345392fcc6f"},"cell_type":"code","source":"def dnn_auc(y_true, y_pred):\n    auc = tf.metrics.auc(y_true, y_pred)[1]\n    K.get_session().run(tf.local_variables_initializer())\n    return auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34a654f635b69c512c585ed1d49759bb53cb9a58"},"cell_type":"code","source":"def create_dnn():\n    model = Sequential()\n    model.add(Dense(200, input_dim=200, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[dnn_auc])\n    return model\n\nmodel = create_dnn()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b254617f7666332e69d48f2ec8d1127bbb26ff3"},"cell_type":"code","source":"model.fit(X, y, batch_size = 10000, epochs = 200, validation_data = (X_val, y_val), )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21c8f8a32f6a057d2c770a773de096f81a6ba35e"},"cell_type":"code","source":"clf_name = 'dnn'\n\ny_pred = model.predict(X_val)\n\nroc = score_model(clf_name, y_pred)\n\niplot(make_roc_fig({clf_name: roc}))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f28336b0a37fb3ce6b1c772ab916be009de97c5"},"cell_type":"markdown","source":"#### Fit the model with the scaled data"},{"metadata":{"trusted":true,"_uuid":"3ba40b6ead06530a36f86a494511665e744b2421"},"cell_type":"code","source":"model = create_dnn()\nmodel.fit(X_sc, y, batch_size = 10000, epochs = 200, validation_data = (X_val_sc, y_val), )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8185469d2b1227953b37e9a335578511b577b784"},"cell_type":"code","source":"clf_name = 'dnn_sc'\n\ny_pred = model.predict(X_val_sc)\n\nroc = score_model(clf_name, y_pred)\n\niplot(make_roc_fig({clf_name: roc}))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bc0e8ed6a24aa1a9e9b84676f3e542f10eda946"},"cell_type":"markdown","source":"# Model Performance"},{"metadata":{"_uuid":"c3fa2872258fb360e3d4d29d29f919554424e81f"},"cell_type":"markdown","source":"Now we can plot the four curves altogether and see which has the best score."},{"metadata":{"trusted":true,"_uuid":"0ae65ae107d91e34da5f17257d6819547e351588"},"cell_type":"code","source":"iplot(make_roc_fig(roc_data))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3df51bf7c56f03a11527ba2ab1f3eb702cd7518b"},"cell_type":"markdown","source":"We can see see that scaling the features has increased NN's score, whereas it stayed exactly the same for the random forest. This is the expected behavior for each of the models, and the both have given OK results for a start."},{"metadata":{"_uuid":"a03d28da142227ffa1f8ec0e549906ef747f2fd2"},"cell_type":"markdown","source":"There is lots to be done to improve these models and explore other algorithms, but we can see here  that `dnn_sc`, the simple DNN with feature scaling, seems to have the best curve out of these models, but it ties to the Random Forest overall (under current conditions) with a score of `0.81`. "},{"metadata":{"_uuid":"ce7e5a074637ce7df4d23da895aa847f2a97d296"},"cell_type":"markdown","source":"# References"},{"metadata":{"_uuid":"0a549979dde5c6d343f533f76d0af5ba27d52fe2"},"cell_type":"markdown","source":"This notebook is part of a final challenge assignment for the following course."},{"metadata":{"_uuid":"eeaa3d51d0cacd8a3e3bb6052becbb47d2d0bcb6"},"cell_type":"markdown","source":"https://www.coursera.org/learn/advanced-data-science-capstone/home/welcome"},{"metadata":{"_uuid":"4768a129fe5c94e4b17cc00d40cc99a9cec222e4"},"cell_type":"markdown","source":"While working through completing this notebook I found the folling pages very useful."},{"metadata":{"_uuid":"b7c554b69fde2b2107c0a332ee6d9b62c79f5db6"},"cell_type":"markdown","source":"https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n\nhttps://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}