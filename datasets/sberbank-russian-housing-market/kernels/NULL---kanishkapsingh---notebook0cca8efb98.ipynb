{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "78877ee5-61e4-d87d-07dd-d1da9fb1035e"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "import numpy as np # linear algebra\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "import seaborn as sns\n",
        "from statistics import mode\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f6153b63-44e9-afde-fe75-90f1af655aa7"
      },
      "outputs": [],
      "source": [
        "class NeuralNetKeras:\n",
        "    def load_data(self,train_data,test_data):\n",
        "        self.train=pd.read_csv(train_data)\n",
        "        self.test=pd.read_csv(test_data)\n",
        "        pass\n",
        "    def merge_all(self):\n",
        "        all_feat=list(self.train.columns)\n",
        "        self.train['Source_data']='train'\n",
        "        self.test['price_doc']=0.0\n",
        "        self.test['Source_data']='test'\n",
        "        self.merged_data=self.train.append(self.test)\n",
        "        pass\n",
        "    \n",
        "    def summary(self):\n",
        "        self.summary_info={}\n",
        "        for col in self.train:\n",
        "            self.summary_info[col]={'Missing':len(self.train[pd.isnull(self.train[col])]),'Min':np.min(self.train[col]),'Max':np.max(self.train[col]),'N_Unique':len(pd.unique(self.train[col]))}\n",
        "        pass\n",
        "    def boxplots(self,vars_list):\n",
        "        for i in range(len(vars_list)):\n",
        "            plt.figure(i)\n",
        "            sns.boxplot(self.train[vars_list[i]])\n",
        "    def HotEncoding(self,col_list):\n",
        "        for col in col_list:\n",
        "            if self.merged_data[col].dtype=='object':\n",
        "                self.merged_data.loc[:,col]=pd.Categorical.from_array(self.merged_data.loc[:,col]).labels\n",
        "            if self.summary_info[col]['N_Unique']<=20:\n",
        "                hot_encode=OneHotEncoder()\n",
        "                hot_encode.fit(np.array(self.merged_data.loc[:,col]))\n",
        "                self.merged_data.loc[:,col]=hot_encode.transform(np.array(self.merged_data.loc[:,col]))\n",
        "        pass\n",
        "    def setFullSq(self,data):\n",
        "        missing_full=(data['full_sq']==0)|(pd.isnull(data['full_sq']))\n",
        "        data.loc[missing_full,'full_sq']=data.loc[missing_full,'life_sq']\n",
        "        return data\n",
        "    def setSq(self,data,col,vs_col,imp_criteria):\n",
        "        trouble=(data[col]==0)|(pd.isnull(data[col]))|(data[col]>data[vs_col])\n",
        "        data.loc[trouble,col]=data.loc[trouble,vs_col]*self.all_area_summary[imp_criteria]['50%']\n",
        "        return data\n",
        "    def handle_sq_ft(self):\n",
        "        area_vars=['full_sq','life_sq','kitch_sq']\n",
        "        tr_te_merge=self.merged_data[area_vars]\n",
        "        all_sq_ft=(pd.notnull(tr_te_merge['full_sq']))&(pd.notnull(tr_te_merge['life_sq']))&(pd.notnull(tr_te_merge['kitch_sq']))&(tr_te_merge['full_sq']!=0)&(tr_te_merge['life_sq']!=0)&(tr_te_merge['kitch_sq']!=0)\n",
        "        tr_te_merge=tr_te_merge.loc[all_sq_ft,:]\n",
        "        #remove outliers from each of the sq_ft columns\n",
        "        no_outlier=(tr_te_merge['full_sq']<=np.mean(tr_te_merge['full_sq'])+3*np.std(tr_te_merge['full_sq']))&(tr_te_merge['full_sq']>=np.mean(tr_te_merge['full_sq'])-3*np.std(tr_te_merge['full_sq']))&(tr_te_merge['life_sq']<=np.mean(tr_te_merge['life_sq'])+3*np.std(tr_te_merge['life_sq']))&(tr_te_merge['life_sq']>=np.mean(tr_te_merge['life_sq'])-3*np.std(tr_te_merge['life_sq']))&(tr_te_merge['kitch_sq']<=np.mean(tr_te_merge['kitch_sq'])+3*np.std(tr_te_merge['kitch_sq']))&(tr_te_merge['kitch_sq']>=np.mean(tr_te_merge['kitch_sq'])-3*np.std(tr_te_merge['kitch_sq']))\n",
        "        tr_te_merge=tr_te_merge.loc[no_outlier,:]\n",
        "        # Generate variable %Kitch/Full, %Kitch/Life and %Life/Full\n",
        "        tr_te_merge.loc[:,'%Life/Full']=tr_te_merge.loc[:,'life_sq']/tr_te_merge.loc[:,'full_sq']\n",
        "        tr_te_merge.loc[:,'%Kitch/Full']=tr_te_merge.loc[:,'kitch_sq']/tr_te_merge.loc[:,'full_sq']\n",
        "        tr_te_merge.loc[:,'%Kitch/Life']=tr_te_merge.loc[:,'kitch_sq']/tr_te_merge.loc[:,'life_sq']\n",
        "        self.all_area_summary=tr_te_merge.describe()\n",
        "        # Impute values for missing sq ft\n",
        "        #Full Sq\n",
        "        self.merged_data=self.setFullSq(self.merged_data)\n",
        "        #Kitch Sq\n",
        "        self.merged_data=self.setSq(self.merged_data,'kitch_sq','full_sq','%Kitch/Full')\n",
        "        #Life Sq\n",
        "        self.merged_data=self.setSq(self.merged_data,'life_sq','full_sq','%Life/Full')\n",
        "        pass\n",
        "    def impute_mode(self,col_list):        \n",
        "        for col in col_list:\n",
        "            all_data=self.merged_data[col]\n",
        "            all_data=all_data[pd.notnull(all_data)]\n",
        "            mode_value=mode(all_data)\n",
        "            missing=len(self.merged_data[pd.isnull(self.merged_data[col])])\n",
        "            self.merged_data.loc[pd.isnull(self.merged_data[col]),col]=mode_value\n",
        "            print('Missing ',col,'=',missing,' out of ',len(self.merged_data[col]) ,'replaced by mode value= ',mode_value)\n",
        "            pass\n",
        "    def handle_missing(self,impute_cols):\n",
        "        # Handles missing sq ft data and imputes data and removes anomaly in the data\n",
        "        self.handle_sq_ft()\n",
        "        self.impute_mode(impute_cols)\n",
        "        #self.handle_missing_categories()\n",
        "        #self.handle_missing_continuous()\n",
        "        pass   \n",
        "    def preprocess_data(self):\n",
        "        self.HotEncoding()\n",
        "        pass\n",
        "    def house_features(self):\n",
        "        self.house_feat=list(self.merged_data.iloc[:,2:11].columns)\n",
        "        print (self.house_feat)\n",
        "    def correlation_mat(self):\n",
        "        self.corr_mat=self.train.corr()\n",
        "        pass\n",
        "    def no_missing_no_string(self):\n",
        "        self.no_missing_cols=[]\n",
        "        for key in self.summary_info:\n",
        "            if self.summary_info[key]['Missing']==0 and key not in ['timestamp','id','price_doc'] and self.train[key].dtype not in ['object']:\n",
        "                self.no_missing_cols.append(key)\n",
        "        pass\n",
        "    def descriptive_stats(self):\n",
        "        self.desc_stats=self.train.describe()\n",
        "        pass\n",
        "    def build_model_skeleton(self,n_nodes,activation_fn,i_dim):\n",
        "        self.model=Sequential()\n",
        "        self.model.add(Dense(n_nodes,input_dim=i_dim))\n",
        "        self.model.add(Activation(activation_fn))\n",
        "        self.model.add(Dense(1, kernel_initializer='normal'))  \n",
        "        pass\n",
        "    def compile_model(self,optimizer_crit,loss_crit):\n",
        "        self.model.compile(optimizer=optimizer_crit,loss=loss_crit)\n",
        "        pass\n",
        "    def fit_model(self,n_epochs,b_size,data_train,data_test):\n",
        "        self.model.fit(x=np.array(data_train[self.house_feat]),y=np.array(data_train['price_doc']),epochs=n_epochs,batch_size=b_size)\n",
        "    def predict_model(self,b_size,data_train,data_test):\n",
        "        self.predictions=self.model.predict(x=np.array(data_test),batch_size=b_size)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "03568b08-1d80-b3d5-f195-da47ade9894a"
      },
      "outputs": [],
      "source": [
        "n1=NeuralNetKeras()\n",
        "n1.load_data('../input/train.csv','../input/test.csv')\n",
        "n1.summary()\n",
        "n1.merge_all()\n",
        "n1.house_features()\n",
        "n1.HotEncoding(n1.house_feat)\n",
        "n1.handle_missing(impute_cols=['floor','max_floor','material','build_year','num_room','state','product_type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "469573c8-72b1-33af-e1ba-a0f97d21efa1"
      },
      "outputs": [],
      "source": [
        "n1.build_model_skeleton(10,'relu',len(n1.house_feat))\n",
        "n1.compile_model('rmsprop','mse')\n",
        "n1.train=n1.merged_data.loc[n1.merged_data['Source_data']=='train',n1.house_feat+['price_doc']]\n",
        "n1.test=n1.merged_data.loc[n1.merged_data['Source_data']=='test',n1.house_feat]                        \n",
        "#n1.fit_model(20000,10000,n1.train,n1.test)\n",
        "#n1.predict_model(10000,n1.train,n1.test)\n",
        "print(n1.train.head())\n",
        "print(n1.test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ff37ba5a-c380-77e5-ebfe-7742515a6e78"
      },
      "outputs": [],
      "source": [
        "#final=pd.DataFrame(n1.merged_data.loc[n1.merged_data['Source_data']=='test','id'])\n",
        "#final['prediction']=n1.predictions\n",
        "#final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "20935e99-4758-c9ab-274d-13c7b65ef54c"
      },
      "outputs": [],
      "source": [
        "#final.to_csv('final.csv')"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}