{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport math\nfrom collections import Counter\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n%matplotlib inline\n\n# Any results you write to the current directory are saved as output.","execution_count":33,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true},"cell_type":"markdown","source":"# Data Preparation\n## Load labels"},{"metadata":{"_uuid":"93586edae33c06e04eb26eb01943a9340324c970","_cell_guid":"81665f03-7a00-4263-b8d1-bee3aedbd703","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")[:3000]\nfilenames = train['Image']\nlabels = train['Id']\nprint(train.shape)\ntrain.head()","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"3b3dc4bdd5e96e18881cd0cb2eff1c819aff284a","_cell_guid":"014c4c3b-0a36-47fc-8edc-4e4c6da27611"},"cell_type":"markdown","source":"## Load Images"},{"metadata":{"_uuid":"2804b96efebce88131da1bbbf712d992a958b5f2","_cell_guid":"0f053bd4-c853-4f11-a771-2447bc83c1cc","collapsed":true,"trusted":true},"cell_type":"code","source":"images={filename: plt.imread(f'../input/train/{filename}') for filename in filenames}\n#images=[ plt.imread(f'../input/train/{filename}') for filename in filenames]","execution_count":45,"outputs":[]},{"metadata":{"_uuid":"f969c017363326bd62b08ee9e907eab78c50ef6a","_cell_guid":"554a3634-0c68-4725-81e7-ce2a9fa67d16"},"cell_type":"markdown","source":"## Explore Dataset"},{"metadata":{"_uuid":"252226dcefbc7b1b9b0c8c9220c755eb26274a2a","_cell_guid":"cb0b4cd2-9283-461c-9403-83b9dba27765"},"cell_type":"markdown","source":"### Some images"},{"metadata":{"_uuid":"dc033489d934bb9f83dc8727b5e71bc770e86581","_cell_guid":"58cd4484-f80e-403a-81aa-438ce880ff38","trusted":true,"collapsed":true},"cell_type":"code","source":"def plot_images(filenames, labels, rows=4):\n    # Set figure to 13 inches x 8 inches\n    figure = plt.figure(figsize=(13, 8))\n\n    cols = len(filenames) // rows +1\n\n    for i in range(len(filenames)):\n        subplot = figure.add_subplot(rows, cols, i+1)\n        subplot.axis('Off')\n        if labels:\n            subplot.set_title(labels[i], fontsize=16)\n        plt.imshow(images[filenames[i]], cmap='gray')\n\n","execution_count":46,"outputs":[]},{"metadata":{"_uuid":"ffc4030e9901949a45a2f7c8ae988049491389ba","_cell_guid":"03419770-deac-43f0-9eca-7b7c2aacdea1","trusted":true},"cell_type":"code","source":"plot_images(list(filenames[:18]), list(labels[:18]))","execution_count":37,"outputs":[]},{"metadata":{"_uuid":"5b17ba7686d9927cf9ba65698ef9034ee3b9c1dd","_cell_guid":"76efbf41-92dc-45e2-a8dd-75be39528d54"},"cell_type":"markdown","source":"### Category level analysis"},{"metadata":{"_uuid":"d44c0b355280bc291f67988f7830dc435824ee09","_cell_guid":"2294d8d1-94f0-4495-a354-0ea62e5a6be8","trusted":true},"cell_type":"code","source":"num_categories = len(train['Id'].unique())\n     \nprint(f'Number of categories: {num_categories}')","execution_count":38,"outputs":[]},{"metadata":{"_uuid":"050d9c02ec9e5100809173a14b0829c6dd91db18","_cell_guid":"1a442af9-f919-429e-a4ea-a840048c3b27","collapsed":true,"trusted":true},"cell_type":"code","source":"categories_count = train['Id'].value_counts()","execution_count":39,"outputs":[]},{"metadata":{"_uuid":"59786c13cba7b1cb4fe079e45e260abc8915985e","_cell_guid":"88aeb65a-9cd4-4157-8457-3fd33f3bb111","trusted":true},"cell_type":"code","source":"size_buckets = Counter(categories_count.values)\n\nplt.figure(figsize=(10, 6))\n\nplt.bar(range(len(size_buckets)), list(size_buckets.values())[::-1], align='center')\nplt.xticks(range(len(size_buckets)), list(size_buckets.keys())[::-1])\nplt.title(\"Num of categories by available images in the training set\")\nplt.xlabel('# of images provided')\nplt.ylabel('# of categories')\n\nplt.show()","execution_count":40,"outputs":[]},{"metadata":{"_uuid":"08be471b5a47cbd778902f0904dbc24ab5b69d50","_cell_guid":"1348746d-9308-4121-9b07-2e60cc511c16","trusted":true},"cell_type":"code","source":"categories_count.head()","execution_count":41,"outputs":[]},{"metadata":{"_uuid":"24277b8f1b90d9a9a6ec16d69926574fbb07465d","_cell_guid":"fe2bc563-3c4d-4b9d-b522-dc883863c4f5","trusted":true},"cell_type":"code","source":"total = len(train['Id'])\nnew_whale_percentage = categories_count[\"new_whale\"]/total\nprint(f'Total images in training set {total}')\nprint(f'Percentage of new_whale {new_whale_percentage*100}%')","execution_count":42,"outputs":[]},{"metadata":{"_uuid":"4fbb8bcb8a1ab0e37ae0d9ebea2df0c32ca11e12","_cell_guid":"fe6c4628-b38d-4554-8b22-a27a6e5f2c6d"},"cell_type":"markdown","source":"### Images of the same category"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"43c3d2aca88b424c75827928b4b8ef4e954b368d"},"cell_type":"code","source":"top_names = categories_count.head().keys()\ntop1_name = top_names[1]\ntop2_name = top_names[2]","execution_count":56,"outputs":[]},{"metadata":{"_uuid":"4aff6e8d54f4f86446759c9a552603c9a1b0a63c","_cell_guid":"4ed017c9-5dd7-4a72-8f6f-ecd97366d924","trusted":true},"cell_type":"code","source":"top1 = list(filenames[train['Id'] == top1_name])\nplot_images(top1, None, rows=len(top1)/4)","execution_count":47,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"63a7f0d9f429999b2988e52044b7ddd26bd68200"},"cell_type":"code","source":"top2 = list(images[train['Id'] == top2_name])\nplot_images(top2, None, rows=len(top1)/4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5dcdf5214ad25cd01d422b3784dae6b7d9c80f5"},"cell_type":"markdown","source":"### General Analysis"},{"metadata":{"trusted":true,"_uuid":"932cc594e62de779654a21b5b6fdf66e005d7131"},"cell_type":"code","source":"num_grey_scale = 0\nnum_grey_scale_unpopular = 0\nfor key, value in images.items():\n    if value.ndim == 2:\n        num_grey_scale += 1\n        if not key in top_names:\n            num_grey_scale_unpopular +=1\n        \npercentage_grey_scale = num_grey_scale/total\npercentage_grey_scale_unpopular = num_grey_scale_unpopular/total\n\nprint(f'Percentage of grey scale images  {percentage_grey_scale*100}%')\nprint(f'Percentage of small data grey scale images  {percentage_grey_scale_unpopular*100}%')","execution_count":59,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9121ac79aa83d94fde31af72abea60f7a21fce8"},"cell_type":"code","source":"img_sizes = Counter([value.shape[:2] for value in images.values()])\n\nsize, freq = zip(*Counter({i: v for i, v in img_sizes.items() if v > 1}).most_common(20))\n\nplt.figure(figsize=(10, 6))\n\nplt.bar(range(len(freq)), list(freq), align='center')\nplt.xticks(range(len(size)), list(size), rotation=70)\nplt.title(\"Image size frequencies (where freq > 1)\")\n\nplt.show()","execution_count":62,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}