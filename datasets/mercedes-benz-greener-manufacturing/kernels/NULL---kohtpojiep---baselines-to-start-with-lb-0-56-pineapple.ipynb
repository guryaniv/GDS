{"nbformat_minor": 0, "cells": [{"outputs": [], "metadata": {"_cell_guid": "42f56561-2bf8-d63b-f0f4-80bad6f10205", "_uuid": "5c356f144071a9d97abaccf0f437277c2add67ac"}, "execution_count": null, "source": "Hi, Kagglers!\n\nHereafter I will try to publish **some basic approaches to climb up the Leaderboard**\n\n**Competition goal**\n\nIn this competition, Daimler is challenging Kagglers to tackle the curse of dimensionality and reduce the time that cars spend on the test bench.\n<br>Competitors will work with a dataset representing different permutations of Mercedes-Benz car features to predict the time it takes to pass testing. <br>Winning algorithms will contribute to speedier testing, resulting in lower carbon dioxide emissions without reducing Daimler\u2019s standards. \n\n**The Notebook adopts skeleton from (maybe?) this script: https://www.kaggle.com/ermolushka/starter-xgboost**\n\n### Stay tuned, this notebook will be updated on a regular basis\n**P.s. Upvotes and comments would let me update it faster and in a more smart way :)**", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "f56612b7-5e56-a982-e444-2e803d037696", "_uuid": "80fcc7a81407a0bc551f8dd182e41cc2c0a0c7a0"}, "execution_count": null, "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib as plt", "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "9b0c5167-5916-1295-6c9a-dd1f6398c2ce", "_uuid": "65573e70586dba2aa73f841475a9c352fcd850ea"}, "execution_count": null, "source": "### Import", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "c1860d05-f575-5b2b-af7e-53478e209504", "_uuid": "e806738a2b1a05f5b7907d9bdb5a398022726e45"}, "execution_count": null, "source": "# read datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# process columns, apply LabelEncoder to categorical features\n#for c in train.columns:\n#    if train[c].dtype == 'object':\n#        lbl = LabelEncoder() \n#        lbl.fit(list(train[c].values) + list(test[c].values)) \n#        train[c] = lbl.transform(list(train[c].values))\n#        test[c] = lbl.transform(list(test[c].values))\n\n# shape        \nprint('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))\n#train = train[train.y < 120]\ntrain.shape", "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "e1b670a7-996f-1b2c-4f94-46fbac0ff748", "_uuid": "5f795c0437455587bc5bba4b6c05857a34f9f678"}, "execution_count": null, "source": "### Add decomposed components: PCA / ICA etc.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "d4d2a6a5-f3fb-241f-ff1b-27206031e5d5", "_uuid": "159aecb88278a76d48e99f8f7a642b389d8261d1"}, "execution_count": null, "source": "from sklearn.decomposition import PCA, FastICA\nn_comp = 20\nprint(train)\nprint(np.corrcoef(train))\n# PCA\npca = PCA(n_components=n_comp, random_state=42)\npca2_results_train = pca.fit_transform(train.drop([\"y\"], axis=1))\n#print(pca.explained_variance_ratio_)\npca2_results_test = pca.transform(test)\nprint(pca2_results_train.shape)\n# ICA\nica = FastICA(n_components=n_comp, random_state=42)\nica2_results_train = ica.fit_transform(train.drop([\"y\"], axis=1))\nica2_results_test = ica.transform(test)\n\n# Append decomposition components to datasets\nfor i in range(1, n_comp+1):\n    train['pca_' + str(i)] = pca2_results_train[:,i-1]\n    test['pca_' + str(i)] = pca2_results_test[:, i-1]\n    \n    train['ica_' + str(i)] = ica2_results_train[:,i-1]\n    test['ica_' + str(i)] = ica2_results_test[:, i-1]\n    \ny_train = train[\"y\"]\ny_mean = np.mean(y_train)", "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "48fabb21-c780-c666-74f1-9fd1dbfe3c4e", "_uuid": "ec18e1106e973733f3577544ed3283828c4d40ec"}, "execution_count": null, "source": "### Preparing Regressor", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "29b158b3-ce67-f979-31d4-11103dd0b968", "_uuid": "0b2bd7c44e3e5e2b64685b2561322f1ccded1e0f"}, "execution_count": null, "source": "from sklearn.ensemble import RandomForestRegressor\nregr_rf = RandomForestRegressor(max_depth=30, random_state=2)\nregr_rf.fit(train.drop('y',axis=1),y_train)", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "5f634dac-4ad8-7c09-9603-5fa817140136", "_uuid": "017d659d19466bda297c4d395791636106b5c4d8"}, "execution_count": null, "source": "# check f2-score (to get higher score - increase num_boost_round in previous cell)\nfrom sklearn.metrics import r2_score\n\n# now fixed, correct calculation\nprint(r2_score(dtrain.get_label(), model.predict(dtrain)))", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "169562ea-efbe-92b1-6f13-08f34b6597a5", "_uuid": "cc6855b9eb7a3a63107aea47b5078e6a100d68e6"}, "execution_count": null, "source": "# make predictions and save results\nprint(\"Original test shape: \" + str(test.shape))\nprint(\"Dtest: \" + str(dtest.num_row()) + \" , \" + str(dtest.num_col()))\ny_pred = model.predict(dtest)\noutput = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\noutput.to_csv('xgboost-depth{}-pca-ica.csv'.format(xgb_params['max_depth']), index=False)", "cell_type": "code"}], "metadata": {"language_info": {"name": "python", "version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "_is_fork": false, "_change_revision": 0}, "nbformat": 4}