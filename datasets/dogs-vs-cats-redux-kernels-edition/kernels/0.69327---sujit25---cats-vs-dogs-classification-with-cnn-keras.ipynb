{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom os import listdir\nfrom os.path import join, basename\nfrom PIL import Image\nprint(listdir(\"../input\"))\nprint(listdir(\".\"))\nIMG_HEIGHT = 50\nIMG_WIDTH = 50\nNUM_CHANNELS = 3\n\nfrom threading import current_thread, Thread, Lock\nfrom multiprocessing import Queue\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"9cbc563b-c649-4d7d-b8e9-6d9d1e2e910a","_uuid":"9a4939ace112a2d5401261184ac7cef13df9402b","collapsed":true,"trusted":true},"cell_type":"code","source":"# initializations related to threading stuff\nbatch_size = 500\nnum_train_images = 25000\nnum_test_images = 12500\nnum_train_threads = int(num_train_images/batch_size)  # 50\nnum_test_threads = int(num_test_images/batch_size)    # 25\nlock = Lock()","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"9412af61-431b-4d75-847e-5d8868fc9aa8","_uuid":"c07700d4deee3209797f2f3f0686f5333196a249","collapsed":true,"trusted":true},"cell_type":"code","source":"# use of queue for collecting results from threads\ndef initialize_queue():\n    queue = Queue()\n    return queue","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_dir_path = \"../input/\" + \"train\"\ntest_dir_path = \"../input/\" + \"test\"\n\ntrain_imgs = [join(train_dir_path,f) for f in listdir(train_dir_path)]\ntest_imgs = [join(test_dir_path,f) for f in listdir(test_dir_path)]\nprint(len(train_imgs))\nprint(len(test_imgs))","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"f0163bc3-70a2-4356-8308-c1e27d32c848","_uuid":"b1c14c2c29624eb9b769ce8f35eb24bd08d2f6a6","collapsed":true,"trusted":true},"cell_type":"code","source":"# one hot encode labels based on name of image file\ndef get_img_label(fpath):\n    category = fpath.split(\".\")[-3]\n    if category == \"dog\":\n        return [1,0]\n    elif category == \"cat\":\n        return [0,1]","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"fad1ec9d-cd73-4801-af4e-acb30bdbc939","_uuid":"79b8d066afde564112439b838bb4b1150afd9974","collapsed":true,"trusted":true},"cell_type":"code","source":"def get_img_array_labels(fpaths, queue):\n    img_array = None\n    labels = []\n    for f in fpaths:\n        arr = Image.open(f)\n        arr = arr.resize((IMG_HEIGHT,IMG_WIDTH), Image.ANTIALIAS)\n        arr = np.reshape(arr, (-1, IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS))\n        if img_array is None:\n            img_array = arr\n        else:\n            img_array = np.vstack((img_array, arr))\n        labels.append(get_img_label(basename(f)))\n    labels = np.array(labels)\n    queue.put((img_array, labels))","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"affa55d4-de26-44fc-a733-9d8721fd5c22","_uuid":"f42d21614e845f8e1e193500ac0b935a791ccdf4","collapsed":true,"trusted":true},"cell_type":"code","source":"# convert testing images to numpy array\ndef get_img_array(fpaths, queue):\n    img_array = None\n    for f in fpaths:\n        arr = Image.open(f)\n        arr = arr.resize((IMG_HEIGHT,IMG_WIDTH), Image.ANTIALIAS)\n        arr = np.reshape(arr, (-1, IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS))\n        if img_array is None:\n            img_array = arr\n        else:\n            img_array = np.vstack((img_array, arr))        \n    queue.put(img_array)","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"689244ea-6932-47f6-bf4e-f9191d7b9124","_uuid":"4bc57f353f8079d570d6f3635a4e352240a38b79","collapsed":true,"trusted":true},"cell_type":"code","source":"def dump_array(fname,arr):\n    with open(fname,'wb') as f:\n        pickle.dump(arr,f)","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"82641566-da99-47b0-8d1d-738d3291a0ed","_uuid":"5bc5d78fb4eef3bdeab299a0727c26b8a0a86a58","collapsed":true,"trusted":true},"cell_type":"code","source":"def load_pickled_array(fname,arr):\n    with open(fname, 'rb') as f:\n        return pickle.load(f)","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"b34b10af-4b84-45db-a801-3fe80fa3b4c5","_uuid":"2a417dc6d391df552d5f54e3c3b2a3059e493f74","collapsed":true,"trusted":true},"cell_type":"code","source":"# using threading combine training array and labels for training data\ndef get_training_data():\n    threads_list = list()\n    train_x = None\n    train_y = []\n    queue = initialize_queue()\n    # iterate over num of threads to create\n    for thread_index in range(num_train_threads):\n        start_index = thread_index * batch_size\n        end_index = (thread_index + 1) * batch_size\n        file_batch = train_imgs[start_index:end_index]\n        thread = Thread(target =get_img_array_labels, args=(file_batch, queue))\n        thread.start()\n        print(\"Thread: {}, start index: {}, end index: {}\".format(thread.name, start_index, end_index))\n        threads_list.append(thread)\n    \n    # join threads\n    for t in threads_list:\n        t.join()\n    while not queue.empty():\n        arr, labels = queue.get()\n        train_y.extend(labels)\n        if train_x is None:\n            train_x = arr\n        else:\n            train_x = np.vstack((train_x, arr))\n    return train_x, train_y","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"c475af6a-7486-4022-86ff-63993f7dad3c","_uuid":"018a148226530bb74723d308770de3c409fad63d","collapsed":true,"trusted":true},"cell_type":"code","source":"# using multithreading combine testing array for testing data\ndef get_testing_data():\n    threads_list = list()\n    test_x = None\n    queue = initialize_queue()\n    # iterate over num of threads to create\n    for thread_index in range(num_test_threads):\n        start_index = thread_index * batch_size\n        end_index = (thread_index + 1) * batch_size\n        file_batch = train_imgs[start_index:end_index]\n        thread = Thread(target =get_img_array, args=(file_batch, queue))\n        thread.start()\n        print(\"Thread: {}, start index: {}, end index: {}\".format(thread.name, start_index, end_index))\n        threads_list.append(thread)\n    \n    # join threads\n    for t in threads_list:\n        t.join()\n        print(\"Thread: {} joined\", t.name)\n    while not queue.empty():\n        arr= queue.get()\n        if test_x is None:\n            test_x = arr\n        else:\n            test_x = np.vstack((test_x, arr))\n    return test_x","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"f675a559-6161-42c4-8542-888342f9161a","_uuid":"da69be260c2959789b3d4f0c4ac8821e161447dd","trusted":true},"cell_type":"code","source":"# convert training images to train_x and train_y\ntrain_x, train_y = get_training_data()","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"34342fd3-bfbc-4bde-a5ea-d26317072685","scrolled":true,"_uuid":"0a7581e5c8c88ce859ba07f9db0c8169e7d4c323","collapsed":true,"trusted":false},"cell_type":"code","source":"print(train_x.shape)\nprint(len(train_y))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"05af746f-54d9-4ed5-b45f-bfedecf22bb1","_uuid":"b53b1576020e880c794b396ee532dc27ddc8a3ed","collapsed":true,"trusted":false},"cell_type":"code","source":"test_x =get_testing_data()\nprint(test_x.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8e5808f3-5494-4902-8bd0-5de95e525104","_uuid":"6fec5eca011c3ecb6db45cdd37e11ecb90441cd2","collapsed":true,"trusted":false},"cell_type":"code","source":"# dump training data\nimport pickle\ndump_array('train_arr.pickle',train_x)\ndump_array('train_labels.pickle',train_y)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2ba0cc13-2ce7-420a-b130-02d10ecf83b4","_uuid":"be5494571b2187511f554d54879258b812a3fac7","collapsed":true,"trusted":false},"cell_type":"code","source":"# dump testing data\ndump_array('test_arr.pickle',test_x)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"708e86eb-2efe-4f2a-b821-ea53cd4600f1","_uuid":"7159fe2a3fd0493e9e875085b387af22ce3d32c9","collapsed":true,"trusted":false},"cell_type":"code","source":"print(\"train_x shape\",train_x.shape)\nprint(\"test_x shape\", test_x.shape)\n# convert train_y to np. array\ntrain_y = np.array(train_y)\nprint(\"train_y.shape\", train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e7c3dd26-2d92-4adf-a8f0-a8380e9e3c46","_uuid":"1f3e127aced8c9acc2a6303464ea617dca23a118","collapsed":true,"trusted":false},"cell_type":"code","source":"# mean normalize train and test images\ntrain_x = train_x/255\ntest_x = test_x/255","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8cf0fa52-3591-4d7c-9d3c-eaee6252ba6e","_uuid":"bf5460e859ceed2b5e85d2c3e81c35c2b899d046","trusted":false,"collapsed":true},"cell_type":"code","source":"# import required packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils, to_categorical\n\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6b36f448-6c85-4b09-a342-a12bf949137b","_uuid":"3978c9642982cf4be9e371bf85f4cfebeb2b2703","collapsed":true,"trusted":false},"cell_type":"code","source":"# CNN model\n# CNN model\nmodel = Sequential()\n\n# -----------------------------------------------------------------------------------\n# conv 1\nmodel.add(Conv2D(16, (3,3), input_shape=(50,50,3))) # 148,148,32\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Activation('relu'))\n#model.add(Dropout(0.5))\n\n# max pool 1\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=2))          # 72,72,32\n\n# -----------------------------------------------------------------------------------\n# conv 2\nmodel.add(Conv2D(16, (3,3)))                      # 68,68,32\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Activation('relu'))\n#model.add(Dropout(0.5))\n\n# max pool 2\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=2))          # 34,34,32\n# -----------------------------------------------------------------------------------\n\n# conv 3\nmodel.add(Conv2D(32, (3,3)))                      # 32,32,32\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Activation('relu'))\n#model.add(Dropout(0.7))\n\n# max pool 3\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=2))          # 17,17,32\n# -----------------------------------------------------------------------------------\n\n# conv 4\nmodel.add(Conv2D(32, (3,3)))                      # 15,15,32\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Activation('relu'))\n#model.add(Dropout(0.7))\n# max pool 4\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=2))  # 7,7,32\n\n# flatten\nmodel.add(Flatten())\n\n\n# fc layer 1\nmodel.add(Dense(512, activation='relu'))\n\n#model.add(Dropout(0.7))\n\n#model.add(Dense(256, activation='relu'))\n\n#model.add(Dropout(0.5))\n\n# fc layer 2\nmodel.add(Dense(2, activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"351169da-d1f7-4201-83f8-fa24bb91f302","_uuid":"e9e73dfb4714ad90f8c208d80d3af545342a2703","collapsed":true,"trusted":false},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0826428c-35db-4fec-8256-719bcec4321e","_uuid":"0182e4e40b3813265bfe4e2954fd97defac974ab","collapsed":true,"trusted":false},"cell_type":"code","source":"print(onehot_encoded_arr[:2])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4375fa16-207d-4d60-bce8-1b605cbf4663","_uuid":"fa5785d394b86683b35d6b0d866a3934f564f790","collapsed":true,"trusted":false},"cell_type":"code","source":"#model.(valdn_x, valdn_y, batch_size=32, verbose=1)\npredictions = model.predict(test_x, batch_size=32, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"40afd710-09e6-460d-9e55-342a16b5c9f9","_uuid":"97f576c1d4083c0160fd319817e09cdd01dd92ce","collapsed":true,"trusted":false},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"71a58d8e-2771-48b9-87ea-5fa56568d3d3","_uuid":"11cfd8a11c440e90fbdfb398e55e2570457f7658","collapsed":true,"trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nfig=plt.figure()\n\nfor index in range(12):\n    # cat: [1,0]\n    # dog: [0,1]\n    y = fig.add_subplot(3,4,index+1)\n    #model_out = model.predict([data])[0]\n    img = test_x[index]\n    model_out = predictions[index]\n    if np.argmax(model_out) == 0: str_label='Dog'\n    else: str_label='Cat'\n        \n    y.imshow(img)\n    plt.title(str_label)\n    y.axes.get_xaxis().set_visible(False)\n    y.axes.get_yaxis().set_visible(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3117c220-17a0-45c2-b4c1-87706bbabbf5","_uuid":"ca611bfb79a8a53a82c044333e1cd485e2b16df3","collapsed":true,"trusted":false},"cell_type":"code","source":"with open('submission.csv','w') as f:\n    f.write('id,label\\n')\n    for index in range(len(test_imgs)):\n        img_id =basename(test_imgs[index]).split(\".\")[0]\n        prob = (predictions[index,0])\n        #print(\"index: {}, img_id: {}, prob:{}\".format(index,img_id, prob))\n        f.write(\"{},{}\\n\".format(img_id, prob))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}