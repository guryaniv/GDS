{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"# Digit Identifier using Convolutional Neural Networks - MNIST Dataset\n* In this dataset, we need to train our model on the training set and use that model to predict the digits in the testing set.\n* The files have grey scale images of hand drawn digits from 0 - 9.\n* The training set has 42000 images and the file has 785 columns - 1 column for label and the 784 columns for pixel information.\n* The testing set has 28000 images and the file has  784 columns - no label, just the pixel information.\n* We will be using a CNN model in Keras for this problem!"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**(1). Importing all the necessary modules and packages:**"},{"metadata":{"trusted":true,"_uuid":"7514789042cbc57b164e506d22d86735b0fcb309","collapsed":true},"cell_type":"code","source":"# IMPORTING NECESSARY PACKAGES AND MODULES\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom collections import Counter\nimport itertools\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\n#IMPORTING KERAS AND RELATED MODULES\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Flatten,Conv2D,MaxPool2D,Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n#SETTING GLOBAL VARIABLES:\nbatch = 64\nclasses = 10\nepochs = 20\ninput_shape = (28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7da9e9eb620915d3e79924c848b27d5e56e5f165"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"9de9fe234abe9aa4a06515c4b30e03d1ea26441c"},"cell_type":"markdown","source":"**(2). Loading and Visualizing the dataset:**"},{"metadata":{"trusted":true,"_uuid":"3ae42df493671bbd61eb7f5f6967e58972bbf019","collapsed":true},"cell_type":"code","source":"#LOADING THE TRAINING DATASET\ntrainingset = pd.read_csv(\"../input/train.csv\")\nprint(trainingset.shape)\ntrainingset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d92fbffbcc3df48f1c73606c865a1e1d4041b564","collapsed":true},"cell_type":"code","source":"#LOADING THE TESTING DATASET\ntestingset = pd.read_csv(\"../input/test.csv\")\nprint(testingset.shape)\ntestingset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13fcd0e84679f7ecb845b17740404940d0ae3e3c","collapsed":true},"cell_type":"code","source":"# CHECKING THE TRAINING DATASET FOR THE DISTRIBUTION OF THE NUMBERS\nprint(trainingset['label'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dad9ba7a65b3535d4e9055b8d074216afdb34426"},"cell_type":"markdown","source":"**(3). Splitting the Training Dataset into X and Y Training Sets for future training:**"},{"metadata":{"trusted":true,"_uuid":"841cf569f8129cafbdff91adf52ffb0efb8d12cc","collapsed":true},"cell_type":"code","source":"x_train = trainingset.ix[:,1:].values.astype('float32')\ny_train = trainingset.ix[:,0].values.astype('int32')\nx_test = testingset.values.astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc308f42164924c712c9be9cbaaa18def09a90f9"},"cell_type":"markdown","source":"Let's plot some of the images to see the dataset!"},{"metadata":{"trusted":true,"_uuid":"3d16b452feb50f8cda37043bce3073b4d8629311","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nx,y = 10,2\nfor i in range(20):\n    plt.subplot(y,x,i+1)\n    plt.imshow(x_train[i].reshape(28,28),interpolation='nearest')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5016caccf1fa80d469dae97b07c7e1921ee2e75a"},"cell_type":"markdown","source":"**(4). Reshaping the data to match the network:**\n* We reshape the images to 28,28,1 because we have set the network imput size to (28,28,1)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3e693569825e8db38823f1dd6ab295774ad4fb47"},"cell_type":"code","source":"X_Tr = x_train.reshape(x_train.shape[0],28,28,1)\nX_Te = x_test.reshape(x_test.shape[0],28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae98728f742016a59186cecb580756952418a792"},"cell_type":"markdown","source":"**(5). Splitting the dataset for validation and to convert the vectors into matrices  - categorical variables:**"},{"metadata":{"trusted":true,"_uuid":"eebb470fad0bfa0244fdb34c956328995ce0b56e","collapsed":true},"cell_type":"code","source":"y_train = keras.utils.to_categorical(y_train,classes)\nX_Tr,X_Va,Y_tr,Y_Va = train_test_split(X_Tr,y_train,test_size=0.1,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a5ccf2cfc556416adab977f861279b4d0a76533"},"cell_type":"markdown","source":"**(6). Defining the Neural Network Model:**"},{"metadata":{"trusted":true,"_uuid":"fe497f305f3ec41bddb03380b2c66e8d3a9f7e2f","collapsed":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.20))\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.RMSprop(),\n              metrics=['accuracy'])\n\nlrr = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001)\n\ndata = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=15, # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62468e90f412322e5198a4527b6f16a325c40237"},"cell_type":"markdown","source":"Training!"},{"metadata":{"trusted":true,"_uuid":"cc34436e9236bd7c57aa0b2281a5423a79ba4902","collapsed":true},"cell_type":"code","source":"data.fit(X_Tr)\nruns =  model.fit_generator(data.flow(X_Tr,Y_tr, batch_size=batch),\n                              epochs = epochs, validation_data = (X_Va,Y_Va),\n                              verbose = 1, steps_per_epoch=X_Tr.shape[0] // batch\n                              , callbacks=[lrr],)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06960ffbaf799b24ca702bc27424c7358b886bb5"},"cell_type":"markdown","source":"**(7). Finding the final loss and accuracy:**"},{"metadata":{"trusted":true,"_uuid":"678124fab92f07f48d289142bc77d623767e2ccb","collapsed":true},"cell_type":"code","source":"fl,fac = model.evaluate(X_Va,Y_Va,verbose=0)\nprint(\"Final Loss =\",fl)\nprint(\"Final Accuracy =\",fac)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d24d474b2922cb8823b8102098c515a20230e07"},"cell_type":"markdown","source":"**(8). Plotting the Confusion Matrix:**"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0c84331d50e55db5f58fe466f2ab15098a7a4edd"},"cell_type":"code","source":"y_pred = model.predict(X_Va)\ny_classes = np.argmax(y_pred,axis=1)\ny_ohv = np.argmax(Y_Va,axis=1)\ncm = confusion_matrix(y_ohv,y_classes)\nprint(\"Confusion Matrix:\")\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44f6399e2187f0f726706628b80941507e2d9612"},"cell_type":"markdown","source":"**(9). Checking the errors and visualizing them:**"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3b9eb18865abddb8f2275e2caf23e385b115f270"},"cell_type":"code","source":"errors = (y_classes - y_ohv != 0)\n\ny_classes_errors = y_classes[errors]\ny_pred_errors = y_pred[errors]\ny_ohv_errors = y_ohv[errors]\nX_Va_errors = X_Va[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    n = 0\n    nrows = 3\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n#PROBABILITY OF WRONG PREDICTION\ny_pred_errors_prob = np.max(y_pred_errors,axis = 1)\n\n# PROBABILITY OF TRUE VALUES IN ERROR SET\ntrue_prob_errors = np.diagonal(np.take(y_pred_errors, y_ohv_errors, axis=1))\n\n# DIFFERENCE BETWEEN TRUE AND ERROR SET\ndelta_pred_true_errors = y_pred_errors_prob - true_prob_errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 9 errors \nmost_important_errors = sorted_dela_errors[-9:]\n\n# Show the top 9 errors\ndisplay_errors(most_important_errors, X_Va_errors, y_classes_errors, y_ohv_errors)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef67cac8134f786b2db844ba8c46d1ee14eeee27"},"cell_type":"markdown","source":"**(10). Classification of the testing dataset:**"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6aacc5816877378e8750fb0903a5df4f56626e50"},"cell_type":"code","source":"pred = model.predict_classes(X_Te)\ny_real = testingset.iloc[:,0]\ntrue = np.nonzero(pred==y_real)[0]\nfalse = np.nonzero(pred!=y_real)[0]\n\nsubmit = pd.DataFrame({'ImageId': list(range(1,len(pred)+1)),'Label':pred})\nsubmit.to_csv(\"final.csv\",index=False,header=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}