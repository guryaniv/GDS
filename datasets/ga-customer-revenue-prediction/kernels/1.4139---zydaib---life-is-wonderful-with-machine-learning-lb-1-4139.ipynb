{"cells":[{"metadata":{"_uuid":"26d4cfe2eecc87421741a389da18ccae668ef94f"},"cell_type":"markdown","source":"**Before Using this kernel:**\n\npreprocessed dataset by olivier https://www.kaggle.com/ogrellier/create-extracted-json-fields-dataset  \nexported google analytics data https://www.kaggle.com/satian/exported-google-analytics-data  \nfuture is here https://www.kaggle.com/ashishpatel26/future-is-here  \nteach-lightgbm-to-sum-predictions https://www.kaggle.com/satian/story-of-a-leak/notebook  \nThanks for YouHan Lee : https://www.kaggle.com/youhanlee/stratified-sampling-for-regression-lb-1-4627  \n\n**If you like my kernel pls press like my kernel**\n\nIf you have any question pls let me know and I would share my idea and try my best to answer you.  \nOr you can send me the email: johnnyjana730@yahoo.com.tw.\nMaybe I would tell you some tip in this competition.\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nimport gc\nimport time\nfrom pandas.core.common import SettingWithCopyWarning\nimport warnings\nimport lightgbm as lgb\nfrom sklearn.model_selection import GroupKFold\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/create-extracted-json-fields-dataset/extracted_fields_train.gz', \n                    dtype={'date': str, 'fullVisitorId': str, 'sessionId':str}, nrows=None)\ntest = pd.read_csv('../input/create-extracted-json-fields-dataset/extracted_fields_test.gz', \n                   dtype={'date': str, 'fullVisitorId': str, 'sessionId':str}, nrows=None)\ntrain['totals.transactionRevenue'] = train['totals.transactionRevenue'].fillna(0)\ny_reg = train['totals.transactionRevenue']\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3919d6f5cc0684f1174f3a8235788f2da71f38b"},"cell_type":"code","source":"def get_folds(df=None, n_splits=5):\n    \"\"\"Returns dataframe indices corresponding to Visitors Group KFold\"\"\"\n    # Get sorted unique visitors\n    unique_vis = np.array(sorted(df['fullVisitorId'].unique()))\n\n    # Get folds\n    folds = GroupKFold(n_splits=n_splits)\n    fold_ids = []\n    ids = np.arange(df.shape[0])\n    for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n        fold_ids.append(\n            [\n                ids[df['fullVisitorId'].isin(unique_vis[trn_vis])],\n                ids[df['fullVisitorId'].isin(unique_vis[val_vis])]\n            ]\n        )\n\n    return fold_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3aa09972b465aff2d230c0152088a6f0b41e93a"},"cell_type":"code","source":"y_reg = train['totals.transactionRevenue'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b98c54fbcca78e3ec6e1ad7f1ccd9d6683a5513"},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6882d23fe594e514beb7430e0058940dbaa5774"},"cell_type":"code","source":"train['target'] = y_reg\nfor df in [train, test]:\n    df['date'] = pd.to_datetime(df['visitStartTime'], unit='s')\n    df['sess_date_dow'] = df['date'].dt.dayofweek\n    df['sess_date_hours'] = df['date'].dt.hour\n    df['sess_date_dom'] = df['date'].dt.day\n    df.sort_values(['fullVisitorId', 'date'], ascending=True, inplace=True)\n    df['next_session_1'] = (\n        df['date'] - df[['fullVisitorId', 'date']].groupby('fullVisitorId')['date'].shift(1)\n    ).astype(np.int64) // 1e9 // 60 // 60\n    df['next_session_2'] = (\n        df['date'] - df[['fullVisitorId', 'date']].groupby('fullVisitorId')['date'].shift(-1)\n    ).astype(np.int64) // 1e9 // 60 // 60\n\ny_reg = train['target']\ndel train['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"403b03e0a5cac53bbc8f654a0b90e2d9b574d6b8"},"cell_type":"code","source":"def browser_mapping(x):\n    browsers = ['chrome','safari','firefox','internet explorer','edge','opera','coc coc','maxthon','iron']\n    if x in browsers:\n        return x.lower()\n    elif  ('android' in x) or ('samsung' in x) or ('mini' in x) or ('iphone' in x) or ('in-app' in x) or ('playstation' in x):\n        return 'mobile browser'\n    elif  ('mozilla' in x) or ('chrome' in x) or ('blackberry' in x) or ('nokia' in x) or ('browser' in x) or ('amazon' in x):\n        return 'mobile browser'\n    elif  ('lunascape' in x) or ('netscape' in x) or ('blackberry' in x) or ('konqueror' in x) or ('puffin' in x) or ('amazon' in x):\n        return 'mobile browser'\n    elif '(not set)' in x:\n        return x\n    else:\n        return 'others'\ndef adcontents_mapping(x):\n    if  ('google' in x):\n        return 'google'\n    elif  ('placement' in x) | ('placememnt' in x):\n        return 'placement'\n    elif '(not set)' in x or 'nan' in x:\n        return x\n    elif 'ad' in x:\n        return 'ad'\n    else:\n        return 'others'\n    \ndef source_mapping(x):\n    if  ('google' in x):\n        return 'google'\n    elif  ('youtube' in x):\n        return 'youtube'\n    elif '(not set)' in x or 'nan' in x:\n        return x\n    elif 'yahoo' in x:\n        return 'yahoo'\n    elif 'facebook' in x:\n        return 'facebook'\n    elif 'reddit' in x:\n        return 'reddit'\n    elif 'bing' in x:\n        return 'bing'\n    elif 'quora' in x:\n        return 'quora'\n    elif 'outlook' in x:\n        return 'outlook'\n    elif 'linkedin' in x:\n        return 'linkedin'\n    elif 'pinterest' in x:\n        return 'pinterest'\n    elif 'ask' in x:\n        return 'ask'\n    elif 'siliconvalley' in x:\n        return 'siliconvalley'\n    elif 'lunametrics' in x:\n        return 'lunametrics'\n    elif 'amazon' in x:\n        return 'amazon'\n    elif 'mysearch' in x:\n        return 'mysearch'\n    elif 'qiita' in x:\n        return 'qiita'\n    elif 'messenger' in x:\n        return 'messenger'\n    elif 'twitter' in x:\n        return 'twitter'\n    elif 't.co' in x:\n        return 't.co'\n    elif 'vk.com' in x:\n        return 'vk.com'\n    elif 'search' in x:\n        return 'search'\n    elif 'edu' in x:\n        return 'edu'\n    elif 'mail' in x:\n        return 'mail'\n    elif 'ad' in x:\n        return 'ad'\n    elif 'golang' in x:\n        return 'golang'\n    elif 'direct' in x:\n        return 'direct'\n    elif 'dealspotr' in x:\n        return 'dealspotr'\n    elif 'sashihara' in x:\n        return 'sashihara'\n    elif 'phandroid' in x:\n        return 'phandroid'\n    elif 'baidu' in x:\n        return 'baidu'\n    elif 'mdn' in x:\n        return 'mdn'\n    elif 'duckduckgo' in x:\n        return 'duckduckgo'\n    elif 'seroundtable' in x:\n        return 'seroundtable'\n    elif 'metrics' in x:\n        return 'metrics'\n    elif 'sogou' in x:\n        return 'sogou'\n    elif 'businessinsider' in x:\n        return 'businessinsider'\n    elif 'github' in x:\n        return 'github'\n    elif 'gophergala' in x:\n        return 'gophergala'\n    elif 'yandex' in x:\n        return 'yandex'\n    elif 'msn' in x:\n        return 'msn'\n    elif 'dfa' in x:\n        return 'dfa'\n    elif '(not set)' in x:\n        return '(not set)'\n    elif 'feedly' in x:\n        return 'feedly'\n    elif 'arstechnica' in x:\n        return 'arstechnica'\n    elif 'squishable' in x:\n        return 'squishable'\n    elif 'flipboard' in x:\n        return 'flipboard'\n    elif 't-online.de' in x:\n        return 't-online.de'\n    elif 'sm.cn' in x:\n        return 'sm.cn'\n    elif 'wow' in x:\n        return 'wow'\n    elif 'baidu' in x:\n        return 'baidu'\n    elif 'partners' in x:\n        return 'partners'\n    else:\n        return 'others'\n\ntrain['device.browser'] = train['device.browser'].map(lambda x:browser_mapping(str(x).lower())).astype('str')\ntrain['trafficSource.adContent'] = train['trafficSource.adContent'].map(lambda x:adcontents_mapping(str(x).lower())).astype('str')\ntrain['trafficSource.source'] = train['trafficSource.source'].map(lambda x:source_mapping(str(x).lower())).astype('str')\n\ntest['device.browser'] = test['device.browser'].map(lambda x:browser_mapping(str(x).lower())).astype('str')\ntest['trafficSource.adContent'] = test['trafficSource.adContent'].map(lambda x:adcontents_mapping(str(x).lower())).astype('str')\ntest['trafficSource.source'] = test['trafficSource.source'].map(lambda x:source_mapping(str(x).lower())).astype('str')\n\ndef process_device(data_df):\n    print(\"process device ...\")\n    data_df['source.country'] = data_df['trafficSource.source'] + '_' + data_df['geoNetwork.country']\n    data_df['campaign.medium'] = data_df['trafficSource.campaign'] + '_' + data_df['trafficSource.medium']\n    data_df['browser.category'] = data_df['device.browser'] + '_' + data_df['device.deviceCategory']\n    data_df['browser.os'] = data_df['device.browser'] + '_' + data_df['device.operatingSystem']\n    return data_df\n\ntrain = process_device(train)\ntest = process_device(test)\n\ndef custom(data):\n    print('custom..')\n    data['device_deviceCategory_channelGrouping'] = data['device.deviceCategory'] + \"_\" + data['channelGrouping']\n    data['channelGrouping_browser'] = data['device.browser'] + \"_\" + data['channelGrouping']\n    data['channelGrouping_OS'] = data['device.operatingSystem'] + \"_\" + data['channelGrouping']\n    \n    for i in ['geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country','geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region','geoNetwork.subContinent']:\n        for j in ['device.browser','device.deviceCategory', 'device.operatingSystem', 'trafficSource.source']:\n            data[i + \"_\" + j] = data[i] + \"_\" + data[j]\n    \n    data['content.source'] = data['trafficSource.adContent'] + \"_\" + data['source.country']\n    data['medium.source'] = data['trafficSource.medium'] + \"_\" + data['source.country']\n    return data\n\ntrain = custom(train)\ntest = custom(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1208c8c802675dd10a87af9533eee84c2e7bbaf0"},"cell_type":"code","source":"excluded_features = [\n    'date', 'fullVisitorId', 'sessionId', 'totals.transactionRevenue', \n    'visitId', 'visitStartTime', 'vis_date', 'nb_sessions', 'max_visits'\n]\n\ncategorical_features = [\n    _f for _f in train.columns\n    if (_f not in excluded_features) & (train[_f].dtype == 'object')\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4541c424f062bda99e9f91fe5f85ce31ceac7436"},"cell_type":"code","source":"\nexcluded_features = ['date', 'fullVisitorId', 'sessionId', 'totals.transactionRevenue', 'visitId', 'visitStartTime']\n\ncategorical_features = [ _f for _f in train.columns\\\n    if (_f not in excluded_features) & (train[_f].dtype == 'object')]\n\ndropcolumns =  [c for c in categorical_features if train[c].nunique() == 1]\ntrain = train[[_f for _f in train.columns if _f not in dropcolumns]]\ntest = test[[_f for _f in test.columns if _f not in dropcolumns]]\n\ncategorical_features = [ _f for _f in train.columns\\\n    if (_f not in excluded_features) & (train[_f].dtype == 'object')]\n\ndef process_device2(train,test):\n    print(\"process device2 ...\")\n    train_objs_num = len(train)\n    dataset = pd.concat(objs=[train, test], axis=0)\n    for f in categorical_features:\n        dataset[f], indexer = pd.factorize(dataset[f])\n    train = dataset[:train_objs_num]\n    test = dataset[train_objs_num:]\n    del dataset\n    return train, test\n\ntrain, test = process_device2(train,test)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"811a656c2f5a272b507938905a79325610f698b2"},"cell_type":"markdown","source":"**Thanks for YouHan Lee : https://www.kaggle.com/youhanlee/stratified-sampling-for-regression-lb-1-4627    \nMy rewrite version: https://www.kaggle.com/zydaib/try-so-hard    **  \nI just load the previous predictions result to here.\n"},{"metadata":{"trusted":true,"_uuid":"1e291bbc2eb08c6ff90d7b8c6a25eaca581e17dd"},"cell_type":"code","source":"print('load')\n\ntemp_train = pd.read_csv('../input/try-so-hard/temp_train_predictions.csv', \n                    dtype={'fullVisitorId': str}, nrows=None)\ntemp_test = pd.read_csv('../input/try-so-hard/temp_test_predictions.csv',\n                   dtype={'fullVisitorId': str}, nrows=None)\n\nprint('finished')\n\ny_reg = train['totals.transactionRevenue']\n\nexcluded_features = ['date', 'fullVisitorId', 'sessionId', 'totals.transactionRevenue', 'visitId', 'visitStartTime','predictions']\ntrain_features = [_f for _f in train.columns if _f not in excluded_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91a233db23d8f4c04f1e2d93129a426df2643961"},"cell_type":"code","source":"trn_data = train[train_features + ['fullVisitorId']].groupby('fullVisitorId').mean()\ntrn_data.sort_index(inplace=True)\ntrn_pred_list = temp_train[['fullVisitorId', 'predictions']].groupby('fullVisitorId')\\\n    .apply(lambda df: list(df.predictions))\\\n    .apply(lambda x: {'pred_'+str(i): pred for i, pred in enumerate(x)})\ntrn_pred_list.sort_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbbfe28bda3d5a5f406f80c3a05661be903278af"},"cell_type":"code","source":"trn_all_predictions = pd.DataFrame(list(trn_pred_list.values), index=trn_data.index)\ntrn_feats = trn_all_predictions.columns\ntrn_all_predictions['t_mean'] = np.log1p(trn_all_predictions[trn_feats].mean(axis=1))\ntrn_all_predictions['t_median'] = np.log1p(trn_all_predictions[trn_feats].median(axis=1))\ntrn_all_predictions['t_sum_log'] = np.log1p(trn_all_predictions[trn_feats]).sum(axis=1)\ntrn_all_predictions['t_sum_act'] = np.log1p(trn_all_predictions[trn_feats].fillna(0).sum(axis=1))\ntrn_all_predictions['t_nb_sess'] = trn_all_predictions[trn_feats].isnull().sum(axis=1)\nfull_data = pd.concat([trn_data, trn_all_predictions], axis=1)\ndel trn_data, trn_all_predictions, temp_train\ngc.collect()\nfull_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"505c73d241a0028678ae0b0e0241d77c5811fba3"},"cell_type":"code","source":"sub_data = test[train_features + ['fullVisitorId']].groupby('fullVisitorId').mean()\nsub_data.sort_index(inplace=True)\nsub_pred_list = temp_test[['fullVisitorId', 'predictions']].groupby('fullVisitorId')\\\n    .apply(lambda df: list(df.predictions))\\\n    .apply(lambda x: {'pred_'+str(i): pred for i, pred in enumerate(x)})\nsub_pred_list.sort_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcfe48ddfe4113b032fad226ba7ab9bfd0d65c55"},"cell_type":"code","source":"sub_all_predictions = pd.DataFrame(list(sub_pred_list.values), index=sub_data.index)\nfor f in trn_feats:\n    if f not in sub_all_predictions.columns:\n        sub_all_predictions[f] = np.nan\nsub_all_predictions['t_mean'] = np.log1p(sub_all_predictions[trn_feats].mean(axis=1))\nsub_all_predictions['t_median'] = np.log1p(sub_all_predictions[trn_feats].median(axis=1))\nsub_all_predictions['t_sum_log'] = np.log1p(sub_all_predictions[trn_feats]).sum(axis=1)\nsub_all_predictions['t_sum_act'] = np.log1p(sub_all_predictions[trn_feats].fillna(0).sum(axis=1))\nsub_all_predictions['t_nb_sess'] = sub_all_predictions[trn_feats].isnull().sum(axis=1)\nsub_full_data = pd.concat([sub_data, sub_all_predictions], axis=1)\ndel sub_data, sub_all_predictions\ngc.collect()\nsub_full_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1eb11da8cb54b83c0c4d2139ca63684c4f1b4f4c"},"cell_type":"code","source":"train['target'] = y_reg\ntrn_user_target = train[['fullVisitorId', 'target']].groupby('fullVisitorId').sum()\ndel train, test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77f7273cd76e30f384bf98e2432835f4b4e3a8dc"},"cell_type":"code","source":"xgb_params = {\n        'objective': 'reg:linear',\n        'booster': 'gbtree',\n        'learning_rate': 0.02,\n        'max_depth': 22,\n        'min_child_weight': 57,\n        'gamma' : 1.45,\n        'alpha': 0.0,\n        'lambda': 0.0,\n        'subsample': 0.67,\n        'colsample_bytree': 0.054,\n        'colsample_bylevel': 0.50,\n        'n_jobs': -1,\n        'random_state': 456\n    }\n\nfrom xgboost import XGBRegressor\nfolds = get_folds(df=full_data[['totals.pageviews']].reset_index(), n_splits=5)\n\nexcluded_features = ['date', 'fullVisitorId', 'sessionId', 'totals.transactionRevenue', 'visitId', 'visitStartTime']\nfor x in range(40,300,1):\n    excluded_features.append('pred_'+str(x))\nfull_features = [_f for _f in full_data.columns if _f not in excluded_features]\nprint(full_features)\n\noof_preds = np.zeros(full_data.shape[0])\noof_preds1 = np.zeros(full_data.shape[0])\nboth_oof = np.zeros(full_data.shape[0])\nsub_preds = np.zeros(sub_full_data.shape[0])\nlgb_temp = np.zeros(sub_full_data.shape[0])\nxgb_temp = np.zeros(sub_full_data.shape[0])\nfeature_importance_df = pd.DataFrame()\n\nfor fold_, (trn_, val_) in enumerate(folds):\n    print(\"-\"* 20 + \"Fold :\"+str(fold_) + \"-\"* 20)\n    trn_x, trn_y = full_data[full_features].iloc[trn_], trn_user_target['target'].iloc[trn_]\n    val_x, val_y = full_data[full_features].iloc[val_], trn_user_target['target'].iloc[val_]\n    xg = XGBRegressor(**xgb_params, n_estimators=20000)\n    reg = lgb.LGBMRegressor(\n        num_leaves=40,\n        learning_rate=0.02,\n        n_estimators=20000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    print(\"-\"* 20 + \"LightGBM Training\" + \"-\"* 20)\n    reg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(trn_x, np.log1p(trn_y)), (val_x, np.log1p(val_y))],\n        eval_names=['TRAIN', 'VALID'],\n        early_stopping_rounds=50,\n        eval_metric='rmse',\n        verbose=100\n    )\n    print(\"-\"* 20 + \"Xgboost Training\" + \"-\"* 20)\n    xg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(trn_x, np.log1p(trn_y)), (val_x, np.log1p(val_y))],\n        early_stopping_rounds=50,\n        eval_metric='rmse',\n        verbose=100\n    )\n\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = trn_x.columns\n    fold_importance_df[\"importance\"] = reg.feature_importances_\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n    oof_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_preds1[val_] = xg.predict(val_x)\n\n    oof_preds[oof_preds < 0] = 0\n    oof_preds1[oof_preds1 < 0] = 0\n\n    both_oof[val_] = oof_preds[val_] * 0.6 + oof_preds1[val_] * 0.4\n\n    # Make sure features are in the same order\n    _preds = reg.predict(sub_full_data[full_features], num_iteration=reg.best_iteration_)\n    _preds[_preds < 0] = 0\n\n    pre = xg.predict(sub_full_data[full_features])\n    pre[pre<0]=0\n\n    sub_preds += (_preds / len(folds)) * 0.6 + (pre / len(folds)) * 0.4\n    lgb_temp += (_preds / len(folds))\n    xgb_temp += (pre / len(folds)) \n    # sub_preds += (_preds / len(folds)) \n    \ndef display_importances(feature_importance_df_,output_name):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\", as_index=False).mean().sort_values(by=\"importance\", ascending=False)[:40]\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x=\"importance\", y=\"feature\", data=cols.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features_' +output_name + '_(avg over folds)')\n    plt.tight_layout()\n    plt.savefig('importance_'+ output_name + '.png')\n    plt\ndisplay_importances(feature_importance_df,\"2nd train\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a64518a25bb811c0d66afd1418d285d86fba4adc"},"cell_type":"code","source":"print(\"LGB  \", mean_squared_error(np.log1p(trn_user_target['target']), oof_preds) ** .5)\nprint(\"XGB  \", mean_squared_error(np.log1p(trn_user_target['target']), oof_preds1) ** .5)\nprint(\"Combine  \", mean_squared_error(np.log1p(trn_user_target['target']), both_oof) ** .5)\n\n\nsub_full_data['PredictedLogRevenue'] = sub_preds\nsub_full_data[['PredictedLogRevenue']].to_csv('futureisthere_gogogo3_both.csv', index=True)\n\nsub_full_data['PredictedLogRevenue'] = lgb_temp\nsub_full_data[['PredictedLogRevenue']].to_csv('futureisthere_gogogo3_lgb.csv', index=True)\n\nsub_full_data['PredictedLogRevenue'] = xgb_temp\nsub_full_data[['PredictedLogRevenue']].to_csv('futureisthere_gogogo3_xgb.csv', index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbf315ff84776e873fccdfb2c8619a20b31e9aab"},"cell_type":"code","source":"futureishere_result = pd.read_csv('../input/future-is-here/new_test.csv', \n                    dtype={'fullVisitorId': str}, nrows=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f172c26093ef5ccd15d81a6314b148fb4952f79"},"cell_type":"code","source":"# print(sub_full_data)\n\nsub_full_data = sub_full_data.reset_index()\n\nsub_full_data['PredictedLogRevenue_lgb+xgb'] = sub_preds\nsub_full_data['PredictedLogRevenue_lgb'] = lgb_temp\nsub_full_data['PredictedLogRevenue_xgb'] = xgb_temp\nsub_full_data['PredictedLogRevenue_futureishere'] = futureishere_result['PredictedLogRevenue']\n\n# print(futureishere_result)\n# print(sub_full_data)\n\nsub1 = sub_full_data[[\"fullVisitorId\", \"PredictedLogRevenue_lgb+xgb\"]]\nsub2 = sub_full_data[[\"fullVisitorId\", \"PredictedLogRevenue_lgb\"]]\nsub3 = sub_full_data[[\"fullVisitorId\", \"PredictedLogRevenue_xgb\"]]\nsub4 = sub_full_data[[\"fullVisitorId\", \"PredictedLogRevenue_futureishere\"]]\n\ndf_base = pd.merge(sub1,sub2,how='inner',on='fullVisitorId')\ndf_base = pd.merge(df_base,sub3,how='inner',on='fullVisitorId')\ndf_base = pd.merge(df_base,sub4,how='inner',on='fullVisitorId')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11ae472ae9fa87b3df2c9bd72a48c6a6ba3f5393"},"cell_type":"code","source":"plt.figure(figsize=(6,6))\nsns.heatmap(df_base.iloc[:,1:].corr(),annot=True,fmt=\".2f\")\n# plt.show()\ndf_base.iloc[:,1:].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f00713a0985ca438a361da308045f28540e30bbf"},"cell_type":"code","source":"sub_df = pd.DataFrame({\"fullVisitorId\":sub1['fullVisitorId']})\nsub_df[\"PredictedLogRevenue\"] = df_base['PredictedLogRevenue_futureishere'] * 0.6 + df_base['PredictedLogRevenue_lgb+xgb'] * 0.4\n# sub_df[\"PredictedLogRevenue\"] = sub_df[\"PredictedLogRevenue\"]\nsub_df.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\nsub_df.to_csv('blend3itall.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}