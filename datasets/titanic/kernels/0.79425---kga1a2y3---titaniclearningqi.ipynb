{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0005958f-ed25-7f02-8ed7-cab8f92acc84"
      },
      "source": [
        "# Titanic data: Learning from disaster\n",
        "\n",
        "**Task**: predict survival of a passage giving his/her ticket class class, name, gender, age, number of siblings / spouses aboard,  number of parents / children aboard, ticket number, cabin number and Port of embarkation\n",
        "\n",
        "**Notes:**\n",
        " \n",
        "- Based on the tutorial \n",
        "- Fix some bugs\n",
        "- Add cross-validation and grid search\n",
        "- Add Validation and Learning curves\n",
        "\n",
        "Part I : Exploratory Data Analysis\n",
        "-------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e795bc15-d2fe-4cbf-5309-964dcc78a1ed"
      },
      "outputs": [],
      "source": [
        "# data analysis and wrangling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# machine learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Learning curve\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import validation_curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a8a94389-da3b-2bac-4499-21098e85fdb8"
      },
      "source": [
        "## Step 1: Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "80b500a5-eeac-0041-17bf-d61d3c8c68b1"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------\n",
        "# Step 01: load data using panda\n",
        "#-----------------------------------------------------------\n",
        "train_df = pd.read_csv('../input/train.csv')  # train set\n",
        "test_df  = pd.read_csv('../input/test.csv')   # test  set\n",
        "combine  = [train_df, test_df]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2eff25d1-e98a-36c0-a527-94ea7e133a7f"
      },
      "source": [
        "## Step 2: Acquire and clean data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4e7eb49b-92d2-787c-f1aa-f8a756025511"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------\n",
        "# Step 02: Acquire and clean data\n",
        "#-----------------------------------------------------------\n",
        "train_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7be2e7ee-366d-d79a-3ae5-fd86edcb95f5"
      },
      "outputs": [],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c8bf8aef-080d-3846-7191-686bb81e51eb"
      },
      "outputs": [],
      "source": [
        "train_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "16ddaa31-86e7-f4e1-341c-2daa2ac5910a"
      },
      "outputs": [],
      "source": [
        "train_df.describe(include=['O'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7c3cb5aa-89d9-651f-c957-9b1555a654c4"
      },
      "source": [
        "Training data statistics:\n",
        "\n",
        " - 891 training samples\n",
        " - Age, Cabin, Embarked: incomplete data\n",
        " - Data type:\n",
        "      - object: Name, Sex, Ticket, Cabin, Embarked\n",
        "      - int64: PassengerId, Survived, Pclass, SibSp, Parch\n",
        "      - float64: Age, Fare\n",
        " - Survive rate: 0.383838"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2435e506-4648-b0b1-b93a-10b5a2ae737c"
      },
      "outputs": [],
      "source": [
        " # remove Features: Ticket, Cabin\n",
        "#train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
        "#test_df  = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
        "#combine  = [train_df, test_df]\n",
        "for dataset in combine:\n",
        "    dataset['Cabin'] = dataset['Cabin'].fillna('U')\n",
        "    dataset['Cabin'] = dataset.Cabin.str.extract('([A-Za-z])', expand=False)\n",
        "    \n",
        "for dataset in combine:\n",
        "    dataset['Cabin'] = dataset['Cabin'].map( {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E':0, \n",
        "                                            'F':0, 'G':0, 'T':0, 'U':1} ).astype(int)\n",
        "    \n",
        "train_df.head()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "44cc259e-fb09-d046-e3c6-f5a56fe64834"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.drop(['Ticket'], axis=1)\n",
        "test_df  = test_df.drop(['Ticket'], axis=1)\n",
        "combine  = [train_df, test_df]\n",
        "\n",
        "\n",
        "# survival rate distribtion as a function of Pclass\n",
        "train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "afbcb4f9-4d6f-f8b9-931e-e7f957ae6ff9"
      },
      "outputs": [],
      "source": [
        "# obtain Title from name (Mr, Mrs, Miss etc)\n",
        "for dataset in combine:\n",
        "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "\n",
        "for dataset in combine:\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Dona'],'Royalty')\n",
        "    dataset['Title'] = dataset['Title'].replace(['Mme'], 'Mrs')\n",
        "    dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'], 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major','Rev'], 'Officer')\n",
        "    dataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Don','Sir'], 'Royalty')\n",
        "    dataset.loc[(dataset.Sex == 'male')   & (dataset.Title == 'Dr'),'Title'] = 'Mr'\n",
        "    dataset.loc[(dataset.Sex == 'female') & (dataset.Title == 'Dr'),'Title'] = 'Mrs'\n",
        "\n",
        "#: count survived rate for different titles\n",
        "train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2a5dc464-0801-bfa5-adee-4b8a640673ee"
      },
      "outputs": [],
      "source": [
        "# Covert 'Title' to numbers (Mr->1, Miss->2 ...)\n",
        "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royalty\":5, \"Officer\": 6}\n",
        "for dataset in combine:\n",
        "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)\n",
        "\n",
        "# Remove 'Name' and 'PassengerId' in training data, and 'Name' in testing data\n",
        "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
        "test_df = test_df.drop(['Name'], axis=1)\n",
        "combine = [train_df, test_df]\n",
        "\n",
        "# if age < 16, set 'Sex' to Child\n",
        "for dataset in combine:\n",
        "    dataset.loc[(dataset.Age < 16),'Sex'] = 'Child'\n",
        "    \n",
        "# Covert 'Sex' to numbers (female:1, male:2)\n",
        "for dataset in combine:\n",
        "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0, 'Child': 2} ).astype(int)\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e92d462a-9749-9aea-3750-2a5d824f3d9f"
      },
      "outputs": [],
      "source": [
        "# Age distribution for different values of Pclass and gender\n",
        "grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\n",
        "grid.map(plt.hist, 'Age', bins=20)\n",
        "grid.add_legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ea2a98df-d453-53d6-987d-8d5ea44dd330"
      },
      "outputs": [],
      "source": [
        "# Guess age values using median values for age across set of Pclass and gender frature combinations\n",
        "guess_ages = np.zeros((2,3))\n",
        "for dataset in combine:\n",
        "    for i in range(0, 2):\n",
        "        for j in range(0, 3):\n",
        "            guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
        "            age_guess = guess_df.median()\n",
        "            \n",
        "            # Convert random age float to nearest .5 age\n",
        "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
        "\n",
        "    for i in range(0, 2):\n",
        "        for j in range(0, 3):\n",
        "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),'Age'] = guess_ages[i,j]\n",
        "    \n",
        "    #convert Age to int\n",
        "    dataset['Age'] = dataset['Age'].astype(int)\n",
        "\n",
        "# create Age bands and determine correlations with Survived\n",
        "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\n",
        "train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "883ca43f-abdf-f42c-9eb8-4019e84c2305"
      },
      "outputs": [],
      "source": [
        "for dataset in combine:\n",
        "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
        "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
        "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
        "\n",
        "train_df = train_df.drop(['AgeBand'], axis=1)\n",
        "combine = [train_df, test_df]\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c06ce72d-e9f0-7c4f-920c-660296b542c2"
      },
      "outputs": [],
      "source": [
        "# Create family size from 'sibsq + parch + 1'\n",
        "for dataset in combine:\n",
        "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
        "\n",
        "train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
        "\n",
        "#create another feature called IsAlone\n",
        "for dataset in combine:\n",
        "    dataset['IsAlone'] = 0\n",
        "    dataset.loc[(dataset['FamilySize'] == 1), 'IsAlone'] = 1\n",
        "    dataset.loc[(dataset['FamilySize'] > 4), 'IsAlone'] = 2\n",
        "\n",
        "train_df[['IsAlone','Survived']].groupby(['IsAlone'], as_index=False).mean()\n",
        "\n",
        "\n",
        "#drop Parch, SibSp, and FamilySize features in favor of IsAlone\n",
        "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
        "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
        "combine = [train_df, test_df]\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "23cd5863-0c13-1a87-23c2-ef459d7a3005"
      },
      "outputs": [],
      "source": [
        "# Create an artfical feature combinbing PClass and Age.\n",
        "for dataset in combine:\n",
        "    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n",
        "\n",
        "train_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5f5b0e95-b296-344c-7c12-ca5296f7909f"
      },
      "outputs": [],
      "source": [
        "# fill the missing values of Embarked feature with the most common occurance\n",
        "freq_port = train_df.Embarked.dropna().mode()[0]\n",
        "for dataset in combine:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
        "train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
        "\n",
        "for dataset in combine:\n",
        "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fe09fcf7-1f76-d45e-7c9e-cb4c0f80d83f"
      },
      "outputs": [],
      "source": [
        "# fill the missing values of Fare\n",
        "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n",
        "\n",
        "# Create FareBand\n",
        "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
        "train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n",
        "\n",
        "# Convert the Fare feature to ordinal values based on the FareBand\n",
        "for dataset in combine:\n",
        "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
        "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
        "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
        "\n",
        "train_df = train_df.drop(['FareBand'], axis=1)\n",
        "combine = [train_df, test_df]\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "57f70dac-3c3a-c862-0dfc-150f2bb0c2ad"
      },
      "outputs": [],
      "source": [
        "train_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "390d74a4-f938-144b-d752-2dee8628437c"
      },
      "source": [
        "Part II : Learning Model\n",
        "-------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e32233a0-4571-8347-4829-0ac4cbf38302"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------------\n",
        "# Step 03: Learning model\n",
        "#------------------------------------------------------------------\n",
        "\n",
        "X_data = train_df.drop(\"Survived\", axis=1)          # data: Features\n",
        "Y_data = train_df[\"Survived\"]                       # data: Labels\n",
        "X_test_kaggle  = test_df.drop(\"PassengerId\", axis=1).copy() # test data (kaggle)\n",
        "\n",
        "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "371566be-b210-b02e-92e4-a40bd898d133"
      },
      "outputs": [],
      "source": [
        "# grid search\n",
        "def grid_search_model(X, Y, model, parameters, cv):\n",
        "    CV_model = GridSearchCV(estimator=model, param_grid=parameters, cv=cv)\n",
        "    CV_model.fit(X, Y)\n",
        "    CV_model.cv_results_\n",
        "    print(\"Best Score:\", CV_model.best_score_,\" / Best parameters:\", CV_model.best_params_)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "29c7ce62-ddea-0c6c-656b-15986d98fda8"
      },
      "outputs": [],
      "source": [
        "#validation curve\n",
        "def validation_curve_model(X, Y, model, param_name, parameters, cv, ylim, log=True):\n",
        "\n",
        "    train_scores, test_scores = validation_curve(model, X, Y, param_name=param_name, param_range=parameters,cv=cv, scoring=\"accuracy\")\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(\"Validation curve\")\n",
        "    plt.fill_between(parameters, train_scores_mean - train_scores_std,train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(parameters, test_scores_mean - test_scores_std,test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "\n",
        "    if log==True:\n",
        "        plt.semilogx(parameters, train_scores_mean, 'o-', color=\"r\",label=\"Training score\")\n",
        "        plt.semilogx(parameters, test_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n",
        "    else:\n",
        "        plt.plot(parameters, train_scores_mean, 'o-', color=\"r\",label=\"Training score\")\n",
        "        plt.plot(parameters, test_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n",
        "\n",
        "    #plt.ylim([0.55, 0.9])\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "\n",
        "    plt.ylabel('Score')\n",
        "    plt.xlabel('Parameter C')\n",
        "    plt.legend(loc=\"best\")\n",
        "    \n",
        "    return plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "58948674-252b-3406-51ae-d082b188c8cc"
      },
      "outputs": [],
      "source": [
        "# Learning curve\n",
        "def Learning_curve_model(X, Y, model, cv, train_sizes):\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(\"Learning curve\")\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "\n",
        "\n",
        "    train_sizes, train_scores, test_scores = learning_curve(model, X, Y, cv=cv, n_jobs=4, train_sizes=train_sizes)\n",
        "\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std  = np.std(train_scores, axis=1)\n",
        "    test_scores_mean  = np.mean(test_scores, axis=1)\n",
        "    test_scores_std   = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "    \n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n",
        "                     \n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca83fda0-3b01-db34-1feb-e8e54a264219"
      },
      "outputs": [],
      "source": [
        "# lrearning, prediction and printing results\n",
        "def predict_model(X, Y, model, Xtest, submit_name):\n",
        "    model.fit(X, Y)\n",
        "    Y_pred  = model.predict(Xtest)\n",
        "    score   = cross_val_score(model, X, Y, cv=cv)\n",
        "\n",
        "    submission = pd.DataFrame({\n",
        "            \"PassengerId\": test_df[\"PassengerId\"],\n",
        "            \"Survived\": Y_pred\n",
        "        })\n",
        "    submission.to_csv(submit_name, index=False)\n",
        "    \n",
        "    return score "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4b921dd0-e7a7-879e-d703-7d8fd8f31b33"
      },
      "source": [
        "###  Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ef8013a2-3cbf-027a-d668-225f5645b552"
      },
      "outputs": [],
      "source": [
        "search_param = 0   # 1 -- grid search / 0 -- don't search\n",
        "plot_vc      = 0   # 1--display validation curve/ 0-- don't display\n",
        "plot_lc      = 1   # 1--display learning curve/ 0 -- don't display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "71271d53-ae3e-c7c2-b29b-5c7ef9cace1a"
      },
      "outputs": [],
      "source": [
        "#grid search: Logistic Regression\n",
        "model = LogisticRegression()\n",
        "if search_param==1:\n",
        "    \n",
        "    param_range = np.logspace(-6, 5, 12)\n",
        "    param_grid = dict(C=param_range)\n",
        "    grid_search_model(X_data, Y_data, model, param_grid, cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "809830e8-6e17-5c12-a721-cc91bc864298"
      },
      "outputs": [],
      "source": [
        "#Validation Curve: Logistic Regression\n",
        "if plot_vc == 1:\n",
        "    param_range = np.logspace(-6, 3, 10)\n",
        "    param_name=\"C\"\n",
        "    ylim=[0.55, 0.9]\n",
        "    validation_curve_model(X_data, Y_data, model, \"C\", param_range, cv, ylim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "364c7e19-9c1e-7011-7869-790daba645ab"
      },
      "outputs": [],
      "source": [
        "#learn curve\n",
        "logreg  = LogisticRegression(C=1000)\n",
        "\n",
        "if plot_lc==1:\n",
        "    train_size=np.linspace(.1, 1.0, 15)\n",
        "    Learning_curve_model(X_data, Y_data, logreg, cv, train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "593bfae6-18f1-e042-5ffc-9527093e9869"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression \n",
        "acc_log = predict_model(X_data, Y_data, logreg, X_test_kaggle, 'submission_Logistic.csv')\n",
        "print(acc_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "715b6dc7-6a6a-e4d5-d1c5-764bb41489ca"
      },
      "source": [
        "XGBoost\n",
        "-------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b7b5d926-f8c4-8d13-ff36-149ad80eb5e4"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgbc= XGBClassifier()\n",
        "acc_xgbc = predict_model(X_data, Y_data, xgbc, X_test_kaggle, 'submission_xgbc.csv')\n",
        "print(acc_xgbc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "53451f24-33aa-6bec-fbd5-d53aaa146c5e"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ed54f9d4-ef60-3630-4161-1f61b6b87281"
      },
      "source": [
        "###  Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ce305255-8fa1-d8ff-e527-9a932dd9da91"
      },
      "outputs": [],
      "source": [
        "search_param = 0   # 1 -- grid search / 0 -- don't search\n",
        "plot_vc      = 1   # 1--display validation curve/ 0-- don't display\n",
        "plot_lc      = 1   # 1--display learning curve/ 0 -- don't display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "be3f188f-e6df-cf3c-b5c4-b0a7eac68f7c"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#grid search: SVM\n",
        "search_param = 0\n",
        "if search_param==1:\n",
        "    param_range = np.linspace(0.5, 5, 9)\n",
        "    param_grid = dict(C=param_range)\n",
        "\n",
        "    grid_search_model(X_data, Y_data, SVC(), param_grid, cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e4c91ef9-6a66-95e2-60a0-d6ff7eb3dc51"
      },
      "outputs": [],
      "source": [
        "#Validation Curve: SVC\n",
        "if plot_vc == 1:\n",
        "    param_range = np.linspace(0.1, 10, 10)\n",
        "    param_name=\"C\"\n",
        "    ylim=[0.78, 0.90]\n",
        "    validation_curve_model(X_data, Y_data, SVC(), \"C\", param_range, cv, ylim, log=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "26940489-0445-c07c-eeac-f6cf3884dd19"
      },
      "outputs": [],
      "source": [
        "#learn curve: SVC\n",
        "svc = SVC(C=1)\n",
        "\n",
        "if plot_lc == 1:\n",
        "    train_size=np.linspace(.1, 1.0, 15)\n",
        "    Learning_curve_model(X_data, Y_data, svc, cv, train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8189993e-5b81-1f34-f346-188fd37a7c94"
      },
      "outputs": [],
      "source": [
        "# Support Vector Machines\n",
        "acc_svc = predict_model(X_data, Y_data, svc, X_test_kaggle, 'submission_SVM.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "eb0f904a-7fc1-014a-d6a8-6e7bf56f11d6"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cc5401c0-418e-2190-eeb4-8d7fd180daa1"
      },
      "outputs": [],
      "source": [
        "search_param = 0   # 1 -- grid search / 0 -- don't search\n",
        "plot_vc      = 0   # 1--display validation curve/ 0-- don't display\n",
        "plot_lc      = 1   # 1--display learning curve/ 0 -- don't display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "746853d9-98dc-fddb-1c43-bc6ce96ebbf6"
      },
      "outputs": [],
      "source": [
        "#grid search: KNN\n",
        "if search_param==1:\n",
        "    param_range = (np.linspace(1, 10, 10)).astype(int)\n",
        "    param_grid = dict(n_neighbors=param_range)\n",
        "\n",
        "    grid_search_model(X_data, Y_data, KNeighborsClassifier(), param_grid, cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0bfb5582-1ebf-7285-1e1e-21eb3e1c8ba7"
      },
      "outputs": [],
      "source": [
        "#Validation Curve: KNN\n",
        "if plot_vc==1:\n",
        "    param_range = np.linspace(2, 20, 10).astype(int)\n",
        "    param_name=\"n_neighbors\"\n",
        "    ylim=[0.75, 0.90]\n",
        "    validation_curve_model(X_data, Y_data, KNeighborsClassifier(), \"n_neighbors\", param_range, cv, ylim, log=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e57117ac-a5bb-3c10-f212-be41be0e4dc2"
      },
      "outputs": [],
      "source": [
        "#learn curve: KNN\n",
        "knn = KNeighborsClassifier(n_neighbors = 10)\n",
        "\n",
        "if plot_lc==1:\n",
        "    train_size=np.linspace(.1, 1.0, 15)\n",
        "    Learning_curve_model(X_data, Y_data, knn, cv, train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "afbf64da-6cbc-856b-f3a5-70d18c9ff7de"
      },
      "outputs": [],
      "source": [
        "# KNN\n",
        "acc_knn = predict_model(X_data, Y_data, knn, X_test_kaggle, 'submission_KNN.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "10a60f42-5f6a-ba0f-2faf-232831b14654"
      },
      "source": [
        "###  Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "95e3e8d4-b0fa-ae95-9e53-cfd77b0b0671"
      },
      "outputs": [],
      "source": [
        "# Gaussian Naive Bayes\n",
        "gaussian = GaussianNB()\n",
        "acc_gaussian = predict_model(X_data, Y_data, gaussian, X_test_kaggle, 'submission_Gassian_Naive_Bayes.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1be193b3-5218-c699-5b60-47c675f7527c"
      },
      "source": [
        "### Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da5af46a-e1d0-3662-ac62-29e12cb8128a"
      },
      "outputs": [],
      "source": [
        "# Perceptron\n",
        "perceptron = Perceptron()\n",
        "acc_perceptron = predict_model(X_data, Y_data, perceptron, X_test_kaggle, 'submission_Perception.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "50dfeac7-b185-2936-3784-302503346eab"
      },
      "source": [
        "###  Linear SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e28deba6-c397-dd56-21e6-f141b8e5da96"
      },
      "outputs": [],
      "source": [
        "# Linear SVC\n",
        "linear_svc = LinearSVC()\n",
        "acc_linear_svc = predict_model(X_data, Y_data, linear_svc, X_test_kaggle, 'submission_Linear_SVC.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "78144161-403a-dfb0-571a-3ffa231651f4"
      },
      "source": [
        "### Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "49f74564-5d99-89bf-bc20-4817e670ccde"
      },
      "outputs": [],
      "source": [
        "# Stochastic Gradient Descent\n",
        "sgd = SGDClassifier()\n",
        "acc_sgd = predict_model(X_data, Y_data, sgd, X_test_kaggle, 'submission_stochastic_Gradient_Descent.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ef7b7bc0-b0e9-6026-e014-ce06c2b74e0d"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "14529b5e-606a-5356-3397-c6d353de0c58"
      },
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "acc_decision_tree = predict_model(X_data, Y_data, decision_tree, X_test_kaggle, 'submission_Decision_Tree.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "da962710-1a21-3409-b7fa-b8a510991d0f"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "efaa503b-0359-0594-0ff8-00c7f2bbce3a"
      },
      "outputs": [],
      "source": [
        "search_param = 0   # 1 -- grid search / 0 -- don't search\n",
        "plot_vc      = 0   # 1--display validation curve/ 0-- don't display\n",
        "plot_lc      = 1   # 1--display learning curve/ 0 -- don't display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "995b5f18-18fe-1d76-b676-f3ca1c929e3b"
      },
      "outputs": [],
      "source": [
        "#grid search: KNN (This step is very slow)\n",
        "#param_range = (np.linspace(10, 110, 10)).astype(int)\n",
        "#param_leaf = (np.linspace(1, 2, 2)).astype(int)\n",
        "#param_grid = {'n_estimators':param_range, 'min_samples_leaf':param_leaf}\n",
        "\n",
        "#grid_search_model(X_data, Y_data, RandomForestClassifier(), param_grid, cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1453ded2-b927-5047-6dd8-084d2fe13150"
      },
      "outputs": [],
      "source": [
        "if plot_vc==1:\n",
        "    param_range = np.linspace(10, 110, 10).astype(int)\n",
        "    ylim=[0.75, 0.90]\n",
        "    validation_curve_model(X_data, Y_data, RandomForestClassifier(min_samples_leaf=12), \"n_estimators\", param_range, cv, ylim, log=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c9874c0f-bec3-54ac-9fca-84566e0bf401"
      },
      "outputs": [],
      "source": [
        "if plot_vc==1:\n",
        "    param_range = np.linspace(1, 21, 10).astype(int)\n",
        "    ylim=[0.75, 0.90]\n",
        "    validation_curve_model(X_data, Y_data, RandomForestClassifier(n_estimators=80), \"min_samples_leaf\", param_range, cv, ylim, log=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "980df8cf-9580-01a5-345c-5203d9c1eeec"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "random_forest = RandomForestClassifier(n_estimators=80, random_state =0, min_samples_leaf = 12)\n",
        "acc_random_forest = predict_model(X_data, Y_data, random_forest, X_test_kaggle, 'submission_random_forest.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1cabc288-9885-acae-5925-a9a1cb131dcc"
      },
      "source": [
        "### Ensemble votring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "699ca99e-c5b4-e29c-0bf7-810e80ab4576"
      },
      "outputs": [],
      "source": [
        "#ensemble votring\n",
        "ensemble_voting = VotingClassifier(estimators=[('lg', logreg), ('sv', svc), ('rf', random_forest),('kn',knn)], voting='hard')\n",
        "acc_ensemble_voting = predict_model(X_data, Y_data, ensemble_voting, X_test_kaggle, 'submission_ensemble_voting.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "247befb3-def0-27ea-9844-a7b8563e562c"
      },
      "outputs": [],
      "source": [
        "models = pd.DataFrame({'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression',\n",
        "                                'Random Forest', 'Naive Bayes', 'Perceptron',\n",
        "                                'Stochastic Gradient Decent', 'Linear SVC',\n",
        "                                'Decision Tree', 'ensemble_voting'],'KFoldScore': [acc_svc.mean(), acc_knn.mean(), acc_log.mean(),\n",
        "                                acc_random_forest.mean(), acc_gaussian.mean(), acc_perceptron.mean(),\n",
        "                                acc_sgd.mean(), acc_linear_svc.mean(), acc_decision_tree.mean(), acc_ensemble_voting.mean()],\n",
        "                                'Std': [acc_svc.std(), acc_knn.std(), acc_log.std(),\n",
        "                                acc_random_forest.std(), acc_gaussian.std(), acc_perceptron.std(),\n",
        "                                acc_sgd.std(), acc_linear_svc.std(), acc_decision_tree.std(), acc_ensemble_voting.std()]})\n",
        "\n",
        "models.sort_values(by='KFoldScore', ascending=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}