{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "578452b5-ef7c-f147-192b-db843175ea6e"
      },
      "source": [
        "Its a rather pure model\n",
        "-----\n",
        "\n",
        "You do a TFIDF on the Q1, Q2, intersection, and difference\n",
        "Than we compact the TFIDF matrix with SVD.\n",
        "It runs very fast, except with the big testfile you have to parse the fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3ec4a4e5-b2b6-afa7-87bd-83b136aef4c1"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "import scipy\n",
        "import xgboost as xgb\n",
        "import difflib\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.metrics import jaccard_distance\n",
        "\n",
        "\n",
        "#Reading and processing of data\n",
        "train=pd.read_csv('../input/train.csv')[:20000].fillna(\"\")\n",
        "#train=pd.read_csv('../input/train.csv').dropna()\n",
        "stops = set(stopwords.words(\"english\"))\n",
        "y=train['is_duplicate']\n",
        "train=train.drop(['id', 'qid1', 'is_duplicate','qid2'], axis=1)\n",
        "\n",
        "#Cleaning up the data\n",
        "#Removing ? mark and non ASCII characters\n",
        "def cleanup(data):\n",
        "    data['question1'] = data['question1'].apply(lambda x: x.rstrip('?'))\n",
        "    data['question2'] = data['question2'].apply(lambda x: x.rstrip('?'))\n",
        "    # Removing non ASCII chars\n",
        "    data['question1']=data['question1'].apply(lambda x: x.replace(r'[^\\x00-\\x7f]',r' '))\n",
        "    data['question2']=data['question2'].apply(lambda x: x.replace(r'[^\\x00-\\x7f]',r' ')) \n",
        "    # Pad punctuation with spaces on both sides\n",
        "    '''\n",
        "    for char in ['.', '\"', ',', '(', ')', '!', '?', ';', ':']:\n",
        "        x = x.replace(char, ' ' + char + ' ')\n",
        "    '''\n",
        "    return data\n",
        "\n",
        "questions = train['question1'].tolist() + train['question2'].tolist()\n",
        "train=cleanup(train)\n",
        "print(train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ecfbb0c7-04ca-bafd-b023-720efa3c65bc"
      },
      "source": [
        "TFIDF\n",
        "----\n",
        "4 matrixes= Q1,Q2,intersection, and difference\n",
        "\n",
        "SVD\n",
        "---\n",
        "Compress TFIDF and find singular values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f0b1b59f-8932-b821-5581-2d3f89eb5adc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity,euclidean_distances,laplacian_kernel,sigmoid_kernel,polynomial_kernel,rbf_kernel\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "def intersecting(a, b):\n",
        "    return ' '.join(list(set(a.split()) & set(b.split())))\n",
        "\n",
        "def differencing(a, b):\n",
        "    return ' '.join(list(set(a.split()) ^ set(b.split())))\n",
        "\n",
        "tfidf = TfidfVectorizer( ngram_range=(1, 3))\n",
        "tfidf.fit_transform(questions)\n",
        "#print(tfidf.vocabulary_)\n",
        "\n",
        "def get_features(df_features):    \n",
        "    df_features['interseq'] = df_features[['question1','question2']].apply(lambda x: intersecting(*x), axis=1)\n",
        "    df_features['diffseq'] = df_features[['question1','question2']].apply(lambda x: differencing(*x), axis=1)    \n",
        "    df_features['q1d'] = df_features[['question1','diffseq']].apply(lambda x: intersecting(*x), axis=1)    \n",
        "    df_features['q2d'] = df_features[['question2','diffseq']].apply(lambda x: intersecting(*x), axis=1)        \n",
        "    \n",
        "    print('tfidf')    \n",
        "    question1_tfidf = tfidf.transform(df_features.question1.tolist())\n",
        "    question2_tfidf = tfidf.transform(df_features.question2.tolist())    \n",
        "    questionI_tfidf = tfidf.transform(df_features.interseq.tolist())    \n",
        "    questionD_tfidf = tfidf.transform(df_features.diffseq.tolist()) \n",
        "    questionQ1D_tfidf = tfidf.transform(df_features.q1d.tolist())    \n",
        "    questionQ2D_tfidf = tfidf.transform(df_features.q2d.tolist()) \n",
        "    print(question1_tfidf.shape)\n",
        "        \n",
        "    print('SVD')\n",
        "    svd = TruncatedSVD(n_components=30)\n",
        "    df_features=df_features.join(pd.DataFrame(svd.fit_transform(questionI_tfidf)),how='inner')\n",
        "    print(svd.explained_variance_ratio_)\n",
        "    print(svd.get_params(deep=True))\n",
        "    \n",
        "    svd = TruncatedSVD(n_components=30)\n",
        "    temp=pd.DataFrame(svd.fit_transform(questionD_tfidf))\n",
        "    temp.rename(columns=lambda x: str(x)+'_d', inplace=True) #nog eens zoeken omcolumns te renamen\n",
        "    df_features=df_features.join(temp,how='inner')  \n",
        "\n",
        "    \n",
        "    svd = TruncatedSVD(n_components=30)\n",
        "    temp=pd.DataFrame(svd.fit_transform(question1_tfidf))\n",
        "    temp.rename(columns=lambda x: str(x)+'_q1', inplace=True) #nog eens zoeken omcolumns te renamen\n",
        "    df_features=df_features.join(temp,how='inner') \n",
        "\n",
        "    print(temp.shape)\n",
        "    \n",
        "    svd = TruncatedSVD(n_components=30)\n",
        "    temp=pd.DataFrame(svd.fit_transform(question2_tfidf))\n",
        "    temp.rename(columns=lambda x: str(x)+'_q2', inplace=True) #nog eens zoeken omcolumns te renamen\n",
        "    df_features=df_features.join(temp,how='inner')     \n",
        " \n",
        "    svd = TruncatedSVD(n_components=30)\n",
        "    temp=pd.DataFrame(svd.fit_transform(questionQ1D_tfidf))\n",
        "    temp.rename(columns=lambda x: str(x)+'_q1d', inplace=True) #nog eens zoeken omcolumns te renamen\n",
        "    df_features=df_features.join(temp,how='inner')   \n",
        "    \n",
        "    svd = TruncatedSVD(n_components=30)\n",
        "    temp=pd.DataFrame(svd.fit_transform(questionQ2D_tfidf))\n",
        "    temp.rename(columns=lambda x: str(x)+'_q2d', inplace=True) #nog eens zoeken omcolumns te renamen\n",
        "    df_features=df_features.join(temp,how='inner')   \n",
        "    \n",
        "    return df_features.fillna(0.0)\n",
        "\n",
        "\n",
        "\n",
        "df_train = get_features(train)\n",
        "feats = df_train.columns.values.tolist()\n",
        "feats=[x for x in feats if x not in ['question1','question2','Q1seq','Q2seq','q1d','q2d','interseq','diffseq','id','qid1','qid2','is_duplicate']]\n",
        "print(\"features\",feats)\n",
        "print(df_train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "69c1a6e4-fc36-8db2-52e4-372ecd37b256"
      },
      "source": [
        "XGBoost train the data\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "70ef8577-60b7-183a-d841-a7e74dc27ac9"
      },
      "outputs": [],
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(df_train[feats], y, test_size=0.3, random_state=0)\n",
        "#XGBoost model\n",
        "params = {\"objective\":\"binary:logistic\",'eval_metric':'logloss',\"eta\": 0.11,\n",
        "          \"subsample\":0.7,\"min_child_weight\":1,\"colsample_bytree\": 0.7,\n",
        "          \"max_depth\":5,\"silent\":1,\"seed\":2017}\n",
        "\n",
        "d_train = xgb.DMatrix(x_train, label=y_train)\n",
        "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
        "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
        "bst = xgb.train(params, d_train, 2000, watchlist, early_stopping_rounds=200,verbose_eval=25) #change to higher #s\n",
        "print('training done')\n",
        "\n",
        "print(\"log loss for training data set\",log_loss(y, bst.predict(xgb.DMatrix(df_train[feats]))))\n",
        "#Predicting for test data set\n",
        "sub = pd.DataFrame() # Submission data frame\n",
        "sub['test_id'] = []\n",
        "sub['is_duplicate'] = []\n",
        "header=['test_id','question1','question2','id','qid1','qid2','is_duplicate']\n",
        "test=pd.read_csv('../input/test.csv')[:20000].fillna(\"\")\n",
        "print(\"cleaning test\")\n",
        "df_test=cleanup(test)\n",
        "print(\"feature engineering for test\")\n",
        "df_test = get_features(df_test)\n",
        "sub=pd.DataFrame({'test_id':df_test['test_id'], 'is_duplicate':bst.predict(xgb.DMatrix(df_test[feats]))})\n",
        "sub.to_csv('quora_submission_xgb_11.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f4848cee-3bb6-ba43-f94c-5c1d12e593f5"
      },
      "source": [
        "[1825]\ttrain-logloss:0.305957\tvalid-logloss:0.420252\n",
        "[1850]\ttrain-logloss:0.304641\tvalid-logloss:0.420013\n",
        "[1875]\ttrain-logloss:0.30305\tvalid-logloss:0.419738\n",
        "[1900]\ttrain-logloss:0.301473\tvalid-logloss:0.419478\n",
        "[1925]\ttrain-logloss:0.299964\tvalid-logloss:0.41919"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}