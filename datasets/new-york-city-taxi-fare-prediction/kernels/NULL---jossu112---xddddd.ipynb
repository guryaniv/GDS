{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport pandas as pd # CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #data viz.\nimport seaborn as sb #data viz.\nfrom sklearn.ensemble import GradientBoostingRegressor #ML algorithm\nfrom sklearn.linear_model import LinearRegression #ML algorithm\nfrom sklearn.model_selection import train_test_split #splitting dataset\nfrom sklearn.metrics import mean_squared_error\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n%matplotlib inline\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train =  pd.read_csv('../input/train.csv', nrows = 2_000_000, parse_dates=[\"pickup_datetime\"])\n\n# list first few rows (datapoints)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04c8a5c2baad87281462dee6068d81d33a155601"},"cell_type":"markdown","source":"<H1> For now just drop missing samples </h1>"},{"metadata":{"trusted":true,"_uuid":"8fce44778c77c3a641b11b4305b06f944370c2ec","scrolled":true},"cell_type":"code","source":"print('Old size: %d' % len(df_train))\ndf_train = df_train.dropna(how = 'any', axis = 'rows')\nprint('New size: %d' % len(df_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76145d5ecdb04c67f4a4e96f3954a6f50b97b618"},"cell_type":"code","source":"df_my_test = df_train.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcb0d1b307a4b028762229896e7a56f2ee7a1919"},"cell_type":"code","source":"df_my_test['distance'] = np.square(df_my_test['pickup_longitude'] - df_my_test['dropoff_longitude']) + np.square(df_my_test['pickup_latitude'] - df_my_test['dropoff_latitude'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9940f1bf6a637317d854f1bc7c0dd7c4bf49479a"},"cell_type":"code","source":"df_my_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad62db8bed022a423260c7973346d4850b6b0e66"},"cell_type":"code","source":"nyc = (-74.0063889, 40.7141667)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df0b006ee950023f2301638e67197106b31c5e1a"},"cell_type":"code","source":"def distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295 # Pi/180\n    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bee15d53ac0237521b62e80a8b1c054a5de9bad1"},"cell_type":"code","source":"df_my_test['distance_miles'] = distance(df_my_test.pickup_latitude, df_my_test.pickup_longitude, \\\n                                     df_my_test.dropoff_latitude, df_my_test.dropoff_longitude)\ndf_my_test['distance_to_center'] = distance(nyc[1], nyc[0], \\\n                                          df_my_test.dropoff_latitude, df_my_test.dropoff_longitude)\n#df_my_test['hour'] = df_my_test.pickup_datetime.apply(lambda t: pd.to_datetime(t).hour)\n#df_my_test['year'] = df_my_test.pickup_datetime.apply(lambda t: pd.to_datetime(t).year)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0268dde7931b398f9bf6f954966a1819579a5bad"},"cell_type":"code","source":"df_my_test['distance_miles'] > 1000 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"439eb20aa691f25914e615e672eb1e0e3ac94887"},"cell_type":"code","source":"X_train = df_my_test[['distance_miles', 'distance_to_center','passenger_count']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c42507537dbf873966d6d42c08ae3928ac392e9e"},"cell_type":"code","source":"uh = df_my_test['hour'] < 8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81472c208010f467c0ec90ba88b6262c600c7539"},"cell_type":"code","source":"X_train['costly'] = uh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"156d4ebdd46784d3023f6851aecccb4266c3334f"},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7e75eaec9ee03ba058b4a7cd259405ee59af1ef"},"cell_type":"code","source":"uh.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd4fea97d1856b8f6f59c04afe83cd8e0160fb81"},"cell_type":"markdown","source":"set weird distances to 0"},{"metadata":{"trusted":true,"_uuid":"c0a95aa1145ee2e6dd9d364a8dc83af5fa5d97f2"},"cell_type":"code","source":"idxs = df_my_test['distance'] > 0.1\ndf_my_test.loc[idxs,'distance'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51a99ab32a000304c80d956e026650160237962a"},"cell_type":"code","source":"idxs = df_my_test['distance'] > 0.1\ndf_my_test[idxs]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e68aa40d6cf2a34317487cea8d04f1b2f5bae891"},"cell_type":"code","source":"df_my_test['norm_distance'] = df_my_test['distance'] / max(df_my_test['distance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c84a8bf2d5b290aa717a7cfe44ac7c4d6c07c073"},"cell_type":"code","source":"df_my_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88fddd38975f96722a31c00ddc68f47adcd7dafb"},"cell_type":"code","source":"max(df_my_test['distance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"237d24d7397a637d1aac62102b3759eef4f05989"},"cell_type":"code","source":"X_train = df_my_test[['distance_miles','passenger_count']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1d1baade9a3a22f10213890e1166d4e7c10bb86"},"cell_type":"code","source":"X_train.head()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a61e828d3b5f3cd2ae5e3d1a56bf938e25bc13d6"},"cell_type":"markdown","source":"we have our features!!\n(maybe add the time somehow.. work for you!!)"},{"metadata":{"trusted":true,"_uuid":"bf04a997401f063cbd91891d925f65ea09dc7b79"},"cell_type":"code","source":"import datetime as dt\n\ndf_my_test['Year'] = df_my_test['pickup_datetime'].dt.year\ndf_my_test['Month'] = df_my_test['pickup_datetime'].dt.month\ndf_my_test['Date'] = df_my_test['pickup_datetime'].dt.day\ndf_my_test['Day_of_Week'] = df_my_test['pickup_datetime'].dt.dayofweek\ndf_my_test['Hour'] = df_my_test['pickup_datetime'].dt.hour\ndf_my_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a2d134a33cce8277b455ad8cb7ca861ae8f407b"},"cell_type":"code","source":"X_train['time'] = df_my_test['']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90c3f9930b853185a40316b1babae262111327e1"},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca43d7617b8eac66af20c879242c2d73d8b9fcfe"},"cell_type":"code","source":"y_train = df_my_test['fare_amount']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc0011e3deb1a02bc1967e12bdf68fc37b866cf2"},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d783f31aa7bf0c3f77791092e1d79036ffeb103"},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\n\nmodel_lin = Pipeline((\n   #     (\"standard_scaler\", StandardScaler()),\n        (\"lin_reg\", LinearRegression()),\n    ))\nmodel_lin.fit(X_train, y_train)\n\ny_train_pred = model_lin.predict(X_train)\n\n#y_test_pred = model_lin.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"deb3bed5e57f16388752b5ff7a9824849cfc8127"},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n    \nrmse = np.sqrt(mean_squared_error(y_train_pred, y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05b687ee48c5b444e1a7b2852f97e2c82db827de"},"cell_type":"code","source":"rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d685f6c9b857bf86fd6131fe7a82e12551b47757"},"cell_type":"code","source":"y_train[1:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e4284b85b177f36ba7eec48fd5c01f873906121"},"cell_type":"code","source":"y_train_pred[1:5]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_uuid":"d4946ecb7237160e63d07da8810107d5b8d293e7"},"cell_type":"markdown","source":"Gradient boosting regression"},{"metadata":{"trusted":true,"_uuid":"cd9813d48725de7baeec63ce0630c55b4b460530"},"cell_type":"code","source":"# Given a dataframe, add two new features 'abs_diff_longitude' and\n# 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n# the pickup location to the dropoff location.\ndef add_travel_vector_features(df):\n    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n\nadd_travel_vector_features(df_my_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61ee79c7192a53c8fa97974b01cf2abfe30f4e5b"},"cell_type":"code","source":"df_my_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e051fdb0d14708a0d7d9d1fa0135124b366fbf19"},"cell_type":"code","source":"#analyzing the distribution of `Fair amount`\nplt.hist(df_my_test['fare_amount'][:2000])\n\nplt.xlabel('Fair amount in dollars')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bc42a9beddd76b1d569fd128568bc83e896b9fa"},"cell_type":"code","source":"df_my_test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3591892016ecde21173c7b8faf7679b905b045d"},"cell_type":"code","source":"#Write a function to get the columns that we want to include in our X matrix as we would be doing the same with our test set.\ndef get_input_matrix(df):\n    return np.column_stack((df.pickup_longitude, df.abs_diff_longitude, df.abs_diff_latitude, \n                            df.pickup_latitude, df.dropoff_longitude, df.dropoff_latitude, \n                            df.Hour, df.Day_of_Week, df.Month, df.Year))\n\nX = get_input_matrix(df_my_test)\nY = np.array(df_my_test['fare_amount'])\n\nprint(X.shape)\nprint(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5f23219e9d2cb834d63079842806b2ba349f4b1"},"cell_type":"code","source":"# Given a dataframe, add two new features 'abs_diff_longitude' and\n# 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n# the pickup location to the dropoff location.\ndef add_travel_vector_features(df):\n    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n\nadd_travel_vector_features(df_my_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ced4d30ea7e1aa8d0e08f23ec9a20223149d7edd"},"cell_type":"code","source":"df_my_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc966a977f042235bd9a5496cfd699772d7b0f2e"},"cell_type":"code","source":"plot = df_my_test.iloc[:10000].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"937a6212fa6729ea56d6a72efc91f40d35434ade"},"cell_type":"code","source":"print('Old size: %d' % len(df_my_test))\ndf_my_test = df_my_test[(df_my_test.abs_diff_longitude < 5.0) & (df_my_test.abs_diff_latitude < 5.0)]\nprint('New size: %d' % len(df_my_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5cdfb467a2048c2c92c0c89446d8ad761fe481e"},"cell_type":"code","source":"#analyzing the distribution of `Fair amount`\nplt.hist(df_my_test['fare_amount'][:2000])\n\nplt.xlabel('Fair amount in dollars')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"582daa640f5ee4651699097881808548f2cf4b19"},"cell_type":"markdown","source":"train our model"},{"metadata":{"trusted":true,"_uuid":"6cbe99a59eea8468d00a2def8eee78681f4e3819"},"cell_type":"code","source":"#Write a function to get the columns that we want to include in our X matrix as we would be doing the same with our test set.\ndef get_input_matrix(df):\n    return np.column_stack((df.pickup_longitude, df.abs_diff_longitude, df.abs_diff_latitude, \n                            df.pickup_latitude, df.dropoff_longitude, df.dropoff_latitude, \n                            df.Hour, df.Day_of_Week, df.Month, df.Year))\n\nX = get_input_matrix(df_my_test)\nY = np.array(df_my_test['fare_amount'])\n\nprint(X.shape)\nprint(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2be518d9d39b65001a9612ee0c4e5f23555aaffd"},"cell_type":"code","source":"#Divide our data into train and validation set. We will be using validation set to tune the hyperparameters of the model. \nX_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size = 0.0005, random_state=0)\n\nprint(X_train.shape)\nprint(X_validation.shape)\nprint(Y_train.shape)\nprint(Y_validation.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6503130cffc3fc09487c2caacdb3cb6d0bd8451"},"cell_type":"code","source":"# train with Gradient Boosting algorithm\n# compute the accuracy scores on train and validation sets when training with different learning rates\n\nlearning_rates = [1]\nfor learning_rate in learning_rates:\n    gb = GradientBoostingRegressor(n_estimators = 10, learning_rate = learning_rate, max_depth = 6, random_state = 0)\n    gb.fit(X_train, Y_train)\n    pred_train = gb.predict(X_train)\n    pred_validation = gb.predict(X_validation)\n    print(\"Learning rate: \", learning_rate)\n    print(\"RMSE (training): {0:.3f}\".format(np.sqrt(mean_squared_error(Y_train, pred_train))))\n    print(\"RMSE (validation): {0:.3f}\".format(np.sqrt(mean_squared_error(Y_validation, pred_validation))))\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2229ef629035c7ae0c20296fa5eabeb9a4f1ad0d"},"cell_type":"code","source":"#let's see what are the significant features in predicting our output\ngb.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29c018b71cb85557c74b02069027bf0ef82170cc"},"cell_type":"code","source":"plt.bar(range(len(gb.feature_importances_)), gb.feature_importances_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0fd6b80ccde7742cfec1ed73d18505d8b5060bf"},"cell_type":"markdown","source":"predictions"},{"metadata":{"trusted":true,"_uuid":"52426a88f251d7ffe99445ad2ffef02cdd06e8bc"},"cell_type":"code","source":"df_my_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0c6ec808c50011bc1fa97c6690a4f025837a787"},"cell_type":"code","source":"test_X = get_input_matrix(df_my_test)\ntest_y_predictions = gb.predict(test_X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f15f23e7487bb7663b3692c66263660a2a27fd8"},"cell_type":"code","source":"ss = pd.read_csv('../input/sample_submission.csv')\nss.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3ee3496f66d1795fe73df5cf7bc4fb488309f31"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}