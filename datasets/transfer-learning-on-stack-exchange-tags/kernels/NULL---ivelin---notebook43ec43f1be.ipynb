{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "metadata": {
        "_cell_guid": "fa771ea8-84c7-1bab-12c8-3b9b0e630c50",
        "_active": false,
        "collapsed": false
      },
      "source": null,
      "execution_count": null,
      "cell_type": "markdown",
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b1b576b0-39e4-9b8c-4fae-287f8ab09663",
        "_active": false,
        "collapsed": false
      },
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "cell_type": "code",
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1b2a18f3-e47c-cf63-8183-0774c8506d31",
        "_active": false,
        "collapsed": false
      },
      "source": "%%time\ndef load_data():\n    import pandas as pd\n    dfs = {\"biology\": pd.read_csv(\"../input/biology.csv\"),\n           \"cooking\": pd.read_csv(\"../input/cooking.csv\"),\n           \"crypto\": pd.read_csv(\"../input/crypto.csv\"),\n           \"diy\": pd.read_csv(\"../input/diy.csv\"),       \n           \"robotics\": pd.read_csv(\"../input/robotics.csv\"),\n           \"travel\": pd.read_csv(\"../input/travel.csv\")}\n    return dfs\n    \n    \ndf = load_data()\nprint(df[\"biology\"].iloc[1])",
      "execution_count": 9,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "48638c27-eac8-7f6e-7d98-d0bd1d4ee873",
        "_active": true,
        "collapsed": false
      },
      "source": "%%time\ndef preprocess(x):\n    from bs4 import BeautifulSoup\n    import re\n    import string\n\n    # remove html tags from contents\n    uri_re = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))'\n    if x:\n        # BeautifulSoup on content\n        soup = BeautifulSoup(x, \"html.parser\")\n        # Stripping all <code> tags with their content if any\n        if soup.code:\n            soup.code.decompose()\n        # Get all the text out of the html\n        text =  soup.get_text()\n        # Returning text stripping out all uris\n        return re.sub(uri_re, \"\", text)\n    else:\n        return \"\"\n\n\n# This could take a while\nfor d in df.values():\n    d[\"content\"] = d[\"content\"].map(preprocess)\n    \nprint(df[\"biology\"].iloc[1])",
      "execution_count": 10,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "387dd71b-5902-ccea-b177-78c078d7f410",
        "_active": false,
        "collapsed": false
      },
      "source": null,
      "execution_count": null,
      "cell_type": "code",
      "outputs": []
    }
  ]
}