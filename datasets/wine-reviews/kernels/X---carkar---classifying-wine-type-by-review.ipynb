{"metadata": {"language_info": {"name": "python", "pygments_lexer": "ipython3", "version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "nbconvert_exporter": "python", "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "cells": [{"outputs": [], "metadata": {"_uuid": "1420de3ebd6096c6b9227ae9a8b8813703e68396", "_execution_state": "idle", "collapsed": false, "_cell_guid": "4a7c2462-bf25-4e2c-8fd5-77ffd0dc09da"}, "source": "Exploration of wine reviews data and text based logistic regression modeling \nAvailable on Gihub: https://github.com/carkar7/Classifying-wine-type-based-on-wine-reviews", "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "252ae7428c39d6056138dcfd81a128070b7ec0e1", "_execution_state": "idle", "trusted": false, "collapsed": false, "_cell_guid": "983b0d3c-ebc0-44df-a031-92c3a09f59dd"}, "execution_count": null, "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.feature_extraction.text import CountVectorizer \n", "from sklearn.model_selection import train_test_split\n", "%matplotlib inline"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "7898f34f280be6007e39cf211d34ce6f23ad1a42", "_cell_guid": "bc02336e-1b29-43fb-b7c2-63f8851556b6"}, "execution_count": null, "source": "# Reading and Cleaning", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "8be985e6c8a135d224f27c93f897cf440b3277bf", "_execution_state": "idle", "trusted": false, "collapsed": false, "_cell_guid": "e69bd0c6-47db-445d-92d8-21dacd240ae4"}, "execution_count": null, "source": "data = pd.read_csv('../input/winemag-data_first150k.csv')\ndata.head(5)", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "1b834952b54fd927e43955382278923146c394d8", "_cell_guid": "95b91504-180b-46c2-b972-d19a0d56c877"}, "execution_count": null, "source": "## Lots of duplicates\nThere are a lot of duplicates in this data. Oddly enough, I noticed that simply running data.drop_duplicates() did not remove all duplicates, which is the result of some columns between the duplicated rows differeing. Nevertheless, the fact that the \"Description\" columns were identical was a dead giveaway that these were not a different reviews. ", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "0d3ede548151ac42eac4d70b0c98b56ac5f2d8f1", "trusted": false, "collapsed": false, "_cell_guid": "b92795cf-1ac0-412d-9bc4-e5c1947636df"}, "execution_count": null, "source": "data[data.duplicated('description',keep=False)].sort_values('description').head(5)", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "63a5c3f732b6e2ce11266cc2bf518d9d50040e5f", "_cell_guid": "7dd3d7ae-eabd-488d-a4f8-4de37e9a97cb"}, "execution_count": null, "source": "I decided to drop all duplicates based on the description column alone and subsequently all missing price data:", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "f23fb766288f1df466dd47f3b0d45855545cdc0d", "trusted": false, "collapsed": false, "_cell_guid": "8f8dcc52-0fc2-48bb-92ef-f0878223b080"}, "execution_count": null, "source": "data = data.drop_duplicates('description')\ndata = data[pd.notnull(data.price)]\ndata.shape", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "9c33921e7b20d41ca8d7a11cfc0a30781a3cff39", "_cell_guid": "7a8fbaa4-c5aa-4b98-8724-0d60b57aaef7"}, "execution_count": null, "source": "# Exploratory Analysis\nNot surprisingly, there's a significant correlation between the cost of wine and its rating, namely theres an average $1.18  increase for every one point incrase in rating.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "9024783b53c9d977225e7e6e532f5dd6660d02fe", "trusted": false, "collapsed": false, "_cell_guid": "59508930-3df2-4f0e-9bbf-e99c01ea1818"}, "execution_count": null, "source": "from scipy.stats import pearsonr\nimport statsmodels.api as sm\nprint(\"Pearson Correlation:\", pearsonr(data.price, data.points))\nprint(sm.OLS(data.points, data.price).fit().summary())\nsns.lmplot(y = 'price', x='points', data=data)\n", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "6719195c84dd13a23e31926203f25a1fbc2e444f", "_cell_guid": "81066395-dd0c-4090-ab78-0aa90f028826"}, "execution_count": null, "source": "Plotting all the countries, there's some odd plots as a result of low sample size for certain countries.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "cd9500d8ce4283db5b7362a9b1ecbc360db7b399", "trusted": false, "collapsed": false, "_cell_guid": "57d13702-38dc-4351-9eb7-ba0f08720a59"}, "execution_count": null, "source": "fig, ax = plt.subplots(figsize = (20,7))\nchart = sns.boxplot(x='country',y='points', data=data, ax = ax)\nplt.xticks(rotation = 90)\nplt.show()", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "d65bd6dea34f51efd38027b73a683c40a62c1e38", "trusted": false, "collapsed": false, "_cell_guid": "25eacb72-3e6f-4b10-b17f-bf46123a4b36"}, "execution_count": null, "source": "data.country.value_counts()[:17]", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "182e5ebb7e53e0cbe1362019e336e56d33fbca45", "_cell_guid": "273896fa-6720-4ce2-9e35-052120dde639"}, "execution_count": null, "source": "After removing all countries with less than 100 observations, it appears that Germany, Austria, and Canada have the highest median scores(points). However, the distribution overall appears to be fairly uniform.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "9516fde893d56c5c0af7fe83e9fa93ba76b82456", "trusted": false, "collapsed": false, "_cell_guid": "9b0388ba-2c92-451a-93d2-b36bd321e91b"}, "execution_count": null, "source": "country=data.groupby('country').filter(lambda x: len(x) >100)\ndf2 = pd.DataFrame({col:vals['points'] for col,vals in country.groupby('country')})\nmeds = df2.median()\nmeds.sort_values(ascending=False, inplace=True)\n\nfig, ax = plt.subplots(figsize = (20,7))\nchart = sns.boxplot(x='country',y='points', data=country, order=meds.index, ax = ax)\nplt.xticks(rotation = 90)\n\nplt.show()", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "c21f180dee7776c2b41af5f6efb0cd7f0fc96298", "_cell_guid": "3e022173-6dc3-4986-b904-d4249e0871f8"}, "execution_count": null, "source": "Below are the average wine prices sorted by median (highest to lowest) in order to evaluate price distortions due to outliers.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "8f8d9133b9691cdb7603ee945cb359cd8c1464f1", "trusted": false, "collapsed": false, "_cell_guid": "ec2502e5-ebbe-45d5-8467-5bd1566b573f", "scrolled": true}, "execution_count": null, "source": "df3 = pd.DataFrame({col:vals['price'] for col,vals in country.groupby('country')})\nmeds2 = df3.median()\nmeds2.sort_values(ascending=False, inplace=True)\n\nfig, ax = plt.subplots(figsize = (20,5))\nchart = sns.barplot(x='country',y='price', data=country, order=meds2.index, ax = ax)\nplt.xticks(rotation = 90)\nplt.show()", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "6f91661c3e01e5bc79c7099db321bbfe24397876", "trusted": false, "collapsed": false, "_cell_guid": "1237d853-5211-49e3-8b7c-ec677fb1475e"}, "execution_count": null, "source": "# medians for the above barplot\nprint(meds2)", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "7b58ecd486befa40e99a20c4b87f548323ca69ab", "_cell_guid": "16679fbc-1e3a-4572-a7d9-41061d8e52c9"}, "execution_count": null, "source": "There's a large variety of wines in the dataset (I never knew there was so many!) However, there's an exponential decline in the number of observations for each wine type, and since we'll be attempting to use these labels to classify our model, I'll be dropping any wine types with less than 200 observations, for the reason that I don't believe there's enough data in these buckets to generate an accuarte model for predicting their respective wine type", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "d32a12f707524dcf59fea1a23cdcac0f8fed75b7", "trusted": false, "collapsed": false, "_cell_guid": "dd10cab8-95c4-4186-9a1b-af93a0d9c2ce"}, "execution_count": null, "source": "data = data.groupby('variety').filter(lambda x: len(x) >100)\nlist = data.variety.value_counts().index.tolist()\nfig4, ax4 = plt.subplots(figsize = (20,7))\nsns.countplot(x='variety', data=data, order = list, ax=ax4)\nplt.xticks(rotation = 90)\nplt.show()", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "d9761e2f07084590a714d05fbd98b7ffb8c96788", "_cell_guid": "98d588d4-f009-49c3-9b42-c247ba061bea"}, "execution_count": null, "source": "Below is a boxplot chart containing all wine varieties (w/ >200 observations) and their respective point distributions. Sangiovese Grosso (never tried it) appears to have the highest median score of all wines. There are some interesting dips occuring after Champagne Blend, Shiraz, Cabernet Sauvignon (my favorite), and Nero d'Avola. Of interest is Merlot, which tends to have a large number of highly reviewed outliers. Despite these slight variations, overall the point distibution is basically uniform.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "57539cdd40d80962e00a87585d7f02bcc3f9de43", "trusted": false, "collapsed": false, "_cell_guid": "04f8e49d-d860-4b58-a2f9-041a3b41d212"}, "execution_count": null, "source": "data = data.groupby('variety').filter(lambda x: len(x) >200)\n\ndf4 = pd.DataFrame({col:vals['points'] for col,vals in data.groupby('variety')})\nmeds3 = df4.median()\nmeds3.sort_values(ascending=False, inplace=True)\n\nfig3, ax3 = plt.subplots(figsize = (20,7))\nchart = sns.boxplot(x='variety',y='points', data=data, order=meds3.index, ax = ax3)\nplt.xticks(rotation = 90)\nplt.show()", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "d4e1d44d1af916e44d219eeddf85dbbe1bd455d3", "trusted": false, "collapsed": false, "_cell_guid": "ef6db3cf-89fb-400a-bb27-3c9b743c8cdc"}, "execution_count": null, "source": "df5 = pd.DataFrame({col:vals['points'] for col,vals in data.groupby('variety')})\nmean1 = df5.mean()\nmean1.sort_values(ascending=False, inplace=True)\n\nfig3, ax3 = plt.subplots(figsize = (20,7))\nchart = sns.barplot(x='variety',y='points', data=data, order=mean1.index, ax = ax3)\nplt.xticks(rotation = 90)\nplt.show()", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "d8589be171caa25c42091730ef1a8e3674bb0eda", "_cell_guid": "a00cadc1-5427-4937-9347-b4157560f90d"}, "execution_count": null, "source": "It's definitely not the same story when you look at price. There's clear variation in here, which may help in predicting the wine type.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "846adc58bc2b0e8030482b74a877e8230fc7644b", "trusted": false, "collapsed": false, "_cell_guid": "5e387d8b-f554-472c-aa4c-3936da0b2b3c"}, "execution_count": null, "source": "df6 = pd.DataFrame({col:vals['price'] for col,vals in data.groupby('variety')})\nmean2 = df6.mean()\nmean2.sort_values(ascending=False, inplace=True)\n\nfig3, ax3 = plt.subplots(figsize = (20,7))\nchart = sns.barplot(x='variety',y='price', data=data, order=mean2.index, ax = ax3)\nplt.xticks(rotation = 90)\nplt.show()", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "06e6c4411fbbb9e59423def0ec5c52e169b788c9", "_cell_guid": "1e40a169-3f1a-4bed-926e-79504682c046"}, "execution_count": null, "source": "# Modeling: Logistic Regression\n", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "00f3e2de113c0ddbaa477b0275c502412b1fd925", "trusted": false, "collapsed": false, "_cell_guid": "d3b20c90-41ed-4755-8d90-ac17dec4c786"}, "execution_count": null, "source": "X = data.drop(['Unnamed: 0','country','designation','points','province','region_1','region_2','variety','winery'], axis = 1)\ny = data.variety\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "648f9415cf075eab486b22c174f51a7980508504", "_cell_guid": "d2a4ed11-ee37-41ad-81fc-da90aef9bb8b"}, "execution_count": null, "source": "### The Label Occurs in the Desciption!\nMy first time around with this dataset, I was getting accuracy scores around 80% but something didn't feel right... \n\nIf you read the descriptions, the reviewers often times say \"Cabertnet\", \"Pinot\", \"Red\", etc. in the review itself, and these words need to be taken off if the aim is to create a model that doesn't rely on the probability that a word in the description that matches the label. WIth that said, I included tokenized versions of the feature labels as parts of the stopwords used in analysis.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "fa1d6f68e1f027b93ca1fb75ee195c36956b3464", "trusted": false, "collapsed": false, "_cell_guid": "4f8eabc4-61e5-435f-b352-6283e70b320e"}, "execution_count": null, "source": "wine =data.variety.unique().tolist()\nwine.sort()\nwine[:10]", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "806465d7f38a934a062ed10a84e5402f11ef8f00", "trusted": false, "collapsed": false, "_cell_guid": "97db9cd6-8450-4509-95c8-9e51a0432373"}, "execution_count": null, "source": "output = set()\nfor x in data.variety:\n    x = x.lower()\n    x = x.split()\n    for y in x:\n        output.add(y)\n\nvariety_list =sorted(output)\nvariety_list[:10]\n", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "f3208ceaa2c64310536f7ecb6e12c5134096aa80", "trusted": false, "collapsed": false, "_cell_guid": "c4edc342-4d77-4615-850b-47af97cf770b"}, "execution_count": null, "source": "extras = ['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}', 'cab',\"%\"]\nfrom nltk.corpus import stopwords\nstop = set(stopwords.words('english'))\nstop.update(variety_list)\nstop.update(extras)", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "61ae3b8e6b69431a8de3f5e00e994fc1e33215c6", "_cell_guid": "7fe3afd4-ad1e-4de9-9813-00b923bdb0c6"}, "execution_count": null, "source": "### Features\nThe features being used in this model will be the wine price and it's description. ", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "fbb5531a0772f51f08275695fc69eff9ccaf4934", "trusted": false, "collapsed": false, "_cell_guid": "52fcd1c8-b3cf-4826-84c2-e18501cd72c8"}, "execution_count": null, "source": "from scipy.sparse import hstack\n\nvect = CountVectorizer(stop_words = stop)\nX_train_dtm = vect.fit_transform(X_train.description)\nprice = X_train.price.values[:,None]\nX_train_dtm = hstack((X_train_dtm, price))\nX_train_dtm", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "517a4188d88cf8899d9983e7c1d65c5014f59cc2", "trusted": false, "collapsed": false, "_cell_guid": "95c8cedb-62f1-4cf8-9c1c-f701213741f7"}, "execution_count": null, "source": "X_test_dtm = vect.transform(X_test.description)\nprice_test = X_test.price.values[:,None]\nX_test_dtm = hstack((X_test_dtm, price_test))\nX_test_dtm", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "f3422d0b6a0dfb162775e13a496faa96bdb08c2d", "trusted": false, "collapsed": false, "_cell_guid": "6c6e3ec8-c1d6-4121-8400-93b7d0ab5e67"}, "execution_count": null, "source": "from sklearn.linear_model import LogisticRegression\nmodels = {}\nfor z in wine:\n    model = LogisticRegression()\n    y = y_train == z\n    model.fit(X_train_dtm, y)\n    models[z] = model\n\ntesting_probs = pd.DataFrame(columns = wine)", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "c1333205bc93988cd93d5e2d1b97c6792e027948", "_cell_guid": "2a9d26bb-3ec3-456d-903d-db672f423a15"}, "execution_count": null, "source": "# Final Accuracy: 53%\nThere's definitely room for improvement, and I could include other features to see if accuracy increases, but for now I'll settle with this and grab a glass of wine for myself :)", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "53c2af7852342806408ccc28bb0106ae530cf05d", "trusted": false, "collapsed": false, "_cell_guid": "2f0764eb-4818-4c40-9483-74a4fa038278"}, "execution_count": null, "source": "for variety in wine:\n    testing_probs[variety] = models[variety].predict_proba(X_test_dtm)[:,1]\n    \npredicted_wine = testing_probs.idxmax(axis=1)\n\ncomparison = pd.DataFrame({'actual':y_test.values, 'predicted':predicted_wine.values})   \n\nfrom sklearn.metrics import accuracy_score\nprint('Accuracy Score:',accuracy_score(comparison.actual, comparison.predicted)*100,\"%\")\ncomparison.head(5)", "cell_type": "code"}], "nbformat_minor": 2, "nbformat": 4}