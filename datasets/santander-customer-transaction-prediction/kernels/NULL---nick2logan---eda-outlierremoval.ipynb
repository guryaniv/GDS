{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/train.csv\")\ntest_data = pd.read_csv(\"../input/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d40c58a722f6e51de18b49f6240543730dfea16e"},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1696823b068edab285f66f6950c7d2501030528a"},"cell_type":"markdown","source":"1. ID_code is unique Identifier\n2. Target is binary\n3. Variables from 0 to 199"},{"metadata":{"trusted":true,"_uuid":"4d55159155000644bec4633e25e491a35748d5af"},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"587841d00627e740795c0a6c0c32272ffd50d98b","_kg_hide-output":true},"cell_type":"code","source":"#plt.figure(figsize=(100, 100))\ntrain_crr=train_data.copy()\ntrain_crr.drop(['ID_code', 'target'],axis=1, inplace=True)\ncorr = train_crr.apply(lambda x: pd.factorize(x)[0]).corr()\n#ax = sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, linewidths=.2, cmap=\"YlGnBu\")\nprint(corr)\ncorr.to_csv(\"corr.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8304f33f8e61a3c3b458daff5f66dee8a449d7d"},"cell_type":"code","source":"#print(\"Correlation Matrix\")\n#print(train_crr.corr())\n#print()\n\ndef get_redundant_pairs(df):\n    '''Get diagonal and lower triangular pairs of correlation matrix'''\n    pairs_to_drop = set()\n    cols = df.columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\ndef get_top_abs_correlations(df, n=5):\n    au_corr = df.corr().abs().unstack()\n    labels_to_drop = get_redundant_pairs(df)\n    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n    return au_corr[0:n]\n\nprint(\"Top Absolute Correlations\")\nprint(get_top_abs_correlations(train_crr, 20))\n#all_crr=get_top_abs_correlations(train_crr, 200)\n#all_crr.to_csv(\"all_crr.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd1157272dbccca63cfa8341668fc03d9b8a8440"},"cell_type":"markdown","source":"Lets take the raw data and run a random forest model to check feature importance. This will give us an order in which we can explore the variables. We will take a sample of 5000 rows and remove ID column"},{"metadata":{"trusted":true,"_uuid":"f701d44cd700e20751b96dfb926b8e8bf2472a06"},"cell_type":"code","source":"train_data.shape\n#(200000, 202)\n\n\nsample_data=train_data.sample(5000)\nsample_data=sample_data.drop([\"ID_code\"], axis=1)\n\nsample_x = sample_data.loc[:, ~sample_data.columns.isin(['target'])]\nsample_y = sample_data.loc[:,'target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12540260d806b6fd0ffcaf706e86d05010db2fbc"},"cell_type":"code","source":"sample_x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d660a45f1cc5207d8696a7ae0a3aa64149e64866"},"cell_type":"code","source":"sample_y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5daf4ac4d4837dc727e6f37dfae8583031011c3"},"cell_type":"code","source":"# Import train_test_split function\nfrom sklearn.model_selection import train_test_split\n\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(sample_x, sample_y, test_size=0.3) # 70% training and 30% test\n\n#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\ny_pred=clf.predict(X_test)\n\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n\n# Model F1 Score\nprint(\"F Score:\" , metrics.fbeta_score(y_test, y_pred, beta=0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66bfae0aafdb3567d89d58704288abb09270db5d"},"cell_type":"code","source":"feature_imp = pd.Series(clf.feature_importances_,index=sample_x.columns).sort_values(ascending=False)\nfeature_imp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f5bd48cdc9dbc898d30c81a85098b5e8fd5d8b8"},"cell_type":"code","source":"df=train_data.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5311f6ab44e1cf8dcba290aef93684be4149019"},"cell_type":"markdown","source":"As per above results, we will explore variable 147 first"},{"metadata":{"trusted":true,"_uuid":"c392bfdac71a0d5824b2a118bcf124710e73814c"},"cell_type":"code","source":"def kdeplot(feature):\n    plt.figure(figsize=(9, 4))\n    plt.title(\"KDE for {}\".format(feature))\n    ax0 = sns.kdeplot(df[df['target'] == 0][feature].dropna(), color= 'navy', label= 'target: 0')\n    ax1 = sns.kdeplot(df[df['target'] == 1][feature].dropna(), color= 'orange', label= 'target: 1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6509a7c6ff7e3d53c31eef64ab33ff7b7e82cfe"},"cell_type":"code","source":"kdeplot('var_147')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5b50b16a082737c6cdc112f448cf471c14cb849"},"cell_type":"markdown","source":"There is not a significant differnece between target values for var_147"},{"metadata":{"_uuid":"aebd6a339d82c78cd6676a97aa8554d87d11f843"},"cell_type":"markdown","source":"Taking helper function from https://towardsdatascience.com/a-starter-pack-to-exploratory-data-analysis-with-python-pandas-seaborn-and-scikit-learn-a77889485baf"},{"metadata":{"trusted":true,"_uuid":"faf757d115495d252d24504f6c16e7c437183644"},"cell_type":"code","source":"def categorical_summarized(dataframe, x=None, y=None, hue=None, palette='Set1', verbose=True):\n    '''\n    Helper function that gives a quick summary of a given column of categorical data\n\n    Arguments\n    =========\n    dataframe: pandas dataframe\n    x: str. horizontal axis to plot the labels of categorical data, y would be the count\n    y: str. vertical axis to plot the labels of categorical data, x would be the count\n    hue: str. if you want to compare it another variable (usually the target variable)\n    palette: array-like. Colour of the plot\n\n    Returns\n    =======\n    Quick Stats of the data and also the count plot\n    '''\n    if x == None:\n        column_interested = y\n    else:\n        column_interested = x\n    series = dataframe[column_interested]\n    print(series.describe())\n    print('mode: ', series.mode())\n    if verbose:\n        print('='*80)\n        print(series.value_counts())\n\n    #sns.countplot(x=x, y=y, hue=hue, data=dataframe, palette=palette)\n    #plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b059b72a32f78894b2554cf732df639725b9ed0e"},"cell_type":"code","source":"# Target Variable: Survival\nc_palette = ['tab:blue', 'tab:orange']\ncategorical_summarized(df, y = 'var_147', palette=c_palette)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba32a56fc736c4cd1b9c10cc70b95a8620a996f2"},"cell_type":"markdown","source":"* Huge difference between minimum and maximum\n* large proportion of values are negative"},{"metadata":{"trusted":true,"_uuid":"4875d140a4dbef839979fb34c6824441cf5b8862"},"cell_type":"code","source":"def quantitative_summarized(dataframe, x=None, y=None, hue=None, palette='Set1', ax=None, verbose=True, swarm=False):\n    '''\n    Helper function that gives a quick summary of quantattive data\n\n    Arguments\n    =========\n    dataframe: pandas dataframe\n    x: str. horizontal axis to plot the labels of categorical data (usually the target variable)\n    y: str. vertical axis to plot the quantitative data\n    hue: str. if you want to compare it another categorical variable (usually the target variable if x is another variable)\n    palette: array-like. Colour of the plot\n    swarm: if swarm is set to True, a swarm plot would be overlayed\n\n    Returns\n    =======\n    Quick Stats of the data and also the box plot of the distribution\n    '''\n    series = dataframe[y]\n    print(series.describe())\n    print('mode: ', series.mode())\n    if verbose:\n        print('='*80)\n        print(series.value_counts())\n\n    sns.boxplot(x=x, y=y, hue=hue, data=dataframe, palette=palette, ax=ax)\n\n    if swarm:\n        sns.swarmplot(x=x, y=y, hue=hue, data=dataframe,\n                      palette=palette, ax=ax)\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5436d430e9ed65e98deb6c1bfea479e775a64e7e"},"cell_type":"code","source":"# univariate analysis\nc_palette = ['tab:blue', 'tab:orange']\nquantitative_summarized(dataframe= df, y = 'var_147', palette=c_palette, verbose=False, swarm=False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bed79004676b8b28a3a9badaa01d49935ef7dd2f"},"cell_type":"markdown","source":"************************ NEW CODE ****************************************"},{"metadata":{"trusted":true,"_uuid":"1863cef4da78da40d524c031510ee311d5013516"},"cell_type":"code","source":"df = train_data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7082b499a5882655253a129b76b5ae52f821be51"},"cell_type":"code","source":"df = df.drop([\"ID_code\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f89daeb2c2d0d890fd5ed5b0a1717f3e8b3c2d56"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b436fb530819d3a48cadadb95bcc7b00e7c7cd9a"},"cell_type":"code","source":"df.iloc[:,0:10].hist(figsize=(15, 15), bins=40, xlabelsize=8, ylabelsize=8); # ; avoid having the matplotlib verbose informations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2880f793932f8d10dd58c32402248ff8e146e476"},"cell_type":"code","source":"df_new_1 = df[df.target==1]\n#Multiply by some constant except the target variable\ndf_new_1.iloc[:,0:10].hist(figsize=(15, 15), bins=40, xlabelsize=8, ylabelsize=8);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d76f26e9aefe664d4d04d79f81728b8cf5e2703"},"cell_type":"code","source":"df_new_0 = df[df.target==0]\n#Multiply by some constant except the target variable\ndf_new_0.iloc[:,0:10].hist(figsize=(15, 15), bins=40, xlabelsize=8, ylabelsize=8);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18dd7e5c40ae17093ff4075948d8d2e90d21c961"},"cell_type":"code","source":"\ndf_corr = df.corr()['target'][:-1] # -1 because the latest row is target\ngolden_features_list = df_corr[abs(df_corr) > 0.1].sort_values(ascending=False)\nprint(\"There is {} strongly correlated values with target:\\n{}\".format(len(golden_features_list), golden_features_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8641ebc10959d34045e3ab0f5bcf723c1b2b110a"},"cell_type":"code","source":"for i in range(0, 5 , 5):\n    sns.pairplot(data=df,\n                x_vars=df.columns[i:i+5],\n                y_vars=['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5431eccd45ea39540619655497bed8679808c32"},"cell_type":"code","source":"for i in range(5, 14 , 5):\n    sns.pairplot(data=df,\n                x_vars=df.columns[i:i+5],\n                y_vars=['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"180e9db6a01b16405cc80e3ac9499a21f45b18f3"},"cell_type":"code","source":"plt.figure(figsize = (5, 5))\nax = sns.boxplot(y='var_0', x='target', data=df)\nplt.setp(ax.artists, alpha=.5, linewidth=2, edgecolor=\"k\")\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97ac80202235fa7574d8bfe8899edb8adf357fb3"},"cell_type":"code","source":"plt.close()\nplt.figure(figsize = (5, 5))\nax = sns.boxplot(y='var_10', x='target', data=df)\nplt.setp(ax.artists, alpha=.5, linewidth=2, edgecolor=\"k\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bee52b7410fe064edaa01869631214f33eecf94"},"cell_type":"code","source":"# Detect outliers from IQR\nQ1 = df.quantile(0.25)\nQ3 = df.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7c0ded5741936430209bd8abf23f9f5371104a0"},"cell_type":"code","source":"print((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28fd58bc7e57fb1267cf5235aca414f6abb91461"},"cell_type":"code","source":"print(\"df.shape:\",df.shape)\ndf_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\nprint(\"df_out.shape:\",df_out.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0ba95a1b50f3e8d7136f4023c2840aa808f9362"},"cell_type":"code","source":"tdata = train_data.copy()\n\ntdata = tdata.loc[tdata.index & df_out.index]\ntdata = tdata.loc[np.intersect1d(tdata.index, df_out.index)]\ntdata = tdata.loc[tdata.index.intersection(df_out.index)]\n\nprint(\"tdata.shape:\",tdata.shape)\n\ntdata.head()\n\ntdata.to_csv(\"train_data_new.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}