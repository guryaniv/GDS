{"cells": [{"cell_type": "code", "execution_count": null, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "plt.rcParams['axes.labelsize'] = 14\n", "plt.rcParams['xtick.labelsize'] = 12\n", "plt.rcParams['ytick.labelsize'] = 12\n", "\n", "%matplotlib inline\n", "\n", "np.random.seed(42)\n", "\n", "\n", "from sklearn.base import BaseEstimator, TransformerMixin\n", "from sklearn.utils import check_array\n", "from sklearn.preprocessing import LabelEncoder\n", "from scipy import sparse\n", "\n", "# Definition of the CategoricalEncoder class, copied from PR #9151.\n", "\n", "from sklearn.base import BaseEstimator, TransformerMixin\n", "from sklearn.utils import check_array\n", "from sklearn.preprocessing import LabelEncoder\n", "from scipy import sparse\n", "\n", "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n", "    \"\"\"Encode categorical features as a numeric array.\n", "    The input to this transformer should be a matrix of integers or strings,\n", "    denoting the values taken on by categorical (discrete) features.\n", "    The features can be encoded using a one-hot aka one-of-K scheme\n", "    (``encoding='onehot'``, the default) or converted to ordinal integers\n", "    (``encoding='ordinal'``).\n", "    This encoding is needed for feeding categorical data to many scikit-learn\n", "    estimators, notably linear models and SVMs with the standard kernels.\n", "    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n", "    Parameters\n", "    ----------\n", "    encoding : str, 'onehot', 'onehot-dense' or 'ordinal'\n", "        The type of encoding to use (default is 'onehot'):\n", "        - 'onehot': encode the features using a one-hot aka one-of-K scheme\n", "          (or also called 'dummy' encoding). This creates a binary column for\n", "          each category and returns a sparse matrix.\n", "        - 'onehot-dense': the same as 'onehot' but returns a dense array\n", "          instead of a sparse matrix.\n", "        - 'ordinal': encode the features as ordinal integers. This results in\n", "          a single column of integers (0 to n_categories - 1) per feature.\n", "    categories : 'auto' or a list of lists/arrays of values.\n", "        Categories (unique values) per feature:\n", "        - 'auto' : Determine categories automatically from the training data.\n", "        - list : ``categories[i]`` holds the categories expected in the ith\n", "          column. The passed categories are sorted before encoding the data\n", "          (used categories can be found in the ``categories_`` attribute).\n", "    dtype : number type, default np.float64\n", "        Desired dtype of output.\n", "    handle_unknown : 'error' (default) or 'ignore'\n", "        Whether to raise an error or ignore if a unknown categorical feature is\n", "        present during transform (default is to raise). When this is parameter\n", "        is set to 'ignore' and an unknown category is encountered during\n", "        transform, the resulting one-hot encoded columns for this feature\n", "        will be all zeros.\n", "        Ignoring unknown categories is not supported for\n", "        ``encoding='ordinal'``.\n", "    Attributes\n", "    ----------\n", "    categories_ : list of arrays\n", "        The categories of each feature determined during fitting. When\n", "        categories were specified manually, this holds the sorted categories\n", "        (in order corresponding with output of `transform`).\n", "    Examples\n", "    --------\n", "    Given a dataset with three features and two samples, we let the encoder\n", "    find the maximum value per feature and transform the data to a binary\n", "    one-hot encoding.\n", "    >>> from sklearn.preprocessing import CategoricalEncoder\n", "    >>> enc = CategoricalEncoder(handle_unknown='ignore')\n", "    >>> enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n", "    ... # doctest: +ELLIPSIS\n", "    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,\n", "              encoding='onehot', handle_unknown='ignore')\n", "    >>> enc.transform([[0, 1, 1], [1, 0, 4]]).toarray()\n", "    array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n", "           [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])\n", "    See also\n", "    --------\n", "    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of\n", "      integer ordinal features. The ``OneHotEncoder assumes`` that input\n", "      features take on values in the range ``[0, max(feature)]`` instead of\n", "      using the unique values.\n", "    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n", "      dictionary items (also handles string-valued features).\n", "    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n", "      encoding of dictionary items or strings.\n", "    \"\"\"\n", "\n", "    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,\n", "                 handle_unknown='error'):\n", "        self.encoding = encoding\n", "        self.categories = categories\n", "        self.dtype = dtype\n", "        self.handle_unknown = handle_unknown\n", "\n", "    def fit(self, X, y=None):\n", "        \"\"\"Fit the CategoricalEncoder to X.\n", "        Parameters\n", "        ----------\n", "        X : array-like, shape [n_samples, n_feature]\n", "            The data to determine the categories of each feature.\n", "        Returns\n", "        -------\n", "        self\n", "        \"\"\"\n", "\n", "        if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:\n", "            template = (\"encoding should be either 'onehot', 'onehot-dense' \"\n", "                        \"or 'ordinal', got %s\")\n", "            raise ValueError(template % self.handle_unknown)\n", "\n", "        if self.handle_unknown not in ['error', 'ignore']:\n", "            template = (\"handle_unknown should be either 'error' or \"\n", "                        \"'ignore', got %s\")\n", "            raise ValueError(template % self.handle_unknown)\n", "\n", "        if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':\n", "            raise ValueError(\"handle_unknown='ignore' is not supported for\"\n", "                             \" encoding='ordinal'\")\n", "\n", "        X = check_array(X, dtype=np.object, accept_sparse='csc', copy=True)\n", "        n_samples, n_features = X.shape\n", "\n", "        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n", "\n", "        for i in range(n_features):\n", "            le = self._label_encoders_[i]\n", "            Xi = X[:, i]\n", "            if self.categories == 'auto':\n", "                le.fit(Xi)\n", "            else:\n", "                valid_mask = np.in1d(Xi, self.categories[i])\n", "                if not np.all(valid_mask):\n", "                    if self.handle_unknown == 'error':\n", "                        diff = np.unique(Xi[~valid_mask])\n", "                        msg = (\"Found unknown categories {0} in column {1}\"\n", "                               \" during fit\".format(diff, i))\n", "                        raise ValueError(msg)\n", "                le.classes_ = np.array(np.sort(self.categories[i]))\n", "\n", "        self.categories_ = [le.classes_ for le in self._label_encoders_]\n", "\n", "        return self\n", "\n", "    def transform(self, X):\n", "        \"\"\"Transform X using one-hot encoding.\n", "        Parameters\n", "        ----------\n", "        X : array-like, shape [n_samples, n_features]\n", "            The data to encode.\n", "        Returns\n", "        -------\n", "        X_out : sparse matrix or a 2-d array\n", "            Transformed input.\n", "        \"\"\"\n", "        X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n", "        n_samples, n_features = X.shape\n", "        X_int = np.zeros_like(X, dtype=np.int)\n", "        X_mask = np.ones_like(X, dtype=np.bool)\n", "\n", "        for i in range(n_features):\n", "            valid_mask = np.in1d(X[:, i], self.categories_[i])\n", "\n", "            if not np.all(valid_mask):\n", "                if self.handle_unknown == 'error':\n", "                    diff = np.unique(X[~valid_mask, i])\n", "                    msg = (\"Found unknown categories {0} in column {1}\"\n", "                           \" during transform\".format(diff, i))\n", "                    raise ValueError(msg)\n", "                else:\n", "                    # Set the problematic rows to an acceptable value and\n", "                    # continue `The rows are marked `X_mask` and will be\n", "                    # removed later.\n", "                    X_mask[:, i] = valid_mask\n", "                    X[:, i][~valid_mask] = self.categories_[i][0]\n", "            X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n", "\n", "        if self.encoding == 'ordinal':\n", "            return X_int.astype(self.dtype, copy=False)\n", "\n", "        mask = X_mask.ravel()\n", "        n_values = [cats.shape[0] for cats in self.categories_]\n", "        n_values = np.array([0] + n_values)\n", "        indices = np.cumsum(n_values)\n", "\n", "        column_indices = (X_int + indices[:-1]).ravel()[mask]\n", "        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n", "                                n_features)[mask]\n", "        data = np.ones(n_samples * n_features)[mask]\n", "\n", "        out = sparse.csc_matrix((data, (row_indices, column_indices)),\n", "                                shape=(n_samples, indices[-1]),\n", "                                dtype=self.dtype).tocsr()\n", "        if self.encoding == 'onehot-dense':\n", "            return out.toarray()\n", "        else:\n", "            return out"], "metadata": {"collapsed": true, "_cell_guid": "b83a9d3f-c669-49ac-8e8a-fac4119ca81c", "_uuid": "c2e3698abcaa17ba5112793cb951629afb853e43"}}, {"cell_type": "markdown", "source": ["# Load the data"], "metadata": {"_cell_guid": "ec4adc5e-22ad-43f3-b31e-308d02453a65", "_uuid": "e955b059ad65af46c05b73d0e5c271cbd95eeb43"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data = {\n", "    'air_reserve': pd.read_csv('../input/air_reserve.csv'),\n", "    'air_store_info': pd.read_csv('../input/air_store_info.csv'),\n", "    'air_visit_data': pd.read_csv('../input/air_visit_data.csv'),\n", "    'date_info': pd.read_csv('../input/date_info.csv'),\n", "    'hpg_reserve': pd.read_csv('../input/hpg_reserve.csv'),\n", "    'hpg_store_info': pd.read_csv('../input/hpg_store_info.csv'),\n", "    'store_id_relation': pd.read_csv('../input/store_id_relation.csv'),\n", "    'sample_submission': pd.read_csv('../input/sample_submission.csv'),\n", "}"], "metadata": {"collapsed": true, "_cell_guid": "f6fd42bc-6649-44dd-a05c-e8b420dcac2e", "_uuid": "38287f2c6f8beb0e11158e1f1be59bbbc7174f16"}}, {"cell_type": "markdown", "source": ["# Data Exploration"], "metadata": {"_cell_guid": "6f578b13-c31e-431c-88a6-536070794f10", "_uuid": "8ac71e246bee1b139565875e6985babac7481b0c"}}, {"cell_type": "markdown", "source": ["**Air Reserve**"], "metadata": {"_cell_guid": "d9456f49-7a86-4f17-b25f-808b164184e0", "_uuid": "3dfb4aa472e88df95e558d4e8cc277882efa3ade"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['air_reserve'].info()"], "metadata": {"_cell_guid": "270d9f60-302c-49c1-91d7-5bf743bc25b6", "_uuid": "c9a316e9b862557f3b84e5f0565b20fb3dbe9461"}}, {"cell_type": "markdown", "source": ["**Columns**\n", "- air_store_id - the restaurant's id in the air system\n", "- visit_datetime - the time of the reservation\n", "- reserve_datetime - the time the reservation was made\n", "- reserve_visitors - the number of visitors for that reservation"], "metadata": {"_cell_guid": "c5dd2795-f667-4785-aafc-074e64679926", "_uuid": "8ca0ea056a656767f5a2d3ebb0631d67cf2a361b"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['air_reserve']['visit_datetime'] = pd.to_datetime(data['air_reserve']['visit_datetime']) #Converting date object\n", "data['air_reserve']['reserve_datetime'] = pd.to_datetime(data['air_reserve']['reserve_datetime']) #Converting date object\n", "data['air_reserve']['air_store_id'].nunique() #Unique stores in air reserve data"], "metadata": {"_cell_guid": "de565c10-6265-40b6-8f57-7eb6b84942bd", "_uuid": "d950867b2eb2f5be32c71805d16b21c10777a167"}}, {"cell_type": "markdown", "source": ["** Air Store Info**"], "metadata": {"_cell_guid": "8ae1dcda-45c6-4a5c-bdcc-0fcad86b01b9", "_uuid": "eba2054c3ac40f76f4367b856156bf386939d1b2"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['air_store_info'].info()"], "metadata": {"_cell_guid": "0132297c-ef6a-4e70-be13-afc9cd13f867", "_uuid": "d1e3d261883fe9f135b4f8368cf71d1a37b8da9d"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['air_store_info']['air_store_id'].nunique()"], "metadata": {"_cell_guid": "409a31de-ba35-4637-82e1-9d0803271282", "_uuid": "39161e26eb176a4f2312a5689f0c60a9909c7e2e"}}, {"cell_type": "markdown", "source": ["** Air Visit Data **"], "metadata": {"_cell_guid": "70b1c526-cafe-4dfb-8781-ec658486f722", "_uuid": "85536069eb500d3cfdfe7258f781a16b951aa1b0"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['air_visit_data'].info()"], "metadata": {"_cell_guid": "dbdeb21b-b633-4e9f-af6a-e44e02227009", "_uuid": "b8cfaf6d7d457618306c2c96dbfe5adc545ad4f9"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['air_visit_data']['air_store_id'].nunique()"], "metadata": {"_cell_guid": "fd71ff41-07c9-4103-bd91-71e51a292c98", "_uuid": "3f567b8ee6bb7bc9d44866c10881ff4e76f31a4c"}}, {"cell_type": "markdown", "source": ["** Date Info **"], "metadata": {"_cell_guid": "e0d8dced-882c-4d18-9992-4bac2d6e5b3a", "_uuid": "859f2b1c317ba3525abe33913ef2ba0a735a14a0"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['date_info'].info()"], "metadata": {"_cell_guid": "0843a251-8279-46ca-9d82-e7731b1bb61f", "_uuid": "451811be8caf466e6bc3b42b81f5679f629a7c9c"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['date_info']['calendar_date'] = pd.to_datetime(data['date_info']['calendar_date'])\n", "#data['date_info'].describe()\n", "#data['date_info']['calendar_date'].max()"], "metadata": {"collapsed": true, "_cell_guid": "15a98768-8e1a-426b-987c-663941eaba49", "_uuid": "6a1a95272aa582fb423dd1a1a444b88fc56d98e0"}}, {"cell_type": "markdown", "source": ["** HPG Reserve **"], "metadata": {"_cell_guid": "12c3f3a3-284f-4e49-aead-c74fd6894981", "_uuid": "08b676c9cf966fbf117a1dc8921717a0a42b3736"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['hpg_reserve'].info()"], "metadata": {"_cell_guid": "d3db08c0-a6b3-40ac-97fd-f9745533cf72", "_uuid": "bfbf00f59ff50850033d2f553e0db5814ac81a77"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['hpg_reserve']['visit_datetime'] = pd.to_datetime(data['hpg_reserve']['visit_datetime']) #Converting date object\n", "data['hpg_reserve']['reserve_datetime'] = pd.to_datetime(data['hpg_reserve']['reserve_datetime']) #Converting date object\n", "data['hpg_reserve']['hpg_store_id'].nunique() #Unique stores in hpg reserve data"], "metadata": {"_cell_guid": "19d26de7-86e1-484c-a940-34061dfc634f", "_uuid": "6627097e27d4dacfd76000201b21fb2ea83058d9"}}, {"cell_type": "markdown", "source": ["** HPG store info **"], "metadata": {"_cell_guid": "c40cfb31-5e51-4e62-b7ff-1d5d35a08aba", "_uuid": "6dc80605eece5d2a3d1d1776bc5d3ee3a4b9ce90"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['hpg_store_info'].info()"], "metadata": {"_cell_guid": "f8d4b93f-56d9-4a81-b1c0-5c5048042717", "_uuid": "d83fe582fdfc31a35f29d383ff5c8b059be672f3"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['hpg_store_info']['hpg_store_id'].nunique() #Unique stores in hpg store info"], "metadata": {"_cell_guid": "e787d2c9-3f0b-48e8-8d16-404ae6c317e6", "_uuid": "eee215594826b8342897b8d4385ded99505c1e88"}}, {"cell_type": "markdown", "source": ["There are some missing store info between reserve and hpg info data"], "metadata": {"_cell_guid": "1bab5872-cd59-4430-8c07-a0a53335ef61", "_uuid": "6dca9aae6461b63d60a10363690c83d9aa2aa397"}}, {"cell_type": "markdown", "source": ["** Store Relation **"], "metadata": {"_cell_guid": "b81c2236-0e91-4bd0-ad73-2f4d7a75606d", "_uuid": "8f31a0d9d3facf31213fd58837a274385fa844e2"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['store_id_relation'].info()"], "metadata": {"_cell_guid": "c33e0f12-1734-4987-a3e4-9f9cfe12fb81", "_uuid": "3c2ce7e3b13040eb5042024044b7da87049bf2ac"}}, {"cell_type": "markdown", "source": ["** Submission **"], "metadata": {"_cell_guid": "f0c6e026-5394-46b5-9ce2-59666054f305", "_uuid": "7323c1de7da3e2bd1d69ecd2242937c80dab46a5"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['sample_submission'].info()"], "metadata": {"_cell_guid": "5d4efd67-315d-4df3-bf92-1992c9e81d21", "_uuid": "676310dd6930852f4df7c11459f8b86839502b64"}}, {"cell_type": "markdown", "source": ["Splitting the sample submission data to air store id and date"], "metadata": {"_cell_guid": "e9302b91-9748-4a63-ae17-cfc5c1dd88d5", "_uuid": "b7072f9143359369d325be861404bca44809ca24"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['submission_prep'] = data['sample_submission'].copy()\n", "data['submission_prep']['visit_date'] = data['submission_prep']['id'].map(lambda x: str(x).split('_')[2])\n", "data['submission_prep']['visit_date'] = pd.to_datetime(data['submission_prep']['visit_date'])\n", "data['submission_prep']['air_store_id'] = data['submission_prep']['id'].map(lambda x: '_'.join(str(x).split('_')[:2]))"], "metadata": {"collapsed": true, "_cell_guid": "5db59060-a9a5-4c6b-853f-705f7cf45243", "_uuid": "01c82a2f44170bd98cd39f440b9f979e896d0062"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['submission_prep']['air_store_id'].nunique()"], "metadata": {"_cell_guid": "0f981817-8b89-4d13-8008-e2bc7fd06c6f", "_uuid": "8b6f2e1e6252f4246d1050da25dd40e9caade3d4"}}, {"cell_type": "markdown", "source": ["# Data Preparation"], "metadata": {"_cell_guid": "d7304d5b-b76d-41be-a396-13df2e1e18ac", "_uuid": "3f60161cb07306e09d297016cefff0380c1c6669"}}, {"cell_type": "markdown", "source": ["Combining the data in both hpg reserve and air reserve"], "metadata": {"collapsed": true, "_cell_guid": "b423405e-1e4b-45f6-b614-7b30f8cb4bdb", "_uuid": "2564d556531acc97da10a0dc1ef9000d21727dac"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['air_hpg_store_info'] = pd.merge(data['store_id_relation'], data['hpg_store_info'], how=\"inner\")"], "metadata": {"collapsed": true, "_cell_guid": "052841ed-fd4d-4bfb-97ca-855e140a9614", "_uuid": "302eb3390fc5a45dde1764f95320141e9db072ba"}}, {"cell_type": "markdown", "source": ["Creating the HPG Reserve table based on store location id"], "metadata": {"_cell_guid": "89ab2f24-2e23-4f03-9dd6-51e62f861261", "_uuid": "9837ef750fc1cad7682e97b7135c9c335a75f1f1"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['hpg_air_reserve'] =pd.merge(data['store_id_relation'], data['hpg_reserve'], how=\"inner\")"], "metadata": {"collapsed": true, "_cell_guid": "02766772-d91c-4b07-96c6-17b2f71916fa", "_uuid": "e32590d77058e45d0e853caa23c43983a5d113ff"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['air_reserve_prep'] = data['air_reserve'].copy()\n", "data['air_reserve_prep']['visit_date'] = data['air_reserve_prep']['visit_datetime'].dt.date\n", "data['air_reserve_prep']['reserve_date'] = data['air_reserve_prep']['reserve_datetime'].dt.date\n", "data['air_reserve_prep'].drop(['visit_datetime', 'reserve_datetime'], axis=1, inplace=True)"], "metadata": {"collapsed": true, "_cell_guid": "e35cae8f-647c-44c3-bf81-19db13335b91", "_uuid": "120d5f2a0c6c30b4a089cf2c89f84240518a3cee"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['air_reserve_prep'] = data['air_reserve_prep'].groupby(['air_store_id', 'visit_date', 'reserve_date']).sum()\n", "data['air_reserve_prep'] = data['air_reserve_prep'].reset_index()"], "metadata": {"collapsed": true, "_cell_guid": "5e0dd721-a593-4707-b0e6-500fbf35126e", "_uuid": "518ddc06c4490ac525625e763eee80ffef57af68"}}, {"cell_type": "markdown", "source": ["HPG Reserve Data Cleaning"], "metadata": {"_cell_guid": "b9943880-06f1-4eeb-bcd0-e127dda1c9fa", "_uuid": "e63bf0995173f06dbf40c12d8c5d14244d6cddf8"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['hpg_air_reserve_prep'] = data['hpg_air_reserve'].copy()\n", "data['hpg_air_reserve_prep']['visit_date'] = data['hpg_air_reserve_prep']['visit_datetime'].dt.date\n", "data['hpg_air_reserve_prep']['reserve_date'] = data['hpg_air_reserve_prep']['reserve_datetime'].dt.date\n", "data['hpg_air_reserve_prep'].drop(['visit_datetime', 'reserve_datetime', 'hpg_store_id'], axis=1, inplace=True)\n", "data['hpg_air_reserve_prep'] = data['hpg_air_reserve_prep'].groupby(['air_store_id', 'visit_date', 'reserve_date']).sum()\n", "data['hpg_air_reserve_prep'] = data['hpg_air_reserve_prep'].reset_index()"], "metadata": {"collapsed": true, "_cell_guid": "d87cc10c-03b3-4ac8-aada-85eb4df745e7", "_uuid": "9481833dfdaee40b3eb12e1d77a90b8a39c5cd04"}}, {"cell_type": "markdown", "source": ["Air Reserve Data Cleaning and merging the hpg reserve data"], "metadata": {"_cell_guid": "92646139-668d-43b9-8bb6-79ea00fdf613", "_uuid": "c575fd8eda4a42a020f77cce044ef5a0ba0f5a04"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['air_reserve_final'] = pd.concat([data['air_reserve_prep'], data['hpg_air_reserve_prep']], axis=0) \n", "data['air_reserve_final'] = data['air_reserve_final'].groupby(['air_store_id', 'visit_date', 'reserve_date']).sum()\n", "data['air_reserve_final'] = data['air_reserve_final'].reset_index()"], "metadata": {"collapsed": true, "_cell_guid": "4d733785-a2c4-4c11-bdaf-0ac0943bae84", "_uuid": "98fe03e4f5a2136c7260e053749f71bfb8e943e6"}}, {"cell_type": "markdown", "source": ["Creating final visit data for model preparation"], "metadata": {"_cell_guid": "f518fd64-c2d9-4ae0-a649-aab891186676", "_uuid": "a97c0eaa56df229a22896b28edea8392e90d442b"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['air_reserve_final']['visit_date'] = pd.to_datetime(data['air_reserve_final']['visit_date'])\n", "data['air_reserve_final']['day_n_of_week'] = data['air_reserve_final']['visit_date'].dt.dayofweek\n", "data['air_reserve_final']['day'] = data['air_reserve_final']['visit_date'].dt.day\n", "data['air_visit_data']['visit_date'] = pd.to_datetime(data['air_visit_data']['visit_date'])"], "metadata": {"collapsed": true, "_cell_guid": "410144eb-7f01-4a89-b797-9ba7dbfed85f", "_uuid": "0d8bb50bb6acd80de90a10c204c8916552853813"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['visit_reserve_final'] = data['air_reserve_final'].drop('reserve_date', axis=1)\n", "data['visit_reserve_final'] = data['visit_reserve_final'].groupby(['air_store_id', 'visit_date']).sum()\n", "data['visit_reserve_final'] = data['visit_reserve_final'].reset_index()\n", "data['visit_final'] = pd.merge(data['visit_reserve_final'], data['air_visit_data'], how=\"right\")\n", "data['visit_final'].shape"], "metadata": {"_cell_guid": "8f594847-9feb-4b6e-9eaf-6fd9274eff21", "_uuid": "c22f1658968c8a2f4db3cde164875add41aa6fa7"}}, {"cell_type": "markdown", "source": ["Merging store info data to visit data set"], "metadata": {"_cell_guid": "5b59fcee-0789-4e74-ad48-083cebabaaf3", "_uuid": "81b2ad11e7cad082da509a37854e72d6e4557f10"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['air_store_info']['air_genre_name'] = data['air_store_info']['air_genre_name'].map(lambda x: str(str(x).replace('/',' ')))\n", "data['air_store_info']['air_area_name'] = data['air_store_info']['air_area_name'].map(lambda x: str(str(x).replace('-',' ')))"], "metadata": {"collapsed": true, "_cell_guid": "19a2e633-f84a-434b-9a0f-ef541324d1ad", "_uuid": "1dc1df5e3909a57a08c650187d82b780d6da660b"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['final_data'] = pd.merge(data['air_store_info'], data['visit_final'])\n", "data['final_data'] = pd.merge(data['final_data'], data['date_info'], how = \"left\", \n", "                              right_on ='calendar_date', left_on='visit_date') #Merge with date information\n", "\n", "#Id Change\n", "air_store_id_reshaped = data['final_data']['air_store_id'].values.reshape(-1, 1)\n", "cat_encoder = CategoricalEncoder(encoding=\"ordinal\")\n", "data['final_data']['store_id'] = cat_encoder.fit_transform(air_store_id_reshaped)\n", "\n", "#Area name split\n", "data['final_data']['region_0'] = data['final_data']['air_area_name'].map(lambda x: str(x).split(' ')[0])\n", "data['final_data']['region_1'] = data['final_data']['air_area_name'].map(lambda x: str(x).split(' ')[1])\n", "data['final_data']['region_2'] = data['final_data']['air_area_name'].map(lambda x: str(x).split(' ')[2])\n", "data['final_data']['region_3'] = data['final_data']['air_area_name'].map(lambda x: str(x).split(' ')[3])\n", "\n", "#Genre name split\n", "data['final_data']['genre_0'] = data['final_data']['air_genre_name'].map(lambda x: str(x).split(' ')[0])\n", "data['final_data']['genre_1'] = data['final_data']['air_genre_name'].map(lambda x: str(x).split(' ')[1] \n", "                                                                         if len(str(x).split(' ')) > 1 else \"\")\n", "\n", "#data['final_data'].shape\n", "data['final_data']['lat_long'] = data['final_data']['longitude'] + data['final_data']['latitude']\n", "\n", "#Adding more fields for visit date, day, month and week\n", "\n", "data['final_data']['month'] = data['final_data']['visit_date'].dt.month\n", "data['final_data']['week'] = data['final_data']['visit_date'].dt.week\n", "data['final_data']['day_n_of_week'] =  data['final_data']['visit_date'].dt.dayofweek + 1\n", "data['final_data']['year'] =  data['final_data']['visit_date'].dt.year\n", "data['final_data']['day'] =  data['final_data']['visit_date'].dt.day \n", "\n", "#mean reserve\n", "data['mean_reserve'] = data['visit_reserve_final'].groupby(['air_store_id'])[['reserve_visitors']].mean().reset_index()\n", "data['mean_reserve'].columns = ['air_store_id', 'mean_reserve_visitors']\n", "data['final_data'] = pd.merge(data['final_data'] , data['mean_reserve'], how = \"left\", right_on=\"air_store_id\", left_on=\"air_store_id\")\n", "\n", "data['mean_week_reserve'] = data['visit_reserve_final'].groupby(['air_store_id', 'day_n_of_week']).agg({'reserve_visitors' : [np.min,np.mean,np.median,np.max]}).reset_index()\n", "data['mean_week_reserve'].columns = ['air_store_id', 'day_n_of_week', 'min_wk_res_visitors', 'mean_wk_res_visitors', 'median_wk_res_visitors',\n", "                                      'max_wk_res_visitors']\n", "data['final_data'] = pd.merge(data['final_data'] , data['mean_week_reserve'], how = \"left\")\n", "\n", "data['mean_day_reserve'] = data['visit_reserve_final'].groupby(['air_store_id', 'day']).agg({'reserve_visitors' : [np.min,np.mean,np.median,np.max]}).reset_index()\n", "data['mean_day_reserve'].columns = ['air_store_id', 'day', 'min_day_res_visitors', 'mean_day_res_visitors', 'median_day_res_visitors',\n", "                                      'max_day_res_visitors']\n", "data['final_data'] = pd.merge(data['final_data'] , data['mean_day_reserve'], how = \"left\")\n", "\n", "#mean_visitors\n", "data['mean_visitors'] = data['final_data'].groupby(['air_store_id'])[['visitors']].mean().reset_index()\n", "data['mean_visitors'].columns = ['air_store_id', 'mean_visitors']\n", "data['final_data'] = pd.merge(data['final_data'] , data['mean_visitors'], how = \"left\", right_on=\"air_store_id\", left_on=\"air_store_id\")\n", "\n", "data['mean_week_visitors'] = data['final_data'].groupby(['air_store_id', 'day_n_of_week']).agg({'visitors' : [np.min,np.mean,np.median,np.max,np.size]}).reset_index()\n", "data['mean_week_visitors'].columns = ['air_store_id', 'day_n_of_week', 'min_wk_visitors', 'mean_wk_visitors', 'median_wk_visitors',\n", "                                      'max_wk_visitors','count_wk_observations']\n", "data['final_data'] = pd.merge(data['final_data'] , data['mean_week_visitors'], how = \"left\")\n", "\n", "data['mean_day_visitors'] = data['final_data'].groupby(['air_store_id', 'day']).agg({'visitors' : [np.min,np.mean,np.median,np.max,np.size]}).reset_index()\n", "data['mean_day_visitors'].columns = ['air_store_id', 'day', 'min_day_visitors', 'mean_day_visitors', 'median_day_visitors',\n", "                                      'max_day_visitors','count_day_observations']\n", "data['final_data'] = pd.merge(data['final_data'] , data['mean_day_visitors'], how = \"left\")\n", "\n", "#Adding 0 on missing values\n", "data['final_data'] = data['final_data'].fillna(0)"], "metadata": {"collapsed": true, "_cell_guid": "f0a13976-2f1c-4ba9-9c7b-b161e1e2aeb0", "_uuid": "6d7d17001f760868b0a7c2fd4bb8b35b9812fed4"}}, {"cell_type": "markdown", "source": ["Preparing the test dataset"], "metadata": {"_cell_guid": "e3fb3f31-6ec8-47bd-a448-6892c83e9700", "_uuid": "4c615c65e1705ed4fec00c52ca78f2fd346f8efc"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['test_data'] = pd.merge(data['visit_reserve_final'], data['submission_prep'], how=\"right\")\n", "data['test_data'] = pd.merge(data['test_data'], data['air_store_info'])\n", "data['test_data'] = pd.merge(data['test_data'], data['date_info'], how = \"left\", \n", "                              right_on ='calendar_date', left_on='visit_date') #Merge with date information\n", "#data['test_data'].shape\n", "\n", "#Id Change\n", "air_store_id_reshaped = data['test_data']['air_store_id'].values.reshape(-1, 1)\n", "cat_encoder = CategoricalEncoder(encoding=\"ordinal\")\n", "data['test_data']['store_id'] = cat_encoder.fit_transform(air_store_id_reshaped)\n", "\n", "#Area name split\n", "data['test_data']['region_0'] = data['test_data']['air_area_name'].map(lambda x: str(x).split(' ')[0])\n", "data['test_data']['region_1'] = data['test_data']['air_area_name'].map(lambda x: str(x).split(' ')[1])\n", "data['test_data']['region_2'] = data['test_data']['air_area_name'].map(lambda x: str(x).split(' ')[2])\n", "data['test_data']['region_3'] = data['test_data']['air_area_name'].map(lambda x: str(x).split(' ')[3])\n", "\n", "\n", "#Genre name split\n", "data['test_data']['genre_0'] = data['test_data']['air_genre_name'].map(lambda x: str(x).split(' ')[0])\n", "data['test_data']['genre_1'] = data['test_data']['air_genre_name'].map(lambda x: str(x).split(' ')[1] \n", "                                                                         if len(str(x).split(' ')) > 1 else \"\")\n", "\n", "data['test_data']['lat_long'] = data['test_data']['longitude'] + data['test_data']['latitude']\n", "\n", "\n", "#Adding more fields for visit date, day, month and week\n", "\n", "data['test_data']['month'] = data['test_data']['visit_date'].dt.month\n", "data['test_data']['week'] = data['test_data']['visit_date'].dt.week\n", "data['test_data']['day_n_of_week'] =  data['test_data']['visit_date'].dt.dayofweek + 1\n", "data['test_data']['year'] =  data['test_data']['visit_date'].dt.year\n", "data['test_data']['day'] =  data['test_data']['visit_date'].dt.day \n", "\n", "#mean reserve\n", "\n", "data['test_data'] = pd.merge(data['test_data'] , data['mean_reserve'], how = \"left\"\n", "                             , right_on=\"air_store_id\", left_on=\"air_store_id\")\n", "data['test_data'] = pd.merge(data['test_data'] , data['mean_week_reserve'], how = \"left\")\n", "data['test_data'] = pd.merge(data['test_data'] , data['mean_day_reserve'], how = \"left\")\n", "\n", "#mean_visitors\n", "data['test_data'] = pd.merge(data['test_data'] , data['mean_visitors'], how = \"left\"\n", "                             , right_on=\"air_store_id\", left_on=\"air_store_id\")\n", "data['test_data'] = pd.merge(data['test_data'] , data['mean_week_visitors'], how = \"left\")\n", "data['test_data'] = pd.merge(data['test_data'] , data['mean_day_visitors'], how = \"left\")\n", "\n", "#Adding 0 on missing values\n", "data['test_data'] = data['test_data'].fillna(0)\n", "data['test_data'] = data['test_data'].sort_values(by=['id'])"], "metadata": {"collapsed": true, "_cell_guid": "0a8d5bc7-5483-4d92-8e8c-1f8025d4a839", "_uuid": "fe33114385edf748096efc5b0905cd6af170d174"}}, {"cell_type": "markdown", "source": ["# Data Exploration"], "metadata": {"_cell_guid": "b9fac961-2578-4849-b378-9a3adc432b33", "_uuid": "a933e4e634969cd6d6f6592fd04322d0265835f7"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["#Visitors based on week days\n", "#fig, ax = plt.subplots(figsize=(10,10))\n", "sns.barplot(x=\"day_n_of_week\", y=\"visitors\", data=data['final_data'])"], "metadata": {"_cell_guid": "35884ba9-f054-48f4-8a24-abbaa12f7c48", "_uuid": "17540ffa3bbd0cad11fb2d5427b9ab3705ce3b4f"}}, {"cell_type": "markdown", "source": ["There are more visitors on Saturday followed by Sunday and Friday and Other days average is less."], "metadata": {"_cell_guid": "55c010a8-e6c1-4160-8cdc-d5c4f88b7f48", "_uuid": "f794541adb241181eff3e1c6e8a50897c16e0515"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["#Visitors each day\n", "f, ax = plt.subplots(1, 1, figsize=(15, 8))\n", "plt1 = data['final_data'].groupby(['visit_date'], as_index=False).agg({'visitors': np.sum})\n", "plt2 = data['final_data'].groupby(['visit_date'], as_index=False).agg({'reserve_visitors': np.sum})\n", "plt1 = plt1.set_index('visit_date')\n", "plt2 = plt2.set_index('visit_date')\n", "plt1.plot(color='c', kind='area', ax=ax)\n", "plt2.plot(color='r', kind='line', ax=ax)\n", "plt.ylabel(\"Sum of Visitors\")\n", "plt.title(\"Visitor and Reservations\")"], "metadata": {"_cell_guid": "23f94e67-1ae8-4ade-9145-0647af0d4762", "_uuid": "8afcf500cdd273ef8c5e6f4ea1a2db750588fbbc"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["#Visitors by Genre\n", "\n", "plt.style.use('seaborn')\n", "color = sns.color_palette()\n", "\n", "f,ax=plt.subplots(1,1, figsize=(10,8))\n", "genre=data['final_data'].groupby(['air_genre_name'],as_index=False)['visitors'].sum()\n", "genre.sort_values(by='visitors', ascending=True, inplace=True)\n", "genre['air_genre'] =[i for i,x in enumerate(genre['air_genre_name'])] \n", "genre = genre.sort_values(by='visitors', ascending=False)#.reset_index()\n", "my_range = genre['air_genre']\n", "plt.hlines(y=my_range, xmin=0, xmax=genre['visitors'], color='goldenrod',alpha=0.8) #[\u2018solid\u2019 | \u2018dashed\u2019 | \u2018dashdot\u2019 | \u2018dotted\u2019]\n", "plt.plot(genre['visitors'], my_range, \"o\",markersize=25,label='visitors',color='orangered')\n", "\n", "# Add titles and axis names\n", "plt.yticks(my_range, genre['air_genre_name'],fontsize=15)\n", "plt.title(\"Total visitors by Air Genre\", loc='center')\n", "plt.xlabel('Score')\n", "plt.ylabel('Features')"], "metadata": {"_cell_guid": "45a86cb9-532f-44e3-a2f6-358415bca594", "_uuid": "a3f061ee48eb731b13bda1da52e72a894bd81825"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["#Visitors by Region\n", "\n", "plt.style.use('seaborn')\n", "color = sns.color_palette()\n", "\n", "f,ax=plt.subplots(1,1, figsize=(10,8))\n", "genre=data['final_data'].groupby(['region_0'],as_index=False)['visitors'].sum()\n", "genre.sort_values(by='visitors', ascending=True, inplace=True)\n", "genre['region'] =[i for i,x in enumerate(genre['region_0'])] \n", "genre = genre.sort_values(by='visitors', ascending=False)#.reset_index()\n", "my_range = genre['region']\n", "plt.hlines(y=my_range, xmin=0, xmax=genre['visitors'], color='goldenrod',alpha=0.8) #[\u2018solid\u2019 | \u2018dashed\u2019 | \u2018dashdot\u2019 | \u2018dotted\u2019]\n", "plt.plot(genre['visitors'], my_range, \"o\",markersize=25,label='visitors',color='orangered')\n", "\n", "# Add titles and axis names\n", "plt.yticks(my_range, genre['region_0'],fontsize=15)\n", "plt.title(\"Region 0\", loc='center')\n", "plt.xlabel('Score')\n", "plt.ylabel('Features')"], "metadata": {"_cell_guid": "7fbeddd9-658a-44e6-acee-b68148c9f37e", "_uuid": "656b33ad9495f541429a7b71b8d942a8e1d7d29d"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["#Visitors by Region\n", "\n", "plt.style.use('seaborn')\n", "color = sns.color_palette()\n", "\n", "f,ax=plt.subplots(1,1, figsize=(10,8))\n", "genre=data['final_data'].groupby(['region_1'],as_index=False)['visitors'].sum()\n", "genre.sort_values(by='visitors', ascending=True, inplace=True)\n", "genre['region'] =[i for i,x in enumerate(genre['region_1'])] \n", "genre = genre.sort_values(by='visitors', ascending=False)#.reset_index()\n", "my_range = genre['region']\n", "plt.hlines(y=my_range, xmin=0, xmax=genre['visitors'], color='goldenrod',alpha=0.8) #[\u2018solid\u2019 | \u2018dashed\u2019 | \u2018dashdot\u2019 | \u2018dotted\u2019]\n", "plt.plot(genre['visitors'], my_range, \"o\",markersize=25,label='visitors',color='orangered')\n", "\n", "# Add titles and axis names\n", "plt.yticks(my_range, genre['region_1'],fontsize=15)\n", "plt.title(\"Region 1\", loc='center')\n", "plt.xlabel('Score')\n", "plt.ylabel('Features')"], "metadata": {"_cell_guid": "b73a79b4-2433-4fe5-b403-57267fa92aa3", "_uuid": "4a6f0dad9276103f11af733259b530b1473a22c7"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["#Visitors by Region\n", "\n", "plt.style.use('seaborn')\n", "color = sns.color_palette()\n", "\n", "f,ax=plt.subplots(1,1, figsize=(15,15))\n", "genre=data['final_data'].groupby(['region_2'],as_index=False)['visitors'].sum()\n", "genre.sort_values(by='visitors', ascending=True, inplace=True)\n", "genre['region'] =[i for i,x in enumerate(genre['region_2'])] \n", "genre = genre.sort_values(by='visitors', ascending=False)#.reset_index()\n", "my_range = genre['region']\n", "plt.hlines(y=my_range, xmin=0, xmax=genre['visitors'], color='goldenrod',alpha=0.8) #[\u2018solid\u2019 | \u2018dashed\u2019 | \u2018dashdot\u2019 | \u2018dotted\u2019]\n", "plt.plot(genre['visitors'], my_range, \"o\",markersize=25,label='visitors',color='orangered')\n", "\n", "# Add titles and axis names\n", "plt.yticks(my_range, genre['region_2'],fontsize=15)\n", "plt.title(\"Region 2\", loc='center')\n", "plt.xlabel('Score')\n", "plt.ylabel('Features')"], "metadata": {"_cell_guid": "4bc408f6-0d68-4b46-af0a-10d9697020f0", "_uuid": "dda367b5d53065ea2f274bd694e242a72c67eb17"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["plt1=data['final_data']['visitors'].value_counts().reset_index().sort_index()\n", "fig, ax = plt.subplots(figsize=(15, 6), nrows=1, ncols=2, sharex=False, sharey=False)\n", "ax[0].bar(plt1['index'] ,plt1['visitors'],color='limegreen')\n", "ax[1]= sns.boxplot(y='visitors',x='day_n_of_week', data=data['final_data'],hue='holiday_flg',palette=\"Set2\")\n", "ax[1].set_title('Number of daily visitors by day of the week')\n", "ax[0].bar(plt1['index'] ,plt1['visitors'],color='limegreen')\n", "ax[0].set_title('Frequency')\n", "ax[0].set_xlim(0,100)\n", "ax[1].set_ylim(0,80)\n", "ax[1].legend(loc=1)"], "metadata": {"_cell_guid": "a035641d-e9e5-4193-8d27-ec1117e91065", "_uuid": "544e2ddc84ae6998283bc37b775570a585256191"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["from sklearn.base import BaseEstimator, TransformerMixin\n", "\n", "# column index\n", "latitude_ix, longitude_ix = 3, 4\n", "\n", "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n", "    def fit(self, X, y=None):\n", "        return self  # nothing else to do\n", "    def transform(self, X, y=None):\n", "        lat_plus_long = X[:, latitude_ix] + X[:, longitude_ix]\n", "        return np.c_[X, lat_plus_long]\n", "    \n", "from sklearn.base import BaseEstimator, TransformerMixin\n", "\n", "# Create a class to select numerical or categorical columns \n", "# since Scikit-Learn doesn't handle DataFrames yet\n", "class DataFrameSelector(BaseEstimator, TransformerMixin):\n", "    def __init__(self, attribute_names):\n", "        self.attribute_names = attribute_names\n", "    def fit(self, X, y=None):\n", "        return self\n", "    def transform(self, X):\n", "        return X[self.attribute_names].values"], "metadata": {"collapsed": true, "_cell_guid": "be2c1067-e8df-4ece-bfbe-60b94788291e", "_uuid": "b114177f666ae6829dcd880980e6b0d88586dbc2"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['train_data'] = data['final_data'].drop('visitors', axis=1)\n", "y_train = np.log1p(data['final_data']['visitors'].copy())\n", "\n", "#num_attribs = list(data['train_data'].select_dtypes(include=[np.number]))\n", "num_attribs =  [#'latitude',\n", "                 #'longitude',\n", "                 'store_id',\n", "                 'reserve_visitors',\n", "                 'day_n_of_week',\n", "                 #'day',\n", "                 'holiday_flg',\n", "                 #'lat_long',\n", "                 'month',\n", "                 #'week',\n", "                 'year',\n", "                 #'mean_reserve_visitors',\n", "                 'min_wk_res_visitors',\n", "                 'mean_wk_res_visitors',\n", "                 'median_wk_res_visitors',\n", "                 'max_wk_res_visitors',\n", "                 #'min_day_res_visitors',\n", "                 #'mean_day_res_visitors',\n", "                 #'median_day_res_visitors',\n", "                 #'max_day_res_visitors',\n", "                 #'mean_visitors',\n", "                 'min_wk_visitors',\n", "                 'mean_wk_visitors',\n", "                 'median_wk_visitors',\n", "                 'max_wk_visitors',\n", "                 'count_wk_observations',\n", "                # 'min_day_visitors',\n", "                # 'mean_day_visitors',\n", "                # 'median_day_visitors',\n", "                # 'max_day_visitors',\n", "                # 'count_day_observations'\n", "                ]\n", "#[\"air_store_id\",\n", "ord_cat_attribs =  [\"air_store_id\"]\n", "                   #\"genre_0\",\n", "                   #\"genre_1\",\n", "                   #\"region_0\",\n", "                   #\"region_1\",\n", "                   #\"region_2\",\n", "                   #\"region_3\"]\n", "\n", "onehot_cat_attribs =  [\"genre_0\",\n", "                   \"genre_1\",\n", "                   \"region_0\",\n", "                   \"region_1\",\n", "                   \"region_2\",\n", "                   \"region_3\"]\n", "\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.preprocessing import StandardScaler, Imputer\n", "\n", "ord_cat_pipeline = Pipeline([\n", "        ('selector', DataFrameSelector(ord_cat_attribs)),\n", "        ('ord_encoder', CategoricalEncoder(encoding=\"ordinal\")),\n", "        ('std_scaler', StandardScaler()),\n", "    ])\n", "\n", "onehot_cat_pipeline = Pipeline([\n", "        ('selector', DataFrameSelector(onehot_cat_attribs)),\n", "        ('onehot_encoder', CategoricalEncoder(encoding=\"onehot-dense\")),\n", "        #('std_scaler', StandardScaler()),\n", "    ])\n", "num_pipeline = Pipeline([\n", "        ('selector', DataFrameSelector(num_attribs)),\n", "        ('imputer', Imputer(strategy=\"mean\")),\n", "        #('attribs_adder', CombinedAttributesAdder()),\n", "        ('std_scaler', StandardScaler()),\n", "    ])"], "metadata": {"collapsed": true, "_cell_guid": "f885a790-0ba7-4e7b-bdb7-094078a8e689", "_uuid": "46102c02bd994f67b18ee589e1a8b34289d2bb28"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["from sklearn.pipeline import FeatureUnion\n", "\n", "full_pipeline = FeatureUnion(transformer_list=[\n", "        #(\"ord_cat_pipeline\", ord_cat_pipeline),\n", "        (\"onehot_cat_pipeline\", onehot_cat_pipeline),\n", "        (\"num_pipeline\", num_pipeline),\n", "    ])\n", "\n", "X_train = full_pipeline.fit_transform(data[\"train_data\"])\n", "\n", "from sklearn.pipeline import FeatureUnion\n", "\n", "full_pipeline = FeatureUnion(transformer_list=[\n", "        #(\"ord_cat_pipeline\", ord_cat_pipeline),\n", "        (\"onehot_cat_pipeline\", onehot_cat_pipeline),\n", "        (\"num_pipeline\", num_pipeline),\n", "    ])\n", "\n", "X_test = full_pipeline.fit_transform(data[\"test_data\"])"], "metadata": {"collapsed": true, "_cell_guid": "cb65834d-927e-4d24-a82d-eeb49dd5f4ca", "_uuid": "47c6999c95c09251d7bcfff76af3bac747925bbe"}}, {"cell_type": "markdown", "source": ["# Select and Train a model"], "metadata": {"_cell_guid": "e05d4c6b-1366-4119-ad27-7f2c89a24a0a", "_uuid": "9dd6b919449144260e91fca83c9412a287bc0e68"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression\n", "\n", "lin_reg = LinearRegression()\n", "lin_reg.fit(X_train, y_train)"], "metadata": {"_cell_guid": "0b981f6b-4888-4640-8a4f-0de441825b13", "_uuid": "e2c6bd8e5a0d9aed6007a1a28035fa332f86cb64"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["from sklearn.metrics import mean_squared_error\n", "\n", "recruit_predictions = lin_reg.predict(X_train)\n", "lin_mse = mean_squared_error(y_train, recruit_predictions)\n", "lin_rmse = np.sqrt(lin_mse)\n", "lin_rmse"], "metadata": {"_cell_guid": "d63644f5-20a5-46f5-98f2-146e6cbc502e", "_uuid": "bea38ab8a8b637053e7ebe621dd9661916c74d62"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["Y_test_pred = np.expm1(lin_reg.predict(X_test))\n", "test_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \"visitors\": Y_test_pred})\n", "#test_submission.head()\n", "test_submission.to_csv(\"test_submission.csv\", index=False)"], "metadata": {"collapsed": true, "_cell_guid": "063b88f0-6960-4cd0-83dc-3bb5d528ebfe", "_uuid": "e70a83a69b323a5b76a81dc8fc35a9448d8fda0b"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["test_submission.head()"], "metadata": {"_cell_guid": "b59222c2-0fa0-4534-a345-c34b04a9ffca", "_uuid": "69c0475162bd78c0286e80dcdba036ec1f460490"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["from sklearn.metrics import mean_squared_error\n", "from sklearn.linear_model import LinearRegression\n", "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n", "from sklearn.svm import SVR\n", "from sklearn.linear_model import SGDRegressor\n", "from sklearn.neighbors import KNeighborsRegressor\n", "from sklearn.tree import DecisionTreeRegressor\n", "\n", "regressors = [\n", "    LinearRegression(),\n", "    RandomForestRegressor(random_state=42),\n", "    GradientBoostingRegressor(learning_rate=0.2, random_state=42),\n", "    KNeighborsRegressor(n_neighbors=4, n_jobs=-1),\n", "    #SGDRegressor(penalty=None, eta0=0.1),\n", "    DecisionTreeRegressor(max_depth= 10, random_state=42)\n", "]\n", "\n", "log_cols = ['Regressor', 'rmse']\n", "log = pd.DataFrame(columns=log_cols)\n", "\n", "rmse_dict = {}\n", "\n", "for reg in regressors:\n", "    name = reg.__class__.__name__\n", "    reg.fit(X_train, y_train)\n", "    predictions = reg.predict(X_train)\n", "    mse = mean_squared_error(y_train, predictions)\n", "    rmse = np.sqrt(mse)\n", "    print(rmse)\n", "    if name in rmse_dict:\n", "        rmse_dict[name] += rmse\n", "    else:\n", "         rmse_dict[name] = rmse\n", "\n", "for reg in rmse_dict:\n", "    log_entry = pd.DataFrame([[reg, rmse_dict[reg]]], columns=log_cols)\n", "    log = log.append(log_entry)\n", "    \n", "plt.xlabel('Root Mean Square Error')\n", "plt.title('RMSE')\n", "\n", "#sns.set_color_codes(\"muted\")\n", "sns.barplot(x='rmse', y='Regressor', data=log, color=\"lightgreen\")"], "metadata": {"_cell_guid": "fc8ee3fb-015a-4aa5-ada8-2c1e0017d693", "_uuid": "5030fcfe106da7f167a2a171c2a0774d78ff9f8c"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["def display_scores(scores):\n", "    print(\"Scores:\", scores)\n", "    print(\"Mean:\", scores.mean())\n", "    print(\"Standard deviation:\", scores.std())"], "metadata": {"collapsed": true, "_cell_guid": "813066e1-26a4-4fcf-897d-04a9f69ee0cc", "_uuid": "967b98a712f45607ab5276e6191a3c7eac562eee"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["from sklearn.model_selection import cross_val_score\n", "\n", "lin_scores = cross_val_score(lin_reg, X_train, y_train,\n", "                             scoring=\"neg_mean_squared_error\", cv=5)\n", "lin_rmse_scores = np.sqrt(-lin_scores)\n", "display_scores(lin_rmse_scores)"], "metadata": {"_cell_guid": "46e6f9ce-7c48-4d41-ba51-7ed11745abe5", "_uuid": "0987c922623804bf467449fe2915e42d22e2eafa"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["from sklearn.ensemble import RandomForestRegressor\n", "\n", "forest_reg = RandomForestRegressor(random_state=42)\n", "forest_reg.fit(X_train, y_train)\n", "\n", "forest_predictions = forest_reg.predict(X_train)\n", "forest_mse = mean_squared_error(y_train, forest_predictions)\n", "forest_rmse = np.sqrt(forest_mse)\n", "forest_rmse"], "metadata": {"_cell_guid": "763add3b-e2ab-46b0-8eae-d8346e055b33", "_uuid": "fdc365985bf0dbd9f44c6121d4a005baf25f238b"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["Y_forest_test_pred = np.expm1(forest_reg.predict(X_test))\n", "test_forest_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \n", "                                       \"visitors\": Y_forest_test_pred})\n", "#test_submission.head()\n", "test_forest_submission.to_csv(\"test_forest_submission.csv\", index=False)"], "metadata": {"collapsed": true, "_cell_guid": "8d9d2e1f-39e4-439a-8bc4-eeb356a4f1f8", "_uuid": "96bbdf2db01bf0fd00e77cad01be6aeee8b76a5d"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["test_forest_submission.head()"], "metadata": {"_cell_guid": "4c93b649-76fa-4eff-8629-8ba5a4fb5ba6", "_uuid": "d3e90f9365d266c037478531e23713db7790f86c"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["#from sklearn.model_selection import cross_val_score\n", "\n", "'''forest_scores = cross_val_score(forest_reg, X_train, y_train,\n", "                             scoring=\"neg_mean_squared_error\", cv=5)\n", "forest_rmse_scores = np.sqrt(-forest_scores)\n", "display_scores(forest_rmse_scores)'''"], "metadata": {"_cell_guid": "a8279df4-a268-4ad2-b705-b2fb1352f884", "_uuid": "8c8de7c3225c57c7f054a912140d5a9e965f5397"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["from sklearn.ensemble import GradientBoostingRegressor\n", "\n", "gbr_reg = GradientBoostingRegressor(learning_rate=0.2, random_state=42)\n", "gbr_reg.fit(X_train, y_train)\n", "\n", "gbr_predictions = gbr_reg.predict(X_train)\n", "gbr_mse = mean_squared_error(y_train, gbr_predictions)\n", "gbr_rmse = np.sqrt(gbr_mse)\n", "gbr_rmse"], "metadata": {"_cell_guid": "fc15a2d9-02b1-41dc-9376-f8136757b276", "_uuid": "07e37a26b82e041929b5867c7629beae0e701681"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["Y_gbr_test_pred = np.expm1(gbr_reg.predict(X_test))#.clip(lower=0.)\n", "test_gbr_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \n", "                                       \"visitors\": Y_gbr_test_pred})\n", "#test_submission.head()\n", "test_gbr_submission.to_csv(\"test_gbr_submission.csv\", index=False)"], "metadata": {"collapsed": true, "_cell_guid": "bc764c96-a202-4c32-8447-49c9536105c1", "_uuid": "57d289a1769d9b475d56021ae112c8eaa29ad526"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["'''from sklearn.model_selection import RandomizedSearchCV\n", "from sklearn.ensemble import GradientBoostingRegressor\n", "from scipy.stats import randint\n", "\n", "param_distribs = {\n", "        'n_estimators': randint(low=20, high=200),\n", "        'max_features': randint(low=10, high=23),\n", "        'max_depth': randint(low=5, high=20),\n", "        'learning_rate': [0.1, 0.2, 0.3, 0.4]\n", "    }\n", "\n", "gbr_reg = GradientBoostingRegressor(random_state=42, subsample=0.8)\n", "gbr_search = RandomizedSearchCV(gbr_reg, param_distributions=param_distribs,\n", "                                n_iter=5, cv=5, scoring='neg_mean_squared_error', random_state=42, verbose=10, n_jobs=-1)\n", "gbr_search.fit(X_train, y_train)'''"], "metadata": {"_cell_guid": "be588e07-f4fe-4b2d-b49f-e72812f9301d", "_uuid": "7814529cf09c60ed09e6bcda32c21391f9cdfce3"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["'''gbr_search.best_score_\n", "gbr_rmse = np.sqrt(-gbr_search.best_score_)\n", "gbr_rmse'''"], "metadata": {"_cell_guid": "d35d1309-039f-4691-a110-bb0b2a70ae07", "_uuid": "5eb89ddfd29fe9b216b3a0f3e8453d7d89ec3348"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["'''gbr_best_model = gbr_search.best_estimator_\n", "\n", "Y_gbr_test_pred = np.expm1(gbr_best_model.predict(X_test))\n", "test_gbr_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \n", "                                       \"visitors\": Y_gbr_test_pred})\n", "#test_submission.head()\n", "test_gbr_submission.to_csv(\"test_gbr_submission.csv\", index=False)'''"], "metadata": {"_cell_guid": "790d08c7-64f3-44e0-ab06-f7313baa7c64", "_uuid": "38f88c7f3dc0d56ad97f0be154fcdb056b46e8e5"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["'''gbr_scores = cross_val_score(gbr_reg, X_train, y_train,\n", "                             scoring=\"neg_mean_squared_error\", cv=5)\n", "gbr_rmse_scores = np.sqrt(-gbr_scores)\n", "display_scores(gbr_rmse_scores)'''"], "metadata": {"_cell_guid": "3b44c36a-da9a-41de-afe8-aa356bd82367", "_uuid": "e4f1acc9e0b6e8b4e215c44cbe234c903ed83917"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["from sklearn.linear_model import ElasticNet\n", "\n", "elastic_net = ElasticNet(alpha=0.01, l1_ratio=0.01, random_state=42)\n", "elastic_net.fit(X_train, y_train)\n", "elastic_net_predictions = elastic_net.predict(X_train)\n", "elastic_net_mse = mean_squared_error(y_train, elastic_net_predictions)\n", "elastic_net_rmse = np.sqrt(elastic_net_mse)\n", "elastic_net_rmse"], "metadata": {"_cell_guid": "b67b86c1-bffa-49f8-91df-beebc0e0c744", "_uuid": "250f89a8fd0c49a27f1728d2b790fc4250eb6040"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["'''eln_scores = cross_val_score(elastic_net, X_train, y_train,\n", "                             scoring=\"neg_mean_squared_error\", cv=5)\n", "eln_rmse_scores = np.sqrt(-eln_scores)\n", "display_scores(eln_rmse_scores)'''"], "metadata": {"_cell_guid": "d7c6fcd1-4834-4743-be09-8dd52a61f3ed", "_uuid": "f83e3b0fbca4b4b0af79fb1ff0133e1c888fcbe3"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["Y_eln_test_pred = np.expm1(elastic_net.predict(X_test))\n", "test_eln_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \n", "                                       \"visitors\": Y_eln_test_pred})\n", "#test_submission.head()\n", "test_eln_submission.to_csv(\"test_eln_submission.csv\", index=False)"], "metadata": {"collapsed": true, "_cell_guid": "2f6b3e65-3e88-4b15-b943-50c564d9f25e", "_uuid": "f55c5f5b856863f967ad905b30b193a67bc1077f"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["knn_reg = KNeighborsRegressor(n_neighbors=4, n_jobs=-1)\n", "knn_reg.fit(X_train, y_train)\n", "\n", "knn_predictions = knn_reg.predict(X_train)\n", "knn_mse = mean_squared_error(y_train, knn_predictions)\n", "knn_rmse = np.sqrt(knn_mse)\n", "knn_rmse"], "metadata": {"_cell_guid": "13a510a3-2fd1-411e-94a7-5e5834d6ae69", "_uuid": "b6cd8f3dce4aed4f2792703b6412530e496820c9"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["knn_reg = KNeighborsRegressor(n_neighbors=4, n_jobs=-1)\n", "knn_reg.fit(X_train, y_train)\n", "\n", "'''knn_scores = cross_val_score(knn_reg, X_train, y_train,\n", "                             scoring=\"neg_mean_squared_error\", cv=5)\n", "knn_rmse_scores = np.sqrt(-knn_scores)\n", "display_scores(knn_rmse_scores)'''"], "metadata": {"_cell_guid": "a9e9e58b-ce68-4edf-9ce2-83c8474b0650", "_uuid": "375e1a73720bbf21547a1bf805ebe22adbbb86af"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["Y_knn_test_pred = np.expm1(knn_reg.predict(X_test))\n", "test_knn_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \n", "                                       \"visitors\": Y_knn_test_pred})\n", "#test_submission.head                                             \n", "test_knn_submission.to_csv(\"test_knn_submission.csv\", index=False)"], "metadata": {"collapsed": true, "_cell_guid": "4c28ea8f-f85e-490e-abd9-deb9eb251387", "_uuid": "0430e3dd1430782afec9d93e0a0313b1901055d4"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["from sklearn.model_selection import RandomizedSearchCV\n", "from sklearn.tree import DecisionTreeRegressor\n", "from scipy.stats import randint\n", "\n", "\n", "param_distribs = {\n", "        'max_depth': randint(low=4, high=100),\n", "        'max_features': randint(low=1, high=23)\n", "    }\n", "\n", "dec_reg = DecisionTreeRegressor(criterion='mse', min_samples_split=4,random_state=42, presort=False)\n", "dec_search = RandomizedSearchCV(dec_reg, param_distributions=param_distribs,\n", "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42, verbose=3)\n", "dec_search.fit(X_train, y_train)"], "metadata": {"_cell_guid": "ab5eb6e7-3e95-4fac-b64a-143e85ba3b31", "_uuid": "355ed710e8e7a7db94e38809f6d03e1d13133345"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["dec_search.best_score_\n", "rmse = np.sqrt(-dec_search.best_score_)\n", "rmse"], "metadata": {"_cell_guid": "6f78e787-3897-4b63-8dde-ce7583d087da", "_uuid": "fb065a10c9e1175f85e63f5223ca38d9cc2fee6c"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["dec_search.best_params_"], "metadata": {"_cell_guid": "c050c8ef-c28c-4c1a-b87d-d8568e2734ea", "_uuid": "866212b1f543f5217b1a00885a3ce30036824cab"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["dec_best_model = dec_search.best_estimator_\n", "\n", "Y_dec_test_pred = np.expm1(dec_best_model.predict(X_test))\n", "test_dec_submission = pd.DataFrame({\"id\": data[\"test_data\"][\"id\"], \n", "                                       \"visitors\": Y_dec_test_pred})\n", "#test_submission.head()\n", "test_dec_submission.to_csv(\"test_dec_submission.csv\", index=False)"], "metadata": {"collapsed": true, "_cell_guid": "77858056-a791-4233-8c21-8fd27c4a4c19", "_uuid": "c151be74014c6d7b8806fc2d2b3d7f03e85b4025"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["avg_visit = data['final_data'].groupby(['air_store_id', 'day_n_of_week'])[['visitors']].mean().reset_index()\n", "dummy = data['submission_prep'].copy()\n", "dummy.drop('visitors', axis=1, inplace=True)\n", "dummy['day_n_of_week'] = dummy['visit_date'].dt.dayofweek + 1\n", "avg_visitors = pd.merge(dummy, avg_visit, how=\"left\")\n", "avg_visitors = avg_visitors[['id', 'visitors']]\n", "avg_visitors = avg_visitors.fillna(1)"], "metadata": {"_cell_guid": "d99c18df-53a1-4556-8bba-665500826e96", "_uuid": "37b04ba8b9000b20160043580214975530d94097"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["data['test_data']['visitors'] = (dec_best_model.predict(X_test) + np.array(np.log1p(avg_visitors['visitors']))) / 2\n", "data['test_data']['visitors'] = np.expm1(data['test_data']['visitors']).clip(lower=0)\n", "recruit_predictions = data['test_data'][['id', 'visitors']]\n", "recruit_predictions.to_csv(\"recruit_predictions.csv\", index=False)"], "metadata": {"collapsed": true, "_cell_guid": "54585741-86eb-49ec-bc03-cb96d23edf78", "_uuid": "b71f1b5f04a771b3347424af777c04ef8c8ae098"}}], "nbformat": 4, "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"mimetype": "text/x-python", "file_extension": ".py", "pygments_lexer": "ipython3", "version": "3.6.3", "name": "python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}}}, "nbformat_minor": 1}