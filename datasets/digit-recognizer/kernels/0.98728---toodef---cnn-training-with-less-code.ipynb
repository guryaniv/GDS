{"cells":[{"metadata":{"trusted":true,"_uuid":"2ce744a96fecee9f2187dbb967995e033e13c586","_kg_hide-output":true},"cell_type":"code","source":"!pip install neural-pipeline==0.1.0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nfrom neural_pipeline import DataProducer, AbstractDataset, TrainConfig, TrainStage,\\\n    ValidationStage, Trainer, FileStructManager, Predictor\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\n\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b27698919a2bb8a57f96d599d1183c032fa0d9f1"},"cell_type":"code","source":"def read_data(path: str, with_labels: bool = True) -> []:\n    content  = np.genfromtxt(path, delimiter=',')[1:]\n    data = content.astype(np.float32)\n    \n    if not with_labels:\n        return data.reshape((data.shape[0], 28, 28))\n    else:\n        data = data[:, 1:]\n        data = data.reshape((data.shape[0], 28, 28))\n    \n    labels = content[:, 0].astype(np.long)\n    return data, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34735224734b1fa83a7940c0d878efc970348a46"},"cell_type":"code","source":"data, labels = read_data('../input/train.csv')\ndata_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n        self.fc2 = nn.Linear(500, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = x.view(-1, 4 * 4 * 50)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\ntransformations = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n\nclass MNISTDataset(AbstractDataset):\n    def __init__(self, data: np.ndarray, labels: np.ndarray = None):\n        self._data = data\n        self._labels = labels\n\n    def __len__(self):\n        return len(self._data)\n\n    def __getitem__(self, item):\n        data = transformations(np.expand_dims(self._data[item], axis=2))\n        if self._labels is None:\n            return data\n        return {'data': data, 'target': self._labels[item]}\n\ntrain_dataset = DataProducer([MNISTDataset(data_train, labels_train)], batch_size=8, num_workers=8)\nvalidation_dataset = DataProducer([MNISTDataset(data_test, labels_test)], batch_size=8, num_workers=8)\n\nmodel = Net()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa08929711300599c7533bac53c15ee7b7bd2deb","_kg_hide-output":false},"cell_type":"code","source":"%matplotlib inline\nfrom neural_pipeline.builtin.monitors.mpl import MPLMonitor\nfsm = FileStructManager(base_dir='data', is_continue=False, exists_ok=True)\n\ntrain_stage = TrainStage(train_dataset)\ntrain_stage.enable_hard_negative_mining(0.1)\ntrain_config = TrainConfig([train_stage, ValidationStage(validation_dataset)], torch.nn.NLLLoss(),\n                           torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.5))\n\ntrainer = Trainer(model, train_config, fsm, torch.device('cuda:0')).set_epoch_num(30)\nmpl_monitor = MPLMonitor()\nmpl_monitor.realtime(False)\ntrainer.monitor_hub.add_monitor(mpl_monitor)\ntrainer.enable_lr_decaying(coeff=0.5, patience=4, target_val_clbk=lambda: np.mean(train_stage.get_losses()))\ntrainer.train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e997c0ec078117f15268f9ee4159e574399189ce"},"cell_type":"code","source":"test_data = read_data('../input/test.csv', with_labels=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff255acacb9eb65bd8b74b92a5b5d5ee89b4cc2c"},"cell_type":"code","source":"fsm = FileStructManager(base_dir='data', is_continue=True)\npredictor = Predictor(model, fsm, device=torch.device('cuda:0'))\n\ndataset = MNISTDataset(test_data)\n\nwith open('submission.csv', 'w') as out:\n    out.write('ImageId,Label\\n')\n    for i, data in enumerate(dataset):\n        res = predictor.predict({\"data\": data.unsqueeze(0)})\n        res = res.cpu().numpy()\n        out.write('{},{}\\n'.format(i + 1, int(np.argmax(res))))\n\nprint('Predict cancel. Predicted', i + 1, 'images')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}