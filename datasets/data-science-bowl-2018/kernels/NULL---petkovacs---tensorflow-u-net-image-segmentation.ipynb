{"cells": [{"source": ["# Data Science Bowl Competition - Kaggle 2018"], "metadata": {"_uuid": "95d6afa39351e98be3936556308332159a7bb3de", "_cell_guid": "c0aec281-7c77-47a3-93a4-fa9fd60d769b"}, "cell_type": "markdown"}, {"source": ["import os\n", "import pandas as pd\n", "import numpy as np\n", "import scipy.misc\n", "import tensorflow as tf\n", "import time\n", "from matplotlib.pyplot import imshow\n", "from PIL import Image\n", "from skimage.transform import resize\n", "%matplotlib inline\n", "\n", "import matplotlib.pyplot as plt\n", "import gc\n", "\n", "class Util(object):\n", "    \n", "    @staticmethod\n", "    def read_images(root):\n", "        \"\"\"\n", "        Read in training images\n", "\n", "        Args:\n", "            relative path\n", "\n", "        Returns\n", "            train_X: dictionary of image_name -> image\n", "        \"\"\"\n", "\n", "        train_X = {}\n", "        for sub_item_name in os.listdir(root):\n", "            img_root = root + \"/\" + sub_item_name\n", "            if os.path.isdir(img_root):\n", "                fileName = img_root + \"/images/\" + sub_item_name + \".png\"\n", "                image = scipy.misc.imread(fileName)\n", "                train_X[sub_item_name] = image\n", "        return train_X\n", "    \n", "    def show_image(image):\n", "        resh = np.reshape(image,(image.shape[0],image.shape[1]))\n", "        tout = (np.array(resh) > 0.4).astype(np.uint8)\n", "        imshow(Image.fromarray(tout))\n", "    \n", "    \n", "    def normalize_images(raw_images, height, width, channels):\n", "        \"\"\"\n", "        Resize images to the given dimension\n", "\n", "        Args:\n", "            raw_images: dictiomary of image_name ->image\n", "            height: height of the resized images\n", "            width: width of the resized images\n", "            channels: number of channels in the resized image\n", "\n", "        Returns\n", "            List of resized images\n", "        \"\"\"\n", "        resized = []\n", "        keys = np.sort(list(raw_images.keys()))\n", "        for key in keys:\n", "            resized.append(resize(raw_images[key], (height, width, channels), mode='constant'))\n", "        return np.array(resized)\n", "    \n", "    \n", "    def convert_to_binary_image(image):\n", "        mean = (np.max(image) + np.min(image)) / 2.0\n", "        return image > mean\n", "    \n", "    def show_binary_image(image):\n", "        \"\"\"\n", "        Display image\n", "        \"\"\"\n", "        assert image.shape[2] == 1, \"image should have shape(,,1)\"\n", "        test_mask = image.astype(np.uint8)\n", "        imshow(test_mask.squeeze(), cmap=\"gray_r\")\n", "    \n", "    def decode_run_length(array, encoding):\n", "        \"\"\"\n", "        Decode run length encoding to the given array\n", "\n", "        Args:\n", "            encoding - strinng run length encoding pairs\n", "            array - array to encode to\n", "\n", "        \"\"\"\n", "        encoding_list = encoding.split(\" \")\n", "        assert len(encoding_list) % 2 ==0, \"Error in encoding\"\n", "        for i in range(0,len(encoding_list),2):\n", "            start_index = int(encoding_list[i])-1\n", "            length = int(encoding_list[i+1]) \n", "            array[start_index:start_index+length] = [1] * length\n", "\n", "\n", "    def map_run_length_encoding_to_images(run_length_encodings,data_X):\n", "        \"\"\"\n", "        Maps dictionary of run length encodings to images\n", "        \n", "        Args:\n", "            run_length_encodings: List of run_length_encodings\n", "                 ImageId - correspongind input image in  data_X\n", "                 EncodedPixels - string of pixel encoding pairs\n", "            data_X: originial images from which run length encoding was generated\n", "        Returns\n", "            Dictionary of decoded run length encodings \n", "        \"\"\"\n", "        train_Y_orig = {}\n", "        for index,row in run_length_encodings.iterrows(): \n", "            imageName = row['ImageId']\n", "            encodedPixels = row['EncodedPixels']\n", "            if(imageName not in train_Y_orig):\n", "                w, h, channels = data_X[imageName].shape\n", "                length = w * h\n", "                mask = [0] * length\n", "                train_Y_orig[imageName] = mask\n", "\n", "            Util.decode_run_length(train_Y_orig[imageName],encodedPixels)\n", "\n", "        for key in train_Y_orig.keys():\n", "            w, h, c = data_X[key].shape\n", "            train_Y_orig[key] = np.reshape(train_Y_orig[key],(w,h,1),order='F')\n", "        return train_Y_orig\n", "\n", "class Config(object):\n", "    # Model input image format\n", "    channels = 3\n", "    width = 256\n", "    height = 256\n", "    #batch format\n", "    batch_size = 50\n", "    \n", "    def __init__(self, batch_size):\n", "        self.batch_size = batch_size"], "metadata": {"_uuid": "18a45ce12e9b1a12bf899db85be280273924e4f5", "_cell_guid": "10a78a0f-a59e-4169-bf98-9f3b4bf80658", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["##### Config Parameters"], "metadata": {"_uuid": "7c0bdc12f29a96d52606c472f1ca0f7f51fe46d1", "_cell_guid": "0782dbc2-524a-4cd4-a7c2-4455b4bcf3df"}, "cell_type": "markdown"}, {"source": ["config = Config(batch_size=16)"], "metadata": {"_uuid": "dfafd6db59a371baf984ea113bb3d264043e20d6", "_cell_guid": "e1b72987-1808-4ae4-a372-4a04dae4f6ff", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["##### Import and reshape input data"], "metadata": {"_uuid": "b9b14a615b1956aeaacd982ee12a37b0809f9951", "_cell_guid": "57aca2b0-f353-4468-ac9d-047b170fb414"}, "cell_type": "markdown"}, {"source": ["train_X_orig = Util.read_images(\"../input/stage1_train\")"], "metadata": {"_uuid": "561066ef65df39f8bbe0f79d91cef088384e9c59", "_cell_guid": "e2b9273a-03b1-4770-bb2f-b4b56953db7a", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["train_X = np.array(Util.normalize_images(train_X_orig, config.width, config.height, config.channels))"], "metadata": {"_uuid": "cc60361a2d67d35b58bfc8aba7f8f72a50eaee3d", "_cell_guid": "d7b95bf3-03c5-4103-9135-95a0aa0d693e", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["##### Import predict set"], "metadata": {"_uuid": "979d0c15a946a4ac1abccc3e146cebfd5a845faa", "_cell_guid": "0ab3a960-8a27-40d2-a922-bcc878072a02"}, "cell_type": "markdown"}, {"source": ["pred_X_orig = Util.read_images(\"../input/stage1_test\")\n", "pred_X = np.array(Util.normalize_images(pred_X_orig, config.width, config.height, config.channels))"], "metadata": {"_uuid": "bd6e6443ebab8bc9fcbca316a36a3861499538cc", "_cell_guid": "3513cd7b-f012-4709-88e2-64d516ab2426", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["##### Import and decoding run length "], "metadata": {"_uuid": "6cbbc65753bb92594f79bfe0a1355e65b4aed0b7", "_cell_guid": "a21aef23-364d-4ab6-a691-39fb9a849c57"}, "cell_type": "markdown"}, {"source": ["train_Y_orig = Util.map_run_length_encoding_to_images(pd.read_csv(\"../input/stage1_train_labels.csv\"),train_X_orig)"], "metadata": {"_uuid": "48ea68a768f3c1017d6351f0da8e77fb33f762a4", "_cell_guid": "e9beb575-25c9-4455-af67-dd1a93194fb8", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["train_Y = Util.normalize_images(train_Y_orig, config.width, config.height, 1)"], "metadata": {"_uuid": "7deb834bcd87f3b7d0599fcb8e85eb994e012d7c", "_cell_guid": "300039ea-88ec-4713-842c-8eee2fed387d", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["train_Y = [Util.convert_to_binary_image(image) for image in train_Y]"], "metadata": {"_uuid": "70e2ce75f0e5c5522e8a3f1e62c87d4016ad32f5", "_cell_guid": "231511ce-5c35-4deb-af57-ee4982ffc75d", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["t = train_X[0]\n", "print(t.shape)\n", "imshow(t.squeeze())"], "metadata": {"_uuid": "67826e98c93676fc26d0442178c203137d732928", "_cell_guid": "9e85d9ab-0623-4016-a7ea-e9f93648b3ce", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["t = train_Y[0]\n", "print(t.shape)\n", "imshow(t.squeeze())"], "metadata": {"_uuid": "67a2c7ac68730c224907a3b0b3b55a8b106abf29", "_cell_guid": "0f88e574-7d51-4d29-91bd-5f8bd52f946c", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["tf.reset_default_graph()"], "metadata": {"_uuid": "80d32a6e525099a06db54a0b8ca3fa6dad14e51d", "_cell_guid": "745218b2-b812-45d9-aa92-0b06c1bf7c63", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["##### Create input placeholder"], "metadata": {"_uuid": "2d3835203aa1928b63cdf465aac8957e512a4398", "_cell_guid": "a12c0f47-e2db-45e5-8423-7d4b9425aef1"}, "cell_type": "markdown"}, {"source": ["#Only the channel size is known\n", "X = tf.placeholder(tf.float32, shape = (None,None,None,config.channels))"], "metadata": {"_uuid": "d139d41eb6e5c9d767d440c8a949f2b0d6d9c83c", "_cell_guid": "f7be9668-ff89-4a69-839d-1102b88e9e1f", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["Y = tf.placeholder(tf.float32, shape = (None,None,None,1))"], "metadata": {"_uuid": "0f356e6edcbbda70c73eedefc10e4a9096596962", "_cell_guid": "f2198e68-6a6b-4b89-bd1b-3318340eab3c", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["##### Create model"], "metadata": {"_uuid": "d40dacec83a28354f2bbfd5232f9d69105a35e7f", "_cell_guid": "fe7dcff3-c341-43e4-bf90-d82184e1990c"}, "cell_type": "markdown"}, {"source": ["def forward_propagation(X):\n", "\n", "    \n", "    CONV_1_1 = tf.get_variable(\"CONV_1_1\",[3,3,config.channels,16], initializer = tf.contrib.layers.xavier_initializer());\n", "    CONV_1_2 = tf.get_variable(\"CONV_1_2\",[3,3,16,16], initializer = tf.contrib.layers.xavier_initializer());\n", "     \n", "    CONV_2_1 = tf.get_variable(\"CONV_2_1\",[3,3,16,32], initializer = tf.contrib.layers.xavier_initializer());\n", "    CONV_2_2 = tf.get_variable(\"CONV_2_2\",[3,3,32,32], initializer = tf.contrib.layers.xavier_initializer());\n", "    \n", "    CONV_3_1 = tf.get_variable(\"CONV_3_1\",[3,3,32,64], initializer = tf.contrib.layers.xavier_initializer());\n", "    CONV_3_2 = tf.get_variable(\"CONV_3_2\",[3,3,64,64], initializer = tf.contrib.layers.xavier_initializer());\n", "    \n", "    CONV_4_1 = tf.get_variable(\"CONV_4_1\",[3,3,64,128], initializer = tf.contrib.layers.xavier_initializer());\n", "    CONV_4_2 = tf.get_variable(\"CONV_4_2\",[3,3,128,128], initializer = tf.contrib.layers.xavier_initializer());\n", "    \n", "    CONV_5_1 = tf.get_variable(\"CONV_5_1\",[3,3,128,256], initializer = tf.contrib.layers.xavier_initializer());\n", "    CONV_5_2 = tf.get_variable(\"CONV_5_2\",[3,3,256,256], initializer = tf.contrib.layers.xavier_initializer());\n", "    \n", "    CONV_6_1 = tf.get_variable(\"CONV_6_1\",[2,2,128,256], initializer = tf.contrib.layers.xavier_initializer());\n", "    CONV_6_2 = tf.get_variable(\"CONV_6_2\",[3,3,256,128], initializer = tf.contrib.layers.xavier_initializer());\n", "    CONV_6_3 = tf.get_variable(\"CONV_6_3\",[3,3,128,128], initializer = tf.contrib.layers.xavier_initializer());\n", "    \n", "    CONV_7_1 = tf.get_variable(\"CONV_7_1\",[2,2,64,128], initializer = tf.contrib.layers.xavier_initializer());\n", "    CONV_7_2 = tf.get_variable(\"CONV_7_2\",[3,3,128,64], initializer = tf.contrib.layers.xavier_initializer());\n", "    CONV_7_3 = tf.get_variable(\"CONV_7_3\",[3,3,64,64], initializer = tf.contrib.layers.xavier_initializer());\n", "    \n", "    CONV_8_1 = tf.get_variable(\"CONV_8_1\",[2,2,32,64], initializer = tf.contrib.layers.xavier_initializer());\n", "    CONV_8_2 = tf.get_variable(\"CONV_8_2\",[3,3,64,32], initializer = tf.contrib.layers.xavier_initializer());\n", "    CONV_8_3 = tf.get_variable(\"CONV_8_3\",[3,3,32,32], initializer = tf.contrib.layers.xavier_initializer());\n", "    \n", "    CONV_9_1 = tf.get_variable(\"CONV_9_1\",[2,2,16,32], initializer = tf.contrib.layers.xavier_initializer());\n", "    CONV_9_2 = tf.get_variable(\"CONV_9_2\",[3,3,32,16], initializer = tf.contrib.layers.xavier_initializer());\n", "    CONV_9_3 = tf.get_variable(\"CONV_9_3\",[3,3,16,16], initializer = tf.contrib.layers.xavier_initializer());\n", "    \n", "    CONV_OUT = tf.get_variable(\"CONV_OUT\",[1,1,16,1], initializer = tf.contrib.layers.xavier_initializer());\n", "      \n", "    Z1 = tf.nn.relu(tf.nn.conv2d(X,CONV_1_1, strides=[1,1,1,1], padding='SAME'))\n", "    D1 = tf.nn.dropout(Z1,keep_prob = 0.9)\n", "    V1 = tf.nn.relu(tf.nn.conv2d(D1,CONV_1_2, strides=[1,1,1,1], padding='VALID'))\n", "    A1 = tf.nn.max_pool(V1, ksize = [1, 127, 127, 1], strides = [1,1,1,1], padding = 'VALID')\n", "    \n", "    tf.summary.histogram('A1', A1)\n", "    \n", "    Z2 = tf.nn.relu(tf.nn.conv2d(A1, CONV_2_1, strides=[1,1,1,1], padding='SAME'))\n", "    D2 = tf.nn.dropout(Z2, keep_prob = 0.9)\n", "    V2 = tf.nn.relu(tf.nn.conv2d(D2, CONV_2_2, strides=[1,1,1,1], padding='VALID'))\n", "    A2 = tf.nn.max_pool(V2, ksize = [1, 63, 63, 1], strides = [1,1,1,1], padding = 'VALID')\n", "    \n", "    tf.summary.histogram('A2', A2)\n", "    \n", "    Z3 = tf.nn.relu(tf.nn.conv2d(A2, CONV_3_1, strides=[1,1,1,1], padding='SAME'))\n", "    D3 = tf.nn.dropout(Z3, keep_prob = 0.8)\n", "    V3 = tf.nn.relu(tf.nn.conv2d(D3, CONV_3_2, strides=[1,1,1,1], padding='VALID'))\n", "    A3 = tf.nn.max_pool(V3, ksize = [1, 31, 31, 1], strides = [1,1,1,1], padding = 'VALID')\n", "    \n", "    tf.summary.histogram('A3', A3)\n", "    \n", "    Z4 = tf.nn.relu(tf.nn.conv2d(A3, CONV_4_1, strides=[1,1,1,1], padding='SAME'))\n", "    D4 = tf.nn.dropout(Z4, keep_prob = 0.8)\n", "    V4 = tf.nn.relu(tf.nn.conv2d(D4, CONV_4_2, strides=[1,1,1,1], padding='VALID'))\n", "    A4 = tf.nn.max_pool(V4, ksize = [1, 15, 15, 1], strides = [1,1,1,1], padding = 'VALID')\n", "\n", "    tf.summary.histogram('A4', A4)\n", "    \n", "    Z5 = tf.nn.relu(tf.nn.conv2d(A4, CONV_5_1, strides=[1,1,1,1], padding='SAME'))\n", "    D5 = tf.nn.dropout(Z5, keep_prob = 0.8)\n", "    Z5 = tf.nn.relu(tf.nn.conv2d(D5, CONV_5_2, strides=[1,1,1,1], padding='SAME'))\n", "   \n", "    tf.summary.histogram('m_Z5', Z5)\n", "\n", "    batch_size = tf.shape(Z5)[0]    \n", "    # top of piramid, or bottom of valley\n", "    Z6 = tf.nn.conv2d_transpose(Z5, CONV_6_1, [batch_size,32,32,128], strides = [1,2,2,1], padding='VALID')\n", "    Z6 = tf.concat([Z6,Z4],3)\n", "    Z6 = tf.nn.relu(tf.nn.conv2d(Z6, CONV_6_2, strides=[1,1,1,1], padding='SAME'))\n", "    D6 = tf.nn.dropout(Z6, keep_prob = 0.8)\n", "    Z6 = tf.nn.relu(tf.nn.conv2d(D6, CONV_6_3, strides=[1,1,1,1], padding='SAME'))\n", "    \n", "    tf.summary.histogram('deconv-Z6', Z6)\n", "    \n", "    Z7 = tf.nn.conv2d_transpose(Z6, CONV_7_1, [batch_size,64,64,64], strides = [1,2,2,1], padding='VALID')\n", "    Z7 = tf.concat([Z7,Z3],3)\n", "    Z7 = tf.nn.relu(tf.nn.conv2d(Z7, CONV_7_2, strides=[1,1,1,1], padding='SAME'))\n", "    D7 = tf.nn.dropout(Z7, keep_prob = 0.8)\n", "    Z7 = tf.nn.relu(tf.nn.conv2d(D7, CONV_7_3, strides=[1,1,1,1], padding='SAME'))\n", "    \n", "    tf.summary.histogram('deconv_Z7', Z7)\n", "    \n", "    Z8 = tf.nn.conv2d_transpose(Z7, CONV_8_1, [batch_size,128,128,32], strides = [1,2,2,1], padding='VALID')\n", "    Z8 = tf.concat([Z8,Z2],3)\n", "    Z8 = tf.nn.relu(tf.nn.conv2d(Z8, CONV_8_2, strides=[1,1,1,1], padding='SAME'))\n", "    D8 = tf.nn.dropout(Z8, keep_prob = 0.9)\n", "    Z8 = tf.nn.relu(tf.nn.conv2d(D8, CONV_8_3, strides=[1,1,1,1], padding='SAME'))\n", "    \n", "    tf.summary.histogram('deconv_Z8', Z8)\n", "    \n", "    Z9 = tf.nn.conv2d_transpose(Z8, CONV_9_1, [batch_size,256,256,16], strides = [1,2,2,1], padding='VALID')\n", "    Z9 = tf.concat([Z9,Z1],3)\n", "    Z9 = tf.nn.relu(tf.nn.conv2d(Z9, CONV_9_2, strides=[1,1,1,1], padding='SAME'))\n", "    D9 = tf.nn.dropout(Z9, keep_prob = 0.9)\n", "    Z9 = tf.nn.relu(tf.nn.conv2d(D9, CONV_9_3, strides=[1,1,1,1], padding='SAME'))\n", "    \n", "    tf.summary.histogram('deconv_Z6', Z9)\n", "    \n", "    output = tf.nn.sigmoid(tf.nn.conv2d(Z9, CONV_OUT, strides=[1,1,1,1], padding='SAME'))\n", "    tf.summary.histogram('activations', output)\n", "    \n", "    return output"], "metadata": {"_uuid": "5efda5c0c2bdad4ae4426a5865852121d5e84c04", "_cell_guid": "aa68ae65-9603-458b-b75a-69901c3cdda8", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["def group_list(data_list, group_size):\n", "    \"\"\"\n", "    Yields groups from l sized group_size\n", "    Args:\n", "        data_list: list\n", "        group_size: size of group\n", "    \n", "    Returns\n", "    yield\n", "    \"\"\"\n", "    for i in range(0, len(data_list), group_size):\n", "        yield data_list[i:i+group_size]"], "metadata": {"_uuid": "7361f86f3e19af362753df26e7570a6bdfb0e4a2", "_cell_guid": "ce7e6d3a-2ba0-48da-b16c-38ba08d0967a", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["predictions = forward_propagation(X)"], "metadata": {"_uuid": "2b8eabac442900d5631fbaa50d54787ad8259eaf", "_cell_guid": "70550d5a-fe6d-473d-8b64-28bbbf8887e8", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["loss = tf.keras.losses.binary_crossentropy(Y,predictions)\n", "cost = tf.reduce_mean(loss)\n", "tf.summary.scalar('cost', cost)"], "metadata": {"_uuid": "243b578808fbbaf16cf8e87b70c9ac454811f6aa", "_cell_guid": "d43000a3-190a-459d-86b3-6cbcfb56fbae", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["##### Intersection over union score"], "metadata": {"_uuid": "1af323d7ced2fc8b55f6857040c6b1a9f63f6787", "_cell_guid": "aefdc534-f433-430b-a55a-ec4892b3c0c9"}, "cell_type": "markdown"}, {"source": ["prediction_mask = tf.to_int64(predictions > 0.5)\n", "iou_score, update_op = tf.metrics.mean_iou(Y, prediction_mask, 2)\n", "with tf.control_dependencies([update_op]):\n", "    iou_score = tf.identity(iou_score)\n", "tf.summary.scalar('intersection_overunion', iou_score)"], "metadata": {"_uuid": "42f32107a4f1ee486a3442207d8b2f4c37b7f7ea", "_cell_guid": "b31d2b37-e30b-4ebc-bfc6-170e9fc22cc5", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["##### Stats"], "metadata": {"_uuid": "f04abc2d647143e0d4052d1293969dbb40c8aeb9", "_cell_guid": "e8fd7dfd-cf26-45ae-a818-e5b0e6159325"}, "cell_type": "markdown"}, {"source": ["merged_summary = tf.summary.merge_all()\n", "train_writer = tf.summary.FileWriter('train')\n", "test_writer = tf.summary.FileWriter('test')"], "metadata": {"_uuid": "1717e12d43dc4ec8b56406c5abb6e2c5a65bf5ee", "_cell_guid": "666cb6db-cdce-439f-ac02-7c0582cd9963", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["def model(train_X, train_Y, test_X, test_Y, epochs, batch_size = 50, learning_rate = 0.005, save = -1, restore= -1):    \n", "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n", "    init = tf.global_variables_initializer()\n", "    init_l = tf.local_variables_initializer()\n", "    saver = tf.train.Saver()\n", "    sess = tf.Session();\n", "    if(True):\n", "        if(restore!=-1):        \n", "            saver.restore(sess,\"saved_model/model_\" + str(restore))\n", "        else:\n", "            sess.run(init);\n", "            sess.run(init_l)\n", "            \n", "        \n", "        for epoch in range(epochs):\n", "            start_time = time.time()\n", "            train_X_batches = group_list(train_X,batch_size)\n", "            train_Y_batches = group_list(train_Y,batch_size)\n", "            t_number_of_batches = len(train_X) // batch_size\n", "            \n", "            avg_cost_value = 0.\n", "            \n", "            avg_iou = 0.\n", "            \n", "            for index in range(0,t_number_of_batches):                \n", "                train_row_X = next(train_X_batches)\n", "                \n", "                train_row_Y = next(train_Y_batches)\n", "                \n", "                summary,opt, cost_value, iou_score_training = sess.run([merged_summary,optimizer, cost, iou_score],feed_dict={X: train_row_X, Y: train_row_Y})\n", "                train_writer.add_summary(summary, epoch)\n", "                avg_cost_value += cost_value / t_number_of_batches\n", "                avg_iou += iou_score_training / t_number_of_batches\n", "                \n", "            summary,test_cost_value, t_iou_score = sess.run([merged_summary,cost,iou_score],feed_dict={X: test_X, Y: test_Y})\n", "            duration = time.time() - start_time\n", "            test_writer.add_summary(summary, epoch)\n", "            print(\"Epoch \" '%03d' % (epoch+1), \n", "                  \": training cost = \", avg_cost_value,\n", "                  \" IOU score =  \", avg_iou ,\n", "                  \" test cost = \", test_cost_value,\n", "                  \" IOU score\", t_iou_score,\n", "                  \" : in \", duration, \"s\")\n", "                    \n", "        return sess"], "metadata": {"_uuid": "023f849a60a189ca3e2941f2953f73a4aac8e3e5", "_cell_guid": "4ceccf19-cb3b-4d48-b6ad-fd76fe86345c", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["sess = model(train_X[:512,:,:,:],\n", "             train_Y[:512],\n", "             train_X[512:,:,:,:],\n", "             train_Y[512:],\n", "             epochs = 50, batch_size = 16)"], "metadata": {"_uuid": "219cbec4459bbcfa41bf0e2ac1c91762d7b96766", "_cell_guid": "3266ff66-cf65-44a8-bede-3dabab3f1841", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["pred_Y = sess.run([predictions],feed_dict={X: pred_X})"], "metadata": {"_uuid": "e143545c858f96672fc9b43bdf26f26f463a8e43", "_cell_guid": "58b87571-9a02-4053-936d-7a933282ebed", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["f, arr = plt.subplots(3,2)\n", "arr[0][0].imshow(pred_X[0])\n", "arr[0][1].imshow(Util.convert_to_binary_image(pred_Y[0][0]).squeeze())\n", "arr[1][0].imshow(pred_X[1])\n", "arr[1][1].imshow(Util.convert_to_binary_image(pred_Y[0][1]).squeeze())\n", "arr[2][0].imshow(pred_X[2])\n", "arr[2][1].imshow(Util.convert_to_binary_image(pred_Y[0][2]).squeeze())"], "metadata": {"_uuid": "ff7cdf205020e5fab6aca3447b0e5b99a61e8709", "_cell_guid": "cc82dd80-12ab-4f38-9221-b0cf6b73ff7a", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}], "nbformat": 4, "nbformat_minor": 1, "metadata": {"language_info": {"version": "3.6.4", "nbconvert_exporter": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "mimetype": "text/x-python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}}