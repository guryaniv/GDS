{"cells":[{"metadata":{"_uuid":"65597b27ae203b427657d3129e984a8ef3ce2019"},"cell_type":"markdown","source":"# Basic setup of images and viewing of images"},{"metadata":{"_uuid":"a7eda0d61cc817c3160bc12adc4e0c3d86e4c940"},"cell_type":"markdown","source":"Lets Import some usefull libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport random\nimport warnings\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom skimage.feature import canny\nfrom skimage.filters import sobel,threshold_otsu, threshold_niblack,threshold_sauvola\nfrom skimage.segmentation import felzenszwalb, slic, quickshift, watershed\nfrom skimage.segmentation import mark_boundaries\nfrom scipy import signal\n\nimport cv2\nfrom PIL import Image\nimport pdb\nfrom tqdm import tqdm\nimport seaborn as sns\nimport os \nfrom glob import glob\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9396d31d061012842d1c913515cae193899abbc"},"cell_type":"markdown","source":"## Lets setup datapaths"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"INPUT_PATH = '../input'\nDATA_PATH = INPUT_PATH\nTRAIN_DATA = os.path.join(DATA_PATH, \"train_v2\")\nTRAIN_MASKS_DATA = os.path.join(DATA_PATH, \"train_v2/masks\")\nTEST_DATA = os.path.join(DATA_PATH, \"test_v2\")\ndf = pd.read_csv(DATA_PATH+'/train_ship_segmentations_v2.csv')\npath_train = '../input/train/'\npath_test = '../input/test/'\ntrain_ids = df.ImageId.values\ndf = df.set_index('ImageId')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74e6c6e13e263c0a81f4ff1f5069a73db96d1e21"},"cell_type":"markdown","source":"## Lets Define Some basic helper functions"},{"metadata":{"trusted":true,"_uuid":"1a8755fe0df377694cd99dd2d61f6367791938a0"},"cell_type":"code","source":"## Gets full path of a image given the image name and image type(test or train)\ndef get_filename(image_id, image_type):\n    check_dir = False\n    if \"Train\" == image_type:\n        data_path = TRAIN_DATA\n    elif \"mask\" in image_type:\n        data_path = TRAIN_MASKS_DATA\n    elif \"Test\" in image_type:\n        data_path = TEST_DATA\n    else:\n        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n\n    if check_dir and not os.path.exists(data_path):\n        os.makedirs(data_path)\n\n    return os.path.join(data_path, \"{}\".format(image_id))\n\ndef get_image_data(image_id, image_type, **kwargs):\n    img = _get_image_data_opencv(image_id, image_type, **kwargs)\n    img = img.astype('uint8')\n    return img\n\n## Function to read image and return it \ndef _get_image_data_opencv(image_id, image_type, **kwargs):\n    fname = get_filename(image_id, image_type)\n    img = cv2.imread(fname)\n    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\n# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction\n\n# https://github.com/ternaus/TernausNet/blob/master/Example.ipynb\ndef mask_overlay(image, mask):\n    \"\"\"\n    Helper function to visualize mask\n    \"\"\"\n    mask = mask.astype(np.uint8)\n    weighted_sum = cv2.addWeighted(mask, 0.75, image, 0.5, 0.)\n    img = image.copy()\n    ind = mask[:, :, 1] > 0    \n    img[ind] = weighted_sum[ind]    \n    return img","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58b71f5be5a76d54e47c32e09ba5ee1618edc5c6"},"cell_type":"markdown","source":"## Lets look at couple of images with and without mask"},{"metadata":{"trusted":true,"_uuid":"cd6dd9cc6d6943cfe9bc415c6605f550429c1707","scrolled":false},"cell_type":"code","source":"import traceback\nimport sys\n\n## This function neatly displays the images in grid , we have option of showing masked / unmasked images.\ndef show_image(df,train_ids,show_masked = True , show_unmasked = True,plot_no_ship_images=False):\n    ## We want to view 32 images in 4 rows\n    nImg = 32  #no. of images that you want to display\n    np.random.seed(42)\n    if df.index.name == 'ImageId':\n        df = df.reset_index()\n    if df.index.name != 'ImageId':\n        df = df.set_index('ImageId')\n\n    _train_ids = list(train_ids)\n    np.random.shuffle(_train_ids)\n    tile_size = (256, 256)\n    ## images per row\n    n = 8\n    alpha = 0.3\n\n    ## Number of rows\n    m = int(np.ceil(nImg * 1.0 / n))\n    complete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n    complete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\n    counter = 0\n    for i in range(m):\n        ## For each row set up the row template for images\n        ys = i*(tile_size[1] + 2)\n        ye = ys + tile_size[1]\n        j = 0\n        while j < n:\n            ## Now for each of images , load the image untill the we get 32 images\n            counter += 1\n            all_masks = np.zeros((768, 768))\n            xs = j*(tile_size[0] + 2)\n            xe = xs + tile_size[0]\n            image_id = _train_ids[counter]\n            ## For initial image exploration we would like to not have images with no ship , this can be toggle via the plot_no_ship_images option.\n            if str(df.loc[image_id,'EncodedPixels'])==str(np.nan):\n                if plot_no_ship_images:\n                    j +=1\n                else:    \n                    continue\n            else:\n                j += 1\n            img = get_image_data(image_id, 'Train')\n\n            try:\n                ## Depending on what type of images we want to see , compute the image matrix\n                \n                if show_unmasked:\n                    img_resized = cv2.resize(img, dsize=tile_size)\n                    img_with_text = cv2.putText(img_resized, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n                    complete_image[ys:ye, xs:xe, :] = img_with_text[:,:,:]\n                    \n                if show_masked:\n                    img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n                    for mask in img_masks:\n                        all_masks += rle_decode(mask)\n                    all_masks = np.expand_dims(all_masks,axis=2)\n                    all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')*255\n\n                    img_masked = mask_overlay(img, all_masks)        \n                    img_masked = cv2.resize(img_masked, dsize=tile_size)\n\n                    img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n                    complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n\n            except Exception as e:\n                all_masks = rle_decode(df.loc[image_id,'EncodedPixels'])\n                all_masks = np.expand_dims(all_masks,axis=2)*255\n                all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')\n\n                img_masked = mask_overlay(img, all_masks)        \n\n                img = cv2.resize(img, dsize=tile_size)\n                img_masked = cv2.resize(img_masked, dsize=tile_size)\n\n                img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n                complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n\n                img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n                complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n                \n    ## Now plot images based on the options\n    if show_unmasked:\n        m = complete_image.shape[0] / (tile_size[0] + 2)\n        k = 8\n        n = int(np.ceil(m / k))\n        for i in range(n):\n            plt.figure(figsize=(20, 20))\n            ys = i*(tile_size[0] + 2)*k\n            ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n            plt.imshow(complete_image[ys:ye,:,:],cmap='seismic')\n            plt.title(\"Training dataset\")\n            \n    if show_masked:\n        m = complete_image.shape[0] / (tile_size[0] + 2)\n        k = 8\n        n = int(np.ceil(m / k))\n        for i in range(n):\n            plt.figure(figsize=(20, 20))\n            ys = i*(tile_size[0] + 2)*k\n            ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n            plt.imshow(complete_image_masked[ys:ye,:,:])\n            plt.title(\"Training dataset: Lighter Color depicts ship\")\n\n##Lets quickly test the function we just wrote            \nshow_image(df,train_ids)        \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4c0c112421c29b471c1c3801f532e8d676f56ff"},"cell_type":"markdown","source":"## Plotting Ship Count\""},{"metadata":{"trusted":true,"_uuid":"177213b6156aae80714c61b2de9d83c46e497f88","scrolled":false},"cell_type":"code","source":"df = df.reset_index()\ndf['ship_count'] = df.groupby('ImageId')['ImageId'].transform('count')\ndf.loc[df['EncodedPixels'].isnull().values,'ship_count'] = 0  #see infocusp's comment\nsns.set_style(\"white\")\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\nsns.distplot(df['ship_count'],kde=False)\nplt.title('Ship Count Distribution in Train Set')\n\nprint(df['ship_count'].describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f99b47608ad76abb1c16641028e9849821aa8969"},"cell_type":"markdown","source":"## Plotting Images: Based on Ship Count"},{"metadata":{"trusted":true,"_uuid":"aa3dbdc8a20aee562c21521be985ea1f64b6b195"},"cell_type":"markdown","source":"### Lets begin with images with no ships"},{"metadata":{"trusted":true,"_uuid":"2dceb006fb1768946133cbf4ba1d90e1920d5e9e"},"cell_type":"code","source":"images_with_noships = df[df[\"ship_count\"] == 0].ImageId.values\nshow_image(df,images_with_noships,show_masked=False,plot_no_ship_images=True)        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6af907af33cfc2a53c2958fe6b0f21121e882483"},"cell_type":"markdown","source":"### Lets begin with images with 1 to 5 ships"},{"metadata":{"trusted":true,"_uuid":"c3ce8ee88eb990145153ca3dae54943eee9a59d2"},"cell_type":"code","source":"images_with_1_5 = df[df[\"ship_count\"].between(1,5)].ImageId.values\nshow_image(df,images_with_1_5,show_unmasked=False,show_masked=True,plot_no_ship_images=True)        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b8cbe873d48260178176faa087c179c24b408f2"},"cell_type":"markdown","source":"## Training Set Images with Ship Count 5 to 10"},{"metadata":{"trusted":true,"_uuid":"3ff4e9c147c543d5447e49cdb4d2e65ba97e7b1f"},"cell_type":"code","source":"images_with_5_10 = df[df[\"ship_count\"].between(5,10)].ImageId.values\nshow_image(df,images_with_5_10,show_unmasked=False,show_masked=True,plot_no_ship_images=True)        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"939d157bc2225acec932b020078d626c445b2440"},"cell_type":"markdown","source":"## Training Set Images with Ship Count greater than 10"},{"metadata":{"trusted":true,"_uuid":"7070eceb7dbc8fa0fc8c30a61d041c3212bca407"},"cell_type":"code","source":"images_with_greater_10 = df[df[\"ship_count\"].between(10,16)].ImageId.values\nshow_image(df,images_with_greater_10,show_unmasked=False,show_masked=True,plot_no_ship_images=True)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1012acba461dd079541108982b2cdf49a71dc95"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}