{"cells": [{"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "metadata": {"_uuid": "39c019d05e952b7aa1dfc1af54927b805c2f9ba5", "_cell_guid": "a9470a29-cd6a-42cd-91b8-0cd78e80ff09"}, "cell_type": "code", "execution_count": 1}, {"source": ["from sklearn.model_selection import train_test_split\n", "\n", "# seed for reproducing same results\n", "seed = 5\n", "np.random.seed(seed)\n", "\n", "# read input and create features (X) and labels (y) variables\n", "data_train = pd.read_csv('../input/train.csv')\n", "X = data_train.drop('label', axis=1)\n", "y = data_train['label']\n", "\n", "# create the train-test-split\n", "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.1, random_state=seed)\n", "\n", "print('There are %d train entries and %d test entries' % (len(X_train), len(y_test)))"], "outputs": [], "metadata": {"_uuid": "0e1e5849d93211ad27c77a87553da4db9953f931", "_cell_guid": "ac3a6128-bcca-4fc7-a74d-2d7e9874428b"}, "cell_type": "code", "execution_count": 2}, {"source": ["%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "import matplotlib.cm as cm\n", "\n", "# transform our pandas dataframes to np-arrays\n", "X_train_matrix = X_train.as_matrix()\n", "y_train_matrix = y_train.as_matrix()\n", "X_test_matrix = X_test.as_matrix()\n", "y_test_matrix = y_test.as_matrix()\n", "\n", "# plot first ten training images\n", "fig = plt.figure(figsize=(20,20))\n", "for i in range(10):\n", "    axis = fig.add_subplot(1, 10, i+1, xticks=[], yticks=[])\n", "    # reshape the image-data from a 1D array to a 2D array with shape (28,28)\n", "    # as the mnist images are squares of 784 pixels\n", "    axis.imshow(np.reshape(X_train_matrix[i], (28,28)), cmap='gray')\n", "    axis.set_title(str(y_train_matrix[i]))"], "outputs": [], "metadata": {"_uuid": "c8a7d0212b71eb4412c2320739ee79cb2594ff20", "_cell_guid": "7fe88ec7-0c81-4f58-816a-09c97d5793ec"}, "cell_type": "code", "execution_count": 3}, {"source": ["# rescale the image data to be between 0 and 1\n", "print('before:')\n", "print(X_train_matrix[0])\n", "\n", "X_train_matrix = X_train_matrix.astype('float32') / 255\n", "X_test_matrix = X_test_matrix.astype('float32') / 255\n", "\n", "print('after:')\n", "print(X_train_matrix[0])"], "outputs": [], "metadata": {"_uuid": "2f9fe0376d167ec97f8ab295112af03159c95a84", "_cell_guid": "8dd0d49b-5905-4199-8b88-20d14b8c71a4"}, "cell_type": "code", "execution_count": 4}, {"source": ["# one-hot-encode the labels\n", "from keras.utils import np_utils\n", "\n", "print('Before:')\n", "print(y_train_matrix[:8])\n", "\n", "# we have 10 categories: 0 to 9\n", "y_train_matrix = np_utils.to_categorical(y_train_matrix, 10)\n", "y_test_matrix = np_utils.to_categorical(y_test_matrix, 10)\n", "\n", "print('After:')\n", "print(y_train_matrix[:8])"], "outputs": [], "metadata": {"_uuid": "9cae54ecd96e7ea16a416f3508a9d6889be2f496", "_cell_guid": "b7677fa1-56fb-4c8a-ba8a-cb22e62d525a"}, "cell_type": "code", "execution_count": 5}, {"source": ["from keras.models import Sequential\n", "from keras.layers import Dense, Dropout\n", "\n", "# let's start with a basic Multilayer Perceptron (MLP) model architecture\n", "# we will compare this to the CNN model later\n", "model = Sequential()\n", "model.add(Dense(784, input_shape=(len(X_train_matrix[0]),)))\n", "model.add(Dense(392, activation='relu'))\n", "model.add(Dropout(0.2))\n", "model.add(Dense(196, activation='relu'))\n", "model.add(Dropout(0.2))\n", "model.add(Dense(10, activation='softmax'))\n", "\n", "# summarize the model's architecture\n", "model.summary()"], "outputs": [], "metadata": {"_uuid": "66571290c2e5408362c6288c85357e91aea3a57f", "_cell_guid": "bcc659f9-74af-4bc2-8b3f-a50bb12241b7"}, "cell_type": "code", "execution_count": 6}, {"source": ["# finally, compile the model\n", "# the accuracy metric will allow us to see how the accuracy changes during training\n", "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n", "\n", "# the model starts with random weights\n", "# let's check if this shows when eveluating test accuracy\n", "score = model.evaluate(X_test_matrix, y_test_matrix, verbose=0)\n", "accuracy = score[1] * 100\n", "# we'd expect this to be around 10%, as there are 10 different categories (numbers 0-9)\n", "print('Random test accuracy is %1.1f%%' % accuracy)"], "outputs": [], "metadata": {"_uuid": "cb08f3c48aa9edecb3353f19e21c0ea1002873d5", "_cell_guid": "0c2cc097-e150-4297-b9ea-393861376c96"}, "cell_type": "code", "execution_count": 7}, {"source": ["# let's train the model!\n", "history = model.fit(X_train_matrix, y_train_matrix, batch_size=100, epochs=6, verbose=1)"], "outputs": [], "metadata": {"_uuid": "53181a124643f7492100ec2ef801865a0571d457", "_cell_guid": "8288a535-f6d3-47c0-b5ba-eb474b770ca7"}, "cell_type": "code", "execution_count": 8}, {"source": ["# let's try some more advanced fitting, including validation & shuffle\n", "# also save the model with the best accuracy\n", "from keras.callbacks import ModelCheckpoint\n", "\n", "cb_checkpoint = ModelCheckpoint(filepath='best-model.hdf5', verbose=1, save_best_only=True)\n", "\n", "history = model.fit(X_train_matrix, y_train_matrix, batch_size=400, epochs=6, \n", "                    validation_split=0.2, shuffle=True, callbacks=[cb_checkpoint], verbose=1)"], "outputs": [], "metadata": {"_uuid": "6e1cf31a65cd073604c867a5955cdf3370f85436", "_cell_guid": "9392db1d-0d3f-4477-9cb3-04ef5aa63ff5"}, "cell_type": "code", "execution_count": 9}, {"source": ["# using a validation set during training did improve accuracy\n", "# it also shows us whether the model tends to overfit our training data\n", "\n", "# now, let's load the model with best validation accuracy\n", "model.load_weights('best-model.hdf5')\n", "\n", "# let's test our model on the test set\n", "score = model.evaluate(X_test_matrix, y_test_matrix, verbose=0)\n", "accuracy = score[1] * 100\n", "print(\"Best Model's test accuracy is %1.1f%%\" % accuracy)"], "outputs": [], "metadata": {"_uuid": "24c3769c83fbea84d01c789da13d8045dcadef12", "_cell_guid": "89bb4a60-b766-466a-9f74-6a13ba2118ec"}, "cell_type": "code", "execution_count": 10}, {"source": ["# transform our data to be used in CNNs\n", "X_train = np.array(list(map(lambda x: np.reshape(x, (28,28,1)), X_train_matrix)))\n", "X_test = np.array(list(map(lambda x: np.reshape(x, (28,28,1)), X_test_matrix)))"], "outputs": [], "metadata": {"_uuid": "6a48232b01483ca98d70ed645ccd3a6c7a78b1d4", "_cell_guid": "9499022f-e2e7-4aa5-83c0-ce8c54e19ba2", "collapsed": true}, "cell_type": "code", "execution_count": 11}, {"source": ["# Now we define our CNN architecture\n", "# I chose to pretty much use the one defined in TensorFlow's \n", "# Deep MNIST for Experts Tutorial (https://www.tensorflow.org/get_started/mnist/pros)\n", "\n", "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n", "\n", "model = Sequential()\n", "model.add(Conv2D(filters=32, kernel_size=5, padding='same', activation='relu', \n", "                 input_shape=(28,28,1)))\n", "model.add(MaxPooling2D(pool_size=2))\n", "model.add(Conv2D(filters=64, kernel_size=5, padding='same', activation='relu'))\n", "model.add(MaxPooling2D(pool_size=2))\n", "model.add(Flatten())\n", "model.add(Dense(1024, activation='relu'))\n", "model.add(Dropout(0.3))\n", "model.add(Dense(10, activation='softmax'))\n", "\n", "# summarize the model's architecture\n", "model.summary()"], "outputs": [], "metadata": {"_uuid": "673aba5b98abbb3f93503ac6cbe7362f9f96ff2b", "_cell_guid": "7b5ff27e-744b-4b3f-8926-fc5419692a19"}, "cell_type": "code", "execution_count": 12}, {"source": ["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n", "\n", "# the model starts with random weights\n", "# let's check if this shows when eveluating test accuracy\n", "score = model.evaluate(X_test, y_test_matrix, verbose=0)\n", "accuracy = score[1] * 100\n", "# we'd expect this to be around 10%, as there are 10 different categories (numbers 0-9)\n", "print('Random test accuracy is %1.1f%%' % accuracy)"], "outputs": [], "metadata": {"_uuid": "50a11052e507d2feeb83ca16ca937a130f58ca17", "_cell_guid": "88b340d9-3a79-4b22-9819-88dec97501cc"}, "cell_type": "code", "execution_count": 15}, {"source": ["cb_checkpoint = ModelCheckpoint(filepath='best-cnn-model.hdf5', verbose=1, save_best_only=True)\n", "\n", "history = model.fit(X_train, y_train_matrix, batch_size=50, epochs=6, \n", "                    validation_split=0.2, shuffle=True, callbacks=[cb_checkpoint], verbose=1)"], "outputs": [], "metadata": {"_uuid": "171da8dbd371eab96bd52c7dd13ca4f2acba5c5a", "_cell_guid": "6f8972e8-ae96-403e-b339-bf01ad6d927d"}, "cell_type": "code", "execution_count": 16}, {"source": ["model.load_weights('best-cnn-model.hdf5')\n", "\n", "# let's test our model on the test set\n", "score = model.evaluate(X_test, y_test_matrix, verbose=0)\n", "accuracy = score[1] * 100\n", "print(\"Best Model's test accuracy is %1.1f%%\" % accuracy)"], "outputs": [], "metadata": {"_uuid": "3d8175f5a905fb945e75a7bcb00bf05abeab32ad", "_cell_guid": "61185fa3-c57c-46e2-a372-44516a59e6f5"}, "cell_type": "code", "execution_count": 17}, {"source": ["# let's use that one to make our final predictions\n", "\n", "data_test = pd.read_csv('../input/test.csv')"], "outputs": [], "metadata": {"_uuid": "26a9d774836f3772f6103ec930eb01d75dee8b79", "_cell_guid": "5a4ff800-9a87-4531-bf46-83bf5bd0f0f6", "collapsed": true}, "cell_type": "code", "execution_count": 18}, {"source": ["test = np.array(list(map(lambda x: np.reshape(x, (28,28,1)), data_test.as_matrix())))\n", "test.shape"], "outputs": [], "metadata": {"_uuid": "add198ca4712fed955f38309a2f4a2d074787598", "_cell_guid": "accd143a-3b01-4572-890d-b63adc4a255f"}, "cell_type": "code", "execution_count": 19}, {"source": ["pred = model.predict(test, batch_size=32, verbose=1)\n", "pred[0]"], "outputs": [], "metadata": {"_uuid": "be115049232c26919f4ece33d09eb488c80314f2", "_cell_guid": "f738886a-9edc-45ac-a7d9-1c1ad86c27f3"}, "cell_type": "code", "execution_count": 20}, {"source": ["# decode the one-hot encoded predictions\n", "predicted_labels = [ np.argmax(r, axis=0) for r in pred ]\n", "predicted_labels"], "outputs": [], "metadata": {"_uuid": "e166b7e08dbdd6013295742b000e12d4d3227598", "_cell_guid": "6bdcf7bc-0263-4f26-8dcc-147db423a851"}, "cell_type": "code", "execution_count": 21}, {"source": ["import csv\n", "\n", "with open('submission.csv', 'w') as csvfile:\n", "    fo = csv.writer(csvfile, delimiter=',', lineterminator='\\n')\n", "    fo.writerow(['ImageId', 'Label'])\n", "    for (index, label) in enumerate(predicted_labels):\n", "        fo.writerow([index + 1, label])"], "outputs": [], "metadata": {"_uuid": "ed3b368c5e3c45e1c8ad05382845d972a00958e8", "_cell_guid": "094d5bbc-73e4-4ae2-8cc0-a7fc1c8606fe", "collapsed": true}, "cell_type": "code", "execution_count": 22}, {"source": [], "outputs": [], "metadata": {"_uuid": "e0d2b63f1fc10aab0d488c8ac2538e6c8e12dc0c", "_cell_guid": "2edf6083-47c0-4f18-b60c-56eec7eb2f8b", "collapsed": true}, "cell_type": "code", "execution_count": null}], "nbformat": 4, "metadata": {"language_info": {"name": "python", "version": "3.6.3", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat_minor": 1}