{"cells":[{"metadata":{"_uuid":"634acd84dce3decc23b57776e77b5b36df0d274a"},"cell_type":"markdown","source":"## [Workbook 2](https://www.kaggle.com/sabasiddiqi/workbook-2-text-preprocessing-feature-extraction) - Text Preprocessing for Beginners - Feature Extraction\n\n<br>**Level : **Beginner\n\n\nThis notebook discusses **Text Data Preprocessing - Feature Extraction** for **NLP Problems** using Toxic Comment Classification Dataset. Data comprises of large number of Wikipedia comments which have been labeled by human raters for toxic behavior. <br>Data is available via following link.\n[Toxic Comment Classification](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)\n\n Previous Notebook : [Workbook 1 - Text Preprocessing for Beginners - Data Cleaning](https://www.kaggle.com/sabasiddiqi/workbook-1-text-pre-processing-for-beginners)\n\n\nTo skip the initial steps (reading data, removing nans, splitting train/test), Jump to [Feature Extraction](#jump)."},{"metadata":{"_uuid":"2cbc211c83ad1494cf60487afc12b94cbf22ddfa"},"cell_type":"markdown","source":"Importing required libraries"},{"metadata":{"trusted":true,"_uuid":"c5eec24d21905e11012689855fbc7c56a697ac3c"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"636d32d3e3edb45b85fb3134b8a42eab1e3dcad8"},"cell_type":"markdown","source":"Reading processed data from CSV file and saving as Pandas' Dataframe"},{"metadata":{"trusted":true,"_uuid":"4072a9654b6b4f266a654dfd6c769663b603965d"},"cell_type":"code","source":"print(os.listdir(\"../input/workbook-1-text-pre-processing-for-beginners/\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"train_data=pd.read_csv('../input/workbook-1-text-pre-processing-for-beginners/train_data.csv')\ntest_data=pd.read_csv('../input/workbook-1-text-pre-processing-for-beginners/test_data.csv')\nprint(\"Preprocessed Training Data: \\n\",train_data.head())\nprint(\"\\n Preprocessed Test Data: \\n\",test_data.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8639cfcf66b002b1a946922a239af9464bc04b56"},"cell_type":"markdown","source":"Checking for empty cells in data"},{"metadata":{"trusted":true,"_uuid":"333706bd922c0d095425219c800615a63541ea22"},"cell_type":"code","source":"print(\"Empty Comment Cells In Train: \",train_data['comment_text'].isna().sum())\nprint(\"Empty Comment Cells In Test: \",test_data['comment_text'].isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc85decb519ac566f2c0e23c15b9ea28ffdbc284"},"cell_type":"markdown","source":"There are 45 and 102 empty comments in train and test after Cleaning Comments data in [Workbook 1](https://www.kaggle.com/sabasiddiqi/workbook-1-text-pre-processing-for-beginners). <br>Extracting index of empty cells to remove them in next step."},{"metadata":{"trusted":true,"_uuid":"689028c4a5de237311e3c398016fee9efb57bed7","scrolled":true},"cell_type":"code","source":"train_drop_list=train_data[train_data.iloc[:,0].isna()]\ntrain_drop_list_idx=train_drop_list.index\ntest_drop_list=test_data[test_data.iloc[:,0].isna()]\ntest_drop_list_idx=test_drop_list.index\nprint(\"Index of Empty Comment Cells in Train: \\n\",train_drop_list_idx)\nprint(\"Index of Empty Comment Cells in Test : \\n\",test_drop_list_idx)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c60b81deed254301698487b9be36914e83d4f25d"},"cell_type":"markdown","source":"Dropping/Removing Empty Cell Rows from data using index values (axis=0 is to specify rows), and verifying."},{"metadata":{"trusted":true,"_uuid":"e69dd0e83a1aa69989192d35c83684a45331ae34"},"cell_type":"code","source":"train_data_new=train_data.drop(train_drop_list_idx,axis=0)\n#test_data_new=test_data.drop(test_drop_list_idx,axis=0)\ntest_data_new=test_data\nprint(\"Verifying - Empty Comments After Removal: \")\nprint(\"Train: \",train_data_new['comment_text'].isna().sum())\nprint(\"Test: \",test_data_new['comment_text'].isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8313a0c825f9c75cccf6ac8e01cde039f8df2974"},"cell_type":"code","source":"print(\"Train Data shape --  Before drop: \",train_data.shape, \"After Drop: \",train_data_new.shape )\nprint(\"Test Data shape --  Before drop: \",test_data.shape, \"After Drop: \",test_data_new.shape )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ee24698f5fbd11755a504a448f29921eeac187a"},"cell_type":"markdown","source":"Splitting preprocessed data into Train (80%) and Test (20%) by using [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). And separating comments and labels for Train and Test data."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#train, test = train_test_split(data_new, test_size=0.2,random_state=42)\ntrain, test = train_data_new, test_data_new\ntest_comments=test.iloc[:,0]\ntrain_comments=train.iloc[:,0]\ntest_labels=test.iloc[:,1:]\ntrain_labels=train.iloc[:,1:]\nprint(\"Train Comments Shape : \",train_comments.shape)\nprint(\"Train Labels Shape :\",train_labels.shape)\nprint(\"Test Comments Shape :\",test_comments.shape)\n#print(\"Test Labels Shape :\",test_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1b1105cad8230a562ef57d8c4b64ae2896b609b"},"cell_type":"markdown","source":"##  <a id=\"jump\">Feature Extraction - Bag of Words</a>"},{"metadata":{"_uuid":"9fa6e7e1fff4f89b2ce4cad1fa94fa035d0f1186"},"cell_type":"markdown","source":"When dealing with textual data, feature extraction refers to conversion of data to numerical form(features) supported by Machine Learning Algorithms.<br>  \nOne way to do so is using \"**Bag of Words**\" , the model  involves representation of text (referred as sentence or document) as a multiset of words keeping a record of their frequency.\nA **Term Frequency Matrix** is used to keep record of frequency of words in the document(comment).\n\nFor example, lets consider these two comments.\n\n*Comment 1: the cat jumped over the fence*<br>\n*Comment 2: the dog jumped over the wall* <br>\n\nTF for these documents will be,\n\n**Term frequency matrix: **\n![](https://storage.googleapis.com/kagglesdsdata/datasets/83007/192833/Picture2.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1543552930&Signature=WhjJ5gcNT4Gj9tvksqIoHb87wHMoc5XnnuzMsG9g8H5rdEEdwvhiEqLye4AkDu7uawiFfDcrYNB%2B619UpzP%2FI9MQb5xDfj5jAHvYRIY4Utr5gzaGHGT1YseIWyFa9OEA6VeCm%2BZAnJ4NBXHlX2yomAt%2F864VS%2FhMaUjuagjmJGOKwrk6sAj3piOex0BXkw3BpKFm31CT8B0x9yXkRzyyhAaF5do84%2F6DqfIOQySkOochZMWcjvpJEk2qAjouqgunUNZa7ki3xuBZIywpFfDJKtE5E8IUIgvUmHDkBdaaQnbAvGsnyF6IvAlTVDM1TuFDvL5mINF13mkId0fnsIUJ0g%3D%3D)\n\n\nOur actual term frequency matrix size has ~ 169000 terms (words). We limit it to 10000 most frequent words.\n"},{"metadata":{"_uuid":"649d546362f870093c09d492e5cb433e4d83b01b"},"cell_type":"markdown","source":"### Creating a Term Frequency Matrix:\n*Note: TF is only fit on training data\n\n[CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)-Convert a collection of text documents to a matrix of token counts <br>\n**fit** : to generate learning model parameters from training data<br>\n**transform** : parameters generated from fit method are applied on model to generate transformed data set."},{"metadata":{"trusted":true,"_uuid":"eb2f2a39ee7d214c3210c326ff9dafd90782e14b"},"cell_type":"code","source":"vectorizer = CountVectorizer(analyzer = 'word',stop_words='english',max_features=10000)\ntrain_comments_count=vectorizer.fit(train_comments).transform(train_comments)\nprint(\"Term Frequency Matrix(TF): \\n\",train_comments_count.toarray())\nprint(\"Verifying that TF is not empty by checking the sum \",train_comments_count.toarray().sum() )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d55de1b848e2f778e6a2c0dac1c62279479ee955"},"cell_type":"markdown","source":"## Inverse Document Frequency<br><br>\n\nWe chose word frequency here to represent text features. However, Inverse Document Frequency can be applied to Term Frequency Matrix to furthur improve our classifier.\n\n**Term Frequency (TF)**  is a scoring of the frequency of the word in the current document, whereas <br>\n**Inverse Document Frequency (IDF)** is a scoring of how rare the word is across documents.<br>\n\n**Why do we need to find rare words ?** Terms that appear across many comments are less discriminating. TFIDF assigns weightage to words wrt other words in document.\n\nTF-IDF not only counts the frequency of a term in the given document), but also reflects the importance of each term to the document by penalizing frequently appearing terms(words) in most samples.\n\n\nTo find out the IDF using Term Frequency Matrix:\n* Scale each term frequency of term** i **by **log(N/fi)** \nwhere, <br>\n**N** = # of comments in Term Frequency matrix  <br>\n**fi** = # of comments term i appears in <br>\n\n\n\n**Scaled matrix:** \n\n\n![](https://storage.googleapis.com/kagglesdsdata/datasets/83007/192833/Picture1.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1543552915&Signature=hd0c%2BFU6RJxKMYj6u4aymfVFyTFGpKAIbRofsmTC6r4MFg7Jud9a2GU7j1O5JrCFB0%2BDfXgdUAWqDL4CTepCzaJjKmFSv4ipzd65kPizjjYmSvR7G0EJ5ZX1AoVn89exl2oepn2VmMiFRtVi8L1PJ%2BqtiBiwupIBBwyVfrBWyZgujkul%2BUKmrtaeWxizVXgTAMMSbctp45pT2ALrGbYwWpStk%2BTYGqhegG353PmvPPBpUUMpGQcUiKY1JtH%2BqrLjwoGK30aC7dSspV1zC%2BDfZkskTsa4qxS1mtUcGismK%2F2OmZpWLUqZAnvEpLJ1PFtO4bfiIAyTpMtx70OVIlr52Q%3D%3D)\n\n"},{"metadata":{"_uuid":"e7dc448d63b7a4e01d907f2ca931c3882be6ee05"},"cell_type":"markdown","source":"**TF-IDF for Training Data:**\n"},{"metadata":{"trusted":true,"_uuid":"b98bc7472bff388f96a8e28026e2b6821f012351"},"cell_type":"code","source":"tf_transformer = TfidfTransformer()\ntf_transformer.fit(train_comments_count)\ntrain_tfidf = tf_transformer.transform(train_comments_count)\nprint(\"Train TF-IDF Matrix Shape: \",train_tfidf.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ee68483b421c8a75290417a40a8850b40e5222c"},"cell_type":"markdown","source":"**TF-IDF forTest Data:**"},{"metadata":{"trusted":true,"_uuid":"b2c53bdfda2e0aee7da061cd18d8309e3858fb0a"},"cell_type":"code","source":"test_comments_count = vectorizer.transform(test_comments)\ntest_tfidf = tf_transformer.transform(test_comments_count)\nprint(\"Test TF-IDF Matrix Shape: \",test_tfidf.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8974070ec16056386b0466f8eca7a70af72e817f"},"cell_type":"markdown","source":"Saving data in npz format (as sparse matrix)  to use it in different notebook, or you can continue working in the same notebook."},{"metadata":{"trusted":true,"_uuid":"a0b33a3aa16aba72733633a99deed410ea32fd1f"},"cell_type":"code","source":"from scipy import sparse\n\ntrain.to_csv('train.csv', index = False)\ntest.to_csv('test.csv', index = False)\nsparse.save_npz(\"train_tfidf.npz\", train_tfidf)\nsparse.save_npz(\"test_tfidf.npz\", test_tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"165b6935107bb5ad9ef3fd44f6f2f0339031825f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}