{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "858598d1-a80a-8c7f-dc1c-31af0fe5f9ba"
      },
      "source": [
        "## First part: display bounding boxes\n",
        "This kernel is linked to the discussion thread: https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening/discussion/31565#174995 where I give three files with bounding boxes.\n",
        "\n",
        "I merged all files into one called annot.tsv\n",
        "\n",
        "I said that there could be a need to account for window resizing, so I show here what is working.\n",
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca505ab9-6fd7-e006-1798-bf0cec34efe7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import PIL\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dc6de224-f703-4348-16e1-80936ecf477f"
      },
      "outputs": [],
      "source": [
        "DATA_HOME_DIR = '../input/'\n",
        "%matplotlib inline\n",
        "data_path = DATA_HOME_DIR + '/' \n",
        "train_path = data_path + 'train/'\n",
        "nb_full_train_samples = 1481\n",
        "bb_json = {}\n",
        "\n",
        "### dict with boxes: use this for your local verification\n",
        "#j = pd.read_table('https://kaggle2.blob.core.windows.net/forum-message-attachments/174995/6330/Type_1_bbox.tsv',sep = \" \",\n",
        "#                header = None,\n",
        "#                usecols = range(6),\n",
        "#                names = ['filename','nbox','x','y','width','height'])\n",
        "#j['y']=j['ymin']+j['height']\n",
        "#filenames=[]\n",
        "#for index, l in j.iterrows():\n",
        "#     filenames.append(l['filename'])\n",
        "#     bb_json[l['filename'].split('/')[-1]] = sorted(\n",
        "#           [l[['height', 'width', 'x', 'y']].to_dict()],\n",
        "#         key = lambda var: var['width']*var['height']\n",
        "#         )\n",
        "#print(l[['x','y','width','height']].to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "611b7c01-220f-e892-efa4-b02934a9a86c"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "def to_plot(img):\n",
        "    return np.rollaxis(img, 0, 3).astype(np.uint8)\n",
        "def plot(img):\n",
        "    plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1e2eca95-8474-a3db-30b0-c2cc2a48e60c"
      },
      "outputs": [],
      "source": [
        "def show_bb(i):\n",
        "    img = PIL.Image.open(train_path+filenames[i])\n",
        "    bb = bb_json[filenames[i].split('/')[-1]][0]\n",
        "    plt.figure(figsize=(6,6))\n",
        "    s = img.size\n",
        "    plot(img)\n",
        "    ax=plt.gca()\n",
        "    ax.add_patch(create_rect([bb['x'],bb['y'],bb['width'],bb['height']], 'yellow'))\n",
        "def create_rect(bb, color='red'):\n",
        "    return plt.Rectangle((bb[0], bb[1]), bb[2], bb[3], color=color, fill=False, lw=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1b33ef25-24e4-1550-dc92-2cd37854b484"
      },
      "source": [
        "Since I cannot read the file on Kaggle kernel, I am manually creating the dict here.\n",
        "\n",
        "          filename  nbox    x     y  width  height\n",
        "          Type_1\\0.jpg     2  882   961   1042    1106\n",
        "          Type_1\\10.jpg     1  972  2349   1052     715\n",
        "          Type_1\\1013.jpg     1  606  1437    774     825\n",
        "          Type_1\\1014.jpg     1  930  1090   1310    1384\n",
        "          Type_1\\1019.jpg     1  620  1304    982    1168\n",
        "          Type_1\\102.jpg     1  722  1486    546     495\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "88c21880-46b2-5d34-59b5-8cf503a3e38c"
      },
      "outputs": [],
      "source": [
        "filenames = [ \"Type_1/0.jpg\",\n",
        "      \"Type_1/10.jpg\",\n",
        "    \"Type_1/1013.jpg\"]\n",
        "bb_json = {}\n",
        "\n",
        "bb_json[\"0.jpg\"] = sorted(\n",
        "           [{'x': 882,\n",
        "           'y':972,\n",
        "           'width':1042,\n",
        "           'height': 1106\n",
        "            }],\n",
        "    key = lambda var: var['width']*var['height']\n",
        "         )\n",
        "bb_json[\"10.jpg\"] = sorted(\n",
        "           [{'x': 972,\n",
        "           'y':2349,\n",
        "           'width':1022,\n",
        "           'height':725}]\n",
        "         ,key = lambda var: var['width']*var['height'])\n",
        "print(bb_json['0.jpg'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2bd8f5a7-63ee-f5c2-4e8b-2d6ad09cb016"
      },
      "outputs": [],
      "source": [
        "show_bb(0)\n",
        "show_bb(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f1d9e7d6-b7ee-52a8-9eef-630793571436"
      },
      "source": [
        "## Second part: showing abnormal images in additional dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d69f1b04-8139-fd47-5fb1-8cc8120ecdd0"
      },
      "outputs": [],
      "source": [
        "add_path = '../input/additional/'\n",
        "def plot_from_path(path):\n",
        "    img = PIL.Image.open(add_path+path)\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plot(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d09facde-359d-a745-ceb0-d0b71e28e49b"
      },
      "source": [
        "### Timeseries of treatment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "22bf1f9f-c233-0c4d-5a19-7c4015474dac"
      },
      "outputs": [],
      "source": [
        "plot_from_path('Type_3/5684.jpg')\n",
        "plot_from_path('Type_3/5683.jpg')\n",
        "plot_from_path('Type_3/5685.jpg')\n",
        "plot_from_path('Type_3/5688.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "13e743fa-0546-d1e2-b25b-bf81bd15fe5b"
      },
      "source": [
        "###Other examples of timeseries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "08246641-f8ab-d2bc-0dfb-9bf58010fa1b"
      },
      "outputs": [],
      "source": [
        "plot_from_path('Type_2/1816.jpg')\n",
        "plot_from_path('Type_2/2946.jpg')\n",
        "plot_from_path('Type_2/3803.jpg')\n",
        "plot_from_path('Type_2/2971.jpg')\n",
        "plot_from_path('Type_2/6893.jpg')\n",
        "plot_from_path('Type_2/6894.jpg')\n",
        "plot_from_path('Type_2/6892.jpg')\n",
        "plot_from_path('Type_2/6891.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ad17723b-4684-cffa-82c2-b4dc4be233c5"
      },
      "source": [
        "### Unrelated images: \n",
        "Found a hand, a bag,..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0348d813-1200-2314-f26b-8c6c8ee6f589"
      },
      "outputs": [],
      "source": [
        "plot_from_path('Type_2/1813.jpg')\n",
        "plot_from_path('Type_1/746.jpg')\n",
        "plot_from_path('Type_1/2030.jpg')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6fd4c8f2-c0dc-4889-7b00-69b87b6c4a28"
      },
      "source": [
        "### Conclusions:\n",
        "\n",
        "Additional dataset can easily be purged of 2/3 of images either because of duplicates (triplicates, n-plicates), unrelated images, or blurry images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "58d58236-4b84-59da-7af6-b423ec2043ec"
      },
      "source": [
        "### Bonus\n",
        "Some advertisement for a cell phone company."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "db340a7f-2354-e5b7-be02-f06fda7dde99"
      },
      "outputs": [],
      "source": [
        "plot_from_path('Type_1/4065.jpg')\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}