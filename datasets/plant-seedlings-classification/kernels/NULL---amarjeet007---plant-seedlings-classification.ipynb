{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"import cv2                \nimport matplotlib.pyplot as plt                        \n%matplotlib inline                               \nfrom keras.preprocessing import image                  \nfrom tqdm import tqdm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6c94f958a5c303759b2d349676925f8a1748dd75"},"cell_type":"code","source":"CATEGORIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n              'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\nNUM_CATEGORIES = len(CATEGORIES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2f1aeab24033e1aee2c6e2e36929f52002b0ab52"},"cell_type":"code","source":"\ndata_dir = '../input/plant-seedlings-classification/'\ntrain_dir = os.path.join(data_dir, 'train')\ntest_dir = os.path.join(data_dir, 'test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21a91ddc7f44d213570de36f14287e639577a260","collapsed":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/plant-seedlings-classification/sample_submission.csv')\nsample_submission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe32bdfe204375bf996b6f82e491840a5c4599db","collapsed":true},"cell_type":"code","source":"for category in CATEGORIES:\n    print('{} {} images'.format(category, len(os.listdir(os.path.join(train_dir, category)))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13cfb126eb2fd283671361120583e0b2dce4cec2","collapsed":true},"cell_type":"code","source":"train = []\nfor category_id, category in enumerate(CATEGORIES):\n    for file in os.listdir(os.path.join(train_dir, category)):\n        train.append(['train/{}/{}'.format(category, file), category_id, category])\ntrain = pd.DataFrame(train, columns=['file', 'category_id', 'category'])\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5de911cf5457fcf0e6357455f2bd34ff24cc62cd","collapsed":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6576774d8e512d1fdb8e3adf96f2907daf4ccef","collapsed":true},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(x='category',data=train).set_title('distribution of different category');\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d74cec232721f12f83c87797b11ab6065ad2ca0a","collapsed":true},"cell_type":"code","source":"test = []\nfor file in os.listdir(test_dir):\n    test.append(['test/{}'.format(file), file])\ntest = pd.DataFrame(test, columns=['filepath', 'file'])\n\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"610536a29e4646cbb6fa57da1bfdf120ce5c952f","collapsed":true},"cell_type":"code","source":"test.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cc92d1955322250fd70981a46a70e9f3a5010d7e"},"cell_type":"code","source":"def read_img(filepath, size):\n    img = image.load_img(os.path.join(data_dir, filepath), target_size=size)\n    img = image.img_to_array(img)\n    img = np.array(img)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4455348adf507f293cb48d4a09b3d2bd79ff33e"},"cell_type":"markdown","source":"## loading training data"},{"metadata":{"trusted":true,"_uuid":"900b4879aca3fbd6cf435afa03f1789c3cbc9cb4","collapsed":true},"cell_type":"code","source":"x_train=[]\nfor file in tqdm(train['file']):\n    img = read_img(file, (224, 224))\n    x_train.append(img)\n\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a257e49325642eedc19fdb394a44333a3b256b86","collapsed":true},"cell_type":"code","source":"x_train=np.array(x_train)\nx_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b299228ebbdc29e8416f9c3534d69d612238bdee","collapsed":true},"cell_type":"code","source":"x_test=[]\nfor file in tqdm(test['filepath']):\n    img=read_img(file,(224,224))\n    x_test.append(img)\nx_test=np.array(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73c42a4b3f277973b83a16ccf48c650332865f9b","collapsed":true},"cell_type":"code","source":"\nx_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6f57899eb8d2011bfa5d6665f2aff969458c2ce"},"cell_type":"markdown","source":"## loading image labels of training data"},{"metadata":{"trusted":true,"_uuid":"f5368aab4617e9a3a465f7d20104022c78308af7","collapsed":true},"cell_type":"code","source":"y_train=train['category_id']\ny_train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01e1b9969e6e939d2689e41efa8d9ba34619317a"},"cell_type":"markdown","source":"## converting labels into one hot vectors"},{"metadata":{"trusted":true,"_uuid":"bba6d24a8e10dd841aaf3237114c50de2a609ebb","collapsed":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer \nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(y_train)\n\ny_train=label_binarizer.transform(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb24125542ee5a8f0072c16acd3c8c976acf1e17","collapsed":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a8fd8b32592ded13e9210a3a91119128d8c7f451"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, Y_train, Y_valid=train_test_split(x_train,y_train,test_size=0.05, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"626ccd4cb648a67a4fe3eda5767d5341955098ca"},"cell_type":"code","source":"X_train=X_train/255\nX_valid=X_valid/255\nx_test=x_test/255","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c78fb1c19ece5c81f86f7ddeae6f8ad42b21e8ba"},"cell_type":"markdown","source":"## image augmentation"},{"metadata":{"trusted":true,"_uuid":"ff092787faf512842a891a76498af169e8fe3c30","collapsed":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndatagen_train = ImageDataGenerator(\n    width_shift_range=0.2,  # randomly shift images horizontally \n    height_shift_range=0.2,# randomly shift images vertically \n    \n    horizontal_flip=True) # randomly flip images horizontally\n\n# fit augmented image generator on data\ndatagen_train.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77ee47be182b2fe04f8d3bc2d2addccc79061277","collapsed":true},"cell_type":"code","source":"from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout\nfrom keras.models import Sequential,Model\nfrom keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a193e1b2da0dccf6757747ed91341a5a6f3fa06"},"cell_type":"markdown","source":"## using pretrained keras model"},{"metadata":{"trusted":true,"_uuid":"1feed111d472ee6b3430e0dc4e5a40e643fa2dd2","collapsed":true},"cell_type":"code","source":"!ls ../input/keras-pretrained-models/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9860d3648a52154260905af3613a80a470f088bf"},"cell_type":"code","source":"cache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0309339aed8115b2516a9d42d53d5222cea8b420"},"cell_type":"code","source":"!cp ../input/keras-pretrained-models/vgg* ~/.keras/models/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d19e9db93afe21188c8067136ae9b8e71473fdb9","collapsed":true},"cell_type":"code","source":"!ls ~/.keras/models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ed82a8a2b3fbd1ec9d9f378f1e9f16fd8631ab6f"},"cell_type":"code","source":"from keras import applications\nmodel = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (224, 224, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0868ad18a0d562a8a9947bec674cf327a6fbf9c","collapsed":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e54c0c3749227359b2f49247236335e07eaf6944"},"cell_type":"markdown","source":"### Freeze all layers "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f8373ff6e927d9f6d0f22e11c64c2ab230ac7008"},"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc21408e919773c3c7ba355220c964ade03b678f","collapsed":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3fc51fd6c39fe36a959e4bc4dca46942b1302689"},"cell_type":"markdown","source":"### Adding Fully connected layers"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7192f6b4574a4c2670cc1d958bd29fa663efe320"},"cell_type":"code","source":"x = model.output\n\n\n\nx = Flatten()(x)\nx = Dense(128, activation=\"relu\")(x)\nx = Dropout(0.4)(x)\npredictions = Dense(12, activation=\"softmax\")(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3813ddfbbde3c7db3381088ab022fe45adee2b7d","collapsed":true},"cell_type":"code","source":"model_final = Model(input = model.input, output = predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fd21966f38b10d5b5282aa7921e0e873786ba2f5"},"cell_type":"code","source":"model_final.compile(loss = \"categorical_crossentropy\",  optimizer ='adam', metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1dea13d465a9de2c0e4a47b49c0251e42055d0a7"},"cell_type":"code","source":"checkpointer = ModelCheckpoint(filepath='vgg16.hdf5', verbose=1, save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1552e8413a6317232bcba3f50f4ee31608941f35","collapsed":true},"cell_type":"code","source":"'''\nmodel_final.fit_generator(datagen_train.flow(X_train, Y_train, batch_size=16), validation_data=(X_valid, Y_valid),\n                         epochs=2,steps_per_epoch=X_train.shape[0],callbacks=[checkpointer], verbose=1)\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbc1df85c08907436d032d54d198ac2614f0b347"},"cell_type":"markdown","source":"## But we can not train this network on kaggle because we need GPU for that"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"91db00fbbe24e25f4f9a2cc8ae93cb2c63cdc3ea"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}