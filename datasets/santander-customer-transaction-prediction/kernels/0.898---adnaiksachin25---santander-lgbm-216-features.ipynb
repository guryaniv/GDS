{"cells":[{"metadata":{"_uuid":"2b1ff554f31584d088f64d8d34c6c74c0186c13e"},"cell_type":"markdown","source":"In this notebook, I will be using LGBM for prediction of our target variable. \nMost of the kagglers tried creating features from row-wise summary of existing features.\nI continued with the same approach but not for all features, some based on features with positive \nmean and some based on those features with negative mean...Let's start..\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\nfrom sklearn import metrics\nimport gc\n\npd.set_option('display.max_columns', 200)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Lets import data sets\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bccb33cd75797351fbd8716d50eaa2ddaae31d4f"},"cell_type":"markdown","source":"Lets have a look of our data sets"},{"metadata":{"trusted":true,"_uuid":"78cbeb94ac815b7291b446f1d5694d97fddc3546"},"cell_type":"code","source":"print(train_df.head())\nprint(test_df.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0e5f4b4db3fb0dd76d47b0139333bce2d5f0995"},"cell_type":"markdown","source":"Lets extract predictors for some feature engineering"},{"metadata":{"trusted":true,"_uuid":"70222ad190888ba89509874016073ba8a8a445b4"},"cell_type":"code","source":"predictors=train_df.columns[2:]\npredictors","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc22d7c7c02621823ae6c77402f4b42cdfb0590f"},"cell_type":"markdown","source":"Lets separate features with positive mean and negative mean values"},{"metadata":{"trusted":true,"_uuid":"13a570e4b657f8bfef722fa2db99a74fcdffb14c"},"cell_type":"code","source":"pos=predictors[train_df[predictors].mean()>0]\nneg=predictors[train_df[predictors].mean()<=0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3034251057b0cc2b6006f3f4d3c9e06d164df5b"},"cell_type":"markdown","source":"Lets add features derived from row-wise summary of existing features with positive mean"},{"metadata":{"trusted":true,"_uuid":"52bcd45c6686fb25cffb5ebd930be7090512c14b"},"cell_type":"code","source":"idx = features = pos\nfor df in [train_df, test_df]:\n    df['sum_pos'] = df[idx].sum(axis=1)  \n    df['min_pos'] = df[idx].min(axis=1)\n    df['max_pos'] = df[idx].max(axis=1)\n    df['mean_pos'] = df[idx].mean(axis=1)\n    df['std_pos'] = df[idx].std(axis=1)\n    df['skew_pos'] = df[idx].skew(axis=1)\n    df['kurt_pos'] = df[idx].kurtosis(axis=1)\n    df['med_pos'] = df[idx].median(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d568635fcc34a41fa1b42f3aecf97907752499dd"},"cell_type":"markdown","source":"Lets add features derived from row-wise summary of existing features with negative mean"},{"metadata":{"trusted":true,"_uuid":"f970eef9e1bd52afa71474be1e9530e11f71b226"},"cell_type":"code","source":"idx = features = neg\nfor df in [train_df, test_df]:\n    df['sum_neg'] = df[idx].sum(axis=1)  \n    df['min_neg'] = df[idx].min(axis=1)\n    df['max_neg'] = df[idx].max(axis=1)\n    df['mean_neg'] = df[idx].mean(axis=1)\n    df['std_neg'] = df[idx].std(axis=1)\n    df['skew_neg'] = df[idx].skew(axis=1)\n    df['kurt_neg'] = df[idx].kurtosis(axis=1)\n    df['med_neg'] = df[idx].median(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15cf6ecd2b1d27335f4f4abe3317d9a550355664"},"cell_type":"markdown","source":"Lets have a look of our data sets"},{"metadata":{"trusted":true,"_uuid":"d8cdb54c909ddca29604314cb61fc040b44fa2a5"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e49d1f09604dd15f3a0993b05575fa4cdba4755"},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47cebc6288ee6eda8c63ff45e88aa22996f1b534"},"cell_type":"markdown","source":"Now lets define parameters for LGBM"},{"metadata":{"trusted":true,"_uuid":"356b698efb0fab04cddf04b3b9d278e633c69183"},"cell_type":"code","source":"param = {\n    'num_leaves': 25,\n     'max_bin': 60,\n     'min_data_in_leaf': 5,\n     'learning_rate': 0.010614430970330217,\n     'min_sum_hessian_in_leaf': 0.0093586657313989123,\n     'feature_fraction': 0.056701788569420042,\n     'lambda_l1': 0.060222413158420585,\n     'lambda_l2': 4.6580550589317573,\n     'min_gain_to_split': 0.29588543202055562,\n     'max_depth': 50,\n     'save_binary': True,\n     'seed': 1234,\n     'feature_fraction_seed': 1234,\n     'bagging_seed': 1234,\n     'drop_seed': 1234,\n     'data_random_seed': 1234,\n     'objective': 'binary',\n     'boosting_type': 'gbdt',\n     'verbose': 1,\n     'metric': 'auc',\n     'is_unbalance': True,\n     'boost_from_average': False\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5c808f24299e96b45950731af2e86a79ef260e8"},"cell_type":"code","source":"# number of folds\nnfold = 10 ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a85448f0f80aa36ff4f109ccde325b0dbc2bc311"},"cell_type":"markdown","source":"Define our target variable and predictors"},{"metadata":{"trusted":true,"_uuid":"5a223a2ada0f36c2f77a532aca87226707dcd55b"},"cell_type":"code","source":"target = 'target'\npredictors = train_df.columns.values.tolist()[2:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b368cc26862157cee8363cc599508175f9ddf75b"},"cell_type":"markdown","source":"Lets build model using LGBM"},{"metadata":{"trusted":true,"_uuid":"f4fdf326fc7db1bda809a7b386503b4c08a64b37"},"cell_type":"code","source":"skf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=2019)\n\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\n\ni = 1\nfor train_index, valid_index in skf.split(train_df, train_df.target.values):\n    print(\"\\nfold {}\".format(i))\n    xg_train = lgb.Dataset(train_df.iloc[train_index][predictors].values,\n                           label=train_df.iloc[train_index][target].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )\n    xg_valid = lgb.Dataset(train_df.iloc[valid_index][predictors].values,\n                           label=train_df.iloc[valid_index][target].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )   \n\n    nround = 8000\n    clf = lgb.train(param, xg_train, nround, valid_sets = [xg_valid], verbose_eval=250)\n    oof[valid_index] = clf.predict(train_df.iloc[valid_index][predictors].values, num_iteration=nround) \n    \n    predictions += clf.predict(test_df[predictors], num_iteration=nround) / nfold\n    i = i + 1\n\nprint(\"\\n\\nCV AUC: {:<0.4f}\".format(metrics.roc_auc_score(train_df.target.values, oof)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ae852b936b6c3c19f613c3ecb44131c69dabcc0"},"cell_type":"markdown","source":"Create submission file and have a look of it..."},{"metadata":{"trusted":true,"_uuid":"e68678f20bd04f55bd251513cb3bf606f0ac05af"},"cell_type":"code","source":"submission = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\nsubmission[\"target\"] = predictions\nsubmission[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0dcbbd1898abc55c0477b5ae0fe9c6343b124e4f"},"cell_type":"markdown","source":"Lets submit our predictions"},{"metadata":{"trusted":true,"_uuid":"71a8e4a7c5f635f1ed19116482ba753fc7ed3590"},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"143bd4f7619ca82c28160716fca8ccf26b6a1b2d"},"cell_type":"markdown","source":"Hope my work helps some kagglers to improve their solutions...\n### Thanks a lot"},{"metadata":{"_uuid":"f142e24ebb574ff8f17c1baa315b7a56aa3f54a7"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"2c4661bed2bfcb3d8df426991e8809ac2ab761f0"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}