{"nbformat_minor": 1, "nbformat": 4, "metadata": {"language_info": {"pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "cells": [{"execution_count": null, "outputs": [], "metadata": {"_uuid": "c20c67f2226b24051e2d64a63555059d96969829", "_cell_guid": "37070448-9c94-480d-8ad4-55d84b7349b0", "collapsed": true}, "cell_type": "code", "source": ["#required libraries\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import csv\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "import re\n", "# Evalaluation\n", "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn import metrics\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n", "from sklearn.preprocessing import LabelBinarizer\n", "import scipy\n", "import lightgbm as lgb\n", "from sklearn.linear_model import Ridge\n", "import time\n", "import gc\n", "from scipy.sparse import csr_matrix, hstack"]}, {"metadata": {"_uuid": "a2348f9930d43043468acba9966cafa05f7864d4", "_cell_guid": "406b37d4-0de2-4ce0-92f3-c633dc48df4e"}, "cell_type": "markdown", "source": ["**It's always a good practice to specify the dtypes**"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "bcfc222d3594290f1e193be174a186425c4dec9a", "_cell_guid": "a52ff5a1-c462-4688-9c9b-11e61649847a", "collapsed": true}, "cell_type": "code", "source": ["types_dict_train = {'train_id': 'int64',\n", "             'item_condition_id': 'int64',\n", "             'price': 'float64',\n", "             'shipping': 'int64'}\n", "types_dict_test = {'test_id': 'int64',\n", "             'item_condition_id': 'int64',\n", "             'shipping': 'int64'}"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "621c94f04f2d4da6ee1234adf9cc4db7173630a1", "_cell_guid": "13acc905-7816-4194-8f8a-4f115224cbd1", "collapsed": true}, "cell_type": "code", "source": ["#read the datasets\n", "train = pd.read_csv('../input/train.tsv', sep='\\t', encoding='utf-8', dtype=types_dict_train)\n", "test=pd.read_csv('../input/test.tsv', sep='\\t', encoding='utf-8', dtype=types_dict_train)"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "522ebae3c614166548cf9ee8196b88b62f81a79e", "_cell_guid": "3b6e60ca-64f4-4403-90b9-d860ba5d18f2", "collapsed": true}, "cell_type": "code", "source": ["#shape of the datasets\n", "print(train.shape)\n", "print(test.shape)"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "32fd34a81140c7f44614f9866a78599d769c85e7", "_cell_guid": "2bc4542d-66d7-482e-a827-f99b3f032e00", "collapsed": true}, "cell_type": "code", "source": ["#check the datatype of training dataset\n", "print(train.dtypes)\n"]}, {"metadata": {"_uuid": "fc33c1ff8e68ea214530a91b94946181b3886916", "_cell_guid": "3d3d3a2f-628e-41fa-870a-b99499e9e78b"}, "cell_type": "markdown", "source": ["**The training dataset has two types of data-\n", "Strings:name,category_name,brand_name,item_description\n", "Numeric:train_id,item_condition_id,shipping,price**"]}, {"metadata": {"_uuid": "f3b3106339a426a79ea14411bf249db001f59eaa", "_cell_guid": "626ffc2b-ca14-4f96-9760-af04d2897987"}, "cell_type": "markdown", "source": ["**Here all categorical variables are stored as 'object' data type.\n", "So I am going to convert them into Pandas Category**"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "029c6d3e90219811fb9726933e16818da10b1817", "_cell_guid": "1851ea7f-0c22-49a4-9afa-d20f9b40658a", "collapsed": true}, "cell_type": "code", "source": ["train.category_name = train.category_name.astype('category')\n", "train.item_description = train.item_description.astype('category')\n", "\n", "train.name = train.name.astype('category')\n", "train.brand_name = train.brand_name.astype('category')\n", "\n", "test.category_name = test.category_name.astype('category')\n", "test.item_description = test.item_description.astype('category')\n", "\n", "test.name = test.name.astype('category')\n", "test.brand_name = test.brand_name.astype('category')"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "1e7b55d05e644be7a57618d129d734213fb4093f", "_cell_guid": "2032c17b-6cec-4884-aa8c-128be85d566d", "collapsed": true}, "cell_type": "code", "source": ["#let's find out the count of distinct values in each column using Pandas\n", "print(\"count of distinct values in train dataset:\")\n", "train.apply(lambda x: x.nunique())"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "a4042fca7754630e5e2a1080ce047c538778ffd6", "_cell_guid": "c96a70c9-1454-4d40-9112-60f71c10a749", "collapsed": true}, "cell_type": "code", "source": ["#let's find out the count of distinct values in each column using Pandas\n", "print(\"count of distinct values in test dataset:\")\n", "test.apply(lambda x: x.nunique())"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "39442bd2d2ab98bc6e40fa776d1bf8f17663df79", "_cell_guid": "423bdcb7-aca6-4718-a672-5ca8c068c033", "collapsed": true}, "cell_type": "code", "source": ["#let's find out the missing values\n", "train.isnull().sum(),train.isnull().sum()/train.shape[0]"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "2f8b3b164510f3931c0a1447ae5a83bddd560805", "_cell_guid": "2a77b078-e305-4659-abc0-d5cddfe04303", "collapsed": true}, "cell_type": "code", "source": ["#let's find out the missing values\n", "test.isnull().sum(),test.isnull().sum()/test.shape[0]"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "6207e49f0e069f99f105ede4707526f248cbb545", "_cell_guid": "c4ac2d03-f2c4-4f34-860c-7e4dbfa3d29c", "collapsed": true}, "cell_type": "code", "source": ["#peek of the training dataset\n", "train.head()"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "6cf17f0391c47f7906bb8580e3a58127eb44e82a", "_cell_guid": "2c227b7a-4600-4312-b011-9c1776b40011", "collapsed": true}, "cell_type": "code", "source": ["#peek of the test dataset\n", "test.head()"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "108c15df51dcb506c23d374ae82d91895f5da0ae", "_cell_guid": "e6c7ef4d-6d74-4adb-ba1e-622a3a77df01", "collapsed": true}, "cell_type": "code", "source": ["#changing train_id/test_id as id column\n", "train = train.rename(columns = {'train_id':'id'})\n", "test = test.rename(columns = {'test_id':'id'})"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "4c6945a4ddd470423d1ff91a51400c6215e8a2ea", "_cell_guid": "199621a2-5874-4c51-825c-2e583e769f54", "collapsed": true}, "cell_type": "code", "source": ["train.head()"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "8e1e2cb665a1414adf222250b69da69ead452fe7", "_cell_guid": "275b2bfd-29e6-4a61-98ae-42e19cead8a7", "collapsed": true}, "cell_type": "code", "source": ["train['is_train'] = 1\n", "test['is_train'] = 0"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "f2a6e0574d6d26f8f75bf92de0ba7705ec4fbe71", "_cell_guid": "9b18b68e-ccc8-41bd-90ee-4a1104dc7946", "collapsed": true}, "cell_type": "code", "source": ["test.head()"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "5e9744e1756d0ea8d11348f140a7bbe2cf1afc72", "_cell_guid": "3110f83e-3c75-4d02-a8ed-85dbbf5d9f07", "collapsed": true}, "cell_type": "code", "source": ["#seperate the target variable and combine the dataset\n", "train_test_combine = pd.concat([train.drop(['price'],axis =1),test],axis = 0)\n", "train_test_combine.category_name = train_test_combine.category_name.astype('category')\n", "train_test_combine.item_description = train_test_combine.item_description.astype('category')\n", "train_test_combine.name = train_test_combine.name.astype('category')\n", "train_test_combine.brand_name = train_test_combine.brand_name.astype('category')"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "8b495e350743c4a8b0d35f8237c082585b8912d9", "_cell_guid": "eb65da05-83ff-4852-b022-3a37ee01b820", "collapsed": true}, "cell_type": "code", "source": ["#droping item description since I don't know about NLP and deep learning\n", "train_test_combine = train_test_combine.drop(['item_description'],axis = 1)"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "c6208ec9cce53359bb45ca210ef4f43267c76ec7", "_cell_guid": "56699f98-d540-4b90-a606-fdc6aa165842", "collapsed": true}, "cell_type": "code", "source": ["#get numeric from categorical variables\n", "train_test_combine.name = train_test_combine.name.cat.codes\n", "train_test_combine.category_name = train_test_combine.category_name.cat.codes\n", "train_test_combine.brand_name = train_test_combine.brand_name.cat.codes"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "d6f3fca61d437fe4fe7243882c459456bf434222", "_cell_guid": "b76fd4ed-56e0-4bdd-a4b2-684da4e2a7b7", "collapsed": true}, "cell_type": "code", "source": ["train_test_combine.head()"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "e39dfb9c494f077529687c26b050a683be796e3a", "_cell_guid": "2c28eb75-a1c5-4c5c-8751-e301f520f947", "collapsed": true}, "cell_type": "code", "source": ["train_test_combine.dtypes"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "98b00a75a2e8788b749acd03ab828239a3f1081d", "_cell_guid": "24586a1e-3b10-4424-8219-5a2d2244f7b0", "collapsed": true}, "cell_type": "code", "source": ["df_test = train_test_combine.loc[train_test_combine['is_train']==0]\n", "df_train = train_test_combine.loc[train_test_combine['is_train']==1]"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "f169c9b9e804ded976e809ded6e9bc3d52544f39", "_cell_guid": "f2e0c056-9eba-4b01-88b4-9224c3d2737d", "collapsed": true}, "cell_type": "code", "source": ["df_test = df_test.drop(['is_train'],axis=1)"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "97904bb8e2e5abcda5717ea4afa96783fa277015", "_cell_guid": "ccba0271-57cf-4fc3-80f8-0e13a5c1e406", "collapsed": true}, "cell_type": "code", "source": ["df_train = df_train.drop(['is_train'],axis=1)"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "d892d0d4dd944ba22e90178810873b538bc710cc", "_cell_guid": "03082ffd-f601-48f7-a70d-e471b6c52fc8", "collapsed": true}, "cell_type": "code", "source": ["#save the target variable from train dataframe\n", "df_train['price'] = train.price"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "3b6f455458e6b4c52074e0b3aa2deb1ab8821b8a", "_cell_guid": "f738a6de-8021-4fcb-8869-db7c515b3d23", "collapsed": true}, "cell_type": "code", "source": ["#taking the log of price\n", "df_train['price'] = df_train['price'].apply(lambda x: np.log(x) if x>0 else x)"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "7a66f14bcecc9583bb2cb11e76a3b721e4db80ea", "_cell_guid": "fc1fe3f8-caff-4a82-9ad3-51ae20f84e64", "collapsed": true}, "cell_type": "code", "source": ["x_train,y_train = df_train.drop(['price'],axis =1),df_train.price"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "a86e9a43f14f775896a4ef24f96414ed830ba7af", "_cell_guid": "3662af93-71f9-49ff-9248-226e4566c59a", "collapsed": true}, "cell_type": "code", "source": ["#modeling the problem\n", "randomfr = RandomForestRegressor(n_jobs=-1,min_samples_leaf=3,n_estimators=200)\n", "randomfr.fit(x_train, y_train)\n", "randomfr.score(x_train,y_train)"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "7b082d7d9ea8d54bb26a58e6b81d2ca893fc3cfb", "_cell_guid": "493f8783-2222-43e6-962e-3b8c25e0ea49", "collapsed": true}, "cell_type": "code", "source": ["preds = randomfr.predict(df_test)"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "b5ee1e007f764cffb81ab8229a20811d907f1934", "_cell_guid": "51199bde-8ef3-4f62-a963-38db68314617", "collapsed": true}, "cell_type": "code", "source": ["preds = pd.Series(np.exp(preds))"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "9b90ac0c04152c8ce8c206639b4474d4099398e9", "_cell_guid": "908c9129-e7cb-4e8c-b4f7-3b8a6dab1b2d", "collapsed": true}, "cell_type": "code", "source": ["submit = pd.concat([df_test.id,preds],axis=1)\n", "submit.columns = ['test_id','price']\n", "submit.to_csv(\"./firstoutput.csv\", index=False)"]}, {"metadata": {"_uuid": "0496a5c128226254efe0428fdffb05e5a042b05d", "_cell_guid": "55c0b0b0-3f48-46b8-b5e0-2638b49dc0c8"}, "cell_type": "markdown", "source": ["**From the RandomForest I got a score of 0.53854**\n", "**Let's try to improve the score by applying light GBM**"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "b2d567d9f9e1867f8ea410fca1f1382bddf16c70", "_cell_guid": "688f9629-9108-44ca-9be4-75ed709200e8", "collapsed": true}, "cell_type": "code", "source": ["import lightgbm as lgb\n", "from sklearn.linear_model import Ridge, LogisticRegression\n", "params = {\n", "    'learning_rate': 0.75,\n", "    'application': 'regression',\n", "    'max_depth': 3,\n", "    'num_leaves': 100,\n", "    'verbosity': -1,\n", "    'metric': 'RMSE',\n", "}\n", "train_X, valid_X, train_y, valid_y = train_test_split(x_train, y_train, test_size = 0.1, random_state = 144) \n", "d_train = lgb.Dataset(train_X, label=train_y, max_bin=8192)\n", "d_valid = lgb.Dataset(valid_X, label=valid_y, max_bin=8192)\n", "watchlist = [d_train, d_valid]\n", "\n", "model = lgb.train(params, train_set=d_train, num_boost_round=2200, valid_sets=watchlist, \\\n", "early_stopping_rounds=50, verbose_eval=100) \n", "preds = model.predict(df_test)\n", "\n", "model = Ridge(solver = \"lsqr\", fit_intercept=False)\n", "\n", "print(\"Fitting Model\")\n", "model.fit(x_train, y_train)\n", "\n", "#preds += model.predict(df_test)\n", "#preds /= 2\n", "#preds = np.expm1(preds)\n", "preds = pd.Series(np.exp(preds))\n", "submit = pd.concat([df_test.id,preds],axis=1)\n", "submit.columns = ['test_id','price']\n", "submit.to_csv(\"./submissionusinglgb.csv\", index=False)"]}, {"metadata": {"_uuid": "4585810349afb324e3e6dbfca84e4298063227f1", "_cell_guid": "ee5232df-01c1-4a69-b065-667db16a582d"}, "cell_type": "markdown", "source": ["**The Light GBM algorithm improves my score from 0.53854 to 0.53284 which improves my rank 6 places up**"]}, {"metadata": {"_uuid": "68d65f3391eb87f75a465866c8177dbf2feb0f39", "_cell_guid": "1d9a29d5-03ff-4ca0-94a1-70092d6386ac"}, "cell_type": "markdown", "source": ["**For improving the model I need to work on the categorical variables more, so let's try new approach**"]}, {"metadata": {"_uuid": "bea405fafc7022bb4da5ded1983ea9fc70389144", "_cell_guid": "412335f7-46e1-43ee-bede-020c992dcc13"}, "cell_type": "markdown", "source": ["\"\"\"Reference:https://www.kaggle.com/tunguz/more-effective-ridge-lgbm-script-lb-0-44944\"\"\""]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "503ff70b3b2ebc5b014a1d610d7a71e663170588", "_cell_guid": "0b85f754-f8a2-4639-b9c1-baa4cf6814e1", "collapsed": true}, "cell_type": "code", "source": ["NUM_BRANDS = 4000\n", "NUM_CATEGORIES = 1000\n", "NAME_MIN_DF = 10\n", "MAX_FEATURES_ITEM_DESCRIPTION = 50000"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "f8c11def62bb51ba20ca81707051d58d5626479c", "_cell_guid": "5dfe01e4-1640-4b5a-ab31-f8e281f74583", "collapsed": true}, "cell_type": "code", "source": ["def handle_missing_inplace(dataset):\n", "    dataset['category_name'].fillna(value='missing', inplace=True)\n", "    dataset['brand_name'].fillna(value='missing', inplace=True)\n", "    dataset['item_description'].fillna(value='missing', inplace=True)"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "9b5733e51c300542bb9da8e45f069e35a8dcc33d", "_cell_guid": "365cc6c8-a6c9-4234-bd74-5f5578ced253", "collapsed": true}, "cell_type": "code", "source": ["#dealing with missing values in categorical variables\n", "def cutting(dataset):\n", "    pop_brand = dataset['brand_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n", "    dataset.loc[~dataset['brand_name'].isin(pop_brand), 'brand_name'] = 'missing'\n", "    pop_category = dataset['category_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n", "    dataset.loc[~dataset['category_name'].isin(pop_category), 'category_name'] = 'missing'\n", "\n", "def to_categorical(dataset):\n", "    dataset['category_name'] = dataset['category_name'].astype('category')\n", "    dataset['brand_name'] = dataset['brand_name'].astype('category')\n", "    dataset['item_condition_id'] = dataset['item_condition_id'].astype('category')"]}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "98b1661bba1d9f9e6a6b0658ca5f89916ec69dfa", "_cell_guid": "285c8d30-c9c5-4634-a562-764a60b5d9f5"}, "cell_type": "code", "source": ["def main():\n", "    start_time = time.time()\n", "\n", "    train = pd.read_table('../input/train.tsv', engine='c')\n", "    test = pd.read_table('../input/test.tsv', engine='c')\n", "    print('[{}] Finished to load data'.format(time.time() - start_time))\n", "    print('Train shape: ', train.shape)\n", "    print('Test shape: ', test.shape)\n", "\n", "    nrow_train = train.shape[0]\n", "    y = np.log1p(train[\"price\"])\n", "    merge: pd.DataFrame = pd.concat([train, test])\n", "    submission: pd.DataFrame = test[['test_id']]\n", "\n", "    del train\n", "    del test\n", "    gc.collect()\n", "\n", "    handle_missing_inplace(merge)\n", "    print('[{}] Finished to handle missing'.format(time.time() - start_time))\n", "\n", "    cutting(merge)\n", "    print('[{}] Finished to cut'.format(time.time() - start_time))\n", "\n", "    to_categorical(merge)\n", "    print('[{}] Finished to convert categorical'.format(time.time() - start_time))\n", "\n", "    cv = CountVectorizer(min_df=NAME_MIN_DF)\n", "    X_name = cv.fit_transform(merge['name'])\n", "    print('[{}] Finished count vectorize `name`'.format(time.time() - start_time))\n", "\n", "    cv = CountVectorizer()\n", "    X_category = cv.fit_transform(merge['category_name'])\n", "    print('[{}] Finished count vectorize `category_name`'.format(time.time() - start_time))\n", "\n", "    tv = TfidfVectorizer(max_features=MAX_FEATURES_ITEM_DESCRIPTION,\n", "                         ngram_range=(1, 3),\n", "                         stop_words='english')\n", "    X_description = tv.fit_transform(merge['item_description'])\n", "    print('[{}] Finished TFIDF vectorize `item_description`'.format(time.time() - start_time))\n", "\n", "    lb = LabelBinarizer(sparse_output=True)\n", "    X_brand = lb.fit_transform(merge['brand_name'])\n", "    print('[{}] Finished label binarize `brand_name`'.format(time.time() - start_time))\n", "\n", "    X_dummies = csr_matrix(pd.get_dummies(merge[['item_condition_id', 'shipping']],\n", "                                          sparse=True).values)\n", "    print('[{}] Finished to get dummies on `item_condition_id` and `shipping`'.format(time.time() - start_time))\n", "\n", "    sparse_merge = hstack((X_dummies, X_description, X_brand, X_category, X_name)).tocsr()\n", "    print('[{}] Finished to create sparse merge'.format(time.time() - start_time))\n", "\n", "    X = sparse_merge[:nrow_train]\n", "    X_test = sparse_merge[nrow_train:]\n", "    \n", "    d_train = lgb.Dataset(X, label=y, max_bin=8192)\n", "    \n", "    params = {\n", "        'learning_rate': 0.75,\n", "        'application': 'regression',\n", "        'max_depth': 3,\n", "        'num_leaves': 100,\n", "        'verbosity': -1,\n", "        'metric': 'RMSE',\n", "    }\n", "    \n", "    model = lgb.train(params, train_set=d_train, num_boost_round=3200,  \\\n", "    verbose_eval=100) \n", "    preds = 0.6*model.predict(X_test)\n", "\n", "    model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205)\n", "    model.fit(X, y)\n", "    print('[{}] Finished to train ridge'.format(time.time() - start_time))\n", "    preds += 0.4*model.predict(X=X_test)\n", "    print('[{}] Finished to predict ridge'.format(time.time() - start_time))\n", "\n", "    submission['price'] = np.expm1(preds)\n", "    submission.to_csv(\"Thirdsubmission_lgbm_ridge.csv\", index=False)\n", "\n", "if __name__ == '__main__':\n", "    main()"]}]}