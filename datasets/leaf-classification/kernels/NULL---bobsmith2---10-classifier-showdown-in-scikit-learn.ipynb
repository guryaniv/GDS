{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3bb42045-03bc-0ca3-36c9-9379444c88b1",
        "_active": false
      },
      "source": "# Which Classifier is Should I Choose? \n\nThis is one of the most import questions to ask when approaching a machine learning problem. I find it easier to just test them all at once. Here's 10 of your favorite Scikit-Learn algorithms applied to the leaf data. ",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "_cell_guid": "e86aec01-dbc6-4696-e066-6da72fedd092",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef warn(*args, **kwargs): pass\nimport warnings\nwarnings.warn = warn\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cross_validation import StratifiedShuffleSplit\nfrom keras.utils import np_utils\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5de1ab5b-9b22-2375-4705-f6d12e9d3046",
        "_active": false
      },
      "source": "## Data Preparation",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "361c2695-95c0-745a-0336-a49f6dec97b2",
        "_active": false
      },
      "outputs": [],
      "source": "# Swiss army knife function to organize the data\n\ndef encode(train, test):\n    le = LabelEncoder().fit(train.species) \n    labels = le.transform(train.species)           # encode species strings\n    classes = list(le.classes_)                    # save column names for submission\n    test_ids = test.id                             # save test ids for submission\n    \n    train = train.drop(['species', 'id'], axis=1)  \n    test = test.drop(['id'], axis=1)\n    \n    return train, labels, test, test_ids, classes\n\ntrain, labels, test, test_ids, classes = encode(train, test)\ntrain.head(1)",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3222a1a2-6df6-e5a6-2c4d-65383fc9ee66",
        "_active": false
      },
      "source": "## Stratified Train/Test Split\n\nStratification is necessary for this dataset because there is a relatively large number of classes (100 classes for 990 samples). This will ensure we have all classes represented in both the train and test indices. ",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "_cell_guid": "7c91b9c9-3b4d-73ac-92d8-db0792f60a3e",
        "_active": false
      },
      "outputs": [],
      "source": "sss = StratifiedShuffleSplit(labels, 10, test_size=0.2, random_state=23)\n\nfor train_index, test_index in sss:\n    X_train, X_test = train.values[train_index], train.values[test_index]\n    y_train, y_test = labels[train_index], labels[test_index]",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e1172a79-cdc8-6544-2580-4a58ee9fb434",
        "_active": false
      },
      "source": "## Sklearn Classifier Showdown\n\nSimply looping through 10 out-of-the box classifiers and printing the results. Obviously, these will perform much better after tuning their hyperparameters, but this gives you a decent ballpark idea. ",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "_cell_guid": "fb7913b9-e36d-ef8b-a012-cc708b583ab4",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "from sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nclassifiers = [\n    KNeighborsClassifier(1),\n    KNeighborsClassifier(2),\n    KNeighborsClassifier(3),\n    KNeighborsClassifier(4),\n    KNeighborsClassifier(5),\n    KNeighborsClassifier(6),\n    RandomForestClassifier(n_estimators=5),\n    RandomForestClassifier(n_estimators=10),\n    RandomForestClassifier(n_estimators=20),\n    RandomForestClassifier(n_estimators=30),\n    RandomForestClassifier(n_estimators=35),\n    RandomForestClassifier(n_estimators=40),\n    RandomForestClassifier(n_estimators=45),\n    RandomForestClassifier(n_estimators=49),\n    RandomForestClassifier(n_estimators=50),\n    RandomForestClassifier(n_estimators=51),\n    RandomForestClassifier(n_estimators=55),\n    RandomForestClassifier(n_estimators=60),\n    RandomForestClassifier(n_estimators=100),\n    LinearDiscriminantAnalysis(solver='svd'),\n    LinearDiscriminantAnalysis(solver='lsqr'),\n    LinearDiscriminantAnalysis(solver='eigen')]\n\n# Logging for Visual Comparison\nlog_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\nlog = pd.DataFrame(columns=log_cols)\n\nfor clf in classifiers:\n    clf.fit(X_train, y_train)\n    name = clf.__class__.__name__\n    \n    print(\"=\"*30)\n    print(name)\n    \n    print('****Results****')\n    train_predictions = clf.predict(X_test)\n    acc = accuracy_score(y_test, train_predictions)\n    print(\"Accuracy: {:.4%}\".format(acc))\n    \n    train_predictions = clf.predict_proba(X_test)\n    ll = log_loss(y_test, train_predictions)\n    print(\"Log Loss: {}\".format(ll))\n    \n    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n    log = log.append(log_entry)\n    \nprint(\"=\"*30)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "_cell_guid": "5d972faa-01b5-f354-155b-9ab11cb9ab63",
        "_active": false
      },
      "outputs": [],
      "source": "sns.set_color_codes(\"muted\")\nsns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n\nplt.xlabel('Accuracy %')\nplt.title('Classifier Accuracy')\nplt.show()\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x='Log Loss', y='Classifier', data=log, color=\"g\")\n\nplt.xlabel('Log Loss')\nplt.title('Classifier Log Loss')\nplt.show()",
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "9fe10a49-f277-b3b8-296a-3950a9196b2f",
        "_active": false,
        "collapsed": false
      },
      "source": "# Predict Train Set\nstarting_clf = LinearDiscriminantAnalysis(solver='svd')\nstarting_clf.fit(X_train, y_train)\nX_train_predictions = starting_clf.predict(X_train)\n#X_train_predictions = starting_clf.predict_proba(X_train)\nX_test_predictions = starting_clf.predict(X_test)\n# Annotating Train Set\n#print(X_train.shape)\n#print(X_train_predictions.shape)\n#z_train = np.concatenate((X_train, X_train_predictions), axis=1)\n#print(z_train.shape)\n\n# Annotating Test Set\n#z_test_predictions = starting_clf.predict_proba(X_test)\n#z_test = np.concatenate((X_test, z_test_predictions), axis=1)\n\nprint(y_train.shape)\nprint('='*5)\nprint(X_train_predictions.shape)\nprint('M'*5)\nprint(y_train[0])\nprint('W'*5)\n\nz_test = y_test\nfor i in range(len(X_test_predictions)):\n    if (X_test_predictions[i] == y_test[i]):\n        z_test[i] = -1\n\n#y_train_oh = np_utils.to_categorical(y_train, 99)\n#z_train_proba = np.subtract(y_train_oh, X_train_predictions)\n#X_test_predictions = starting_clf.predict_proba(X_test)\n\n#for i in range(len(z_train)):\n#if (z_train_proba.shape[-1] > 1):\n#z_train = z_train_proba.argmax(axis=-1)\n#else:\n#    z_train = (z_train_proba > 0.5).astype('int32')\n\n#print(type(z_train))\nprint('W'*5)\nprint(z_train.shape)\nprint(z_train[0:5])\nprint(y_train.shape)\nprint(z_train > -1)\n#print(z_train_proba.shape[-1] > 1)",
      "execution_count": 65,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "a3fce05f-e13e-c5d7-a928-1613a335d21e",
        "_active": true,
        "collapsed": false
      },
      "source": "# Testing classifiers on the residual\n\nfor clf in classifiers:\n    clf.fit(X_test, z_test)\n    name = clf.__class__.__name__\n    \n    print(\"=\"*30)\n    print(name)\n    \n    print('****Results****')\n    train_predictions0 = starting_clf.predict(X_test)\n    train_predictions1 = clf.predict(X_test)\n    train_predictions0_ll = starting_clf.predict_proba(X_test)\n    train_predictions1_ll = clf.predict_proba(X_test)\n\n    print(train_predictions0.shape)\n    print(train_predictions1.shape)\n    print(train_predictions0_ll.shape)\n    print(train_predictions1_ll.shape)\n\n    train_predictions_ll = train_predictions1_ll\n    \n    for j in range(len(train_predictions1)):\n        if (train_predictions1[j] == -1):\n            train_predictions[j] = train_predictions0[j]\n            train_predictions_ll[j] = train_predictions0_ll[j]\n        else:\n            train_predictions[j] = train_predictions1[j]\n            train_predictions_ll[j] = train_predictions1_ll[j]\n\n#    train_predictions = np.add(train_predictions0, train_predictions1)\n#    if (train_predictions.shape[-1] > 1):\n#        z_test = train_predictions.argmax\n#    else:\n#        z_test = (train_predictions > 0.5).astype('int32')\n#    acc = accuracy_score(y_test, z_test)\n    acc = accuracy_score(y_test, train_predictions)\n    print(\"Accuracy: {:.4%}\".format(acc))\n    \n    ll = log_loss(y_test, train_predictions_ll)\n    print(\"Log Loss: {}\".format(ll))\n    \n    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n    log = log.append(log_entry)\n    \nprint(\"=\"*30)",
      "execution_count": 63,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d6948e0b-fa3f-151d-baf4-a5e12f6fd1ec",
        "_active": false,
        "collapsed": false
      },
      "source": "## Submission\n\nAfter choosing your favorite classifier, format the output for a leaderboard submission. ",
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "67b61747-c076-c692-2c97-f467d4a4fd18",
        "_active": false,
        "collapsed": false
      },
      "source": null,
      "execution_count": null,
      "cell_type": "code",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e8370e61-ea98-94a6-2b46-99ca7e401e9f",
        "_active": false
      },
      "outputs": [],
      "source": "# Predict Test Set\nfavorite_clf = LinearDiscriminantAnalysis()\nfavorite_clf.fit(X_train, y_train)\ntest_predictions = favorite_clf.predict_proba(test)\n\n# Format DataFrame\nsubmission = pd.DataFrame(test_predictions, columns=classes)\nsubmission.insert(0, 'id', test_ids)\nsubmission.reset_index()\n\n# Export Submission\n#submission.to_csv('submission.csv', index = False)\nsubmission.tail()"
    }
  ]
}