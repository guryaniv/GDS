{"nbformat_minor": 1, "cells": [{"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import cv2                 # working with, mainly resizing, images\n", "import numpy as np         # dealing with arrays\n", "import os                  # dealing with directories\n", "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n", "from tqdm import tqdm      # a nice pretty percentage bar for tasks. Thanks to viewer Daniel B\u00fchler for this suggestion\n", "\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "\n", "%cd /kaggle/working\n", "\n", "TRAIN_DIR = '../input/dogs-vs-cats-redux-kernels-edition/train'\n", "TEST_DIR = '../input/dogs-vs-cats-redux-kernels-edition/test'\n", "\n", "#print(check_output([\"ls\", \"./\"]).decode(\"utf8\"))\n", "\n", "IMG_SIZE = 50\n", "LR = 1e-3\n", "\n", "#MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '2conv-basic') # just so we remember which saved model is which, sizes must match"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "cc070c244403405160c4023979ce35e28f32bc4e", "_cell_guid": "93c82a19-bf92-4a75-a769-cee9dbbba7e7"}, "execution_count": 4}, {"source": ["def label_img(img):\n", "    word_label = img.split('.')[-3]\n", "    # conversion to one-hot array [cat,dog]\n", "    #                            [much cat, no dog]\n", "    if word_label == 'cat': return [1]\n", "    #                             [no cat, very doggo]\n", "    elif word_label == 'dog': return [0]\n", "    \n", "def create_train_data():\n", "    training_data = []\n", "    for img in tqdm(os.listdir(TRAIN_DIR)):\n", "        label = label_img(img)\n", "        path = os.path.join(TRAIN_DIR,img)\n", "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n", "        \n", "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n", "        training_data.append([img,label])\n", "    \n", "    #cv2.imshow(\"foo\", img)\n", "    shuffle(training_data)\n", "    \n", "    training_data = np.array(training_data)\n", "    np.save('train_data.npy', training_data)\n", "    return training_data\n", "\n", "def process_test_data():\n", "    testing_data = []\n", "    for img in tqdm(os.listdir(TEST_DIR)):\n", "        path = os.path.join(TEST_DIR,img)\n", "        img_num = img.split('.')[0]\n", "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n", "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n", "        testing_data.append([np.array(img), img_num])\n", "        \n", "    shuffle(testing_data)\n", "    np.save('test_data.npy', testing_data)\n", "    return testing_data\n", "\n", "\n", "train_data = create_train_data()\n", "test_data = process_test_data()\n", "# If you have already created the dataset:\n", "#train_data = np.load('train_data.npy')\n", "#test_data = np.load('test_data.npy')"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "8e50b666fb34222b8f71acdec84188a8092156f3", "_cell_guid": "d60c7add-f6f6-4b2c-8d0a-27415840b2b8"}, "execution_count": 5}, {"source": ["from matplotlib import pyplot as plt\n", "\n", "from PIL import Image\n", "#plt.imshow(train_data[0][0])\n", "Image.fromarray(train_data[2][0])"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "fb5458a7e8ff27d36300471544899b56252477e3", "_cell_guid": "3d5012c7-19f8-432e-9567-a810a33af8f4"}, "execution_count": 6}, {"source": ["from keras.models import Sequential, Model, load_model\n", "from keras.applications.vgg16 import VGG16\n", "\n", "from keras import optimizers\n", "from keras.layers import Dropout, Flatten, Dense, Activation\n", "\n", "from keras.models import Sequential\n", "from keras import utils"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "ae60c5cbf9c8ad8825dae3e9c80a9e7b9c6448a7", "_cell_guid": "7ad8adac-fcaf-483a-a50e-f9d38d3a77d3"}, "execution_count": 7}, {"source": ["# Weights for VGG16\n", "from os import listdir, makedirs\n", "from os.path import join, exists, expanduser\n", "\n", "img_rows, img_cols, img_channel = IMG_SIZE, IMG_SIZE, 3\n", "\n", "WEIGHTS_DIR = '../input/vgg16'\n", "\n", "cache_dir = expanduser(join('~', '.keras'))\n", "if not exists(cache_dir):\n", "    makedirs(cache_dir)\n", "models_dir = join(cache_dir, 'models')\n", "if not exists(models_dir):\n", "    makedirs(models_dir)\n", "print(check_output([\"ls\", WEIGHTS_DIR]).decode(\"utf8\"))\n", "!cp ../input/vgg16/*notop* ~/.keras/models/\n"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "695e7a9337aa581c3693f8ec256bfb31c9fef8e6", "_cell_guid": "dbe0f870-bb02-445a-93a8-0bbd053fac85"}, "execution_count": 8}, {"source": ["train = train_data[:-500]\n", "test = train_data[-500:]"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "bcae10be1e9b5edf45ee0bba18f01c210956a933", "collapsed": true, "_cell_guid": "3ec60324-6c0c-48a6-85e4-5622990358bd"}, "execution_count": 9}, {"source": ["X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n", "Y = [i[1] for i in train]"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "90279ef517be5a6ca3664bcadc18c9b17498ad72", "collapsed": true, "_cell_guid": "ad76373c-4f2a-486b-a628-ecdeaf122b5e"}, "execution_count": 10}, {"source": ["test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n", "test_y = np.array([i[1] for i in test])"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "0fe93af2dc1d753dd81c56918382ddbf0211c994", "collapsed": true, "_cell_guid": "2872278b-0fa3-45b3-ab66-1a63b29c1661"}, "execution_count": 11}, {"source": ["from keras import backend as K\n", "\n", "#model = VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))\n", "\n", "\n", "model = Sequential()\n", "\n", "model.add(Conv2D(32, (3, 3), input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n", "#model.add(Activation('relu'))\n", "#model.add(MaxPooling2D(pool_size=(2, 2)))\n", "\n", "    # this converts our 3D feature maps to 1D feature vectors\n", "model.add(Flatten())\n", "#model.add(Dense(64))  # we now have numbers not 'images'\n", "#model.add(Activation('relu'))\n", "#model.add(Dropout(0.5))\n", "\n", "    # Output Layer\n", "model.add(Dense(1))\n", "#model.add(Activation('sigmoid'))\n", "\n", "model.compile(loss='binary_crossentropy',\n", "                  optimizer='adam',\n", "                  metrics=['accuracy'])\n", "\n", "model.fit(X[:600], np.array(Y)[:600], epochs=1, batch_size=600, verbose=1)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "a00acf1997d6d6ec3e36862ca7dfd1e9bad0bf56", "scrolled": true, "_cell_guid": "4860395d-4fce-4233-88f2-a79a9a7ed0a3"}, "execution_count": 32}, {"source": ["from keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n", "from keras.models import Sequential\n", "\n", "\n", "def shallow_net():\n", "    model = Sequential()\n", "\n", "    model.add(Conv2D(32, (3, 3), input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n", "    model.add(Activation('relu'))\n", "    model.add(MaxPooling2D(pool_size=(2, 2)))\n", "\n", "    model.add(Conv2D(32, (3, 3)))\n", "    model.add(Activation('relu'))\n", "    model.add(MaxPooling2D(pool_size=(2, 2)))\n", "\n", "    model.add(Conv2D(64, (3, 3)))\n", "    model.add(Activation('relu'))\n", "    model.add(MaxPooling2D(pool_size=(2, 2)))\n", "\n", "    # this converts our 3D feature maps to 1D feature vectors\n", "    model.add(Flatten())\n", "\n", "    model.add(Dense(64))  # we now have numbers not 'images'\n", "    model.add(Activation('relu'))\n", "    model.add(Dropout(0.5))\n", "\n", "    # Output Layer\n", "    model.add(Dense(1))\n", "    model.add(Activation('sigmoid'))\n", "\n", "    model.compile(loss='binary_crossentropy',\n", "                  optimizer='adam',\n", "                  metrics=['accuracy'])\n", "\n", "    \n", "    return model\n", "\n", "model = shallow_net()\n", "\n", "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n", "#model.summary()\n", "\n", "\n", "model.fit(X, np.array(Y), epochs=1, batch_size=6000, verbose=1)\n", "\n"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "6f99435d9623b8143a35d775d6ac6c98da41f5f5", "_cell_guid": "4b8cd14b-af8f-4ba8-ad9f-eeb9f154f2ab"}, "execution_count": 13}, {"source": ["\n", "import random\n", "\n", "d = random.choice(test_data)\n", "img_data, img_num = d\n", "data = cv2.resize(img_data, (IMG_SIZE,IMG_SIZE))\n", "prediction = model.predict(np.array([data]))[0]\n", "\n", "fig = plt.figure(figsize=(6, 6))\n", "ax = fig.add_subplot(111)\n", "ax.imshow(img_data, cmap=\"gray\")\n", "print(f\"{prediction[0]}% likelihood it is a cat\")"], "outputs": [], "cell_type": "code", "metadata": {}, "execution_count": 26}, {"source": [], "outputs": [], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "version": "3.6.4", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}