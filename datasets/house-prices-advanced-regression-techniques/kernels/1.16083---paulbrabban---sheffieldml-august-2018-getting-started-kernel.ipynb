{"cells":[{"metadata":{"_uuid":"57d0c4d74f6548f31e5ab5c49158b7968dcf4136"},"cell_type":"markdown","source":"For SheffieldML's August session, we've written a simple \"getting started\" Kernel, to help those new to machine learning or Kaggle get up and running.\n\nWhat follows demonstrates the processes of interacting with Kaggle and the data, making and visualising a model to predict house prices. It also gives you a baseline submission score of *1.16083*.\n\nYour challenge is to make a submission to Kaggle that beats it!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91115aedc05f282e44ddf6e440cdbe54da541b0a"},"cell_type":"markdown","source":"The stuff above is relevant boilerplate that Kaggle adds when you create a new kernel.\n\nFirst, I load the training set. I don't need the test set yet, I'll load that later when I'm ready to use it."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8f45ff6791ccfc34a0e226cdb8fcc42277032e84"},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70ece0b6dd40f65f91b45e1f20610c20e2c10809"},"cell_type":"markdown","source":"\nBefore I wrote the next block, I checked out what Kaggle says about the [data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data). I could see descriptions of the columns, as well as histograms that gave be a rough idea of what the data in each column looked like. I've also got the advantage of remembering some of what we discovered in the last Sheffield ML session on this competition!\n\n`OverallQual` looks like a good place to start with a linear regression. You'd expect higher quality houses to sell for higher prices, it's never missing and it has numeric values with a meaningful order - a lower number represents a lower quality than a higher one. That means I can use it without having to do any cleaning up or other munging.\n\nLet's see if there's any evidence that my guess about the relationship between `OverallQual` and `SalePrice` is correct. We can see how correlated they are really easily:"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"train[[\"OverallQual\", \"SalePrice\"]].corr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6abe4e12fa2a5d8935cc4d15f14679c6092c089f"},"cell_type":"markdown","source":"We're interested in the values of 0.79 on the off-diagonal.\n\nLooks good! A correlation of 0 would mean that there's no simple relationship between the values in these columns. That means that a higher quality *does* suggest a higher sale price.\n\nLet's visualise the relationship, by plotting the price against the quality and drawing a best fit line though the points. [Seaborn](https://seaborn.pydata.org/) is a neat visualisation library that solves that problem in one line!"},{"metadata":{"trusted":true,"_uuid":"8bffa2920cccba4aae50b90d57eef4fa2378bdfb","collapsed":true},"cell_type":"code","source":"import seaborn as sns\nresult = sns.regplot(train[\"OverallQual\"], train[\"SalePrice\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7a397e290028a0be5eb511f56420cca76a3c119"},"cell_type":"markdown","source":"It's reasonably clear that there's a relationship now! Let's train a model that we can use to predict house prices. The go-to tool in Python is [Scikit-Learn](http://scikit-learn.org/stable/)."},{"metadata":{"trusted":true,"_uuid":"24cf76b72eb735637206ee143678e628d0da1196","collapsed":true},"cell_type":"code","source":"from sklearn import linear_model\n\nmodel = linear_model.LinearRegression()\nmodel.fit(train[\"OverallQual\"].values.reshape(-1, 1), train[\"SalePrice\"].values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f08de18374215c2b7799bbc4302d71cf8e129eaa"},"cell_type":"markdown","source":"The `.values` property returns our Pandas dataframe as a numpy array, which is the data structure sklearn needs. `.reshape(-1, 1)` just turns our array (think one row) into a 2D matrix with one column instead, which again is just to confirm to what sklearn expects. If you take out those calls, the error messages you see tell you what you need to do to add them back in.\n\nSo we have a model. Let's see what it does, by asking it for the house price predictions of `OverallQual` values 1, 5 and 10:"},{"metadata":{"trusted":true,"_uuid":"3a851de462dde9270951080af72475985194121f","collapsed":true},"cell_type":"code","source":"model.predict([[1], [5], [10]]) # argument same as [1, 5, 10].reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06f778d41198f3f9ec0ecce4cde65f020a955b38"},"cell_type":"markdown","source":"Those are the prices that our model would predict for those qualities. It's a really basic model we've built, especially when qualities are integers in the range 1-10 - it'll only ever make one of 10 predictions!\nStill, it'll be a lot better than guessing randomly. Let's make our predictions from the supplied test data and submit:"},{"metadata":{"trusted":true,"_uuid":"8c68c5c0393008723fe9533141fc9d815b19f178","collapsed":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/test.csv\")\n\npredicted = model.predict(test[\"OverallQual\"].values.reshape(-1, 1))\n\nmy_submission = pd.DataFrame({'Id': test[\"Id\"], 'SalePrice': predicted})\n\nmy_submission.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba4386bf116682f486ba397ca2042d758f24b36c"},"cell_type":"markdown","source":"That's it! When you commit this notebook, a my_submission.csv will be available in the output in the view you see before you edit the notebook. You can submit by selecting it and hitting submit. [This post](https://www.kaggle.com/dansbecker/submitting-from-a-kernel) explains that part in more detail.\n\nSubmitting this results file means that Kaggle compares your predictions to the correct values and calculates your error. See [Evalution](https://www.kaggle.com/c/house-prices-advanced-regression-techniques#evaluation) for more details. You're then assigned a score - this kernel scores 1.16083. Lower is better, and the [best kernels](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/leaderboard) can score less than 0.1!\n\nTo get your own copy of this notebook as a starting point, just hit the \"Fork Notebook\" button at the top of the screen.\n\nSo the question now is - how are you going to beat 1.16083?"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}