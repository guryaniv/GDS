{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Activation, Flatten, Dense, Dropout\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport time\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\").values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"267ecdf154b97a091dfa68622f3168df9d69f64d"},"cell_type":"code","source":"def convert_to_onehot(a):\n    b = np.zeros((a.size, a.max() + 1))\n    b[np.arange(a.size), a] = 1\n    return b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3936c402a5c4ab1f953a0cb3fa0fcd074473aa3a"},"cell_type":"code","source":"X = np.reshape(train[:, 1:], (-1, 28, 28, 1))\nY = train[:, 0]\n\nimg_num = 6001\nplt.imshow(X=X[img_num].reshape(28, 28), cmap=plt.get_cmap('gray'))\nplt.title(\"Y[\" + str(img_num) + \"] = \" + str(Y[img_num]))\n\nprint(\"Y[\" + str(img_num) + \"] = \" + str(Y[img_num]))\nY = convert_to_onehot(Y)\nprint(\"One hot encoded Y[\" + str(img_num) + \"] = \" + str(Y[img_num]))\nprint()\n\nX_train, X_dev, Y_train, Y_dev = train_test_split(X, Y, test_size=0.1, random_state=42)\nprint(\"X_train shape: \" + str(X_train.shape))\nprint(\"Y_train shape: \" + str(Y_train.shape))\nprint(\"X_dev shape: \" + str(X_dev.shape))\nprint(\"Y_dev shape: \" + str(Y_dev.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49808bd0920e47bacf30ad3f89122ce5d0c8de6d"},"cell_type":"code","source":"def digitRecogModel(input_shape):\n    X_input = Input(input_shape)\n    \n    X = Conv2D(filters=16, kernel_size=3)(X_input)\n    X = Activation('relu')(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Dropout(0.2)(X)\n    X = MaxPooling2D(pool_size=2)(X)\n    \n    X = Conv2D(filters=32, kernel_size=4)(X)\n    X = Activation('relu')(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Dropout(0.2)(X)\n    X = MaxPooling2D(pool_size=2)(X)\n    \n    X = Conv2D(filters=64, kernel_size=4)(X)\n    X = Activation('relu')(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Dropout(0.2)(X)\n    X = MaxPooling2D(pool_size=2)(X)\n    \n    X = Flatten()(X)\n    X = Dense(64, activation='relu')(X)\n    X = BatchNormalization(axis=1)(X)\n    X = Dropout(0.2)(X)\n    X = Dense(32, activation='relu')(X)\n    X = BatchNormalization(axis=1)(X)\n    X = Dropout(0.2)(X)\n    X = Dense(16, activation='relu')(X)\n    X = BatchNormalization(axis=1)(X)\n    X = Dropout(0.2)(X)\n    X = Dense(10, activation='sigmoid')(X)\n    \n    model = Model(inputs=X_input, outputs=X)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf2a0ed65d5b29d87e35a3bb63b3fd27518edfb2","_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"model = digitRecogModel(X_train[0].shape)\nmodel.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f186d90d9bfa3a4ef5d6ef3ce377729630d946de","scrolled":true},"cell_type":"code","source":"start = time.time()\nmodel.fit(x=X_train, y=Y_train, epochs=100, batch_size=20)\nprint(\"Training Time: \" + str(time.time() - start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0442a0def0d0312d5b08987f7208916dfc511b06","scrolled":true},"cell_type":"code","source":"preds = model.evaluate(x=X_dev, y=Y_dev)\n\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Test Accuracy = \" + str(preds[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60d327ddbae6b6a5d1ed7347ab66b4af01e73fbb"},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv').values\nX_test = np.reshape(test, (-1, 28, 28, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d092c6cbe75e7c90ef508b0077fcb2b288eee91"},"cell_type":"code","source":"results = model.predict(x=X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"259ac36f4bcef3faead5c38538c6373724c97918"},"cell_type":"code","source":"results = np.argmax(results, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b910641ed29c844436bf76866dad7f171dd3062"},"cell_type":"code","source":"img_num = 3\nplt.imshow(X=X_test[img_num].reshape(28, 28), cmap=plt.get_cmap('gray'))\nplt.title('Prediction is ' + str(results[img_num]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6279dece726fbdf4ce85ebc72e72f8b257b74b1"},"cell_type":"code","source":"df = pd.DataFrame(results)\ndf.index.name='ImageId'\ndf.index+=1\ndf.columns=['Label']\ndf.to_csv('results.csv', header=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41e69519b49202ea409f0f50d4959d873d3d6741"},"cell_type":"markdown","source":"Learning Rate: 0.01 | Batch Size: 100<br />\nInput->Conv(16,3)->Activation(relu)->BatchNorm->Dropout(0.1)->MaxPool(2)->Conv(32,4)->Activation(relu)->BatchNorm->Dropout(0.1)->MaxPool(2)->Conv(64,4)->Activation(relu)->BatchNorm->Dropout(0.1)->MaxPool(2)<br />\n->FC(64,relu)->BatchNorm->Dropout(0.1)->FC(32,relu)->BatchNorm->Dropout(0.1)->FC(16,relu)->BatchNorm->Dropout(0.1)->FC(10,sigmoid)<br />\nEpoch 50/50<br />\n37800/37800 [==============================] - 42s 1ms/step - loss: 7.9550e-04 - acc: 0.9960<br />\nTraining Time: 2050.899270057678<br />\nLoss = 0.0015409128824879624<br />\nTest Accuracy = 0.9911904761904762<br />\n\nLearning Rate: 0.01 | Batch Size: 100<br />\nInput->Conv(16,3)->Activation(relu)->BatchNorm->Dropout(0.1)->Conv(32,4)->Activation(relu)->BatchNorm->Dropout(0.1)->Conv(64,4)->Activation(relu)->BatchNorm->Dropout(0.1)<br />\n->FC(64,relu)->BatchNorm->Dropout(0.2)->FC(32,relu)->BatchNorm->Dropout(0.2)->FC(16,relu)->BatchNorm->Dropout(0.2)->FC(10,sigmoid)<br />\nEpoch 50/50<br />\n37800/37800 [==============================] - 41s 1ms/step - loss: 0.0011 - acc: 0.9952<br />\nTraining Time: 2018.899007320404<br />\nLoss = 0.0015599045548667404<br />\nTest Accuracy = 0.9914285714285714<br />\n\nLearning Rate: 0.01 | Batch Size: 100<br />\nInput->Conv(32,3)->Activation(relu)->BatchNorm->Dropout(0.1)->Conv(64,4)->Activation(relu)->BatchNorm->Dropout(0.1)<br />\n->FC(64,relu)->BatchNorm->Dropout(0.2)->FC(32,relu)->BatchNorm->Dropout(0.2)->FC(16,relu)->BatchNorm->Dropout(0.2)->FC(10,sigmoid)<br />\nEpoch 50/50<br />\n37800/37800 [==============================] - 68s 2ms/step - loss: 8.6022e-04 - acc: 0.9967<br />\nTraining Time: 3421.957444190979<br />\nLoss = 0.0017906383639997637<br />\nTest Accuracy = 0.9902380952380953<br />"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}