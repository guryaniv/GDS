{"nbformat_minor": 0, "cells": [{"outputs": [], "metadata": {"_execution_state": "idle", "_cell_guid": "1c2f5c85-ac7c-4cd5-91fe-02da863dc340", "_uuid": "47400f9371409791c9721ec87b99695d1952324c", "collapsed": false}, "execution_count": null, "source": "### This notebook is the first try of the invasive classification\nThe first section is the visualization of image and the second part is the model part using Keras.\n\n\n- Make some edit due to run time in Kaggle Kernels ", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "1afd7af0-16e2-4693-95ff-f8cbce3b53a8", "_uuid": "7926d1769245905c3c79b90315af37e8007b170b"}, "execution_count": null, "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom glob import glob\nimport cv2\n\nfrom scipy.misc import imread\nimport os\nimport datetime, time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom subprocess import check_output", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "_cell_guid": "a35cb805-3efe-4dfd-94e6-b29ae01e0c3c", "_uuid": "b140736b59c0e9a3132d3918ce32a448bac21775", "collapsed": false}, "execution_count": null, "source": "## Section 1: Image Visualization\n\n### How many files are we dealing with?\nLet's see the number of both training and testing images for us to make a model and prediction.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "ab7ca358-0393-449b-af37-6f4ff520d913", "_uuid": "5a4f4c2f93e7dea717594a1d4ccd148301d2aeda", "collapsed": false}, "execution_count": null, "source": "# Examine the total pictures\ndef get_number_of_file(my_dir):\n    return str(len(os.listdir(my_dir)))\n\nprint(\"# of training files: {}\".format(get_number_of_file(\"../input/train\")))\nprint(\"# of testing files: {}\".format(get_number_of_file(\"../input/test\")))", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "_cell_guid": "9618b238-4d55-4f7b-bf80-e2c38b6328d6", "_uuid": "97a586824031a241af4a5db9301f05417206eec8", "collapsed": false}, "execution_count": null, "source": "### The proportion of invasive labels in training datasets", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "42271d7d-67bd-43bf-bdb4-5e74f24c5295", "_uuid": "34b83942831ea120ebb376e553d57998fd49a973", "collapsed": false}, "execution_count": null, "source": "train_labels = pd.read_csv(\"../input/train_labels.csv\")\ntrain_labels.groupby(['invasive']).size().reset_index(name='counts')", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "_cell_guid": "289387b4-0765-4ca1-ad21-ab109e9b31e7", "_uuid": "3fcbc5fa3af70bce9d8b2edd35b35e4f7fabd8a4", "collapsed": false}, "execution_count": null, "source": "### Let's visualize some images\nIn the below section, I will show some images on the training images, as well provided some filters using ***cv2***.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "11bbe2a2-9d88-4db4-8fe0-3303545d2eeb", "_uuid": "a65a3577b682d6d895117e437b47648e6eb4adf1", "collapsed": false}, "execution_count": null, "source": "def smpl_visual(path, smpl, dim_y):\n    \n    smpl_pic = glob(smpl)\n    fig = plt.figure(figsize=(20, 14))\n    \n    for i in range(len(smpl_pic)):\n        ax = fig.add_subplot(round(len(smpl_pic)/dim_y), dim_y, i+1)\n        plt.title(\"{}: Height {} Width {} Dim {}\".format(smpl_pic[i].strip(path),\n                                                         plt.imread(smpl_pic[i]).shape[0],\n                                                         plt.imread(smpl_pic[i]).shape[1],\n                                                         plt.imread(smpl_pic[i]).shape[2]\n                                                        )\n                 )\n        plt.imshow(plt.imread(smpl_pic[i]))\n        \n    return smpl_pic\n\nsmpl_pic = smpl_visual('..input/train\\\\', '../input/train/112*.jpg', 4)", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "482fa1d1-d82a-46e2-8c37-2230315a2081", "_uuid": "6da809b5cc84ba0199fedeea6d856fb1e0b54f51", "collapsed": false}, "execution_count": null, "source": "def visual_with_transformation (pic):\n\n    for idx in list(range(0, len(pic), 1)):\n        ori_smpl = cv2.imread(pic[idx])\n        smpl_1_rgb = cv2.cvtColor(cv2.imread(pic[idx]), cv2.COLOR_BGR2RGB)\n        smpl_1_lab = cv2.cvtColor(cv2.imread(pic[idx]), cv2.COLOR_BGR2LAB)\n        smpl_1_gray =  cv2.cvtColor(cv2.imread(pic[idx]), cv2.COLOR_BGR2GRAY) \n\n        f, ax = plt.subplots(1, 4,figsize=(30,20))\n        (ax1, ax2, ax3, ax4) = ax.flatten()\n        train_idx = int(pic[idx].strip(\"../input/train\\\\\").strip(\".jpg\"))\n        print(\"The Image name: {} Is Invasive?: {}\".format(pic[idx].strip(\"train\\\\\"), \n                                                           train_labels.loc[train_labels.name.values == train_idx].invasive.values)\n             )\n        ax1.set_title(\"Original - BGR\")\n        ax1.imshow(ori_smpl)\n        ax2.set_title(\"Transformed - RGB\")\n        ax2.imshow(smpl_1_rgb)\n        ax3.set_title(\"Transformed - LAB\")\n        ax3.imshow(smpl_1_lab)\n        ax4.set_title(\"Transformed - GRAY\")\n        ax4.imshow(smpl_1_gray)\n        plt.show()\n\nvisual_with_transformation(smpl_pic)", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "_cell_guid": "0f5f9bde-9d0b-41da-bd39-712ef54968f8", "_uuid": "bea84027299095bff1b7f0133e86c0befd6163ed", "collapsed": false}, "execution_count": null, "source": "## Section 2: Let's do some simple model", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "0185e982-26e7-453b-bf94-9af2000d1f49", "_uuid": "0761b81d79eac5131d894c30c95f741991a60002", "collapsed": false}, "execution_count": null, "source": "import keras\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers import Flatten, Dense, Dropout\nfrom keras.optimizers import SGD\nfrom skimage import io, transform", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "fb63e763-a6e6-4b92-bfcd-1b18230f39f7", "_uuid": "b42826dddcdb37e76a7dee6e24eb33b634a3b1cb", "collapsed": false}, "execution_count": null, "source": "# Initialize values -\n\nx_train = np.empty(shape=(100, 150, 150, 3))\ny_train = np.array(train_labels.invasive.values[0:100])\nx_val = np.empty(shape=(100, 150, 150, 3))\ny_val = np.array(train_labels.invasive.values[100:200])\n\nfor i in range(100):\n    tr_img = cv2.imread(\"../input/train/\" + str(i+1) + '.jpg')\n    x_train[i] = transform.resize(tr_img, output_shape=(150, 150, 3), mode='constant')\n\n    \nfor i in range(100):\n    val_img = cv2.imread(\"../input/train/\" + str(i+1001) + '.jpg')\n    x_val[i] = transform.resize(val_img, output_shape=(150, 150, 3), mode='constant')", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "bc8a3646-c897-45a1-b448-f78acc6f39ee", "_uuid": "84b8f0c4582b22b5fa8daef0b3202a49ecf4a24b", "collapsed": false}, "execution_count": null, "source": "# Start some model\nmodel = Sequential()\n\nmodel.add(ZeroPadding2D((1, 1), input_shape=(150, 150, 3)))\n\nmodel.add(Convolution2D(64, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(128, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(Flatten()) # maps back to 1D feature\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n\nprint(model.summary())", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "f9c4ac0b-1e8f-4dc3-b18b-253c2a55da14", "_uuid": "0e7f4852945713588f639302554f506ca00dbf89", "collapsed": false}, "execution_count": null, "source": "model.fit(x_train, y_train, epochs=3, batch_size=10)", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "e0208dfc-42af-4d20-8be1-1c44da10eea2", "_uuid": "71a3450f8cd6ec146b28f63ac626a4481feea8e1", "collapsed": false}, "execution_count": null, "source": "acc = model.evaluate(x_val, y_val)[1]\nprint('Evaluation accuracy:{0}'.format(round(acc, 4)))", "cell_type": "code"}], "metadata": {"language_info": {"name": "python", "version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat": 4}