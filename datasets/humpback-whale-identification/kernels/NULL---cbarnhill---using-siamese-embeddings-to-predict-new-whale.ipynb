{"cells":[{"metadata":{"_uuid":"8550ee3d8b7f5a1bb87fb8f23dea1e3a60134ab7"},"cell_type":"markdown","source":"# Determining 'new_whale' Position Using Siamese-Learned Embeddings\n## Overview\nLike many others, I found a lot of inspiration from [@martinpiotte](https://kaggle.com/martinpiotte)'s [work](https://www.kaggle.com/martinpiotte/whale-recognition-model-with-score-0-78563) on the playground dataset. The embeddings learned from a Siamese network architecture are such that the distance between embeddings of similar images is less than the distance between embeddings of dissimilar images. This notebook takes the following strategy for predicting out of sample whales:\n* Use siamese-learned embeddings to build an Approximate Nearest Neighbors index\n* Segment available data into:\n  * a support set \n  * a training/validation set with\n    * features based on the distance to images in the support set\n    * labels that are binary depending on whether the class has an example in the support set\n* Train a model to predict in-sample vs out-of-sample \n* Investigate how the choice of decision threshold affects precision\n* Choose multiple decision thresholds to determine which position to ultimately place 'new_whale' before submission\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"import base64\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nfrom annoy import AnnoyIndex\nfrom IPython.display import HTML\nfrom sklearn.metrics import roc_curve, auc, precision_score, f1_score, recall_score, roc_auc_score, precision_recall_curve\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom tqdm import tqdm_notebook\nfrom xgboost import XGBClassifier\n\nLABELS = '../input/humpback-whale-identification/train.csv'\nSAMPLE_SUB = '../input/humpback-whale-identification/sample_submission.csv'\nMPIOTTE = '../input/mpiotte-standard-features/mpiotte_combined_features.pkl'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38cc7d505c98f8e1b2ed8b52a4ce9277e0b2ed7c"},"cell_type":"code","source":"df = pd.read_csv(LABELS)\nsample_df = pd.read_csv(SAMPLE_SUB)\nmpiotte_combined = pd.read_pickle(MPIOTTE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71e99fb5f5f0197db1d78a90901d0d1eb8768913"},"cell_type":"code","source":"df_features = pd.merge(mpiotte_combined, df, left_on='image_name', right_on='Image', how='left', sort=False)\n\n# df_features contains embeddings for images in training and test set\ndf_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"626dff9abeb61faa37a839dba4c26de88b26a5fe"},"cell_type":"code","source":"df_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c7ea20b774a5b42cd4c656c8df6162e2ca816b1"},"cell_type":"code","source":"# embeddings are a concatenation of mpiotte_standard and mpiotte_bootstrap. 512 + 512 = 1024\nlen(df_features.loc[0, 'features'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85ffd1d8197e2ff4641ce19c2ee9581e458901b0"},"cell_type":"code","source":"# separate train/val from test\ndf_train_val = df_features[ ~df_features.Id.isnull() ].drop(columns=['image_name', 'features'])\ndf_test = df_features[ df_features.Id.isnull() ].drop(columns=['Id', 'features'])\n\n# separate unlabeled from labeled\nnew_whales = df_train_val[df_train_val.Id == 'new_whale']\nlabeled = df_train_val[df_train_val.Id != 'new_whale']\n\n# separate labeled into classes with single observation and classes with multiple observations\nsingle_obs = labeled.groupby('Id').filter(lambda x: x['Id'].count() == 1)\nmulti_obs = labeled.groupby('Id').filter(lambda x: x['Id'].count()>1)\n\n# stratifying 'multi_obs' by class, every image in 'known' should have at least one image in 'support_train' with the same class\nsupport_train, known = train_test_split(multi_obs, test_size=0.5, random_state=2, stratify=multi_obs.Id)\nknown['label'] = 'known'\n\n# 'single_obs' and 'new_whale' should have no images in 'support_train'\nunknown = pd.concat([new_whales, single_obs])\nunknown['label'] = 'unknown'\n\n# this will be the full data set for training and validation\nfull = pd.concat([unknown, known]).drop(columns=['Id'])\nfull.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0a1f62cb262b37ac86c5a77a1a58625344c1bc1"},"cell_type":"code","source":"# build Approximate Nearest Neighbors index\nf = 1024\nt = AnnoyIndex(f)\n\nfor i, row in tqdm_notebook(df_features.iterrows(), total=len(df_features.index)):\n    t.add_item(i, row['features'])\n    \nt.build(1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c071188e747101344c6ac5a9eeb959ff72638511"},"cell_type":"code","source":"# given an element's index and the support indices, return \n# * distance from element to closest neighbor in support\n# * average distance from element to 10 closest observations in support\n# * average distance from element to 100 closest observations in support\n# * average distance from element to all observations in support\ndef get_metrics(i, support_indices):\n    distances = []\n    for j in support_indices:\n        distances.append(t.get_distance(i, j))\n        \n    sorted_distance = np.sort(distances)\n        \n    return pd.Series({\n        'min_distance': sorted_distance[0],\n        'avg_10_distance': np.mean(sorted_distance[:10]), \n        'avg_100_distance': np.mean(sorted_distance[:100]), \n        'avg_distance': np.mean(distances)\n    })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8ad3f3a86d355fc8d8c2a14b061aff237652116"},"cell_type":"code","source":"# compute distance metrics for train/val set\nfull.reset_index(inplace=True)\nnew_columns = full.apply(\n    lambda row: get_metrics(row['index'], support_train.index.values.tolist()), \n    axis=1,\n    result_type='expand'\n)\nfull = pd.concat([full, new_columns], axis='columns')\nfull.set_index('index', drop=True, inplace=True)\nfull.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e484d978784caf52729c5c23de1ac3d135f465c"},"cell_type":"code","source":"# separate into x & y, train & val\nfeatures_list = ['min_distance', 'avg_10_distance', 'avg_100_distance', 'avg_distance']\nlb = LabelBinarizer()\n\nx_full = full[features_list]\ny_full = lb.fit_transform(full.label.values).ravel()\n\nx_train, x_val, y_train, y_val = train_test_split(x_full, y_full, test_size=0.25, random_state=2, stratify=y_full)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eaf3c148f225c2ea24a2eca21db6977f1770f640"},"cell_type":"code","source":"# fit classifier to train & predict probabilities on val\nclf_val1 = XGBClassifier(n_estimators=500)\nclf_val2 = RandomForestClassifier(n_estimators=1000, max_depth=10)\nclf_val3 = LinearDiscriminantAnalysis()\n\nclf_val = VotingClassifier(\n    estimators=[\n        ('XGB', clf_val1), \n        ('RF', clf_val2), \n        ('LDA', clf_val3), \n    ],\n    voting='soft'\n)\n\nclf_val.fit(x_train, y_train)\ny_scores = clf_val.predict_proba(x_val)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b78ac69645b5ba84207c070cd5bc269f4f297b03"},"cell_type":"markdown","source":"## Investigate choice of threshold"},{"metadata":{"trusted":true,"_uuid":"6619cc573872b4733b8ba8b8cf28da6e89790ec4"},"cell_type":"code","source":"def plot_roc_curve(fpr, tpr, label=None):\n    \"\"\"\n    The ROC curve, modified from \n    Hands-On Machine learning with Scikit-Learn and TensorFlow; p.91\n    \"\"\"\n    plt.figure(figsize=(8,8))\n    plt.title('ROC Curve')\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([-0.005, 1, 0, 1.005])\n    plt.xticks(np.arange(0,1, 0.05), rotation=90)\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate (Recall)\")\n    plt.legend(loc='best')\n    \nfpr, tpr, auc_thresholds = roc_curve(y_val, y_scores)\nauc(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1894e0fc4d486dfdb61a731da86817b3017d5e0"},"cell_type":"code","source":"plot_roc_curve(fpr, tpr, 'recall_optimized')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abcebbfc30cd57297b561abe630df750fa3a3cec"},"cell_type":"code","source":"p, r, thresholds = precision_recall_curve(y_val, y_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26a32956b5df3f7c3375d67f63612e4de1d20214"},"cell_type":"code","source":"def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    \"\"\"\n    Modified from:\n    Hands-On Machine learning with Scikit-Learn\n    and TensorFlow; p.89\n    \"\"\"\n    plt.figure(figsize=(8, 8))\n    plt.title(\"Precision and Recall Scores as a function of the decision threshold\")\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n    plt.ylabel(\"Score\")\n    plt.xlabel(\"Decision Threshold\")\n    plt.legend(loc='best')\n    \nplot_precision_recall_vs_threshold(p, r, thresholds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa655b1d891e9f1fb6d9e0c6c5db7c17d610ceff"},"cell_type":"code","source":"y_hat = (y_scores >= 0.8).astype(int)\n\nprecision_score(y_val, y_hat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94174733824ca0591b26c4d7173e86dd05f6847a"},"cell_type":"code","source":"f1_score(y_val, y_hat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9004e2b00d4a0024316a970dcdc8f34e5fb24aa5"},"cell_type":"code","source":"recall_score(y_val, y_hat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a6b1663a7d7769f8f9e480182d4991bfac2a040"},"cell_type":"code","source":"roc_auc_score(y_val, y_hat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0889edcb4349da283da33f42a372100f0f49abf0"},"cell_type":"code","source":"# fit on full dataset\nclf_test1 = XGBClassifier(n_estimators=500)\nclf_test2 = RandomForestClassifier(n_estimators=1000, max_depth=10)\nclf_test3 = LinearDiscriminantAnalysis()\n\nclf_test = VotingClassifier(\n    estimators=[\n        ('XGB', clf_test1),\n        ('RF', clf_test2),  \n        ('LDA', clf_test3), \n    ],\n    voting='soft'\n)\n\nclf_test.fit(x_full, y_full) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b68c64b0c06f8f80132c0f672fbe2cd733f672c2"},"cell_type":"code","source":"# when computing distance metrics for test set, use all labeled points as support\nsupport_test = labeled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90067af70125aabdacd3a9d335cdc89e0b3a93af"},"cell_type":"code","source":"# compute distance metrics for test set\ndf_test.reset_index(inplace=True)\nnew_columns = df_test.apply(\n    lambda row: get_metrics(row['index'], support_test.index.values.tolist()), \n    axis=1,\n    result_type='expand'\n)\ndf_test = pd.concat([df_test, new_columns], axis='columns')\ndf_test.set_index('index', drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83988ac6d5141125079d98c7c81847b75994612c"},"cell_type":"code","source":"# predict probabilities and apply thresholds\ndf_test['prob'] = clf_test.predict_proba(df_test[features_list])[:, 1]\ndf_test['nw_num'] = df_test.apply(lambda row: 1 if row['prob'] >=0.85 else (2 if row['prob'] > 0.5 else (3 if row['prob'] > 0.05 else 5)), axis=1)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"576e0796e5f9c5bab8c162525cedc14d51fd545e"},"cell_type":"code","source":"# generate output\nsubmission = pd.merge(\n    sample_df.drop(columns=['Id']), \n    df_test[['image_name', 'prob', 'nw_num']], \n    left_on='Image', \n    right_on='image_name', \n    how='left', \n    sort=False\n).drop(columns=['image_name'])\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b853432f9968d565c30c8747620083b648b92342"},"cell_type":"code","source":"# sanity check: \n# training set has ~38% new_whale and public LB ~27%\nlen(submission[submission.nw_num == 1].index) / len(submission.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec4eed418b4d2e190556a52b5d96cfb535b46571"},"cell_type":"code","source":"submission.to_csv('submission_new_whale.csv', header=True, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"531376f7541d30e57fa030ce64907e59bd16114d"},"cell_type":"code","source":"def create_download_link(df, title = \"Download CSV file\", filename = \"submission.csv\"):  \n    csv = df.to_csv(header=True, index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5b19d6a4882309d7774ea98102006cc4a2e6c62"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}