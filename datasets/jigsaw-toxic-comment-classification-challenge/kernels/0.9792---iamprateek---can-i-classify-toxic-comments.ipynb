{"cells": [{"source": ["#changes:except LR all other models taking so much time\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "326f783807d6854603906d3a8e31a4f73ad06eea", "collapsed": true, "_cell_guid": "d6fdcd34-eab4-4be5-9f17-bea806317501"}, "execution_count": null}, {"source": ["#import libraries\n", "train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')\n", "sub = pd.read_csv('../input/sample_submission.csv')"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "0797c43943489427b3c0aa0daafc67109aafd73b", "collapsed": true, "_cell_guid": "180cf7af-7894-48d6-9fcd-baf60d49f37d"}, "execution_count": null}, {"source": ["#shape of training dataset\n", "train.shape"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "9362612452737e88397f100886b591349e7214f0", "collapsed": true, "_cell_guid": "943e3812-1d8b-4305-99b3-570c3f96c689"}, "execution_count": null}, {"source": ["#shape of testing dataset\n", "test.shape"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "a0bf1fd43f5f5f72a71f48841d0b9ef29f82b164", "collapsed": true, "_cell_guid": "34f89493-9c82-4ff1-ba71-d20c0c9bb9de"}, "execution_count": null}, {"source": ["#peek of the dataset\n", "train.head()"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "123654486f4b95c83ea31906fb125352586e53f1", "collapsed": true, "_cell_guid": "f5e17251-086a-4a79-b87c-a37202a0fa2e"}, "execution_count": null}, {"source": ["#peek of the dataset\n", "test.head()"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "444b0ca2424ae665565437230b4ee67ed7475288", "collapsed": true, "_cell_guid": "9540db2c-9195-44cb-b73f-1ff87befa802"}, "execution_count": null}, {"source": ["#peek of the submission file\n", "sub.head()"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "ad379894b58c4a839f71d7924b918386bdfc93ae", "collapsed": true, "_cell_guid": "05894067-0601-4e65-b716-27e83c6528a1"}, "execution_count": null}, {"source": ["#check datatypes\n", "train.dtypes"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "3c3c72ad5ac98674eb56978df50baa14b6ea0363", "collapsed": true, "_cell_guid": "f6071478-067b-48a1-acef-cfc97fe1c9d1"}, "execution_count": null}, {"source": ["test.dtypes"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "8a7e2fc8ee00e41625c41febad098935311b5597", "collapsed": true, "_cell_guid": "71a70385-64fa-47a9-ac70-b7767e036a1e"}, "execution_count": null}, {"source": ["import nltk.stem\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "english_stemmer = nltk.stem.SnowballStemmer('english')\n", "class StemmedTfidfVectorizer(TfidfVectorizer):\n", "    def build_analyzer(self):\n", "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n", "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "6733e8e6d673329f5a1bcea1abb9cf5c43ecca70", "collapsed": true, "_cell_guid": "fc2fefae-2a2c-4d1e-a78d-4c5ecc6d7263"}, "execution_count": null}, {"source": ["import re\n", "def clean_text( text ):\n", "    # Function to convert a document to a sequence of words\n", "    text = re.sub(\"[^A-za-z0-9^,?!.\\/'+-=]\",\" \", text)\n", "    text = re.sub(r\"what's\", \"what is \", text)\n", "    text = re.sub(r\"\\'s\", \" \", text)\n", "    text = re.sub(r\"\\'ve\", \" have \", text)\n", "    text = re.sub(r\"can't\", \"cannot \", text)\n", "    text = re.sub(r\"n't\", \" not \", text)\n", "    text = re.sub(r\"i'm\", \"i am \", text)\n", "    text = re.sub(r\"\\'re\", \" are \", text)\n", "    text = re.sub(r\"\\'d\", \" would \", text)\n", "    text = re.sub(r\"\\'ll\", \" will \", text)\n", "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n", "    text = re.sub(r\",\", \" \", text)\n", "    text = re.sub(r\"\\.\", \" \", text)\n", "    text = re.sub(r\"!\", \" _exclamationmark_ \", text)\n", "    text = re.sub(r\"\\?\", \" _questionmark_ \", text)\n", "    return text"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "b7f91f4889450f648c50e024830ee75646d94e76", "collapsed": true, "_cell_guid": "022d1358-9f46-4493-b86c-6877d3116571"}, "execution_count": null}, {"source": ["def build_data_set(ngram=3,stem=False,max_features=2000,min_df=2,remove_stopwords=True):\n", "    train = pd.read_csv(\"../input/train.csv\")\n", "    test = pd.read_csv(\"../input/test.csv\")\n", "    test.fillna('missing',inplace=True)\n", "    clean_train_comments = []\n", "    \n", "    for i in range(train.shape[0]):\n", "        clean_train_comments.append( clean_text(train[\"comment_text\"][i]) )\n", "\n", "    for i in range(test.shape[0]):\n", "        clean_train_comments.append( clean_text(test[\"comment_text\"][i]) )\n", "        \n", "    qs = pd.Series(clean_train_comments).astype(str)\n", "    \n", "    if not stem:\n", "        # 1-gram / no-stem\n", "        vect = TfidfVectorizer(analyzer=u'word',stop_words='english',\n", "                               min_df=min_df,ngram_range=(1, ngram),max_features=max_features)\n", "        ifidf_vect = vect.fit_transform(qs) \n", "        #print(\"ifidf_vect:\", ifidf_vect.shape)\n", "        X = ifidf_vect.toarray()\n", "        X_train = X[:train.shape[0]]\n", "        X_test = X[train.shape[0]:]\n", "    else:\n", "        vect_stem = StemmedTfidfVectorizer(analyzer=u'word',stop_words='english',\n", "                                           min_df=min_df,ngram_range=(1, ngram),max_features=max_features)\n", "        ifidf_vect_stem = vect_stem.fit_transform(qs)\n", "        #print(\"ifidf_vect_stem:\", ifidf_vect_stem.shape)\n", "        X = ifidf_vect_stem.toarray()\n", "        X_train = X[:train.shape[0]]\n", "        X_test = X[train.shape[0]:]\n", "    Y_train = train[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]\n", "    assert Y_train.shape[0] == X_train.shape[0]\n", "    del train, test\n", "    return X_train,X_test,Y_train"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "90a55e44741d1570c362c85d148532db9a5b772d", "collapsed": true, "_cell_guid": "5d6adeb7-7c4e-47c0-969c-f86c103cb63a"}, "execution_count": null}, {"source": ["labels = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n", "params = {\n", "    'toxic': {'ngrams': 1, 'stem': True, 'max_features': 1000, 'C': 10 } , \n", "    'threat': {'ngrams': 1, 'stem': False, 'max_features': 1000, 'C': 10 } , \n", "    'severe_toxic': {'ngrams': 1, 'stem': True, 'max_features': 1000, 'C': 1.2 } , \n", "    'obscene': {'ngrams': 1, 'stem': True, 'max_features': 1000, 'C': 10 } , \n", "    'insult': {'ngrams': 1, 'stem': True, 'max_features': 1000, 'C': 1.2 } , \n", "    'identity_hate': {'ngrams': 1, 'stem': True, 'max_features': 1000, 'C': 10 } \n", "}"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "1b9e0d8d820845a4cf509057af42e4cc8b632582", "collapsed": true, "_cell_guid": "975d016f-5841-47f3-a2e2-fd89fc7d630a"}, "execution_count": null}, {"source": ["import time\n", "from sklearn import model_selection\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.svm import SVC\n", "from sklearn import svm\n", "from sklearn import metrics\n", "from sklearn.model_selection import cross_val_score"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "2df8c6f059ecf4db0c3d5cdfeb3d24d228978e12", "collapsed": true, "_cell_guid": "cb9b7de3-6dad-43ce-836d-9a6553b5a34a"}, "execution_count": null}, {"source": ["start_time = time.time()\n", "\n", "for label in labels:\n", "    print(\">>> processing \",label)\n", "    \n", "    X_train,X_test,Y_train = build_data_set(ngram=params[label]['ngrams'],\n", "                                            stem=params[label]['stem'],\n", "                                            max_features=params[label]['max_features'],\n", "                                            min_df=2,remove_stopwords=True)\n", "    Y_train_lab = Y_train[label]\n", "    seed = 7\n", "    scoring = 'accuracy'\n", "    # Spot Check Algorithms\n", "    models = []\n", "    models.append(('LR', LogisticRegression()))\n", "    #models.append(('LDA', LinearDiscriminantAnalysis()))\n", "    #models.append(('KNN', KNeighborsClassifier()))\n", "    #models.append(('CART', DecisionTreeClassifier()))\n", "    #models.append(('NB', GaussianNB()))\n", "    #models.append(('SVM', SVC()))\n", "    # evaluate each model in turn\n", "    results = []\n", "    names = []\n", "    for name, model in models:\n", "        kfold = model_selection.KFold(n_splits=10, random_state=seed)\n", "        cv_results = model_selection.cross_val_score(model, X_train, Y_train_lab, cv=kfold, scoring=scoring)\n", "        results.append(cv_results)\n", "        names.append(name)\n", "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n", "        print(msg)"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "b54df39ef67d27b2c4c4b48e48a19a08bfc64fc9", "collapsed": true, "_cell_guid": "19d9fdb6-eaf0-4e08-b06f-a6a0002db45b"}, "execution_count": null}, {"source": ["#sub[label] = output\n", "#sub.to_csv(\"output_.csv\", index=False)"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "a0bf40440b4212f50d09058f58aac23046a34fa5", "collapsed": true, "_cell_guid": "282ae7ac-e1b2-4ce5-b9ec-c4072af9e886"}, "execution_count": null}], "metadata": {"language_info": {"file_extension": ".py", "pygments_lexer": "ipython3", "name": "python", "nbconvert_exporter": "python", "version": "3.6.3", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat": 4, "nbformat_minor": 1}