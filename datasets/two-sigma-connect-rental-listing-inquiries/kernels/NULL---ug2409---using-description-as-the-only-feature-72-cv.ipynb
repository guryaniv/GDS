{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "df89a24e-7f2b-c7e4-d8bd-143e825b120f"
      },
      "source": [
        "This notebook shows how you can use description to improve your model. We will be using description, as the only feature for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c99a12fb-9db6-470e-8fec-d7796fb6b684"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6d13d410-c4e9-a4c0-da18-ccded6ff6ac2"
      },
      "outputs": [],
      "source": [
        "train = pd.read_json(\"../input/train.json\")\n",
        "test = pd.read_json(\"../input/test.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cb6798d0-b85f-ccb5-730c-162680e3caae"
      },
      "outputs": [],
      "source": [
        "# We need listing_id, description and interest_level for this notebook\n",
        "train = train[['listing_id','description','interest_level']]\n",
        "test = test[['listing_id','description']]\n",
        "\n",
        "train['flag'] = 'train'\n",
        "test['flag'] = 'test'\n",
        "full_data = pd.concat([train,test])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1ab762f5-b231-ec0f-953b-0850983c6efb"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6b9e1ada-7ef5-f7d4-4e46-bdef5dde445d"
      },
      "source": [
        "> Stemming is the process of reducing inflected (or sometimes derived) words to their word stem. Example: gardens to garden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4143321c-43e2-c607-05ed-ce9030f5593c"
      },
      "outputs": [],
      "source": [
        "# Removes symbols, numbers and stem the words to reduce dimentional space\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def clean(x):\n",
        "    regex = re.compile('[^a-zA-Z ]')\n",
        "    # For user clarity, broken it into three steps\n",
        "    i = regex.sub(' ', x).lower()\n",
        "    i = i.split(\" \") \n",
        "    i= [stemmer.stem(l) for l in i]\n",
        "    i= \" \".join([l.strip() for l in i if (len(l)>2) ]) # Keeping words that have length greater than 2\n",
        "    return i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "015450db-fe3b-6183-75b5-9d121af07522"
      },
      "outputs": [],
      "source": [
        "# This takes some time to run. It would be helpful if someone can help me optimize clean() function.\n",
        "full_data['description_new'] = full_data.description.apply(lambda x: clean(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5cad277c-d263-43c6-d37f-68c65f2f3606"
      },
      "outputs": [],
      "source": [
        "full_data[['description','description_new']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "68a40924-2496-d610-21c2-a7112e3af6cf"
      },
      "source": [
        "We have removed all punctuation and numbers, as we are only interested in words for now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8165ac23-2acd-d50b-1a00-ebc515e7da85"
      },
      "source": [
        "### Using CountVectorizer\n",
        "We can use CountVectorizer or tfidfvectorizer for building a word matrix. For me countvectorizer gave better performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c419401-ae92-3644-ac80-868b7c0bd0ae"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer #Can use tfidffvectorizer as well\n",
        "\n",
        "cvect_desc = CountVectorizer(stop_words='english', max_features=200)\n",
        "full_sparse = cvect_desc.fit_transform(full_data.description_new)\n",
        " # Renaming words to avoid collisions with other feature names in the model\n",
        "col_desc = ['desc_'+ i for i in cvect_desc.get_feature_names()] \n",
        "count_vect_df = pd.DataFrame(full_sparse.todense(), columns=col_desc)\n",
        "full_data = pd.concat([full_data.reset_index(),count_vect_df],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "67625d28-40c0-b2e2-f102-6e77a6af7bd0"
      },
      "outputs": [],
      "source": [
        "full_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f3a1bf52-baea-8e8e-dc83-7cea90558207"
      },
      "source": [
        "### Running Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "90ef0b2c-efb0-ac7a-7e0a-852757083c15"
      },
      "outputs": [],
      "source": [
        "train =(full_data[full_data.flag=='train'])\n",
        "test =(full_data[full_data.flag=='test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5390381f-4bcf-6014-5e5e-e231ae487ece"
      },
      "outputs": [],
      "source": [
        "labels = {'high':0, 'medium':1, 'low':2}\n",
        "train['interest_level'] = train.interest_level.apply(lambda x: labels[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "367fadf9-3fc3-08fe-3381-4df7fe006dcb"
      },
      "outputs": [],
      "source": [
        "feat = train.drop(['interest_level','flag','listing_id','description','index','description_new'],axis=1).columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3e534cff-57f8-1b69-e290-8b3f9e97b25e"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier  as GBM\n",
        "from sklearn.ensemble import RandomForestClassifier  as RF\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3051e9e6-6636-b1df-26aa-74791cdf1454"
      },
      "outputs": [],
      "source": [
        "def run_mod(train_X, test_X,train_Y):\n",
        "    reg = GBM(max_features = 'auto',n_estimators=200,random_state=1)\n",
        "    reg.fit(train_X,train_Y)\n",
        "    pred = reg.predict_proba(test_X)\n",
        "    imp = reg.feature_importances_\n",
        "    return pred,imp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f079c8f8-3e6b-59e2-7cf4-28b600357101"
      },
      "outputs": [],
      "source": [
        "def cross_val(train,feat,split):\n",
        "    cv_scores = []\n",
        "    importances = []\n",
        "    # Cross Validation preprocessing\n",
        "    train_X = train[feat]\n",
        "    train_Y = train['interest_level']\n",
        "\n",
        "    train_X = train_X.as_matrix()\n",
        "    train_Y = train_Y.as_matrix()\n",
        "\n",
        "    test_X = test[feat]\n",
        "    test_X = test_X.as_matrix()\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=split, shuffle=True, random_state=1)\n",
        "    for dev_index, val_index in kf.split(train_X,train_Y):\n",
        "            train_X_X, test_X_X = train_X[dev_index,:], train_X[val_index,:]\n",
        "            train_Y_Y, test_Y_Y = train_Y[dev_index,], train_Y[val_index,]\n",
        "            pred,imp = run_mod(train_X_X, test_X_X,train_Y_Y)\n",
        "            cv_scores.append(log_loss(test_Y_Y, pred))\n",
        "            importances.append(imp)\n",
        "    return np.mean(cv_scores),importances\n",
        "#print np.average(importances,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f032c46a-d567-bfc9-491b-0b284027b58c"
      },
      "outputs": [],
      "source": [
        "cv_score,imp = cross_val(train,feat,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "caefc629-b598-0617-04d0-869429dee2d1"
      },
      "outputs": [],
      "source": [
        "cv_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "60b98eb6-3cdb-279f-89ce-b4706a5fc514"
      },
      "outputs": [],
      "source": [
        "# Lets chaeck the importance of words\n",
        "importances = list(np.average(imp,axis=0))\n",
        "features = cvect_desc.get_feature_names()\n",
        "df = pd.DataFrame({'words':features,'imp':importances}).sort_values(by='imp',ascending=False).head(30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8a2dbbeb-f044-fcf5-255e-6fcd72b473c2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,15))\n",
        "sns.barplot(y=df.words,x=df.imp)\n",
        "# Remember, these are stemmed words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "db714d32-d6b8-f5bc-a6fe-9d17729a838a"
      },
      "source": [
        "* Well, the score is using description and an untuned GBM. But a tuned one dies on me in this kernal (though it has score of 0.71). \n",
        "* It would be great if someone can post what score they get using XGB.\n",
        "* I think it is a good start for someone just starting out with text data. Similar transformation can be done with column feature.\n",
        "* It would be great if someone can help me optimize the clean() function.\n",
        "\n",
        "Thanks!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b84450aa-0b5c-e97c-0950-b97c944bc149"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}